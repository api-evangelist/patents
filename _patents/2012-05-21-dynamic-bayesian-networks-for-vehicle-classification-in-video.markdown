---
title: Dynamic Bayesian Networks for vehicle classification in video
abstract: A system and method for classification of passenger vehicles and measuring their properties, and more particularly to a stochastic multi-class vehicle classification system, which classifies a vehicle (given its direct rear-side view) into one of four classes Sedan, Pickup truck, SUV/Minivan, and unknown, and wherein a feature pool of tail light and vehicle dimensions is extracted which feeds a feature selection algorithm to define a low-dimensional feature vector, and the feature vector is then processed by a Hybrid Dynamic Bayesian Network (HDBN) to classify each vehicle.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09466000&OS=09466000&RS=09466000
owner: THE REGENTS OF THE UNIVERSITY OF CALIFORNIA
number: 09466000
owner_city: Oakland
owner_country: US
publication_date: 20120521
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","GOVERNMENT INTEREST","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY","DETAILED DESCRIPTION","CONCLUSION"],"p":["This application claims priority under 35 U.S.C. \u00a7119 to U.S. Provisional Application No. 61\/487,944 entitled DYNAMIC BAYESIAN NETWORKS FOR VEHICLE CLASSIFICATION IN VIDEO, filed May 19, 2011, the entire content of which is hereby incorporated by reference.","This invention was made with Government support under Grant No. IIS0905671 awarded by National Science Foundation. The Government has certain rights in this invention.","The present invention relates to a system and method for classification of passenger vehicles and measuring their properties, and more particularly to a stochastic multi-class vehicle classification system, which classifies a vehicle (given its direct rear-side view) into one of four classes Sedan, Pickup truck, SUV\/Minivan, and unknown, and wherein a feature pool of tail light and vehicle dimensions is extracted, which feeds a feature selection algorithm to define a low-dimensional feature vector, and the feature vector is then processed by a Hybrid Dynamic Bayesian Network (HDBN) to classify each vehicle.","Over the past few years vehicle classification has been widely studied as part of the broader vehicle recognition research area. A vehicle classification system is essential for effective transportation systems (e.g., traffic management and toll systems), parking optimization, law enforcement, autonomous navigation, etc. A common approach utilizes vision-based methods to detect and classify a vehicle in still images and video streams. A human being may be capable of identifying the class of a vehicle with a quick glance at the digital data (image, video) but accomplishing that with a computer is not as straight forward. Several problems such as occlusion, tracking a moving object, shadows, rotation, lack of color invariance, and many more must be carefully considered in order to design an effective and robust automatic vehicle classification system. Much research has been conducted for object classification, but vehicle classification has shown to have its own specific problems, which motivates research in this area.","Not much has been done on vehicle classification from the rear view. For the side view, appearance based methods especially edge-based methods have been widely used for vehicle classification. These approaches utilize various methods such as weighted edge matching, Gabor features, edge models, shape based classifiers, part based modeling, and edge point groups. Model-based approaches that use additional prior shape information have also been investigated in 2D (two-dimensions) and more recently in 3D (three-dimensions).","Vehicle make and model classification from the frontal view has also been investigated (i.e., high resolution, close up frontal view images, neural network classifier), and also (SIFT features). For the rear view, Dlagnekov extends a new license plate recognition system to perform vehicle make and model recognition for video surveillance using a database of partial license plate and vehicle visual description data. Adaboost and cascaded classifiers are used to detect the license plate. Given the license plate, visual features are extracted using two feature-based methods (SIFT and shape context matching) and one appearance-based method (Eigencars). The drawbacks of the proposed system are that it does not perform color inference, is relatively slow, and only the license plate recognition stage is done in real-time.","Vehicle classification has evolved into a significant subject of study due to its importance in autonomous navigation, traffic analysis, surveillance and security systems, and transportation management. While numerous approaches have been introduced for this purpose, no specific study has been able to provide a robust and complete video-based vehicle classification system based on the rear-side view where the camera's field of view is directly behind the vehicle. In accordance with an embodiment, a stochastic multi-class vehicle classification system is presented, which classifies a vehicle (given its direct rear-side view) into one of four classes Sedan, Pickup truck, SUV\/Minivan, and unknown. A feature pool of low-level tail light and vehicle dimension features is extracted, which feeds a feature selection algorithm to define a low-dimensional feature vector. The feature vector is then processed by a Hybrid Dynamic Bayesian Network (HDBN) to classify each vehicle.","In accordance with an exemplary embodiment, a method for vehicle classification comprises: performing a Bayesian network analysis for vehicle classifications, which are known, wherein the Bayesian network is defined as a directed acyclic graph G=(V, E) where the nodes (vertices) represent random variables from the domain of interest and the arcs (edges) symbolize the direct dependencies between the random variables.","In accordance with a further exemplary embodiment, a system for classification of vehicles comprises: a camera for capturing images of at least one moving object; and a computer processing unit, which performs the steps as recited herein.","In accordance with another exemplary embodiment, a computer program product comprising a non-transitory computer usable medium having a computer readable code embodied therein for classification of passenger vehicles and measuring their properties from a rear view video frame, the computer readable program code is configured to execute a process, which performs the steps as recited herein.","The details of one or more embodiments of the disclosure are set forth in the accompanying drawings and the description below. Other features, objects, and advantages will be apparent from the description and drawings, and from the claims.","In accordance with an exemplary embodiment, a probabilistic classification framework is disclosed, which determines the class of a vehicle given its direct rear view (). It can be appreciated that the main classes can include Sedan, Pickup truck, SUV\/minivan, and also a class for unknown vehicles. In accordance with an embodiment, SUVs and minivans were combined because the number of available minivans in the dataset was small. However, it would be desirable to distinguish minivans from SUVs after obtaining a reasonable number of minivans for our training dataset.","In accordance with an exemplary embodiment, the direct rear view is chosen for two main reasons. First, most of the research in this area has focused on the side view, whereas the frontal view and rear view have been less investigated. Secondly, the license place location is a descriptive feature of a vehicle's class (e.g., usually pickup truck's license plate is mounted on the bumper) but not all states require a front license plate (e.g., 19 states in the USA require only the rear license plate).","In accordance with an exemplary embodiment, a Hybrid Dynamic Bayesian Network (HDBN) classifier with multiple time slices corresponding to multiple video frames to increase classification accuracy is disclosed. In accordance with an exemplary embodiment, the need for high resolution images\/videos is eliminated by using simple low-level features (e.g., height, width, and angle), which are also computationally inexpensive, thus, the proposed method is capable of running in real-time.","Technical Approach","The complete proposed system pipeline is shown in , which includes data collection, feature extraction, feature selection, and classification. Each of the components are explained in the following sections.","Feature Extraction","In accordance with an embodiment, three main types of features are extracted from the images; tail lights, license plate, and rear dimensions. The tail light features include separately for each tail light, a width, distance from the license plate, and an angle between tail light and license plate. The license plate location and size is used as a reference to enable comparison and help normalize tail light properties and vehicle size values. The feature extraction component consists of three subcomponents: vehicle detection, license plate extraction, and tail light extraction.","Vehicle Detection","In accordance with an embodiment, a Gaussian mixture model approach is used for moving object detection. The Gaussian distributions are used to determine if a pixel is more likely to belong to the background model or not. An AND approach is used which determines a pixel as background only if it falls within three standard deviations for all the components in all three R, G, and B color channels (i.e., red, green, and blue color channels). The detected moving object is validated by using a simple frame differencing approach and cross checking the masks from both methods.","The resulting mask may include some shadow and erroneous pixels. The shadow is removed by finding the vertical axis of symmetry using an accelerated version of Loy's symmetry and readjusting the bounding box containing the mask with respect to the axis of symmetry. This is preferably done by measuring the distance between each point on both vertical sides of the bounding box and the axis symmetry and moving the vertical side that is farther away closer to the axis of symmetry such that each side has the same distance from it.  shows results from multiple steps of this approach. The aforementioned shadow removal method fails if the shadow is behind the vehicle. In such cases, the shadow is preferably removed using the approach introduced by Nadimi et al., which does not rely on the common geometrical assumptions such as camera location, object geometry, and ground surface geometry. Given the vehicle rear mask, the height and width of the bounding box and area of the mask are measured.","License Plate Extraction","The license plate corner coordinates are input into the algorithm. It can be appreciated that there are a number of algorithms for license plate extraction. In accordance with an exemplary embodiment, the corners of the license plate are manually extracted. To have more realistic license plate location coordinates, Gaussian noise with constant mean 0 and variance 0.2 time width is added to the license plate width measurement.","Tail Light Extraction","For tail light detection, the regions of the image where red color pixels are dominant are located. The redness of each image pixel can be computed by fusing two methods. In the first approach, the image is converted to HSV (hue, saturation, and value) color space and then pixels are classified into three main color groups red, green, and blue. The second method proposed by Gao et. al defines the red level of each pixel as",{"@attributes":{"id":"p-0039","num":"0038"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["r","i"]},"mo":"=","mfrac":{"mrow":[{"mn":"2","mo":"\u2062","msub":{"mi":["r","i"]}},{"msub":[{"mi":["G","i"]},{"mi":["B","i"]}],"mo":"+"}]}}}},"br":{},"figref":"FIG. 4"},"Feature Pool","As the result of the feature extraction component, the following 11 features are extracted from each image frame (all distances are normalized with respect to the license plate width):","1. perpendicular distance from license plate centroid to a line connecting two tail light centroids;","2. right tail light width;","3. left tail light width;","4. right tail light-license plate angle;","5. left tail light-license plate angle;","6. right tail light-license plate distance;","7. left tail light-license plate distance;","8. bounding box width;","9. bounding box height;","10. license plate distance to bounding box bottom side; and","11. vehicle mask area.","Given a set of features Y, feature selection determines a subset X which optimizes an evaluation criterion J. Feature selection is performed for various reasons including improving classification accuracy, shortening computational time, reducing measurements costs, and relieving the curse of dimensionality. In accordance with an exemplary embodiment, a Sequential Floating Forward Selection (SFFS) was chosen, which returns a single suboptimal solution. SFFS starts from an empty set and adds the most significant features (e.g., features that increase accuracy the most). The SFFS provides a kind of back tracking by removing the least significant feature during the third step, conditional exclusion. A stopping condition is required to halt the SFFS algorithm, therefore, in accordance with an exemplary embodiment, the number of feature selection iterative steps is limited to 2(where n is the number of features) and a correct classification rate (CCR) threshold of b % where b is greater than the CCR of the case when all features are used is defined. In other words, the algorithm stops when either the CCR is greater than b %, or 2iterations are completed. The pseudo code for SFFS is shown below, wherein k is the number of features already selected.","1. Initialization: k=0; X={\u00d8}","2. Inclusion: add the most significant feature\n\n","3. Conditional Exclusion: find the least significant feature and remove (if not last added)\n\n","4. Continuation of Conditional Exclusion\n\n","5. Stopping Condition Check\n\n",{"@attributes":{"id":"p-0059","num":"0069"},"figref":"FIG. 5"},"Classification","1) Known or Unknown","The classification component consists of a two stage approach. Initially, the vehicle feature vector is classified as known or unknown. To do such, the Gaussian distribution parameters of the distance to the nearest neighbor for all vehicles in the training dataset are estimated. To determine if a vehicle test case is known or unknown first the distance to its nearest neighbor is computed. Then following the empirical rule if the distance does not lie within 4 standard deviations of the mean (\u03bc\u00b14\u03c3) it is classified as unknown. If the vehicle is classified as known it is a candidate for the second stage of classification.","2) DBNs for Classification","In accordance with an exemplary embodiment, the use of a Dynamic Bayesian Networks (DBNs) for vehicle classification in video is proposed.","Bayesian networks offer a very effective way to represent and factor joint probability distributions in a graphical manner, which makes them suitable for classification purposes. A Bayesian network is defined as a directed acyclic graph G=(V, E) where the nodes (vertices) represent random variables from the domain of interest and the arcs (edges) symbolize the direct dependencies between the random variables. For a Bayesian network with n nodes X, X, . . . , Xthe full joint distribution is defined as:",{"@attributes":{"id":"p-0066","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"},{"mi":["x","n"]}],"mo":[",",",","\u2062",","],"mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}}},{"mrow":[{"mrow":[{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"x","mn":"1"}}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"x","mn":"2"},{"mi":"x","mn":"1"}],"mo":"\u2758"}}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":[{"mi":["x","n"]},{"mi":"x","mn":"1"}],"mo":"\u2758"},"mo":[",",",","\u2062",","],"msub":[{"mi":"x","mn":"2"},{"mi":"x","mrow":{"mi":"i","mo":"-","mn":"1"}}],"mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}}}],"mo":["\u00d7","\u00d7","\u00d7"],"mi":"\u2026"},{"munderover":{"mo":"\u220f","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":"\u2062","mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mn":"1"}],"mo":"\u2758"},"mo":[",","\u2062",","],"mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"msub":{"mi":"x","mrow":{"mi":"i","mo":"-","mn":"1"}}}}}}],"mo":"="}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0067","num":"0077"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"p","mo":"(","mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":[",",",","\u2062",","],"mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"msub":{"mi":"x","mrow":{"mi":"n","mo":")"}},"mo":"=","mrow":{"munderover":{"mo":"\u220f","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":"\u2062","mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","i"]},"mo":"\u2758","mrow":{"mi":"parents","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["X","i"]}}}}}}}}}}}},"br":{},"sub":["1","2","n","1","1 ","n","n"],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00001","he":"2.12mm","wi":"1.78mm","file":"US09466000-20161011-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00002","he":"2.12mm","wi":"1.78mm","file":"US09466000-20161011-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}]},"In accordance with an embodiment, the accuracy of the model is based on the structure of the Bayesian network. For example, learning the best structure\/topology for a Bayesian network takes exponential time because the numbers of possible structures for a set of given nodes is super-exponential in the number of nodes. To avoid performing exhaustive search, a K2 algorithm (Cooper and Herskovits, 1992) may be used to determine a sub-optimal structure. K2 is a greedy algorithm that incrementally add parents to a node according to a score function. In accordance with an exemplary embodiment, a BIC (Bayesian Information Criterion) function may be used as the scoring function.  illustrates the resulting Bayesian network structure. In accordance with another exemplary embodiment, a manually structured network () is defined and the two structures are compared. The details for each node are as following:","1. C: vehicle class, discrete hidden node, size=3","2. LP: license plate, continuous observed node, size=2","3. LTL: left tail light, continuous observed node, size=3","4. RTL: right tail light, continuous observed node, size=3","5. RD: rear dimensions, continuous observed node, size=3","For continuous nodes the size indicates the number of features each node is representing, and for the discrete node C it denotes the number of classes. RTL and LTL are continuous nodes and each contain the normalized width, angle with the license plate, and normalized Euclidean distance with the license plate centroid. LP is a continuous node with distance to the bounding box bottom side and perpendicular distance to the line connecting the two tail light centroids as its features. RD is a continuous node with bounding box width and height, and vehicle mask area as its features. For each continuous node of size n, a multivariate Gaussian conditional probability distribution (CPD) is defined, where each feature of each continuous node has \u03bc=[\u03bc, . . . \u03bc]and \u03a3 as an n\u00d7n symmetric, positive definite covariance matrix. The discrete node C has a corresponding conditional probability table (CPT) assigned to it which defines the probabilities P(C=sedan), P(C=pickup), and P(C=SUV or minivan).","Adding a temporal dimension to a standard Bayesian network creates a DBN. The time dimension is explicit, discrete, and helps model a probability distribution over a time-invariant process. In accordance with an exemplary embodiment, a DBN is created by replicating a Bayesian network with time-dependent random variables over T time slices. A new set of arcs defining the transition model is also used to determine how various random variables are related between time slices.","In accordance with an exemplary embodiment, a video based classifier is modeled by extending the aforementioned Bayesian network () to a DBN. The DBN structure is defined as following:","1. for each time slice tthe DBN structure is similar to the Bayesian network structure given in .","2. each feature Xis the parent of X.","3. C\u2032 is the parent of C.","4. all intra slice dependencies (arcs) also hold as inter time slices except for arcs from time slice t hidden nodes to time slice t+1 observed nodes.",{"@attributes":{"id":"p-0081","num":"0091"},"figref":"FIG. 7","sub":["1 ","i,i=2, . . . , 5 "]},"p(LTL|C, LTL), p(RTL|C, RTL)","p(C|C), p(RD|C, RD)","p(LP|C, LTL, RTL, LP, LTL, RTL)","For example, to determine p(LTL|C, LTL) three distributions with different parameters, one for each value of C, are required. Hence, p(LTL|LTL, C=sedan), p(LTL|LTL, C=pickup), and p(LTL|LTL, C=SUV or Minivan) are estimated, and p(LTL|LTL) is derived by summing over all the Ccases.","The next step is inference where a probability distribution over the set of vehicle classes is assigned to the feature vector representing a vehicle. In other words inference provides p(C|f) where frefers to all features from time slice tto t.","Experiments","Data Collection","In accordance with an exemplary embodiment, video data of passing vehicles was captured using a Sony HDR-SR12 Video Camera. The videos are taken in the early afternoon with sunny and partly cloudy conditions. Lossless compressed PNG image files were extracted from the original HD MPEG4 AVC\/H.264 video format, and then down sampled from 1440\u00d71080 to 320\u00d7240 using bicubic interpolation. Downsampling is performed to reduce the computation time. All image frames were manually labeled with the vehicle class to provide the ground-truth for evaluation purposes.","The dataset consists of 100 sedans, 27 pickup trucks, and 42 SUV\/minivans. Before extracting the features and generating the feature pool, it is important to determine the number of frames required for classification. Classification accuracy was recorded for different number of frames. The maximum accuracy is achieved when 5 frames are used. Note that these frames are not successive. In accordance with an exemplary embodiment, \u0394t=2 was used, which means leaving out two frames between candidate frames. This value is directly related to the speed of the vehicle and the overall time the vehicle is visible in the camera's field of view.","To evaluate how well the algorithm performs in the case of an unknown vehicle, 8 unknown vehicles were collected, which were not part of the training dataset.  shows two examples of unknown vehicles.",{"@attributes":{"id":"p-0092","num":"0102"},"figref":"FIG. 9"},"Feature Selection Evaluation","Table I shows classification evaluation metrics both when (a) using the entire feature set, and (b) using a suboptimal subset. Results show that using the subset of the features generated by SFFS decreases the accuracy and precision by approximately 1%. Feature selection also decreases the average testing time per frame from 0.05 to 0.03 seconds.",{"@attributes":{"id":"p-0095","num":"0105"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Feature Selection Results"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["FS","Selected",{},"FA",{},"Testing"]},{"entry":["Method","features","Precision","Rate","CCR","time(s)"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["(a) None","all","95.68","0.02","97.63","0.05"]},{"entry":["(b) SFFS","1, 4, 6, 10,","94.23","0.03","96.68","0.03"]},{"entry":[{},"11"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}]}}},"Classification Results","In accordance with an exemplary embodiment, a Bayes Net Toolbox (BNT), an open source Matlab package, was used for defining the DBN structure, parameter learning, and computing the marginal distribution on the class node. In accordance with an exemplary embodiment, the proposed classification system was tested on a dataset consisting of 169 known and 8 unknown vehicles. A stratified k-fold cross-validation with k=10 was used to evaluate the approach. The resulting confusion matrix is shown in Table II. As shown, all sedans are correctly classified except for the one that is misclassified as a pickup truck ().  shows an SUV misclassified as a pickup truck. A closer look at the data and pattern-feature matrix shows great similarity for both these cases with the pickup class due to the license plate location and rear tail light width.",{"@attributes":{"id":"p-0098","num":"0108"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE II"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Confusion Matrix"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Pred. Class"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},{},{},"SUV\/",{}]},{"entry":["True Class","Unknown","Sedan","Pickup","Minivan","Total"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Unknown","8","0","0","0","8"]},{"entry":["Sedan","0","99","1","0","100"]},{"entry":["Pickup","0","0","27","0","27"]},{"entry":["SUV\/Minivan","0","3","2","37","42"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}]}}},"Structure Learning Evaluation","Table III presents the classification evaluation metrics for the two structures given in  and . The results show that learning the structure using K2 decreases the classification accuracy and precision. This is because the K2 search algorithm requires a known linear ordering of nodes prior to model selection. One way to overcome this is to determine the ordering of nodes prior to performing K2. Determining the required ordering using a dynamic programming approach takes O(n2) time and O(n2) space where n is the number of nodes. The linear order determines the possible parent candidates for each node in a way that the BN is guaranteed to be an acyclic graph.",{"@attributes":{"id":"p-0101","num":"0111"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE III"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Structure Learning Evaluation"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Structure Learning","Precision","FA Rate","CCR"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"K2&BIC (FIG. 6(a))","93.68","0.04","96.06"]},{"entry":[{},"Manual (FIG. 6(b))","95.68","0.02","97.63"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}]}}},"Comparison with Other Methods","The results were compared with 3 well-known classifiers: k-nearest neighbor (kNN), linear discriminant analysis (LDA), and support vector machines (SVM). Tables IV, V, and VI show classification accuracy, false positive ratio (false alarm), and precision respectively. The class \u201cunknown\u201d is not included in computing the results for Tables IV, V, and VI.",{"@attributes":{"id":"p-0104","num":"0114"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE IV"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"CCR COMPARISON"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"14pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Classifier",{}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"56pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Vehicle Class","kNN","LDA","SVM","HDBN"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]},{"entry":[{},"Sedan","88.25","94.67","96.44","97.63"]},{"entry":[{},"Pickup","95.12","94.67","96.44","98.22"]},{"entry":[{},"SUV\/Minivan","90.90","92-89","92.30","97.04"]},{"entry":[{},"Overall","91.42","94.07","95.06","97.63"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0105","num":"0115"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE V"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"FALSE ALARM PERCENTAGES COMPARISON"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"126pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"14pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Classifier",{}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"49pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Vehicle Class","kNN","LDA","SVM","HBN"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]},{"entry":[{},"Sedan","0.17","0.07","0.06","0.04"]},{"entry":[{},"Pickup","0.04","0.05","0.03","0.02"]},{"entry":[{},"SUV\/Minivan","0.04","0.02","0.04","0"]},{"entry":[{},"Overall","0.09","0.05","0.04","0.02"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0106","num":"0116"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE VI"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"PRECISION PERCENTAGES COMPARISON"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"14pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Classifier",{}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"56pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Vehicle Class","kNN","LDA","SVM","HBN"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"56pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Sedan","88.46","95.05","96.07","97.05"]},{"entry":[{},"Pickup","80.64","78.13","86.20","90.00"]},{"entry":[{},"SUV\/Minivan","85.29","91.67","87.17","100"]},{"entry":[{},"Overall","84.80","88.28","89.81","95.68"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0107","num":"0117"},"figref":"FIG. 11"},"In accordance with an exemplary embodiment, a Dynamic Bayesian Network for vehicle classification using multiple video frames in a DBN structure can outperform well known classifiers such as kNN, LDA, and SVM. Experimental results showed that obtaining high classification accuracy does not always require high level features and simple features (e.g., normalized distance and angle) may also provide such results making it possible to perform real-time classification.","In accordance with another exemplary embodiment, a computer program product comprising a non-transitory computer usable medium having a computer readable code embodied therein for classification of passenger vehicles and measuring their properties from a rear view video frame, the computer readable program code is configured to execute a process, which performs the steps as recited herein.","The computer usable medium, of course, may be a magnetic recording medium, a magneto-optic recording medium, or any other recording medium which will be developed in future, all of which can be considered applicable to the present invention in all the same way. Duplicates of such medium including primary and secondary duplicate products and others are considered equivalent to the above medium without doubt. Furthermore, even if an embodiment of the present invention is a combination of software and hardware, it does not deviate from the concept of the invention at all. The present invention may be implemented such that its software part has been written onto a recording medium in advance and will be read as required in operation.","It will be understood that the foregoing description is of the preferred embodiments, and is, therefore, merely representative of the article and methods of manufacturing the same. It can be appreciated that many variations and modifications of the different embodiments in light of the above teachings will be readily apparent to those skilled in the art. Accordingly, the exemplary embodiments, as well as alternative embodiments, may be made without departing from the spirit and scope of the articles and methods as set forth in the attached claims."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings are included to provide a further understanding of the invention, and are incorporated in and constitute a part of this specification. The drawings illustrate embodiments of the invention and, together with the description, serve to explain the principles of the invention. In the drawings,",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIGS. 6() and 6()"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 7","sub":"i"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
