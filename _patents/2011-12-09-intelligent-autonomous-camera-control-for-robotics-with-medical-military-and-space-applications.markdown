---
title: Intelligent autonomous camera control for robotics with medical, military, and space applications
abstract: A system for autonomous camera control includes a first robot having a surgical tool mounted as an end effector and a second robot having a camera mounted as an end effector. A controller may be provided for manipulating the second robot, where the controller stores a first kinematic model for the first robot and a second kinematic model for the second robot. The controller may be configured to automatically manipulate the second robot to position the camera based on the second kinematic model and an expected position of the surgical tool according the first kinematic model of the first robot. The controller is further configured to identify a threshold angle from a viewing axis of the camera, calculate a tool angle from the viewing axis of the camera, and move the camera toward or further away from the tool depending on if the tool angle is greater than or less than the threshold angle.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09439556&OS=09439556&RS=09439556
owner: Wayne State University
number: 09439556
owner_city: Detroit
owner_country: US
publication_date: 20111209
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND","Field of the Invention","DETAILED DESCRIPTION"],"p":["This application is a 371 national stage application of PCT Application No. PCT\/US2011\/064171, filed Dec. 9, 2011, which application claims the benefit of U.S. Provisional Patent Application No. 61\/421,877 filed Dec. 10, 2010, the content of which is hereby incorporated by reference in its entirety.","This application is related to a robotic system with autonomous camera control.","A system for autonomous camera control is provided. The system may include a first robot having a surgical tool mounted as an end effector and a second robot having a camera mounted as an end effector. A controller may be provided for manipulating the second robot, where the controller stores a first kinematic model for the first robot and a second kinematic model for the second robot. The controller may be configured to automatically manipulate the second robot to position the camera based on the second kinematic model and an expected position of the surgical tool according the first kinematic model of the first robot.","The controller may be configured to identify a threshold angle from a viewing axis of the camera, calculate a tool angle from the viewing axis of the camera, moving camera further away from the tool if the tool angle is greater than the threshold angle.","The tool angle is calculated according to the relationship:",{"@attributes":{"id":"p-0034","num":"0033"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"\u03b8","mo":"=","mrow":{"msup":{"mi":"cos","mrow":{"mo":"-","mn":"1"}},"mo":["(",")"],"mfrac":{"mrow":[{"mover":[{"msub":{"mi":["V","RC"]},"mo":"\u2192"},{"msub":{"mi":["V","CT"]},"mo":"\u2192"}],"mo":"\u00b7"},{"mrow":[{"mo":["\uf603","\uf604"],"msub":{"mi":["V","RC"]}},{"mo":["\uf603","\uf604"],"msub":{"mi":["V","CT"]}}],"mo":"*"}]}}}}},"br":{},"sub":["RC ","CT "]},"The angles and threshold angles may be relative to the camera viewing axis, and distances may be calculated based on the kinematic model of the camera carrying robot and the kinematic model of the tool carrying robot. Although it is understood that other methodologies may be used including using the camera image, or external measuring devices, like trackers. Further, it understood that the viewing axis would be a line typically perpendicular to the sensing surface of the camera extending from the center of the sensing surface. However, it is also understood in the art that viewing axis may vary, for example based on the optical setup the viewing axis may be bent or transformed by the optical system.","The controller may also be configured to calculate a distance of the camera from a trocar point. As such, the controller may prevent the camera from adjusting the camera backward based on the threshold angle when the distance of the camera from the trocar point is less than a threshold distance.","The controller may be configured to identify a threshold angle from a viewing axis of the camera, calculate a tool angle from the viewing axis of the camera, moving camera closer to the surgical tool if the surgical tool angle is less than the threshold angle.","The controller also may be configured to calculate a distance of the camera from the surgical tool, the controller preventing the camera from adjusting the camera toward the surgical tool based on the threshold angle when the distance of the camera from the surgical tool is less than a threshold distance.","The controller may be in communication with an input device for control of the first robot and a display for providing an image from the camera, the system being configured to maintain the relation between the image and the input device. The relationship may be maintained by manipulating (e.g. rotating, transforming, etc.) the image or by moving the robot in response to input device based at least in part on the coordinate system of the image.","The controller may also track the roll of the camera and provide cues to the surgeon suggesting the direction of motion of the surgical tool.","The controller may also be configured to maintain a relationship between the camera and the tool based on the first and second kinematic model. Further, the controller may be configured to position the camera so that the tool is in the center of the view.","The controller may calculate a first point which is on a line between the trocar point and the surgical tool, where the first point is located a distance away from the trocar point that is about one fourth of a distance from the trocar point to the surgical tool.","The controller may position the camera based on the relationship:\n\n\n\nwhere Tis the transform from the camera to the tool, Tis the transform from the origin of the second robot to the tool, Tis the transform from the origin of the second robot to the camera.\n","The system of any of the previous claims, wherein the first robot is one robot of a plurality of robots each robot of the plurality of robots having a surgical tool of a plurality of surgical tools, and controller is configured to position the camera such that the mid-point of the plurality surgical tools is in the center of the field of view of the camera. In addition, the system may include other elements as further described throughout this specification.","In another aspect of the system, the controller is configured to define a zone such that the first robot will not be allowed to enter the zone. As such, the controller may be configured to determine the motion of the second robot to avoid entering the zone that was defined with respect to the first robot.","A method for autonomous camera control is also contemplated. The method may include, storing a first kinematic model for a first robot and a second kinematic model for a second robot, and automatically manipulating the second robot to position a camera based on the second kinematic model and an expected position of a surgical tool mounted on the first robot according the first kinematic model of the first robot.","The method may also include identifying a threshold angle from a viewing axis of the camera, calculating a tool angle from the viewing axis of the camera, moving camera further away from the tool if the tool angle is greater than the threshold angle.","The method may also include identifying a threshold angle from a viewing axis of the camera, calculating a tool angle from the viewing axis of the camera, and moving camera closer to the surgical tool if the surgical tool angle is less than the threshold angle.","The method may also include communicating with an input device for control of the first robot and a display for providing an image from the camera, and maintaining the relation between the image and the input device.","The method may also include maintaining a relationship between the camera and the tool based on the first and second kinematic model.","The method may also include calculating a first point which is on a line between the trocar point and the surgical tool, wherein the first point is located a distance away from the trocar point that is about one fourth of a distance from the trocar point to the surgical tool, and moving the camera to the first point. In addition, the method may include other elements as further described throughout this specification.","A computer readable medium containing instructions in the form of a computer program for performing the method steps or for controlling system elements as described throughout this specification is also contemplated herein.","Robots are being used to perform a wide range of surgeries. They have provided surgeons with additional features like motion scaling, tremor filtration etc. While robotics has made the surgeon's life easier in the operating room by augmenting their abilities, automation of the surgery has not yet been possible. As a first step towards automation, this project is intended to develop an autonomous camera positioning system for the existing surgical robot platforms. In some system implementations, the system may be designed to enable the surgeon to control the position of the camera without using the conventional methods, like a remote control or voice control. The surgeon should not need to worry about the camera position while doing his tasks, and the system could calculate the best position for the camera and control the position of the camera accordingly.","In this section, minimally invasive and robotic surgery is discussed, however, the system described herein could be adapted to military and space applications, as well.","Laparoscopic surgery, also known as, Minimally Invasive Surgery (MIS), is a technique where long tools are inserted into the patient's body through small incisions to perform a surgery. This allows the surgeons to perform the surgery without having to make large incisions in the patient's body. For the open procedure, the patient was opened to access the internal organs. Whereas in a laparoscopic procedure, the internal organs are accessed using long tools through small openings in the patient's abdomen.","Laparoscopic surgeries are usually performed in the abdominal area. Since the patient is not opened to access the organs, there is very little space for the surgeons to operate the tools. In order to overcome this problem, the area at which the operation is performed is filled with Carbon Dioxide (CO) to inflate the area. The laparoscopic tools, along with a laparoscopic camera, are then inserted into the patient's body.","The video from the laparoscopic camera is shown to the surgeon who operates the tools based on these images. There are a wide range of laparoscopic tools to perform different types of surgical tasks like holding, cutting, cauterizing, etc. The tools and the camera are inserted into the body through small openings called trocars. The surgeon can move the tool inside the patient's body by moving the handles on the other side of the tool, which is outside the patient's body.","MIS has many advantages over open procedures. Since the size of the incisions is much smaller when compared to those of an open surgery the patient has less pain after the surgery and less blood loss which leads to faster recovery times.","However, in MIS the surgeon is forced to operate with long instruments whose motion is highly restricted by the small opening through which it is inserted into the body. Also, the opening through which the tools are inserted act as a pivot point and all the motions are reversed. Hence, if the surgeon has to move the tip of the tool to the left, he has to move his hand to the right. This is called the fulcrum effect. It is also possible that the amount of tremor in the surgeons hand is amplified at the tip of the tools, based on the position of the opening with respect to the tool.","In laparoscopic surgery, the camera is held by an assistant who follows the surgeon's instructions and places the camera wherever the surgeon asks. One disadvantage of the assistant holding the camera is that camera is not held by stable platform. Any tremor in the assistant's hands will lead to blurred images and fatigue will played major role in the assistant's ability to hold the camera at the same place. When comparing the performance between a robot and an assistant holding the camera during a surgery, it has been found that robot provides a stable platform and better accuracy than a surgical assistant.","Hence performing MIS is more difficult for the surgeon because of reduced dexterity, the fulcrum effect and poor ergonomic conditions. There have also been a few reports suggesting that the surgeons experience physical deformities on themselves while performing MIS over a long period of time. A study was performed on laparoscopic surgeons and found that laparoscopic surgery is more taxing on the surgeons. The report indicated that 87% of laparoscopic surgeons who perform laparoscopic surgery regularly suffer from injuries.","In order to eliminate the difficulties involved in traditional MIS, robots are being used manipulate the laparoscopic tools. Robotic surgery puts the surgeon in an ergonomically comfortable position during the surgery. It also eliminates the fulcrum effect and tremors. Robotic surgery also provides certain features like motion scaling, where the large motions of the surgeons can be scaled down to small motions of the tools, which leads to more accuracy. Robotic surgery also restores the 6 degrees of freedom at the tools, where the tools are restricted to only 4 degrees of freedom in traditional MIS.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 1","b":"120"},"a) In and Out (arrow ).","b) Up and Down (arrow ).","c) Left and Right (arrow ).","d) Rotation\/Roll (arrow ).","On the other hand, in robotic surgery, the degrees of freedom of the robotic tool are similar to those of the human hand. Because of this feature, the surgeons will be able to reach certain areas which were hard to reach using traditional MIS. Robotic systems also provide much more stable platform to hold the laparoscopic camera when compared to traditional laparoscopic approach, where the camera is held by an assistant.","Robotic surgery augments the strengths of the surgeon with those of the robot. Robots are tireless and accurate. They can move the surgical instruments in a defined trajectory any number of times with the same precision and accuracy. On the other hand, a surgeon is medically trained and is driven by judgment. Hence, a partnership between the surgeon and the robot can result in performing a task better than either can perform alone. Robotic surgery, currently, is performed in a master-slave environment, where the surgeon manipulates a controller remotely and the robot performs the surgery on the patient. This mode of operation is also known as teleoperation. In this master-slave environment, the robot can be controlled only by the surgeon's actions and there are no automated tasks being done. The \u201cZeus\u00ae Robotic Surgical System\u201d (Intuitive Surgical Inc. Sunnyvale, Calif.) and the \u201cda Vinci Surgical System\u201d (Intuitive Surgical Inc. Sunnyvale, Calif.) are the most commonly used surgical robots.",{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 2","b":["210","212","214","216","218","220","212","222","212"]},{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 3","b":["300","310","312","314"]},"Even with the advantages of robotic surgery over traditional laparoscopic procedures, there are certain tasks which the surgeons find difficult to perform, especially when they are repeated again and again. Tasks like suturing and knot tying are some of the most common tasks performed in surgery. It has been found that suturing sometimes can take more time when performed robotically when compared to that of a laparoscopic procedure. Hence automation or augmentation of these tasks within the robotic surgery environment might be desirable. In this way, repetitive tasks could be done automatically such that the surgeon's performance could be increased. This would lead towards a better partnership between the surgeon and the robot and can possibly reduce the time taken to perform these surgeries. The current systems provide only visual feedback to the surgeon and do not provide any kind of positional feedback. The current systems which are built for master-slave control only are closed architecture and do not provide the position and orientation of the operating tool tip. This positional feedback of the end-effector is necessary to perform any kind of automation using the robot. In addition, most surgeries utilize more than one surgical arm and hence a kinematic relation between each arm is highly important in order to coordinate automation between arms. For example, if the surgeon wants to define a boundary or a safe zone for the robot to maneuver, without a kinematic relationship between the robots, the surgeon is forced to define the boundaries for each robot. If a kinematic relationship between each robot is determined, then defining the boundaries with one robot would be sufficient as these boundaries can be transformed between each robot. Also a kinematic relationship between each of the robots links can be used to avoid collision between the robots.","The closed architecture of the current robotic systems do not allow for programming or research into automation. Therefore, the robotic systems may be modified to enable kinematic feedback of the surgical tools and autonomous control.  shows a basic block diagram of a surgical system, which allows such kinematic feedback and also automation of tasks. The surgeon  interacts with the master controller  to provide input for controlling the Zeus robot and surgical tool attached thereto. The master controller  may be in communication with a motion capture platform  to interpret the user input from the surgeon . The motion capture platform provides commands to the control software  based on the user input. The control software  provides kinematic feedback  to the surgeon, while the surgeon may provide automation commands  to the control software . The control software  may then provide commands to a motion controller . The motion controller  may then provide signals to the motors of the robot  to manipulate the robot joints according to the user input. The robot  using the surgical tool interacts with the patient site . The camera  simultaneously images the patient site  and provides visual feedback to the surgeon . In addition, the control software  for the motion of the surgical tool may be in communication with the control software  for the motion of the camera. The control software  may provide commands to the motion controller  for manipulating the robot  to position the camera  based on the information from the control software . Further it is understood that one of more of the controller, platform, or software blocks represented in  may be integrated into a single controller system or may work together in cooperation as separate elements which collectively and simply may be referred to as a controller elsewhere in this application.","The motion control hardware of present systems can be modified or replaced to enable kinematic feedback and automation, along with the ability to tele-operate the robot. The hardware\/software interface shown in the figure can control the robot based on the signals from the master controller and also provide the user with positional feedback of the end effector and the ability to automate tasks.","The positional feedback can also be obtained using position trackers and external sensors. However, using such equipment would require additional space in the operating room. The most common types of position trackers are either optical or magnetic. Using an optical tracker requires a clear line of sight between the sensor and the reflectors, which is an issue with the number of people and instruments in the operating room. The magnetic trackers do not work well in an environment filled with ferrous metals, and the robots are made of metal which rules out their use. Moreover, using these sensors would increase the setup time. For these reasons, it may be desirable to have a system which does not add to the current equipment.","In the current robotic systems, the camera holder is operated by the surgeon to change the view. During a surgical task, if the surgeon wants to change the view, he has to switch between the tool control and camera control. This leads to some necessary down-time during the surgery. This can be avoided if the camera holder can adjust itself dynamically as required by the surgeon to give an optimal view of the surgical site. During surgery there are certain scenarios, like knot tying, in which the tools would go out of the camera view. In such cases the position of the camera can be autonomously adjusted so that the tools will always be in the view. In this type of control, the surgeon does not have to worry about switching the controls to change the view of the camera. The surgeon can move the tools wherever he\/she wants to and the camera will automatically adjust itself so that the tools are centered. Such a system can reduce both effort and time required for the surgery.","In some systems, the position of the tools may be detected using the images from the laparoscopic camera. There are other image processing based systems to identify the position of the tools. The one problem with such systems is the reduced visibility of the tools during certain conditions of the surgery, where there is a lot of smoke and water vapor present. Reduced visibility can mislead image based systems and can lead to errors. This system may also encounter problems in detecting the tools due to specular reflection. Other systems may adjust the camera view based on the positions of the laparoscopic tools. This system relies on the images obtained from the camera view to determine the position of the tools. They also rely on special markings on the tools to enable tool detection. Other systems may control the camera based on the position of the tool, using electromagnetic position sensors to detect the position of the tool and the camera. Using sensors to detect the position of the tools adds to the already complex environment in the operating room. Also electromagnetic sensors do not work well near metals. On the other hand, with positional feedback from the robot, a system can be developed which can autonomously adjust the position of the camera so that the tools are always in the view.","In developing the systems described herein, the motion control hardware of the Zeus Surgical System was redesigned to perform MIS using the robot along with the positional feedback of the tool's end-effector and automation of surgical tasks. The another aim is to develop a control system for the AESOP Robot, which holds a laparoscopic camera, and autonomously adjust the position of the camera based on the position of the tools.","In the original Zeus Surgical system, the Zeus and AESOP Robots are controlled by the Zeus Master Controller, which houses all the control circuits for the robots. Because of its closed architecture, it is not possible to modify their system for our requirements. However, the cable connecting the master controller to the robots may be spliced to understand how it works and which wires control which parts of the robots.","The Zeus Robot is used to control the laparoscopic tools and is controlled by the surgeon using the master controller. The AESOP robot is used to control the laparoscopic camera and is controlled either by a remote or through voice commands. The mechanical structure of the Zeus and AESOP robots are similar, except for one extra joint on the Zeus robot. This makes it easy to develop the motion control systems and the kinematics for these robots.","The Zeus robot  has seven joints in total. Out of the seven joints, five of them are active joints, e.g., their position can be controlled by the motors. The other two joints do not have motors and are called passive joints. All the joints have feedback mechanism. The active joints have encoders and potentiometers for feedback while the passive joints have only potentiometers for feedback. All the joints were given names for convenience of this description, they are \u2018Linear\u2019 , \u2018Shoulder\u2019 , \u2018Elbow\u2019 , \u2018Wrist\u2019  \u2018Finger\u2019 , \u2018Nail\u2019  and \u2018Yaw\u2019 . Out of these, the \u2018Linear\u2019 , \u2018Shoulder\u2019 , \u2018Elbow\u2019 , \u2018Nail\u2019  and \u2018Yaw\u2019  are the active joints and the \u2018Wrist\u2019  and \u2018Finger\u2019  joints are passive. The \u2018Finger\u2019 and \u2018Yaw\u2019 joints were not used in testing the autonomous camera control project because they control only the orientation of the gripper and do not alter the position of the gripper and hence are not useful for tracking with the camera.  shows the Zeus robot and the names of each joint. The direction of motion of each joint is also denoted. All the joints except the \u2018Linear\u2019 joint  are rotary joints and the \u2018Linear\u2019 joint , as the name suggests, has linear motion.","The AESOP Robot  is very similar to the Zeus Robot . The only difference is that it does not have the \u2018Yaw\u2019 joint, which is in the Zeus Robot. The \u2018Linear\u2019 , \u2018Shoulder\u2019 , \u2018Elbow\u2019  and \u2018Nail\u2019  are the active joints and the \u2018Wrist\u2019  and \u2018Finger\u2019  joints are passive. The \u2018Nail\u2019  joint in the AESOP robot controls the roll of the camera and was not used for testing this system.  shows the AESOP  robot and the names of each joint. The directions that each joint of the robot moves is also denoted.","The AESOP robot also has encoders and potentiometers for the purpose of feedback.","The feedback from the joints can be used to calculate the joint angles. The encoders may be used in the active joints to calculate the angles and the potentiometers may be used in the passive joints. The encoder counts in the \u2018Linear\u2019 joints  provide the linear displacement of the joint and the encoder counts in the \u2018Shoulder\u2019  and \u2018Elbow\u2019  give the angular displacement of the joint with respect to the X-axis of the robot. The potentiometer readings provide the angular displacement of the passive joints with respect to their previous joints.","The \u2018Shoulder\u2019  and the \u2018Elbow\u2019  joints in both Zeus and AESOP robots are linked to each other. When the \u2018Shoulder\u2019 joint  is moved in the clock wise direction, the \u2018Elbow\u2019 joint  moves in the counterclockwise direction and if the \u2018Shoulder\u2019 joint  is moved in the counterclockwise direction, the \u2018Elbow\u2019 joint  moves in the clockwise direction. However, when the \u2018Elbow\u2019 joint  is moved, it does not affect the \u2018Shoulder\u2019 joint . This causes problems when measuring the joint angles.","The link between the \u2018Shoulder\u2019 and \u2018Elbow\u2019 joint ,  means that when the \u2018Shoulder\u2019  is moved, the encoder value at the \u2018Elbow\u2019 joint  also changes and hence results in a change in the angle even when the \u2018Elbow\u2019 joint  is not moved. In order to avoid this problem, the angle of the \u2018Shoulder\u2019 joint  is subtracted from the value of the \u2018Elbow\u2019 joint  to obtain the angle of the \u2018Elbow\u2019 joint  with respect to the \u2018Shoulder\u2019 joint .","Motion Controllers are typically electronic circuits used to control robotic arms or manipulators using motors and drives. They usually provide position or velocity control of each motor. They are closed loop control systems which control the motors based on the feedback from the motor shaft. The feedback can be either in the form of a quadrature encoder or a potentiometer.  shows the basic block diagram of a motion controller setup, where the controller controls a D.C. Motor based on the feedback from encoder connected to the shaft of the motor.","The motion controller used to control Zeus and AESOP robots is the Galil DMC-21\u00d73 Controller.  is a block diagram of the setup of a motion controller system . Figure shows a motion controller  used to control a D.C. Motor  at each joint of the robot using encoders as feedback. The input command  can be either a target position or target speed and the controller generates motor control signals  to manipulate controls the position or speed of the motor  based on the input . The motion controller  may use encoders  connected to the motor  to generate a feedback signal  to the motion controller .","The Galil Motion Controller DMC21\u00d73 has the ability to control D.C. motors with encoder feedback and can also read the potentiometer values. It provides two options for communication, through RS-232 communication or Ethernet. DMC Smart Terminal, software provided by Galil, is used to establish communication with the motion controller and to control the robots. The communication libraries are also provided which allows building software in C++ to communicate with the motion controller and control the robot. Two motion controllers were used for the project, one for each robot. The DMC2183 controller (can control up to 8 motors) is used to control the Zeus robot and the DMC2143 controller (can control up to 4 motors) is used to control the AESOP robot.","The motion controller contains an amplifier board which provides the connectors to connect to the motors and the encoders. This board amplifies the control signals before sending them to the motors. Each pair of connectors is named as \u2018X\u2019, \u2018Y\u2019, \u2018Z\u2019 and \u2018W\u2019. The motion controller also has a separate board to read analog signals. This board is used to read the potentiometer values from the passive joints. The controller provides a wide range of commands to control the motors and get feedback from the encoders. The ones used commonly for testing this implementation are listed below.","Galil Motion Controller Commands","1. Position Relative (PR)\n\n","2. Position Absolute (PA)\n\n","3. Begin Movement (BG)\n\n","4. Tell Position (TP)\n\n","5. Speed (SP)\n\n","6. Acceleration (AC)\n\n","7. Deceleration (DC)\n\n","8. Stop (ST)\n\n","9. Abort (AB)\n\n","10. Jog (JG)\n\n","11. Tell Torque (TT)\n\n","12. Define Position (OP)\n\n","13. Tell Error (TE)\n\n","The Zeus and AESOP robots fall under the category of manipulator arms, which are basically a series of joints attached to one another. The \u2018Linear\u2019 joint is connected to the base of the robot at one end and to the \u2018Shoulder\u2019 joint at the other end. Similarly, one end of the \u2018Elbow\u2019 is connected to the \u2018Shoulder\u2019 and the other end is connected to the \u2018Wrist\u2019. This way the whole robot comprises of links and joints connected to one another to form the kinematic model of the whole robot. The calculations involved in controlling each joint to position the end-effector at the target position and orientation is called kinematics of the robot. This involves two types of calculations. They are:\n\n","To control the robot and to calculate the kinematics of the robot, it is necessary for us to know the angle of each joint, with respect to the previous joint. These robots have five joints, out of which three are active and two are passive (Zeus has two additional active joints and AESOP has one active joint but these joints were not used for testing this project). The active joints, which can be controlled by motors, comprise optical encoders and potentiometers to provide positional feedback. The passive joints are free moving joints and their position depends on the positions of the active joints and the trocar point through which the tool is placed. The passive joints have only potentiometers for positional feedback.","In order to get the conversion between the encoder counts at the joints of the robot and the angles, the total span on each joint and the total range of the corresponding encoder can be measured. Using this data, the number of encoder counts required to move a joint by one degree can be determined. The encoder count of each joint is obtained from the Galil Motion Controller. The position of each joint, in mm\/rad, may be obtained from a Polaris Tracking System. Polaris is an optical tracking instrument which is used to get the position of a point in 3D space. It uses infra-red light and cameras to track specific tools, with infrared reflectors, in 3D space.","The tip of the tracking tool is placed at two different points of a joint, with the joints at different positions. The positions of the tip are recorded and then used to calculate the angle between each orientation of the joint. Two points on the joint were chosen and the tracking tool was placed on these points to record the position of the two points, while the joint was moved along its range of motion. While recording the position of the tracking tool tip, the encoder count of the joint is also recorded.  shows a vector diagram of the tracked points on the joint. A and B are the points ,  on the joint at position  and Aand Bare the points ,  on the joint at position . Vis the vector  from Bto Aand Vis the vector  from Bto A. \u03b8 is the angle between Vand V.","The angle, \u03b8 is calculated using the following formula.",{"@attributes":{"id":"p-0109","num":"0126"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"\u03b8","mo":"=","mrow":{"msup":{"mi":"cos","mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mfrac":{"mrow":[{"mover":[{"msub":{"mi":"V","mn":"1"},"mo":"\u2192"},{"msub":{"mi":"V","mn":"2"},"mo":"\u2192"}],"mo":"\u00b7"},{"mrow":[{"mo":["\uf603","\uf604"],"msub":{"mi":"V","mn":"1"}},{"mo":["\uf603","\uf604"],"msub":{"mi":"V","mn":"2"}}],"mo":"*"}]}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"1"}}]}}}}},"The measurements were taken all along the range of the motion of the joints and the average encoder counts per radian were calculated. This was done for both the Zeus and AESOP robots. The calculated conversion factors are:","Conversion factors for Zeus Robot:",{"@attributes":{"id":"p-0112","num":"0129"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":[{},"Joint Name","Encoder Counts"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Linear","173.8779707\/mm"]},{"entry":[{},"Shoulder","\u221221113.92907\/radian"]},{"entry":[{},"Elbow","\u221221425.51029\/radian"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"Conversion factors for AESOP Robot:",{"@attributes":{"id":"p-0114","num":"0131"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":[{},"Joint Name","Encoder Counts"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Linear","\u2212792.6891211\/mm"]},{"entry":[{},"Shoulder","131582.8693\/radian"]},{"entry":[{},"Elbow","\u2212114998.1311\/radian"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"Since there was no way to control the position of the passive joints and the inability to use conventional methods like protractors and scales, a camera was used to take pictures and measure the angles. The camera was placed at a level, which is parallel to the robot's arm. Then, pictures of the joint at different positions were taken and the corresponding potentiometer readings were noted. Then a line on the joint and the base are taken and the angle between the lines is measured.","As shown in , the pixel positions of the points A, B, Aand Bwere noted down. These pixel positions were taken as the co-ordinate points in a plane parallel to the face of the camera. The slopes of the \u2018Joint Line\u2019 (AB)  and the \u2018Base Line\u2019 (AB)  may be calculated. Further, the angle between the lines is calculated using these slopes.","Following the same procedure, the angles between the arm and the base may be calculated and the corresponding potentiometer values may be taken. A graph may be plotted between the angle and the voltage.  shows the plot  between the angle of the wrist and the voltage for the Zeus robot. A linear relation was obtained between the voltage and angle. The calculated relation for the wrist joint of the Zeus Robot is:\n\nAngle=\u22120.259*Voltage+0.091\u2003\u2003Equation 2\n","The same procedure may be followed to obtain the relation between the voltages and joint angles for the AESOP Robot.  shows the plot  between the angle of the wrist and the voltage for the AESOP robot. The calculated relation for the wrist joint of the AESOP Robot is:\n\nAngle=\u22120.2637*Voltage+0.0096\u2003\u2003Equation 3\n","In a similar way, the joint angles for the finger may be measured and plotted against the corresponding voltages.  shows the points taken on the finger joint for the calculations, including two points on the base Aand Bto form the base line  and two points on the figure Aand Bto form the arm line .",{"@attributes":{"id":"p-0120","num":"0137"},"figref":"FIG. 13","b":"1310","br":{},"in-line-formulae":[{},{}]},{"@attributes":{"id":"p-0121","num":"0138"},"figref":"FIG. 14","b":"1410","br":{},"in-line-formulae":[{},{}]},"In all multi-link robots, each link is connected to another link and the relation between them is given by the homogeneous transformation matrix between each pair of the links connected at a joint. A commonly used convention to represent the transformation matrices is the Oenavit and Hartenberg Convention [19]. In this convention, each homogeneous transformation is represented by four parameters called O-H Parameters. O-H Parameters are essential to calculate the kinematics of any robot. The O-H Parameters for the Zeus robot are obtained from Martinsen [20]. Table 3 shows the O-H Parameters of the Zeus robot.",{"@attributes":{"id":"p-0123","num":"0140"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"D-H Parameters of the Zeus Robot."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},{},{},{},{},"Hardware"]},{"entry":["Link","a","\u03b1","d","\u03b8","Joint Type","Joint"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","0","0","0","0","Translational","Linear"]},{"entry":["2","384.44","0","0","0","Rotational","Shoulder"]},{"entry":["3","52.71","pi\/2","0","0","Rotational","Elbow"]},{"entry":["4","0","Pi\/2","0","Pi\/2","Non-Moveable","Dummy"]},{"entry":["5","0","Pi\/2","250.7","Pi","Rotational","Wrist"]},{"entry":["6","17.2","\u2212pi\/2\u2002","0","Pi\/2","Rotational","Finger"]},{"entry":["7","0","Pi","0","0","Rotational","Nail"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}}]}}},"The D-H Parameters for the AESOP robot may be obtained by measuring the distance between each joint using Vernier Calipers. Table 4 shows the O-H Parameters of the AESOP robot.","These D-H Parameters may be used to calculate and generate the homogeneous transformation matrices for each joint and may be used to calculate the forward kinematics and inverse kinematics of the robot.",{"@attributes":{"id":"p-0126","num":"0143"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 4"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Table 4: D-H Parameters of the AESOP 1000 Robot."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},{},{},{},{},"Hardware"]},{"entry":["Link","a","\u03b1","d","\u03b8","Joint Type","Joint"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","0","0","0","0","Translational","Linear"]},{"entry":["2","384.44","0","0","0","Rotational","Shoulder"]},{"entry":["3","52.71","pi\/2","0","0","Rotational","Elbow"]},{"entry":["4","0","pi\/2","0","pi\/2","Non-Moveable","Dummy"]},{"entry":["5","0","pi\/2","250.7","pi","Rotational","Wrist"]},{"entry":["6","17.2","\u2212pi\/2\u2002","0","pi\/2","Rotational","Finger"]},{"entry":["7","0","pi","0","\u2212pi\/2\u2002","Rotational","Nail"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}}]}}},"In addition, a direct solution for the inverse kinematics of the robots may be implemented. As discussed earlier, the robots have two passive joints, which cannot be controlled by motors and whose position depends on the position of the trocar through which the tool is inserted.  shows the Zeus robot  holding the tool  and the trocar point key hole . Pis the position of the tool's end-effector; Pis the position of the key hole, and Pis the position of the robot's end-effector at which the tool is held.","The position Pis registered initially with respect to the base of the Zeus robot. If Pis the desired position of the tool, then, since the tool is rigid, there can only be one P. Therefore the position Pis calculated by projecting Pthrough P.","However, the point Pis located in the center of the \u2018Nail\u2019 joint, which is a connected to a passive joint (Finger) and its position cannot be controlled. Hence, this point can be transformed to another point on the robot which can be controlled. It has been observed that the center of the joint between \u2018Finger\u2019 and \u2018Wrist\u2019 (say P) always lies along the axis of the \u2018Elbow\u2019 joint, which is an active joint and can be controlled. So, for the purpose of the inverse kinematics calculations, the axis along the \u2018Elbow\u2019 joint and the point \u2018P\u2019 can be considered to be one single joint and the point \u2018P\u2019 is transformed to point \u2018P\u2019.","It should also be noted that the only movable joint between the \u2018Finger\u2019 and \u2018Nail\u2019 is the joint which controls the roll of the end-effector and that it is not being for this project. Hence, the transformation between the point \u2018P\u2019 and \u2018P\u2019 may be fixed no matter what the position and orientation of the other joints are. This allows the transformation to be calculated between these two points during the registration stage and used it for the calculations.","The transformation between \u2018P\u2019 and \u2018PREE\u2019 is calculated while the key-hole (PKH) is being registered. Now the transformation matrix from \u2018P\u2019 to \u2018P\u2019 would be the inverse of the transformation between \u2018P\u2019 and \u2018P\u2019. Whenever, the inverse kinematics solution has to be calculated, the point \u2018P\u2019 may be transferred to \u2018P\u2019 and then transferred to point \u2018P\u2019.","Once the point \u2018P\u2019 is known, the robot effectively operates as a 3 joint robot with the \u2018Linear\u2019, \u2018Shoulder\u2019 and \u2018Elbow\u2019 joints. Although the \u2018Elbow\u2019 joint now constitutes the \u2018Elbow\u2019 and \u2018Wrist\u2019 joints with point \u2018P\u2019 as the end of the joint. The point \u2018P\u2019 is a point in the 3D space with respect to the base of the robot with \u2018X\u2019, and \u2018Y\u2019 and \u2018Z\u2019 as the three coordinates of the point. The value of \u2018Z\u2019 holds a linear relation to the height of the linear joint and hence can be calculated using the formula:\n\nLength of Linear Joint=\u2003\u2003Equation 6\n\n","Once the length of the linear joint to reach the \u2018Z\u2019 co-ordinate is calculated, the joint angles for the \u2018Shoulder\u2019 and \u2018Elbow\u2019 joints should be calculated to reach the \u2018X\u2019 and \u2018Y\u2019 co-ordinates.",{"@attributes":{"id":"p-0134","num":"0153"},"figref":["FIG. 16","FIG. 16"],"sub":["1","2","1","2","1","2"],"b":["1610","1612","614","1616","1618"]},"Now,",{"@attributes":{"id":"p-0135","num":"0154"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"R","mo":"=","msqrt":{"mrow":{"msup":[{"mi":"X","mn":"2"},{"mi":"Y","mn":"2"}],"mo":"+"}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"7"}}]},{"mtd":[{"mrow":{"mi":"\u03b8","mo":"=","mrow":{"msup":{"mi":"tan","mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mfrac":{"mi":["Y","X"]}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"8"}}]},{"mtd":[{"mrow":{"msub":{"mi":"\u03b1","mn":"1"},"mo":"=","mrow":{"mo":"\u00b1","mrow":{"msup":{"mi":"cos","mrow":{"mo":"-","mn":"1"}},"mo":"\u2061","mrow":{"mo":["[","]"],"mfrac":{"mrow":[{"msup":{"mi":"R","mn":"2"},"mo":["+","-"],"msubsup":[{"mi":"L","mn":["1","2"]},{"mi":"L","mn":["2","2"]}]},{"mn":"2","mo":["*","*"],"mi":"R","msub":{"mi":"L","mn":"1"}}]}}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"9"}}]},{"mtd":[{"mrow":{"msub":{"mi":"\u03b1","mn":"2"},"mo":"=","mrow":{"mo":"\u00b1","mrow":{"msup":{"mi":"cos","mrow":{"mo":"-","mn":"1"}},"mo":"\u2061","mrow":{"mo":["[","]"],"mfrac":{"mrow":[{"msup":{"mi":"R","mn":"2"},"mo":["+","-"],"msubsup":[{"mi":"L","mn":["2","2"]},{"mi":"L","mn":["1","2"]}]},{"mn":"2","mo":["*","*"],"mi":"R","msub":{"mi":"L","mn":"2"}}]}}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"10"}}]},{"mtd":[{"mrow":{"msub":{"mi":"\u03b8","mn":"1"},"mo":"=","mrow":{"msub":{"mi":"\u03b1","mn":"1"},"mo":"+","mi":"\u03b8"}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"11"}}]},{"mtd":[{"mrow":{"msub":{"mi":"\u03b8","mn":"2"},"mo":"=","mrow":{"msub":{"mi":"\u03b1","mn":"2"},"mo":"-","mi":"\u03b8"}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"12"}}]}]}}}},"Using the above calculations, the values of \u03b8and \u03b8may be calculated. Hence the joint angles of the \u2018Linear\u2019, \u2018Shoulder\u2019 and \u2018Elbow\u2019 joints may be calculated using the above equations. The joint angles may be converted into encoder counts and then commands may be sent to the motion controller to move the joints to the corresponding positions. This way, whenever the tool has to be placed at position \u2018PTEE\u2019, the inverse kinematics algorithm performs the above state calculations and moves the tool to the required position.","As discussed earlier, the motion control system for the Zeus and AESOP robots and the basic control algorithms can be developed. The next step in the project is to allow the Zeus robot to perform tele-operation. This chapter explains how the tele-operation of the Zeus robot is done using the motion control system described herein.","In the original Zeus system the surgeon or the operator sits at the Master Console and operates the tools on the robots using the two controllers. All the motions of the two controllers are transformed into the motion of the robot end-effectors. The Master Console also has the \u2018Clutch\u2019 which helps the user to reset the positions of the controllers. It also has features like \u2018Motion Scaling\u2019 and \u2018Tremor Filtration\u2019.","Each controller at the Master Console has multiple joints named \u2018Shoulder\u2019, \u2018Slider\u2019, \u2018Pitch\u2019, \u2018Roll\u2019, \u2018Yaw\u2019 and \u2018Gripper\u2019. Each joint has positional feedback mechanisms in the form of either encoders or potentiometers. The electronics and the control hardware of the Zeus system may read the values of these encoders and potentiometers from each joint and then may translate these values into control signals for the motors on the joints.","In order to track the motion of the two controllers at the Master Console, Sachin Motion Tracking hardware may be connected to the Zeus controllers electronic hardware to track the values the encoders and potentiometers of each joint. The motion tracking hardware may also track the value of the clutch. This hardware may have a serial port through which it sends out these values to any computer. In order to be able to read these values and track the position and orientation of the controller, a software library may be developed. These libraries may be used in the control software to track the position and orientation of the controllers.","Zeus Master Controller Library","This library provides routines to do the following essential functions:","1. Establish communication with the motion tracking hardware.","2. Read the encoder and potentiometer values.","3. Convert them to joint angles.","4. Calculate position and orientation of the controllers.","5. Track the state of the clutch.","6. Track the state of the gripper.","7. Track the state of the buttons.","Using this software library, the position and orientation of the master controllers may be obtained and used in the control software to perform the tele-operation of the Zeus robot.","It has been observed in the original Zeus system that during tele-operation, the motion of each joint in the Zeus robot is linked to the motion of one joint in the master controller. The following table lists the link between each joint of the robot and the controller.",{"@attributes":{"id":"p-0150","num":"0169"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 5"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":[{},"Joint on the","Corresponding joint"]},{"entry":[{},"Zeus Robot","on the controller"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Linear","Slider"]},{"entry":[{},"Shoulder","Shoulder"]},{"entry":[{},"Elbow","Linear"]},{"entry":[{},"Nail","Roll"]},{"entry":[{},"Yaw","Yaw"]},{"entry":[{},"Gripper","Gripper"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"Since the system may be configured so that the orientation of the tool does not affect the tracking of the camera, the \u2018Nail\u2019 and \u2018Yaw\u2019 joints of the Zeus robot are not controlled.",{"@attributes":{"id":"p-0152","num":"0171"},"figref":["FIG. 17","FIG. 17"],"b":["1710","1712","1720","1722"]},{"@attributes":{"id":"p-0153","num":"0172"},"figref":["FIGS. 18-","FIG. 18"],"b":["1810","1812","1814","1816"]},"The Jog (JG) command may be used to control the robot as it allows for continuous motion of the joints. The jog speed may be proportional to the difference in the position of the master controller. This way, if the master controller is moved at high speeds, the jog speed increases and results in the faster motion of the end-effector. If the master controller is moved at low speeds, the jog speed decreases and results in the slower motion of the end-effector.",{"@attributes":{"id":"p-0155","num":"0174"},"figref":"FIG. 19","b":["1900","1910","1912","1914","1916","1920","1918","1924","1924","1926","1936","1928","1938","1940","1912"]},"This way, the end-effector follows the motion of the controller. The motion scale factor allows the system to adjust the motion scale such that large motions (in cm) at the master controller can be translated to minute motions at the end-effector (in mm).","Another function in the program may be tremor filtration. This is done by comparing the difference between the present and previous positions of the controller with a defined threshold as denoted by step . If the difference is greater than the threshold, the method follows line  and the motion commands are sent. If the difference is less than the threshold, the method follows line , the motion commands are not sent. This way the tremors at the controller (which is usually a minute motion) do not have any effect on the motion of the robot and as a result, the tremors are filtered.","The optimum values for the constants like the threshold and the constants used to convert the difference to jog speeds may be obtained by trial and error. Thus this program restores the tele-operation of the Zeus robot, along with the motion scaling, tremor filtration and clutch.","Autonomous camera control involves tracking the position of the tool and the camera and then calculating the position of the tool with respect to the camera. Once the position of the tool with respect to the camera is found, the program can calculate the appropriate position for the camera so that the tool is always in the view.","Two control strategies may be developed for the camera placement. They are:","1. Adjust the zoom level of the camera based on the tool position.","2. Follow the tool so that the tool is in the center of the view.","The user can control the mode by pressing a button on the master controller. This is illustrated in . By default, the camera does not move with respect to the tool, as denoted by block . If the button is pressed once, the control mode may switch to Zoom Mode as denoted by block . If the button is pressed again, the control mode may switch to Follow Mode as denoted by block . If the button is pressed again, the camera may stay stationary and go into the default mode .","In , \u2018A\u2019 and \u2018Z\u2019 are the bases of AESOP Robot  and Zeus Robot , respectively. \u2018C\u2019 is the camera  and \u2018T\u2019 is the tool . \u2018Tr\u2019 is the trocar , and \u2018P\u2019 is a registration point . \u2018T\u2019 is the transformation between \u2018Z\u2019 and \u2018T\u2019. \u2018T\u2019 is the transformation between \u2018A\u2019 and \u2018C\u2019. \u2018T\u2019 is the transformation between \u2018A\u2019 and \u2018P\u2019. \u2018T\u2019 is the transformation between \u2018Z\u2019 and \u2018P\u2019. \u2018T\u2019 is the transformation between the \u2018A\u2019 and T\u2019. \u2018T\u2019 is the transformation between \u2018A\u2019 and \u2018Z\u2019.","\u2018T\u2019 and \u2018T\u2019 are obtained by calculating the forward kinematics for the AESOP and Zeus robots respectively. \u2018P\u2019 is a random point chosen for the registration. Location of \u2018P\u2019 should be easily accessible by both the robots for proper registration. Now to obtain \u2018T\u2019, the camera \u2018C\u2019 is placed at the position \u2018P\u2019 and the forward kinematics is calculated. The tool \u2018T\u2019 is placed at position \u2018P\u2019 and the forward kinematics is calculated to obtain \u2018T\u2019.","Now to obtain \u2018T\u2019, the transformation between \u2018A\u2019 to \u2018P\u2019 is multiplied with the transformation between \u2018P\u2019 to \u2018Z\u2019, which is the inverse of the transformation between \u2018Z\u2019 to \u2018P\u2019.","Therefore,\n\n\u2003\u2003Equation 13\n","Now, the transformation between \u2018A\u2019 and \u2018T will be the transformation between \u2018A\u2019 and \u2018Z\u2019 multiplied by the transformation between \u2018Z\u2019 and \u2018T.","Therefore,\n\n\u2003\u2003Equation 14\n","To calculate the position of the tool \u2018T\u2019 with respect to the position of the camera \u2018C\u2019, the transformation between \u2018C\u2019 and \u2018T may be obtained, which can be represented by \u2018T\u2019. The transformation \u2018T\u2019 can be obtained by multiplying the transformation between \u2018T\u2019 and \u2018A\u2019 to the transformation between \u2018A\u2019 and \u2018C\u2019. However, the transformation between \u2018T\u2019 and \u2018A\u2019 is the inverse of the transformation \u2018T\u2019.","Therefore,\n\n\u2003\u2003Equation 15\n","Using the above equation, the position of the tool with respect to the position of the camera can be calculated. The position of the tool with respect to the camera may be used to find out if the tool is in the view or not and an appropriate action may be taken by the software to position the camera so that the tool is in the view.","Zoom mode is the first control mode for the camera. In this mode the position of the tool and the position of the camera are tracked. Further, the position of the tool with respect to the camera is calculated following the procedure discussed above. Now the position of the camera, \u2018C\u2019, the position of the tool with respect to the camera, \u2018T\u2019, and the position of the trocar through which the camera is placed, \u2018T\u2019 have been calculated.","The vector from \u2018T\u2019 to \u2018C\u2019 may be calculated as:\n\n\u2003\u2003Equation 16\n","The vector from \u2018C\u2019 to \u2018T\u2019, \u2018V\u2019 will be equal to \u2018T\u2019 because \u2018V\u2019 is the position of the tool with respect to the camera.","Now the angle between vectors \u2018V\u2019 and \u2018V\u2019 may be calculated using the following formula.",{"@attributes":{"id":"p-0174","num":"0193"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"\u03b8","mo":"=","mrow":{"msup":{"mi":"cos","mrow":{"mo":"-","mn":"1"}},"mo":["(",")"],"mfrac":{"mrow":[{"mover":[{"msub":{"mi":["V","RC"]},"mo":"\u2192"},{"msub":{"mi":["V","CT"]},"mo":"\u2192"}],"mo":"\u00b7"},{"mrow":[{"mo":["\uf603","\uf604"],"msub":{"mi":["V","RC"]}},{"mo":["\uf603","\uf604"],"msub":{"mi":["V","CT"]}}],"mo":"*"}]}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"17"}}]}}}}},{"@attributes":{"id":"p-0175","num":"0194"},"figref":"FIG. 22","sub":"RC ","b":["2210","2220","2220"]},"The angle, \u03b8, may be calculated using the above formula and if \u03b8 is greater than 35\u00b0, the linear joint of the AESOP Robot may be moved up, as a result, the camera moves up. This is done in steps of 2 cm every time until the angle \u03b8 is less than a first threshold angle such as 35\u00b0. This way, if the tool goes out of view, the camera autonomously positions itself so that the tool comes back to view.","If the angle \u03b8 is close to 0\u00b0, it means the tool is in the center of the camera view. So, whenever the angle falls below a second threshold angle such as 15\u00b0, the linear joint of the AESOP Robot may be moved down, as a result the camera zooms into the scene and the tool appears to be closer. This could be useful when the user is performing a delicate task and needs a clearer view of the scene. When the camera is zooming in, the system is programmed to stop zooming in further, if the distance between the tool and the camera is less than a threshold amount such as 2 cm. Limiting the distance between the tool and the camera prevents the camera from hitting the tool and damaging the lens. Performing tasks can also be difficult if the camera is very close to the tool. The threshold distance of 2 cm was found to be a comfortable threshold. When the camera zooms out to get the tool back in view, the camera might slide out of the trocar point. In order to avoid the camera sliding out of the trocar point, the distance between the camera and the trocar is calculated before zooming out. If the distance between the camera and trocar point is less than a distance threshold, such as 1 cm, the camera may be programmed to stop zooming out.","The follow mode is the second mode of control for the camera positioning. In the follow mode, the camera is positioned so that the tool is always in the center of the view. The position of \u2018T\u2019 with respect to \u2018A\u2019 can be obtained from the transformation \u2018T\u2019, which was discussed previously. In addition, the position of the trocar, \u2018T\u2019 with respect to \u2018A\u2019 has also been calculated. Now as the tool is moving, a first point which lies along the line between and \u2018A\u2019 and is one fourth the distance between \u2018T\u2019 and \u2018A\u2019 from \u2018T,\u2019 is calculated. The first point is given to the inverse kinematics algorithm of the AESOP Robot to position the camera at the first point. When the camera reaches the first point, the camera's position is along the line between the trocar and the tool and since it passes through the trocar, its points along the same line, as a result of which the camera has the tool in the view. This is done repetitively and thus the camera may follow the tool wherever the tool goes. Various examples can be seen in . In each of these figures, the camera is denoted by , the tool is denoted by , and the trocar is denoted by . The calculated position is one fourth the distance away from Talong the line from Tto T.","When the camera control is in follow mode, the continuous motion of the camera can cause motion sickness to the user and it can also be very irritating. In order to avoid motion sickness, the speeds of each joint of the AESOP Robot are set to low values. Moreover, the Galil Motion Controller does not allow motion commands to be sent while the robot is moving. In order to avoid conflict, the program may check if the robot is moving or not and will send the motion commands only when the robot is not moving. Because of the delay in sending commands, the robot moves at very slow speeds and therefore, the response of the camera might be sluggish. The speeds of the joints of the AESOP Robot may be adjusted to improve the response, but care should be taken not to make the movement too fast.","The inverse kinematics algorithm of the AESOP robot might not be very accurate. Due to the accuracy, the tool may not be exactly in the center of the view, but the tool should not leave the view. The inaccuracy of the inverse kinematics also means that it is possible that the camera might slide out of the trocar point when the tool comes close to the trocar. In order to avoid sliding of the camera, the motion commands are not sent to the robot if the camera is less than a threshold distance, such as 1 cm, away from the trocar point.","As described above, the system may support autonomous zoom control of the laparoscopic camera. The AESOP  robot, which may hold the laparoscopic camera, can be configured to adjust the zoom level of the camera by moving the camera up or down based on the position of the tools. The camera may zoom out if the tool is at the edge of the view and may zoom in if the tool is in the center of the view. The angle between the position of the tool and the camera may be calculated and compared to two thresholds. The outer threshold may be 35\u00b0 and if the angle is greater than this threshold, the camera may zoom out. The inner threshold is 15\u00b0 and if the angle is less than the inner threshold, the camera may zoom in. Whenever the angle becomes less than the inner threshold, the distance between the camera and the tool is checked. If the distance is less than a first limit, such as 2 cm, the camera is not zoomed in further. This check avoids the camera being zoomed in too close to the tool. Whenever the angle is greater than the outer limit, the distance between the camera and the trocar point is checked. If the distance is less than a second limit, such as 1 cm, the camera is not zoomed out further. The second check avoids the camera from sliding out of the trocar.",{"@attributes":{"id":"p-0182","num":"0201"},"figref":["FIGS. 24-","FIG. 24","FIGS. 24and ","FIG. 24","FIGS. 24"],"b":["2410","2410"],"i":"c. "},"In addition, the system may be configured in an autonomous follow mode in which the camera follows the tool and keeps the tool in the center of the view. In the autonomous follow mode, the position of the tool may be used to calculate the position of the camera so that the tool is in the center of the view. shows images of the camera view in the zoom mode. In , the tool  is in the center. In , the tool  is moved to the left edge of the scene and the camera followed the tool  (Note that the left side of the picture shows the left edge of the paper). In , the tool  is moved to the top right corner of the scene and the camera followed the tool  (Note that the top right side of the picture shows the top corner of the paper).","As such, both features discussed have been implemented using the Zeus Surgical System apart from restoring the tele-operation. Adding these features allows the surgeons to concentrate on their tasks and the system takes care of placing the camera in the optimum position.","Although the camera may always follow the tool and never loses track of the tool, the kinematics of the AESOP robot may not be accurate enough. The D-H Parameters of the AESOP  robot were measured using vernier calipers to the best possible accuracy for testing, but this technique may not be accurate enough for surgical automation. Hence the accurate D-H Parameters of the robots may be obtained for better accuracy. One possible way to calculate the D-H parameters more accurately is by using optimization algorithms to calculate the D-H parameters. Moreover, passive joints on the robot increase the difficulty in calculating the inverse kinematics.","It should be noted that the robots used in testing these concepts, Zeus and AESOP are designed for tele-operation and not automation. In tele-operation, since the surgeon is the one controlling the robot, it is not as necessary for the kinematics to be very accurate. One major contributor for inaccuracies in the Zeus and AESOP is the mountings of the robot. The mountings are not rigid and hence the robots may lean when the arms are extended and thus may change the position and orientation of the base, which is very important for kinematics of the robot. Hence, for surgical automation, the robots may be designed specifically for automation, without passive joints and with better mountings, and that will lead to better accuracy.","While the system was tested to position of the camera based on the position of one tool. The system could be extended to accommodate two arms. One of the control strategies with two arms may be to follow the mid-point of the two arms and adjust the zoom so that both the tools are in the view. This way the system can combine both the Zoom mode and the Follow mode. If the tools are far apart, the camera may zoom out and may center to the mid-point of the two tools. If the tools are very close to each other, the camera may zoom in, giving a better view of the tools.","Since the position of the tools are being tracked, the system may implement virtual fixtures. Using virtual fixtures, \u2018No-Fly\u2019 zones can be defined in the patient's body which will prevent the tools from entering sensitive areas of the patient's body without the surgeon's knowledge. Further, when the camera is at its maximum zoomed out position, if the surgeon tries to move the tool out of the view at that point, the motion can be restricted and the surgeon can be informed that it is unsafe to move out of the view.","Since the tools and the camera are being registered with respect to one another, the surgeon can define the \u2018No-Fly\u2019 zones using one tool. The \u2018No-Fly\u2019 zones can be transformed to the other tools using the registrations to prevent the other tools from entering the sensitive areas. As such, the surgeon does not have to define the zones for each tool separately.","One of the joints which were not used during testing on the AESOP robot is the \u2018Roll\u2019 joint, which controls the camera roll. Using the roll joint, the camera can be rotated along the camera's viewing. The rolling motion of the camera will rotate the view and hence affect the control of the tools using the master controller. For example, the camera is in its normal position and there is no roll, then if the surgeon moves the master controller to the left, the tool may move to the left. Then, if the camera is rolled , all the motions will be reversed and if the surgeon moves the controller to the left, the tool moves to the right in the camera view. If the \u2018Roll\u2019 joint is tracked, it is possible to provide the surgeon with Augmented Reality Cues suggesting which are the X, Y and Z axes of the tool with respect to the camera. It is also possible to transform the motion of the tools based on the roll of the camera so that the tools moves in the same direction (in the camera view) as the controller is moved no matter what the orientation of the camera. Adjusting the motion or providing augmented reality cues can possibly avoid confusion during the surgery.","Using the control described herein, it is possible to automate certain surgical tasks like suturing, knot tying, etc. Using the techniques of tele-operation and full inverse kinematic solutions, new algorithms can be developed to automate the surgical tasks.","Any of the methods described may be implemented and controlled with one or more computer systems. If implemented in multiple computer systems the code may be distributed and interface via application programming interfaces. Further, each method may be implemented on one or more computers. One exemplary computer system is provided in . The computer system  includes a processor  for executing instructions such as those described in the methods discussed above. The instructions may be stored in a computer readable medium such as memory  or a storage device , for example a disk drive, CD, or DVD. The computer may include a display controller  responsive to instructions to generate a textual or graphical display on a display device , for example a computer monitor. In addition, the processor  may communicate with a network controller  to communicate data or instructions to other systems, for example other general computer systems. The network controller  may communicate over Ethernet or other known protocols to distribute processing or provide remote access to information over a variety of network topologies, including local area networks, wide area networks, the internet, or other commonly used network topologies.","In an alternative embodiment, dedicated hardware implementations, such as application specific integrated circuits, programmable logic arrays and other hardware devices, can be constructed to implement one or more of the methods described herein. Applications that may include the apparatus and systems of various embodiments can broadly include a variety of electronic and computer systems. One or more embodiments described herein may implement functions using two or more specific interconnected hardware modules or devices with related control and data signals that can be communicated between and through the modules, or as portions of an application-specific integrated circuit. Accordingly, the present system encompasses software, firmware, and hardware implementations.","In accordance with various embodiments of the present disclosure, the methods described herein may be implemented by software programs executable by a computer system. Further, in an exemplary, non-limited embodiment, implementations can include distributed processing, component\/object distributed processing, and parallel processing. Alternatively, virtual computer system processing can be constructed to implement one or more of the methods or functionality as described herein.","Further the methods described herein may be embodied in a computer-readable medium. The term \u201ccomputer-readable medium\u201d includes a single medium or multiple media, such as a centralized or distributed database, and\/or associated caches and servers that store one or more sets of instructions. The term \u201ccomputer-readable medium\u201d shall also include any medium that is capable of storing, encoding or carrying a set of instructions for execution by a processor or that cause a computer system to perform any one or more of the methods or operations disclosed herein.","As a person skilled in the art will readily appreciate, the above description is meant as an illustration of the principles of this application. This description is not intended to limit the scope or application of the claim in that the invention is susceptible to modification, variation and change, without departing from spirit of this application, as defined in the following claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0004","num":"0003"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 6","b":"1000"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 9","sub":["arm","arm","base ","base"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 18-"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIGS. 23-"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIGS. 24-"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIGS. 25-"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 26"}]},"DETDESC":[{},{}]}
