---
title: Exterior hybrid photo mapping
abstract: Embodiments disclosed pertain to the use of user equipment (UE) for the generation of a 3D exterior envelope of a structure based on captured images and a measurement set associated with each captured image. In some embodiments, a sequence of exterior images of a structure is captured and a corresponding measurement set comprising Inertial Measurement Unit (IMU) measurements, wireless measurements (including Global Navigation Satellite (GNSS) measurements) and/or other non-wireless sensor measurements may be obtained concurrently. A closed-loop trajectory of the UE in global coordinates may be determined and a 3D structural envelope of the structure may be obtained based on the closed loop trajectory and feature points in a subset of images selected from the sequence of exterior images of the structure.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09405972&OS=09405972&RS=09405972
owner: QUALCOMM Incorporated
number: 09405972
owner_city: San Diego
owner_country: US
publication_date: 20140925
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application claims the benefit of and priority to U.S. Provisional Application No. 61\/883,921 entitled \u201cOff-Target Tracking Using Feature Aiding in the Context of Inertial Navigation,\u201d filed Sep. 27, 2013, which is incorporated by reference in its entirety herein.","The subject matter disclosed herein relates generally to terrestrial positioning systems, and in particular, to systems and methods for exterior hybrid photo mapping.","Mapping techniques are increasingly moving away from government maps based on satellite imagery and photogrammetry to detailed localized maps. A majority of current outdoor mapping strategies are focused on the use of heavily instrumented and expensive \u201cwar driving\u201d vans capable of collecting large amounts of data. However, the data collected by war driving vans is often proprietary and unavailable to the vast majority of mobile device users. In addition, because the use of war driving vans is limited to areas with vehicular access, many locations frequented by users cannot be mapped.","Further, attempts to use a combination of GPS receivers, cameras and online cartography tools for mapping have been limited and cumbersome. In addition, there has been no significant attempt to map the exterior of outdoor structures such as by determining the size, three dimensional (3D) shape, orientation and position of structures. The sheer number of structures makes traditional mapping techniques impractical. On the other hand, the number of such unmapped structures leaves a void that limits detail in local maps. Moreover, because structures are constantly torn down, remodeled, updated or rebuilt, keeping accurate updated maps of the exterior of outdoor structures is often cost prohibitive.","Therefore, there is a need for coherent strategies to cost-effectively acquire and maintain exterior maps of structures.","In some embodiments, a method on a user equipment (UE) may comprise: capturing a plurality of images of the exterior of a structure when traversing a plurality of locations in the vicinity of the structure; capturing a plurality of measurement sets, wherein each measurement set corresponds to at least one image and comprises at least one of Inertial Measurement Unit (IMU) measurements or available wireless measurements with correction information for the wireless measurements; and estimating, based, in part, on the captured images and the corresponding plurality of measurement sets, a 3D structural envelope of the structure and a trajectory of the UE. In some embodiments, the estimated trajectory of the UE, and one or more of the 3D structural envelope, captured images, or the corresponding measurement sets, may be sent to a server wirelessly coupled to the UE; and a corrected trajectory of the UE and a 3D structural envelope of the structure registered to absolute coordinates may be received from the server, wherein the received corrected trajectory is based, in part, on the estimated trajectory of the UE, captured images and\/or measurement sets.","In another aspect, a User Equipment (UE) may comprise: a camera configured to capture a plurality of images of the exterior of a structure when traversing a plurality of locations in the vicinity of the structure; a plurality of sensors, the sensors comprising an Inertial Measurement Unit (IMU); a wireless module configured to take measurements of available wireless signals, and acquire correction information for the wireless measurements; and a processor, coupled to the camera, sensors and wireless module. Further, the processor may be configured to: obtain the plurality of images of the exterior of a structure; obtain a plurality of measurement sets, wherein each measurement set corresponds to at least one image in the plurality of images, and each measurement set comprises at least one of IMU measurements and available wireless measurements with correction information for the wireless measurements; estimate, based, in part, on the captured images and the corresponding plurality of measurement sets, a 3D structural envelope of the structure and a trajectory of the UE; send the estimated trajectory of the UE, and one or more of the 3D structural envelope, captured images, or the corresponding measurement sets, to a server wirelessly coupled to the UE; and receive, based, in part, on the estimated trajectory of the UE, captured images and measurement sets, a corrected trajectory of the UE and a 3D structural envelope of the structure registered to absolute coordinates.","In a further aspect, a User Equipment (UE) may comprise: imaging means configured to capture a plurality of images of the exterior of a structure when traversing a plurality of locations in the vicinity of the structure; sensing means, the sensing means comprising an Inertial Measurement Unit (IMU) means; wireless measurement means configured to take measurements of available wireless signals, and acquire correction information for the wireless measurements; means for obtaining the plurality of images of the exterior of a structure; means for obtaining a plurality of measurement sets, wherein each measurement set corresponds to at least one image in the plurality of images, and each measurement set comprises at least one of IMU measurements and available wireless measurements with correction information for the wireless measurements; means for estimating, based, in part, on the captured images and the corresponding plurality of measurement sets, a 3D structural envelope of the structure and a trajectory of the UE; means for sending the estimated trajectory of the UE, and one or more of the 3D structural envelope, captured images, or the corresponding measurement sets, to a server wirelessly coupled to the UE; and means for receiving, based, in part, on the estimated trajectory of the UE, captured images and measurement sets, a corrected trajectory of the UE and a 3D structural envelope of the structure registered to absolute coordinates.","In some embodiments, a non-transitory computer-readable medium may comprise instructions, which, when executed by a processor, cause the processor to be configured to: capture a plurality of images of the exterior of a structure when traversing a plurality of locations in the vicinity of the structure; capture a plurality of measurement sets, wherein each measurement set corresponds to at least one image and comprises at least one of Inertial Measurement Unit (IMU) measurements or available wireless measurements with correction information for the wireless measurements; estimate, based, in part, on the captured images and the corresponding plurality of measurement sets, a 3D structural envelope of the structure and a trajectory of the UE; send the estimated trajectory of the UE, and one or more of the 3D structural envelope, captured images, or the corresponding measurement sets, to a server wirelessly coupled to the UE; and receive, based, in part, on the estimated trajectory of the UE, captured images and measurement sets, a corrected trajectory of the UE and a 3D structural envelope of the structure registered to absolute coordinates.","The methods disclosed may be performed by one or more UE's such as servers (including location servers), mobile stations, mobile devices, etc. using LPP, LPPe or other protocols. Embodiments disclosed also relate to software, firmware, and program instructions created, stored, accessed, read or modified by processors using non transitory computer readable media or computer readable memory.","The terms \u201cUser Device\u201d (UD) or \u201cuser equipment\u201d (UE) or are used interchangeably herein and may refer to a device such as a cellular or other wireless communication device, personal communication system (PCS) device, personal navigation device (PND), Personal Information Manager (PIM), Personal Digital Assistant (PDA), laptop or other suitable mobile device which is capable of receiving wireless communication and\/or navigation signals. The terms are also intended to include devices which communicate with a personal navigation device (PND), such as by short-range wireless, infrared, wireline connection, or other connection\u2014regardless of whether satellite signal reception, assistance data reception, and\/or position-related processing occurs at the device or at the PND. The UE may represent a mobile telephone, notepad computer or laptop, or it may be a vehicle that collects said measurement sets for the purpose of creating street maps and\/or the delay and\/or signal strength maps herein.","In addition, the terms UD, UE, \u201cmobile station\u201d \u201cmobile device\u201d or \u201ctarget\u201d are intended to include all devices, including wireless and wireline communication devices, computers, laptops, etc. which are capable of communication with a server, such as via the Internet, Wi-Fi, cellular wireless network, DSL network, packet cable network or other network, and regardless of whether satellite signal reception, assistance data reception, and\/or position-related processing occurs at the device, at a server, or at another device associated with the network. Any operable combination of the above are also considered a \u201cuser device.\u201d",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 1A","b":["100","100","100","100"]},"UE  may, for example, include one or more processing units or processing unit(s) , memory , a transceiver  (e.g., wireless network interface), and (as applicable) GNSS or Satellite Positioning System (SPS) receiver , optical sensors\/camera(s) , magnetometer, altimeter, barometer and sensor bank  (collectively referred to as sensors ), Inertial Measurement Unit (IMU) , non-transitory computer-readable medium , display , and memory , which may be operatively coupled to each other with one or more connections  (e.g., buses, lines, fibers, links, etc.). In certain example implementations, all or part of UE  may take the form of a chipset, and\/or the like. The magnetometer may be capable of measuring the intensity and\/or the direction of the Earth's magnetic field and may serve as a compass and\/or provide an indication of a direction of travel of UE . The altimeter may be used to provide an indication of altitude above a calibrated level, while the barometer may provide an indication of atmospheric pressure, which may also be used to obtain a determination of altitude.","GNSS\/SPS receiver  may be enabled to receive signals associated with one or more SPS resources. Received GNSS\/SPS signals may be used to determine a position of UE . Transceiver  may, for example, include a transmitter  enabled to transmit one or more signals over one or more types of wireless communication networks and a receiver  to receive one or more signals transmitted over one or more types of wireless communication networks.","In some embodiments, UE  may comprise image sensors such as CCD or CMOS sensors and\/or camera(s) , which are hereinafter referred to as \u201ccamera(s) \u201d. Camera(s)  may convert an optical image into an electronic or digital image and may send captured images to processing unit(s) . For example, as shown in , in some embodiments, camera(s)  may be housed in a wearable user device, and may be operationally coupled to display , processing unit(s)  and\/or other functional units in UE .","In some embodiments, processing unit(s)  may also receive input from one or more sensors , which may include a magnetometer, altimeter and\/or barometer. In addition, sensors  may include one or more of an ambient light sensor, acoustic transducers such as microphones\/speakers, ultrasonic transducers and\/or depth sensors, which may be used to acquire depth information and\/or determine distance to a target. In general, the list of sensors above in not exhaustive and sensor bank  may include various other types of sensors and transducers which are increasingly being incorporated into modern smartphones and other user devices.","In some embodiments, UE  may also include Inertial Measurement Unit (IMU) . In some embodiments, IMU , which may comprise 3 axis accelerometer(s), 3-axis gyroscope(s), and\/or magnetometer(s), may provide velocity, orientation, and\/or other position related information to processing unit(s) . In some embodiments, IMU  may be configured to measure and output measured information synchronized to the capture of each image frame by camera(s) , and\/or measurements taken by sensors  in UE . In some embodiments, the output of IMU  may be used by processing unit(s)  to determine a position and orientation of UE .","The term \u201cwireless measurements\u201d is used herein to refer to measurements of SPS, cellular, WLAN, WPAN, and other radio signals. The term \u201cnon-wireless measurements\u201d refer to sensor measurements including (but not limited to) IMU, barometer, altimeter, and magnetometer measurements. In some embodiments, the capture of wireless measurements by a UE may be synchronized with the capture of non-wireless measurements. Further, the capture of wireless and\/or non-wireless measurements can be synchronized with the capture of images by the UE. For example, measurements (wireless and\/or non-wireless) and captured images may be timestamped and the measurements and images may be associated with each other based on the time stamps. The association of measurements with image and\/or with each other may occur concurrently with measurement\/image recordation, and\/or at a later point in time based on the timestamps associated with the measurements.","The term \u201cmeasurement set\u201d is used to refer to signal measurements performed by a UE at a measurement location at a point in time or within some specified interval of a point in time. The signal measurements made may be related to mapping and\/or position determination. The signal measurements made may also depend on UE , the capabilities of UE , environmental characteristics and\/or signal characteristics that are available for measurement by UE  at a specific location\/time. Typically, a measurement set may comprise image(s), wireless measurements and non-wireless measurements, where each element of the measurement set may have been recorded within some specified time interval of a point in time. The measurement sets recorded by UE  may be stored in memory  on UE  and\/or sent to a server, where they may be processed and\/or aggregated with other measurements related to that measurement location. For example, the measurement sets may stored in a Base Station Almanac (BSA) and\/or used for mapping\/location determination.","Processing unit(s)  may be implemented using a combination of hardware, firmware, and software. In some embodiments, processing unit(s)  may include Mapping Module (MM) , Navigation Module (NM) , and Location Assistance Data Module (LADM) . In some embodiments, LADM  may process received location assistance data to estimate a location of the UE. Location assistance data may take the form of layered map information such as multipath and visibility map assistance information, Observed Time Difference of Arrival (OTDOA) assistance information, including PRS assistance information, etc. In some embodiments, processing unit(s)  may also include Computer Vision Module (CVM) , which may implement a variety of image processing and CV functions.","The term \u201cmap layer\u201d as used herein in refers to information, such as location assistance information, tailored to a position and position uncertainty of a UE. Each layer of the map may comprise information about a parameter, wherein the information is provided in relation to absolute or global coordinates common to the layers. In general, map layers may comprise various types of information. For example, map layers may comprise one or more of: a received signal strength map layer that correlates a received signal strength with map locations; a Signal to Noise Ratio (SNR) map layer correlating SNRs with map locations; a Forward Link Calibration (FLC) layer that correlates FLC information with map locations; etc.","In some embodiments, camera(s)  may include multiple cameras, front and\/or rear facing cameras, wide-angle cameras, and may also incorporate CCD, CMOS, and\/or other sensors. Camera(s) , which may be still and\/or video cameras, may capture a series of 2-Dimensional (2D) still and\/or video image frames of an environment and send the captured image frames to processing unit(s) . In some embodiments, camera(s)  may be a wearable camera, or an external camera, which may be operationally coupled to, but housed separately from, other functional units in UE . In one embodiment, images captured by camera(s)  may be in a raw uncompressed format and may be compressed prior to being processed and\/or stored in memory . In some embodiments, image compression may be performed by processing unit(s)  (e.g. by CVM ) using lossless or lossy compression techniques.","In some embodiments, camera  may be a depth sensing camera or may be coupled to depth sensors. The term \u201cdepth sensor\u201d is used to refer to functional units that may be used to obtain depth information for an environment independently and\/or in conjunction with camera(s) . In some embodiments, may comprise RGBD cameras, which may capture per-pixel depth (D) information when the depth sensor is enabled, in addition to color (RGB) images. As another example, in some embodiments, camera  may take the form of a 3D Time Of Flight (3DTOF) camera. In embodiments with 3DTOF cameras , the depth sensor may take the form of a strobe light coupled to the 3DTOF camera , which may illuminate objects in a scene and reflected light may be captured by a CCD\/CMOS sensor in camera . Depth information may be obtained by measuring the time that the light pulses take to travel to the objects and back to the sensor.","As a further example, the depth sensor may take the form of a light source coupled to cameras . In one embodiment, the light source may project a structured or textured light pattern, which may consist of one or more narrow bands of light, onto objects in a scene. Depth information may then be obtained by exploiting geometrical distortions of the projected pattern caused by the surface shape of the object. In one embodiment, depth information may be obtained from stereo sensors such as a combination of an infra-red structured light projector and an infra-red camera registered to a RGB camera. In some embodiments, camera(s)  may be stereoscopic cameras capable of capturing 3 Dimensional (3D) images. In another embodiment, camera(s)  may include depth sensors that are capable of estimating depth information. For example, a depth sensor may form part of a passive stereo vision sensor, which may use two or more cameras to obtain depth information for a scene. The pixel coordinates of points common to both cameras in a captured scene may be used along with camera pose information and\/or triangulation techniques to obtain per-pixel depth information. In some embodiments, depth sensors may be disabled, when not in use. For example, the depth sensor may be placed in a standby mode, or powered off when not being used. In some embodiments, processors  may disable (or enable) depth sensing at one or more points in time.","Processing unit(s)  may also execute software to process image frames captured by camera(s) . For example, processing unit(s)  may be capable of processing one or more image frames received from camera(s)  to determine the pose of camera(s) , implementing various computer vision and image processing algorithms and\/or performing 3D reconstruction of an environment corresponding to an image received from camera(s) . The pose of camera(s)  refers to the position and orientation of the camera(s)  relative to a frame of reference. In some embodiments, camera pose may be determined for 6-Degrees Of Freedom (6-DOF), which refers to three translation components (which may be given by X,Y,Z coordinates of a frame of reference) and three angular components (e.g. roll, pitch and yaw relative to the same frame of reference).","In some embodiments, the pose of camera(s)  and\/or UE  may be determined and\/or tracked by processing unit(s)  using a visual tracking solution based on image frames captured by camera(s) . In some embodiments, CVM  may be implemented using dedicated circuitry, such as Application Specific Integrated Circuits (ASICs), Digital Signal Processors (DSPs), and\/or dedicated processor (such as processing unit(s) ). In some embodiments, CVM  may include functionality to communicate with one or more other processors on UE .","In some embodiments, CVM  may implement various computer vision and\/or image processing methods such as 3D reconstruction, image compression and filtering. CVM  may also implement computer vision based tracking, model-based tracking, Simultaneous Localization And Mapping (SLAM), etc. In some embodiments, the methods implemented by CVM  may be based on color or grayscale image data captured by camera(s) , which may be used to generate estimates of 6-DOF pose measurements of the camera.","SLAM refers to a class of techniques where a map of an environment, such as a map of an environment being modeled by UE , is created while simultaneously tracking the pose of UE  relative to that map. SLAM techniques include Visual SLAM (VLSAM), where images captured by a camera, such as camera(s)  on UE , may be used to create a map of an environment while simultaneously tracking the camera's pose relative to that map. VSLAM may thus involve tracking the 6DOF pose of a camera while also determining the 3-D structure of the surrounding environment. For example, in some embodiment, VSLAM techniques may detect salient feature patches or keypoints or feature descriptors in one or more captured image frames and store the captured imaged frames as keyframes or reference frames. In keyframe based SLAM, the pose of the camera may then be determined, for example, by comparing a currently captured image frame with one or more previously captured and\/or stored keyframes. Image feature descriptors may take the form of Scale Invariant Feature Transform (SIFT), Speeded-Up Robust Descriptors (SURF), etc., which are well-known in the art. The determined\/stored image descriptors may be utilized at a later point by an image or object detector to determine the pose of a UE.","In some embodiments, CVM  may comprise 3D reconstruction module, which may use the camera pose and per-pixel map information to create a 3D model or representation of the environment. In some embodiments, 3D reconstruction module may be implemented using dedicated circuitry, such as Application Specific Integrated Circuits (ASICs), Digital Signal Processors (DSPs), and\/or dedicated processor (such as processing unit(s) ). 3D reconstruction module may use a set of 3D points in a point cloud, which may be determined from images of a structure, to obtain a 3D model of the structure.","In one embodiment, processing unit(s)  may track the position of camera(s)  by using monocular VSLAM techniques to build a coarse map of the environment around UE  for accurate and robust 6DOF tracking of camera(s) . The term monocular refers to the use of a single non stereoscopic camera to capture images or to images captured without depth information.","Tracking UE and\/or camera pose, in a spatial coordinate system can be accomplished in a variety of ways. Where Satellite Positioning System (SPS) signals are unavailable or unreliable, such as in dense outdoor environments, such tracking can be done using a combination of visual and inertial tracking systems. For example, images captured by camera(s)  may be used in conjunction with measurements by IMU  and\/or sensors in sensor bank  (e.g. altimeter, barometer, magnetometer etc.) and\/or other wireless measurements (e.g. WWAN signal measurements) to determine the pose of UE  and\/or camera(s) . In some embodiments, VSLAM based techniques may be used, in part, to correct for errors (such as biases and drift) in IMU . Where available, GPS coordinates may also be used to provide location information. In some embodiments, a hybrid Visual-Inertial Tracker may incorporate a SLAM\/VSLAM system with an Extended Kalman Filter (EKF), providing various inputs to the EKF to track the pose of camera(s)  and\/or UE . The Kalman Filter (KF) is a widely used method for tracking and pose estimation. Specifically, the KF operates recursively on a sequence of noisy input measurements over time to produce a statistically optimal estimate of the underlying system state, which may include estimates of unknown variables. The EKF linearizes non-linear models to facilitate application of the KF.","In some embodiments, the pose of the camera may be used to recalibrate sensors in IMU , and\/or to compensate for and\/or remove biases from measurements of sensors  and\/or sensors in IMU . For example, IMU  and\/or sensors  may output measured information in synchronization with the capture of each image frame by camera(s)  by UE . When the camera pose can be estimated accurately, for example, based on VLSAM (e.g. successful detection of one or more corresponding feature points in images) then the VSLAM estimated camera pose may be used to apply corrections to measurements by IMU  and\/or sensors  and\/or to recalibrate IMU \/sensors , so that measurements by IMU \/sensors  may more closely track the VSLAM determined pose.","In another embodiment, depth data from a depth sensor, which may be captured in conjunction with the capture of a depth-image by camera(s) , may be used to generate and incrementally update a 3D or volumetric model of the environment in real-time (or offline). For example, the current camera pose may be obtained by tracking a live depth-image frame relative to the 3D model based on the observed available depth data. As one example, each depth-image in a sequence of captured depth-images may be used with real-time SLAM to produce and\/or incrementally update a 3D model while simultaneously tracking the pose of camera(s)  based on the depth data in each frame. With depth sensors and SLAM techniques users may be able to generate a smooth incrementally updating 3D reconstruction. In some embodiments, to save power, the depth sensors may be enabled to acquire depth information, when the SLAM based 3D reconstruction techniques determine that information that is new to an existing 3D model has been imaged.","Further, in instances, where 3D reconstruction capability is unavailable UE , the captured image data along with camera pose and other sensor data captured or measured in conjunction with the capture of image frames or the determination of camera pose may be stored in memory , medium  and\/or sent to a server using transmitter , where the data may be processed offline to obtain a 3D model and\/or map of the environment. Accordingly, one or more methods disclosed herein may also be performed offline by a server in communication with UE .","In some instances, the 3D model may take the form of a textured 3D mesh, a volumetric data set, a CAD model, a wireframe model, etc., which may be used to render the 3D environment being modeled. For example, in embodiments where a 3D mesh is used, keyframes in a VSLAM technique may be used to acquire a point cloud representation of an environment. The term point cloud refers to a set of data points in a coordinate system, such as, for example a 3D coordinate system with X, Y, and Z coordinates. The point cloud representation may then be converted into a 3D mesh using an appropriate scattered data interpolation method. In some instances, a sparse point cloud representation, which is based on a set of scattered data points, may be obtained and used during 3D reconstruction.","Further, in some embodiments, processing unit(s)  may further comprise a Positioning Engine (PE) or Position Determination Module (PDM)  (hereinafter PDM ), which may use information derived from images, sensor and wireless measurements by UE  either independently, or in conjunction with received location assistance data to determine a position and a position uncertainty estimate for UE . For example, LADM  may process location assistance information comprising multipath and visibility map assistance information, PRS timing pattern and\/or muting information, etc., which may then be used by processing unit(s)  to select a signal acquisition\/measurement strategy and\/or determine an initial location. In some embodiments, processing unit(s)  may also be capable of processing various other received such as Long Term Evolution (LTE) Positioning Protocol (LPP) or LPP extensions (LPPe) messages including assistance information either directly or in conjunction with one or more other functional blocks shown in .","In some embodiments, UE  may include one or more UE antennas (not shown) which may be internal or external. UE antennas may be used to transmit and\/or receive signals processed by transceiver  and\/or SPS receiver . In some embodiments, UE antennas may be coupled to transceiver  and SPS receiver . In some embodiments, measurements of signals received (transmitted) by UE  may be performed at the point of connection of the UE antennas and transceiver . For example, the measurement point of reference for received (transmitted) RF signal measurements may be an input (output) terminal of the receiver  (transmitter ) and an output (input) terminal of the UE antennas. In an UE  with multiple UE antennas or antenna arrays, the antenna connector may be viewed as a virtual point representing the aggregate output (input) of multiple UE antennas. In some embodiments, UE  may measure received signals including signal strength and TOA measurements and the raw measurements may be processed by processing unit(s) .","The methodologies described herein may be implemented by various means depending upon the application. For example, these methodologies may be implemented using modules in hardware, firmware, software, or any combination thereof. For a hardware implementation, the processing unit(s)  may be implemented within one or more application specific integrated circuits (ASICs), digital signal processors (DSPs), digital signal processing devices (DSPDs), programmable logic devices (PLDs), field programmable gate arrays (FPGAs), processors, controllers, micro-controllers, microprocessors, electronic devices, other electronic units designed to perform the functions described herein, or a combination thereof.","For a firmware and\/or software implementation, the methodologies may be implemented using code, procedures, functions, and so on that perform the functions described herein. Any machine-readable medium tangibly embodying instructions may be used in implementing the methodologies described herein. For example, software codes may be stored in a non-transitory computer-readable medium  or memory  that is connected to and executed by processing unit(s) . Memory may be implemented within the processor unit or external to the processor unit. As used herein the term \u201cmemory\u201d refers to any type of long term, short term, volatile, nonvolatile, or other memory and is not to be limited to any particular type of memory or number of memories, or type of media upon which memory is stored. In some embodiments, memory  may hold program code that facilitates hybrid photo navigation and mapping, image processing, SLAM, tracking, modeling, 3D reconstruction, and other tasks performed by MM , NM , CVM  and\/or PDM  on processor . For example, memory  may hold data, captured still images, depth information, video frames, program results, 3D models, keyframes, as well as data provided by IMU , various sensors .","If implemented in firmware and\/or software, the functions may be stored as one or more instructions or program code on a computer-readable medium, such as medium  and\/or memory . Examples include computer-readable media encoded with computer programs and data associated with or used by the program. For example, the computer-readable medium including program code stored thereon may include program code to support hybrid photo mapping and navigation in a manner consistent with disclosed embodiments. The code may further support Advanced Forward Link Trilateration (AFLT)\/hybrid-AFLT\/Reference Signal Time Difference (RSTD)\/OTDOA measurement and positioning, in part, by using location assistance information. Computer-readable media  includes physical computer storage media. A storage medium may be any available medium that can be accessed by a computer. By way of example, and not limitation, such non-transitory computer-readable media can comprise RAM, ROM, EEPROM, CD-ROM, flash memory, or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other medium that can be used to store desired program code in the form of instructions and\/or data and that can be accessed by a computer; disk and disc, as used herein, includes compact disc (CD), laser disc, optical disc, digital versatile disc (DVD), floppy disk and blu-ray disc where disks usually reproduce data magnetically, while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer-readable media.","In addition to storage on computer readable medium , instructions and\/or data may be provided as signals on transmission media included in a communication apparatus. For example, a communication apparatus may include a transceiver , which may receive signals through receiver  indicative of instructions and data. The instructions and data may cause one or more processors to implement hybrid photo mapping and navigation and\/or AFLT\/hybrid-AFLT\/RSTD\/OTDOA measurement and positioning, and\/or other functions outlined herein. That is, the communication apparatus includes transmission media with signals indicative of information to perform disclosed functions.","Memory  may represent any data storage mechanism. Memory  may include, for example, a primary memory and\/or a secondary memory. Primary memory may include, for example, a random access memory, read only memory, etc. While illustrated in this example as being separate from processing unit(s) , it should be understood that all or part of a primary memory may be provided within or otherwise co-located\/coupled with processing unit(s) . Secondary memory may include, for example, the same or similar type of memory as primary memory and\/or one or more data storage devices or systems, such as, for example, a disk drive, an optical disc drive, a tape drive, a solid state memory drive, etc.","In certain implementations, secondary memory may be operatively receptive of, or otherwise configurable to couple to a non-transitory computer-readable medium . As such, in certain example implementations, the methods and\/or apparatuses presented herein may take the form in whole or part of a computer-readable medium  that may include computer implementable instructions  stored thereon, which if executed by at least one processing unit(s)  may be operatively enabled to perform all or portions of the example operations as described herein. Computer readable medium  may be a part of memory .","Further, UE  may include a screen or display  capable of rendering color images, including 3D images. In some embodiments, display  may be used to display live images captured by camera(s) , Graphical User Interfaces (GUIs), program output, etc. In some embodiments, display  may comprise and\/or be housed with a touchscreen to permit users to input data via some combination of virtual keyboards, icons, menus, or other Graphical User Interfaces (GUIs), user gestures and\/or input devices such as a stylus and other writing implements. In some embodiments, display  may be implemented using a Liquid Crystal Display (LCD) display or a Light Emitting Diode (LED) display, such as an Organic LED (OLED) display. In other embodiments, for example as shown in , display  may be a wearable display or a heads-up display, which may be operationally coupled to camera , processing unit(s) , and\/or other functional units in UE .",{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 2","b":["200","200"]},"For example, in some instances, server  may optionally send maps or other location assistance information to UE  (or a plurality of UDs ), which may be used by UE  to estimate an approximate location. Further, one or more image frames, video, and\/or other measurements, which may be captured by UE  may sent to server . For example, in some instances, based on the received location assistance data (e.g. by LADM ) UE  may obtain measurements, including wireless signal measurements, and\/or measurements using sensors , which may be captured in conjunction with the capture of images by camera(s) . The captured images and\/or measurements may be used locally by UE  and\/or may be sent to server . For example, the captured images and measurements may be used by UE  and\/or server  to generate or update models\/maps of a location and\/or to update Base Station Almanac (BSA) data. The updated data\/BSA data may then be sent to one or more UE  as location assistance data.","As illustrated in , the UE  may communicate with server  through network  and base station antennas ---, collectively referred to as antennas , which may be associated with network . Server  may, in some instances, provide the functionality of one or more of a mapping server, location server, BSA server, position determination entity (PDE), or another network entity. The transfer of the location and other information may occur at a rate appropriate to both UE  and server .","In some embodiments, system  may use messages such as LPP or LPPe messages between UE  and server . The LPP Protocol is well-known and described in various publicly available technical specifications from an organization known as the 3rd Generation Partnership Project (3GPP). LPPe has been defined by the Open Mobile Alliance (OMA) and may be used in combination with LPP such that each combined LPP\/LPPe message would be an LPP message comprising an embedded LPPe message.","In some embodiments, UE  may receive and measure signals from base station antennas , which may be used for position determination. Antennas  may form part of a wireless communication network, which may be a wireless wide area network (WWAN), wireless local area network (WLAN), a wireless personal area network (WPAN), and so on. The term \u201cnetwork\u201d and \u201csystem\u201d are often used interchangeably herein. A WWAN may be a Code Division Multiple Access (CDMA) network, a Time Division Multiple Access (TDMA) network, a Frequency Division Multiple Access (FDMA) network, an Orthogonal Frequency Division Multiple Access (OFDMA) network, a Single-Carrier Frequency Division Multiple Access (SC-FDMA) network, Long Term Evolution (LTE), WiMax and so on.","A CDMA network may implement one or more radio access technologies (RATs) such as cdma2000, Wideband-CDMA (W-CDMA), and so on. Cdma2000 includes IS-95, IS-2000, and IS-856 standards. A TDMA network may implement Global System for Mobile Communications (GSM), Digital Advanced Mobile Phone System (D-AMPS), or some other RAT. GSM, W-CDMA, and LTE are described in documents from an organization known as the \u201c3rd Generation Partnership Project\u201d (3GPP). Cdma2000 is described in documents from a consortium named \u201c3rd Generation Partnership Project 2\u201d (3GPP2). 3GPP and 3GPP2 documents are publicly available. A WLAN may be an IEEE 802.11x network, and a WPAN may be a Bluetooth network, an IEEE 802.15x, or some other type of personal area network. The techniques may also be implemented in conjunction with any combination of WWAN, WLAN and\/or WPAN. For example, antennas  and network  may form part of, e.g., an evolved UMTS Terrestrial Radio Access Network (E-UTRAN) (LTE) network, a W-CDMA UTRAN network, a GSM\/EDGE Radio Access Network (GERAN), a 1\u00d7RTT network, an Evolution-Data Optimized (EvDO) network, a WiMax network or a WLAN.","UE  may also receive signals from one or more Earth orbiting Space Vehicles (SVs) --- collectively referred to as SVs , which may be part of a SPS\/GNSS. SVs , for example, may be in a GNSS constellation such as the US Global Positioning System (GPS), the European Galileo system, the Russian Glonass system or the Chinese Compass system. In accordance with certain aspects, the techniques presented herein are not restricted to global systems (e.g., GNSS) for SPS. For example, the techniques provided herein may be applied to or otherwise enabled for use in various regional systems, such as, e.g., Quasi-Zenith Satellite System (QZSS) over Japan, Indian Regional Navigational Satellite System (IRNSS) over India, and\/or various augmentation systems (e.g., an Satellite Based Augmentation System (SBAS)) that may be associated with or otherwise enabled for use with one or more global and\/or regional navigation satellite systems. By way of example but not limitation, an SBAS may include an augmentation system(s) that provides integrity information, differential corrections, etc., such as, e.g., Wide Area Augmentation System (WAAS), European Geostationary Navigation Overlay Service (EGNOS), Multi-functional Satellite Augmentation System (MSAS), GPS Aided Geo Augmented Navigation or GPS and Geo Augmented Navigation system (GAGAN), and\/or the like. Thus, as used herein an SPS may include any combination of one or more global and\/or regional navigation satellite systems and\/or augmentation systems, and SPS signals may include SPS, SPS-like, and\/or other signals associated with such one or more SPS.","For simplicity, only one UE  and server  are shown in . In general, system  may comprise multiple cells indicated by -(0\u2266k\u2266N, where Nis the number of cells) with additional networks , LCS clients , UDs , servers , (base station) antennas , and Space Vehicles (SVs) . System  may further comprise a mix of cells including macrocells and femtocells in a manner consistent with embodiments disclosed herein.","UE  may be capable of wirelessly communicating with server  through one or more networks  that support positioning and location services, which may include but are not limited to the Secure User Plane Location (SUPL) location solution defined by OMA and the Control Plane location solution defined by 3GPP for use with an LTE serving network. For example, Location services (LCS) may be performed on behalf of LCS Client  that accesses server  (which may provide functionality associated with a location server) and issues a request for the location of UE . Server  may then respond to LCS Client  with a location estimate for UE . LCS Client  may also be known as a SUPL Agent\u2014e.g. when the location solution used by server  and UE  is SUPL. In some embodiments, UE  may also include an LCS Client or a SUPL agent (not shown in ) that may issue a location request to some positioning capable function such as PDM  within UE  and later receive back a location estimate for UE . The LCS Client or SUPL Agent within UE  may perform location services for the user of UE \u2014e.g. provide navigation directions or identify points of interest within the vicinity of UE .","Server  may take the form of a SUPL Location Platform (SLP), an evolved Serving Mobile Location Center (eSMLC), a Serving Mobile Location Center (SMLC), a Gateway Mobile Location Center (GMLC), a Position Determining Entity (PDE), a Standalone SMLC (SAS), and\/or the like.","As illustrated in , the UE  may communicate with server  through network  and antennas , which may be associated with network . UE  may receive and measure signals from antennas , which may be used for position determination. For example, UE  may receive and measure signals from one or more of antennas -, -, - and\/or -, which may be associated with cells -, -, - and -, respectively, in order to facilitate position determination. As another example, UE  may use a hybrid position location scheme, using a Global Positioning System (GPS) receiver on UE  and computing its position based on measurements from sensors  and\/or captured images, in combination with AFLT and GPS measurements (e.g. from SVs ). In some embodiments, a combination of GNSS\u2032, terrestrial measurements (e.g. AFLT, cell sector measurements, WLAN measurements, OTDOA) and\/or sensor measurements (e.g. measurements using IMU , sensors , cameras or image sensors (which may include depth sensors), etc.) may be used to obtain a position estimate.","In some embodiments, a position estimate obtained may be a coarse and\/or initial position estimate and may be refined in a manner consistent with disclosed embodiments. In general, measurements made by UE  may be combined with network related measurements, such as those stored in a BSA, to enhance the availability and accuracy of the computed positions of UE  and\/or antennas .","As another example, in OTDOA based positioning, which is used with WCDMA and LTE, UE  may measure time differences in received signals from a plurality of base station antennas . Because positions of the antennas  are known, the observed time differences may be used to calculate the location of UE . For example, the measured time difference of arrival of Positioning Reference Signals (PRS), which is termed the Reference Signal Time Difference (RSTD), may be used along with the absolute or relative transmission timing of each cell, and the known position(s) of antennas  for the reference and neighboring cells, to calculate the position of UE .","In AFLT based positioning, which is used with CDMA, UE  may measure phases of pilot signals, which are synchronized to an absolute time scale (e.g. GPS time), and transmitted from four base station antennas ---. The measured phase of a pilot signal from an antenna -, 1\u2266i\u22664 may be used to calculate the distance between UE  and the respective antenna. The set of distance measurements may be used to calculate location of UE  provided the time offsets of antennas  are known.","UE  may obtain a measure of time synchronization of the forward link cell signal by comparing the time of arrival of a cell signal with the absolute time scale. UE  may record the known GPS position and GPS time at the time of this measurement and using the known position of the cell transmitter(s), such as antenna -, a time of arrival bias for the cell signal may be determined.","Determination of the time bias for a cell signal is known as Forward Link Calibration (FLC). In some instances, UE  may send raw measurement information to server , which may perform the forward link calibration. For example, the distance correction is quantified as a forward link calibration value (FLC). FLC improves positioning accuracy because even a synchronization variation of the order of a 100 ns between cells will translate into 30 meters of ranging error. Therefore, FLC accuracy facilitates optimal performance in terrestrial positioning systems. However, even within a cell , FLC may vary with position of UE based on a variety of factors such as signal attenuation, blockage, multi-path, etc. For example, in dense urban environments, where blockage and\/or multipath is more prevalent, mapping the environment to determine an exterior structural envelope and\/or obtaining accurate position estimates may present challenges. For example, various signals, such as signals from SVs , and\/or from one or more antennas  may be unavailable or weak thereby limiting position determination techniques that are based solely on wireless signals.","Accordingly, embodiments disclosed herein facilitate mapping and navigation in indoor environments using hybrid photo mapping and navigation techniques disclosed herein and thereby improving position estimation and extending terrestrial positioning system deployment and utilization.",{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIGS. 3A and 3B"},"As shown , SPS based positioning techniques are typically highly available outdoors globally, exhibit high outdoor precision, low outdoor position ambiguity, and fair power consumption. Further, a Line Of Sight (LOS) to the satellites facilitates time stitching with SPS systems. Time stitching refers to the capability to accurately correlate and align measurements obtained from various sensors to captured images on a common time scale.","Inertial navigation techniques are highly available both indoors and outdoors and exhibit fair power consumption but, because of drift and other biases, their precision is lower ranging typically from medium to good. IMU measurements are more easily time stitched and correlated with other measurements.","Photo navigation is highly available outdoors but exhibits higher power consumption and higher outdoor location ambiguity. For example, similar images may sometimes be obtained at various different locations making identification of a single location difficult without additional images and\/or other sensory input. On the other hand, when UEs can be localized to an area, then location precision is high. For example, there may be a limited set of locations from where a known landmark or structural feature is visible, so based on a captured image, the location of the UE may be accurately determined for both mapping and navigation. Captured images may be time stitched and correlated with other measurements relatively quickly.","WAN based location techniques exhibit good availability both outdoors and indoors and, when available, have relatively strong signals. However, WAN signals have limited global availability because there may areas that are not served by cellular signals. WAN based location techniques exhibit relatively low power consumption, have medium outdoor precision, low outdoor location ambiguity and may be time stitched with fair ease.","Finally, LAN or beacon based location techniques exhibit fair availability outdoors but signal strength may vary significantly with location. LAN signals have good global availability, exhibit fair power consumption, have medium outdoor precision, low outdoor location ambiguity and may be time stitched with fair ease.","As can be seen from  and the above description, the location techniques have various strengths and drawbacks when used individually. Thus, when using current location determination techniques, which rely on one of the above methods, mapping and\/or navigation solutions are often sub-optimal.","Therefore, methods disclosed herein combine measurements from a plurality of sensors with images and wireless signal measurements to facilitate location determination. For example, SPS have global scope, while strong WAN signals may help with low power background navigation in a localized indoor environment, especially in situations where the locations of wireless access points are known. When combined with the excellent local precision provided by camera images and measurements from inertial sensors, which can provide additional input when wireless signals are unavailable, more robust and accurate positioning solutions may be enabled.","However, there is a dearth of maps, especially maps that show buildings and exterior features of structures in a manner that facilitates user orientation and navigation. Without such accurate and detailed maps, optimal utilization of position information is difficult. For example, while simple navigation instructions from point A to point B may be provided with a basic map, there may be considerable ambiguity that may lead to user frustration. Providing structural information or other visual cues for structures along the path from point A to point B may reduce ambiguity and user frustration. Therefore, obtaining reliable, accurate and detailed maps inexpensively for locations may facilitate more optimal use of existing user device functionality.","In some embodiments, showing local landmarks or exterior envelopes of structures that are registered to a map, may facilitate user orientation and use of the map. Therefore, disclosed techniques also combine measurements from a plurality of sensors with images and wireless signal measurements to facilitate mapping and\/or navigation. For example, image based navigation techniques may be enhanced when used with precise \u201cphoto\u201d and\/or visibility maps. Similarly, precise calibration provided by images captured by a camera may be used provide effective outdoor wireless navigation. These and other techniques disclosed herein are used with user devices both to obtain and update maps of locations and to enable navigation functionality.","In some embodiments, Mapping Module (MM)  may be used to place UE  in a \u201cmapping mode\u201d. In the mapping mode, camera(s)  on UE  may capture images or video at a specified frame rate in conjunction with measurements from sensors  (which may include various non-wireless\/non-RF sensors such as magnetometers, altimeters, barometers and\/or other magnetometer, altimeter, barometer and\/or other) and IMU . For example, a user may place UE  in mapping mode when using UE  for mapping. In mapping mode, the camera may be placed in a \u201cwide angle\u201d mode. Further, in mapping mode, high resolution images may be captured, but the images may be compressed, filtered, or altered to reduce size. In some embodiments, the images captured by camera(s)  may be stored locally at high resolution and\/or sent to server  for later processing. For example, in some embodiments, the images may be reduced to a vector map, or vector images, which provide variety of different content and resolutions to suit different needs.","Further, in some embodiments, when in mapping mode, CV module  may be configured to use \u201cManhattan World\u201d assumptions. Manhattan World (MW) assumptions, which are used extensively to produce 3D reconstructions of urban structures from images and\/or point clouds, assume that scenes or images captured by a camera consist of piece-wise planar surfaces with dominant directions. Typically, when MW assumptions are used to determine building geometry, a predominance of three mutually orthogonal directions in scene is assumed. Level and plumb surfaces and edges may also be assumed. MW assumptions facilitate 3D reconstruction from 2D images. Various well-known techniques are available for 3D reconstruction based on captured images. For example, in one exemplary embodiment, dominant plane directions (e.g. X, Y, Z) may be extracted from an image, hypotheses may be generated for planes in the image (e.g. based on feature point densities in the image) and a 3D reconstruction obtained by associating image pixels with one or more of the planes. When used with depth sensors, MW assumptions may facilitate faster 3D reconstruction based on the acquired depth information. When inertial sensors are used to determine device orientation and camera angle, MW assumptions may facilitate more efficient discernment of vertical and horizontal edges and surfaces and their respective locations, orientations and relationships.","In some embodiments, a mapping mode on a UE  may be activated opportunistically when the user is travelling through an area and\/or is incentivized to travel through an area: (i) that has not been mapped and\/or (ii) an area where updating map data is desirable. For example, when in mapping mode, based on crowdsourced data (or the absence of such data) pertaining to a location at a server the UE may request a \u201csurvey\u201d of the interior and\/or exterior of a structure. In another embodiment, opportunistic crowdsourcing may be used, and the user may be asked to enter mapping mode based on an estimated location of the UD. In some embodiments, the user's consent may be obtained and the user may actively participate in opportunistic crowdsourced mapping. In some embodiments, for example, where camera  is wearable, image capture and sensor data collection may be automatically triggered and the data may be stored on UE  and\/or transmitted to server  based on previously obtained user consent. The term \u201ccrowdsourcing\u201d is used to refer to the collection and subsequent aggregation of the collected image, RF, sensor and positioning related measurements from a plurality of UDs and\/or PDEs. In some embodiments, upon detecting that a user is near a structure which may be desirable to map (or to update an existing map), the user may be asked or incentivized to perform the mapping in a manner consistent with disclosed embodiments. Because of the number of structures and the frequency of changes to the structures, traditional methods of maintaining updated maps which include exterior structural envelopes of the structures, even when possible, are cost prohibitive. The use of crowdsourcing in conjunction with mapping methods disclosed herein facilitates the maintenance and update of maps including 3D external envelopes of structures. Further, areas that are highly trafficked are more likely to have frequently updated and accurate maps. Thus, a map database based on crowdsourced map data including exterior 3D structural envelopes of buildings, obtained in a manner consistent with disclosed embodiments is more likely to be populated with data for areas with a higher demand for accurate and updated data.",{"@attributes":{"id":"p-0091","num":"0090"},"figref":"FIG. 4A","b":["400","400","100","150","100","400","155","405","400"]},"Referring to , which shows the user in an environment where mapping application  may be run and where signal reception from satellite vehicles (SVs)  and\/or wireless networks may be available. Accordingly, in , UE  may be place in a mapping mode and images may be collected by UE  as the user travels around an outdoor location\u2014such as a building \u2014as directed by the application.","For example, the user may be directed to follow trajectory  and images may be collected by UE  as the user travels around structure . In some embodiments, in conjunction with the capture of images, UE  may obtain a measurement sets comprising wireless and non-wireless measurements, where each measurement set is associated with at least one image. For example, UE  may determine its position and record measurements of signals from SVs  at various locations on trajectory . In addition, UE  may also record measurements of wireless signals from wireless network  and\/or antennas - and - in conjunction with image capture. In addition, UE  may also record measurements from IMU  and\/or one or more sensors , including magnetometer, altimeter, barometer etc. in conjunction with image capture. For example, in some embodiments, MM  may commence mapping at a location where SPS signals are available and may determine the location of UE  at various times by timestitching measurement sets based on timestamps associated with the measurements and\/or by using VSLAM on the timestamped captured images.","In some embodiments, a mapping application and\/or MM  may direct the user to capture images of salient visual features including externally visible signs (such as store sign \u201cXYZ STORE\u201d), windows, doors, overhangs, corner points, neighboring structures, etc. For example, the inference that a wall is both \u201cexterior\u201d and \u201cinterior\u201d can be made if it has a window in it. That window, as viewed from the outside and inside, may be used to align the two different views of the same wall. Accordingly, MM  may direct a user to capture features that are likely to be visible from both inside and outside the structure.","Accordingly, as illustrated in , CVM  may receive image frames of the exterior of structure  that are synchronized to the capture of wireless and non-wireless measurements. Depending on available functionality, the image frames may be captured as a series of still images and\/or as part of video. Embodiments utilizing video capture can, for example, receive images at 30 frames per second. Other embodiments may utilize other frame rates. CVM  may use camera calibration. Intrinsic camera calibration may include principal point, focal length, and radial distortion. Extrinsic camera calibration parameters may include rotation and translation information relative to IMU . Rotation can be estimated or, in some instances, the IMU may be assumed to be aligned with the camera.","As outlined above, CVM  may employ any of a variety of algorithms to determine and detect keypoints in image frames to estimate a 6 Degrees Of Freedom (6DOF) camera\/UE pose relative to a current image frame. Some subset of the captured image frames may be stored as keyframes. In some embodiments, CVM  may use the pose determined in a prior image frame as an initial pose, which may then be refined based on the locations of keypoints in the image frame. When the pose of UE  has changed by more than some threshold, the current image frame may be stored by CM  as a new keyframe. The locations of keypoints and other image correspondences relative to a prior image frame or a stored keyframe may also be used to estimate scene geometry. For example, CVM  may assign depth information to features of structure  and 3D model of structure  may be iteratively created. In some embodiments, MW assumptions may be used to simplify 3D external envelope determination for a structure.","In some embodiments, the keypoint detection can result in the identification of measured 2D camera coordinates of keypoints, which are relayed to EKF component . The EKF component  may further share predicted 2D camera coordinates of keypoints with the CVM  to narrow the keypoint search space. When one or more keypoints are located by CVM , the 2D camera coordinates of these keypoints may be provided to EKF component . In some embodiments, CVM  may also provide a 6 Degrees Of Freedom (6DOF) camera pose, which may be determined by CVM , based on the locations of keypoints in image frames.","In some embodiments, the input 6DOF camera pose (provided by CVM ) may be refined by EKF  to obtain a pose of the UE in absolute coordinates based on inputs supplied by CVM  and\/or IMU and\/or wireless measurements. The 6DOF camera pose determined by the EKF may also be used to calculate\/update a 3D location of one or more the target features. EKF component  may utilize the 2D keypoint measurements from CVM  along with wireless and\/or non-wireless measurements to track the 6DOF pose of camera \/UE  in absolute coordinates. For example, EKF component  may use a recent GPS or other wireless measurements (when available) to anchor measurement sets to an absolute coordinate framework.","The term \u201cabsolute coordinates\u201d or \u201cglobal coordinates\u201d is used to refer to absolute SPS coordinates such as provided by GPS or any other global coordinate system such as the World Geodetic System (WGS) standards used for mapping and navigation. In some embodiments, EKF component  may provide a gravity vector in addition to the 3D locations of detected features points in image frames to CVM . In some embodiments, gravity and 3-D locations of keypoints may be obtained during or as part of the pose estimation process. For more information regarding determination of gravity, see \u201cVisual-Inertial Navigation, Mapping And Localization: A Scalable Real-Time Causal Approach\u201d (2010) by Eagle S. Jones, Stefano Soatto. In systems using conventional visual-inertial techniques a trajectory of a UE may be determined. However, conventional techniques do not disclose 3D structural envelope determination and the determination of outdoor maps based on the measurements, where the structural 3D envelope information and the outdoor maps are registered to absolute coordinates.","By determining UE\/camera pose relative to the target and anchoring measurements to absolute coordinates, an absolute pose of the UE can be determined by EKF .","EKF component  may further determine any biases associated with IMU  and\/or other sensors, which may be used to mitigate drift. Global optimization techniques such as Global Bundle Adjustment (GBA) may be used by the EKF  to correct for drift and in the computation of a closed loop trajectory of DE during mapping as outlined further below.","For example, in some embodiments, the mapping application may direct the user to return to features that were previously imaged. In some embodiments, the trajectory of the user may be corrected, to account for drift, by returning to visual features previously photographed. A \u201cclosed loop\u201d trajectory may then be determined and used to correct for drift. The external 3D structural envelope of structure  registered to absolute coordinates may be determined based on the corrected and\/or closed loop trajectory.","In some embodiments, the data gathered by UE , including the estimated trajectory and\/or 3D structural envelope can be sent to a server to build an outdoor map, which may include 3D structural envelope information for structure  registered to absolute coordinates on the outdoor map.","When traversing path  collecting data for map creation, the determined locations (e.g. the pose of UE  output by EKF ) may be subject to drift. For a 1% drift error, for example, a path length of 100 m will result in a drift of about 1 m. To correct for drift errors, loop closure detection (LCD) and global bundle adjustment (GBA) can be performed on the data gathered by UE \/MM  and\/or poses of the UE  output by EKF  after the user has completed gathering the data. In some embodiments, LCD and GBA may be performed on a server (e.g., a server creating the map). For example, DE  may send the collected data and\/or an estimated trajectory to a server, which may perform LCD and GBA tasks. However, depending on the capabilities available on UE , one or more of LCD and GBA may be performed on UE .","For example, in some embodiments, the mapping application may direct the user to return to features that were previously imaged. In some embodiments, LCD may identify previously viewed features in images to determine drift. Using the data gathered by UE \/MM , CVM  may use feature information from images captured by camera(s)  to determine areas with common feature information. For example, a first set of coordinates may be determined for a first static feature in a first image based on a camera pose and measurements associated with the first image. The first static feature may be identified in a subsequent image captured by the camera and associated with a second set of coordinates. Because the location associated with the feature has not changed, the LCD algorithm may determine a drift over the trajectory of UE . For example, the LCD algorithm may \u201cclose the loop\u201d by assigning the first set of coordinates to any subsequent visit of the same feature. A GBA algorithm can then be used to correct and align the measurements to mitigate or eliminate drift error from an initially estimated trajectory (corresponding to path ) and calculate an updated \u201cclosed-loop\u201d trajectory (also corresponding to path ). In some embodiments, the updated closed loop trajectory may be used along with an initially estimated external 3D structural envelope to obtain an updated external 3D structural envelope of structure , which may be registered to absolute coordinates on an outdoor map.",{"@attributes":{"id":"p-0106","num":"0105"},"figref":"FIG. 5A","b":["500","500","100","500","100","150"]},"In step , UE  may enter a mapping mode. In \u201cmapping mode\u201d UE  may collect continuous GNSS, camera and inertial data and other sensor data at a relatively high rate. Further, in mapping mode, sensory measurements such as RF measurements, GNSS measurements and data from inertial, magnetometer, altimeter, and\/or barometric sensors may be captured in conjunction with the capture of images. In the mapping mode actual GNSS measurement data may be used such as continuous carrier phase observables (as opposed to the \u201cposition outputs\u201d normally seen in smart phones) to provide a further anchor for the visual odometry process and to stabilize the UE clock state, so long as Line of Sight (LOS) conditions exist for at least one or more SPS satellites .","Typically data received from SVs  may have several sources of error. For example, errors may occur due to clock drift, ionospheric delay, multipath, a lower number of visible satellites, satellite geometry, satellite elevation relative to the horizon, etc. In some embodiments, SPS receiver may include a carrier phase receiver, which may measure carrier wave related information. The carrier wave, which typically has a much higher frequency than the pseudo random noise (PRN) sequence that it carries, facilitates more accurate position determination when used in conjunction with code phase measurements and differential techniques. The use of carrier phase measurements along with differential correction, can yield sub-meter position accuracy. In some embodiments, UE may use real-time carrier phase differential GPS (CDGPS) techniques to determine the position of UE at various point and times. UE positions may be used, in part, for example, to compute trajectory  (in ),","In step , a 6-DOF \u201copen loop\u201d trajectory of the UE  may be determined based on inertial measurements. For example, measurements by IMU  or sensors  on UE  may be used to determine the trajectory from an initial or starting position. Because of errors due to drift and other biases in the sensors, the trajectory, as measured by IMU  and\/or sensors  will diverge from the actual trajectory followed by UE . Thus, the term \u201copen loop\u201d refers to the possibility that even if the UE's trajectory terminates at the starting location, a trajectory determined solely from measurements by IMU \/sensors  may indicate that the trajectory end-point is different from the starting location.","In some embodiments, in step , measurements by IMU \/sensors , wireless measurements (e.g. SPS\/WLAN), captured images and other sensor measurements may be used to correct the inertial trajectory. For example, GNSS measurements may be used to correct the inertial trajectory. In some embodiments, the captured measurement data may be processed on UE  and\/or sent to a server for processing. In some embodiments, floating integer carrier smoothed code measurements may be used, or carrier cycle ambiguities may be resolved. With strong GPS signal conditions, GPS carrier beat phase counting can be used to smooth code phase. Code multipath can change quickly when the MS is moving outdoors, which facilitates code phase smoothing. For example, multiple types of measurements for each satellite \u201cchannel\u201d may be obtained from GNSS measurement engines including: code phase, Doppler and accumulated beat phase, also known as integrated carrier phase or accumulated delta-range. One or more of the measurements and\/or techniques detailed above may be used for more accurate corrected absolute UE position determination at various points in time. The corrected absolute DE positions may be used to make trajectory corrections (such as to 7-DOF trajectory ) followed by the UE .","Although, absolute errors may occasionally persist, distortions due to wireless multipath variation can be effectively mitigated using disclosed techniques, thereby providing a precise trajectory and therefore a precise map with multiple precisely associated map layers. For example, even in instances where the uncertainty in the absolute position of a structure error is in the order of a meter at mapping time, the associations in the various map layers may all be accurate to better than a meter. Therefore, in some embodiments, when the device is in LOS to GNSS signals, a precise trajectory may be determined. The precise trajectory determined may be used to cooperatively calibrate IMU sensors, and also determine the potentially larger biases and stability of other measurement sources and\/or sensors , such as WWAN, WLAN, barometric sensors and magnetometers.","In step , a 3D building envelope or external 3D structural envelope and\/or an exterior 3D map may be obtained based on the captured images, wireless (SPS and\/or RF) signal measurements, measurements by IMU , and\/or measurements by sensors . In some embodiments, the user may be directed to capture images of neighboring landmarks, structures, building overhangs etc while keeping a structure (such as structure ) in view. The term \u201cbuilding envelope\u201d refers to the outer shell of the building\/structure that serves as a physical separator between the interior and the exterior environments of a building.","In step , a closed loop trajectory of UE  may be determined. For example, in instances, where LOS conditions exist to more than one satellite thereby permitting simultaneous multiple carrier phase observations the inertial trajectory may be stabilized. For example, the user\/UE  may be directed to return to visual feature(s) that were previously photographed during the data collection. When a previously viewed location or feature is detected, the estimated trajectory can be re-estimated, which is termed as \u201cloop-closing\u201d. Camera poses for the two images may be computed, for example, using VSLAM techniques based on the position of the visual feature in the two images. In some embodiments, an Extended Kalman Filter (EKF) or other techniques may be used to fuse camera and inertial (accelerometer\/gyroscope) measurements to obtain a 6DOF camera pose for the captured images. Based on camera poses associated with the two images, IMU (gyro and accelerometer errors)  measurements may be modeled such that the trajectory is re-estimated to return to the photographed visual feature(s) with no apparent errors. This closed loop trajectory may be viewed as having 7 Degrees Of Freedom (7-DOF) indicating 3 dimensions of position uncertainty, 3 dimensions of rotational uncertainty, and an additional \u201cdimension\u201d of receiver clock bias.","The receiver clock bias relates wireless ranging measurements such as those associated with GNSS, WWAN and WLAN RTT. Receiver clock bias can be useful to improve accuracy because even timing errors on the order of 1 ns can translate into ranging errors on the order of 1 foot. In LOS conditions to GNSS satellites, corrected carrier phase measurements may have a precision on the order of 1 cm, but an unknown constant of integration. The constant of integration may be determined by a number of techniques known in the kinematic carrier phase processing art. In some embodiments, changes in carrier phase over the trajectory may be used to determine a precise UE position and a clock bias profile over the trajectory without knowledge of the constant of integration. In some embodiments, the changes in carrier phase over the trajectory may facilitate the creation of precise wireless delay maps, even in instances where the constant of integration is unknown or unavailable.","In many cases, absolute errors on the order of meters may remain, but distortions due to wireless multipath variation can be effectively mitigated, providing a precise trajectory and therefore a precise map with multiple precisely associated map layers, where the associations may all be accurate to better than a meter, even if the absolute position of the structure is not known to better than a meter at the time of mapping. While the device is in LOS to GNSS signals, then, it is possible to create a highly precise trajectory that can be used to not only cooperatively calibrate IMU sensors, but also determine the larger biases and stability of other measurement sources, such as WWAN, WLAN, barometric sensors and magnetometers.","In step , an exterior photographic feature map may be determined for the exterior envelope using visible features determined from the captured images. For example, a sparse 3D map of feature points for the exterior of a structure may be created. Feature detection and tracking may be performed, for example, using the well-known Lukas-Kanade method or variations thereof.","In step , GNSS carrier phase data may be used to repair losses of lock and corrections may then be applied to facilitate determination of absolute position. For example, if LOS conditions exist with respect to one or more of SVs, while Non-LOS (NLOS) conditions exist with respect to other SVs at various times, then, the carrier phase observations of the LOS satellites may be stitched together. In situations where there is a brief outage of the carrier phase observable (often referred to as a cycle slip) or NLOS conditions exist, data from a combination of inertial sensors, barometric sensors, magnetometers, and\/or image based odometry may be used to \u201cstitch\u201d across the outages and determine UE position.","Non Line of Sight (NLOS) conditions may exist to one or more satellites at various points in time, but if LOS conditions exist to other satellites at those times, then, carrier phase observations of the LOS satellites may be stitched together. For example, as shown in , at time T0, when following trajectory , UE  may receive LOS signals from SVs - and -, antenna -, while signals received from SV -, antenna - and AP - may be NLOS. Further, at a subsequent time T1 and at a different location on trajectory , UE  may receive LOS signals from SV - and antenna -, while signals from SVs - and -, antenna - and AP - may be NLOS.","Thus, if LOS conditions exist with respect to one or more of SVs -, -, and\/or - at various times, then, the carrier phase observations of the LOS satellites may be stitched together. In situations where there is a brief outage of the carrier phase observable (often referred to as a cycle slip) or Non LOS (NLOS) conditions exist, data from a combination of inertial sensors, barometric sensors, magnetometers, and\/or image based odometry may be used to \u201cstitch\u201d across the outages and determine UE position.","For example, inertial stitching may be used when inertial trajectory drift is less than some threshold (e.g. less than half a GPS L1 wavelength). In some embodiments, if signals from SV's  and\/or antennas  are unavailable for a period, then measurements from IMU  may be used to determine the trajectory from the position and point in time when the signals from SV  and\/or antennas  were last available to the position and point in the time when the SV\/antenna signals next become available. In some embodiments, the reprocessed carrier phase data and\/or stitching may be applied to correct the 7-DOF or closed loop trajectory.","Referring to , in step , in some embodiments, the 3D building envelope may then be re-determined based on the re-estimated 7-DOF trajectory. In some embodiments, MW assumptions may use to determine the building envelope. For example, it may be assumed that most walls are plumb (perfectly vertical) and meet at 90 degree angles. Thus, in this way, an initial, \u201copen loop\u201d 3D photo model of the building may be adjusted to rectangular walls and vertically aligned. The walls may also be assumed to be perpendicular or parallel. Then, the trajectory of UE  may be recalculated from the visual odometry data against this adjusted 3D photo model.","In step , the position of the building may then be registered to global coordinates, in part, by using GNSS pseudorange measurements. In some embodiments, the external envelope of the structure may be adjusted based on overhead images (e.g. satellite or other aerial images) in combination with local views of roof overhangs or other features. Overhead images of a structure at various resolutions may be obtained from various government and\/or other publicly accessible databases.","In step , the re-estimated trajectory may then be registered to global coordinates. In some embodiments, the pseudorange measurement errors arising on account of multipath, satellite position, satellite clock drift, residual ionospheric and tropospheric signal delays, etc. may be mitigated using differential methods, where more accurate models for satellite position and clock, ionospheric activity and tropospheric wet delay etc may be used to mitigate errors. Furthermore, to the extent that carrier phase observations are concurrently available, multipath errors may be reduced using code-carrier smoothing and measurements with large code-carrier variance may be weighted appropriately.","In some embodiments, carrier phase differential GNSS processing may be used to further improve the device trajectory estimate with either floating or fixed (resolved) carrier cycle ambiguities. Carrier phase differential GNSS processing typically uses a nearby reference receiver at a known benchmark location that has been registered to a global coordinate system. In this case, residual atmospheric errors largely cancel out and cycle ambiguities may be resolved.","In an alternate embodiment, the device trajectory may be stitched together using visual odometry to form a synthetic carrier phase differential process over time. Because satellite-related errors and atmospheric errors change relatively slowly, the precision of the local map may be maintained initially without differential processing, and differential processing may be added subsequently for map registration and clarification when the appropriate reference data becomes available. The reference data may include observations of actual satellite position, orientation and clock offset.","In some embodiments, the satellite orientation may be determined while accounting for the phase pattern of the satellite antenna so that wide area satellite carrier phase corrections may be determined and applied. If the satellite orientation or any other factor creating signal phase variation is determined using a terrestrial reference receiver network, with or without the satellite antenna phase corrections, the resultant \u201cdifferential corrections\u201d may then be localized for use in the map processing.","In some embodiments, in step , barometric offset observations may be obtained. Barometric pressure typically follows a standard adiabatic lapse rate as height within the building changes. However, some buildings or portions of buildings may be pressurized. Any deviations from the standard adiabatic lapse rate may be inferred to be as a result of building pressurization. Those deviations, as well as any uncertainty in the deviations, may be noted as barometric annotations to the map. For example, \u201cBarometric pressure observed to be X mm Hg higher than adiabatic lapse rate would predict from floor  to .\u201d","In step , wireless measurements may be corrected based on antenna patterns. For example, UE  may be placed in a calibration mode during or prior to entering mapping mode. When in calibration the determination of antenna patterns for an antenna on UE  may be initiated. In some situations, antenna pattern determination may be performed outdoors. Each antenna will have its own phase and gain pattern. When the orientation of UE  is known, the antenna pattern may be determined with a user holding the device in a typical pose and rotating it around one or more axes. The antenna pattern data obtained may be used to mitigate antenna pattern effects on subsequent RF signal characterization.","In step , measurements obtained in mapping mode from sensors may also be used to generate and\/or update one or more existing maps, which may be stored on server . These maps may include one or more of an outdoor 2D road map or floor plan, a photo map, which may include 3D navigable feature database, a heat map, which may indicate signal strengths for one or more antennas at various locations, and\/or a spatially variable FLC map, which may indicate signal delays for an antenna at various locations.","In some embodiments, one or more of the maps may be stored as and\/or aggregated with measurements in existing map layers at differing levels of position granularity. The term \u201cmap layer\u201d as used herein refers to information, such as measurement data, information derived from measurement data, location assistance information, etc. that is tailored to a position and position uncertainty of a UD. There may be different layers for each measurement type, all registered to the same local or absolute coordinates. For example, for each wireless signal of interest, there may be at least one of: FLC delay, signal strength, or attenuation map layers. There may be a barometric variation annotation layer. There may be a magnetic field variation layer, providing local corrections to a standard Earth magnetic field model.","In some embodiments, when in mapping mode, UE  may request and\/or receive location assistance information to determine an initial location estimate, which may also be provided in the form of map layers. For example, location assistance information comprising a first FLC value may be provided in a first map layer to UE  based on an estimated first position and position uncertainty of UE . When the position\/position uncertainty of UE  is refined or re-estimated based on the previously provided location assistance information, FLC values based on the refined position estimate\/position uncertainty may be retrieved from another map layer to facilitate a more accurate determination of UE position.","In general, map layers may comprise various other types of information. For example, map layers may comprise one or more of: a received signal strength map layer that correlates a received signal strength with map locations; a Signal to Noise Ratio (SNR) map layer correlating SNRs with map locations; a Line of Sight (LOS) map layer indicating map locations where LOS conditions are likely with respect to one or more antennas; a Non-Line of Sight map layer, the NLOS map layer indicating map locations where NLOS or body blocked conditions are likely with respect to one or more antennas, etc.","In some embodiments, the map layers may also comprise at least one multipath layer to provide an indication of the extent of multipath for the antenna for locations in the BSA. Further, in one embodiment, the multipath layer may further comprise at least one of: a long shadow layer to indicate long shadow regions for the antenna, the long shadow layer comprising exclusion zones, an indication of the magnitude of multipath, and\/or signal attenuation levels for the antenna in the long shadow regions; or a short shadow layer to indicate short shadow regions for the antenna, the short shadow layer comprising timing granularity information for antenna signals in the short shadow regions; or a transmitting pattern layer to indicate unique transmission patterns in at least one coverage area of the antenna. In some embodiments, UE  may use information in one or more map layers to estimate a location and location uncertainty, and based on the location and location uncertainty may request additional map layers. In some embodiments, a plurality of map layers may be provided to UE  based on the location\/location uncertainty of UE . In general, location assistance information comprising map layers may be provided to UE  based on protocols used for communication with UE , available bandwidth for communication, signal conditions, cost, communication, memory and\/or processing capability available at UE  and various other parameters.","Similarly, when measurements are received from UE , the measurements may be used to generate and\/or update existing map layers. For example, the new measurements may replace one or more older measurements used to determine one or more map layers. For example, measurements older than some time period, and\/or measurement deemed unreliable or inaccurate (e.g. with a position uncertainty estimate exceeding that in the current measurement) in one or more map layers may be updated. In some embodiments, the new measurements may be aggregated with the older measurements. For example, when statistically significant, an average, median and\/or other statistical measure may be computed by aggregating the measurement with existing measurements to produce one or more updated map layers. In some embodiments, an appropriate version control mechanism may be used to maintain timeliness, precision and accuracy of the provided map layers.","In step , if the determination of the outdoor envelope of the structure is incomplete (\u201cN\u201d in step ), then the process or portions of the process may be repeated and another iteration commenced in step .","If the determination of the outdoor envelope is complete (\u201cY\u201d in step ) then, the measured data of interest may be recorded on UE  and\/or transmitted to a server. For example, the data may be recorded in database  associated with a mapping application. In some embodiments, the data may be stored in memory , removable media and\/or computer readable medium  and\/or other storage coupled to UE .","In some embodiments, all or part of the collected data may be processed on the UE  and\/or sent to a server  for processing. In some embodiments, if maps are available for neighboring and\/or attached structures, the indoor\/outdoor maps for the current structure and the attached\/neighboring structures may be stitched together, for example, by using exterior images. In some embodiments, pointers\/associations to nearby structure maps may be cached in UE , and\/or on the server. In some embodiments, where a \u201csmart glass\u201d or other wearable device is coupled to the phone such as a Bluetooth headset with a camera, the camera on the smart-glass\/wearable device may be triggered when UE  is placed in mapping mode.",{"@attributes":{"id":"p-0138","num":"0137"},"figref":"FIG. 6","b":["600","600","100","600","600","150","600","100","600","605","100"]},"Next, in step , a search for wireless signals may be started. In some embodiments, location assistance data requested and\/or received from server  may be used by UE  to select a strategy for wireless signal search. In some embodiments, the location assistance data may include WWAN, WLAN and\/or GNSS assistance data. In step , feedback may be provided on the wireless signal search. For example, signals may be received from the serving cell and one or more neighboring WWAN cells , one or more GNSS SVs  and\/or one or more WLAN APs  and their absolute and\/or relative signal strengths noted.","In step , one or more sensors on UE  may be activated. For example, camera , sensors , and\/or IMU  may be activated. In some embodiments, measurements of sensors  and\/or IMU  may be synchronized to the capture of image frames by camera . In some embodiments, if wireless positioning (e.g. positioning based on GNSS and\/or hybrid measurements) is available based on signals obtained in steps \/, then IMU  may be initialized with an initial position based on the wireless positioning.","In some embodiments, when UE  is placed in mapping mode, sensor measurements may be taken fine granularity in conjunction with and\/or based on the video frame rate from 15 fps-30 fps. In some embodiments, one or more sensors may be calibrated using a camera pose determined using CV techniques based on the captured images. In some embodiments, one or more of an image timestamp obtained at an application level, a sensor timestamp obtained from an Application Programming Interface (API), an offset between the timestamps, and\/or jitter in camera timestamps based on exposure times may be used for: (i) correlating various sensor measurements, (ii) correlating captured images with the sensor measurements, and\/or (iii) time stitching the measurements. In some embodiments, when correlating sensor measurements with images relative timestamps or offsets may be used.","In some embodiments, in step , the user may be optionally instructed on calibration of IMU . In one embodiment, IMU  may be calibrated using images captured by camera . For example, the user may be instructed to point the camera at a target object and\/perform a motion sequence. In step , the user may be provided feedback related to the motion sequence and\/or the progress of calibration. For example Computer Vision (CV) based techniques, may be used to obtain a camera pose for a plurality of images. IMU  may be calibrated, in part, by comparing CV based poses for each of the plurality of frames with corresponding IMU determined poses for the frames. In some embodiments, IMU  may be calibrated using observation equations that relate CV measurements to IMU  error states, which may be modeled using well-known Kalman filter techniques.","In step , determination of antenna patterns for an antenna on UE  may be initiated. In some situations, antenna pattern determination may be performed outdoors. Each antenna will have its own phase and gain pattern. When the orientation of UE  is known, the antenna pattern may be determined with a user holding the device in a typical pose and rotating it around one or more axes.","Accordingly, in step , the user may be given instructions pertaining to the motion of UE  so that antenna pattern information for UE  may be determined. In some embodiments, to facilitate performance of the motion or movement of UE , feedback may be provided, in step , in terms of a direction to move the device, and\/or the extent of completion of the antenna pattern determination process. In some embodiments, the feedback may be provided using Graphical User Interface (GUI) shown on display .","In step , UE  may provide an indication that the antenna pattern determination has completed and antenna pattern  for UE  may be generated. In some embodiments, antenna patterns determined in step  may be further corrected, for example, during step  in method  (), based on the estimated orientation of the UE  over the course of a trajectory followed, such as, for example, trajectory . For increased accuracy and to further mitigate any residual GNSS carrier multipath, in portions of trajectory , where observation indicate that carrier multipath is most challenging along the inertial trajectory, with availability of a highly overdetermined trajectory solution, any residual phase errors may be mapped out and removed and\/or deweighted. Accordingly, antenna pattern correction may occur even after the completion of step  and\/or in conjunction with the performance of one or more steps (e.g.  through  in ) related to the determination of the outdoor trajectory in method . In some embodiments, antenna pattern data  may be used to mitigate antenna pattern effects on subsequent RF signal characterization.","In step , UE  may be placed in an outdoor envelope data collection mode; and, in step , the user may be instructed regarding outdoor data collection. For example, camera(s)  may be placed in a wide-angle mode and the user may be directed to capture images of doors, windows, and other features\/structural elements that may also be visible indoors. As another example, the user may be directed to capture images of any roof overhangs, such that they may be subtracted from roof dimensions in the process of establishing a building perimeter from a combination of overhead imagery of the roof structure and photographs of the overhangs from the underside. It should be appreciated that overhangs may be the same on all sides of a building, but not always. Thus, models may assume a single observed overhang is the same around the entire perimeter and then correct this assumption later during the map determination process. Likewise, several estimates of the roof overhang may be made and averaged along a single exterior wall. Thus, it is important to keep track of not only the estimate of the overhang length and the roof pitch, but also how well these parameters are known, in the form of an uncertainty parameter.","In step , the user may be provided feedback regarding the trajectory to be followed. For example, the user of UE  may be asked to follow a continuous trajectory to obtain a view of the structure from all sides, while maintaining an optimal distance and\/or view of the structure. In some embodiments, the user may be directed to capture images of nearby structures, landmarks etc while keeping the outdoor structure being mapped in view. The user may also be asked to point the camera such that entire edges, such as the full extent of a building corner, the full length of an eave or foundation wall, the full length of the edge between wall and ceiling, etc. may be seen at once. The user may be asked to circumnavigate the perimeter of a building or city block, for example, and return to their starting point to close the loop of the inertial navigation and confirm that the trajectory was precisely tracked for the entirety of the loop. The user may be asked to back-track if lock on too many satellites was lost or IMU calibration compromised for more than a brief period of time. In some embodiments, the user may be asked to reacquire the trajectory using visual means, assure lock has been regained and then continue on the route.","In step , if the image capture and measurement process for the outdoor envelope determination is incomplete, then, another iteration may be commenced in step . For example, the user may be asked to repeat trajectory  to maximize carrier phase continuity and\/or to avoid specific difficult multipath locations while still maintaining a good visual view of the structure. In some embodiments, the satellite locations in the sky may be displayed to the user, with a representation of when lock is lost and\/or regained, to provide the user with rapid feedback for how they are holding the device and maintaining lock.","In step , the measurements and images collected may be processed to obtain map data . In some embodiments, step  may be performed offline on a server such as server . For example, UE  may transmit the collected measurements and images to server . For example, sever  may be a Base Station Almanac (BSA) server and\/or another location server, which may process and\/or aggregate the measurements\/images with data received from other UDs. In some embodiments, the sensor\/RF\/SPS\/measurements may be correlated to the captured images to obtain map data .","In step , one or more maps  may be generated based on map data . In some embodiments, existing maps may be updated based on map data  to obtain maps . In some embodiments, maps  may be organized as layers at differing levels of UE position granularity. In step , results, such as the exterior envelope of the structure on a map may be optionally displayed to the user.","In step , the user may be prompted to end the mapping mode or repeat one or more steps in method . In some embodiments, a summary of map data  and\/or the data collected may be shown to the user, when the user is prompted to end mapping mode. Based on the user input, mapping mode may terminate in step  and\/or one more steps in method  may be repeated.",{"@attributes":{"id":"p-0152","num":"0151"},"figref":"FIG. 7","b":["700","710","1","713","715","717","639","719"]},"In outdoor data processing phase , data collected in outdoor data collection phase - may be used to obtain Outdoor Open Loop Trajectory , which may then be used to obtain an exterior 3D building envelope , Outdoor Wireless Map  and Outdoor Closed Loop Trajectory .","In a map generation phase , some or all of the data collected outdoors in data collection phases - and -, respectively, may be used to update exterior 3D building model  and to generate various maps. For example, outdoor 3D wireless map, magnetic map layer, barometric annotations, etc. may be obtained.","Barometric pressure typically follows a standard adiabatic lapse rate as height within the building changes. However, some buildings or portions of buildings may be pressurized. Any deviations from the standard adiabatic lapse rate may be inferred to be as a result of building pressurization. Those deviations, as well as any uncertainty in the deviations, may be noted as barometric annotations  to the map. For example, \u201cBarometric pressure observed to be X mm Hg higher than adiabatic lapse rate would predict from floor  to .\u201d",{"@attributes":{"id":"p-0156","num":"0155"},"figref":"FIG. 8A","b":["800","800","100","250","800","100","100"]},"In step , outdoor 6-DOF open loop trajectory  of the UE may be determined based on the inertial data in camera and inertial data .","In step , in some embodiments, the exterior 3D building envelope  may be obtained based on outdoor 6-DOF open loop trajectory .","In step , outdoor 7-DOF closed loop trajectory  may be obtained by reprocessing visual odometry against exterior 3D building envelope . In some embodiments, a combination of SPS\/GNSS\/LAN\/WAN measurements, IMU  measurements and images captured by camera(s)  may be used to determine the outdoor 7-DOF closed loop trajectory  of UE . For example, inertial stitching may be used when inertial trajectory drift is less than some threshold (e.g. less than half a GPS L1 wavelength). For example, where LOS conditions exist to more than one satellite thereby permitting simultaneous multiple carrier phase observations the inertial trajectory may be stabilized by returning to visual feature(s) that were previously photographed during the data collection and gyro and accelerometer errors may be modeled such that the trajectory (is re-estimated to return to the visual feature(s) with no apparent errors.","In some embodiments, MW assumptions may be used in determination of exterior 3D building envelope . Then, the trajectory of UE  may be recalculated from the visual odometry data against this adjusted 3D photo model to obtain outdoor 7-DOF closed loop trajectory .","Next, in step , the 3D building envelope  may be updated and\/or reprocessed based on 7-DOF closed loop trajectory .","Referring to , in some embodiments, in step , the position and orientation of the building may also be registered to global coordinates, in part, by using updated 3D building envelope  and wireless (e.g. GNSS) measurements . In step , outdoor 7-DOF closed loop trajectory  may then be registered to global coordinates.","In some embodiments, in step , antenna patterns , updated 3D building envelope  and wireless measurements  may also be used to generate and\/or update one or more existing outdoor wireless map(s) . In some embodiments, outdoor wireless map(s)  may be generated and\/or stored on server . These maps may include one or more of an outdoor 2D road map or floor plan, a photo map, which may include 3D navigable feature database, a heat map, which may indicate signal strengths for one or more antennas at various locations, and\/or a spatially variable FLC map, which may indicate signal delays for an antenna at various locations. In some embodiments, one or more of the maps may be stored as layers at differing levels of position granularity.","In step , 3D outdoor wireless map  may be obtained based on outdoor closed loop trajectory , wireless measurement data , antenna patterns  and 3D model building model .","In step , magnetometer data  may be used to produce magnetic map layer , and in step , barometric data  may be used to produce barometric map annotations .","In some embodiments, all or part of the collected data may be processed on the UE  and\/or sent to a server  for processing. In some embodiments, if maps are available for neighboring and\/or attached structures, the indoor\/outdoor maps for the current structure and the attached\/neighboring structures may be stitched together, for example, by using exterior images. In some embodiments, pointers\/associations to nearby structure maps may be cached in the UD, and\/or on the server. In some embodiments, where a \u201csmart glass\u201d or other wearable device is coupled to the phone such as a Bluetooth headset with a camera, the camera on the smart-glass\/wearable device may be triggered.",{"@attributes":{"id":"p-0167","num":"0166"},"figref":["FIG. 9","FIG. 9"],"b":["900","100","900","100","970","902","904","970","280","240","620","230","100","902","280","240"]},"In some instances, UE  may also obtain an initial location estimate  by using initial measurements . Initial location estimate , which is sometimes termed a \u201cprefix\u201d, may be a coarse estimate of the position of UE . In some instances, range measurements by UE  may be used to obtain initial location estimate . In some instances, a location associated with the serving cell, or the strongest cell, or the earliest cell, or another cell may be used as initial location estimate . For example, the centroid of the serving cell, or the strongest cell, or the earliest cell, or some other cell may be used as initial location estimate . As a further example, a random or default starting location within a cell may be used as initial location estimate . Cell related information may be obtained from the Cell Sector Identity, Network ID, System ID, and other information transmitted by the base station. UE  may provide initial location estimate  and\/or initial measurements  (e.g., satellite measurements from one or more GNSSs, or network measurements such as OTDOAs and\/or RSTDs from one or more networks, etc.) to server . In some situations, UE  may not determine initial location estimate , instead, initial measurements  taken by UE  may be sent to server , which may use initial measurements  to determine initial location estimate  for UE .","Server  may provide then provide location related information based on initial location estimate , such as location assistance data  to UE . In some embodiments, the location assistance data may be received by one or more of LDAM , MM , PDM , and\/or NM  and may be used to assist UE  in acquiring and measuring signals from SVs  and\/or antennas , and\/or in refining any initial location estimate  obtained from measurements . In some embodiments, the location assistance data may include map layers and\/or other information at a granularity tailored to initial location estimate  and a position uncertainty associated with initial location estimate .","For example, UE , which in some instances may take the form of a Secure User Plane (SUPL) Enabled Terminal (SET), may communicate with server  and use location assistance data  obtain additional measurements . In some embodiments, additional measurements  may comprise various FLC related measurements and\/or Pilot Phase measurements, Time of Arrival, RSTD\/OTDOA measurements, measurements related to time offsets of base station antennas, GPS (e.g. pseudorange) measurements, etc. In some instances, in response to the receipt of location assistance data or lack thereof, UE  may enter mapping mode and capture additional measurements , which may include measurements from camera(s) , IMU , sensors  and other wireless (GNSS\/WAN\/LAN) signal measurements as outlined above. In some embodiments, UE  may send additional measurements  to server  or another PDE over network  and\/or store the measurements in memory .","In some embodiments, server , UE , or another PDE may use additional measurements  to obtain a refined location for UE . In some embodiments, UE  may use additional measurements  to directly obtain a refined location estimate. Further, in some embodiments, the refined location estimate for UE  may be communicated to LCS Client . When the position\/position uncertainty of UE  is refined or re-estimated based on the previously provided location assistance information, FLC values and\/or other information based on the refined position estimate\/position uncertainty may be retrieved from another map layer to facilitate a more accurate determination of UE position. In general, position location may be UD-assisted, where UE  sends back raw or pre-processed measurement data through the base station to a PDE in the network for use in position determination; or, UD-based, where the position computation is performed by UE .","Wireless communication systems that provide position determination services, typically store and\/or aggregate calibration information and other measurements used for location determination in one or more databases, such as a Base Station Almanac (BSA) database, a map database, etc. For example, the databases may include maps with map layers, which may include various other types of information.","For example, map layers may include one or more of: a received signal strength map layer that correlates a received signal strength with map locations; a Signal to Noise Ratio (SNR) map layer correlating SNRs with map locations; a Line of Sight (LOS) map layer indicating map locations where LOS conditions are likely with respect to one or more antennas; a Non-Line of Sight map layer, the NLOS map layer indicating map locations where NLOS or body blocked conditions are likely with respect to one or more antennas, etc. In some embodiments, the map layers may also include at least one multipath layer to provide an indication of the extent of multipath for the antenna for locations in the BSA. Further, in one embodiment, the multipath layer may further comprise at least one of: a long shadow layer to indicate long shadow regions for the antenna, the long shadow layer comprising exclusion zones, an indication of the magnitude of multipath, and\/or signal attenuation levels for the antenna in the long shadow regions; or a short shadow layer to indicate short shadow regions for the antenna, the short shadow layer comprising timing granularity information for antenna signals in the short shadow regions; or a transmitting pattern layer to indicate unique transmission patterns in at least one coverage area of the antenna.","In some embodiments, UE  may use information in one or more map layers to estimate a location and location uncertainty, and based on the location and location uncertainty may request or retrieve additional map layers. In some embodiments, a plurality of map layers may be provided to UE  based on the location\/location uncertainty of UE . In general, location assistance information comprising map layers may be provided to UE  based on protocols used for communication with UE , available bandwidth for communication, signal conditions, cost, communication, memory and\/or processing capability available at UE  and various other parameters.","In some embodiments, each region on a map may be identified by the coordinates (e.g. latitude, longitude, altitude) of one or more boundary points, which may be dependent on the granularity of the map layer. Accordingly, in these embodiments, measurements pertaining to points within a region may be aggregated and associated with the region. Some or all of the hierarchy of aggregated measurements and related data may be provided to UE  based on its position\/position uncertainty.","The BSA database may store\/aggregate calibration and other base station related information. The BSA record for a base station may specify the base station identification information, the position (e.g. altitude, latitude and longitude) of the base station antenna(s), FLC values at a position for an antenna, antenna orientation, range, repeater information, etc. The term \u201cFLC value\u201d as used herein may refer to both FLC values and FLC residuals. FLC residuals may be specified in distance units (e.g. meters), while FLC values may be specified in time units (e.g. seconds). In some embodiments, the BSA may also include information such as the center of a base station sector coverage area, the maximum range of the base station signals, the average terrain height over one or more coverage area(s)\/sub-area(s), the terrain height standard deviation over the one or more coverage area(s)\/sub-area(s), round-trip delay (RTD) calibration information, pseudo-random noise (PN) increments in CDMA systems, uncertainty in the base station antenna position, uncertainty in the forward-link delay calibration, and uncertainty in the round-trip delay calibration.","In some embodiments, a system to facilitate terrestrial positioning system calibration may aggregate additional measurements , including FLC related measurements and refined position estimates by a plurality of UDs\/PDEs. In some embodiments, measurements in mapping mode by each of the plurality of UDs may be aggregated and stored on a server and statistical significance may be derived based on the aggregation. For example, a standard deviation, variance, mean, median and other statistical measures may be derived from the aggregation. In some embodiments, measurements taken by an UE  may be used to replace measurements in the database. For example, if visual images and\/or other measurements indicate that the interior of a structure has changed relative to a stored 3D building model , then stored building model  may be updated and\/or replaced with a new building model based on the more recent measurements. Similarly, one or more of exterior 3D building envelope , 3D wireless map , magnetic map layer  and\/or barometric map annotations , and\/or other map layers may be updated based on new measurements. Thus, UE  may both receive location assistance data  in the form of information in the database(s) and additional measurements  captured by UE  in mapping mode may be used to update the existing database(s).","For example, refined location estimate(s) associated with UE  and measurements (including images captured) by UE  at those location(s) may be associated and\/or aggregated with measurements by other UEs for the same location and\/or for a region in the vicinity of that location based on the granularity of the information stored in the database. In some embodiments, one or more of the captured images may be stored as keyframes or reference frames along with an estimated camera pose(s) associate with the keyframe image(s). In some embodiments, the exterior 3D envelope  may include keyframes.","In some embodiments, the refined position estimate may be associated with the aggregated measurements based on a quality threshold associated with the position fix. For example, a \u201cHorizontal Estimated Position Error\u201d (HEPE) quality measure, which represents an estimate of the error associated with each location fix, may be used to determine which measurements are added and\/or aggregated to the BSA database. For example, measurements associated with position fixes with a HEPE value of less than some specified threshold depending on the desired accuracy or position granularity\u2014may be added and\/or aggregated with the database(s).","In some embodiments, a base station almanac database may be configured initially with default, average or estimated FLC values and with reasonably accurate antenna positions. In some embodiments, existing BSAs may be used and updated based on the plurality of additional measurements  received from the plurality of UE's  and\/or PDEs. Based on repeated measurements made by the plurality of UE's \/PDEs, the antenna position estimates and spatially-variable FLC values will continually improve over time leading to greater antenna position certainty, which may be used to improve the forward link calibration accuracy.","In some embodiments, server  may aggregate raw measurement information from a crowd of UDs to create statistically significant maps with information at different granularities associated with the measurements. In some embodiments, server  may perform some or all of the functions of a BSA, map, and\/or location server. For example, server  may collect and format location data, generate and update maps or models, may provide assistance to UDs for position estimation, and\/or may perform computations to obtain position estimates for the UEs. In some embodiments, server  may comprise a BSA server, which may manage a BSA database that stores a complete BSA.","Embodiments disclosed, for example, including the crowd sourcing of photographic and other measurements from a plurality of UDs\/PDEs, may provide continuously maintained map data including indoor maps and reduce or remove the need for resource intensive field work. In some embodiments, a high sampling rate may be maintained throughout the network because of frequent crowd sourced sampling by a plurality of user owned devices. In some embodiments, the crowd sourced measurement may be used to build and\/or update the database(s)\/BSA.","Because the sampling rate, statistical significance, and accuracy of information are proportional to user density at a location, popular locations, which have higher user density, will be calibrated frequently. Accordingly, such crowd based calibration systems may optimize themselves to where users are located and\/or where location services are repeatedly used. In contrast, existing systems are typically calibrated based on some metric of network geometry or signal propagation models, which may not reflect usage patterns. Further, popular locations that are frequented by UE users will also tend to have up to date, statistically significant, and accurate information. In addition, during the deployment of a system consistent with embodiments disclosed herein, FLC information for popular locations may be quickly obtained based on more frequent gathered measurements thereby facilitating deployment.","In some embodiments, photographic data and measurements may also be collected and\/or supplemented by \u201cwardriving\u201d. In wardriving, a user may capture images, take sensor measurements and take measurements of wireless signals, which may be correlated with UE position to obtain maps. The collected measurements may be aggregated with and\/or used to supplement and\/or replace measurements stored in databases and\/or to update existing maps. In some embodiments, UE users, (e.g. users that are near a location or route where measurements\/mapping is desired) may be incentivized to travel to the location and\/or take a specified route. For example, a reward in the form of a cash reward, rebate, free airtime, or incentives targeted to establishments near the desired location or along the route may be used as incentives. In some embodiments, user consent may be obtained to install an application on a smartphone that may report measurements periodically to server .","In some embodiments, information in maps provided to UE  may include an indication of one or more of: the likelihood of detection of a signal, the likely accuracy of the signal at estimated position of UE  along with an estimate of the initial position uncertainty of UE . Further, in some embodiments, the maps provided to UE  may also include an indication of one or more of: the likelihood of LOS conditions, the lack of long multipath conditions, and\/or a determination of whether UE  lies in a long or short shadow region. The maps may include simple annotations such as eNodeB antenna location, antenna pattern and output power, such that the UE may perform a simple link analysis with a first order model. Further, the map may contain differences between this first order model and a more localized model, containing higher order correction terms.","Reference is now made to , which is a schematic block diagram illustrating a server  enabled to support enabled to support hybrid photo mapping and navigation. In some embodiments, server  may also provide support for position determination and crowdsourced map generation and navigation. In some embodiments, server  may support location determination by providing location assistance information including layered maps in a manner consistent with disclosed embodiments. Further, in some embodiments server  may update databases (e.g. a BSA, map, and\/or a configuration database) based on measurements and information reported by one or more UD\u2032  in a manner consistent with disclosed embodiments. In some embodiments, server  may include, for example, one or more processing units , memory , storage , and (as applicable) communications interface  (e.g., wireline or wireless network interface), which may be operatively coupled with one or more connections  (e.g., buses, lines, fibers, links, etc.). In certain example implementations, some portion of server  may take the form of a chipset, and\/or the like.","Communications interface  may include a variety of wired and wireless connections that support wired transmission and\/or reception and, if desired, may additionally or alternatively support transmission and reception of one or more signals over one or more types of wireless communication networks. Communications interface  may also include interfaces for communication with various other computers and peripherals. For example, in one embodiment, Communications interface  may comprise network interface cards, input-output cards, chips and\/or ASICs that implement one or more of the communication functions performed by server . In some embodiments, communications interface  may also interface with network  to obtain a variety of network configuration related information, such as PCIs, configured PRS information, and\/or timing information used by the base stations in the network. For example, Communications interface  may make use of the LPP annex (LPPa) protocol defined in 3GPP TS 36.455 or a modification of this protocol to obtain PCI, configured PRS, timing and\/or other information from the base stations in network . Processing unit  may use some or all of the received information to generate location assistance data in a manner consistent with disclosed embodiments.","Processing unit  may be implemented using a combination of hardware, firmware, and software. In some embodiments, processing unit  may include Server Location Assistance Data Module , which may generate location assistance information, including layered maps, with multi-path and visibility information, spatially variable FLC data, PRS timing and muting assistance information, etc. for transmission to UDs . In some embodiments, Server Location Assistance Data Module  may also generate location assistance information for transmission to UDs . Processing unit  may also be capable of processing various other LPP\/LPPe assistance information either directly or in conjunction with one or more other functional blocks shown in . In some embodiments, processing unit  may generate the location assistance information as Long Term Evolution (LTE) Positioning Protocol (LPP) or LPP extensions (LPPe) messages.","Further, in some embodiments, processing unit(s)  may further comprise a Position Determination Module (not shown), which may use information obtained from measurements by UE  to determine a position and a position uncertainty estimate for UE .","In some embodiments, processing unit(s)  may also comprise Database Update Module , which may correlate measurements by UE  with corresponding position estimates and position uncertainty estimates and update one or more BSAs and\/or calibration databases. For example, for a measurement received from an UE , Database Update Module  may aggregate the received measurement information with stored BSA data based on the position estimate and\/or position uncertainty estimate associated with the measurement. The position estimate and position uncertainty estimate may be either determined by and received from UE , determined by server  (e.g. by a PDM on server ), or by another network entity.","In some embodiments, processing unit  may represent one or more circuits configurable to perform at least a portion of a data signal computing procedure or process related to the operation of server .",{"@attributes":{"id":"p-0192","num":"0191"},"figref":"FIG. 11","b":["1100","1100","100","100","1100","100","250"]},"In some embodiments, in step , a plurality of images of the exterior of a structure may be captured when traversing a plurality of locations in the vicinity of the structure.","In step , a plurality of measurement sets may be captured within a short time window of the image capture, wherein each measurement set corresponds to at least one image and comprises at least one of Inertial Measurement Unit (IMU) measurements or available wireless measurements with correction information for the wireless measurements.","In some embodiments, the wireless measurements may comprise: Global Navigation Satellite System (GNSS) measurements comprising differentially corrected code and carrier phase observables and wherein the correction information for the wireless measurements comprises one or more of: GNSS code and carrier differential corrections, GNSS precise orbital and clock information, and GNSS atmospheric corrections.","Further, in some embodiments, the correction information for the wireless measurements is received by the UE from a network server. For example, the UE may send uncorrected wireless measurements to a network server and receive corrected wireless measurement information from the network server. In some embodiments, the correction information for the wireless measurements may comprise antenna pattern information for the UE.","The wireless measurements may further comprise Wireless Wide Area Network (WWAN) measurements comprising one or more of: Observed Time Difference of Arrival (OTDOA) measurements, or Reference Signal Time Difference (RSTD) measurements, or Advanced Forward Link Trilateralation (AFLT) measurements, or hybrid-AFLT measurements.","Next, in step , a 3D structural envelope of the structure and\/or a trajectory of the UE may be estimated based, in part, on the captured images and the corresponding plurality of measurement sets. In some embodiments, the trajectory of the UE may be estimated by: applying, for each location in a subset of locations on the trajectory, one or more of the: GNSS code and carrier differential corrections, GNSS precise orbital and clock information, or GNSS atmospheric corrections to GNSS measurements at the location; obtaining, for each location in the subset, a corresponding corrected location based on the corrected GNSS measurements; and determining a trajectory based, in part, on the corrected location corresponding to each location in the subset.","In some embodiments, the estimated trajectory of the UE and 3D structural envelope of the structure may be determined by applying Visual Simultaneous Localization and Mapping (VSLAM) techniques to a subset of the plurality of images of the structure to determine a scene geometry and a 6 Degrees Of Freedom (6DOF) pose of the UE relative to each image in the subset and a scene geometry, the pose being determined based on keypoints in the subset of images; and obtaining the external 3D structural envelope of the structure based, in part, on the scene geometry; and obtaining the estimated trajectory based, in part, on the estimated 6DOF pose. For example, the estimated trajectory may be obtained by providing the 6DOF pose to an Extended Kalman Filter (EKF), wherein the EKF determines a pose of the UE in absolute coordinates, based in part, on the 6DOF pose, IMU measurements and available wireless measurements.","In step , the estimated trajectory of the UE, and one or more of the 3D structural envelope, captured images, and\/or the corresponding measurement sets may be sent to a server wirelessly coupled to the UE.","In step , a corrected trajectory of the UE and a 3D structural envelope of the structure registered to absolute coordinates may be received by the UE. The received corrected trajectory and\/or structural envelope registered to absolute coordinates may be based, in part, on the estimated trajectory of the UE, and\/or captured images and\/or measurement sets, The corrected trajectory may correspond to a closed-loop trajectory of the UE. Further, in some embodiments, the corrected trajectory and 3D structural envelope of the structure registered to absolute coordinates may be received with an outdoor map comprising the corrected trajectory and the 3D structural envelope, wherein the outdoor map may comprise a plurality map layers registered to the absolute coordinates.","In some embodiments, the plurality of layers may include at least two of: a plan view map; or a 3D structural map, with external 3D structural envelope information for neighboring structures; attenuation or delay of WWAN signals associated with the structure, or annotations for any variation in WWAN signal strength in the vicinity of the structure; or a Line Of Sight (LOS) map layer, indicating, for each absolute coordinate in a first plurality of absolute coordinates on the map, corresponding WLAN antennas in a line of sight relative to the absolute coordinate.","The methodologies described herein in flow charts and message flows may be implemented by various means depending upon the application. For example, these methodologies may be implemented in hardware, firmware, software, or any combination thereof. For a hardware implementation, the processing unit  may be implemented within one or more application specific integrated circuits (ASICs), digital signal processors (DSPs), digital signal processing devices (DSPDs), programmable logic devices (PLDs), field programmable gate arrays (FPGAs), processors, controllers, micro-controllers, microprocessors, electronic devices, other electronic units designed to perform the functions described herein, or a combination thereof.","Although the disclosure is illustrated in connection with specific embodiments for instructional purposes, the disclosure is not limited thereto. Various adaptations and modifications may be made without departing from the scope Therefore, the spirit and scope of the appended claims should not be limited to the foregoing description."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1B"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIGS. 3A and 3B"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4A","b":"400"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4B"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 8A and 8B"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
