---
title: Monitoring and updating tasks arrival and completion statistics without data locking synchronization
abstract: Each processing resource in a scheduler of a process executing on a computer system maintains counts of the number of tasks that arrive at the processing resource and the number of tasks that complete on the processing resource. The counts are maintained in storage that is only writeable by the corresponding processing resource. The scheduler collects and sums the counts from each processing resource and provides statistics based on the summed counts and previous summed counts to a resource manager in response to a request from the resource manager. The scheduler does not reset the counts when the counts are collected and stores copies of the summed counts for use with the next request from the resource manager. The counts may be maintained without synchronization and with thread safety to minimize the impact of gathering statistics on the application.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08843927&OS=08843927&RS=08843927
owner: Microsoft Corporation
number: 08843927
owner_city: Redmond
owner_country: US
publication_date: 20090423
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Applications in a computer system typically do not have access to low level statistical data from the operating system about the application. The statistic data may identify a number of instructions retired by the application or the resource utilization by the application, for example. To obtain statistical data, application developers often resort to intrusive methods of gathering statistical data such as profiling the execution of the application or making rough approximations about the execution of the application. Unfortunately, the use of intrusive methods of gathering statistical data generally affects the outcome of the experiment (i.e., the observation changes the performance of the application) and the use of approximations may provide crude or unusable data.","In applications that implement concurrent programming (viz., interaction between multiple execution contexts such as threads, fibers (i.e., lightweight threads), and child processes), shared data is typically synchronized. When an execution context accesses data, it generally invokes a lock or other synchronization technique to ensure that no other execution context performs a conflicting access to the data. The synchronization prevents data from being corrupted but adds processing overhead to each data access. Perhaps more importantly, the synchronization often serializes the access to the data by different execution contexts. This serialization may inhibit the performance and scalability of a process, particularly where there are many independent processing resources that execute execution contexts.","This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.","Each processing resource in a scheduler of a process executing on a computer system maintains counts of the number of tasks that arrive at the processing resource and the number of tasks that complete on the processing resource. The counts are maintained in storage that is only writeable by the corresponding processing resource. The scheduler collects and sums the counts from each processing resource and provides statistics based on the summed counts and previous summed counts to a resource manager in response to a request from the resource manager. The scheduler does not reset the counts when the counts are collected and stores copies of the summed counts for use with the next request from the resource manager. The counts may be maintained without synchronization and with thread safety to minimize the impact of gathering statistics on the application.","In the following Detailed Description, reference is made to the accompanying drawings, which form a part hereof, and in which is shown by way of illustration specific embodiments in which the invention may be practiced. In this regard, directional terminology, such as \u201ctop,\u201d \u201cbottom,\u201d \u201cfront,\u201d \u201cback,\u201d \u201cleading,\u201d \u201ctrailing,\u201d etc., is used with reference to the orientation of the Figure(s) being described. Because components of embodiments can be positioned in a number of different orientations, the directional terminology is used for purposes of illustration and is in no way limiting. It is to be understood that other embodiments may be utilized and structural or logical changes may be made without departing from the scope of the present invention. The following detailed description, therefore, is not to be taken in a limiting sense, and the scope of the present invention is defined by the appended claims.","It is to be understood that the features of the various exemplary embodiments described herein may be combined with each other, unless specifically noted otherwise.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1","b":["22","12","10","22"]},"Runtime environment  represents a runtime mode of operation in a computer system, such as a computer system  shown in  and described in additional detail below, where the computer system is executing instructions. The computer system generates runtime environment  from a runtime platform such as a runtime platform  shown in  and described in additional detail below.","Runtime environment  includes an least one invoked process , an operating system (OS) , a set of hardware threads ()-(M), where M is an integer that is greater than or equal to one and denotes the Mth hardware thread (M), and a resource manager . Runtime environment  allows tasks from process  to be executed, along with tasks from any other processes that co-exist with process  (not shown), using OS , resource manager , and hardware threads ()-(M). Runtime environment  operates in conjunction with OS  and\/or resource manager  to allow process  to obtain processor and other resources of the computer system (e.g., hardware threads ()-(M)).","Runtime environment  includes a scheduler function that generates scheduler . In one embodiment, the scheduler function is implemented as a scheduler application programming interface (API). In other embodiments, the scheduler function may be implemented using other suitable programming constructs. When invoked, the scheduler function creates scheduler  in process  where scheduler  operates to schedule tasks of process  for execution by one or more hardware threads ()-(M). Runtime environment  may exploit fine grained concurrency that application or library developers express in their programs (e.g., process ) using accompanying tools that are aware of the facilities that the scheduler function provides.","Process  includes an allocation of processing and other resources that host one or more execution contexts (viz., threads, fibers (i.e., lightweight threads), or child processes). Process  obtains access to the processing and other resources in the computer system (e.g., hardware threads ()-(M) and memory ) from OS  and\/or resource manager . Process  causes tasks to be executed using the processing and other resources. In the embodiment of , the processing resources include virtual processors ()-(N), where N is an integer greater than or equal to two and denotes the Nth virtual processor .","Process  generates work in tasks of variable length where each task is associated with an execution context in scheduler . More than one task may be associated with a given execution context. Each task includes a sequence of instructions that perform a unit of work when executed by the computer system. Each execution context forms a thread, fiber (i.e., a lightweight thread), or analogous OS concept such as child process that executes associated tasks on allocated processing resources. Each execution context includes program state and machine state information. Execution contexts may terminate when there are no more tasks left to execute. For each task, runtime environment  and\/or process  either assign the task to scheduler  to be scheduled for execution or otherwise cause the task to be executed without using scheduler .","Process  may be configured to operate in a computer system based on any suitable execution model, such as a stack model or an interpreter model, and may represent any suitable type of code, such as an application, a library function, or an operating system service. Process  has a program state and machine state associated with a set of allocated resources that include a defined memory address space. Process  executes autonomously or substantially autonomously from any co-existing processes in runtime environment . Accordingly, process  does not adversely alter the program state of co-existing processes or the machine state of any resources allocated to co-existing processes. Similarly, co-existing processes do not adversely alter the program state of process  or the machine state of any resources allocated to process .","OS  manages processing and other resources of the computer system and provides a set of functions that allow process  and other processes in the computer system to access and use the components. In addition, OS  offers execution contexts to scheduler  and process  and allocates memory from a memory system, such as a memory system  shown in  and described in additional detail below, to scheduler  and process . OS  may allocate memory from the memory system in any suitable fixed or variable sizes (e.g., pages of 4 kilobytes (KB) to 64 KB).","Hardware threads  reside in execution cores of a set or one or more processor packages (e.g., processor packages  shown in  and described in additional detail below) of the computer system. Each hardware thread  is configured to execute instructions independently or substantially independently from the other execution cores and includes a machine state. Hardware threads  may be included in a single processor package or may be distributed across multiple processor packages. Each execution core in a processor package may include one or more hardware threads .","Resource manager  allocates processing resources to process  by assigning one or more hardware threads  to process . Resource manager  exists separately from OS  in the embodiment of . In other embodiments, resource manager  or some or all of the functions thereof may be included in OS .","Process  implicitly or explicitly causes scheduler  to be created via the scheduler function provided by runtime environment . Scheduler instance  may be implicitly created when process  uses APIs available in the computer system or programming language features. In response to the API or programming language features, runtime environment  creates scheduler  with a default policy. To explicitly create a scheduler , process  may invoke the scheduler function provided by runtime environment  and specifies a policy for scheduler . As described with reference to , A, and B below, process  may include any number of schedulers  and the schedulers  may be arranged in one or more scheduler bundles as shown in .","Scheduler  interacts with OS  and resource manager  to negotiate processing and other resources of the computer system in a manner that is transparent to process . OS  allocates memory to scheduler  in response to requests from virtual processors . Resource manager  allocates hardware threads  to scheduler  based on supply and demand and any policies of scheduler .","In the embodiment shown in , scheduler  manages the processing resources by creating virtual processors  that form an abstraction of underlying hardware threads . Scheduler  multiplexes virtual processors  onto hardware threads  by mapping each virtual processor  to a hardware thread . Scheduler  may map more than one virtual processor  onto a particular hardware thread  but maps only one hardware thread  to each virtual processor . In other embodiments, scheduler  manages processing resources in other suitable ways to cause instructions of process  to be executed by hardware threads .","Prior to executing tasks, scheduler  obtains execution contexts  and  from runtime environment  or OS . Available virtual processors  locate and execute execution contexts  and  to begin executing tasks. The set of execution contexts in scheduler  includes a set of execution contexts ()-(N) with respective, associated tasks ()-(N) that are being executed by respective virtual processors ()-(N), a set of zero or more runnable execution contexts , and a set of zero or more blocked (i.e., wait-dependent) execution contexts . Each execution context ,  and  includes state information that indicates whether an execution context ,  and  is executing, runnable (e.g., in response to becoming unblocked or added to scheduler ), or blocked. Execution contexts  that are executing have been attached to a virtual processor  and are currently executing. Execution contexts  that are runnable include an associated task  and are ready to be executed by an available virtual processor . Execution contexts  that are blocked include an associated task  and are waiting for data, a message, or an event that is being generated or will be generated by another execution context , , or .","Each execution context  executing on a virtual processor  may generate, in the course of its execution, additional tasks , which are organized in any suitable way (e.g., added to work queues (not shown in )). Work may be created by using either application programming interfaces (APIs) provided by runtime environment  or programming language features and corresponding tools in one embodiment. When processing resources are available to scheduler , tasks are assigned to execution contexts  or  that execute them to completion or a blocking point (e.g. waiting for a message or a stolen child task to complete) on virtual processors  before picking up new tasks. An execution context  executing on a virtual processor  may also unblock other execution contexts  by generating data, a message, or an event that will be used by another execution context .","Each task in scheduler  may be realized (e.g., realized tasks  and ), which indicates that an execution context  or  has been or will be attached to the task and the task is ready to execute. Realized tasks typically include light weight tasks and agents and may be associated with an execution context  or  just before executing or in advance of execution. A task that is not realized is termed unrealized. Unrealized tasks (e.g., tasks ) may be created as child tasks generated by the execution of parent tasks and may be generated by parallel constructs (e.g., parallel, parallel for, begin, and finish). Scheduler  may be organized into a synchronized collection (e.g., a stack and\/or a queue) for logically independent tasks with execution contexts (i.e., realized tasks) along with a list of workstealing queues for dependent tasks (i.e., unrealized tasks) as illustrated in the embodiment of  described below.","Upon completion, blocking, or other interruption (e.g., explicit yielding or forced preemption) of a task  associated with an execution context  running on a virtual processor , the virtual processor  becomes available to execute another realized task  or unrealized task . Scheduler  searches for a runnable execution context , a realized task , or an unrealized task  to attach to the available virtual processor  for execution in any suitable way. For example, scheduler  may first search for a runnable execution context  to execute before searching for a realized task  or an unrealized task  to execute. Scheduler  continues attaching execution contexts  to available virtual processors  for execution until all execution contexts  of scheduler  have been executed. In other embodiments, runnable execution contexts  and realized tasks  may be merged into single concept from the perspective of schedulers .","Scheduler  includes one or more memory allocators (not shown) that cause memory to be allocated for internal data structures of scheduler  (not shown) and tasks  of execution contexts  executing on virtual processors . The memory allocators request and receive access to pages of memory from OS  and allocate objects or other suitable portions of memory from the pages to tasks  executing on virtual processors . OS  may provide pages in predefined sizes of memory such as page sizes of 4 kilobytes (KB) to 64 KB to the memory allocators.","The memory allocated may include thread or context local storage (TLS or CLS) (not shown). With thread and context local storage, the allocated memory corresponds to an execution context  that is currently being executed by a virtual processor . This memory is saved along with the program state and machine state information of an execution context  when the execution context  blocks or is otherwise interrupted so that the memory can be restored when the corresponding thread or context resumes. The thread or context local storage may be moved to a new virtual processor  along with the execution context  when the execution context  is picked up by the new virtual processor  for execution. As a result, thread and context local storage is only available to tasks  that are executed on an execution context  that corresponds to the thread or context local storage. Thread and context local storage does not persist across execution contexts, and the contents of thread and context local storage are not maintained across execution contexts.","The memory allocated also includes virtual processor local storage for each virtual processor . Each virtual processor local storage persists across all execution contexts  that execute on a corresponding virtual processor . Accordingly, the contents of virtual processor local storages are maintained when execution contexts  complete, block, or are otherwise interrupted on virtual processors . Such contents are not saved with the program state and machine state information of an execution context  when the execution context  blocks or is otherwise interrupted. Subsequent execution contexts  executed by available virtual processors  may access, modify, and\/or overwrite the data in corresponding virtual processor local storages.","Because each virtual processor  may execute only one execution context  at any given time, the execution context  executing on a given virtual processor  may access the virtual processor local storage corresponding to the virtual processor  without synchronization. As a result, each virtual processor  allows different tasks  that execute on different execution contexts  to access the same data in the virtual processor local storage corresponding to the virtual processor  at different times without synchronization (i.e., without using locks or other synchronization techniques on the data). An execution context  on one virtual processor  may also access the virtual processor local storage of another virtual processor  without synchronization for unsynchronized read accesses or without synchronization if the virtual processor local storage is structured to inherently prevent conflicting accesses.","The virtual processor local storage allocated for each virtual processor  in process  includes a current arrived counter  and a current completed counter . Current arrived counter  stores a count of the number of tasks that have arrived in scheduler  via the corresponding virtual processor , and current completed counter  stores a count of the number of tasks that been completed by the corresponding virtual processor . Each time that a task , , or  arrives at a virtual processor , the virtual processor  increments the corresponding current arrived counter . Each time that a task  completes on a virtual processor , the virtual processor  increments the corresponding current completed counter .","Current arrived counters  and current completed counters  are each configured to store an unsigned integer and wrap around to zero after reaching a maximum value (i.e., current arrived counters  and current completed counters  each implement modulo 2 behavior). In one embodiment, current arrived counters  and current completed counters  each include 64 bits. In other embodiments, current arrived counters  and current completed counters  each include other suitable numbers of bits that may minimize the number of time that the counters wrap around during the execution of process .","Each current arrived counter  and each current completed counter  may be written (i.e., incremented) only by the corresponding virtual processor . For example, only virtual processor () may increment current arrived counter () and current completed counter (). Because each virtual processor  may only execute one execution context  and task  at a time, races to write the current arrived counter  and the current completed counter  of a virtual processor  do not occur. Accordingly, each current arrived counter  and each current completed counter  may be accessed by the corresponding virtual processor  without synchronization and while ensuring thread safety.","The virtual processor local storage allocated for each virtual processor  in process  also includes a previous arrived counter  and a previous completed counter . Previous arrived counters  store the previous counts of the corresponding current arrived counters  read by scheduler  in gathering statistics, and previous completed counters  stores the previous counts of the corresponding current completed counter  read by scheduler  in gathering statistics. Previous arrived counters  and previous completed counters  may be the same size as the corresponding current arrived counters  and current completed counters , respectively (e.g, 64 bits). Scheduler  reads the values of previous arrived counter  and previous completed counter  and uses the values in calculating statistics as described below.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 2","FIG. 2"],"b":["22","22","18"]},"Referring to , any time that a scheduler  receives a request for statistics as indicated in a block , scheduler  sums the current arrived counts  and current completed counts  from each virtual processor  in the scheduler  as indicated in a block . In response to requests for statistics from resource manager , scheduler  reads the values of the current arrived counters  and the current completed counters  for all virtual processors ()-(N) in scheduler . Scheduler  sums the current arrived counters ()-(N) in current tasks arrived  as shown in Equation I and sums the current completed counters ()-(N) in current tasks completed  as shown in Equation II.",{"@attributes":{"id":"p-0042","num":"0041"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"CurrentTasksArrived","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["CurrentArrivedCount","i"]}}}},{"mrow":{"mi":["Equation","I"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}}}}]},{"mtd":[{"mrow":{"mi":"CurrentTasksCompleted","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["CurrentCompletedCount","i"]}}}},{"mrow":{"mi":["Equation","II"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}}}}]}]}}}},"Rather than resetting current arrived counters  and current completed counters  after the reads, scheduler  leaves current arrived counters  and current completed counters  unchanged. By doing so, scheduler  may safely collect the data in current arrived counters  and current completed counters  without causing a synchronization point or a race condition.","Scheduler  may also reads the values of the previous arrived counters  and the previous completed counters  for all virtual processors ()-(N) in scheduler . Scheduler  sums the previous arrived counters ()-(N) in previous tasks arrived  as shown in Equation III and sums the previous completed counters ()-(N) in previous tasks completed  as shown in Equation IV.",{"@attributes":{"id":"p-0045","num":"0044"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"PreviousTasksArrived","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["PreviousArrivedCount","i"]}}}},{"mrow":{"mi":["Equation","III"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}}}}]},{"mtd":[{"mrow":{"mi":"PreviousTasksCompleted","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["PreviousCompletedCount","i"]}}}},{"mrow":{"mi":["Equation","IV"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}}}}]}]}}}},"After summing the current arrived counters , the current completed counters , the previous arrived counters , the previous completed counters , scheduler  calculates any desired statistical information from the current tasks arrived count , the current tasks completed count , a previous tasks arrived count , and a previous tasks completed count . The statistics calculated by scheduler  may include an arrival rate of tasks calculated as shown in Equation V using current tasks arrived  and previous tasks arrived  and a completion rate of tasks calculated as shown in Equation VI using current tasks completed  and previous tasks completed . The arrival rate indicates an approximate number of tasks , , , and  that have arrived in scheduler  since the last time scheduler  gathered statistics, and the completion rate indicates an approximate number of tasks , , , and  that have been completed in scheduler  since the last time scheduler  gathered statistics.",{"@attributes":{"id":"p-0047","num":"0046"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"ArrivalRate","mo":"=","mfrac":{"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"CurrentTasksArrived","mo":"-"}}},{"mtd":{"mi":"previousTasksArrived"}}]},"mrow":{"mi":["\u0394","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},{"mrow":{"mi":["Equation","V"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}}}}]},{"mtd":[{"mrow":{"mi":"CompletionRate","mo":"=","mfrac":{"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"CurrentTasksCompleted","mo":"-"}}},{"mtd":{"mi":"previousTasksCompleted"}}]},"mrow":{"mi":["\u0394","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},{"mrow":{"mi":["Equation","VI"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}}}}]}]}}}},"The statistics calculated by scheduler  may also include a length of queue of scheduler  calculated as shown in Equations VII and VIII using current arrived counters  and current completed counters  (Equation VII) or current tasks arrived  and current tasks completed  (Equation VIII). The length of queue of scheduler  indicates an approximate total number of tasks , , , and  in scheduler  at the time scheduler  reads the current arrived counters  and the current completed counters .",{"@attributes":{"id":"p-0049","num":"0048"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"LengthofQueue","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":["CurrentArrivedCount","i"]},"mo":"-"}}},{"mtd":{"msub":{"mi":["CurrentCompletedCount","i"]}}}]}}}}},{"mrow":{"mi":["Equation","VII"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}}}}]},{"mtd":[{"mrow":{"mi":"LengthofQueue","mo":"=","mrow":{"mi":["CurrentTasksArrived","CurrentTasksCompleted"],"mo":"-"}}},{"mrow":{"mi":["Equation","VIII"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}}}}]}]}}}},"The statistics calculated by scheduler  may further include a rate of queue change as shown in Equation IX using the current length of the queue (Equation VIII) and a previous length of queue calculated by substituting previous tasks arrived  and previous tasks completed  for current tasks arrived  and current tasks completed , respectively, in Equation VIII. The rate of queue change indicates a positive or negative approximate rate of change in the size of the queue (i.e., the number of tasks , , , and ) in scheduler  since the last time scheduler  gathered statistics.",{"@attributes":{"id":"p-0051","num":"0050"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"RateofQueueChange","mo":"=","mfrac":{"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"CurrentLengthofQueue","mo":"-"}}},{"mtd":{"mi":"previousLengthofQueue"}}]},"mrow":{"mi":["\u0394","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},{"mrow":{"mi":["Equation","IX"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}}}}]}}}}},"Scheduler  provides statistics based on the summed current arrived counts  and current completed counts  as indicated in a block . Scheduler  also stores the current arrived counts  as the previous arrived counts  and the current completed counts  as the previous completed counts  as indicated in a block  and waits for the next request to gather statistics from resource manager .","Because the above embodiments do not use synchronization, the counts read by scheduler  at each polling point may not be exactly accurate because of inconsistent memory or processor buffers in the computer system. Any inaccuracies, however, may even out after several polls by resource manager , and any possible spikes and\/or inaccurate results (i.e., statistical anomalies) may be discarded by resource manager .","In addition, because counters , , , , , and  have maximum values, an order of magnitude error in calculating the statistics may occur when one or more of counters , , , , , and  exceed the maximum values (i.e., wrap around). In one embodiment, the size of counters , , , , , and  may be selected to minimize the likely number of wrap arounds that may occur in the execution of process . In addition, resource manager  may configured to request statistics on a frequent basis maintain a likelihood that the statistics provided by scheduler  fall within an expected range. For example, the size of counters , , , , , and  may each be 64 bits and the resource manager  may request statistics from a scheduler  every 100 ms to likely eliminate the possibility that the counters , , , , , and  would exceed a maximum value between requests for statistics. In other embodiments, scheduler  and\/or resource manager  may be configured to detect and compensate for wrap arounds of , , , , , and  in other suitable ways.","The embodiment of the method of  may be performed at any suitable frequency for each of a set of schedulers ()-(P) in process  as shown in  where P is an integer greater than or equal to one.  is a block diagram illustrating an embodiment of resource manager  polling schedulers ()-(P) as indicated by arrows ()-(P). Resource manager  may poll each scheduler ()-(P) at any suitable frequency. Schedulers ()-(P), in turn, access corresponding current arrived and current completed counts  and  and previous arrived and previous completed counts  and  as indicated by sets of arrows ()-(P) to gather the data to calculate the statistics. For example, scheduler () sums current arrived counts ()()-()(N) in current arrived tasks (), current completed counts ()()-()(N) in current completed tasks (), previous arrived counts ()()-()(N) in previous arrived tasks (), previous completed counts ()()-()(N) in previous completed tasks (), in response to a request from resource manager . Scheduler () then calculates statistics from current arrived tasks (), current completed tasks (), previous arrived tasks (), and previous completed tasks () and provides the statistics to resource manager . Resource manager  may use the statistics from schedulers ()-(P) to drive dynamic feedback algorithms to determine whether to allocate more or less processing resources to schedulers ()-(P).","In the above embodiments, one or more virtual processors  may be removed from scheduler  during the operation of scheduler . A scheduler  may end an oversubscription of virtual processors  or resource manager  may reallocate one or more virtual processors  to another scheduler instance . Each time that a virtual processor  is removed from a scheduler , the counts - are added in an interlocked (i.e., synchronized) manner to an aggregate store in the scheduler  (not shown) and included in a subsequent gathering of statistics by scheduler .","Although one instance of scheduler  was shown in the embodiment of , other embodiments may include other instances of scheduler  where each instance includes current arrived and current completed counters  and  and previous arrived and previous completed counters  and  for each virtual processor  and responds to requests for statistics from resource manager  as described above.","In some embodiments, scheduler  may allow external execution contexts from process  to be inducted into scheduler  to execute tasks of the scheduler . In these embodiments, each external execution context stores current arrived and current completed counts and previous arrived and previous completed counts in thread local storage (not shown) similar to the way each virtual processor  stored the counts in virtual processor local storage as described above. For each request for statistics, scheduler  reads the current arrived and current completed counts and the previous arrived and previous completed counts from the thread local storage of each external count and includes these counts into the generated statistics.","External execution contexts may exit the scheduler  at any time. When external execution contexts exit the scheduler , the exiting external execution contexts store corresponding indicators with the corresponding counts in the thread local storages. Each indicator indicates that a corresponding external execution context has exited the scheduler . On each request for statistics, scheduler  detects any indicators that indicate that an external execution context has exited the scheduler  and deletes the counts of all external execution contexts that exited the scheduler  after reading the counts and including the counts in the generated statistics.","Any set or subset of schedulers  in process  may be configured into one or more scheduler bundle  in resource manager  as shown in the embodiments of . Resource manager  may poll schedulers  in a scheduler bundle  as described above with reference to the embodiments of  and provide the statistics or other information based on the statistics to the scheduler bundle . Scheduler bundles  may use the statistics or other information to make resource allocation decisions for the schedulers  in the scheduler bundle .",{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIGS. 4A-4B","b":["82","84","1","84","86","1","86","10","86","84","34","32","22","1","22","82"]},"In the embodiment of , runtime environment  includes a scheduler bundle function that generates scheduler bundle  with virtual processor roots  and thread proxies  in addition to the scheduler function that generates schedulers  for inclusion in scheduler bundle . In one embodiment, the scheduler bundle function is implemented as an application programming interface (API). In other embodiments, the scheduler bundle function may be implemented using other suitable programming constructs. When invoked, the scheduler bundle function creates scheduler bundle  to manage one or more schedulers  in scheduler bundle . The scheduler bundle function also creates a set of virtual processor roots ()-(R), where each virtual processor root  manages a corresponding set of virtual processors  across the schedulers  in scheduler bundle . The scheduler bundle function further creates a set of thread proxies ()-(R), where each thread proxy  executes a corresponding set of scheduler execution contexts across the schedulers  in scheduler bundle  on a corresponding virtual processor root . The scheduler function creates a scheduler  in scheduler bundle , where each scheduler  operates to schedule execution contexts of process  for execution on virtual processors  of the scheduler . The execution contexts execute on thread proxies  which in turn execute on execution contexts on hardware threads .","Resource manager  also includes the scheduler bundle function in one embodiment and thus, creates and manages scheduler bundle , virtual processor roots , and thread proxies . Resource manager  causes thread proxies  on corresponding virtual processor roots  to be executed on underlying execution contexts obtained from the OS on hardware threads .","Process  implicitly or explicitly causes scheduler bundle , virtual processor roots ()-(R), thread proxies ()-(R), and schedulers ()-(Q) to be created via the corresponding functions provided by runtime environment  and\/or resource manager . Scheduler bundle , virtual processor roots , thread proxies , and schedulers  may be implicitly created when process  uses APIs available in the computer system or programming language features. In response to the API or programming language features, runtime environment  creates scheduler bundle , virtual processor roots , thread proxies , and schedulers  that inherit the policies of scheduler bundle . To explicitly create scheduler bundle , virtual processor roots , thread proxies , and schedulers , process  may invoke the scheduler bundle and scheduler functions provided by runtime environment  and specify one or more policies for scheduler bundle , virtual processor roots , thread proxies , and schedulers .","Scheduler bundle  manages virtual processor roots  and corresponding thread proxies  to share virtual processor roots  and thread proxies  among all schedulers ()-(Q) in scheduler bundle . Scheduler bundle  may share virtual processor roots  and thread proxies  among schedulers ()-(Q) cooperatively, preemptively, or with another suitable type of time slicing. As part of creating scheduler bundle , resource manager  allocates virtual processor roots  and thread proxies  to scheduler bundle  based on supply and demand and any policies of scheduler bundle . In one embodiment, scheduler bundle  creates each scheduler ()-(Q). In other embodiments, one or more of scheduler ()-(Q) that are external to scheduler bundle  may invoke a programming API or other suitable programming construct to attach to scheduler bundle .","In one embodiment, process  adds each scheduler ()-(Q) to scheduler bundle  with the same set of scheduler policies. In another embodiment, process  adds each scheduler ()-(Q) to scheduler bundle  with a different set of scheduler policies. Each scheduler  receives virtual processors ()-(R) where each virtual processor  forms an abstraction of underlying virtual processor roots  and hardware threads . Each scheduler  also receives information that maps virtual processors ()-(R) of a scheduler  to corresponding virtual processor roots ()-(R). As shown in , virtual processors ()()-(Q)() from respective schedulers ()-(Q) map to virtual processor root (), virtual processors ()()-(Q)() from respective schedulers ()-(Q) map to virtual processor root (), and so on.","Scheduler bundle  allows virtual processor roots  and thread proxies  to be shared among execution contexts  of schedulers ()-(Q) cooperatively, preemptively, or with another suitable time slicing. Each virtual processor root  forms an abstraction of a hardware thread  and executes a corresponding thread proxy . Each thread proxy  forms an abstraction of an execution context and executes the execution context on a corresponding virtual processor root . Resource manager  multiplexes virtual processor roots  onto hardware threads  by mapping each virtual processor root  to a hardware thread . Resource manager  may map more than one virtual processor root  onto a particular hardware thread  but maps only one hardware thread  to each virtual processor root . In other embodiments, resource manager  manages processing resources in other suitable ways to cause thread proxies  to be executed by hardware threads .","Scheduler bundle  schedules the execution contexts  on thread proxies  and schedules thread proxies  on virtual processor roots  which execute on execution contexts associated with hardware threads . Each thread proxy  switches between execution of execution contexts  on virtual processors  on the corresponding virtual processor root . Each thread proxy  causes a single execution context  to be executed at any given time but periodically performs context switches between execution of execution contexts  to execute each of the set of execution contexts  on virtual processors  that correspond to the virtual processor root  of the thread proxy . Each thread proxy  provides a quantum of execution upon dispatching an execution context  of a scheduler . The quantum of execution may be expressed in time (e.g., 50 ms), by a number of tasks to be executed, or by any other suitable metric. The quantum of execution may be the same or different for each dispatched execution context .","As shown in , thread proxy () switches between execution of execution contexts ()()-(Q)() from respective schedulers ()-(Q), thread proxy () switches between execution of execution contexts ()()-(Q)() from respective schedulers ()-(Q), and so on. As shown by an arrow , for example, thread proxy () dispatches execution context ()() for a quantum of execution on virtual processor root () and, once execution context ()() detects that quantum has expired and yields back to thread proxy (), thread proxy () dispatches execution context ()() for a quantum of execution on virtual processor root (). Thread proxy () continues the process of dispatching a next one of the set of execution contexts ()()-(Q)() each time a current one of the set of execution context ()()-(Q)() yields back to thread proxy (). Referring back to , scheduler  executes execution contexts  on virtual processors  which are, in turn, executed by thread proxies  on virtual processor roots .","As noted above, resource manager  may poll schedulers  in scheduler bundle  as described above with reference to the embodiments of  and provide the statistics or other information based on the statistics to the scheduler bundle . Scheduler bundle  may use the statistics or other information to determine whether or not a given scheduler  should be serviced by a thread proxy . Scheduler bundle  may avoid servicing schedulers  with no tasks to execute.","The above embodiments may allow data to be gathered from process  while minimizing the effects of the data gathering on process . The gathering of statistics without synchronization and with thread safety minimizes the impact on scheduling tasks for execution in each scheduler  while providing statistical information to resource manager  that allows resource manager  to make informed decisions regarding resource allocation.","In the above embodiments, scheduler  may operate as a cooperative scheduler where process  and other processes are associated with virtual processors  in a controlled way. In other embodiments, scheduler  may operate as another type of scheduler such as a preemptive scheduler.","In one embodiment, process  (shown in ) organizes tasks into one or more schedule groups  (shown in ) and presents schedule groups  to scheduler  as shown in . In other embodiments, process  organizes tasks into collections for each virtual processor  of scheduler  in other suitable ways.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 5","b":["90","22","90","92","93","94","96","92","38","22","38","92","93","39","38","22","93","22","12","94","96","98","34","96","96","42","34","38"]},"Using the embodiment of , scheduler  may first search for unblocked execution contexts  in the runnables collection  of each schedule group  in scheduler . Scheduler  may then search for realized tasks in the realized task collection  of all schedule groups  before searching for unrealized tasks in the workstealing queues  of the schedule groups .","In one embodiment, a virtual processor  that becomes available may attempt to locate a runnable execution context  in the runnables collection  or a realized task  in the realized task collection  in the schedule group  from which the available virtual processor  most recently obtained a runnable execution context  (i.e., the current schedule group ). The available virtual processor  may then attempt to locate a runnable execution context  in the runnables collections  or a realized task  in the realized task collection  in the remaining schedule groups  of scheduler  in a round-robin or other suitable order. If no runnable execution context  is found, then the available virtual processor  may then attempt to locate an unrealized task  in the workstealing queues  of the current schedule group  before searching the workstealing queues  in the remaining schedule groups  in a round-robin or other suitable order.","In other embodiments, schedule groups  contain other suitable numbers, types, and\/or configurations of task collections.",{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 6","b":["100","10","22","12","22"]},"Computer system  includes one or more processor packages , memory system  (also shown in ), zero or more input\/output devices , zero or more display devices , zero or more peripheral devices , and zero or more network devices . Processor packages , memory system , input\/output devices , display devices , peripheral devices , and network devices  communicate using a set of interconnections  that includes any suitable type, number, and configuration of controllers, buses, interfaces, and\/or other wired or wireless connections.","Computer system  represents any suitable processing device configured for a general purpose or a specific purpose. Examples of computer system  include a server, a personal computer, a laptop computer, a tablet computer, a personal digital assistant (PDA), a mobile telephone, and an audio\/video device. The components of computer system  (i.e., processor packages , memory system , input\/output devices , display devices , peripheral devices , network devices , and interconnections ) may be contained in a common housing (not shown) or in any suitable number of separate housings (not shown).","Processor packages  include hardware threads ()-(M). Each processor package  may include hardware threads  with the same or different architectures and\/or instruction sets. For example, hardware threads  may include any combination of in-order execution cores, superscalar execution cores, and GPGPU execution cores. Each hardware thread  in processor packages  is configured to access and execute instructions stored in memory system . The instructions may include a basic input output system (BIOS) or firmware (not shown), OS  (also shown in ), a runtime platform , applications , and resource manager  (also shown in ). Each hardware thread  may execute the instructions in conjunction with or in response to information received from input\/output devices , display devices , peripheral devices , and\/or network devices .","Memory system  includes any suitable type, number, and configuration of volatile or non-volatile storage devices configured to store instructions and data. The storage devices of memory system  represent computer readable storage media that store computer-executable instructions including OS , resource manager , runtime platform , and applications . Memory system  stores instructions and data received from processor packages , input\/output devices , display devices , peripheral devices , and network devices . Memory system  provides stored instructions and data to processor packages , input\/output devices , display devices , peripheral devices , and network devices . The instructions are executable by computer system  to perform the functions and methods of OS , resource manager , runtime platform , and applications  described herein. Examples of storage devices in memory system  include hard disk drives, random access memory (RAM), read only memory (ROM), flash memory drives and cards, and magnetic and optical disks.","Computer system  boots and executes OS . OS  includes instructions executable by hardware threads  to manage the components of computer system  and provide a set of functions that allow applications  to access and use the components. In one embodiment, OS  is the Windows operating system. In other embodiments, OS  is another operating system suitable for use with computer system .","Resource manager  includes instructions that are executable in conjunction with OS  to allocate resources of computer system  including hardware threads  as described above with reference to . Resource manager  may be included in computer system  as a library of functions available to one or more applications  or as an integrated part of OS , for example.","Runtime platform  includes instructions that are executable in conjunction with OS  and resource manager  to generate runtime environment  and provide runtime functions to applications . These runtime functions include a scheduler function as described in additional detail above with reference to . The runtime functions may be included in computer system  as part of an application , as a library of functions available to one or more applications , or as an integrated part of OS  and\/or resource manager .","Each application  includes instructions that are executable in conjunction with OS , resource manager , and\/or runtime platform  to cause desired operations to be performed by computer system . Each application  represents one or more processes, such as process  as described above, that may execute with one or more schedulers  as provided by runtime platform .","Input\/output devices  include any suitable type, number, and configuration of input\/output devices configured to input instructions or data from a user to computer system  and output instructions or data from computer system  to the user. Examples of input\/output devices  include a keyboard, a mouse, a touchpad, a touchscreen, buttons, dials, knobs, and switches.","Display devices  include any suitable type, number, and configuration of display devices configured to output textual and\/or graphical information to a user of computer system . Examples of display devices  include a monitor, a display screen, and a projector.","Peripheral devices  include any suitable type, number, and configuration of peripheral devices configured to operate with one or more other components in computer system  to perform general or specific processing functions.","Network devices  include any suitable type, number, and configuration of network devices configured to allow computer system  to communicate across one or more networks (not shown). Network devices  may operate according to any suitable networking protocol and\/or configuration to allow information to be transmitted by computer system  to a network or received by computer system  from a network.","Although specific embodiments have been illustrated and described herein, it will be appreciated by those of ordinary skill in the art that a variety of alternate and\/or equivalent implementations may be substituted for the specific embodiments shown and described without departing from the scope of the present invention. This application is intended to cover any adaptations or variations of the specific embodiments discussed herein. Therefore, it is intended that this invention be limited only by the claims and the equivalents thereof."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings are included to provide a further understanding of embodiments and are incorporated in and constitute a part of this specification. The drawings illustrate embodiments and together with the description serve to explain principles of embodiments. Other embodiments and many of the intended advantages of embodiments will be readily appreciated as they become better understood by reference to the following detailed description. The elements of the drawings are not necessarily to scale relative to each other. Like reference numerals designate corresponding similar parts.",{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIGS. 4A-4B"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
