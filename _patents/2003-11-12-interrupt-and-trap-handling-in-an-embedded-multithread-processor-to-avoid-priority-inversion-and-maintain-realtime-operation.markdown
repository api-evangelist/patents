---
title: Interrupt and trap handling in an embedded multi-thread processor to avoid priority inversion and maintain real-time operation
abstract: A real-time, multi-threaded embedded system includes rules for handling traps and interrupts to avoid problems such as priority inversion and re-entrancy. By defining a global interrupt priority value for all active threads and only accepting interrupts having a priority higher than the interrupt priority value, priority inversion can be avoided. Switching to the same thread before any interrupt servicing, and disabling interrupts and thread switching during interrupt servicing can simplify the interrupt handling logic. By storing trap background data for traps and servicing traps only in their originating threads, trap traceability can be preserved. By disabling interrupts and thread switching during trap servicing, unintended trap re-entrancy and servicing disruption can be prevented.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07774585&OS=07774585&RS=07774585
owner: Infineon Technologies AG
number: 07774585
owner_city: Neubiberg
owner_country: DE
publication_date: 20031112
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["1. Field of the Invention","The invention relates to real-time embedded processors, and in particular, to a method and system for handling interrupts and traps in a multi-threaded processor without introducing priority inversion and unwanted re-entrancy.","2. Discussion of Related Art","An embedded system is a system that includes an embedded processor for controlling the behavior of that system. For example, modern automobiles, home appliances, personal electronics, and entertainment systems all typically include at least one embedded processor. These embedded systems are increasingly being required to provide \u201creal-time\u201d operation\u2014i.e., the system must provide accurate and timely responses to external events. One of the keys to real-time performance is that a system respond to interrupt requests within a very short time period (e.g., tens of clock cycles). Therefore, real-time embedded processors typically should not queue interrupt requests and then service them on a scheduled basis.","As real-time embedded systems become ever more complex, the use of multithreaded code in such systems becomes increasingly appealing. Multithreaded code allows a processor to hold the state of several active threads. Each of the active threads can be executed independently, so that when one of the threads becomes blocked (e.g., due to a cache miss) another thread can be executed so that processor cycles are not wasted. This thread switching capability can significantly enhance system responsiveness by making more efficient use of processor capacity. In addition, multithreading allows state information to be efficiently shared among the active threads, and can therefore reduce the size and cost of the resources required for a given system.","Unfortunately, the conventions of real-time embedded systems can conflict with the desired operating characteristics of multithreaded code. For example, as noted above, real-time systems respond to all interrupt requests almost immediately. However, in a multi-threaded system (i.e., a system running multi-threaded code), accepting interrupt requests as soon as such requests are made can result in \u201cpriority inversion.\u201d In a multi-threaded system, the active threads are assigned thread priority values that determine which active thread is actually executed at a particular point in time. Priority inversion occurs when a lower-priority thread prevents a higher-priority thread from executing, which can result in a critical deadline being missed, which in turn can lead to system failure.",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1","b":["0","1","0","1","0","0","1","1","0","0","1","1"]},"At a time t, an interrupt request is generated, at which point an interrupt handler IH associated with thread T begins servicing the requested (low-priority) interrupt INT. Because interrupt handler IH is still servicing interrupt INT when thread T becomes unblocked at a time t, thread T cannot resume execution until the interrupt handler is finished with interrupt INT at a time t. Thus, for the period from time t to time t, threads T and T are in priority inversion, with the execution of high-priority thread T being pre-empted by the low-priority interrupt INT, and therefore low-priority thread T.","Traps (i.e., internally generated responses to internal conditions, such as error conditions) pose a similar problem for multi-threaded systems. Trap routines rely on the traceable nature of a trap to resolve and rectify a problem, and then restart the task that caused the trap. However, multi-threaded systems can encounter difficulties with trap handling due to the fact that traps can be either synchronous or asynchronous. A synchronous trap occurs during or immediately after the instruction that led to the trap condition, whereas an asynchronous trap can occur some time after the causal instruction. Therefore, in a multi-threaded system, by the time an asynchronous trap is generated, a thread switch or multiple thread switches may have already occurred. This can make the thread that originated the trap difficult to identify, which in turn can lead to problems servicing the trap.","Furthermore, because the multiple active threads of a multi-threaded system can all generate trap conditions, a trap condition from one thread can be generated while a trap from another thread is being serviced. For example,  shows an operational diagram for a multi-threaded system that includes two active threads T and T. As in , thread T is assigned a higher priority than thread T, as indicated by the \u201cTHREAD PRIORITY\u201d axis. At a time t, thread T is executing (indicated by the diagonal hatching), while thread T is held pending (indicated by the solid white fill). At a time t, a blocking event for thread T occurs, and the execution of thread T is disabled (indicated by the cross-hatching). Because thread T is blocked, lower-priority thread T begins executing at time t.","At a time t, thread T generates a low priority trap TR. Because thread T is executing at the time trap TR is generated, trap TR is a synchronous trap. Thread T branches to a trap handler TH and begins servicing trap TR at time t. However, before this servicing of trap TR is completed, thread T generates a higher-priority asynchronous trap TR at time t. Because trap TR has a higher priority than trap TR, thread T branches to a trap handler TH and immediately begins servicing trap TR even though trap TR has not been fully serviced. Because both trap handlers TH and TH may use the same shared resources, trap TR is unintentionally re-entrant (indicated by the solid black fill). Therefore, trap TR may be serviced incorrectly due to ill-defined information states resulting from the incomplete operation of trap handler TH. Interrupted trap handler TH may also fail to execute properly due to this unexpected re-entrancy.","Thus, it is desirable to provide a method and system for allowing a real-time embedded system to run multi-threaded code that properly handles interrupts without generating priority inversion conditions, and properly handles traps without causing unintended trap re-entrancy.","Accordingly, a real-time embedded system in accordance with the invention includes threshold interrupt logic and\/or trap-tagging logic for preventing priority inversion, ensuring proper servicing of traps, and preventing unintended trap re-entrancy during multi-threaded operation. Interrupt handling logic in accordance with an embodiment of the invention assigns interrupts individual interrupt priority values, while associating a single interrupt threshold value with all active threads. An interrupt must have an interrupt priority value higher than the current interrupt threshold value to be serviced. Therefore, the conditions for priority inversion are eliminated, as any interrupt being serviced will have a higher priority than any pending thread. By adjusting the interrupt threshold value, the system can increase or decrease the number of interrupts that can be accepted by the system.","According to another embodiment of the invention, an \u201cinterrupt thread\u201d can be designated by the system, and execution would be switched to the interrupt thread prior to servicing any interrupt. By always using the same thread for interrupt handling, the logic for saving and restoring the thread context during interrupt handling can be significantly simplified. According to another embodiment of the invention, interrupts and thread switching can be disabled once an interrupt is accepted to further reduce interrupt handling complexity.","According to another embodiment of the invention, a trap can be handled only in the thread originating the trap. Trap handling logic in accordance with an embodiment of the invention can record trap background data and generate a \u201ctrap pending\u201d indicator in response to an asynchronous trap. Then when the originating thread begins executing, the trap pending indicator instructs the thread to service the trap using the stored trap background data to ensure correct trap handling. According to an embodiment of the invention, each thread can include dedicated \u201ctrap registers\u201d for storing trap background data. According to another embodiment of the invention, the trap handling logic stores trap background data for all detected traps. According to another embodiment of the invention, interrupts and thread switching can be disabled once a trap is taken to prevent problems such as unintended trap re-entrancy. According to another embodiment of the invention, both the interrupt and trap handling logic can use the same disabling logic for disabling interrupts and thread switching during interrupt and trap handling. According to another embodiment of the invention, a multithreaded system including interrupt and trap handling logic can include lookahead logic to ensure thread execution immediately upon completion of interrupt or thread handling routines.","The present invention will be more fully understood in view of the following description and drawings.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 3","FIGS. 1 and 2"],"b":["300","300","310","0","320","310","300","310","310","310"]},"To avoid priority inversion, thread handling logic  processes interrupts using a global interrupt handling methodology in which threshold interrupt logic  specifies an interrupt threshold value ITV that controls interrupt handling across all active threads. More specifically, an interrupt is only accepted by thread execution logic  if a unique interrupt priority value (IPV) assigned to that interrupt is higher than interrupt threshold value ITV. In this manner, interrupt threshold value ITV effectively represents a global interrupt priority value for all active threads T()-T(Z\u22121). Therefore, since any interrupt accepted by thread execution logic  must have a higher interrupt priority value than this global interrupt priority value, any interrupt being serviced will always have a higher interrupt priority than any of the active threads, thereby preventing priority inversion.","According to an embodiment of the invention, an interrupt request I_REQ(M) is received by threshold interrupt logic , which compares the interrupt priority of the requested interrupt (an interrupt INT(M)) to interrupt threshold value ITV. If the interrupt priority is higher than interrupt threshold value ITV, threshold interrupt logic  passes interrupt INT(M) to thread execution logic  for servicing (i.e., thread program counter T(N)_PC replaced with the address of an interrupt handler (interrupt service routine, or ISR) for interrupt INT(M)). Otherwise, interrupt request I_REQ(M) is ignored. According to another embodiment of the invention, interrupt threshold value ITV is passed from threshold interrupt logic  to thread execution logic  (as indicated by the dashed arrow) and is assigned to each of the active threads. Then, all interrupts are passed to thread execution logic , which only accepts those interrupts having an interrupt priority value higher than interrupt threshold value ITV.","In any case, when an interrupt is accepted by thread execution logic , the context of the executing thread is saved to memory and execution branches to the ISR. To simplify context management and the underlying multi-threaded code, according to another embodiment of the invention thread execution logic  includes interrupt thread logic . Interrupt thread logic  forces execution to switch to a predetermined \u201cinterrupt thread\u201d before taking the interrupt (if the interrupt thread is not already executing). Any of active threads T()-T(Z\u22121) can be designated the interrupt thread by thread execution logic . By always taking interrupts in the same interrupt thread, the multi-threaded code implicitly knows which thread context is saved when an interrupt is taken, thereby simplifying the logic required to keep track of the branch and return routines for processing an interrupt.","According to another embodiment of the invention, thread execution logic  includes disabling logic  for disabling interrupts and thread switching once an interrupt has been accepted, and re-enabling interrupts and thread switching after a predetermined interval. The predetermined interval can be specified by thread execution logic  to be any interval that is long enough to allow usage of any shared resources by the ISR to be completed. In this manner, lower priority threads can be prevented from claiming shared resources that the (higher priority) ISR may subsequently need to access.",{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 4A","b":["410","420","425","430"]},"According to an embodiment of the invention, INTERRUPT ENTRY PROCESS  can include an optional (as indicated by the dotted outline) \u201cSWITCH TO INTERRUPT THREAD\u201d step , in which execution is switched to a predetermined interrupt thread, as described above with respect to . According to another embodiment of the invention, INTERRUPT ENTRY PROCESS  can also include an optional \u201cDISABLE INTERRUPTS\/THREAD SWITCHING\u201d step , in which interrupts and thread switching are disabled once the interrupt is accepted. Then, in a \u201cSAVE THREAD CONTEXT\u201d step  the executing thread context is saved, and in a \u201cBRANCH TO ISR\u201d step  execution branches to an interrupt handler address for the interrupt. Note also that according to an embodiment of the invention, step  can perform a full context save, in which all the registers of the executing thread are saved to appropriate context save locations, and according to another embodiment of the invention, step  can perform a partial context save, in which only a first set of the context registers are saved. The ISR then saves and restores the remaining context registers (the \u201csecond set\u201d) during interrupt servicing, which allows the saving and restoring of that second set of context registers to be avoided if those registers are not affected by the ISR, thereby improving overall interrupt processing speed.","The interrupt is then serviced in a \u201cSERVICE INTERRUPT\u201d step , after which an \u201cINTERRUPT EXIT PROCESS\u201d step  is performed to return control from the ISR. A return from exception (RFE) instruction is executed in a \u201cRFE\u201d step , and the thread context previously saved in step  is restored (popped) in a \u201cRESTORE THREAD CONTEXT\u201d step . Note that depending on whether a full or partial context save was performed in step , a corresponding full or partial, respectively, context restore will be performed in step . Then, interrupts and thread switching are enabled in an optional \u201cENABLE INTERRUPTS\/THREAD SWITCHING\u201d step  if they were previously disabled (in optional step ). Note that interrupts and thread switching may already have been enabled at this point, if the potential for resource conflicts has already passed (as described above with respect to ).","Once INTERRUPT EXIT PROCESS  is complete, normal thread execution is resumed in a \u201cRESUME EXECUTION\u201d step . Note if execution was previously switched to an interrupt thread (in optional step ), execution resumes in that interrupt thread, rather than in the thread that had originally been executing when the interrupt request was made. Execution can then switch to the (unblocked) active thread having highest execution priority.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 4B","FIG. 4A","FIG. 4B"],"b":["0","1","0","1","0","1","1","0","0","1","1"]},"For purposes of explanation, let thread T() be designated as the interrupt thread (as described above with respect to step  of ). Then, when an interrupt INT() is requested at a time t (interrupt INT() having an interrupt priority higher than a specified interrupt threshold value), execution switches from thread T() to thread T() as part of INTERRUPT ENTRY PROCESS  described with respect to  (and indicated by the dark line in thread T() at time t). The optional interrupt and thread switch disabling (step ) can be performed, the context of thread T() is saved (step ) and an interrupt handler IH() is called (step ). Interrupt handler IH() then services interrupt INT(), and when this servicing is competed at a time t, the INTERRUPT EXIT PROCESS  is performed (indicated by the dark line in thread T() at time t). A RFE instruction is executed (step ), the thread T() context is restored (step ), and interrupts and thread switching are re-enabled (step ), if necessary.","Since thread T() is no longer blocked at time t (blocking event ended at time t), execution after INTERRUPT EXIT PROCESS  remains in thread T(), since it has a higher execution priority than thread T. Note, however, that the interrupt thread is not required to be the thread having the highest execution priority. For example, if thread T() is assigned a higher priority than thread T(), then upon completion of INTERRUPT EXIT PROCESS , execution would immediately switch from thread T() (the interrupt thread) to thread T() (highest priority unblocked thread).","At a time t, while thread T() is executing, another interrupt INT() is requested (once again, having an interrupt priority higher than the interrupt threshold value. This time, since interrupt thread T() is already executing, the interrupt entry process (indicated by the dark line in thread T() at time t) no thread switch is necessary. The optional interrupt and thread switch disabling is performed (step ), the context of thread T() is saved (step ), and interrupt handler IH() is called (step ) to service interrupt INT() (step ). Upon completion of the service routine, the INTERRUPT EXIT PROCESS  is performed, and execution resumes in thread T() (step ) at a time t.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 5","FIG. 3"],"b":["500","500","510","0","530","500","300","510","510","510"]},"To ensure proper handling of traps, thread execution logic  is configured to service traps only in the thread in which the trap occurred. Therefore, to ensure trap traceability, trap tagging logic  can record the \u201ctrap background data\u201d for a trap\u2014i.e., the information required for proper trap servicing (cause of the trap, the thread and instruction with which the trap is associated, etc.). While this information storage may not be necessary for synchronous traps, which allow for interruption of the instruction stream at the instruction that caused the trap, storing background trap data for asynchronous traps ensures that such traps are properly handled, regardless of the number of instructions or thread switches that take place before the trap is actually serviced. According to an embodiment of the invention, each thread includes a trap register(s), such as trap register TR_REG() in threat T(), in which the trap background data can be stored.","Thus, according to an embodiment of the invention, when trap tagging logic  detects a trap TRP(M) related to a thread T(M), it determines whether or not trap TRP(M) is synchronous or asynchronous. If trap TRP(M) is synchronous, trap tagging logic  simply passes trap TRP(M) to thread execution logic , which services the trap. Note that for a synchronous trap TRP(M), the executing thread would be its originating thread T(M) and the causal instruction would be known, so thread execution logic  would not need to provide any additional information to allow trap TRP(M) to be properly serviced. If trap TRP(M) is asynchronous, trap tagging logic  records the trap background data for trap TRP(M) and generates a \u201ctrap pending\u201d indicator for thread T(M). (Note that according to other embodiments of the invention, trap tagging logic  can automatically record the trap background data for all traps, regardless of whether they are synchronous or asynchronous.) Once thread T(M) resumes execution, the trap pending indicator causes thread execution logic  to service trap TRP(M) using the stored trap background data. In this manner, trap tagging logic  ensures that even asynchronous traps are correctly serviced.","According to another embodiment of the invention, thread execution logic  includes disabling logic  for disabling interrupts and thread switching once a trap has been taken, and re-enabling interrupts and thread switching once the trap has been sufficiently serviced. In doing so, disabling logic  can prevent problems such as unintended trap re-entrancy by ensuring that trap servicing is not disrupted prematurely. Note that according to an embodiment of the invention, disabling logic  can disable interrupts and thread switching for less than the full duration of the trap servicing process, so long as the period of disablement is long enough to prevent any resource usage conflicts. Note further that according to various embodiments of the invention, disabling logic  can also be used to perform the functions of disabling logic  shown in  for interrupt processing.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 6A","b":["610","620","640","641","640","642","643","644"]},"Note that according to an embodiment of the invention, step  can perform a full context save, in which all the registers of the executing thread are saved to appropriate context save locations, and according to another embodiment of the invention, step  can perform a partial context save, in which only a first set of the context registers are saved. The trap handler then saves and restores the remaining context registers (the \u201csecond set\u201d) during trap servicing, which allows the saving and restoring of that second set of context registers to be avoided if those registers are not affected by the trap handler, thereby improving overall trap processing speed.","The trap is then serviced in a \u201cSERVICE TRAP\u201d step , after which a \u201cTRAP EXIT PROCESS\u201d step  is performed. A return from trap instruction is executed in a \u201cRETURN FROM TRAP\u201d step , and the thread context previously saved in step  is restored in a \u201cRESTORE TRAP THREAD CONTEXT\u201d step . Note that depending on whether a full or partial context save was performed in step , a corresponding full or partial, respectively, context restore will be performed in step . Then, interrupts and thread switching are enabled in an optional \u201cENABLE INTERRUPTS\/THREAD SWITCHING\u201d step  if they were previously disabled (in optional step ). Note that interrupts and thread switching may already have been enabled at this point, if the potential for resource conflicts has already passed (as described above with respect to ). Once TRAP EXIT PROCESS  is complete, normal thread execution is resumed in a \u201cRESUME EXECUTION\u201d step .",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 6B","FIG. 6A","FIG. 6B"],"b":["0","1","0","1","0","0","1","1","0","1","1"]},"At time t, thread T() generates a synchronous trap S_TR, so the TRAP ENTRY PROCESS  described with respect to  (and indicated by the dark line in thread T() at time t) is initiated. The optional interrupt and thread switch disabling (step ) can be performed, the context of thread T() is saved (step ) and a trap handler TH() is called (step ). Trap handler TH() then services interrupt trap S_TR, and when this servicing is competed at a time t, the TRAP EXIT PROCESS  is performed (indicated by the dark line in thread T() at time t). A return from trap instruction is executed (step ), the thread T() context is restored (step ), and interrupts and thread switching are re-enabled (step ), if necessary.","As indicated by the dotted line in thread T() at a time t (prior to time t), an asynchronous trap A_TR is generated from thread T() at time t. However, since trap handler TH() is still servicing trap S_TR at time t, the trap background data for asynchronous trap A_TR is recorded (step ) and a trap pending indicator for thread T() is generated and the TRAP ENTRY PROCESS  for trap A_TR begins. Initially, the process remains in a wait state (step ) since even after the servicing of trap S_TR is completed at time t, servicing of trap A_TR cannot begin, since thread T() is still blocked. Once thread T() becomes unblocked at a time t, execution switches from the lower-priority thread T() to higher-priority thread T(). Then, due to the presence of the trap pending indicator generated at time t, servicing of trap A_TR is then performed in a manner substantially similar to that described with respect to trap S_TR.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 7","FIGS. 1 and 2"],"b":["700","700","710","701","720","730","710","700","710"]},"For example, thread program counter T(N)_PC can be provided to a fetch unit , which requests an instruction INST(N) from the program counter T(N)_PC address in an instruction cache . Instruction INST(N) is decoded by a predecode unit  into a decoded instruction D_INST(N), and is then stored in a decoded instruction buffer (DIB) , where it can be read into an execution pipeline  for execution. If a cache miss occurs, instruction cache  sends a MISS signal to fetch unit , which can then instruct thread execution logic  to switch to the next highest priority thread . Meanwhile, instruction cache  sends a MISS_FETCH signal to system memory to read the desired instruction as a signal MISS_RETURN. A busy signal BUSY can be provided while instruction cache  cannot service any additional misses. Note that various other architectures can be used with thread handling logic , as indicated by the dashed lines used for fetch unit , instruction cache , system memory , predecode unit , DIB , and execution pipeline .","To process interrupts, threshold interrupt logic  and thread execution logic  operate in a manner substantially similar to threshold interrupt logic  and thread execution logic , respectively, shown in . An interrupt request I_REQ(S) is only accepted by thread execution logic  if a unique interrupt priority value (IPV) assigned to the requested interrupt INT(S) is higher than interrupt threshold value ITV defined by threshold interrupt logic . Optional interrupt thread logic  in thread execution logic  switches execution to a predetermined interrupt thread prior to the handling of any interrupt, in a manner substantially similar to that described with respect to interrupt thread logic  shown in . Optional disabling logic  can be used to disable interrupts and thread switching for a predetermined portion of the interrupt handling process, in a manner substantially similar to that described with respect to disabling logic  shown in .","To process traps, trap tagging logic  and thread execution logic  operate in a manner substantially similar to trap tagging logic  and thread execution logic , respectively, shown in . When trap tagging logic  detects a trap TRP(R), it saves the trap background data and generates a trap pending indicator as necessary, so that the trap can be serviced when its originating thread executes. Optional disabling logic  can be used to disable interrupts and thread switching for a predetermined portion of the trap handling process, in a manner substantially similar to that described with respect to disabling logic  shown in .","Because a certain number of clock cycles are required before interrupt or trap handling instructions can propagate to DIB , there will typically be a delay between the detection (and completion) of an instruction request or trap condition, and the actual start (or completion) of the execution of the instruction or trap handling instructions. According to an embodiment of the invention, DIB  is a type of first-in-first-out (FIFO) memory that allows any existing instructions in DIB  to be executed when an interrupt or trap is taken by thread execution logic  before the ISR or trap handling instructions are fed into execution pipeline . Similarly, when an instruction or trap handling routine is completed, those instructions prefetched during the RFE or return from trap instruction could simply be discarded since the executing context would still be the ISR or trap handling context. According to another embodiment of the invention, predecode unit  could include a branch lookahead facility to identify an upcoming RFE or return from trap so that the appropriate thread can begin prefetching instructions without delay.","Various embodiments of the invention have been described to ensure proper handling of interrupts and traps in a real-time, multi-threaded embedded system. The various embodiments of the invention that are described above are illustrative only of the principles of this invention and are not intended to limit the scope of the invention to the particular embodiments described. Thus, the invention is limited only by the following claims and their equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 4B","FIG. 4A"]},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 6B","FIG. 6A"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
