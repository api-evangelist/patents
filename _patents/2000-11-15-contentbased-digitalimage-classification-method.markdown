---
title: Content-based digital-image classification method
abstract: A method of classification for a content-based digital-image, including: defining a set of low-level features describing the semantic content of the image, the features being quantities obtainable from the image by means of logico-mathematical expressions that are known beforehand, and the choice of said features depending upon the image classes used for the classification; indexing an image to be classified, with the purpose of extracting therefrom a feature vector, the components of which consist of the values assumed, in the image, by said low-level features; splitting the feature space defined by the low-level features into a plurality of classification regions, to each one of the regions there being associated a respective image class, and each classification region being the locus of the points of the feature space defined by a finite set of conditions laid on at least one component of the feature vector; associating the feature vector to the feature space; identifying, among the classification regions, a specific classification region containing the feature vector extracted from the image to be classified; and identifying the image class associated to the specific classification region identified.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08452088&OS=08452088&RS=08452088
owner: STMicroelectronics S.r.l.
number: 08452088
owner_city: Agrate Brianza
owner_country: IT
publication_date: 20001115
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["The present invention regards a content-based digital-image classification method.","In particular, the present invention finds an advantageous, but not exclusive, application in the classification of images according to the following three classes: photographs, texts, and graphics. Consequently, the ensuing treatment will refer to these classes, without this implying any loss of generality.","The present invention moreover finds advantageous application in the classification of photographs according to the following three classes: outdoor, indoor, and close-ups; in the classification of outdoor photographs, according to the following four classes: landscapes, buildings, actions, and people; in the classification of indoor photographs, according to the following two classes: presence and absence of people; in the classification of close-ups, according to the following two classes: portraits and objects; in the classification of graphics, according to the following three classes: clip art, graphic illustrations (photorealistic graphics), and business graphics (tables and charts); and in the classification of texts, according to the following two classes: black and white, and color.","As is known, Internet and the Web have become the key enablers which have motivated and rendered possible the revolution in the management of all the steps necessary for the use of images in digital format, i.e., the so-called \u201cimaging workflow.\u201d This emerging workflow structure depends upon the effective implementation of three fundamentals steps: image acquisition, the so-called \u201cdigital way-in;\u201d image re-utilization, the so-called \u201cdigital recirculation;\u201d and cross-device image rendering, the so-called \u201cdigital way-out,\u201d i.e., the rendering of the images among heterogeneous devices (monitor, printer, etc.), in particular, the processing of the images for a specific purpose, such as printing or filing.","A content-based digital-image classification has by now become an indispensable need for an accurate description and use of digital images, particularly for the adoption of the most suitable image-processing strategies for satisfying the ever-increasing demand for quality of image, speed of transmission, and ease of use in Internet-based applications, such as improvement of digital images, i.e., the so-called \u201cimage enhancement,\u201d color-processing, and image compression.","At present, one of the methodologies used for content-based digital-image classification is essentially based on an approach of a heuristic type, implemented by means of expert systems. In other words, this methodology basically involves determination of the content of the image by analyzing the digital image in regions of variable size according to directions and pre-set scanning rules using an algorithm of the type \u201cif . . . then . . . else,\u201d i.e., by evaluating the meaning of the region of interest in the light of the characteristics of the preceding or adjacent regions, as well as by the verification of a structured sequence of membership conditions with one or more rules.","Although widely used, the above methodology presents a number of drawbacks. The first drawback is represented by the computational complexity required for analysis of the high number of pixels of an image, along with the other evident drawbacks in terms of time and cost associated thereto. The second drawback is represented by the extremely complex optimization that this methodology may be subject to. The third drawback is represented by the substantial impossibility of optimizing analysis using parallel architectures. The fourth drawback is due to the not extremely high intrinsic \u201crobustness\u201d of the methodology, caused by the unavoidable possibility of not considering, in the above-mentioned \u201cif . . . then . . . else\u201d algorithm, particular cases that may arise in images.","An embodiment of the present invention provides a content-based digital-image classification method free from the drawbacks of the known methods.","According to an embodiment of the present invention, a content-based digital-image classification method is provided that overcomes the limitations of the prior art by providing a classification method that describes the semantic content of an image by defining a set of N low-level features, including quantities obtained from the image by use of predetermined logico-mathematical expressions; indexes the image to be classified to extract therefrom a feature vector formed by the values assumed, in the image, by the N low-level features; and identifies a class of the image by processing the feature vector according to a processing algorithm.","According to one aspect of the invention, the processing of the feature vector according to a processing algorithm includes: defining a feature space as a function of the N low-level features; splitting the feature space into a finite number of classification regions, each of which is associated a respective image class and each of which is the locus of the points of the feature space; associating the extracted feature vector with one of the feature spaces; identifying a specific classification region containing the feature vector; and identifying an image class associated with the classification region, whereby the image class is associated with the specific classification region identified.","According to another aspect of the invention, the defining of a feature space as a function of the N low-level features also includes defining the feature space as a function of a finite set of conditions laid on one or more components of the feature vector.","According to still another aspect of the invention, the splitting of the feature space into a finite number of classification regions also includes utilizing a tree-structured classifier utilizing recursive partitioning of the feature space according to a predetermined partition criterion.","According to another aspect of the invention, the tree-structured classifier includes a binary-tree constructed by: defining a set of training images which include multiple images having different characteristics for each image class; indexing each of the training images to extract a respective feature vector from each; and constructing the binary tree-structured classifier by performing a recursive binary partition procedure as a function of both the feature vectors extracted from the training images and the predetermined partition criterion.","According to another aspect of the invention, the construction method used in constructing the binary tree-structured classifier is substantially defined by: the predetermined partition criterion; a predetermined construction-procedure termination criterion; and a predetermined terminal-node labeling criterion, which is chosen to minimize the likelihood of image misclassification.","According to yet other aspects of the invention, the terminal-node labeling criterion used in constructing the binary tree-structured classifier includes assigning to each node an image misclassification cost relative to the node, which is indicative of the reliability of the classifier conditioned at the node; a label naming the class of images chosen among a set of predefined labels such as to minimize the image misclassification cost relative to the node; a cardinality of each node defining a total number of training images which, during the construction of the classifier, have reached the node; and a probability distribution of the labels in the node. Preferably, a label validation procedure is performed, the procedure including comparing a cardinality associated with each terminal node with a threshold cardinality, and comparing a misclassification cost associated with each terminal node with a threshold misclassification cost.","First of all it should be emphasized that in what follows the term \u201cimages\u201d indicates not only the complete images, but also the subimages obtained by dividing an image up (image splitting).",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1"},"According to what is illustrated in , the present classification method involves the following steps:\n\n","In particular, the choice of the low-level features is an essential factor for a good classification of the image on the basis of its pictorial content. The following criteria of choice have guided the systematic study carried out by the applicant with the purpose of determining the features of the image that are best suited for describing the content of the image in terms of color, contrast, and form (see also the following publications: 1) P. Ciocca and R. Schettini, \u201cA relevance feedback mechanism for content-based image retrieval,\u201d Information Processing and Management 35, pp. 605-632, 1999; and 2) I. Gagliardi and R. Schettini, \u201cA method for the automatic indexing of color images for effective image retrieval,\u201d The New Review of Hypermedia and Multimedia 3, pp. 201-224, 1997, the complete texts of which are incorporated herein by reference):\n\n","The study carried out by the applicant using the criteria of choice referred to above has led to the identification of the low-level features listed hereinafter, which, according to an aspect of the present invention, constitute a library of features, from among which are chosen, according to the classes of image amongst which it is aimed to carry out the classification, the N low-level features used for indexing the image:","a) the color histogram in the 64-colour quantized hue saturation value (HSV) color space;","b) the color coherence vectors (CCVs) in the 64-color quantized HSV color space; the buckets color pixels are defined as coherent or incoherent according to whether they belong or not to similarly colored regions (i.e., regions of one and the same color) having a size greater than a threshold value; for further details see, for example, G. Pass, R. Zabih, and J. Miller, \u201cComparing Images Using Color Coherence Vectors,\u201d ACM Multimedia 96, pp. 65-73, 1996, the complete text of which is incorporated herein by reference;","c) the 11-colour quantized color-transition histogram in the HSV color space (in particular, red, orange, yellow, green, blue, purple, pink, brown, black, gray, and white); for further details, see, for example, I. Gagliardi and R. Schettini, \u201cA method for the automatic indexing of color images for effective image retrieval,\u201d The New Review of Hypermedia and Multimedia 3, pp. 201-224, 1997);","d) the moments of inertia of color distribution in the non-quantized HSV color space; for further details, see, for example, M. A. Snicker and M. Orengo, \u201cSimilarity of Color Images,\u201d Paper presented at the SPIE Storage and Retrieval for Image and Video Data-Bases III Conference, 1995, the complete text of which is incorporated herein by reference;","e) the moments of inertia (mean value, variance, and skewness) and the kurtosis of the luminance of the image;","f) the percentage of non-colored pixels in the image;","g) the number of colors of the image in the 64-color quantized HSV color space;","h) the statistical information on the edges of the image extracted by means of Canny's algorithm; in particular:","h1) the percentage of low, medium and high contrast edge pixels in the image;","h2) the parametric thresholds on the gradient strength corresponding to medium and high-contrast edges;","h3) the number of connected regions identified by closed high-contrast contours; and","h4) the percentage of medium-contrast edge pixels connected to high-contrast edges;","i) the histogram of the directions of the edges extracted by means of the Canny's edge detector (15 bars or gaps, each having an angular width of 12\u00b0, have been used to represent the histogram); for further details, see, for example, above incorporated P. Ciocca and R. Schettini, \u201cA relevance feedback mechanism for content-based image retrieval,\u201d Information Processing and Management 35, pp. 605-632, 1999;","j) the mean value and the variance of the absolute values of the coefficients of the subimages of the first three levels of the multi-resolution Daubechies wavelet transform of the luminance of the image; for further details, see, for example, P. Scheunders, S. Livens, G. Van de Wouwer, P. Vautrot, and D. Van Dyke, \u201cWavelet-based Texture Analysis,\u201d International Journal of Computer Science and Information Management, 1997, the complete text of which is incorporated herein by reference;","k) the estimation of the texture characteristics of the image based on the neighborhood gray-tone difference matrix (NGTDM), in particular coarseness, contrast, busyness, complexity, and strength (a quantity used in image-texture analysis); for further details, see, for example, the following: 1) M. Amadasun and R. King, \u201cTextural features corresponding to textural properties,\u201d IEEE Transaction on System, Man and Cybernetics 19, pp. 1264-1274, 1989; and 2) H. Tamura, S. Mori, and T. Yamawaki, \u201cTextural features corresponding to visual perception,\u201d IEEE Transaction on System, Man and Cybernetics 8, pp. 460-473, 1978, the complete texts of which are incorporated herein by reference);","l) the spatial-chromatic histogram of the color regions identified by means of the 11-colour quantization process in the HSV color space (for further details, see, for example, the above-incorporated publication \u201cA relevance feedback mechanism for content-based image retrieval\u201d), and in particular:","11) the co-ordinates of the centroid of the colors; and","12) the dispersion of the color regions (i.e., pixel regions of the same color) with respect to their centroids;","m) the spatial composition of the color regions identified by means of the 11-colour quantization process (for further details, see the above-incorporated publication \u201cA relevance feedback mechanism for content-based image retrieval\u201d), and in particular:","m1) the fragmentation (the number of color regions);","m2) the distribution of the color regions with respect to the center of the image; and","m3) the distribution of the color regions with respect to the x-axis and with respect to the y-axis.","As may be noted, the total number of features is relatively high (389) but not necessarily constrained given that a number of direction and color histograms are used of intrinsically large size. However, the extremely different nature of the features enables reduction of the risk of classifying in the same class images that are very different from one another.","As mentioned previously, following upon indexing of the image to be classified, the feature vector  is processed according to a processing algorithm with the purpose of identifying the class of the image.","In particular, processing of the feature vector  involves the following steps:\n\n","The classification methodology described with reference to blocks - is in practice implemented by using a binary-tree structured classifier, which is conveniently constructed according to the known Cart methodology; for a detailed treatment of this methodology, the reader is referred to the following texts:\n\n","The Cart methodology has been chosen in that it enables management of any combination of features selected from among the aforementioned list and the coexistence of different relations between the features in different classification regions of the image-characteristics space.","In addition, the Cart methodology provides a clear characterization of the conditions that control the classification, i.e., the conditions that determine when an image belongs to one given class of images rather than to another.","The procedure for construction of the tree-structured classifier basically involves carrying out a recursive binary partition of the feature space according to a predetermined binary partition criterion, from which the above-mentioned conditions that control splitting of the feature space into classification regions are drawn.","In particular, with reference to , the construction of the binary tree-structured classifier involves the following steps:\n\n","In the terminology proper to the processes of construction of the trees, the feature space defined by the N low-level features is the route node, whilst the various classification regions are the terminal nodes, or leaves, of the tree, each of which is labeled with a corresponding image class.","Classification of an image is in practice performed by supplying at input to the binary tree-structured classifier the feature vector  of an image, then traversing the classifier until a terminal node is reached and associating to the image undergoing classification the image class made up of the label attached to the terminal node in which the feature vector  has finished.","The procedure for construction of a binary tree-structured classifier is substantially defined by three rules:\n\n","In particular:\n\n","In detail, the terminal-node labeling criterion involves assigning to each node of the tree-structured classifier, whether this be a terminal node or an intermediate node, the following properties:\n\n",{"@attributes":{"id":"p-0060","num":"0080"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"Size","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"-","mn":"1"},"mi":"J"},"mo":"\u2062","msub":{"mi":["N","j"]}}}}},"br":{},"sub":"j ","ul":{"@attributes":{"id":"ul0016","list-style":"none"},"li":{"@attributes":{"id":"ul0016-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0017","list-style":"none"},"li":"a probability distribution of the labels in the node, i.e., for each image class the ratio between the number of training images which, traversing the classifier, have reached the node, and the cardinality of the node; in mathematical form, the probability distribution of the labels in the node may be expressed as {p(j\\node)}, where:"}}}},{"@attributes":{"id":"p-0061","num":"0082"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["j","\\n","ode"],"mo":["\u2062","\u2062"]}}},"mo":"=","mfrac":{"msub":{"mi":["N","j"]},"mi":"Size"}},{"mi":"j","mo":"=","mrow":{"mn":"1","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":["\u2026","J"]}}],"mo":","}}},"ul":{"@attributes":{"id":"ul0018","list-style":"none"},"li":{"@attributes":{"id":"ul0018-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0019","list-style":"none"},"li":"an image misclassification cost relative to the node, which is indicative of the reliability of the classifier conditioned at the node; for example, the image misclassification cost relative to the node, designated as MC, may be defined by the following formula, which represents the ratio between the number of misclassified images in the node and the cardinality of the node:"}}}},{"@attributes":{"id":"p-0062","num":"0084"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"MC","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mrow":[{"mi":"j","mo":"=","mn":"1"},{"mi":["j","L"],"mo":"\u2260"}],"mo":","},"mi":"J"},"mo":"\u2062","mrow":{"mrow":[{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["j","odo"],"mo":["\u2062","\u2062"],"mrow":{"mi":["\\","n"],"mo":"\u2062"}}}},{"munderover":{"mo":"\u2211","mrow":{"mrow":[{"mi":"j","mo":"=","mn":"1"},{"mi":["j","L"],"mo":"\u2260"}],"mo":","},"mi":"J"},"mo":"\u2062","mfrac":{"msub":{"mi":["N","j"]},"mi":"Size"}}],"mo":"\u2062"}}}}}},"It is pointed out that the expected image misclassification cost relative to the node coincides with the expected probability of misclassification of the images that have reached the node in the case where the image misclassification costs corresponding to the individual image classes coincide with one another.","It is moreover emphasized that numerous other formulas may be used to define an expected image misclassification cost relative to a node, these formulas being in any case required to provide an indication regarding the classifier reliability conditioned at the node.","In addition, the properties described previously can be assigned indifferently to all the nodes of the tree-structured classifier, or else only to the terminal nodes.","Finally, it is pointed out that the probability distribution of the labels in a node, the cardinality of the node, and the image misclassification cost relative to the node could be determined using a set of training images different from the one used for constructing the tree-structured classifier.","In addition, according to a further aspect of the present invention, once construction of the tree-structured classifier is completed and once the properties listed above have been assigned to its nodes, a procedure for validation of the labeling of the terminal nodes of the classifier is carried out.","In particular, the labeling validation procedure involves considering, one at a time, the terminal nodes of the classifier and, for each one of these, comparing its cardinality with a threshold cardinality, and its misclassification cost with a threshold misclassification cost.","Should the cardinality associated to the node considered be less than the threshold cardinality, or the misclassification cost associated to the node be greater than the threshold misclassification cost, then a rejected-images class is associated to the node considered, and consequently the label assigned to it during construction of the classifier is eliminated, and a \u201crejected images\u201d label is assigned to that node; otherwise, the label assigned to the node during construction of the classifier is confirmed.","In general, in a problem of classification understood as assignment of objects to defined classes, it is convenient to introduce a further class of images called \u201crejected-images class,\u201d to which may be assigned the images that the classifier used classifies with a level of \u201creliability\u201d which is not considered acceptable for the problem in question.","In a problem of image classification in which the image classes are those of photographs, graphics and texts, it is quite foreseeable, for instance, that in the rejected-images class there may finish up photographs of graphics, a few illustrations, and\/or composite images, i.e., images deriving from the combination of images, each one of which belonging to one of the image classes envisaged.","The images that have reached a terminal node to which the \u201crejected images\u201d label is assigned, if necessary, may anyway subsequently be classified so that, in the application considered, the consequence of a possible wrong assignment causes as little harm as possible, or else an ad hoc strategy could be applied to them, such as, for example in the case of composite images, segmentation.","In addition, the tree-structured classification methodology enables definition of the set of the conditions on the values of the low-level features which an image must satisfy for it to be assigned to the rejected-images class, this in practice being defined by the joining of those terminal nodes to which the \u201crejected images\u201d label is assigned.","It is moreover emphasized that, in the terminal node labeling validation procedure, the decision on whether or not to validate the label of the terminal node may also be taken on the basis of just one of the two properties described; i.e., it may be taken by considering just the cardinality of the node, or else just the misclassification cost associated thereto.","As regards the criterion of splitting of the nodes, one of the key problems is how to define the goodness of the split. The most widely used approach is to select the split that causes the data contained in the descendant nodes to be more \u201chomogenous\u201d than the data contained in the parent node. A function that defines a measure of the goodness of the split is the \u201cimpurity of the nodes\u201d function, which in practice measures the \u201cdisorder\u201d of the image classes within the node, and the smaller the impurity of a node, the greater the goodness of the split.","In other words, to carry out splitting of a node, first of all a plurality of possible splits are generated by imposing a finite set of conditions on each component of the feature vector, and, among the various splitting possibilities, the one that maximizes the difference between the impurity of the parent node and the impurity of the descendant nodes is chosen.","Another function that may be used to measure the goodness of a splitting of a node is the reduction in deviance; for a more detailed treatment, the reader is referred to the following texts, the complete texts of which are incorporated herein by reference:\n\n","In general, tree-structured classifiers may be very big and overloaded with data, even though they define poor models of the structure of the problem. One of the significant advantages of the Cart methodology is that \u201cthe explanatory tree\u201d originally obtained may be pruned, and the pruning procedure produces a sequence of subtrees, the performance of each one of these subtrees, in terms of misclassification likelihood, or of expected misclassification costs, being evaluated on the basis of sets of test images not present in the set of training images, or else by means of the so-called \u201ccross validation approach\u201d applied to the set of training images.","The use of the best trees of the sequence of pruned trees as classifiers, instead of the explanatory trees, yields more parsimonious classifiers and reduces the marked dependence of the predictions upon the set of training images.","The present classification method has been subjected by the applicant to a test on a so-called high-level classification problem, in which it was necessary to distinguish photographs from graphics and texts. In this experiment, validation of the labeling of the terminal nodes was not performed, and hence the rejected-images class described above was not taken into consideration.","In particular, the test was carried out using both the set of training images employed for the construction of the classifier and a set of test images which was altogether unrelated to and independent of the set of training images.","In detail, a database of images made up of 4500 images coming from various sources was used. These images consisted of images downloaded from the Web, scanned-in images, and bit-map versions of electronic pages. In particular, the database of images included 2600 photographs, 1300 graphics, and 700 texts.","The various images differed in size (ranging from 120\u00d7120 to 1500\u00d71500 pixels), resolution and depth of tone. The classes of photographs included photographs of indoor and outdoor scenes, landscapes, people and things. The class of graphics included banners, logotypes, maps, sketches, and photo-realistic graphics. The class of texts included, instead, digitized manuscript texts, black-and-white and color texts, and scanned or computer-generated texts with various fonts. The classes of texts and graphics comprised images, such as texts with a highly colored background or only a few words in large characters, and photo-realistic graphics, the classification of which may be particularly difficult.","Initially, a number of explanatory trees were constructed using various training sets made up of about 1600 images (approximately 700 photographs, 600 graphics, and 300 texts) drawn at random from the above-mentioned database. In all the experiments, the images not included in the set of training images were used to form a set of test images. In the experiments conducted using the training sets and the explanatory trees, the percentages of correct classification of the images were as follows: photographs, 95%-97%; graphics, 91%-93%; texts, 94%-97%. Instead, in the experiments conducted using the set of test images and the explanatory trees, the percentages of correct classification of the images were as follows: photographs, 90%-91%; graphics, 80%-85%; texts, 89%-91%.","These experiments were then repeated using pruned trees obtained by eliminating those features which captured purely local characteristics, such as the histograms of the colors and the directions of the edges, so obtaining a set of 72 low-level features.","In the experiments carried out using the pruned trees, there was a mean increase in probability of correct classification of 4% for the photographs and 3% for the graphics. In particular, using the training set, the percentages of correct classification of the images increased and were the following: photographs, 97%-98%; graphics, 93%-95%; texts, 93%-96%. Instead, in the set of test images, the percentages of correct classification of the images were the following: photographs, 94%-95%; graphics, 84%-87%; texts, 88%-91%.","From an examination of the characteristics of the method of classification provided according to the present invention, the advantages that this makes possible are evident.","In particular, it is emphasized that the surprising results illustrated above may be achieved with a much smaller exploitation of computational resources than that necessary for the implementation of the methods according to the known art, in that the only real computational effort is represented by the construction of the tree-structured classifier, which occurs only once and outside of the flow of execution in the phase of use of the method.","In addition, the present classification method is highly optimizable and modular, lends itself to an implementation through parallel architectural structures, and is extremely \u201crobust\u201d in so far as the use of a tree-structured classifier eliminates entirely the possibility of not taking into consideration particular cases that might arise in images.","Finally, it is clear that numerous variations and modifications may be made to the classification method described and illustrated herein, without thereby departing from the protection scope of the present invention, as defined by the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["For a better understanding of the present invention, a preferred embodiment thereof is now described, simply to provide a non-limiting example, with reference to the attached drawings, in which:",{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 2"}]},"DETDESC":[{},{}]}
