---
title: Distributed processor allocation for launching applications in a massively connected processors complex
abstract: A compute processor allocator architecture for allocating compute processors to run applications in a multiple processor computing apparatus is distributed among a subset of processors within the computing apparatus. Each processor of the subset includes a compute processor allocator. The compute processor allocators can share a common database of information pertinent to compute processor allocation. A communication path permits retrieval of information from the database independently of the compute processor allocators.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07454595&OS=07454595&RS=07454595
owner: Sandia Corporation
number: 07454595
owner_city: Albuquerque
owner_country: US
publication_date: 20050419
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["This application claims the priority under 35 U.S.C. \u00a7119(e)(1) of provisional application Ser. No. 60\/563,334 filed Apr. 19, 2004 and incorporated herein by reference.","This invention was developed under Contract DE-AC04-94AL8500 between Sandia Corporation and the U.S. Department of Energy. The U.S. Government has certain rights in this invention.","This application discloses subject matter that is related to subject matter disclosed in co-pending U.S. Ser. No. 11\/110,206, and U.S. Ser. No. 11\/110,344, now U.S. Pat. No. 7,246,217, both filed concurrently herewith.","The invention relates generally to multiple processor computing and, more particularly, to supercomputing.","A multiple processor computer apparatus, such as a supercomputer, is typically used in a wide variety of applications that require massive amounts of computation. Examples of such applications include shock physics, radiation transport, materials aging and design, computational fluid dynamics, structural dynamics, etc.","Historically, the performance of supercomputers has been measured in a number of ways, including by peak floating-point operations per second, by simple benchmarks such as MPLINPACK, and by complex physical simulations. The best conventional supercomputers have achieved 70-75% of peak performance on the MPLINPACK benchmark. However, for many complex simulation codes, the performance is only 10-20% of peak for a single processor and can be as low as one or two percent when parallel efficiency is considered. The performance, as measured against peak, for complex simulation codes has been declining in recent supercomputing generations. This trend seems to be continuing in the newest supercomputers.","One area of computer hardware design that has contributed significantly to this trend is the machine interconnect structure. Interconnect hardware development has severely lagged behind the pace of increasing processor performance. The shift from tightly coupled Massively Parallel Processor (MPP) designs such as the Intel ASCI Red and Cray T3E designs, to clusters that use I\/O buses for interconnect connections, has resulted in not only a relative reduction in interconnect performance, but also in an absolute reduction. At the same time, processor performance has been increasing rapidly. This combination has resulted in growing performance imbalance in large parallel computer systems. Also, the size of machines in terms of the number of processors has been increasing, putting even more stress on interconnect performance. The result has been poor scalability compared to that achieved on earlier generations of tightly coupled MPPs, and poor overall efficiency of computer systems.","Another factor that is having a negative impact on performance is the poor scalability of the operating system and operating system services such as compute processor allocation, job loading, internal communication, network communication, file management and file I\/O.","Many users will typically utilize a supercomputer to perform a wide variety of applications, including the examples given above. Some of these applications may include classified information that can only be made available to a limited number of users, and must not be made available to all users of the supercomputer. Accordingly, some type of partitioning mechanism is necessary to separate classified applications from unclassified users. Although it is necessary to partition unclassified users from classified applications, it is nevertheless desirable to effectuate this partitioning with a minimum amount of inconvenience to the unclassified users. This challenge of providing classified\/unclassified partitioning, while also minimizing the inconvenience to unclassified users has been a problem in conventional systems.","It is desirable in view of the foregoing to provide for a multiple processor computing apparatus which can avoid the various difficulties described above.","Exemplary embodiments of the invention provide a compute processor allocator architecture for allocating compute processors to run applications in a multiple processor computing apparatus. The compute processor allocator architecture is distributed among a subset of processors within the computing apparatus. Each processor of the subset includes a compute processor allocator. In some embodiments, the compute processor allocators can share a common database of information pertinent to compute processor allocation. In some embodiments, a communication path permits retrieval of information from the database independently of the compute processor allocators.","The following definitions and acronyms are used herein:","Application In the context of this document, an application runs on one or more compute processors and is managed by Launcher. Users create applications and run them on a computing system. The user's purpose for using the computing system is to run applications.","Batch Job A type of job that runs unattended. Users submit batch jobs to a batch system in the form of a job script. The batch system determines when and where (i.e., on which service processor) the job script should be run.","Compute Processor The computing system is typically made up of many thousand compute processors. Applications run on a partition of compute processors that was allocated by the CPA.","Interactive Job A type of job that requires user interaction. Interactive jobs are submitted to the batch system in a similar way to batch jobs, but without a job script. When the batch system launches an interactive job, it opens up a shell on a login processor for the user to interact with. Interactive jobs are useful for tasks such as debugging.","Job A job is a task or set of tasks being performed by or on behalf of a user (e.g. invoke Launcher to launch an application). Jobs are submitted by users to the batch system in the form of a job script. The batch system determines when a job should run based on a scheduling policy and the available resources. The batch system terminates a job when it exceeds its time limit. A job is considered finished when its job script exits.","Job Script A UNIX shell script defining the commands to run for a batch job. Typically, a job script will contain one or more Launcher invocations.","Login Processor The computing system is typically made up of many login processors. Users are placed onto login processors by a load balancing mechanism. Launcher can only be run from login processors.","Partition A partition defines a physical set of compute processors. The batch system allocates a partition for each job it launches. A job can only access the compute processors in its partition. Purely inactive launchers (those not part of a batch job) also run inside of a partition. When an interactive launcher wishes to run its application, it must first create a partition.","PCT One process control thread (PCT) daemon runs on each compute processor. Launcher communicates with PCTs in order to launch and manage its application. The CPA communicates with PCTs in certain error cases.","Showmesh The Showmesh program used by users to display the state of all compute processors in the system.","Launcher Launcher is the program that launches and manages an application running on compute processors. Launcher must request and be granted a set of compute processors from a compute processor allocator before it can run its application.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 1","FIG. 1"],"b":["11","13","13","13","15","17","12","11","13","11","13","11","19","19","11","13"]},{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIG. 2","FIG. 1","FIG. 2","FIG. 1","FIG. 3"],"b":["11","13","11","13"]},{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 3","FIG. 2","FIG. 3","FIG. 2"],"b":["31","33","11","13","33","11","13"]},{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 4","FIG. 4","FIG. 3","FIG. 1"],"b":["33","33","11","11","41","11","41","41","12"]},{"@attributes":{"id":"p-0042","num":"0041"},"figref":["FIG. 5","FIG. 5","FIG. 4","FIG. 5","FIG. 1"],"b":["33","41","13","33","13","42","42","41","13","12","13"]},"For clarity of exposition, some components (such as local memory devices) not necessary for understanding the present invention have been omitted in .","Referring to , some exemplary embodiments include R=4 rows of cabinets, C=31 columns of cabinets, K=3 card cages per cabinet, and B=8 circuit boards per card cage. In such embodiments, a compute processor cabinet which houses only compute processors would house 4\u00d724=96 compute processors, and a service processor cabinet which houses only service processors would house 2\u00d724=48 service processors. In some embodiments, 27 of the 31 columns are populated with compute processor cabinets, and the remaining 4 columns (2 columns on each end of the array) include only service processor cabinets. Such embodiments thus include 4\u00d727\u00d796=10,368 compute processors and 4\u00d74\u00d748=768 service processors. The network mesh  of , in conjunction with the generally rectangular cabinet array of , permits the computing apparatus to be physically scaled upwardly to include more processors as desired.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 6","FIG. 1","FIGS. 4 and 5","FIG. 6","FIG. 3","FIG. 3","FIG. 6"],"b":["12","12","41","41","31","61","62","63","64","61","64","65","68","61","62","63","64","65","66","67","68"]},"For the cabinet array of , with R rows and C columns, each xy plane (or planar grid) of the logical network mesh corresponds to the interconnections of the routers of all boards in the same corresponding board positions in the cabinets. So the xy plane will include 4RC of the routers  of . The routers on each board are connected in series with one another, each router is connected to its corresponding router on the correspondingly positioned board in the next row-adjacent cabinet, and each set of series connected routers of a given board is connected in series with the set of series connected routers of the correspondingly positioned board of each column-adjacent cabinet. This results in 4R series connected routers per column of  (y direction of ), and 4 sets of C interconnected routers per row of  (x direction of ). Adjacent columns in  are indicated at CN\u22121, CN, CN+1, and CN+2, and adjacent rows in  are indicated at RN and RN+1.",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 7","FIG. 3","FIG. 6","FIG. 2","FIG. 7"],"b":["12","71"]},"More particularly, and referring to  as an example, the left-most router  of  would be connected in a torus with each of the other KB\u22121 left-most routers on the other KB\u22121 circuit boards within its cabinet. So each router of each board is interconnected with every other positionally corresponding router of every other board in the cabinet to form a torus. As mentioned above with respect to , each planar grid of the mesh includes 4RC routers, so there are 4RC interconnections in the z direction between each plane of the three-dimensional network mesh, as illustrated in .",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 8","FIG. 2","FIG. 8"]},"Each of the disconnect cabinets includes a switching structure which is designated generally by an X in the cabinet. These switching structures permit the x direction connections in the three-dimensional network grid to be selectively closed and opened in order to provide flexibility for classified\/unclassified partitioning. In the example of , all compute cabinets between the end pairs of service cabinet columns are selectively switchable into communication with one another and with either of the end pairs of service cabinet columns. The service cabinets provide access to the user interfaces and disk storage  and  (see also ).","When all of the switch structures are closed to make all x-direction connections between all cabinets, then all compute cabinets and all service cabinets are available to all users. When the switch structures in the cabinets of Column  are opened and all other switches are closed, users at  on the right-hand side of  can still utilize the right-hand pair of service cabinet columns to access disk storage  at the right-hand side. In this configuration, all of the compute cabinets and the left-hand pair of service cabinet columns are available for classified operations for users at the left-hand side, and are also isolated from unclassified users at the right-hand side. If this configuration is modified by closing the switches at Column  and opening those at Column , then users at the right-hand side would have access to the compute cabinets between Columns  and , but still would not have access to the remainder of the compute cabinets, and vice versa for the users on left-hand side of the arrangement. Thus, various combinations of opening and closing the switches in Columns , ,  and  can provide various numbers of compute cabinets for either classified or unclassified operations, but in any event unclassified users can still access service cabinets and disk storage. In other switch configurations, the unclassified users can access some, or even most of the compute cabinets, depending on the amount of compute cabinets needed for the desired classified operations.","Referring again to  and the corresponding description, there are 4 KB connections between row-adjacent processor cabinets, so the switching structures must each be capable of switching 4 KB communication paths. In the aforementioned example where K=3 and B=8, each of the 16 switch structures illustrated in  must be capable of switchably making and breaking 4\u00d73\u00d78=96 x-direction connections between cabinets.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 9","FIGS. 1-8","FIG. 9","FIG. 9"],"b":["91","91","91"]},{"@attributes":{"id":"p-0054","num":"0053"},"figref":["FIG. 10","FIG. 10","FIG. 10","FIG. 9"],"b":["11","91"]},{"@attributes":{"id":"p-0055","num":"0054"},"figref":["FIG. 11","FIG. 9","FIG. 10"],"b":["13","13","110","13","111","110","111","91","110","111","101","91","13","11","111","101","91","91","110","91","13","11"]},"The aforementioned capability of launching and managing applications from a single job on both compute processors  and service processors  permits the service processors  to render support processing (e.g., graphics processing) relative to the computational information produced by the compute processors  involved in the job. Without the PCT emulator layer , the launchers within a single job can launch and manage applications on either the compute processors  or the service processors , but not on both compute and service processors during the same job. Therefore, without the PCT emulator , any computations produced by the compute processors  would need to be stored on disk storage  (see also ), and the aforementioned support processing performed by the service processors  would have to be performed on the stored computations during another job.",{"@attributes":{"id":"p-0057","num":"0056"},"figref":["FIG. 12","FIG. 12","FIG. 9"],"b":"11"},"The CPAs can be implemented as daemons (e.g. UNIX programs written in C) running on the respective login processors.  diagrammatically illustrates various entities which interface with any given CPA daemon. The CPA daemon can communicate with each of the illustrated entities via suitable application programming interfaces and associated library functions. The use of application programming interfaces for communication among software models is well known in the art. In some embodiments, the batch system  (running on a service processor ) and the launchers are the only clients of the CPA. The launcher clients are illustrated generally at  and  in . As illustrated, some launchers are part of jobs that have been batched by the batch system , and other launchers are interactive launchers which launch applications for activities such as interactive development and debugging operations.","In some embodiments, the CPA daemons run continuously on the respective login processors. The CPA daemon accepts requests from its clients, launchers and the batch system. The CPA daemon waits for client requests in its main dispatch loop. Upon receiving a client request, the CPA processes the request and returns the result to the client. It then returns to waiting. Client requests are processed in FIFO order. The CPA daemon can also respond to event indicators received from the RCA (Resiliency Communication Agent) . As described in more detail below, upon receiving an RCA event, the CPA determines if it must take action, and if so, performs the required action. It can then return to waiting in its main dispatch loop. RCA events are processed in FIFO order.","The batch system  can cooperate with a CPA to create and assign a compute processor partition for each job before it is started. In this sense, a compute processor partition is simply a number of processors required by the batch job (or interactive application). Each launcher that is part of a batch job must allocate compute processors from the partition in which the job is running. An interactive launcher can cooperate with a CPA to create and assign to itself its own compute processor partition, and can then allocate processors from the partition for the application to be launched by the interactive launcher.","In some embodiments, the compute processors are divided into a batch pool and an interactive pool, the batch pool available for batch jobs, and the interactive pool available for the applications launched by interactive launchers. Only the batch system  may create a partition in the batch pool. When the batch system , or an interactive launcher at , requests the CPA to create a partition, the CPA retrieves from the system database  a list of available compute processors. This aspect of the invention is useful because state information for the entire computing apparatus can be stored in the system database . This means that all of the CPA daemons can be stateless. This decreases the processing burden placed on the login processors to run the CPA daemons, and also makes the CPA daemons more modular in nature and more easily selectable to replace one another in the even of CPA failures. The system database , in some embodiments, is implemented by one or more service processors  running the commercially available MySQL server, and accessing disk storage  (see also ).","Once the CPA receives the list of available processors from the system database , the CPA calls a physical processor allocation algorithm  and provides that algorithm with the list of available processors, the partition size requested by the client, and a processor ID list to use when allocating the compute processors. The processor ID list is typically provided by the batch system or interactive launcher program to specifically identify the compute processors desired for its applications.","In some embodiments, the physical processor allocation algorithm  can allocate compute processors according to any suitable conventionally available algorithm. Once the compute processor allocation has been completed at , the CPA communicates with the system database  to update the overall system state such that it reflects the new compute processor allocation, and provides the new compute processor allocation information to the requesting client.","When a batch job exits, the batch system  requests destruction of the partition that the job was running in. An interactive launcher requests destruction of its partition when it exits. Whenever the CPA destroys a partition, it updates the system database appropriately to reflect this destruction.","As indicated above, the system database  stores persistent state information such as what compute processors are available for allocation, how many compute processors are available for allocation, how many compute processors a job is allowed to use, and what launchers are running and which compute processors have been assigned to them. If any part of the CPA architecture crashes, the system database information is used to restore state when the CPA architecture is restarted. This use of database backend has several benefits. First, it provides robust mechanisms for storing state. When system state is to be changed, a conventional atomic database transaction can be used to insure that the state is either completely updated or not at all. This improves upon prior art systems that store persistent state information in a flat file. It is difficult to ensure that a flat file is written consistently when the CPA crashes.","Another advantage is that the database backend provides a straightforward mechanism for storing and efficiently querying structured information, for example using standard SQL statements. Designing database tables is less error prone and more flexible than designing custom data structures for the CPA. Finally, the use of a database enables the compute processor allocator architecture to be distributed. Conventional network databases are designed to multiplex many simultaneous clients (e.g., CPAs). Locking mechanisms and transaction semantics are provided to prevent clients from conflicting with one another and corrupting data.","Furthermore with respect to the system database , a program designated as Showmesh  in  provides users with the capability of accessing the state information stored in the system database . In some embodiments, the Showmesh program illustrated in  runs on a service processor , and uses the conventional SQL2C library to query the system database . By interacting directly with the system database on behalf of interested users, the Showmesh program provides a communication path to the system database that is independent of the CPA daemons. The design of the CPA daemons can thus be simpler than in systems wherein the CPA daemons support user access to the database.","Some embodiments do not require that a CPA daemon run on each login processor. In such embodiments, the CPA daemon is designed such that it can process requests from launchers running on other login processors which do not have CPA daemons. However, by maximally distributing CPA daemons among the login processors, the burden of management duties on any single CPA daemon will be reduced. The distributed design of the CPA structure is more scalable than prior art single daemon approaches. At the same time, distributing the CPA daemons only among the login processors provides advantages in terms of processing power when compared to prior art systems that provide CPA daemons on every compute processor.","In some embodiments, the persistent state information maintained in the system database  of  includes some or all of the information described below.",{"@attributes":{"id":"p-0070","num":"0069"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"63pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"Processor ID","Alloc Mode","Partition ID","Launcher ID"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Integer","batch\/","64-bit\/","64-bit\/"]},{"entry":[{},{},"interactive\/","NONE","NONE"]},{"entry":[{},{},"reserved"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}}},"The Compute Processor Allocation Table contains one row (example row shown above) for every compute processor in a compute system that is available for allocation. The \u2018Alloc Mode\u2019 field specifies how the processor can be allocated. If the \u2018Alloc Mode\u2019 is set to batch, the processor may be allocated to batch jobs. If \u2018Alloc Mode\u2019 is set to interactive, the processor may be allocated to batch jobs and interactive Launchers. If \u2018Alloc Mode\u2019 is set to reserved, the processor may not be assigned in the future. The \u2018Partition ID\u2019 field specifies the partition ID that a process is part of, or is NONE if the processor isn't part of a partition. The \u2018Launcher ID\u2019 field specifies the Launcher ID that the processor has been assigned to, or NONE if the processor isn't assigned to a Launcher.",{"@attributes":{"id":"p-0072","num":"0071"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"49pt","align":"center"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}},{"entry":[{},"Administration","Allocation",{},{}]},{"entry":["Partition ID","Cookie","Cookie","User ID","Batch Job ID"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["unsigned 64-bit","64-bits","64-bit","String","integer\/NONE"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}}}},{"@attributes":{"id":"p-0073","num":"0072"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"105pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"center"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Partition Creation Time","Max In Use","Batch Job Error"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Date and time","Integer","boolean"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"The Partition Table contains one entry (example entry shown above) for each compute processor partition in the system. The compute processors making up a partition can be obtained by inspecting the Compute Processor Allocation Table. The \u2018Partition ID\u2019 filed stores the ID that the CPA assigned to the partition. This ID is guaranteed to be unique within a single boot-shutdown cycle of the computing apparatus. The \u2018Administration Cookie\u2019 field stores a pseudo-random number that a client must match in order to destroy the partition. The \u2018Allocation Cookie\u2019 field stores a pseudo-random number that a client must match in order to allocate processors from a partition. Both cookie fields can only be read and set by the CPA daemon. The \u2018User ID\u2019 specifies the UNIX user name of the partition's owner. The \u2018Batch Job ID\u2019 field specifies the batch job ID that the partition has been assigned to, or NONE if the partition is in use by an Interactive Launcher. The \u2018Partition Creation Time\u2019 field stores the date and time when the partition was created. The \u201cMax In Use\u2019 field stores the maximum number of compute processors simultaneously in use by Launchers running inside of the partition. The \u2018Batch Job Error\u2019 flag is set when a batch job encounters an error with one or more compute processors in the partition. This flag is also set when a Launcher running inside of the partition that is part of a batch job exits abnormally.",{"@attributes":{"id":"p-0075","num":"0074"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"49pt","align":"center"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}},{"entry":["Launcher ID","Launcher Cookie","Partition ID","Login Processor","Process ID","Command","Creation Time"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["unsigned 64-bit","64-bits","unsigned 64-bit","Integer","unsigned","String","date and time"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}}}},"br":{}},"In some embodiments, each launcher registers with the RCA , then cooperates with a CPA to obtain a compute processor allocation, and then launches its application. The RCA, provided on every login processor in some embodiments, monitors a periodic heartbeat signal provided by the launcher. When the launcher's application has completed and the launcher exits, it unregisters with the RCA. If the launcher heartbeat signal ends before the launcher unregisters with the RCA, then the RCA reports this occurrence to the CPA. This indicates that the launcher has exited improperly in some manner. The CPA responds to this indication by invoking an executable on its login node, which executable \u201ccleans up\u201d the compute processors by interrupting and closing any still-running applications that had been launched by the launcher that exited improperly. The operation of the \u201cclean up\u201d executable is designated generally at  in .","Although exemplary embodiments of the invention have been described above in detail, this does not limit the scope of the invention, which can be practiced in a variety of embodiments."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","DETAILED DESCRIPTION"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 6","FIG. 1"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 7","FIG. 1"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 8","FIG. 2"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
