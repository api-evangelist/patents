---
title: Multiple scan line sample filtering
abstract: A system and method for generating pixels for a display device. The system may include a sample buffer for storing a plurality samples in a memory, a sample cache for caching recently accessed samples, and a sample filter unit for filtering one or more samples to generate a pixel. The generated pixels may then be stored in a frame buffer or provided to a display device. The method operates to take advantage of the common samples shared by neighboring pixels in both the x and y directions for reduced sample buffer accesses and improved performance. The method involves reading samples from the memory that correspond to pixels in a plurality of neighboring scan lines, and possibly also to multiple pixels in each of these scan lines. The samples may be stored in a cache memory and then accessed from the cache memory for filtering. The method maximizes use of the common samples shared by neighboring pixels in both the x and y directions.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06914609&OS=06914609&RS=06914609
owner: Sun Microsystems, Inc.
number: 06914609
owner_city: Santa Clara
owner_country: US
publication_date: 20020228
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE EMBODIMENTS"],"p":["1. Field of the Invention","This invention relates generally to the field of computer graphics and, more particularly, to a high performance graphics system which implements super-sampling.","2. Description of the Related Art","A computer system typically relies upon its graphics system for producing visual output on the computer screen or display device. Early graphics systems were only responsible for taking what the processor produced as output and displaying that output on the screen. In essence, they acted as simple translators or interfaces. Modern graphics systems, however, incorporate graphics processors with a great deal of processing power. They now act more like coprocessors rather than simple translators. This change is due to the recent increase in both the complexity and amount of data being sent to the display device. For example, modern computer displays have many more pixels, greater color depth, and are able to display images that are more complex with higher refresh rates than earlier models. Similarly, the images displayed are now more complex and may involve advanced techniques such as anti-aliasing and texture mapping.","As a result, without considerable processing power in the graphics system, the CPU would spend a great deal of time performing graphics calculations. This could rob the computer system of the processing power needed for performing other tasks associated with program execution and thereby dramatically reduce overall system performance. With a powerful graphics system, however, when the CPU is instructed to draw a box on the screen, the CPU is freed from having to compute the position and color of each pixel. Instead, the CPU may send a request to the video card stating: \u201cdraw a box at these coordinates\u201d. The graphics system then draws the box, freeing the processor to perform other tasks.","Generally, a graphics system in a computer (also referred to as a graphics system) is a type of video adapter that contains its own processor to boost performance levels. These processors are specialized for computing graphical transformations, so they tend to achieve better results than the general-purpose CPU used by the computer system. In addition, they free up the computer's CPU to execute other commands while the graphics system is handling graphics computations. The popularity of graphical applications, and especially multimedia applications, has made high performance graphics systems a common feature of computer systems. Most computer manufacturers now bundle a high performance graphics system with their systems.","Since graphics systems typically perform only a limited set of functions, they may be customized and therefore far more efficient at graphics operations than the computer's general-purpose central processor. While early graphics systems were limited to performing two-dimensional (2D) graphics, their functionality has increased to support three-dimensional (3D) wire-frame graphics, 3D solids, and now includes support for three-dimensional (3D) graphics with textures and special effects such as advanced shading, fogging, alpha-blending, and specular highlighting.","While the number of pixels is an important factor in determining graphics system performance, another factor of equal import is the quality of the image. Various methods are used to improve the quality of images, including anti-aliasing, alpha blending, and fogging, among numerous others. While various techniques may be used to improve the appearance of computer graphics images, they also have certain limitations. In particular, they may introduce their own aberrations and are typically limited by the density of pixels displayed on the display device.","As a result, a graphics system is desired which is capable of utilizing increased performance levels to increase not only the number of pixels rendered but also the quality of the image rendered. In addition, a graphics system is desired which is capable of utilizing increases in processing power to improve graphics effects.","Prior art graphics systems have generally fallen short of these goals. Prior art graphics systems use a conventional frame buffer for refreshing pixel\/video data on the display. The frame buffer stores rows and columns of pixels that exactly correspond to respective row and column locations on the display. Prior art graphics system render 2D and\/or 3D images or objects into the frame buffer in pixel form, and then read the pixels from the frame buffer during a screen refresh to refresh the display. Thus, the frame buffer stores the output pixels that are provided to the display. To reduce visual artifacts that may be created by refreshing the screen at the same time as the frame buffer is being updated, most graphics systems' frame buffers are double-buffered.","To obtain images that are more realistic, some prior art graphics systems have gone further by generating more than one sample per pixel. In other words, some graphics systems implement super-sampling whereby the graphics system may generate a larger number of samples than exist display elements or pixels on the display. By calculating more samples than pixels (i.e., super-sampling), a more detailed image is calculated than can be displayed on the display device. For example, a graphics system may calculate 4, 8 or 16 samples for each pixel to be output to the display device. After the samples are calculated, they are then combined or filtered to form the pixels that are stored in the frame buffer and then conveyed to the display device. Using pixels formed in this manner may create a more realistic final image because overly abrupt changes in the image may be smoothed by the filtering process.","As used herein, the term \u201csample\u201d refers to calculated information that indicates the color of the sample and possibly other information, such as depth (z), transparency, etc., of a particular point on an object or image. For example, a sample may comprise the following component values: a red value, a green value, a blue value, a z value, and an alpha value (e.g., representing the transparency of the sample). A sample may also comprise other information, e.g., a z-depth value, a blur value, an intensity value, brighter-than-bright information, and an indicator that the sample consists partially or completely of control information rather than color information (i.e., \u201csample control information\u201d).","When a graphics system implements super-sampling, the graphics system is typically required to read a plurality of samples, i.e., sample data, corresponding to the area or support region of a filter, and then filter the samples within the filter region to generate an output pixel. This typically requires a large number of reads from the sample memory. Therefore, improved methods are desired for more efficiently accessing sample data from the sample memory in order to generate output pixels for a sample buffer, frame buffer and\/or a display device.","One embodiment of the invention comprises a system and method for generating pixels for a display device. The system may include a sample buffer for storing a plurality samples in a memory, a sample cache for caching recently accessed samples, and a sample filter unit for filtering one or more samples to generate a pixel. The generated pixels may then be stored in a frame buffer or provided to a display device. The method operates to take advantage of the common samples shared by neighboring pixels in both the x and y directions for reduced sample buffer accesses and improved performance.","The method may involve reading a first portion of samples from the memory. The first portion of samples may correspond to pixels in a plurality of (at least two) neighboring scan lines. The first portion of samples may be stored in a cache memory and then accessed from the cache memory for filtering.","The sample filter unit may then operate to filter a first subset of the first portion of samples to generate a first pixel in a first scan line. The sample filter unit may also filter a second subset of the first portion of samples to generate a second pixel in a second scan line, wherein the second scan line neighbors the first scan line. The first subset of the first portion of samples may include a plurality of common samples with the second subset of the first portion of samples. Thus the method may operate to reduce the number of accesses required to be made to the sample buffer. Where the sample filter unit is configured to access samples for greater than 2 neighboring scan lines, the sample filter unit may also access the requisite samples from the cache and filter other subsets of the first portion of samples to generate additional pixels in other scan lines.","The sample filter unit may also be operable to generate additional pixels neighboring the first and second pixels in the x direction (in the first and second scan lines) based on the read. In this case, the sample filter unit may access a third subset of the first portion of samples from the cache memory and filter the third subset of samples to generate a third pixel in the first scan line, wherein the third pixel neighbors the first pixel in the first scan line. The sample filter unit may access a fourth subset of the first portion of samples from the cache memory and filter the fourth subset of samples to generate a fourth pixel in the second scan line, wherein the fourth pixel neighbors the second pixel in the second scan line.","The above operation may then be repeated for multiple sets of pixels in the plurality of scan lines, e.g., to generate all pixels in the first and second scan lines. For example, the method may then involve reading a second portion of samples from the memory, wherein the second portion of samples corresponds to pixels in the at least two neighboring scan lines, wherein the second portion of samples neighbors the first portion of samples. The sample filter unit may filter a first subset of the second portion of samples to generate a third pixel in the first scan line, and may filter a second subset of the second portion of samples to generate a fourth pixel in the second scan line. The third pixel may neighbor the first pixel in the first scan line, and the fourth pixel may neighbor the second pixel in the second scan line. The first subset of the second portion of samples may include a plurality of common samples with the first subset of the first portion of samples, and the second subset of the second portion of samples may include a plurality of common samples with the second subset of the first portion of samples.","Thus the sample filter unit may proceed by generating pixels in multiple neighboring scan lines, e.g., generating a pair of pixels in neighboring scan lines in the x direction, one pair at a time. This operates to more efficiently use the sample memory accesses in the generation of pixels.","While the invention is susceptible to various modifications and alternative forms, specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, the intention is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the present invention as defined by the appended claims. Note, the headings are for organizational purposes only and are not meant to be used to limit or interpret the description or claims. Furthermore, note that the word \u201cmay\u201d is used throughout this application in a permissive sense (i.e., having the potential to, being able to), not a mandatory sense (i.e., must).\u201d The term \u201cinclude\u201d, and derivations thereof, mean \u201cincluding, but not limited to\u201d. The term \u201cconnected\u201d means \u201cdirectly or indirectly connected\u201d, and the term \u201ccoupled\u201d means \u201cdirectly or indirectly connected\u201d.","Incorporation by Reference","The following applications are hereby incorporated by reference in their entirety as though fully and completely set forth herein.","U.S. patent application Ser. No. 09\/251,453 titled \u201cGraphics System with Programmable Real-Time Sample Filtering\u201d filed Feb. 17, 1999, whose inventors are Michael F. Deering, David Naegle and Scott Nelson.","U.S. patent application Ser. No. 09\/970,077 titled \u201cProgrammable Sample Filtering For Image Rendering\u201d filed Oct. 3, 2001, whose inventors are Wayne E. Burk, Yan Y. Tang, Michael G. Lavelle, Philip C. Leung, Michael F. Deering and Ranjit S. Oberoi.","U.S. patent application Ser. No. 09\/861,479 titled \u201cSample Cache For Supersample Filtering\u201d filed May 18, 2001, whose inventors are Michael G. Lavelle, Philip C. Leung and Yan Y. Tang","Computer System\u2014",{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 1","b":"80"},"As shown, the computer system  includes a system unit  and a video monitor or display device  coupled to the system unit . The display device  may be any of various types of display monitors or devices (e.g., a CRT, LCD, or gas-plasma display). Various input devices may be connected to the computer system, including a keyboard  and\/or a mouse , or other input device (e.g., a trackball, digitizer, tablet, six-degree of freedom input device, head tracker, eye tracker, data glove, or body sensors). Application software may be executed by the computer system  to display graphical objects on display device .","Computer System Block Diagram\u2014",{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 2","b":["1","80","102","104","104","106","104"]},"Host processor  may include one or more processors of varying types, e.g., microprocessors, multi-processors and CPUs. The system memory  may include any combination of different types of memory subsystems such as random access memories (e.g., static random access memories or \u201cSRAMs,\u201d synchronous dynamic random access memories or \u201cSDRAMs,\u201d and Rambus dynamic random access memories or \u201cRDRAMs,\u201d among others), read-only memories, and mass storage devices. The system bus or host bus  may include one or more communication or host computer buses (for communication between host processors, CPUs, and memory subsystems) as well as specialized subsystem buses.","In , a graphics system  is coupled to the high-speed memory bus . The graphics system  may be coupled to the bus  by, for example, a crossbar switch or other bus connectivity logic. It is assumed that various other peripheral devices, or other buses, may be connected to the high-speed memory bus . It is noted that the graphics system  may be coupled to one or more of the buses in computer system  and\/or may be coupled to various types of buses. In addition, the graphics system  may be coupled to a communication port and thereby directly receive graphics data from an external source, e.g., the Internet or a network. As shown in the figure, one or more display devices  may be connected to the graphics system .","Host CPU  may transfer information to and from the graphics system  according to a programmed input\/output (I\/O) protocol over host bus . Alternately, graphics system  may access system memory  according to a direct memory access (DMA) protocol or through intelligent bus mastering.","A graphics application program conforming to an application programming interface (API) such as OpenGL\u00ae or Java 3D\u2122 may execute on host CPU  and generate commands and graphics data that define geometric primitives such as polygons for output on display device . Host processor  may transfer the graphics data to system memory . Thereafter, the host processor  may operate to transfer the graphics data to the graphics system  over the host bus . In another embodiment, the graphics system  may read in geometry data arrays over the host bus  using DMA access cycles. In yet another embodiment, the graphics system  may be coupled to the system memory  through a direct port, such as the Advanced Graphics Port (AGP) promulgated by Intel Corporation.","The graphics system may receive graphics data from any of various sources, including host CPU  and\/or system memory , other memory, or from an external source such as a network (e.g. the Internet), or from a broadcast medium, e.g., television, or from other sources.","Note while graphics system  is depicted as part of computer system , graphics system  may also be configured as a stand-alone device (e.g., with its own built-in display). Graphics system  may also be configured as a single chip device or as part of a system-on-a-chip or a multi-chip module. Additionally, in some embodiments, certain of the processing operations performed by elements of the illustrated graphics system  may be implemented in software.","Graphics System\u2014",{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 3","b":["112","112","112","14","18","20","22","24","112","26","28","14","18"]},"In some embodiments, one or more of these components may be removed. For example, the texture buffer may not be included in an embodiment that does not provide texture mapping. In other embodiments, all or part of the functionality incorporated in either or both of the media processor or the hardware accelerator may be implemented in software.","In one set of embodiments, media processor  is one integrated circuit and hardware accelerator is another integrated circuit. In other embodiments, media processor  and hardware accelerator  may be incorporated within the same integrated circuit. In some embodiments, portions of media processor  and\/or hardware accelerator  may be included in separate integrated circuits.","As shown, graphics system  may include an interface to a host bus such as host bus  in  to enable graphics system  to communicate with a host system such as computer system . More particularly, host bus  may allow a host processor to send commands to the graphics system . In one embodiment, host bus  may be a bi-directional bus.","Media Processor\u2014",{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 4","b":["14","14","112","80","80","112","14"]},"Transformation refers to the spatial manipulation of objects (or portions of objects) and includes translation, scaling (e.g. stretching or shrinking), rotation, reflection, or combinations thereof. More generally, transformation may include linear mappinga (e.g. matrix multiplications), nonlinear mappings, and combinations thereof.","Lighting refers to calculating the illumination of the objects within the displayed image to determine what color values and\/or brightness values each individual object will have. Depending upon the shading algorithm being used (e.g., constant, Gourand, or Phong), lighting may be evaluated at a number of different spatial locations.","As illustrated, media processor  may be configured to receive graphics data via host interface . A graphics queue  may be included in media processor  to buffer a stream of data received via the accelerated port of host interface . The received graphics data may include one or more graphics primitives. As used herein, the term graphics primitive may include polygons, parametric surfaces, splines, NURBS (non-uniform rational B-splines), sub-divisions surfaces, fractals, volume primitives, voxels (i.e., three-dimensional pixels), and particle systems. In one embodiment, media processor  may also include a geometry data preprocessor  and one or more microprocessor units (MPUs) . MPUs  may be configured to perform vertex transformation, lighting calculations and other programmable functions, and to send the results to hardware accelerator . MPUs  may also have read\/write access to texels (i.e. the smallest addressable unit of a texture map) and pixels in the hardware accelerator . Geometry data preprocessor  may be configured to decompress geometry, to convert and format vertex data, to dispatch vertices and instructions to the MPUs , and to send vertex and attribute tags or register data to hardware accelerator .","As shown, media processor  may have other possible interfaces, including an interface to one or more memories. For example, as shown, media processor  may include direct Rambus interface  to a direct Rambus DRAM (DRDRAM) . A memory such as DRDRAM  may be used for program and\/or data storage for MPUs . DRDRAM  may also be used to store display lists and\/or vertex texture maps.","Media processor  may also include interfaces to other functional components of graphics system . For example, media processor  may have an interface to another specialized processor such as hardware accelerator . In the illustrated embodiment, controller  includes an accelerated port path that allows media processor  to control hardware accelerator . Media processor  may also include a direct interface such as bus interface unit (BIU) . Bus interface unit  provides a path to memory  and a path to hardware accelerator  and video output processor  via controller .","Hardware Accelerator\u2014","One or more hardware accelerators  may be configured to receive graphics instructions and data from media processor  and to perform a number of functions on the received data according to the received instructions. For example, hardware accelerator  may be configured to perform rasterization, 2D and\/or 3D texturing, pixel transfers, imaging, fragment processing, clipping, depth cueing, transparency processing, set-up, and\/or screen space rendering of various graphics primitives occurring within the graphics data.","Clipping refers to the elimination of graphics primitives or portions of graphics primitives that lie outside of a 3D view volume in world space. The 3D view volume may represent that portion of world space that is visible to a virtual observer (or virtual camera) situated in world space. For example, the view volume may be a solid truncated pyramid generated by a 2D view window, a viewpoint located in world space, a front clipping plane and a back clipping plane. The viewpoint may represent the world space location of the virtual observer. In most cases, primitives or portions of primitives that lie outside the 3D view volume are not currently visible and may be eliminated from further processing. Primitives or portions of primitives that lie inside the 3D view volume are candidates for projection onto the 2D view window.","Set-up refers to mapping primitives to a three-dimensional viewport. This involves translating and transforming the objects from their original \u201cworld-coordinate\u201d system to the established viewport's coordinates. This creates the correct perspective for three-dimensional objects displayed on the screen.","Screen-space rendering refers to the calculations performed to generate the data used to form each pixel that will be displayed. For example, hardware accelerator  may calculate \u201csamples.\u201d Samples are points that have color information but no real area. Samples allow hardware accelerator  to \u201csuper-sample,\u201d or calculate more than one sample per pixel. Super-sampling may result in a higher quality image.","Hardware accelerator  may also include several interfaces. For example, in the illustrated embodiment, hardware accelerator  has four interfaces. Hardware accelerator  has an interface  (referred to as the \u201cNorth Interface\u201d) to communicate with media processor . Hardware accelerator  may receive commands and\/or data from media processor  through interface . Additionally, hardware accelerator  may include an interface  to bus . Bus  may connect hardware accelerator  to boot PROM  and\/or video output processor . Boot PROM  may be configured to store system initialization data and\/or control code for frame buffer . Hardware accelerator  may also include an interface to a texture buffer . For example, hardware accelerator  may interface to texture buffer  using an eight-way interleaved texel bus that allows hardware accelerator  to read from and write to texture buffer . Hardware accelerator  may also interface to a frame buffer . For example, hardware accelerator  may be configured to read from and\/or write to frame buffer  using a four-way interleaved pixel bus.","The vertex processor  may be configured to use the vertex tags received from the media processor  to perform ordered assembly of the vertex data from the MPUs . Vertices may be saved in and\/or retrieved from a mesh buffer .","The render pipeline  may be configured to rasterize 2D window system primitives and 3D primitives into fragments. A fragment may contain one or more samples. Each sample may contain a vector of color data and perhaps other data such as alpha and control tags. 2D primitives include objects such as dots, fonts, Bresenham lines and 2D polygons. 3D primitives include objects such as smooth and large dots, smooth and wide DDA (Digital Differential Analyzer) lines and 3D polygons (e.g. 3D triangles).","For example, the render pipeline  may be configured to receive vertices defining a triangle, to identify fragments that intersect the triangle.","The render pipeline  may be configured to handle full-screen size primitives, to calculate plane and edge slopes, and to interpolate data (such as color) down to tile resolution (or fragment resolution) using interpolants or components such as:","r, g, b (i.e., red, green, and blue vertex color);","r, g, b (i.e., red, green, and blue specular color from lit textures);","alpha (i.e. transparency);","z (i.e. depth); and","s, t, r, and w (i.e. texture components).","In embodiments using supersampling, the sample generator  may be configured to generate samples from the fragments output by the render pipeline  and to determine which samples are inside the rasterization edge. Sample positions may be defined by user-loadable tables to enable various types of sample-positioning patterns.","Hardware accelerator  may be configured to write textured fragments from 3D primitives to frame buffer . The render pipeline  may send pixel tiles defining r, s, t and w to the texture address unit . The texture address unit  may determine the set of neighboring texels that are addressed by the fragment(s), as well as the interpolation coefficients for the texture filter, and write texels to the texture buffer . The texture buffer  may be interleaved to obtain as many neighboring texels as possible in each clock. The texture filter  may perform bilinear, trilinear or quadlinear interpolation. The pixel transfer unit  may also scale and bias and\/or lookup texels. The texture environment  may apply texels to samples produced by the sample generator . The texture environment  may also be used to perform geometric transformations on images (e.g., bilinear scale, rotate, flip) as well as to perform other image filtering operations on texture buffer image data (e.g., bicubic scale and convolutions).","In the illustrated embodiment, the pixel transfer MUX  controls the input to the pixel transfer unit . The pixel transfer unit  may selectively unpack pixel data received via north interface , select channels from either the frame buffer  or the texture buffer , or select data received from the texture filter  or sample filter .","The pixel transfer unit  may be used to perform scale, bias, and\/or color matrix operations, color lookup operations, histogram operations, accumulation operations, normalization operations, and\/or min\/max functions. Depending on the source of (and operations performed on) the processed data, the pixel transfer unit  may output the processed data to the texture buffer  (via the texture buffer MUX ), the frame buffer  (via the texture environment unit  and the fragment processor ), or to the host (via north interface ). For example, in one embodiment, when the pixel transfer unit  receives pixel data from the host via the pixel transfer MUX , the pixel transfer unit  may be used to perform a scale and bias or color matrix operation, followed by a color lookup or histogram operation, followed by a min\/max function. The pixel transfer unit  may then output data to either the texture buffer  or the frame buffer .","Fragment processor  may be used to perform standard fragment processing operations such as the OpenGL\u00ae fragment processing operations. For example, the fragment processor  may be configured to perform the following operations: fog, area pattern, scissor, alpha\/color test, ownership test (WID), stencil test, depth test, alpha blends or logic ops (ROP), plane masking, buffer selection, pick hit\/occlusion detection, and\/or auxiliary clipping in order to accelerate overlapping windows.","Texture Buffer ","Texture buffer  may include several SDRAMs. Texture buffer  may be configured to store texture maps, image processing buffers, and accumulation buffers for hardware accelerator . Texture buffer  may have many different capacities (e.g., depending on the type of SDRAM included in texture buffer ). In some embodiments, each pair of SDRAMs may be independently row and column addressable.","Frame Buffer ","Graphics system  may also include a frame buffer . In one embodiment, frame buffer  may include multiple 3D-RAM memory devices (e.g. 3D-RAM64 memory devices) manufactured by Mitsubishi Electric Corporation. Frame buffer  may be configured as a display pixel buffer, an offscreen pixel buffer, and\/or a super-sample buffer. Furthermore, in one embodiment, certain portions of frame buffer  may be used as a display pixel buffer, while other portions may be used as an offscreen pixel buffer and sample buffer. In one embodiment, graphics system  may include a sample buffer for storing samples, and may not include a frame buffer  for storing pixels. Rather, the graphics system  may be operable to access and filter samples and provide resulting pixels to a display with no frame buffer. Thus, in this embodiment the samples are filtered and pixels generated and provided to the display \u201con the fly\u201d with no storage of the pixels.","Video Output Processor\u2014","A video output processor  may also be included within graphics system . Video output processor  may buffer and process pixels output from frame buffer . For example, video output processor  may be configured to read bursts of pixels from frame buffer . Video output processor  may also be configured to perform double buffer selection (dbsel) if the frame buffer  is double-buffered, overlay transparency (using transparency\/overlay unit ), plane group extraction, gamma correction, psuedocolor or color lookup or bypass, and\/or cursor generation. For example, in the illustrated embodiment, the output processor  includes WID (Window ID) lookup tables (WLUTs)  and gamma and color map lookup tables (GLUTs, CLUTs) . In one embodiment, frame buffer  may include multiple 3DRAM64s  that include the transparency overlay  and all or some of the WLUTs . Video output processor  may also be configured to support two video output streams to two displays using the two independent video raster timing generators . For example, one raster (e.g., A) may drive a 1280\u00d71024 CRT while the other (e.g., B) may drive a NTSC or PAL device with encoded television video.","DAC  may operate as the final output stage of graphics system . The DAC  translates the digital pixel data received from GLUT\/CLUTs\/Cursor unit  into analog video signals that are then sent to a display device. In one embodiment, DAC  may be bypassed or omitted completely in order to output digital pixel data in lieu of analog video signals. This may be useful when a display device is based on a digital technology (e.g., an LCD-type display or a digital micro-mirror display).","DAC  may be a red-green-blue digital-to-analog converter configured to provide an analog video output to a display device such as a cathode ray tube (CRT) monitor. In one embodiment, DAC  may be configured to provide a high resolution RGB analog video output at dot rates of 240 MHz. Similarly, encoder  may be configured to supply an encoded video signal to a display. For example, encoder  may provide encoded NTSC or PAL video to an S-Video or composite video television monitor or recording device.","In other embodiments, the video output processor  may output pixel data to other combinations of displays. For example, by outputting pixel data to two DACs  (instead of one DAC  and one encoder ), video output processor  may drive two CRTs. Alternately, by using two encoders , video output processor  may supply appropriate video input to two television monitors. Generally, many different combinations of display devices may be supported by supplying the proper output device and\/or converter for that display device.","Sample-to-Pixel Processing","In one set of embodiments, hardware accelerator  may receive geometric parameters defining primitives such as triangles from media processor , and render the primitives in terms of samples. The samples may be stored in a sample storage area (also referred to as the sample buffer) of frame buffer . The samples may be computed at positions in a two-dimensional sample space (also referred to as rendering space). The sample space may be partitioned into an array of bins (also referred to herein as fragments). The storage of samples in the sample storage area of frame buffer  may be organized according to bins (e.g. bin ) as illustrated in FIG. . Each bin may contain one or more samples. The number of samples per bin may be a programmable parameter.","The samples may then be read from the sample storage area of frame buffer  and filtered by sample filter  to generate pixels. In one embodiment, the pixels may be stored in a pixel storage area of frame buffer . The pixel storage area may be double-buffered. Video output processor  reads the pixels from the pixel storage area of frame buffer  and generates a video stream from the pixels. The video stream may be provided to one or more display devices (e.g. monitors, projectors, head-mounted displays, and so forth) through DAC  and\/or video encoder . In one embodiment, as discussed above, the sample filter  may filter respective samples to generate pixels, and the pixels may be provided as a video stream to the display without any intervening frame buffer storage, i.e., without storage of the pixels.","Super-Sampling Sample Positions\u2014",{"@attributes":{"id":"p-0108","num":"0107"},"figref":"FIG. 8","b":"166"},"The sample filter  may be programmed to generate one pixel position in each bin (e.g. at the center of each bin). For example, if the bins are squares with side length one, the horizontal and vertical step sizes between successive pixel positions may be set equal to one.","Each pixel may be computed on the basis of one or more samples. For example, the pixel located in bin  may simply take the values of samples in the same bin. Alternatively, the pixel located in bin  may be computed on the basis of filtering samples in a support region (or extent) covering multiple bins including bin .",{"@attributes":{"id":"p-0111","num":"0110"},"figref":["FIG. 8","FIG. 8"],"b":["166","172"]},"The pixel at the center of bin  may be computed on the basis of a plurality of samples falling in support region . The radius of the support region may be programmable. As the radius increases, the support region  would cover a greater number of samples, possibly including those from neighboring bins.","The sample filter  may compute each pixel by operating on samples with a filter. Support region  illustrates the support of a filter which is localized at the center of bin . The support of a filter is the set of locations over which the filter (i.e. the filter kernel) is defined. In this example, the support region  is a circular disc. The output pixel values (e.g. red, green, blue) for the pixel at the center of bin  are determined by samples which fall within support region . This filtering operation may advantageously improve the realism of a displayed image by smoothing abrupt edges in the displayed image (i.e., by performing anti-aliasing). The filtering operation may simply average the values of samples within the support region  to form the corresponding output values of pixel . More generally, the filtering operation may generate a weighted sum of the values of samples within the support region , where the contribution of each sample may be weighted according to some function of the sample's position (or distance) with respect to the center of support region .","The filter, and thus support region , may be repositioned for each output pixel being calculated. For example, the filter center may visit the center of each bin. It is noted that the filters for neighboring pixels may have one or more samples in common in both the x and y directions. One embodiment of the present invention comprises a method for accessing samples from a memory in an efficient manner during pixel calculation to reduce the number of memory accesses. More specifically, one embodiment of the present invention comprises a method for accessing samples from a memory for pixels being generated in multiple neighboring or adjacent scan lines.","FIG. \u2014Sample-to-Pixel Processing Flow\u2014Pixel Generation From Samples",{"@attributes":{"id":"p-0115","num":"0114"},"figref":["FIG. 9","FIG. 9"],"b":["112","350","112","352","352","162","166","174","180","184","352","350"]},"In addition to the vertex data, draw process  also receives sample coordinates from a sample position memory . In one embodiment, position memory  is embodied within sample generator & evaluator . Sample position memory  is configured to store position information for samples that are calculated in draw process  and then stored into super-sampled sample buffer A. The super-sampled sample buffer A may be a part of frame buffer  in the embodiment of FIG. . In one embodiment, position memory  may be configured to store entire sample addresses. Alternatively, position memory  may be configured to store only x- and y-offsets for the samples. Storing only the offsets may use less storage space than storing each sample's entire position. The offsets may be relative to bin coordinates or relative to positions on a regular grid. The sample position information stored in sample position memory  may be read by a dedicated sample position calculation unit (not shown) and processed to calculate sample positions for graphics processor .","Sample-to-pixel calculation process (or sample filter)  may use the same sample positions as draw process . Thus, in one embodiment, sample position memory  may generate sample positions for draw process , and may subsequently regenerate the same sample positions for sample-to-pixel calculation process .","As shown in the embodiment of , sample position memory  may be configured to store sample offsets dX and dY generated according to a number of different schemes such as a regular square grid, a regular hexagonal grid, a perturbed regular grid, or a random (stochastic) distribution. Graphics system  may receive an indication from the host application or the graphics API that indicates which type of sample positioning scheme is to be used. Thus the sample position memory  may be configurable or programmable to generate position information according to one or more different schemes.","In one embodiment, sample position memory  may comprise a RAM\/ROM that contains stochastically determined sample points or sample offsets. Thus, the density of samples in the rendering space may not be uniform when observed at small scale. As used herein, the term \u201cbin\u201d refers to a region or area in virtual screen space.","An array of bins may be superimposed over the rendering space, i.e. the 2-D viewport, and the storage of samples in sample buffer A may be organized in terms of bins. Sample buffer A may comprise an array of memory blocks which correspond to the bins. Each memory block may store the sample values (e.g. red, green, blue, z, alpha, etc.) for the samples that fall within the corresponding bin. The approximate location of a sample is given by the bin in which it resides. The memory blocks may have addresses which are easily computable from the corresponding bin locations in virtual screen space, and vice versa. Thus, the use of bins may simplify the storage and access of sample values in sample buffer A.","The bins may tile the 2-D viewport in a regular array, e.g. in a square array, rectangular array, triangular array, hexagonal array, etc., or in an irregular array. Bins may occur in a variety of sizes and shapes. The sizes and shapes may be programmable. The maximum number of samples that may populate a bin is determined by the storage space allocated to the corresponding memory block. This maximum number of samples per bin is referred to herein as the bin sample capacity, or simply, the bin capacity. The bin capacity may take any of a variety of values. The bin capacity value may be programmable. Henceforth, the memory blocks in sample buffer A which correspond to the bins in rendering space will be referred to as memory bins.","The specific position of each sample within a bin may be determined by looking up the sample's offset in the RAM\/ROM table, i.e., the sample's offset with respect to the bin position (e.g. the lower-left corner or center of the bin, etc.). However, depending upon the implementation, not all choices for the bin capacity may have a unique set of offsets stored in the RAM\/ROM table. Offsets for a first bin capacity value may be determined by accessing a subset of the offsets stored for a second larger bin capacity value. In one embodiment, each bin capacity value supports at least four different sample positioning schemes. The use of different sample positioning schemes may reduce final image artifacts that would arise in a scheme of naively repeating sample positions.","In one embodiment, sample position memory  may store pairs of 8-bit numbers, each pair comprising an x-offset and a y-offset. When added to a bin position, each pair defines a particular position in rendering space. To improve read access times, sample position memory  may be constructed in a wide\/parallel manner so as to allow the memory to output more than one sample location per read cycle.","Once the sample positions have been read from sample position memory , draw process  selects the samples that fall within the polygon currently being rendered. This is illustrated in FIG. . Draw process  then may calculate depth (z), color information, and perhaps other sample attributes (which may include alpha and\/or a depth of field parameter) for each of these samples and store the data into sample buffer A. In one embodiment, sample buffer A may only single-buffer z values (and perhaps alpha values) while double-buffering other sample components such as color. Graphics system  may optionally use double-buffering for all samples (although not all components of samples may be double-buffered, i.e., the samples may have some components that are not double-buffered).","The filter process  may operate in parallel with draw process . The filter process  may be configured to:","(a) read sample values from sample buffer A,","(b) read corresponding sample positions from sample position memory ,","(c) filter the sample values based on their positions (or distance) with respect to the pixel center (i.e. the filter center),","(d) output the resulting output pixel values to a frame buffer, or directly onto video channels.","Sample-to-pixel calculation unit or sample filter  implements the filter process. Filter process  may be operable to generate the red, green, and blue values for an output pixel based on a spatial filtering of the corresponding data for a selected plurality of samples, e.g. samples falling in a filter support region around the current pixel center in the rendering space. Other values such as alpha may also be generated.","In one embodiment, filter process  is configured to:","(i) determine the distance of each sample from the pixel center;","(ii) multiply each sample's attribute values (e.g., red, green, blue, alpha) by a filter weight that is a specific programmable) function of the sample's distance (or square distance) from the pixel center;","(iii) generate sums of the weighted attribute values, one sum per attribute (e.g. a sum for red, a sum for green, . . . ), and","(iv) normalize the sums to generate the corresponding pixel attribute values.","In the embodiment just described, the filter kernel is a function of distance from the pixel center. However, in alternative embodiments, the filter kernel may be a more general function of X and Y sample displacements from the pixel center, or a function of some non-Euclidean distance from the pixel center. Also, the support of the filter, i.e. the 2-D neighborhood over which the filter kernel is defined, need not be a circular disk. Rather the filter support region may take various shapes.","As described further below, in one embodiment the filter process  may be configured to read sample values from the sample buffer A corresponding to pixels in multiple neighboring or adjacent scan lines. The filter process  may also read corresponding sample positions from sample position memory  for each of the read samples. The filter process  may filter the sample values based on their positions (or distance) with respect to the pixel center (i.e. the filter center) for pixels in multiple scan lines. Thus, for example, the filter process  may generate pixels in pairs in the x direction, wherein the pixel pairs comprise pixels with the same x coordinates and residing in neighboring scan lines.","Thus, one embodiment of the invention comprises a system and method for generating pixels. The system may include a sample buffer A for storing a plurality samples in a memory, a sample cache  () for caching recently accessed samples, and a sample filter unit  for filtering one or more samples to generate a pixel. The generated pixels may then be stored in a frame buffer or provided to a display device. The method operates to take advantage of the common samples shared by neighboring pixels in both the x and y directions for reduced sample buffer accesses and improved performance.","The method may involve reading a first portion of samples from the memory. The first portion of samples may correspond to pixels in a plurality of (at least two) neighboring scan lines. The first portion of samples may be stored in the cache memory  and then accessed from the cache memory  for filtering.","The sample filter unit  may then access samples from the cache to generate first and second pixels (e.g., two or more pixels) having the same x coordinates, and residing in neighboring or adjacent scan lines. The sample filter unit  may operate to filter a first subset of the first portion of samples to generate a first pixel in a first scan line. The sample filter unit  may also filter a second subset of the first portion of samples to generate a second pixel in a second scan line, wherein the second scan line neighbors the first scan line. The first subset of the first portion of samples may include a plurality of common samples with the second subset of the first portion of samples. Thus the method may operate to reduce the number of accesses required to be made to the sample buffer A. Where the sample filter unit  is configured to access samples for greater than 2 neighboring scan lines, the sample filter unit  may also obtain these samples during the read performed above, access the requisite samples from the cache  and filter other subsets of the first portion of samples to generate additional pixels in other adjacent scan lines.","The sample filter unit  may also be operable to generate additional pixels neighboring the first and second pixels in the x direction (in the first and second scan lines) based on the read. In other words, the sample filter unit  may also be operable to generate additional pixels having different x coordinates than the first and second pixels, wherein the additional pixels neighbor the first and second pixels in the x direction. In this case, the sample filter unit  may access a third subset of the first portion of samples from the cache memory  and filter the third subset of samples to generate a third pixel in the first scan line, wherein the third pixel neighbors the first pixel in the first scan line. The sample filter unit  may access a fourth subset of the first portion of samples from the cache memory  and filter the fourth subset of samples to generate a fourth pixel in the second scan line, wherein the fourth pixel neighbors the second pixel in the second scan line.","The above operation may then be repeated for multiple sets of pixels in the plurality of scan lines, e.g., to generate all pixels in the first and second scan lines. For example, the method may then involve reading a second portion of samples from the sample memory A into the cache , wherein the second portion of samples corresponds to pixels in the at least two neighboring scan lines, and wherein the second portion of samples neighbors the first portion of samples. The sample filter unit  may filter a first subset of the second portion of samples to generate a third pixel in the first scan line, and may filter a second subset of the second portion of samples to generate a fourth pixel in the second scan line. The third pixel may neighbor the first pixel in the first scan line, and the fourth pixel may neighbor the second pixel in the second scan line. In other words, if the first and second pixels have x coordinate A, the third ad fourth pixels have x coordinates A+1. The first subset of the second portion of samples may include a plurality of common samples with the first subset of the first portion of samples, and the second subset of the second portion of samples may include a plurality of common samples with the second subset of the first portion of samples.","The above operation may then be repeated for all of the scan lines in the image being rendered. Thus the sample filter unit  may proceed by generating pixels in multiple neighboring scan lines, e.g., generating a pair of pixels in neighboring scan lines having the same x coordinates, and proceeding in this manner in the x direction, one pair at a time until the end of the multiple neighboring scan lines is reached. The method may then operate again on a next set of multiple scan lines, and so on, until all pixels have been rendered. This operates to more efficiently use the sample memory accesses in the generation of pixels.","The description of  further illustrates one embodiment of the invention.","Sample Filtering","As described above, the graphic system may implement super-sampling. The implementation of super-sampling includes a method for filtering the samples into pixels as described above. In one embodiment, each sample that falls into the filter's area or support region has a weight associated with it. Each sample is multiplied by its corresponding weight and added together. This sum is then divided by the sum of the weights to produce the final pixel color. For example, the following filter equation may be used. \n\n","Exemplary filters that may be used in various embodiments include a square filter, a cone filter, a Gaussian filter, and a sinc filter. As described above, a filter can include several bins in its calculation to determine the color of a single pixel. A bin may be a 1\u00d71 pixel in size and in one embodiment can hold up to 16 samples.","Filter diameters may be as follows:",{"@attributes":{"id":"p-0148","num":"0147"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},{},"Maximum Footprint"]},{"entry":[{},"Filter","Diameter (in bins)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Square","1"]},{"entry":[{},"Cone","2"]},{"entry":[{},"Gaussian","3"]},{"entry":[{},"Sinc","4"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"The filter may be centered on the pixel in question, and all samples which are within the filter's diameter or support region may contribute to the pixel. Each sample may be weighted according to the filter function. In normal super-sampling mode, the filter moves in one bin increments in the x direction over a scan line. However, during zoom-in the filter moves in fractional increments and during zoom-out the filter moves in greater than one decimal increments. The filter may be implemented with a lookup table. The samples may be listed in order of quality. As the quality of the filter increases, the computation cost increases as well.",{"@attributes":{"id":"p-0150","num":"0149"},"figref":"FIGS. 10A-10D"},{"@attributes":{"id":"p-0151","num":"0150"},"figref":"FIGS. 11A-11C"},{"@attributes":{"id":"p-0152","num":"0151"},"figref":"FIGS. 12A-12C"},{"@attributes":{"id":"p-0153","num":"0152"},"figref":"FIGS. 13A-13C"},{"@attributes":{"id":"p-0154","num":"0153"},"figref":["FIG. 14","FIG. 15"]},"In a first embodiment, pixels are filtered first in increasing x coordinates, then in increasing y coordinates. This is shown by the numbers - in , whereby the pixels in the top scan line are generated first (pixels -), followed by the pixels in the next scan line (beginning with pixel ) and so on. All filtered pixels in the same x coordinates form a scan line. For example, as shown in , all pixels represented by dotted circles form a scan line. Thus, this embodiment does not generate pixels in multiple neighboring scan lines for each read, but rather only generates one or more pixels in a single scan line for each read of the sample memory.","In the first embodiment, the filtering process may operate as follows. First, the samples may be read into a cache memory. The method may operate to read tiles into the cache memory to cover all the bins that the filter support region or footprint covers in a ymajor fashion. For example, the method may read a 2\u00d7n strip at a time. Since n can be odd, in one embodiment the method reads half tiles into the cache memory. For the sinc filter, n=5. Thus, for each strip, 2 full tiles and 1 half tile may be read. This read is illustrated in FIG. .","If the x address of the tile is greater than the edge of the filter for a pixel, then all the samples for the pixel have been read into the cache and the pixel may be now filtered. This may occur when:\n\n>filter_center+filter_radius) \n\nHowever, depending on the size of the filter and the zoom factor, all the samples for multiple pixels may have been read into the cache after reading a previous 2\u00d7n strip. For example,  illustrates use of a cone filter which has a radius of 1 and a zoom factor of 2. As shown in , the samples for 4 pixels (all residing in the same scan line in this embodiment) were read into the cache memory after reading a single 2\u00d7n strip.\n","In order to filter samples into a pixel, the filter may require knowledge of the pixel center, the position of each sample, and the type of filter. The distance from the pixel center to a sample is given by a simple distance equation.\n\n=()\n\nThe distance may be used to find the appropriate weight given the type of filter, e.g., using a table lookup. If the sample is outside the filter, then the weight is zero.  is a block diagram of a filtering method that implements the distance equation above and accesses a filter table based on the distance d to generate a weight value.\n","The weight of each sample is multiplied by the color of each sample and the result is accumulated. The result is divided by the sum of the weights, producing the filtered pixel color. The following filter equation may be used. \n\n\nAfter this, the next pixel center may be calculated using the reciprocal of the zoom factor, e.g.:\n\npixel center+=(zoom factor)\n\nMultiple Scan Line Sample Filtering\n","As described above, a large amount of overlap may occur between samples in the footprint or support region of the filter applied to adjacent pixels. One embodiment of the invention recognizes this overlap both for neighboring pixels in the same scan line, and for neighboring pixels in adjacent scan lines. The method described above showed the reuse of samples when pixel filtering is performed in the x direction. However, as shown above, a large amount of overlap between samples in adjacent pixels may also occur in consecutive scan lines.","In one embodiment, a cache memory is used to store samples after they are read from the sample memory A, e.g., frame buffer . This may allow reuse of samples that have been already read for a neighboring filter operation. In addition, as described above, multiple filter commands may be generated or issued after samples for two or more pixels in adjacent scan lines (having the same x coordinates) have been read. This is because an access of samples for multiple pixels in adjacent scan lines may include the requisite samples for one or more neighboring pixels in the x direction. The reuse of samples for pixels in multiple scan lines (and adjacent pixels in the same scan lines) and access of samples from the cache memory that have been previously read are very important. This is because read of sample data from the sample buffer or frame buffer  is typically a bottleneck operation.","One embodiment of the present mention operates to take advantage of this overlap of samples between multiple x scan lines. This embodiment operates to filter multiple scan lines at a time, preferably 2 scan lines at a time. This operates to reduce accesses to both the cache memory and the sample memory.","FIG. \u2014Sample Filter Embodiment",{"@attributes":{"id":"p-0163","num":"0162"},"figref":"FIG. 19","b":["172","172","422","422","422","424","426","428","430","440"],"sup":["2","2 "]},"The sample memory A may be a portion of the frame buffer . The sample memory A may be accessed to obtain sample values for use in generating respective pixels. As mentioned above, in one embodiment of the invention, the method operates to access the sample memory A to retrieve samples corresponding to pixels in a plurality of neighboring scan lines, i.e., two or more scan lines. In other words, the sample memory A may be accessed to retrieve samples corresponding to pixels having the same x coordinates and residing in two or more horizontal rows or scan lines. This may operate to further reduce the amount of accesses to sample memory A. The samples read from the sample memory A may be stored in a cache memory  as shown. The samples may then be accessed from the cache memory  and provided to the filter tree . The filter tree  may multiply the sample values by respective weights from the weight queue  and perform an averaging function to produce the final pixel value.",{"@attributes":{"id":"p-0165","num":"0164"},"figref":["FIG. 20","FIG. 20","FIG. 20"]},{"@attributes":{"id":"p-0166","num":"0165"},"figref":["FIG. 20","FIG. 20"],"b":["1","10","20"]},{"@attributes":{"id":"p-0167","num":"0166"},"figref":"FIG. 21"},"The method which involves multiple scan line processing as described herein may operate as follows. First, the method may read tiles of samples into the cache memory  in order to cover all of the bins that the union of the two filter footprints or support regions cover, in a ymajor fashion. In one embodiment, since the difference in y coordinates between the two centers is a maximum of 1, this results in an additional two pixels being read as compared to the single scan line method described above with respect to . Thus, the method reads in a 2X(n+1) strip at a time. Since n can be odd, the method may operate to read half tiles into the cache . In an example using a Sinc filter where n=5, for each 2X(n+1) strip, 3 full tiles are read. This is illustrated in FIG. . As shown,  illustrates the tile read order for a Sinc filter. As shown, the read operates to read samples for 2 pixels, i and j, having the same x coordinates, and residing in neighboring scan lines.","The filtering operation may be performed when all of the requisite samples have been obtained for the pixel being generated. This may occur when the x address of the tile is greater than the edge of the filter for the respective pixel,\n\n(>filter_center+filter_radius),\n\nthen all the samples for pixeland pixelhave been read into the cache , and pixeland pixelmay be filtered. However, depending on the size of the filter and the zoom factor, all the samples for multiple pixels in each of multiple scan lines may have been read into the cache  after reading a 2X(n+1) strip. For example, consider the cone filter which has a radius of 1 and a zoom factor 2, as shown in FIG. . In this example, the samples for 8 pixels were read into the cache  after reading a single 2X(n+1) strip. In one embodiment, both pixeland pixel(having the same x coordinates and residing in neighboring scan lines) are filtered in parallel. In other embodiments, the system may include additional filters and thus an even larger number of pixels may be filtered in parallel as desired.\n","The filtering operation may be performed as follows. As described above, in order to filter samples into a pixel, the filter may require knowledge of the pixel center, the position of each sample, and the type of filter. The distance from the pixel center to a sample is given by a simple distance equation.\n\n()\n\nThe distance may be used to find the appropriate weight given the type of filter, e.g., using a table lookup. If the sample is outside the filter, then the weight is zero. As described above,  is a block diagram of a filtering method that implements the distance equation above and accesses a filter table based on the distance d to generate a weight value. The weight of each sample is multiplied by the color of each sample and the result is accumulated. The result is divided by the sum of the weights, producing the filtered pixel color. The filter equation described above may be used.\n","In one embodiment, the system includes a plurality of filter and weight units corresponding to the plurality of pixels in neighboring scan lines being rendered in parallel. For example, in an embodiment where 2 pixels (having the same x coordinates and residing in neighboring scan lines) are being rendered in parallel, the system has 2 filter and weight units.","The pixel center of pixelcan be derived from pixelas follows:\n\npixel center of =pixel center of +(zoom factor)\n\nAfter this, the next pixel center(s) may be calculated using the reciprocal of the zoom factor in the x direction\n\npixel center+=(zoom factor)\n","However, in the y direction, after two or more scan lines have been completely processed and the system is advancing to begin at the next group of multiple scan lines, since multiple (e.g., 2) scan lines are being processed at one time, the pixel center is moved by a multiple of this amount in the y direction, the multiple being dependent on the number of scan lines being processed in parallel. For example, where 2 scan lines are being processed at one time, the pixel center is moved by twice this amount.",{"@attributes":{"id":"p-0174","num":"0173"},"figref":"FIG. 24","b":["24","25"]},"The sample filter  basically comprises the following blocks: the span walker (SW), the sample generator (SG), the frame buffer addressing unit (FBA) and the frame buffer readback unit (FRB).","The span walker's responsibility is to issue sample read and filter commands to the FBA. Each read command gives an integer x, y address of the upper lefthand corner of the tile to be read. Each pixel tile sent by SW may be either a full tile (2\u00d72) or a horizontal half tile (2\u00d71). In that way, the FBA can maximize the read throughput and expand the pixel tile in a regular fashion. The span walker issues read tile commands walking the area of the filter in a ymajor fashion. Therefore, the span walker is actually reading 2X(n+1) strips where n is the height of the footprint embracing the filters. The span walker will also avoid straddling block boundaries. An example of the read order is shown in FIG. . As shown, the read order proceeds in the order from 0 to 8.","In determining when to issue filter commands, where the method is about to read a new 2X(n1) strip, the x address is examined. If this x address is greater than the edge of the filter, then a filter command is sent for this pixel pair. Therefore, the span walker uses knowledge of the radius, center, and zoom factor of the filter.  illustrates an example of issuing a filter command for one pixel pair.","However, it is possible, after reading a 2X(n+1) strip, that enough samples may have been read for more than 1 pixel pair. Therefore, the method may consider more than 1 pixel pair and send down filter commands for more than 1 pixel pair as well.  illustrates an example of issuing filter commands for multiple pixel pairs.","As shown in , it is possible that the method may issue a number of consecutive filter commands. Therefore, the span walker may be required to keep track of a number of pixels. In one embodiment, the maximum that the span walker considers is 8. An example of how this extreme case can be achieved is shown in FIG. .  illustrates an example of the maximum number of pixels that can be filtered by reading a 2Xn strip in one embodiment.","A filter command comprises the pixel center in fixed point arithmetic. The span walker will also add the reciprocal of the zoom factor to produce the new pixel center.","During read sample operations, frame buffer address (FBA) is responsible for receiving pixel (bin) tiles from span walker (SW) and expanding them into sample tiles in a regular fashion according to sample packing rules. In one embodiment, as shown in , each sample density follows a table of 3DRAM interleave enable assignment.","Since in the current embodiment the pixel tiles from SW is limited to either a full tile (2\u00d72) or a horizontal half tile (2\u00d71), SG can expand a pixel tile into sample tiles in a regular fashion.  summarize the expansion taken place in SG.","The FRB performs the actual filtering of the samples. When FRB receives a read-sample command, it stores the samples read out from frame buffer memory into its cache. The sample cache can hold samples belonging to an area of 8\u00d76 bins. The cache is made up of 8 separate 1\u00d76 strip (column), each a 2-port memory. When the FRB receives a filter command, it first calculates the weight for each sample. This may be done using a jitter table and a mirror table to compute the position of a given sample in a bin. The distance between a sample and the pixel center is used to lookup a weight in a filter table. The samples are \u201cvisited\u201d in the order of the easiest way to read samples out of the cache. The FRB reads samples out in an xmajor fashion. Since in one embodiment the maximum filter size is 5 columns, the filter has been made to handle 10 samples at a time. Therefore, the weights are computed for the first two samples in each column, and then the next two samples in each column and so on.  shows the cache organization and read ports.","Once the weights have been computed, they are placed in a queue where they wait to be filtered. In the current embodiment, the filter can handle up to 10 samples at a time and multiplies the sample color by the weights. The results are accumulated and divided by the sum of the weights to get the resulting pixel. The samples are filtered in the same order that the weight computation was done.  shows the order in which the samples are visited for a specific example.","FRB includes 2 units to handle filtering for the 2 scanlines. Each cycle, the same 10 samples are read out, and sent to the 2 units respectively. The \u201cdistance from pixel center\u201d is calculated separately for the 2 units, and hence the corresponding weight will be selected for the same sample, but with respect to 2 different filter centers.","The filter process described in the previous sections involving SW, SG, FBA and FRB can be summarized in an \u201copcode flows\u201d diagram.  shows the opcode flow from SW to FRB during a regular copy read. This Figure is used as a comparison.  shows the super-sample read pass (SS buffer->FB) opcode flows.  shows the super-sample filter pass(SS buffer->FB) opcode flows.","Although the embodiments above have been described in considerable detail, other versions are possible. Numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications. Note the section headings used herein are for organizational purposes only and are not meant to limit the description provided herein or the claims attached hereto."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing, as well as other objects, features, and advantages of this invention may be more completely understood by reference to the following detailed description when read together with the accompanying drawings in which:",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 5","FIG. 3"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 6","FIG. 3"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIGS. 10A-10D"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIGS. 11A-11C"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIGS. 12A-12C"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIGS. 13A-13C"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIGS. 14 and 15"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIGS. 31 and 32"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 37"}]},"DETDESC":[{},{}]}
