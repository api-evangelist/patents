---
title: Method for modeling human visual discrimination task performance of dynamic scenes
abstract: Methods for determining the probability of a human observer correctly performing a visual discrimination task of a target with a dynamic image stream, movie, are based on the Vcriterion, or the number of resolvable cycles needed by the human observer for a fifty percent probability of discrimination task completion, for performing the same visual discrimination task of the same targets in static scenes given an infinite amount of time. Once the Vvalue is determined for the target set using static images, this value is used with the resolvable cycles V of the target set from the movie in an empirical Target Transfer Probability Function TTPF defined by P(t)=(V(t)/V(t))/(1+(V(t)/V(t))). The TTPF calculates the probability of correctly performing the visual discrimination task of a target at a given instance in time within the movie. These P values are then modified by a time limited search equation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09152880&OS=09152880&RS=09152880
owner: THE UNITED STATES OF AMERICA AS REPRESENTED BY THE SECRETARTY OF THE ARMY
number: 09152880
owner_city: Washington
owner_country: US
publication_date: 20140530
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["GOVERNMENT INTEREST","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["The invention described herein may be manufactured, used, sold, imported, and\/or licensed by or for the Government of the United States of America.","The present invention applies generally to methods of modeling human performance while using an imaging system. More particularly, the present invention is an analytical method for predicting the performance of humans in classifying and identifying targets while using imaging systems sensitive to the short-, mid-, and long-wave infrared spectral bands as well as monochrome and gray scale visible images.","Accurate predictions of a human observer's performance, in terms of not only range at which the human will detect, classify, recognize, or identify a target but also how long it takes to accurately detect, classify, recognize, or identify a target while using electro-optical and forward looking infrared (FLIR) systems are important for several reasons. These predictions are guides for system designers and developers since predictions can be made on theoretical systems prior to manufacture to determine if they are expected to meet performance specifications. The predictions also allow purchasers of systems a way to evaluate manufactured systems for the same purpose. Finally, war game simulations and tactical decision aids use these predictions in order to evaluate engagement tactics. Therefore it is important to accurately model the range and amount of time required for a human to perform a visual discrimination task such as detecting, classifying, recognizing, or identifying a target.","The primary modeling technique for resolution and sensitivity requirements known in the prior art is the Vollmerhausen Targeting Task Performance (TTP) metric. The TTP metric uses several parameters to accurately model the environment, the imaging system (from entrance optics of the imager through the display), and also incorporates a numerical approximation of Barten's eye Contrast Threshold Function (CTF) to represent the human observer. The TTP metric is then multiplied by the angle subtended to the eye of the target and yields the psychophysical quantity of resolvable cycles (V). These resolvable cycles were used to develop an empirical Target Transfer Probability Function (TTPF). The TTPF then predicts the probability of task completion (detection, classification, recognition, identification) for a particular target or target set at various ranges with some confidence.","The original TTP metric was developed to predict a human observer's ability to detect and identify military vehicles at long ranges, >1 km. At this range, a typical advanced tactical sensor with a 50 \u03bcm pixel integrated a space of more than 0.2 m, which was sufficient when discussing large vehicles, >3 m long. The other assumption of a static scene was also sufficient since most vehicles were either static or moving slowly (in angular velocity) into an attack posture. While this worked well for characterizing human visual discrimination performance for identification of large objects that were either stationary or moving slowly at a large range, it is insufficient for objects moving at moderate speeds and close range or objects which may be rotating and thereby changing their profile to the imaging system. When research into modeling the detection and identification of humans and handheld objects commenced, it became apparent that the tactical range had dramatically shifted from kilometers to hundreds of meters. It is predominately this short range that renders the static observer\/static target assumption invalid. An observer moving at only 30 mph will cover a 500 m range in less than 1 minute.","To compensate for this limitation most war gamers assume that a target is static and randomly distributed in aspect to the imaging system and the time to make a higher level visual discrimination decision, such as classification or identification, is assumed to be an instantaneous event. The difficulty of an observer to classify or identify a randomly aspect distributed target is the cycle criterion for the TTPF (V). This Vis the number of resolvable cycles required to correctly detect, classify, recognize, or identify a target with 50 percent probability. This cycle criterion is reported for a number of different target sets but remains as an average over the predefined aspects a target may assume in the environment. In an attempt to determine the Vfor either a moving imaging system or a non-stationary target, experiments are being conducted using movies, which has led to an order of magnitude increase in the generation and storage of imagery causing monetary resources to be used for computer memory upgrades. The time to make a higher level visual discrimination decision, such as classification or identification, is usually measured but rarely reported.","The primary technique for modeling the temporal response of a human is known in the prior art as the Edwards-Vollmerhausen Time Limited Search (TLS) model. The TLS model uses the known probability of detection for a target given an infinite amount of time (P) to predict the actual probability of human observers if they do not have an infinite amount of time to search an image or scene. The cumulative probability of finding a target within time t is calculated using an exponential buildup curve equation. The mean time to detect the target is a calibrated parameter which varies due to scene complexity and image quality, but is a function of P. This TLS equation was developed for and strictly applied to the task of detecting targets. Many war gamers assume the task of classifying, recognizing, or identifying targets is an instantaneous event. This assumption could allow for an over prediction in the effectiveness and speed of an engagement involving imaging systems. A human observer may delay in making an identification simply because the target may be moving or turning in hopes of obtaining a better\/easier aspect on which to make their decision. This delay in identification affects the temporal speed of a possible engagement and could cascade through an entire war game simulation.","In light of the above, the objectives of the present invention are to provide: a method for predicting the probability of detection, classification, recognition, and identification of either stationary or moving targets with a either a stationary or moving imaging system; a method which can be calibrated from more cost efficient static image experiments; finally a method which can be applied to mono-chrome or gray scale visible spectrum imagery, short-, mid-, and long-wave infrared spectrum imagery.","Methods for determining the probability of a human observer correctly performing a visual discrimination task of a target with a dynamic image stream, movie, are based on the Vcriterion, or the number of resolvable cycles needed by the human observer for a fifty percent probability of discrimination task completion, for performing the same visual discrimination task of the same targets in static scenes given an infinite amount of time. Once the Vvalue is determined for the target set using static images, this value is used with the resolvable cycles V of the target set from the movie in an empirical Target Transfer Probability Function TTPF defined by Pc(t)=(V(t)\/V(t))\/(1+(V(t)\/V(t))). The TTPF calculates the probability of correctly performing the visual discrimination task of a target at a given instance in time within the movie. These P values are then modified by a time limited search equation.","An exemplary method for modeling human visual discrimination task performance using dynamic scenes in accordance with the present invention includes the step of measuring the number of resolvable cycles V, for a particular imaging system against a particular target or particular set of targets at a particular range and aspect, as a function of time. The resolvable cycles are given by:",{"@attributes":{"id":"p-0012","num":"0011"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["V","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mrow":[{"mo":["(",")"],"mrow":{"mi":["T","T"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mrow":{"msub":{"mi":["P","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}}},{"mo":["(",")"],"mfrac":{"mrow":[{"msub":{"mi":"d","mrow":{"mi":["c","a"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"R","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}}],"mo":"\u2062"}],"mo":"="}}},"br":{},"sub":["c,a ","a ","a ","50,a","50,a "]},{"@attributes":{"id":"p-0013","num":"0012"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":"P","mrow":{"mi":["\u221e","a"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mfrac":{"msup":{"mrow":{"mo":["(",")"],"mfrac":{"mrow":[{"msub":{"mi":["V","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":"V","mrow":{"mn":"50","mo":",","mi":"a"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}},"mn":"1.5"},"mrow":{"mn":"1","mo":"+","msup":{"mrow":{"mo":["(",")"],"mfrac":{"mrow":[{"msub":{"mi":["V","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":"V","mrow":{"mn":"50","mo":",","mi":"a"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}},"mn":"1.5"}}},"mo":"."}],"mo":"="}}}},"This Vparameter is range independent and its value is governed by the visual discrimination task and items which comprise the target set. In the prior art Vhas been based on the targets which make up the target set with multiple aspects of those targets presented to the observer in a human perception experiment. This invention allows both the Vand Vquantities to vary as a function of time. Therefore an aspect dependent Vis necessary to account for any turning of the target with respect to the imaging system. However, this aspect dependent Vis readily measurable from a static image experiment which contained a sampling of aspects of the targets.","Once the Pvalues are calculated, the methods of this invention include the step of scaling them with respect to time by using the Time Limited Search (TLS) equation:",{"@attributes":{"id":"p-0016","num":"0015"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mrow":[{"msub":{"mi":"P","mrow":{"mi":["\u221e","a"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mrow":{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mrow":[{"mo":"-","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mrow":{"msub":{"mi":["t","d"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}}}},{"mi":"\u03c4","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}}}}}],"mo":"\u2062"}],"mo":"="},"mo":","}}}},"where tinitially represents the temporal experimental overhead required for an observer to make a response, t is the modeled scenario time, and \u03c4 is the mean time to perform the discrimination task and is given by:\n\n\u03c4()=()\n\nwhere A and B are empirically determined constants directly measurable from the same static image experiment used to measure the Vparameter if the observer response time is also recorded during the experiment. The modeled P(t) value is a cumulative probability versus time. In the prior art, the TLS equation was used strictly for the task of search and detection. In this invention the TLS equation is used for all visual discrimination levels (detection, classification, recognition, and identification) and the mean time to perform a discrimination task \u03c4 is allowed to change as Pchanges temporally. This invention also requires that every instance in which Pexceeds a threshold value P, . . . a new TLS curve be started by calculating an appropriate tfactor that is given by:\n",{"@attributes":{"id":"p-0018","num":"0017"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["t","d"]},"mo":"=","mrow":{"mi":"t","mo":["+","-"],"mrow":[{"mo":["(",")"],"mrow":{"mrow":[{"mi":"\u03c4","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"ln","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mfrac":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mrow":{"mi":["\u0394","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},{"msub":{"mi":"P","mrow":{"mi":["\u221e","a"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}}}}],"mo":"\u22c6"}},{"mi":["\u0394","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}}}},"br":{}},"By way of background, in prior art a method for modeling human visual discrimination task performance begins with the step of measuring the number of resolvable cycles V, for a particular imaging system against a particular target or particular set of targets at a particular range. The resolvable cycles are given by:",{"@attributes":{"id":"p-0029","num":"0028"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"V","mo":"=","mrow":{"mrow":[{"mo":["(",")"],"mi":"TTP"},{"mo":["(",")"],"mfrac":{"msub":{"mi":["d","c"]},"mi":"R"}}],"mo":"\u2062"}}}},"br":{},"sub":"c "},{"@attributes":{"id":"p-0030","num":"0029"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["P","\u221e"]},"mo":"=","mfrac":{"msup":{"mrow":{"mo":["(",")"],"mfrac":{"mi":"V","msub":{"mi":"V","mn":"50"}}},"mn":"1.5"},"mrow":{"mn":"1","mo":"+","msup":{"mrow":{"mo":["(",")"],"mfrac":{"mi":"V","msub":{"mi":"V","mn":"50"}}},"mn":"1.5"}}}}}},"br":{},"sub":["50","50 "]},"For the detection discrimination task, a series of static images, some containing targets and some containing no targets, are presented to the observers and they are asked to locate the region of the image containing the target. The location of their response and the time elapsed from when the image appeared on the screen until they responded are recorded. The responses from the observers are averaged together on an image-by-image basis to calculate the P value for each image. The resolvable cycles that the target presented in each image is also calculated using a sensor performance metric such as TTP. The sensor performance metric takes into account all imaging sensor physical attributes, environmental conditions, existing external lighting conditions, characteristic size of target, target signature, and range to target. The Vparameter that maps the calculated resolvable cycles closest to the observer P values is the measured Vfor the detection task of the set of targets which were detected. The recorded observer response time for each image is then compiled for all images which contain a similar observer P value. The contribution to the total probability of detection of each correct response, s, is normalized, such that P=P*(1\/S), where S is the total number of observer responses. The summed probability as a function of response time is shown in , .","The TLS equation is given by:",{"@attributes":{"id":"p-0033","num":"0032"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":["P","\u221e"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mrow":{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mrow":{"mo":"-","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","msub":{"mi":["t","d"]}}}},"mi":"\u03c4"}}}}}}],"mo":"="}}},"br":[{},{},{}],"sub":["d ","\u221e","\u221e","\u221e","\u221e","\u221e"],"b":["101","200","201"],"figref":["FIG. 1","FIG. 2"],"in-line-formulae":[{},{}],"i":"A\u2212B*P"},"For higher order discrimination tasks (classification, recognition, and identification), an N-alternative forced choice experiment with single frame static images of a set of targets is conducted. The set of targets are chosen to be consistent with the definition of the discrimination task being measured and the targets are generally shown at multiple aspects. The target set is generally degraded in discrete steps in either resolution or sensitivity. When presented with a degraded target image, the observer is given N-alternatives to choose from in making their response. The correctness of their responses and the elapsed time from when the image appeared on the screen until they responded are recorded. An individual observer's responses are then averaged across all targets and aspects by resolution\/sensitivity level and then an average is taken of all observers for each resolution\/sensitivity level. This produces a measured average observer probability value for the target set at each experimental level. By the nature of the forced choice experimental set-up, a potentially significant probability of correct responses could be achieved by guessing. A method to remove the probability of guessing is given by:",{"@attributes":{"id":"p-0035","num":"0034"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["P","\u221e"]},"mo":"=","mfrac":{"mrow":[{"msub":{"mi":["P","M"]},"mo":"-","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"\/","mi":"N"}}},{"mn":"1","mo":"-","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"\/","mi":"N"}}}]}}}},"br":{},"sub":["M ","50 ","\u221e","50 ","50 "]},"The above cited processes are well known in the art and are further described in the open literature specifically in \u201cNVESD time-limited search model\u201d, Timothy C. Edwards et al., Proceedings of SPIE, vol. 5076, 2003, and \u201cNew metric for predicting target acquisition performance\u201d Richard H. Vollmerhausen et al., Optical Engineering, vol. 43(11), pp. 2806-2818, which are hereby incorporated by reference. The Targeting Task Performance (TTP) metric can be used for detection, classification, recognition and identification tasks if only the probability of human performance is required, but must be coupled with the Time Limited Search (TLS) equation to gain the added in sight to the time it takes an observer to make a detection.","Methods are disclosed for determining the probability of a human observer correctly performing a visual discrimination task (detection, classification, recognition, or identification) of a target with a dynamic image stream, movie, based on the Vcriterion, or the number of resolvable cycles needed by the human observer for a fifty percent probability of discrimination task completion, for performing the same visual discrimination task of the same targets in static scenes given an infinite amount of time. Once the Vvalue is determined for the target set using static images, this value is used with the resolvable cycles (V) of the target set from the movie in an empirical Target Transfer Probability Function (TTPF) defined by P(t)=(V(t)\/V(t))\/(1+(V(t)\/V(t))). The TTPF calculates the probability of correctly performing the visual discrimination task of a target at a given instance in time within the movie. These P values are then modified by the time limited search (TLS) equation P(t)=P(t)(1\u2212exp(\u2212(t\u2212t))) where t is the actual time in the movie in seconds, tis the experimental time delay associated with experimental set up, and \u03c4(t) is the mean time to perform the visual discrimination task, and is calculated as \u03c4(t)=A\u2212B*P(t). A and B are calibration constants that are measured from a static image perception experiment and encompass the target set and a representative clutter level of the movie.","Exemplary methods of the present invention are described in greater detail. For example, an exemplary method for predicting a human observers probability of detection, classification, recognition, and identification of either stationary or moving targets with either a stationary or moving imaging system comprises the steps of:","Step A: Measuring an aspect varying Vas the cycle criterion required for a fifty percent (50%) probability of detection, classification, recognition, or identification of a particular target set imaged within a specific spectral region for each target set at each specified aspect through the conduct of a human perception experiment, either N-alternative forced choice experiment, or free response, using images of static targets from static imaging systems measuring simultaneously observer response to the visual discrimination task under investigation and the time required for that response;","Step B: Measuring the mean time to accomplish a visual discrimination task (\u03c4) as a function of the probability of accomplishing the visual discrimination task through the conduct of a human perception experiment, either N-alternative forced choice experiment, or free response, using images of static targets from static imaging systems measuring simultaneously observer response to the visual discrimination task under investigation and the time required for that response;","Step C: Determining the cycles resolved (V) on a target set for a specific sensor as the number of equivalent cycles resolved by the sensor temporally according to the relationship:",{"@attributes":{"id":"p-0042","num":"0041"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"msub":{"mi":["V","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mrow":[{"msub":{"mi":["TTP","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mo":["(",")"],"mfrac":{"mrow":[{"msub":{"mi":"d","mrow":{"mi":["c","a"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"R","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}}],"mo":"\u2062"}],"mo":"="},"mo":";"}}}},"Step D: Determining the probability, P, of visual task performance according to the relationship:",{"@attributes":{"id":"p-0044","num":"0043"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":{"msub":{"mi":"P","mrow":{"mi":["\u221e","a"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},"mo":"=","mfrac":{"msup":{"mrow":{"mo":["(",")"],"mfrac":{"mrow":[{"msub":{"mi":["V","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":"V","mrow":{"mn":"50","mo":",","mi":"a"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}},"mn":"1.5"},"mrow":{"mn":"1","mo":"+","msup":{"mrow":{"mo":["(",")"],"mfrac":{"mrow":[{"msub":{"mi":["V","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":"V","mrow":{"mn":"50","mo":",","mi":"a"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}},"mn":"1.5"}}}},"mo":";"}}}},"Step E: Determining the mean time to accomplish a visual discrimination task (\u03c4);","Step F: Determining if cumulative probability has exceeded a threshold and requires a new cumulative probability function needs to be started by calculating an updated time delay (t); and","Step G: Calculating an accurate probability of human observer performance as a function of time for output in predicting a human observers probability of detection, classification, recognition, and\/or identification of either stationary or moving targets.","Referring now to and , an exemplary analysis methodology required to produce an accurate model calibration for the present invention in resolution, sensitivity, and temporally is disclosed. For calibration purposes, a standard static image static imaging system human perception experiment is conducted, as is already known in the art for all levels of human observer visual discrimination. In order to calibrate the present invention for resolution and sensitivity, either an N-alternative forced choice experiment, or free response experiment, is conducted with single frame static images. Each image contains a single target however the set of images span a set of targets at different aspects. However, unlike the present art, the observers' probabilities must be calculated for the set of targets at each aspect as depicted by block  in and . The probabilities for an N-alternative forced choice experiment are then adjusted to remove the probability that the observer guessed correctly according to the relationship:",{"@attributes":{"id":"p-0049","num":"0048"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"P","mrow":{"mi":["\u221e","ma"],"mo":","}},"mo":"=","mfrac":{"mrow":[{"msub":{"mi":"P","mrow":{"mi":["M","a"],"mo":","}},"mo":"-","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"\/","mi":"N"}}},{"mn":"1","mo":"-","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"\/","mi":"N"}}}]}}}},"br":{},"sub":"M,a ","b":"301","figref":"FIG. 3","i":"a"},{"@attributes":{"id":"p-0050","num":"0049"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["V","a"]},"mo":"=","mrow":{"mrow":[{"mo":["(",")"],"msub":{"mi":"\u03bc","mrow":{"mi":["TTP","a"],"mo":","}}},{"mo":["(",")"],"mfrac":{"msub":{"mi":"\u03bc","mrow":{"msub":{"mi":["d","c"]},"mo":",","mi":"a"}},"mi":"R"}}],"mo":"\u2062"}}}},"br":{},"sub":["TTP,a ","dc,a ","\u221e,ma "],"b":["302","303","304","305"]},{"@attributes":{"id":"p-0051","num":"0050"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"P","mrow":{"mi":["\u221e","a"],"mo":","}},"mo":"=","mfrac":{"msup":{"mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["V","a"]},{"mi":"V","mrow":{"mn":"50","mo":",","mi":"a"}}]}},"mn":"1.5"},"mrow":{"mn":"1","mo":"+","msup":{"mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["V","a"]},{"mi":"V","mrow":{"mn":"50","mo":",","mi":"a"}}]}},"mn":"1.5"}}}}}},"br":{},"sub":["50,a ","50,a ","\u221e,a ","\u221e,ma ","50,a "],"b":"306"},"Turning specifically to , in order to calibrate the current invention for temporal distribution for all visual discrimination levels, the current invention requires measurement of the amount of time each observer requires to make a correct discrimination, as depicted in block . Each correct response is weighted to have a P1\/S) value, where S is the total number of observer responses as depicted in block . These individual responses are graphed as probability versus time and will be a cumulative probability build-up curve, as depicted in block , will be similar to the one shown in , . Referring to , the mean time to detect is a fit parameter for the TLS equation given by:",{"@attributes":{"id":"p-0053","num":"0052"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":"P","mrow":{"mi":["\u221e","ma"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mrow":{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mrow":{"mo":"-","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","msub":{"mi":["t","d"]}}}},"mi":"\u03c4"}}}}}}],"mo":"="}}},"br":[{},{},{}],"sub":["d ","\u221e","\u221e,ma ","\u221e,ma "],"b":["310","311"],"in-line-formulae":[{},{}],"i":"A\u2212B*P"},"Once the \u03c4 versus Prelationship is modeled and the resolution and sensitivity requirement measured for the target set and for the visual discrimination task, the current invention is considered calibrated. Referring to  of the current invention, the imaging system and environmental conditions are modeled using the TTP metric, as depicted in block . If the environmental conditions can be considered unchanging with respect to the time scale of the scenario, the imaging system only needs to be modeled once with the present environmental conditions; otherwise the TTP must be modeled as a function of time. The characteristic size, d, of the target set needs to be known temporally, as depicted in block , as well as the range, R, from the imaging system to the target set as a function of time, as depicted in block . The resolvable cycles as a function of time can then be calculated given by:",{"@attributes":{"id":"p-0055","num":"0054"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["V","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mrow":[{"mo":["(",")"],"mrow":{"mi":"TTP","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}},{"mrow":{"mo":["(",")"],"mfrac":{"mrow":[{"msub":{"mi":"d","mrow":{"mi":["c","a"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"R","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}},"mo":"."}],"mo":"\u2062"}],"mo":"="}}}},"A scenario to be modeled is generated with accurate values of the number of resolvable cycles an observer would experience as a function of time, depicted in block . This scenario also requires an accurate description of the target aspect to the imaging system as a function of time, as depicted in block . The Pvalue as a function of time will then be calculated using a time dependent TTPF given by:",{"@attributes":{"id":"p-0057","num":"0056"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":"P","mrow":{"mi":["\u221e","a"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},"mo":"=","mfrac":{"msup":{"mrow":{"mo":["(",")"],"mfrac":{"mrow":[{"msub":{"mi":["V","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":"V","mrow":{"mn":"50","mo":",","mi":"a"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}},"mn":"1.5"},"mrow":{"mn":"1","mo":"+","msup":{"mrow":{"mo":["(",")"],"mfrac":{"mrow":[{"msub":{"mi":["V","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":"V","mrow":{"mn":"50","mo":",","mi":"a"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}},"mn":"1.5"}}}}}}},"as depicted in block . As the scenario evolves in time the current invention uses the largest Pvalue, up to the current time, in calculating the mean time to accomplish the visual discrimination task. This decision is depicted in block . If the current time Pvalue is less than the largest Pvalue until that time then, depicted in block , then the largest previous Pvalue is used, depicted in block , in calculating the mean time to accomplish the visual discrimination task (\u03c4) depicted in block  and given by:\n\n\u03c4()=()\n\nwhere A and B were previously calibrated coefficients for the discrimination task and target set. If the current time Pvalue is larger than all previous time Pvalues, depicted in block , than \u03c4(t) is directly calculated using this current Pvalue, as depicted in block .\n","A series of threshold values, P, are established with the calculation of the initial Pvalue and is given by:\n\n(0)+\n\nwhere n starts at zero and increases in integer increments to infinity and \u0394Phas a magnitude of \u0394t\/25 with \u0394t being the time increment of the simulation, as depicted in block . The factor of 25 in \u0394P that determines the threshold values for starting a new probability is a minimum value that provides good agreement to experimental data. The next decision, depicted in block , is if the current Pvalue is greater than Pinitially. If the current Pvalue is less than the P, as depicted by block , than P(t) is calculated, as depicted in block , given by:\n",{"@attributes":{"id":"p-0060","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mrow":[{"msub":{"mi":"P","mrow":{"mi":["\u221e","a"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mrow":{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mrow":[{"mo":"-","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","msub":{"mi":["t","d"]}}}},{"mi":"\u03c4","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}}}}}],"mo":"\u2062"}],"mo":"="}}},"br":{},"sub":["d ","\u221e,a","n ","n+1","d "],"b":["412","415"]},{"@attributes":{"id":"p-0061","num":"0060"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["t","d"]},"mo":"=","mrow":{"mi":"t","mo":["+","-"],"mrow":[{"mo":["(",")"],"mrow":{"mrow":[{"mi":"\u03c4","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"ln","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mfrac":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mrow":{"mi":["\u0394","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},{"msub":{"mi":"P","mrow":{"mi":["\u221e","a"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}}}}],"mo":"\u22c6"}},{"mi":["\u0394","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}}}},"br":{},"sub":["\u221e,a","d ","\u221e,a ","n+1","\u221e,a ","\u221e,a ","\u221e,a ","\u221e,a","\u221e,a ","\u221e,a "],"b":"416"},"The current invention was tested with three human perception experiments, a search and detection experiment from a moving vehicle, a target recognition experiment where the target was turning with respect to the imaging system and the imaging system was stationary, and a target identification experiment where the target was turning with respect to the imaging system and the imaging system was stationary. All human observers were unique to each experiment. However, each human observer participated in both the static image calibration experiments and the dynamic image experiments. The current invention modeled the observer results at a temporal frequency of 30 Hz.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIGS. 5","b":["6","7","500","600","601","700","701","501","602","603","702","703"]},"Those of skill in the art will appreciate still additional alternative structural and functional designs for a human observer predictive model by differentiating the current embodiment with respect to time and their applications through the disclosed principles of the present invention. Thus, while particular embodiments and applications of the present invention have been illustrated and described, it is to be understood that the invention is not limited to the precise construction and components disclosed herein and that various modifications, change and variations which will be apparent to those skilled in the art may be made in the arrangement, operation and details of the method and apparatus of the present invention disclosed herein without departing from the spirit and scope of the invention as defined in the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The novel features of this invention will be best understood from the accompanying drawings, taken in conjunction with the accompanying description, in which similar characters refer to similar parts, and in which:",{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 3","i":"a "},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 3","i":"b "},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
