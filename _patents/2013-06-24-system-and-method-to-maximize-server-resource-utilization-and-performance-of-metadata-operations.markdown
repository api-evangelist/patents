---
title: System and method to maximize server resource utilization and performance of metadata operations
abstract: An MDS (metadata server) in a distributed storage system includes data servers (DSs) storing file contents and one or more MDSs performing metadata operations in response to metadata requests of different types, the MDS including a controller having a processor and a memory, the MDS storing file system metadata. The controller is configured to: classify the metadata operations into different categories, which include a normal category and one or more special categories different from the normal category, the normal category having a primary stage which does not involve communication between the MDS and a component external to the MDS; for each special category, partition each metadata operation into a plurality of stages at least one of which involves communication between the MDS and a component external to the MDS; and dynamically assign resources to each of the partitioned stage based on monitored workloads of the different types of metadata requests.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09197703&OS=09197703&RS=09197703
owner: HITACHI, LTD.
number: 09197703
owner_city: Tokyo
owner_country: JP
publication_date: 20130624
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION","Embodiment 1","Embodiment 2","Embodiment 3","Embodiment 4"],"p":["The present invention relates generally to storage systems and, more particularly, to system and method to maximize server resource utilization and performance of metadata operations.","Distributed file systems and parallel file systems involve a plurality of servers cooperating with each other in order to complete the processing of file system requests from clients.","In one consideration, a parallel file system such as pNFS (parallel network file system) includes a plurality of Data Servers (DSs) to process read\/write requests while a dedicated Metadata Server (MDS) processes all metadata requests. A client first establishes connection to the MDS. Then it performs a file open operation on the interested file to obtain the location information such as IP address of the DS, file identifier on the DS, etc. After knowing the location information and the identifier, the client sends read\/write requests directly to the DS. It is the MDS's responsibility to obtain file identifiers from all the DSs as part of the operations such as file open and file create. Hence for certain metadata operations, there is a need for MDS-to-DS communication typically called the Control Path Protocol (CPP). While processing such operations, existing systems block the thread servicing an operation during the CPP procedure, and hence the resources (e.g., CPU, memory, etc.) assigned to the thread cannot be utilized to service other operations. This leads to under-utilization of MDS resources and thereby reduces the overall metadata access performance by a single MDS.","Although separating metadata and read\/write service capabilities to MDS and DS respectively greatly improves read\/write performance by providing high throughput parallel I\/O (HPC applications and streaming applications leverage such architectures), a typical HPC workload contains more than 50% of metadata operations. Hence, MDS server performance is critical in improving overall file system performance as seen by the clients. Virtualized multiple metadata server cluster solutions have been proposed to provide distributed metadata service to increase overall metadata access performance. However, even in such a solution, each MDS is underutilized during CPP communication. Thus, there is a need to provide a solution to effectively utilize MDS resources during CPP communication.","In another consideration, multiple MDS solutions which provide global namespace and a virtualized view of MDSs need MDS-to-MDS communication for certain metadata requests such as directory create and directory listing. As an illustration, in some multiple MDS solution where metadata distribution is at the directory level, a create directory operation may need to create the directory at another MDS other than the one receiving the create directory request. During such MDS-to-MDS communication, threads block as aforementioned and leads to underutilization of MDS resources.","Exemplary embodiments of the invention provide a solution to effectively utilize MDS resources for metadata operations requiring server-to-server communication, including the aforementioned CPP communication and MDS-to-MDS communication. In general, a solution which can improve metadata server resource utilization during any server-to-server communication is desired. Specific embodiments are directed to a method to maximize server resource utilization and performance of metadata operations by classifying the metadata operation into different categories (normal category and plurality of special categories) and partitioning the metadata server program into a plurality of stages for special categories of metadata operations and dynamically assigning resources to each of the partitioned stage based on the monitored client workload of various metadata request categories.","Existing solutions can be classified into two categories. The first approach is to reduce the server-to-server traffic and the second approach is to maximize utilization of server resources by resource management strategies.","In the first approach, the server-to-server traffic is avoided for metadata operations by either a prefetching technique or by a caching technique. US2010\/0161585 uses a prefetching technique to reduce MDS-to-DS (CPP) communication during file creation. In this technique, data server resources are created and all resource information required to identify the file are pre-fetched and stored in the MDS. When the client requests for file creation, the MDS uses one of the pre-allocated data server resources and maps that resource to the requested file creation. This avoids the CPP communication during file creation and hence improves file creation performance. However, such a technique only caters to file creation performance but MDS resources are underutilized during other metadata operations involving CPP communication such as file open, file close, file remove etc. U.S. Pat. No. 7,827,192 uses a caching technique to reduce CPP communication. For metadata operations requiring CPP communication, the MDS uses the cached data server resource information and avoids the actual CPP communication. However, such techniques are only suitable for read-only metadata operations but cannot solve underutilization problem during update or create metadata operations. Similar caching techniques have been proposed to reduce other server-to-server traffic such as MDS-to-MDS but they only improve performance for read-only requests.","Using the second approach, the metadata resources are utilized efficiently by using resource management techniques using information collected by monitoring current resource utilization and\/or client workload. U.S. Pat. No. 8,091,089 monitors resource utilization of multiple instances of metadata server programs running on a single machine and manages resource allocation among those instances efficiently. For example, if one instance of metadata server program is underutilizing its resources, the resource management program de-allocates underutilized resources and assigns it to other instances of metadata server program which are using their currently assigned resources to the limit. U.S. Pat. No. 8,145,759 performs similar resource management technique to effectively assign resources to different applications running on the server. In this technique, the number of client requests to each server application is monitored. Upon receiving a configuration change request for an application, the resource management program increases or decreases server resources dedicated to that application based on the current assignment, current number of client requests, and new resource limit. Such resource management techniques effectively reduce underutilization of server resources by dynamically managing resources across different instances of the program. However, they do not consider different categories of client requests for the same server program and do not allocate resources to different stages of the same server program which is critical to solve the identified problem (because processing time for different metadata operations vary significantly due to server-to-server communication required for some of those operations).","This invention can be used to design metadata servers to improve\/maximize MDS resources utilization and thereby increasing metadata access performance. In specific examples, the invention can be used to design metadata servers on dedicated physical machine such as those in asymmetric architecture (e.g., pNFS), or to design metadata server program on symmetric distributed file system and symmetric clusters.","An aspect of the present invention is directed to an MDS (metadata server) in a distributed storage system which includes a plurality of data servers (DSs) storing file contents and one or more MDSs performing a plurality of metadata operations in response to metadata requests of different types, the MDS including a controller having a processor and a memory, the MDS storing file system metadata. The controller is configured to: classify the metadata operations into different categories, which include a normal category and one or more special categories which are different from the normal category, the normal category having a primary stage which does not involve communication between the MDS and a component external to the MDS; for each of the one or more special categories, partition each of the metadata operations into a plurality of stages at least one of which involves communication between the MDS and a component external to the MDS; and dynamically assign resources to each of the partitioned stage based on monitored workloads of the different types of metadata requests.","In some embodiments, the classifying comprises classifying the metadata operations into different categories based on type and amount of processing required for each category. The one or more special categories of metadata operations comprise at least one of (i) a first special category of metadata operations that require communication between the MDS and one or more of the plurality of DSs; or (ii) a second special category of metadata operations that require communication between the MDS and one or more other MDSs. The stages for the first special category of metadata operations comprise the primary stage; and a pNFS manager stage for performing pNFS related metadata management including preparing requests to be sent to the DSs; an MDS-DS asynchronous client stage for sending asynchronous requests to the DSs; an asynchronous DS processing stage which is performed on the DSs for processing asynchronous requests from the MDS and sending a response back to the MDS after processing completes; a DS response aggregator stage for receiving responses from the DSs and aggregating all the received responses to a single context representing a corresponding metadata operation; and a secondary metadata processor stage for post processing on the MDS. The stages for the second special category of metadata operations comprise the primary stage; and an MDSC manager stage for performing MDS cluster management including preparing requests to be sent to the one or more other MDSs; an inter-MDS asynchronous client stage for sending asynchronous requests to the one or more other MDSs; an asynchronous inter-MDS processing stage which is performed on the one or more other MDSs; an MDS response aggregator stage for receiving responses from the plurality of MDSs and aggregating all the received responses to a single context representing a corresponding metadata operation; a secondary metadata processor for post processing on the MDS.","In specific embodiments, the partitioning comprises partitioning each metadata operation into a plurality of stages each of which (i) involves communication with a component external to the MDS, or (ii) involves a processing logic that is modularly different from its preceding processing logic and its succeeding processing logic. A stage which involves communication with a component external to the MDS has a processing logic that treats the external component with which the stage of the metadata operation communicates as an asynchronous server component.","In some embodiments, the dynamically assigning resources comprises: monitoring metadata workload of the normal category and the one or more special categories to obtain a number of metadata operations for each category and a total number of metadata operations for all categories; calculating, for each special category, a ratio of the number of metadata operations for said each special category to the total number of metadata operations for all categories obtained from the monitoring; calculating a processing time for each of the normal category and the one or more special categories; and allocating a plurality of threads representing units of execution across all the stages by considering: (i) an estimated processing time for each stage, (ii) the calculated ratio for each special category, (iii) the calculated processing time for each category, and (iv) a total number of threads allocated to the MDS. The threads allocated to a particular special category are assigned to each stage involved in the particular special category in the ratio of the estimated processing time of each stage relative to the processing time of all the stages of the particular special category.","In specific embodiments, the controller is configured to identify, from the one or more special categories of metadata operations, one or more candidate metadata operations to be executed in batch mode. The one or more candidate metadata operations each (i) has a potential to be batched together in a single network call to perform similar metadata operations speculatively, or (ii) has a potential to be locally completed asynchronously within the MDS and, at a later point in time, to be batched together with similar metadata operations to complete inter-server processing between the MDS and one or more external components.","In some embodiments, the controller is configured: (i) when the one or more candidate metadata operations each has a potential to be batched together in a single network call to perform similar metadata operations speculatively, to identify data structures required to be stored in the memory of the MDS in order to perform a batch operation to speculatively fetch information from the external component; or (ii) when the one or more candidate metadata operations each has a potential to be locally completed asynchronously within the MDS and, at a later point in time, to be batched together with similar metadata operations to complete inter-server processing between the MDS and one or more external components, to identify a data consistency protocol for batch mode execution involving asynchronous processing.","In specific embodiments, the controller is configured to: count a total number of each candidate metadata operation to be executed in batch mode based on monitoring the metadata workload; and when the total number of a particular candidate metadata operation exceeds a preset threshold for the particular candidate metadata operation, select the particular candidate metadata operation to be executed in batch mode. The dynamically assigning resources comprises: monitoring metadata workload of the normal category and the one or more special categories to obtain a number of metadata operations for each category and a total number of metadata operations for all categories; calculating, for each special category, a ratio of (the number of metadata operations for said each special category minus a number of metadata operations for said each special category which have been selected to be executed in batch mode) to the total number of metadata operations for all categories obtained from the monitoring; calculating a processing time for each of the normal category and the one or more special categories; and allocating a plurality of threads representing units of execution across all the stages by considering: (i) an estimated processing time for each stage, (ii) the calculated ratio for each special category, (iii) the calculated processing time for each category, and (iv) a total number of threads allocated to the MDS.","Another aspect of the invention is directed to a method of managing resources of an MDS (metadata server) in a distributed storage system which includes a plurality of data servers (DSs) storing file contents and one or more MDSs performing a plurality of metadata operations in response to metadata requests of different types, the MDS including a controller having a processor and a memory, the MDS storing file system metadata. The method comprises: classifying the metadata operations into different categories, which include a normal category and one or more special categories which are different from the normal category, the normal category having a primary stage which does not involve communication between the MDS and a component external to the MDS; for each of the one or more special categories, partitioning each of the metadata operations into a plurality of stages at least one of which involves communication between the MDS and a component external to the MDS; and dynamically assigning resources to each of the partitioned stage based on monitored workloads of the different types of metadata requests.","These and other features and advantages of the present invention will become apparent to those of ordinary skill in the art in view of the following detailed description of the specific embodiments.","In the following detailed description of the invention, reference is made to the accompanying drawings which form a part of the disclosure, and in which are shown by way of illustration, and not of limitation, exemplary embodiments by which the invention may be practiced. In the drawings, like numerals describe substantially similar components throughout the several views. Further, it should be noted that while the detailed description provides various exemplary embodiments, as described below and as illustrated in the drawings, the present invention is not limited to the embodiments described and illustrated herein, but can extend to other embodiments, as would be known or as would become known to those skilled in the art. Reference in the specification to \u201cone embodiment,\u201d \u201cthis embodiment,\u201d or \u201cthese embodiments\u201d means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the invention, and the appearances of these phrases in various places in the specification are not necessarily all referring to the same embodiment. Additionally, in the following detailed description, numerous specific details are set forth in order to provide a thorough understanding of the present invention. However, it will be apparent to one of ordinary skill in the art that these specific details may not all be needed to practice the present invention. In other circumstances, well-known structures, materials, circuits, processes and interfaces have not been described in detail, and\/or may be illustrated in block diagram form, so as to not unnecessarily obscure the present invention.","Furthermore, some portions of the detailed description that follow are presented in terms of algorithms and symbolic representations of operations within a computer. These algorithmic descriptions and symbolic representations are the means used by those skilled in the data processing arts to most effectively convey the essence of their innovations to others skilled in the art. An algorithm is a series of defined steps leading to a desired end state or result. In the present invention, the steps carried out require physical manipulations of tangible quantities for achieving a tangible result. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals or instructions capable of being stored, transferred, combined, compared, and otherwise manipulated. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, instructions, or the like. It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise, as apparent from the following discussion, it is appreciated that throughout the description, discussions utilizing terms such as \u201cprocessing,\u201d \u201ccomputing,\u201d \u201ccalculating,\u201d \u201cdetermining,\u201d \u201cdisplaying,\u201d or the like, can include the actions and processes of a computer system or other information processing device that manipulates and transforms data represented as physical (electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system's memories or registers or other information storage, transmission or display devices.","The present invention also relates to an apparatus for performing the operations herein. This apparatus may be specially constructed for the required purposes, or it may include one or more general-purpose computers selectively activated or reconfigured by one or more computer programs. Such computer programs may be stored in a computer-readable storage medium including non-transient medium, such as, but not limited to optical disks, magnetic disks, read-only memories, random access memories, solid state devices and drives, or any other types of media suitable for storing electronic information. The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus. Various general-purpose systems may be used with programs and modules in accordance with the teachings herein, or it may prove convenient to construct a more specialized apparatus to perform desired method steps. In addition, the present invention is not described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the invention as described herein. The instructions of the programming language(s) may be executed by one or more processing devices, e.g., central processing units (CPUs), processors, or controllers.","Exemplary embodiments of the invention, as will be described in greater detail below, provide apparatuses, methods and computer programs for improving server resource utilization and performance of metadata operations.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 1","b":["0110","0120","0130","0100"]},"MDSs  are servers or devices which manage the namespace of the file system, contain metadata of the files and directories, and provide service to metadata operations initiated by clients . In addition, MDSs  may communicate with other MDSs  or DSs  for the following reasons. MDSs  communicate with DSs  in order to map the files in the namespace with the physical data present in DSs . Such information is used to process some metadata operations initiated by clients . MDSs  may communicate with other MDSs  to provide a global namespace while processing some metadata operations initiated by the client .","DSs  are servers or devices which store data or file contents. DSs  process requests (mainly Read and Write) from clients . DSs  also process requests from MDSs  to provide details and location of the file contents on DSs .","Clients  are devices (such as PCs or other application servers) which have network file system client program. Clients  communicate with MDSs  to access, modify file system namespace, and obtain metadata information (including location of DSs and identifiers of files or data on DSs ). Clients  communicate with DSs  to read and write data or file contents.",{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 2","b":["0110","0210","0220","0230","0240","0250","0260","0270","0280","0280","0281","0282","0283","0284","0285","0286","0287","0288","0289","028","028","028","028","028","028","028","028","028","028","028"]},"The processor  represents a central processing unit that executes computer programs. The NFS protocol module  is responsible for both client and server functionality of NFS protocol (such as NFSV4.1). As a client, NFS protocol module  sends requests to DSs  and, as a server, provides service to metadata operations initiated from clients . The network interface  connects the MDS  to the network  for communication with DSs  and clients . The workload information table , the pre-fetched DS_FH table , the pre-fetched metadata table , and the pre-fetched MDS_FH table  are read and written to by the programs in system memory . The storage interface  connects the storage management module  to a storage device over the storage area network (SAN) or to an internal hard disk drive (HDD) for raw data storage. The storage management module  organizes raw data onto a metadata volume  which contains directories  and files  (representing file metadata and location of file contents). The directories  and files  are read and written to by file system program . Commands and data are communicated between the processor  and other components of the MDS  over a system bus .",{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 3","b":["0120","0310","0320","0330","0340","0350","0360","0310","0120","0100","0110","0130","0320","0110","0130","0330","0331","0320","0110","0360","0340","0340","0350","0351"]},{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 4","b":["0130","0410","0420","0430","0410","0420","0110","0120","0430","0130","0100","0110","0120"]},{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 5","b":["0110","0510","0520","0510"]},{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 6","b":["028","0640","0650","0610","0110","0620","0110","0120","0610","0630","0110","0110","0110","0130","0630","0610"]},"Referring back to , after classifying the list of metadata operations into categories in step , the following is performed in step . For each metadata operation category identified in step , the metadata operation processing is split into a plurality of stages. The task of splitting the processing into multiple stages is performed at the time of designing the MDS  itself. Step  provides an exemplary set of policies using which this task is performed. As per the first policy, operation processing is split into a stage if that part of the processing involves communication with a component external to the MDS . In addition, it is critical to design the logic of such a stage as an asynchronous client component and design the corresponding external component with which this stage communicates as an asynchronous server component (such as asynchronous DS program  and inter-MDS asynchronous server program G). The second policy in step  recommends splitting the part of processing into a stage if that part of processing is modularly (functionally) different from its preceding and succeeding processing logic. The policies listed in step  can be extended or modified based on the specific MDS  design requirements. As an example, a policy can be defined to split the processing into a stage if that part of processing needs a write to a heavily accessed hard disk drive. In step , the average processing time required for each stage is estimated either based on empirical analysis using previously profiled data on an MDS  with similar machine configuration or by theoretical hypothesis. The list of metadata operation categories, the list of stages for each category, and the estimated processing time are recorded in a table. This table is referred to as the work distribution table .",{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 7","b":["0286","0610","0710","0110","0710","0711"]},"The special type A  category consists of six stages. The second stage is pNFS manager  which is responsible for performing pNFS related metadata management including preparing requests to be sent to DSs . The estimated processing time for pNFS manager  is A_t2 . The third stage is MDS-DS asynchronous client  which is responsible for sending asynchronous requests to DSs . After the asynchronous request is acknowledged by DS , the resources allocated to that metadata operation are free to be used for the subsequent metadata operations. The estimated processing time for MDS-DS asynchronous client  is A_t3 . The fourth stage is asynchronous DS processing  performed on DSs . In this stage, DSs  processes asynchronous requests from MDS  and sends a response back to MDS  after processing completes. The estimated processing time for asynchronous DS processing  is DS_t4 . However, it is to be noted that during this time, no resource is allocated for the corresponding metadata operation on MDS . The fifth stage is DS response aggregator  which is responsible for receiving responses from plurality of DSs  and aggregating all the responses to a single context representing the corresponding metadata operation. The estimated processing time for DS response aggregator  is A_t5 . The last stage is secondary metadata processor  which is responsible for post processing on MDS  for special category type A  operations. The estimated processing time for secondary metadata processor A is t6 A.","The special type B  category consists of six stages. The first stage is primary metadata processor . The second stage is MDSC manager  which is responsible for performing MDS cluster management including preparing requests to be sent to other MDSs . The estimated processing time for MDSC manager  is B_t2 . The third stage is inter-MDS asynchronous client  which is responsible for sending asynchronous requests to one or more second MDSs . After the asynchronous request is acknowledged by a second MDS , the resources allocated to that metadata operation are free to be used for the subsequent metadata operations. The estimated processing time for inter-MDS asynchronous client  is B_t3 . The fourth stage is asynchronous inter-MDS processing  which is performed on one or more second MDSs . In this stage, the second MDS  processes asynchronous requests from first MDS  and sends a response back to first MDS  after processing completes. The estimated processing time for asynchronous inter-MDS processing  is MDS_t4 . Again, it is to be noted that during this time, no resource is allocated for the corresponding metadata operation on first MDS . The fifth stage is MDS response aggregator  which is responsible for receiving responses from a plurality of MDSs  and aggregating all the responses to a single context representing the corresponding metadata operation. The estimated processing time for MDS response aggregator  is B_t5 . The last stage is secondary metadata processor A which is responsible for post processing on MDS  for special category type B  operations. The estimated processing time for secondary metadata processor A is t6 A.",{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 8","b":["0810","0610","0820","0840","0620","0830","0850","0110","0630"]},{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 9","b":["0610","0810","0130","0110","0710"]},{"@attributes":{"id":"p-0079","num":"0078"},"figref":["FIG. 10","FIG. 21","FIG. 20"],"b":["028","0710","1010","1020","2110","2110","0710","1030","0810","1040","2010","2030","1050","028","0610","0130","1080","0620","028","1060","0630","028","1070"]},"In step , the operation context  is sent to the workload monitoring program . In step A, the thread is released. Other steps of the program are explained while describing processing of special type A & B category operations.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":["FIG. 11","FIG. 10","FIG. 11","FIG. 12","FIG. 13"],"b":["0620","0820","0130","0110","0710","1060","2030","028","0720","0730","0740"]},{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIG. 12","FIG. 21"],"b":["028","0720","1210","1220","2120","0720","1230","2030","1240","1250","2030","028","1260"]},{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 13","FIG. 21"],"b":["028","0730","1310","1320","2130","0730","1330","2010","1340","2030","028","1350","0120","1360"]},"Referring back to , the asynchronous DS program  on the DS  provides the asynchronous functionality for requests received from the MDS . After the request is processed on the DS , a response, which also includes the context ID , is sent to the MDS . The response from each DS  is received by the DS response aggregator program H on the MDS .  shows the process flow from the asynchronous DS processing stage  to the DS response aggregator stage  (), and then to the secondary metadata processor stage A () to produce a response to the client .",{"@attributes":{"id":"p-0085","num":"0084"},"figref":["FIG. 14","FIG. 21"],"b":["028","0750","1410","0120","1420","2140","0750","1430","028","2010","1440","2030","0120","2020","2010","028","1450","2020","2010","0120","1480","2030","028","1460","1470","2030","028","1480"]},{"@attributes":{"id":"p-0086","num":"0085"},"figref":["FIG. 15","FIG. 21"],"b":["028","07","0","1510","1520","2180","07","0","1530","0820","1540","0130","1550"]},{"@attributes":{"id":"p-0087","num":"0086"},"figref":["FIG. 16","FIG. 10","FIG. 16","FIG. 17","FIG. 18"],"b":["0630","0110","0110","0110","0820","0130","0110","0710","1070","2030","028","0760","0770","0780"]},{"@attributes":{"id":"p-0088","num":"0087"},"figref":"FIG. 17","b":["028","0760","1710","1720","2150","0760","1730","2030","1740","1750","2030","028","1760"]},{"@attributes":{"id":"p-0089","num":"0088"},"figref":["FIG. 18","FIG. 21"],"b":["028","0770","1810","1820","2160","0770","1830","2010","1840","2030","028","1850","0120","1860"]},"Referring back to , the inter-MDS asynchronous server program G on the second MDS  provides the asynchronous functionality for requests received from the first MDS . After the request is processed on the second MDS , a response, which also includes the context ID , is sent to the first MDS . The response from the second MDS  is received by the MDS response aggregator program I on the first MDS .  shows the process flow from the inter-MDS asynchronous server stage  to the MDS response aggregator stage  (), and then to the secondary metadata processor stage A () to produce a response to the client .",{"@attributes":{"id":"p-0091","num":"0090"},"figref":["FIG. 19","FIG. 21"],"b":["028","0790","1910","0110","1920","2170","0790","1930","028","2010","1940","2030","0110","1950","2030","028","1960","2030","028","1970"]},"Referring back to  of the exemplary steps performed by the secondary metadata processor program J to complete the secondary metadata processor A stage, in step , the secondary metadata processor program J iteratively checks if there is any incoming operation and loops back if NO. If YES, in step , a thread is assigned from a secondary metadata processor thread pool  (). If there is no thread available, the secondary metadata processor A stage stalls until a thread is available. Step  performs the rest of the compound operation processing. For the directory creation  metadata operation, GETFH, GETATTR, RESTOREFH, and GETATTR are processed. In step , a response is sent to the client  which initiated this metadata operation. In step , the thread is released.",{"@attributes":{"id":"p-0093","num":"0092"},"figref":"FIG. 20","b":["028","028","028","028","028","028","2010","2020","0110","2010","2030"]},{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 21","FIG. 10","FIG. 21","FIG. 22","FIG. 23","FIG. 24","FIG. 25"],"b":["0110","1090","2030","0282","2110","2120","2130","2140","2150","2160","2170","0710","0130","0282","0283","0284","0285","2110","2120","2130","2140","2150","2160","2170","2180"]},{"@attributes":{"id":"p-0095","num":"0094"},"figref":"FIG. 22","b":["0282","2210","0283","2220","2030","2230","2240","0284","0283","2260","2250","2260","2260","2220","0283"]},{"@attributes":{"id":"p-0096","num":"0095"},"figref":"FIG. 23","b":["0283","2310","2320","0610","0620","0630"]},{"@attributes":{"id":"p-0097","num":"0096"},"figref":"FIG. 24","b":["0284","2410","028","2420","0282","2430","0283","2431","2432","2440","0285","2450","0110"]},{"@attributes":{"id":"p-0098","num":"0097"},"figref":["FIG. 25","FIG. 26"],"b":["0285","2510","2431","2432","0284","2520","2530","028","028","028","028","028","028","028","028","2540","0285"]},{"@attributes":{"id":"p-0099","num":"0098"},"figref":"FIG. 26","b":["2610","0286","0280","2620","2630","0286","0280"]},"1. Total processing time for special type A category stages (Time).","2. Total processing time for special type B category stages (Time).","The next step after step  or step  is . In step , the thread allocation is calculated for each of the programs which process one of the stages for metadata operations. The programs are B, C, D, E, F, H, I, and J. The rationale behind the below thread allocation scheme is to allocate threads, across all the stages such that, all metadata operations are fairly processed. For example, allocating relatively more threads to the primary metadata processor stage  can improve normal metadata operation but impact the performance of special type A and special type B category metadata operations. The vice versa allocation not only impacts normal operation performance but also leads to underutilization of threads allocated to special category type A and type B stages. This is because, due to shortage of threads in the primary metadata processor stage , there are not enough metadata operations reaching special type A and type B stages. A fair and efficient way to allocate the threads across all the stages is by considering the following information:","1. Ratios of workload R1  and R2 .","2. Processing time (estimated as discussed above in step  of ) for each stage, that is, t.","3. The total processing time for each metadata operation category (see ), that is,","a. t1  for Normal category","b. (t1 +At2 +At3 +At5 +t6 A) for Special Type A category","c. (t1 +Bt2 +Bt3 +Bt5 +t6 A) for Special Type B category","4. Total number of threads allocated to MDS  (e.g.,  shown in ). This value is statically defined at the time of designing MDS  based on hardware configuration on which the MDS  would be deployed (number of CPUs, system memory, etc.), estimated maximum workload, etc.",{"@attributes":{"id":"p-0105","num":"0104"},"figref":["FIG. 27","FIG. 26"],"b":["2720","2710","2730","0110","2750","2740","2760","2710","40","30","30","0710","0710","0720","0730","0750","07","0","0710","0760","0770","0790","07","0"]},{"@attributes":{"id":"p-0106","num":"0105"},"figref":["FIG. 28","FIGS. 10","FIG. 21"],"b":["2810","12","15","17","19","2820","2830","2110","2180","2840","2190","2820","2830","2850","2110","2180","2190","2860","2850","2850","2860","2110","2180","2190","2820"]},"The description of a second embodiment of the present invention will mainly focus on the differences from the first embodiment.","In the first embodiment, although efficient resource allocation is made for fair servicing of different categories of metadata operations, special type A  and special type B category  may still suffer from network overhead due to MDS-DS or inter-MDS communication. In this embodiment, batch mode of execution is presented for certain metadata operations belonging to special type A and type B categories. This mode of execution can improve the performance of special type A and type B category operations which are executing in batch mode and the performance of normal category metadata operations significantly.","The batch mode execution needs to be designed separately for specific metadata operations. Each of such metadata operation may need specific data structures to be stored in the system memory . In this embodiment, designs for four metadata operations, namely, file creation , directory creation , \u201cget file layout\u201d , and \u201cget file attributes\u201d , are presented but extensions can be made to accommodate batch mode for other metadata operations. The decision to design these four operations to work in batch mode is made after studying the application workload during the design phase of MDS . In the presented embodiment, batch mode execution for four operations is designed after studying the typical behavior of HPC and scientific application workload.","For example, HPC applications tend to create large number of files and directories in parallel at the beginning of the application. Due to the involvement of multiple servers in processing these operations, it may lead to lower MDS performance during that time. Hence, to increase the performance of time consuming metadata operations such as file and directory creation, batch mode execution speculatively creates additional files or directories and fetches corresponding handles in advance. The subsequent file or directory creation operations complete much faster as the corresponding handles are locally available on the MDS  where the operation is received and there is no need for inter-server communication. In the present embodiment, the trigger for entering batch mode execution for file creation  and directory creation  is when the rate of receiving those operations is greater than a pre-defined threshold.","For \u201cget file layout\u201d  and \u201cget file attributes\u201d  batch mode execution, there is a challenge. As the operations are requesting specific file information, the MDS  would be unaware of which file information would be requested in the subsequent operations. However, after studying the typical HPC and scientific application workload, it is observed that large number of \u201cget file layout\u201d  or \u201cget file attributes\u201d  are received by the MDS  in parallel for files under a specific directory. Hence, batch mode execution speculatively fetches corresponding file information for files under a single directory. In the present embodiment, the trigger for entering batch mode execution for \u201cget file layout\u201d  and \u201cget file attributes\u201d  is when the rate of receiving those operations under a specific directory is greater than a pre-defined threshold.","Another example of batch mode execution could be deletion of file or directory. In a distributed environment, deletion operation may need clean-up of related information on some other server requiring an inter-server communication. However, in batch mode execution, such operations may be locally completed on the MDS  that receives the operation and a reply is sent back to the client . Such processing, commonly known as asynchronous processing, may involve delayed inter-server communication. For example, after a certain number of deletions, the MDS  may cumulatively perform a clean-up of all the deleted files or directories on other servers using a single network call. Batch mode execution for deletion may also need to take care of data inconsistencies across multiple servers. In the present invention, batch mode execution for file or directory deletion is not described in detail but has been mentioned here to illustrate one of many possible extensions of batch mode execution.",{"@attributes":{"id":"p-0113","num":"0112"},"figref":["FIG. 29","FIG. 5"],"b":["0110","2910","0510","0540","2920","0110","0110","0110","2930","0280","0110","0110","2920","2910"]},{"@attributes":{"id":"p-0114","num":"0113"},"figref":["FIG. 30","FIG. 36","FIG. 37","FIG. 30","FIG. 33","FIG. 33","FIG. 12","FIG. 17","FIG. 32","FIG. 34","FIG. 35"],"b":["0620","0630","0284","0710","0820","0830","0840","0850","0710","0110","0620","0630","0282","0283","0284","0287","0288","0289","028","0720","0760","0730","0770","0120","0110","0750","0790","0120","0110","0287","0288","0289","028","07","0","0130"]},{"@attributes":{"id":"p-0115","num":"0114"},"figref":["FIG. 31","FIG. 31","FIG. 10","FIG. 10","FIG. 10","FIG. 33","FIG. 32","FIG. 10"],"b":["028","0710","3110","1010","1040","1040","2030","3120","3130","3130","1050","10","0","3120","0287","0288","0289","0820","0287","0120","0120","3350","0830","0820","0289","0840","0288","3380","3390","0850","0840","0288","3150","3160","0820","0830","0287","0289","3160","1080","1090","10","0"]},"If NO in step , step  is performed to check if any similar batch mode operation was already sent to further stages which would get the desired information for this operation. To make this decision, step  needs to maintain a history of batch mode operations that are sent to further stages. The information that needs to be maintained depends on the operation itself. For example, if the operation is file creation  or directory creation , only the number of currently pre-fetched FH count is required. This number also includes the FH count that would be pre-fetched from an outstanding batch mode file creation  or directory creation  which was sent to further stages. If this pre-fetched file handle count is greater than a predefined threshold, then the result of step  is YES; otherwise the result is NO. The threshold can be a design choice or a configurable number at the time of system deployment.","If the operation is \u201cget file layout\u201d  or \u201cget file attributes\u201d , more details are required. Stage  needs to maintain a table containing a list of parent FHs for which the batch mode \u201cget file layout\u201d  or \u201cget file attributes\u201d  was initiated. The table needs to also contain, for each parent FH, a file identifier range of children whose metadata is already pre-fetched. If the current operation's parent FH is listed in this table and if the range of children that have been pre-fetched includes the current FH, then the result of step  result is YES; otherwise the result is NO.","If YES in step , the operation context  is stored in the pending operation context table A in step . If NO in step , the operation context  is sent to further processing stages depending upon the operation's category. For example, file creation  and \u201cget file layout\u201d  which belong to special type A category are sent to the pNFS manager program C, and directory creation  and \u201cget file attributes\u201d  which belong to special type B category are sent to the MDSC manager program D.","Referring back to , the operation context  with batch mode flag set to 1 is forwarded to either the pNFS manager  stage or the MDSC manager  stage and then to the MDS-DS asynchronous client  stage or the inter-MDS asynchronous client  stage.",{"@attributes":{"id":"p-0120","num":"0119"},"figref":["FIG. 32","FIG. 32","FIG. 13","FIG. 18","FIG. 13","FIG. 18","FIG. 13","FIG. 18"],"b":["028","028","0730","0790","028","028","3210","028","1310","1320","028","1810","1820","3220","028","0120","028","0110","3230","028","1340","1360","028","1840","1860"]},{"@attributes":{"id":"p-0121","num":"0120"},"figref":["FIG. 33","FIG. 29","FIG. 31","FIG. 34","FIG. 35"],"b":["028","028","028","028","2010","2020","2030","3310","3320","3330","0287","3340","3350","0289","3360","3370","0288","3380","3390","33","0","33","0"]},{"@attributes":{"id":"p-0122","num":"0121"},"figref":["FIG. 34","FIG. 34","FIG. 14","FIG. 14","FIG. 14","FIG. 14","FIG. 33","FIG. 33"],"b":["028","0750","3410","1410","1440","3420","0287","0288","0820","0120","0287","0840","2030","0288","3430","1450","1450","1480","1450","3440","3440","1460","028","3330","0820","3320","0840","3310"]},"In step , if no operation context list  is found, the program performs step  of .","In step , if an operation context list  is found, step  is performed. In step , for each operation context  in the operation context list , pre-fetched information from the corresponding pre-fetched information tables ( and ) are assigned. For example, if the metadata operation is file creation , for each operation context  in the operation context list , DS  FHs from the pre-fetched DS_FH table  are updated to the operation context's  DS response data. If the metadata operation is \u201cget file layout\u201d , for each operation context  in the operation context list , the pre-fetched metadata table  is looked up. First the operation context's  parent FH is matched in the parent FH  column. Then the operation context's  current FH is matched in the children FH  column. Then, the corresponding file layout is assigned to the operation context's  DS response data. In step , each operation context  in the operation context list  is sent to the secondary metadata processor program J for further processing. Then the program performs step  of .",{"@attributes":{"id":"p-0125","num":"0124"},"figref":["FIG. 35","FIG. 35","FIG. 19","FIG. 19","FIG. 33","FIG. 33"],"b":["028","0790","3510","1910","1960","3520","0289","0288","0830","0110","0289","0850","2030","0288","3520","028","3330","0830","3320","0850","3310"]},"In step , if no operation context list  is found, then the program performs step . In step , the program stores the pre-fetched information in the corresponding pre-fetched information table (, ) and then perform step  of .","In step , if an operation context list  is found, step  is performed. In step , for each operation context  in the operation context list , pre-fetched information from the asynchronous MDS response are assigned. For example, if the metadata operation is directory creation , for each operation context  in the operation context list , MDS  FH from the pre-fetched MDS_FH table  is updated to operation context's  MDS response data. If the metadata operation is \u201cget file attributes\u201d , for each operation context  in the operation context list , the pre-fetched metadata table  is looked up. First the operation context's  parent FH is matched under the parent FH  column. Then the operation context's  current FH is matched under the children FH  column. Next, the corresponding file attributes are assigned to the operation context's  MDS response data. In step , each operation context  in the operation context list  is sent to the secondary metadata processor program J for further processing. Then step  is performed where the pre-fetched information is stored in the corresponding pre-fetched information table (, ). However, only pre-fetched FHs which are unassigned in step  are stored in the pre-fetched MDS_FH table. The program then performs step  of .","From the description of  to , one can clearly see that most operations which are in batch execution mode need to be processed only in the primary metadata processor  stage. Periodically, a batch mode operation will be forwarded to further stages with batch mode flag set to 1 which will pre-fetch metadata information from the DS  or some other MDSs  in the anticipation that many similar metadata operations would follow. Similar metadata operations which follow will benefit from the pre-fetched metadata information.","Based on the thread allocation scheme used in first embodiment, most metadata operations which are executing in batch mode only use threads allocated to the primary metadata processor program B. The threads allocated to further stages are underutilized. Hence, a modified thread allocation scheme is presented in this embodiment.",{"@attributes":{"id":"p-0130","num":"0129"},"figref":"FIG. 36","b":["0283","3500","0610","0620","0630","3610","0282","0820","0830","0840","0850"]},{"@attributes":{"id":"p-0131","num":"0130"},"figref":["FIG. 37","FIG. 36"],"b":["0284","3710","3740","3770","37","0","0820","0830","0840","0850","3610","0283","3500","3720","3750","3780","37","0","3730","3760","3790","3700","0110"]},"Finally, step D is similar to steps  to  of . The only difference is that in step , the ratios are calculated considering non-batch mode special category operations (i.e., the number of metadata operation for a particular special category minus the number of metadata operations for that particular special category which have been selected to be executed in batch mode). The reason for this change is that, operations that are executing in batch mode complete processing in the primary metadata processor  stage itself (excluding an infrequent, speculatively executing batch operation). In other words, this change enforces the thread allocation scheme to consider operations executing in batch mode as a normal category operation. This scheme of thread allocation makes full use of otherwise underutilized threads in stages , , , , , , and A dedicated for batch mode operations of special type A and type B categories. This thread allocation scheme improves the performance of batch mode operations and normal category operations significantly.","The description of a third embodiment of the present invention will mainly focus on the differences from the previous embodiments.","In the first embodiment, clients  first access the metadata from MDSs  and then file contents directly from DSs . In other words, MDSs  are not participating in the file content access path. However, a client  may not have the capability to differentiate the process of metadata access and file contents access, i.e., to send metadata operations to MDSs  and send file content operations to DSs . Instead, a client  may send both metadata operations and file content operations to MDSs . Therefore, in the third embodiment, the MDSs  will serve both metadata access and file content access from clients .",{"@attributes":{"id":"p-0135","num":"0134"},"figref":"FIG. 38","b":["0110","0120","0130","0130","0110","0100","0110","0120","3810","0130","0110","0100","0110","0110","0120","3810","0130","0100","0110","0130","0100","0120","3810"]},"The description of a fourth embodiment of the present invention will mainly focus on the differences from the previous embodiments.","In the above described embodiments, an MDS  maintains location information of file contents , and a Client  uses the location information to access file contents  stored in DSs  through NFS protocol module . In the fourth embodiment, a MDS , a DS , and a Client  can also be equipped with a block-access protocol module, such as iSCSI (Internet Small Computer System Interface) and FCOE (Fibre Channel over Ethernet). An MDS  can store location information of file contents in such a way that a Client  can access file contents via either NFS protocol module or block-access protocol module.","Of course, the system configurations illustrated in  are purely exemplary of information systems in which the present invention may be implemented, and the invention is not limited to a particular hardware configuration. The computers and storage systems implementing the invention can also have known I\/O devices (e.g., CD and DVD drives, floppy disk drives, hard drives, etc.) which can store and read the modules, programs and data structures used to implement the above-described invention. These modules, programs and data structures can be encoded on such computer-readable media. For example, the data structures of the invention can be stored on computer-readable media independently of one or more computer-readable media on which reside the programs used in the invention. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include local area networks, wide area networks, e.g., the Internet, wireless networks, storage area networks, and the like.","In the description, numerous details are set forth for purposes of explanation in order to provide a thorough understanding of the present invention. However, it will be apparent to one skilled in the art that not all of these specific details are required in order to practice the present invention. It is also noted that the invention may be described as a process, which is usually depicted as a flowchart, a flow diagram, a structure diagram, or a block diagram. Although a flowchart may describe the operations as a sequential process, many of the operations can be performed in parallel or concurrently. In addition, the order of the operations may be re-arranged.","As is known in the art, the operations described above can be performed by hardware, software, or some combination of software and hardware. Various aspects of embodiments of the invention may be implemented using circuits and logic devices (hardware), while other aspects may be implemented using instructions stored on a machine-readable medium (software), which if executed by a processor, would cause the processor to perform a method to carry out embodiments of the invention. Furthermore, some embodiments of the invention may be performed solely in hardware, whereas other embodiments may be performed solely in software. Moreover, the various functions described can be performed in a single unit, or can be spread across a number of components in any number of ways. When performed by software, the methods may be executed by a processor, such as a general purpose computer, based on instructions stored on a computer-readable medium. If desired, the instructions can be stored on the medium in a compressed and\/or encrypted format.","From the foregoing, it will be apparent that the invention provides methods, apparatuses and programs stored on computer readable media for improving server resource utilization and performance of metadata operations. Additionally, while specific embodiments have been illustrated and described in this specification, those of ordinary skill in the art appreciate that any arrangement that is calculated to achieve the same purpose may be substituted for the specific embodiments disclosed. This disclosure is intended to cover any and all adaptations or variations of the present invention, and it is to be understood that the terms used in the following claims should not be construed to limit the invention to the specific embodiments disclosed in the specification. Rather, the scope of the invention is to be determined entirely by the following claims, which are to be construed in accordance with the established doctrines of claim interpretation, along with the full range of equivalents to which such claims are entitled."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 27","FIG. 26"]},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 31"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 33","FIG. 29"]},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 37"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 38"}]},"DETDESC":[{},{}]}
