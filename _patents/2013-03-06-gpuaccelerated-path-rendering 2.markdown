---
title: GPU-accelerated path rendering
abstract: This disclosure is directed to techniques for performing GPU-accelerated path rendering. A GPU is described that is configured to receive data indicative of a path segment of a path to be rendered, tessellate the path segment into a plurality of primitives, and render at least one of a fill area and a stroke area for the path segment based on the plurality of primitives. The techniques of this disclosure may be used to improve the performance of path rendering operations, to reduce memory bandwidth requirements needed to perform path rendering operations, and/or to reduce the memory footprint needed to perform path rendering operations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09619853&OS=09619853&RS=09619853
owner: QUALCOMM INCORPORATED
number: 09619853
owner_city: San Diego
owner_country: US
publication_date: 20130306
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["This application claims the benefit of U.S. Provisional Application No. 61\/755,312, filed Jan. 22, 2013, U.S. Provisional Application No. 61\/713,377, filed Oct. 12, 2012, and U.S. Provisional Application No. 61\/681,498, filed Aug. 9, 2012 the entire content of each of which is incorporated herein by reference.","This disclosure relates to graphics processing, and more particularly, to techniques for path rendering.","Path rendering may refer to the rendering of two-dimensional (2D) vector graphics paths (alternatively referred to herein as \u201cpaths\u201d), each of which may include one or more path segments. When a path includes two or more path segments, the individual path segments may be of the same type or of different types. The types of path segments may include, for example, a line, an elliptic arc, a quadratic B\u00e9zier curve, and a cubic B\u00e9zier curve. In some examples, the path segment types may be defined in accordance with a standard vector graphics application programming interface (API), such as, e.g., the Open Vector Graphics (OpenVG\u2122) API.","Path rendering may be implemented in a central processing unit (CPU). However, such an approach may be CPU-intensive, and may therefore limit the amount of CPU processing cycles available for other CPU tasks. Moreover, in some cases, a relatively large amount of data may need to be transferred to a graphics processing unit (GPU) to render the path segment at a desired level of detail. The relatively large amount of data may consume a significant amount of memory storage space when storing the data, and may consume a significant amount of memory bandwidth when transferring the data to the GPU.","This disclosure is directed to techniques for performing GPU-accelerated path rendering. A GPU designed in accordance with the GPU-accelerated path rendering techniques of this disclosure may be configured to tessellate a received path segment into a plurality of primitives (e.g., a plurality of line segments), and to render at least one of a fill area and a stroke area for the path segment based on the plurality of primitives. The techniques of this disclosure may provide partial-to-total GPU hardware acceleration for the execution of one or more path rendering operations, such as, e.g., path filling operations and path stroking operations.","In one example, this disclosure describes a method that includes receiving, with a GPU, data indicative of a path segment of a path to be rendered. The method further includes tessellating, with the GPU, the path segment into a plurality of primitives. The method further includes rendering, with the GPU, at least one of a fill area and a stroke area for the path segment based on the plurality of primitives.","In another example, this disclosure describes a device that includes a GPU configured to receive data indicative of a path segment of a path to be rendered. The GPU is further configured to tessellate the path segment into a plurality of primitives. The GPU is further configured to render at least one of a fill area and a stroke area for the path segment based on the plurality of primitives.","In another example, this disclosure describes an apparatus that includes means for receiving data indicative of a path segment of a path to be rendered. The apparatus further includes means for tessellating the path segment into a plurality of primitives. The apparatus further includes means for rendering at least one of a fill area and a stroke area for the path segment based on the plurality of primitives.","In another example, this disclosure describes a computer-readable storage medium storing instructions that, when executed, cause one or more processors to receive data indicative of a path segment of a path to be rendered. The computer-readable storage medium further stores instructions that, when executed, cause the one or more processors to tessellate the path segment into a plurality of primitives. The computer-readable storage medium further stores instructions that, when executed, cause the one or more processors to render at least one of a fill area and a stroke area for the path segment based on the plurality of primitives.","The details of one or more examples of the disclosure are set forth in the accompanying drawings and the description below. Other features, objects, and advantages of the disclosure will be apparent from the description and drawings, and from the claims.","This disclosure is directed to techniques for performing GPU-accelerated path rendering. Path rendering may refer to the rendering of two-dimensional (2D) vector graphics paths (alternatively referred to herein as \u201cpaths\u201d), each of which may include one or more path segments. When a path includes two or more path segments, the individual path segments may be of the same type or of different types. The types of path segments may include, for example, a line, an elliptic arc, a quadratic B\u00e9zier curve, and a cubic B\u00e9zier curve. In some examples, the path segment types may be defined in accordance with a standard vector graphics application programming interface (API), such as, e.g., the Open Vector Graphics (OpenVG\u2122) API.","GPUs typically implement a three-dimensional (3D) graphics pipeline that is designed to be compliant with one or more 3D graphics APIs. Because the prevailing 3D graphics APIs in use today do not require that compliant devices support path rendering commands, modern GPUs often provide little to no hardware acceleration for path rendering commands. For example, a typical 3D graphics pipeline implemented in a modern GPU may include a rasterizer that is designed to rasterize low-order, non-curved, 3D graphics primitives (such as, e.g., points, lines and triangles), but is not capable of directly rendering curved path rendering primitives (such as, e.g., elliptic arcs and B\u00e9zier curves).","One approach for path rendering may involve using a 3D GPU pipeline to provide partial GPU hardware acceleration for the execution of path rendering commands. This approach involves preprocessing a path segment with a central processing unit (CPU) in order to convert the path segment into one or more low-order, non-curved, 3D graphics primitives that can be rasterized by the GPU. For example, a CPU may tessellate a curved path segment (e.g., an elliptical arc or a B\u00e9zier curve) into a set of relatively small triangles that approximates the curvature of the path segment, and may cause the set of triangles to be rendered using the GPU. Such an approach, however, may be CPU-intensive, and may therefore limit the amount of CPU processing cycles available for other CPU tasks. Moreover, in some cases, a relatively large amount of triangles may be needed to render the path segment at a desired level of detail. The relatively large amount of triangles may consume a significant amount of memory storage space when storing the data, and may consume a significant amount of memory bandwidth when transferring the data to the GPU.","Another approach for providing partial-to-total GPU hardware acceleration for the execution of path rendering commands may involve modifying the architecture of the GPU to support a dedicated, hardware-accelerated, path rendering pipeline. However, because the prevailing 3D graphics APIs (e.g., the Microsoft\u00ae DirectX\u00ae 11 (DX) API) do not require a GPU architecture to include a dedicated path rendering pipeline, such an approach does not result in a cross-platform, hardware-accelerated, path rendering solution that would be guaranteed to be supported by all GPUs which are compliant with a particular 3D graphics API (e.g., the DX 11 API).","The path rendering techniques in this disclosure may provide a GPU hardware-accelerated path rendering solution where the GPU is configured to tessellate a received path segment into a plurality of line segments, and to render the tessellated line segments using a 3D graphics pipeline. By using the GPU to tessellate a path segment into line segments, the burden of preprocessing path segments is lifted from the CPU, thereby freeing up processing resources for other CPU tasks. Moreover, the GPU may, in some examples, utilize a highly-parallel, modern GPU tessellation architecture to perform the tessellation operations, which may, in some examples, allow the GPU to render a path segment in a more efficient manner than the CPU. In addition, because the tessellation occurs in the GPU, rather than in the CPU, a multitude of tessellated primitives do not need to be stored in system memory and do not need to be passed from the CPU to the GPU, thereby reducing the memory footprint needed for path rendering as well as the memory bandwidth needed for path rendering.","In some examples, a GPU designed in accordance with the techniques of this disclosure may be configured to tessellate and render a path segment using a graphics architecture that is specified by a particular 3D graphics API, such as, e.g., the DX 11 API, without requiring any additional hardware components and\/or modifications to the graphics architecture. By utilizing only architectural features likely or guaranteed to be present by a particular 3D graphics API when performing path rendering in such examples, a cross-platform, hardware-accelerated, path rendering solution may be realized that is capable of being implemented on any device that is compliant with the 3D graphics API. For example, the techniques of this disclosure may, in some examples, provide a path rendering solution that is capable of being used on any DirectX\u00ae 11 compliant graphics hardware. In some examples, dashing and cusp handling may be disabled in order to implement a DirectX\u00ae 11 path rendering solution that utilizes the DirectX\u00ae 11 architecture without any modifications.","Path rendering may be divided into two main operations: (1) filling a path segment; and (2) stroking a path segment. In some examples, one or both of the filling and stroking operations may be performed to completely render a path. Conceptually, the filling operation may correspond to filling the interior region of a path segment with a specified fill color. The stroking operation may conceptually correspond to \u201cwidening\u201d the edges of a path segment using a straight-line pen held perpendicularly to the path. In some examples, the stroking operation may also involve applying various types of end caps to the ends of a path and\/or applying various types of joins between the endpoints of interior path segments of a path.","After a path segment has been tessellated, a GPU that implements the path rendering techniques of this disclosure may be configured to generate 3D geometry corresponding to the tessellated path segments that allows one or both of a fill area for the path segment and a stroke area for the path segment to be rendered by the GPU. The 3D geometry may include low-order, non-curved, 3D graphics primitives (e.g., triangles) that are capable of being rasterized by existing 3D rasterization engines. By rendering the fill areas and\/or stroke areas for a path segment based on the 3D geometry that is generated by a GPU from a plurality of tessellated line segments that approximate a path to be rendered, a 3D GPU pipeline may be used to provide either a 100% or a nearly 100% GPU solution for the execution of filling and stroking operations.",{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 1","b":["2","2"]},"As illustrated in the example of , computing device  includes a user interface , a CPU , a memory controller , a memory , a graphics processing unit (GPU) , a GPU cache , a display interface , a display  and bus . User interface , CPU , memory controller , GPU  and display interface  may communicate with each other using bus . It should be noted that the specific configuration of buses and communication interfaces between the different components shown in  is merely exemplary, and other configurations of computing devices and\/or other graphics processing systems with the same or different components may be used to implement the techniques of this disclosure.","CPU  may comprise a general-purpose or a special-purpose processor that controls operation of computing device . A user may provide input to computing device  to cause CPU  to execute one or more software applications. The software applications that execute on CPU  may include, for example, an operating system, a word processor application, an email application, a spread sheet application, a media player application, a video game application, a graphical user interface application or another program. The user may provide input to computing device  via one or more input devices (not shown) such as a keyboard, a mouse, a microphone, a touch pad or another input device that is coupled to computing device  via user interface .","The software applications that execute on CPU  may include one or more graphics rendering instructions that instruct GPU  to cause the rendering of graphics data to display . In some examples, the software instructions may conform to a graphics application programming interface (API), such as, e.g., an Open Graphics Library (OpenGL\u00ae) API, an Open Graphics Library Embedded Systems (OpenGL ES\u00ae) API, a Direct3D\u00ae API, a DirectX\u00ae API, a RenderMan\u00ae API, a WebGL\u2122 API, or any other public or proprietary standard graphics API. In order to process the graphics rendering instructions, CPU  may issue one or more graphics rendering commands to GPU  to cause GPU  to perform some or all of the rendering of the graphics data. In some examples, the graphics data to be rendered may include a list of graphics primitives, e.g., points, lines, triangles, quadrilaterals, triangle strips, patches, etc. In further examples, the graphics data to be rendered may include one or more path rendering primitives, such as, e.g., line segments, elliptic arcs, quadratic B\u00e9zier curves, and cubic B\u00e9zier curves.","Memory controller  facilitates the transfer of data going into and out of memory . For example, memory controller  may receive memory read requests and memory write requests from CPU  and\/or GPU , and service such requests with respect to memory  in order to provide memory services for the components in computing device . Memory controller  is communicatively coupled to memory . Although memory controller  is illustrated in the example computing device  of  as being a processing module that is separate from each of CPU , GPU , and memory , in other examples, some or all of the functionality of memory controller  may be implemented on one or more of CPU , GPU , and memory .","Memory  may store program modules and\/or instructions that are accessible for execution by CPU  and\/or data for use by the programs executing on CPU . For example, memory  may store user applications and graphics data associated with the applications. Memory  may also store information for use by and\/or generated by other components of computing device . For example, memory  may act as a device memory for GPU  and may store data to be operated on by GPU  as well as data resulting from operations performed by GPU . For example, memory  may store any combination of path data, path segment data, surfaces, texture buffers, depth buffers, stencil buffers, vertex buffers, frame buffers, or the like. In addition, memory  may store command streams for processing by GPU . For example, memory  may store path rendering commands, 3D graphics rendering commands, and\/or general-purpose GPU computing commands. Memory  may include one or more volatile or non-volatile memories or storage devices, such as, for example, random access memory (RAM), static RAM (SRAM), dynamic RAM (DRAM), synchronous dynamic random access memory (SDRAM), read-only memory (ROM), erasable programmable ROM (EPROM), electrically erasable programmable ROM (EEPROM), Flash memory, a magnetic data media or an optical storage media.","GPU  may be configured to execute commands that are issued to GPU  by CPU . The commands executed by GPU  may include graphics commands, draw call commands, GPU state programming commands, memory transfer commands, general-purpose computing commands, kernel execution commands, etc.","In some examples, GPU  may be configured to perform graphics operations to render one or more graphics primitives to display . In such examples, when one of the software applications executing on CPU  requires graphics processing, CPU  may provide graphics data to GPU  for rendering to display  and issue one or more graphics commands to GPU . The graphics commands may include, e.g., draw call commands, GPU state programming commands, memory transfer commands, blitting commands, etc. The graphics data may include vertex buffers, texture data, surface data, etc. In some examples, CPU  may provide the commands and graphics data to GPU  by writing the commands and graphics data to memory , which may be accessed by GPU .","In further examples, GPU  may be configured to perform general-purpose computing for applications executing on CPU . In such examples, when one of the software applications executing on CPU  decides to off-load a computational task to GPU , CPU  may provide general-purpose computing data to GPU , and issue one or more general-purpose computing commands to GPU . The general-purpose computing commands may include, e.g., kernel execution commands, memory transfer commands, etc. In some examples, CPU  may provide the commands and general-purpose computing data to GPU  by writing the commands and graphics data to memory , which may be accessed by GPU .","GPU  may, in some instances, be built with a highly-parallel structure that provides more efficient processing of vector operations than CPU . For example, GPU  may include a plurality of processing elements that are configured to operate on multiple vertices, control points, pixels and\/or other data in a parallel manner. The highly parallel nature of GPU  may, in some instances, allow GPU  to render graphics images (e.g., GUIs and two-dimensional (2D) and\/or three-dimensional (3D) graphics scenes) onto display  more quickly than rendering the images using CPU . In addition, the highly parallel nature of GPU  may allow GPU  to process certain types of vector and matrix operations for general-purposed computing applications more quickly than CPU .","GPU  may, in some examples, be integrated into a motherboard of computing device . In other instances, GPU  may be present on a graphics card that is installed in a port in the motherboard of computing device  or may be otherwise incorporated within a peripheral device configured to interoperate with computing device . In further instances, GPU  may be located on the same microchip as CPU  forming a system on a chip (SoC). GPU  may include one or more processors, such as one or more microprocessors, application specific integrated circuits (ASICs), field programmable gate arrays (FPGAs), digital signal processors (DSPs), or other equivalent integrated or discrete logic circuitry.","In some examples, GPU  may be directly coupled to GPU cache . Thus, GPU  may read data from and write data to GPU cache  without necessarily using bus . In other words, GPU  may process data locally using a local storage, instead of off-chip memory. This allows GPU  to operate in a more efficient manner by eliminating the need of GPU  to read and write data via bus , which may experience heavy bus traffic. In some instances, however, GPU  may not include a separate cache, but instead utilize memory  via bus . GPU cache  may include one or more volatile or non-volatile memories or storage devices, such as, e.g., random access memory (RAM), static RAM (SRAM), dynamic RAM (DRAM), erasable programmable ROM (EPROM), electrically erasable programmable ROM (EEPROM), Flash memory, a magnetic data media or an optical storage media.","CPU  and\/or GPU  may store rendered image data in a frame buffer that is allocated within memory . The rendered image data may include rendered fill areas and stroke areas for a path segment to be rendered. Display interface  may retrieve the data from the frame buffer and configure display  to display the image represented by the rendered image data. In some examples, display interface  may include a digital-to-analog converter (DAC) that is configured to convert the digital values retrieved from the frame buffer into an analog signal consumable by display . In other examples, display interface  may pass the digital values directly to display  for processing.","Display  may include a monitor, a television, a projection device, a liquid crystal display (LCD), a plasma display panel, a light emitting diode (LED) array, a cathode ray tube (CRT) display, electronic paper, a surface-conduction electron-emitted display (SED), a laser television display, a nanocrystal display or another type of display unit. Display  may be integrated within computing device . For instance, display  may be a screen of a mobile telephone handset or a tablet computer. Alternatively, display  may be a stand-alone device coupled to computer device  via a wired or wireless communications link. For instance, display  may be a computer monitor or flat panel display connected to a personal computer via a cable or wireless link.","Bus  may be implemented using any combination of bus structures and bus protocols including first, second and third generation bus structures and protocols, shared bus structures and protocols, point-to-point bus structures and protocols, unidirectional bus structures and protocols, and bidirectional bus structures and protocols. Examples of different bus structures and protocols that may be used to implement bus  include, e.g., a HyperTransport bus, an InfiniBand bus, an Advanced Graphics Port bus, a Peripheral Component Interconnect (PCI) bus, a PCI Express bus, an Advanced Microcontroller Bus Architecture (AMBA) Advanced High-performance Bus (AHB), an AMBA Advanced Peripheral Bus (APB), and an AMBA Advanced eXentisible Interface (AXI) bus. Other types of bus structures and protocols may also be used.","According to this disclosure, GPU  may be configured to provide partial-to-total GPU-hardware acceleration for the execution of various path rendering commands. For example, CPU  may issue one or more path rendering commands to GPU , and GPU  may execute the path rendering commands. As one example, CPU  may issue to GPU  one or more path filling commands that instruct GPU  to perform a path filling operation, and GPU  may execute the path filling commands. As another example, CPU  may issue to GPU  one or more path stroking commands that instruct GPU  to perform a path stroking operation, and GPU  may execute the path stroking commands.","In some examples, GPU  may be configured to receive data indicative of a path segment of a path to be rendered, tessellate the path segment into a plurality of primitives, and render at least one of a fill area and a stroke area for the path segment based on the plurality of primitives. The GPU may render a fill area for the path segment when performing a fill operation, and may render a stroke area for the path segment when performing a stroke operation. The plurality of primitives, in some examples, may be a plurality of line segments.","In some examples, GPU  may use a two-pass rendering approach to perform a path filling operation. For example, as part of a first rendering pass, GPU  may receive data indicative of a path segment of a path to be rendered, tessellate the path segment into a plurality of line segments, and generate a plurality of triangle primitives based on the plurality of line segments. GPU  may generate each of the plurality of triangle primitives based on a respective one of the plurality of line segments. GPU  may render each of the plurality of triangle primitives into a common stencil buffer such that the common stencil buffer stores data indicative of which pixels are inside of the fill area for the path segment. After rendering the primitives into the common stencil buffer, GPU  may perform a second rendering pass. During the second rendering pass, GPU  may render one or more primitives that encompass the pixels that are inside of the fill area for the path segment based on the data stored in the stencil buffer and a fill color in order to generate a rasterized version of the fill area for the path segment. In this manner, GPU  may provide GPU-hardware acceleration for the performance of path filling operations.","To generate the plurality of triangle primitives for the path filling operation, GPU  may, in some examples, generate a plurality of triangle primitives such that each of the triangle primitives has a common vertex that is the same for all of the triangle primitives generated for a path segment. In such examples, GPU  may generate the plurality of triangle primitives such that each of the triangle primitives has two additional vertices (i.e., two vertices in addition to the common vertex) that correspond to the endpoints of a respective one of the plurality of line segments. Each additional vertex may correspond to a respective one of the endpoints of a corresponding line segment.","To render each of the plurality of triangle primitives into a common stencil buffer, GPU  may use one of the following techniques. According to a first technique, GPU  may, for each of the plurality of triangle primitives, invert one or more values in the stencil buffer that correspond to the respective triangle primitive. According to a second technique, GPU  may, for each of the plurality of triangle primitives, increment one or more values in the stencil buffer that correspond to the respective triangle primitive if a vertex order for the respective triangle primitive is oriented in a clockwise direction, and decrement values in the stencil buffer that correspond to the respective triangle primitive if a vertex order for the respective triangle primitive is oriented in a counter-clockwise direction.","In some cases, GPU  may use one or both of the following techniques to perform the path filling operation. According to a first technique, GPU  may tessellate the path segment into a plurality of line segments using a fixed-function tessellation engine of GPU  and a domain shader program executing on a programmable shader unit of GPU . According to a second technique, GPU  may generate the plurality of triangle primitives using a geometry shader program executing on a programmable shader unit of GPU . Using one or more of the tessellation engine, the domain shader, and the geometry shader of GPU  to perform the path filling operation may allow the path filling operation to be performed, in some examples, using a GPU that is compliant with an on-chip, tessellation-enabled, 3D graphics API, such as, e.g., the DX 11 API, without requiring modification of the API or modification of the graphics architecture specified by the API.","In further examples, GPU  may use a single-pass rendering approach to perform a path stroking operation. For example, GPU  may receive data indicative of a path segment of a path to be rendered, tessellate the path segment into a plurality of line segments, and generate a plurality of triangle primitives that spatially correspond to a stroke area for the path segment based on the plurality of line segments. For each of the plurality of line segments, GPU  may generate one or more primitives (e.g., triangle primitives) that spatially correspond to a stroke area for the respective line segment, and render the one or more primitives for the respective line segment based on a stroke color to generate a rasterized version of the stroke area for the path segment. In this manner, GPU  may provide GPU-hardware acceleration for the performance of path stroking operations.","To generate one or more primitives (e.g., triangle primitives) that spatially correspond to a stroke area of a line segment, GPU  may, in some examples, generate a plurality of normal vectors for the respective line segment. Each of the normal vectors may be indicative of a direction that is perpendicular to a tangent of the path segment at a respective one of a plurality of points along the path segment. Each of the plurality of points along the path segment may correspond to a respective one of the endpoints of the respective line segment. GPU  may determine corner points of a stroke area for the respective line segment based on the plurality of normal vectors and a stroke width. GPU  may generate the one or more primitives that spatially correspond to the stroke area for the respective line segment based on the corner points of the stroke area.","In some cases, GPU  may use one or more of the following techniques to perform the path stroking operation. According to a first technique, GPU  may tessellate the path segment into a plurality of line segments using a fixed-function tessellation engine of GPU  and a domain shader program executing on a programmable shader unit of GPU . According to a second technique, GPU  may generate the one or more primitives using a geometry shader program executing on a programmable shader unit of GPU . According to a third technique, GPU  may generate the plurality of normal vectors using a domain shader program executing on a programmable shader unit of GPU . Using one or more of the tessellation engine, the domain shader, and the geometry shader of GPU  to perform the path stroking operation may allow the path stroking operation to be performed, in some examples, using a GPU that is compliant with an on-chip, tessellation-enabled, 3D graphics API, such as, e.g., the DX 11 API, without requiring modification of the API or modification of the graphics architecture specified by the API.","The path rendering techniques described in this disclosure may be implemented in any of the components of computing device  illustrated in  including, e.g., CPU , GPU , and memory . In some examples, all or almost all of the path rendering techniques may be implemented in GPU  (e.g., in a graphics pipeline of GPU ). In additional examples, CPU  may implement techniques for configuring the state of the graphics pipeline and binding shader programs to the graphics pipeline to implement a path rendering pipeline in GPU  that performs the path rendering techniques of this disclosure. In further examples, CPU  may be configured to place data indicative of a path to be rendered into one or more buffers (e.g., one or more vertex buffers) that may be accessed by GPU  to render one or more paths.",{"@attributes":{"id":"p-0062","num":"0061"},"figref":["FIG. 2","FIG. 1","FIG. 2"],"b":["6","12","10","2","6","12","10","12","6","10","12","6","12","6","12","6","12","6"]},"CPU  is configured to execute a software application , a graphics API , a GPU driver  and an operating system . Software application  may include one or more instructions that cause graphics images to be displayed and\/or one or more instructions that cause a non-graphics task (e.g., a general-purposed computing task) to be performed on GPU . Software application  may issue instructions to graphics API . Graphics API  may be a runtime service that translates the instructions received from software application  into a format that is consumable by GPU driver . GPU driver  receives the instructions from software application , via graphics API , and controls the operation of GPU  to service the instructions. For example, GPU driver  may formulate one or more commands , place the commands  into memory , and instruct GPU  to execute the commands . In some examples, GPU driver  may place the commands  into memory  and communicate with GPU  via operating system , e.g., via one or more system calls.","GPU  includes a command engine  and one or more processing units . In some examples, the one or more processing units  may form and\/or implement a 3D graphics rendering pipeline, e.g., a DX 11 graphics rendering pipeline (i.e., a 3D graphics pipeline that is compliant with the DX 11 graphics API).","Command engine  is configured to receive commands from CPU  (e.g., via memory ) and to cause GPU  to execute the commands. In response to receiving a state command, command engine  may be configured to set one or more state registers in GPU  to particular values based on the state command, and\/or to configure one or more of the fixed-function processing units  based on the state command. In response to receiving a draw call command, command engine  may be configured to cause processing units  to render one or more path segments based on data that defines the geometry of the one or more path segments to be rendered and based on data indicative of the type of path segment for each of the path segments to be rendered. In some examples, the data that defines the geometry of the one or more path segments to be rendered and the data that defines the type of path segment for each of the path segments may be stored in one or more vertex data structures in memory . Command engine  may also receive shader program binding commands, and load particular shader programs into one or more of the programmable processing units  based on the shader program binding commands.","Processing units  may include one or more processing units, each of which may be a programmable processing unit or a fixed-function processing unit. A programmable processing unit may include, for example, a programmable shader unit that is configured to execute one or more shader programs that are downloaded onto GPU  from CPU . A shader program, in some examples, may be a compiled version of a program written in a high-level shading language, such as, e.g., an OpenGL\u00ae Shading Language (GLSL), a High Level Shading Language (HLSL), a C for Graphics (Cg) shading language, etc. In some examples, a programmable shader unit may include a plurality of processing units that are configured to operate in parallel, e.g., an SIMD pipeline. A programmable shader unit may have a program memory that stores shader program instructions and an execution state register, e.g., a program counter register that indicates the current instruction in the program memory being executed or the next instruction to be fetched. The programmable shader units in processing units  may include, for example, vertex shader units, pixel shader units, geometry shader units, hull shader units, domain shader units, tessellation control shader units, tessellation evaluation shader units, compute shader units, and\/or unified shader units.","A fixed-function processing unit may include hardware that is hard-wired to perform certain functions. Although the fixed function hardware may be configurable, via one or more control signals for example, to perform different functions, the fixed function hardware typically does not include a program memory that is capable of receiving user-compiled programs. In some examples, the fixed function processing units in processing units  may include, for example, processing units that perform raster operations, such as, e.g., depth testing, scissors testing, alpha blending, etc.","Memory  may store path data  and one or more commands . In some examples, path data  may be stored as a plurality of vertices (or control points) in one or more vertex buffers allocated in memory . In some examples, the path data may be stored in a patch list data structure (e.g., a four control point patch list). Commands  may be stored in one or more command buffers (e.g., a ring buffer). CPU  (e.g., GPU driver  via operating system ) may place path data  and commands  into memory  for consumption by GPU . GPU  (e.g., command engine ) may retrieve and execute commands  stored in memory .","In examples where path data  is stored as vertices (e.g., control points), the vertices may include one or more attributes that geometrically define a path segment to be rendered. For example, for a line, the vertices in the patch control list may include data indicative of coordinates for the endpoints of the line (e.g., (x0, y0) and (x1, y1)). For a cubic B\u00e9zier curve, the vertices in the patch control list may include data indicative of the coordinates of the four control points that define the curve (e.g., (x0, y0), (x1, y1), (x2, y2), (x3, y3)). For a quadratic B\u00e9zier curve, the vertices in the patch control list may include data indicative of coordinates for three control points instead of four control points. For elliptic arcs, the vertices in the patch control list may include data indicative of an endpoint parameterization of the elliptic arc or data indicative of a center parameterization of the elliptic arc.","In some cases, the one or more attributes that geometrically define the path segment to be rendered may be resolution-independent. In other words, the attributes that geometrically define the path segment may be independent of the amount of tessellation to be performed when rendering the path segment and\/or independent of the amount of vertices to be generated when rendering the path segment.","CPU  may also place data indicative of the type of path segment to be rendered (i.e., a \u201cpath segment type indicator\u201d) into one or more otherwise unused vertex attributes in the vertex buffer. In some examples, the different path segment types may correspond to a set of path segment types that are defined by a vector graphics API and are available for use by software application . In some examples, the different path segment types may correspond to a set of path segment types that are defined by the OpenVG\u2122 API.","Commands  may include one or more state commands and\/or one or more draw call commands. A state command may instruct GPU  to change one or more of the state variables in GPU , such as, e.g., the draw color, the fill color, the stroke color, etc. In some examples, the state commands may include path rendering state commands that are configured to set one or more state variables associated with rendering a path. For example, the state commands may include a paint mode command that is configured to indicate whether a path to be rendered is to be filled, stroked, or both. As another example, the state commands may include a fill color command that specifies a color to be used for filling operations and\/or a stroke color command that specifies a color to be used for stroking operations. As a further example, the state commands may specify one or more parameters for the stroke operation, such as, e.g., a stroke width, an end cap style (e.g., round, square), a line join style (e.g., miter, round, bevel), a miter limit, etc. In some examples, in addition to or in lieu of using a state command to set one or more state parameters, one or more of the state parameters may be set by using a draw call command or by placing state indicators into a vertex buffer that contains path data .","A draw call command may instruct GPU  to render the geometry defined by a group of one or more vertices (e.g., defined in a vertex buffer) stored in memory . In some examples, the draw call command may invoke GPU  to render all of the vertices stored in a defined section (e.g., a vertex buffer or path data ) of memory . In other words, once GPU  receives the draw call command, control is passed to GPU  for rendering the geometry and primitives represented by the vertices in the defined section (e.g., vertex buffer or path data ) of memory .","The draw call commands may include one or both of 3D draw call commands and path rendering draw call commands. For 3D rendering draw call commands, the geometry defined by the group of one or more vertices in the vertex buffer may correspond to one or more 3D graphics primitives to be rendered (e.g., points, lines, triangles, quadrilaterals, triangle strips, patches, etc.), and the 3D rendering draw call command may instruct GPU  to render the one or more 3D graphics primitives. For path rendering draw call commands, the geometry defined by the group of one or more vertices in the vertex buffer may correspond to one or more path primitives to be rendered (e.g., line segments, elliptic arcs, quadratic B\u00e9zier curves, and cubic B\u00e9zier curves, etc.), and the path rendering draw call command may instruct GPU  to render the one or more path primitives. In some examples, the path primitives capable of being rendered by GPU  may correspond to the different types of path segments described in this disclosure.","In some examples, the path rendering techniques described in this disclosure may be implemented in any of the components shown in  including, e.g., graphics API , GPU driver , command engine  and processing units . In further examples, all or almost all of the path rendering techniques may be implemented in a graphics pipeline in GPU  formed by processing units . In additional examples, software application , graphics API  and\/or GPU driver  of CPU  may implement techniques for configuring the state of the graphics pipeline and binding shader programs to the graphics pipeline to implement a path rendering pipeline in GPU  that performs the path rendering techniques described in this disclosure. In further examples, software application , graphics API  and\/or GPU driver  of CPU  may be configured to place data indicative of a path to be rendered into one or more buffers (e.g., one or more vertex buffers) that may be accessed by GPU  to render one or more paths.",{"@attributes":{"id":"p-0076","num":"0075"},"figref":["FIG. 3","FIG. 3"],"b":["40","40","42","44","46","48","50","52","54","56","58","60","48","50","52","62","40"]},"Resources block  may correspond to one or more memory resources used by graphics pipeline , such as, e.g., one or more textures and\/or one or more buffers. Resources block  may store input data to be processed by one or more of the processing stages in graphics pipeline  and\/or output data from one or more of the processing stages in graphics pipeline . As one example, resources block  may store a stencil buffer used for performing a path filling operation as described in this disclosure. As another example, resources block  may store a frame buffer that holds a rasterized version of a fill area for a path segment and\/or a rasterized version of a stroke area for a path segment as described in this disclosure. In some examples, the memory resources that form resources block  may reside in memory  and\/or GPU cache  of computing device .","The processing stages depicted in  with straight corners represent fixed-function processing stages, and the processing stages depicted in  with rounded corners represent programmable processing stages. For example, as shown in , input assembler , tessellator , rasterizer  and output merger  are fixed-function processing stages, and vertex shader , hull shader , domain shader , geometry shader  and pixel shader  are programmable processing stages. Each of the programmable stages may be configured to execute a shader program of a particular type. For example, vertex shader  may be configured to execute a vertex shader program, hull shader  may be configured to execute a hull shader program, etc. Each of the different types of shader programs may execute either on a common shader unit of GPU  or on one or more dedicated shader units that are dedicated to executing shader programs of one or more particular types.","As shown in , input assembler , vertex shader , hull shader , domain shader , geometry shader , pixel shader  and output merger  are communicatively coupled to resources block . Input assembler , vertex shader , hull shader , domain shader , geometry shader , pixel shader  and output merger  are configured to retrieve and\/or to receive input data from resources block . Geometry shader  and output merger  are configured to write output data to resources block . The above-described configuration of communication between the processing stages in graphics pipeline  and resources block  is merely one example of how the communication may be configured between the processing stages of graphics pipeline  and resources block . In other examples, more or less uni-directional and\/or bi-directional communication channels may be provided between the processing stages of graphics pipeline  and resources block .","Additional background information regarding the general operation of the DirectX\u00ae 11 graphics pipeline may be found in \u201cGraphics Pipeline,\u201d Programming Guide for Direct3D 11, Windows, Dev Center\u2014Desktop, the entire content of which is incorporated herein by reference. Further information regarding the general operation of the DirectX\u00ae 11 graphics pipeline may be found in Zink et al., \u201cPractical Rendering & Computation with Direct3D\u00ae 11,\u201d CRC Press (2011), the entire content of which is incorporated herein by reference.","As discussed above, the two main path rendering operations are: (1) filling a path segment; and (2) stroking a path segment. Solutions for performing each of these operations with graphics rendering pipeline  (e.g., the DirectX\u00ae 11 graphics pipeline) will now be described.","The filling operation may utilize a two-pass approach that may generally involve the following steps:","Pass 1\n\n","Pass 2\n\n","For the first pass, CPU  may place data indicative of a path segment to be rendered into one or more vertices of a vertex buffer. In some examples, the vertex buffer may correspond to path data  shown in . The primitive topology for the vertices in the vertex buffer may be, in some examples, a patch control list. For a line, the vertices in the patch control list may include data indicative of coordinates for the endpoints of the line (e.g., (x0, y0) and (x1, y1)). For a cubic B\u00e9zier curve, the vertices in the patch control list may include data indicative of the coordinates of the four control points that define the curve (e.g., (x0, y0), (x1, y1), (x2, y2), (x3, y3)). For a quadratic B\u00e9zier curve, the vertices in the patch control list may include data indicative of coordinates for three control points that define the curve instead of four control points. For elliptic arcs, the vertices in the patch control list may include data indicative of an endpoint parameterization of the elliptic arc or data indicative of a center parameterization of the elliptic arc. CPU  may also place data indicative of the type of path segment to be rendered into an otherwise unused vertex attribute of the patch control list.","One example format for the path data  received and used by GPU  to perform path rendering will now be described. It should be understood that this is merely one example of how data indicative of a path to be rendered and\/or a path segment to be rendered may be provided by CPU  to GPU  and that other examples are possible and within the scope of this disclosure. In this example, GPU  receives each path segment as a four (4) control point patch list primitive. Each of the vertices (e.g., control points) in the patch list, in this example, includes three (3) float attributes that define attributes for the respective vertex (e.g., control point).","For a line path segment, the input path data may take the following form or a similar form:",{"@attributes":{"id":"p-0088","num":"0091"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","X0,","Y0,","2.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","X1,","Y1,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) },"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"The remaining vertices and attributes in this example may be unused and\/or may be used to indicate other attributes for the path segment. Other attributes for the path segment may include, e.g., whether the path segment is the beginning or end of an open path, whether the path segment should be displayed for the path, whether an endcap should be placed on either end of the path segment, what type of endcap should be used if any, whether a join should be placed on either end of the path segment, and what type of join to use if any.","The input path data for a cubic B\u00e9zier path segment may take the following form or a similar form:",{"@attributes":{"id":"p-0091","num":"0094"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","X0,","Y0,","3.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","X1,","Y1,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","X2,","Y2,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","X3,","Y3,","1.0f ) },"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"Similar input may be used for a quadratic B\u00e9zier path segment except that three control points may be provided instead of four control points, and the path segment type indicator may be different to distinguish the primitive from a cubic B\u00e9zier path segment. For example, the input path data for a quadratic B\u00e9zier path segment may take the following form or a similar form:",{"@attributes":{"id":"p-0093","num":"0096"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","X0,","Y0,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","X1,","Y1,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","X2,","Y2,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) },"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}}},"In this example, each row represents a vertex or control point of a four control point patch list, and each parameter in the parentheses represents an attribute of a respective vertex or control point. The last attribute of the first control point, in this example, stores data indicative of the type of path segment to be rendered (i.e., a \u201cpath segment type indicator\u201d). Specifically, the path segment type indicator in this example is 1.0f, which means that the path segment is a quadratic B\u00e9zier path segment. X0-X2 and Y0-Y2 are the coordinates of the control points for the quadratic B\u00e9zier path segment where (X0, Y0) represents a first control point, (X1, Y1) represents a second control point, etc. The remaining vertices and attributes in this example may be unused and\/or may be used to indicate other attributes for the path segment. The other attributes for the path segment may include, in some examples, attributes similar to those described above with respect to the line path segment.","In some examples, the input path data for an elliptic arc path segment may include data indicative of a center parameterization of the elliptic arc path segment. For example, the input path data for an elliptic arc path segment may take the following form or a similar form:",{"@attributes":{"id":"p-0096","num":"0099"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"70pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","X0,","Y0,","4.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","X1,","Y1,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","c.x,","c.y,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","theta0,","theta1,","angle ) },"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"In further examples, the input path data for an elliptic arc path segment may include data indicative of an endpoint parameterization of the elliptic arc path segment. For example, the input path data for an elliptic arc path segment may take the following form or a similar form:",{"@attributes":{"id":"p-0098","num":"0101"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"70pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","X0,","Y0,","4.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","X1,","Y1,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","rH,","rV,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","angle,","0.0f,","1.0f ) },"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"In examples where the input path data includes an elliptic arc represented in an endpoint parametric form, CPU  may, in some examples, convert the representation of the elliptic arc from an endpoint parametric form into a center parametric form prior to sending data indicative of the elliptic arc to GPU  for rendering. For example, CPU  may generate a center parameterization of an elliptic arc based on an endpoint parameterization of the elliptic arc, and send the center parameterization of the elliptic arc to GPU . The center parameterization for the elliptic arc may conform to the example input data form specified above. The center parameterization may be used by CPU  to find the endpoint tangents and\/or normals for the elliptic arc, which may in turn be used by CPU  to generate join primitives for rendering by GPU .","In some examples, stroking operations may use three additional fields of the vertex path data input to handle endcaps, joins and open paths. For example, certain vertex coordinates may store data indicative of whether the path segment is the beginning of an open path, the end of an open path, and whether the path segment may be dropped (e.g., the path segment is the closing path segment of an open path). The following is an example template that includes the above-described vertex attributes:",{"@attributes":{"id":"p-0101","num":"0104"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","X0,","Y0,","2.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","X1,","Y1,","2.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","2.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","2.0f ) },"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{},"b":["12","12"]},"To perform a path filling operation, input assembler  obtains path data  from memory , and passes the path data onto one or more subsequent stages of graphics pipeline  to render the path segments (e.g., path primitives) specified by path data . For example, input assembler  may obtain a plurality of vertices from a vertex buffer stored in memory  and cause vertex shader  to process the vertices. In some examples, input assembler  may pass the vertices to be processed directly to vertex shader . In additional examples, input assembler  may direct vertex shader  to retrieve particular vertices for processing from a vertex buffer in resources block .","Vertex shader  is configured to process vertices received from input assembler  and\/or resources block  and to generate an output vertex for each input vertex processed by vertex shader . For example, for each input vertex, vertex shader  may execute an instance of a vertex shader program on a shader unit of GPU . In some examples, vertex shader  may execute a \u201cpass-through\u201d vertex shader program for each input vertex. The \u201cpass-through\u201d vertex shader program may cause vertex shader  to, for each input vertex, output a vertex that corresponds to the input vertex. In this case, an output vertex may correspond to an input vertex if the output vertex has the same attributes as the input vertex. To implement the \u201cpass-through\u201d vertex shader program, in some examples, vertex shader  may apply an identity transformation to each input vertex to generate an output vertex with the same attributes. The input vertices received by vertex shader  and the output vertices generated by vertex shader  may be alternatively referred to as input control points and output control points, respectively.","In further examples, vertex shader  may generate one or more output attributes for an output vertex that are not identical to the input attributes of a corresponding input vertex. For example, vertex shader  may perform substantive processing on one or more of the attributes of the input vertices to generate one or more attributes for the output vertices. As one example, vertex shader  may perform one or more of a world transformation, a view transformation, a projection transformation, or any combination thereof on the positional attributes of the input vertices to generate one or more attributes for the output vertices. As another example, vertex shader  may add and\/or delete attributes from the set of input attributes to generate a set of output attributes for an output vertex.","Tessellation stages  (i.e., hull shader , tessellator , and domain shader ) may tessellate a path segment defined by the input path data into a plurality of line segments. The plurality of line segments may approximate the curvature of the path segment to be rendered. In general, hull shader  may pass the control points received from vertex shader  to domain shader  for further processing, and provide configuration data to tessellator . Tessellator  may determine values at which one or more parametric equations that represent a particular type of path segment should be evaluated. Domain shader  may evaluate the parametric equations at the values determined by tessellator , and output a vertex for each evaluation. In some examples, each of the vertices output by domain shader  may include one or more attributes that are indicative of the position of the vertex. In additional examples, each of the vertices output by domain shader  may include one or more attributes that are indicative of the type of path rendering primitive associated with the vertex.","In some examples, hull shader  may process the control points received from vertex shader  and\/or resources block  and may generate an output control point for each instance of the hull shader program executed by hull shader . For example, for each output control point to be generated by hull shader , hull shader  may execute an instance of a hull shader program on a shader unit of GPU . In some examples, hull shader  may execute a \u201cpass-through\u201d hull shader program for each output control point. The \u201cpass-through\u201d hull shader program may cause hull shader  to, for each output control point, output a control point that corresponds to a respective one of the input control points. In this case, an output control point may correspond to an input control point if the output control point has the same attributes as the input control point.","In further examples, hull shader  may generate one or more output attributes for an output control point that are not identical to the input attributes of a respective one of the input control points. For example, hull shader  may perform substantive processing on one or more of the attributes of the input control points to generate one or more attributes for the output control points. As another example, hull shader  may add and\/or delete attributes from a set of input attributes to generate the set of output attributes for an output control point. In some examples, if GPU  receives path data for an elliptical arc that is in the form of an endpoint parameterization, hull shader  may convert the endpoint parameterization of the elliptical arc into a center parameterization for the elliptical arc as described in further detail below.","In additional examples, hull shader  may drop primitives that are not to be rendered for a particular rendering operation. Dropping a primitive may refer to the process of causing data corresponding to the primitive to not be passed on to further stages of graphics pipeline , thereby effectively causing such a primitive to not be rendered by the remainder of the pipeline. For example, when graphics pipeline  is performing a filling operation, hull shader  may drop join primitives and cap primitives. As another example, when graphics pipeline  is performing a stroking operation, hull shader  may drop close-path primitives for open paths. A close-path primitive may refer to a primitive that represents a line path segment that closes a loop. A close-path primitive is typically used for paths that are closed paths rather than open paths. In some examples, a close-path primitive may be identified by a different primitive type identifier than the primitive type identifier used for identifying other line path segments in a path. For example, a close path primitive may be identified by a primitive type identifier of 2.1f instead of 2.0f.","Hull shader  may also execute an instance of a patch constant function for each path segment. The patch constant function may determine and provide configuration parameters to tessellator  to be used by tessellator  when generating output values. For example, the patch constant function may cause hull shader  to provide tessellation factors to tessellator . The tessellation factors may specify a degree of tessellation that tessellator  is to apply to a particular tessellation domain (e.g., how finely the domain should be subdivided and\/or the number of smaller objects into which the domain should be subdivided). In some examples, hull shader  may cause tessellator  to perform 4\u00d7 tessellation for cubic B\u00e9zier curves, 4\u00d7 tessellation for round joins and caps, and 1\u00d7 tessellation for line segments.","As another example, the patch constant function may cause hull shader  to provide a type of tessellation domain to be used during tessellation to tessellator . A tessellation domain may refer to an object that is used by tessellator  to generate a plurality of coordinates for use by domain shader . Conceptually, the tessellation domain may correspond to an object that is subdivided by tessellator  into a plurality of smaller objects. The positional coordinates of the vertices of the smaller objects are then sent to domain shader  for further processing. In some examples, the type of tessellation domain may be selected to be one of a quad, a tri, and an isoline. The smaller objects into which the domain is subdivided, in some examples, may correspond to triangles, line segments, or points. In some examples, hull shader  may specify an isoline tessellation domain type and specify that tessellator  should subdivide the isoline domain into line segments.","Tessellator  may generate a plurality of output values for each path segment processed by tessellation stages . The output values may determine the values at which one or more parametric equations that represent a particular type of path segment should be evaluated by domain shader . In some examples, tessellator  may generate the plurality of output values based on one or more tessellation factors and\/or a tessellation domain type provided to tessellator  by hull shader . For example, tessellator  may subdivide an isoline into a plurality of line segments, and generate an output value for each endpoint of the plurality of line segments in a normalized coordinate system.","Domain shader  may receive output values from tessellator  and control points for a path segment from hull shader , and generate output vertices that correspond to a plurality of tessellated line segments that approximate the curvature and\/or shape of a path segment. For example, for each of the output values received from tessellator , domain shader  may execute an instance of a domain shader program on a shader unit of GPU . The domain shader program may cause domain shader  to, for each of the output values received from tessellator , evaluate one or more parametric equations at a particular value that is determined based on the respective output value to generate positional coordinates for an output vertex that corresponds to the respective output value. One or more of the coefficients of the parametric equations used to generate the output vertex coordinates may be defined based on one or more of the control points received from hull shader . Each output vertex may correspond to an endpoint of one of the plurality of tessellated line segments. Two consecutive output vertices may correspond to the endpoints of a single tessellated line segment.","In additional examples, the domain shader program may cause domain shader  to generate normal coordinates for output vertices that correspond to each of the output values received from tessellator . For example, the domain shader program may cause domain shader  to, for each of the output values received from tessellator , evaluate one or more additional parametric equations at a particular value that is determined based on the respective output value in order to generate tangent coordinates for an output vertex that corresponds to the respective output value. The tangent coordinates for an output vertex may be indicative of a direction of a tangent line of the path segment that intersects the path segment at the output vertex. Domain shader  may generate normal coordinates for each of the output vertices based on the tangent coordinates that correspond to the respective output vertex. The normal coordinates generated for a particular output vertex may be indicative of a normal vector that indicates a direction which is perpendicular to a tangent of the path segment that intersects the path segment at the output vertex.","In some examples, when graphics pipeline  is performing a filling operation, domain shader  may generate vertices corresponding to the locations of the endpoints of the tessellated line segments without generating any normals for such locations. In such examples, when graphics pipeline  is performing a stroking operation, domain shader  may, in some examples, generate vertices corresponding to the locations of the endpoints of the tessellated line segments and generate normals corresponding to such locations.","Domain shader  may output the vertices in an ordered sequence where each set of adjacent vertices represents a tessellated line segment. The line segments may collectively approximate the path segment that was defined in the vertex buffer. For example, domain shader  may output the following set of vertices {0, 1, 2, 3, 4, 5} that define the following line segments: {0, 1}, {1, 2}, {2, 3}, {3, 4}, {4, 5}. In additional examples, domain shader  may output the following set of vertices {0, 1, 1, 2, 2, 3, 3, 4, 4, 5} that may define the same line segments as listed in the previous example.","In some examples, tessellator  and domain shader  may be configured to uniformly tessellate a path segment into a plurality of line segments according to the following technique. Specifically, tessellator  may output coordinates for parametric evaluation (e.g., t=0\/T, 1\/T, 2\/T . . . T\/T, where T is the tessellation factor). Depending on the type of primitive, domain shader  may evaluate one or more parametric equations at the values that are output by tessellator .","For a line, T may, in some examples, be always equal to 1. In such examples, domain shader  may not necessarily need to perform any evaluation to generate vertices that correspond to the line path segment.","For a cubic B\u00e9zier curve, domain shader  may evaluate the curve and generate output vertices according to the following parametric equation:\n\n()=0*(1)1*3*(1)2*3(1)*3\u2003\u2003(1)\n\nwhere t corresponds to an output value provided by tessellator , V(t) corresponds to an output vertex that is generated for a particular output value (i.e., t), and C0, C1, C2, C3 correspond to the control points for the cubic B\u00e9zier curve.\n","Alternatively, for the cubic B\u00e9zier curve, domain shader  may evaluate the curve and generate output vertices according to the following parametric equations:\n\n()=0*(1)1*3*(1)2*3*(1)*3\u2003\u2003(2)\n\n()=0*(1)1*3*(1)2*3*(1)*3\u2003\u2003(3)\n\nwhere t corresponds to an output value provided by tessellator , x(t) corresponds to the x-coordinate of an output vertex that is generated for a particular output value (i.e., t), y (t) corresponds to the y-coordinate of the output vertex that is generated for the particular output value (i.e., t), and (X0, Y0), (X1, Y1), (X2, Y2), (X3, Y3) correspond to the control points for the cubic B\u00e9zier curve.\n","For a quadratic B\u00e9zier curve, domain shader  may evaluate the curve and generate output vertices according to the following parametric equation:\n\n()=0*(1)1*2*(1)*2\u2003\u2003(4)\n\nwhere t corresponds to an output value provided by tessellator , V(t) corresponds to an output vertex that is generated for a particular output value (i.e., t), and C0, C1, C2 correspond to the control points for the quadratic B\u00e9zier curve.\n","Alternatively, for the quadratic B\u00e9zier curve, domain shader  may evaluate the curve and generate output vertices according to the following parametric equations:\n\n()=0*(1)1*(1)*2\u2003\u2003(5)\n\n()=0*(1)1*(1)*2\u2003\u2003(6)\n\nwhere t corresponds to an output value provided by tessellator , x(t) corresponds to the x-coordinate of an output vertex that is generated for a particular output value (i.e., t), y (t) corresponds to the y-coordinate of the output vertex that is generated for the particular output value (i.e., t), and (X0, Y0), (X1, Y1), (X2, Y2) correspond to control points for the quadratic B\u00e9zier curve.\n","For an elliptic arc path segment, domain shader  may evaluate the curve and generate output vertices according to the following parametric equations:\n\n=CenterCos*cos(angle)\u2212Sin*sin(angle)\u2003\u2003(7)\n\n=CenterSin*cos(angle)+Cos*sin(angle)\u2003\u2003(8)\n\nwhere the parameterization angle angleis determined from tessellator output t, x corresponds to the x-coordinate of an output vertex that is generated for a particular parameterization angle (i.e., angle), y corresponds to the y-coordinate of the output vertex that is generated for the parameterization angle (i.e., angle), rh represents the horizontal radius of the unrotated ellipse, ry represents the vertical radius of the unrotated ellipse, rvCos, rvSin, rhCos and rhSin represent rv*Cos(angle), rv*Sin(angle), rh*Cos(angle) and rh*Sin(angle), respectively, and angle represents the counter-clockwise angle of the ellipse relative to the x axis measured prior to scaling by (rh, rv). In some examples, hull shader  may be configured to determine (e.g., precompute) cos(angle) and sin(angle) and\/or to determine (e.g., precompute) the rvCos, rvSin, rhCos and rhSin values, and to provide these values to domain shader  for use in evaluating the above-recited parametric equations for elliptic arcs.\n","As discussed above with respect to elliptic arcs, the vertices in the patch control list, in some examples, may include data indicative of an endpoint parameterization for the elliptic arc. In such examples, hull shader  (e.g., a hull shader program executing on a shader unit of GPU ) may be used to convert the data indicative of an endpoint parameterization of the elliptic arc to data indicative of a center parameterization of the elliptic arc.","An example technique for finding the correct center of an ellipse when converting an endpoint parameterization of an elliptic arc to a center parameterization of the elliptic arc is now described. The example technique may determine a center point (cx, cy) and the initial and final angles \u03b81 and \u03b82 of an ellipse and\/or elliptic arc based on an endpoint representation of an ellipse defined by the set of parameters (x0, y0), (x1, y1), rh, rv, f, and f. An ellipse with center point (cx, cy), radii rh and rv, and rotation angle rot may satisfy the implicit equation (x\u2032)+(y\u2032)=1, where x\u2032=((x\u2212cx)*cos(rot)+(y\u2212cy)*sin(rot))\/rh and y\u2032=(\u2212(x\u2212cx)*sin(rot)+(y\u2212cy)*cos(rot))\/rv. The transformation from (x, y) to (x\u2032, y\u2032) maps the desired ellipse into a unit circle centered at the origin.","To determine the center points of the pair of ellipses with common radii and rotation angle that pass through the two given points (x, y) and (x, y), a plane is first transformed into a suitably scaled and rotated coordinate system such that the equation of each ellipse becomes (x\u2032\u2212cx\u2032)+(y\u2032\u2212cy\u2032)=1. Then the centers (i.e., (cx\u2032, cy\u2032) and (cx\u2032, cy\u2032)) of the two unit circles whose circumferences pass through two given points may be found. Finally, the center points are placed through an inverse transformation to obtain solutions in the original coordinate system.","The center points of the two unit circles that pass through points (x, y) and (x, y) are given by (x\u00b1\u0394y*d, y\u2213\u0394x*d), where x=(x+x)\/2, y=(y+y)\/2, \u0394x=(x\u2212x), \u0394y=(y\u2212y), and d=\u221a(1\/(\u0394x+\u0394y)\u2212\u00bc.). If d is infinite or imaginary, no solution exists due to the input points being coincident or too far apart, respectively. The angles \u03b81 and \u03b82 may be found by finding the slope of the endpoints on the circle and computing arctangents.","The following pseudo-code illustrates the process of computing ellipse centers according to the above-described technique. The findUnitCircles function is called by findEllipses following inverse transformation of the original ellipse parameters.",{"@attributes":{"id":"p-0128","num":"0131"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/* Given: Points (x0, y0) and (x1, y1)"},{"entry":"* Return: TRUE if a solution exists, FALSE otherwise"},{"entry":"* Circle centers are written to (cx0, cy0) and (cx1, cy1)"},{"entry":"*\/"},{"entry":"static VGboolean findUnitCircles(double x0, double y0,"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"double x1, double y1,"]},{"entry":[{},"double *cx0, double *cy0,"]},{"entry":[{},"double *cx1, double *cy1)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"{"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/* Compute differences and averages *\/"]},{"entry":[{},"double dx = x0 \u2212 x1;"]},{"entry":[{},"double dy = y0 \u2212 y1;"]},{"entry":[{},"double xm = (x0 + x1)\/2;"]},{"entry":[{},"double ym = (y0 + y1)\/2;"]},{"entry":[{},"double dsq, disc, s, sdx, sdy;"]},{"entry":[{},"\/* Solve for intersecting unit circles *\/"]},{"entry":[{},"dsq = dx*dx + dy*dy;"]},{"entry":[{},"if (dsq == 0.0) return VG_FALSE; \/* Points are coincident *\/"]},{"entry":[{},"disc = 1.0\/dsq \u2212 1.0\/4.0;"]},{"entry":[{},"if (disc < 0.0) return VG_FALSE; \/* Points are too far apart *\/"]},{"entry":[{},"s = sqrt(disc);"]},{"entry":[{},"sdx = s*dx;"]},{"entry":[{},"sdy = s*dy;"]},{"entry":[{},"*cx0 = xm + sdy;"]},{"entry":[{},"*cy0 = ym \u2212 sdx;"]},{"entry":[{},"*cx1 = xm \u2212 sdy;"]},{"entry":[{},"*cy1 = ym + sdx;"]},{"entry":[{},"return VG_TRUE;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":"\/* Given: Ellipse parameters rh, rv, rot (in degrees),"},{"entry":"* endpoints (x0, y0) and (x1, y1)"},{"entry":"* Return: TRUE if a solution exists, FALSE otherwise"},{"entry":"* Ellipse centers are written to (cx0, cy0) and (cx1, cy1)"},{"entry":"*\/"},{"entry":"VGboolean findEllipses(double rh, double rv, double rot,"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"double x0, double y0, double x1, double y1,"]},{"entry":[{},"double *cx0, double *cy0, double *cx1, double *cy1)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"{"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"double COS, SIN, x0p, y0p, x1p, y1p, pcx0, pcy0, pcx1, pcy1;"]},{"entry":[{},"\/* Convert rotation angle from degrees to radians *\/"]},{"entry":[{},"rot *= M_PI\/180.0;"]},{"entry":[{},"\/* Pre-compute rotation matrix entries *\/"]},{"entry":[{},"COS = cos(rot); SIN = sin(rot);"]},{"entry":[{},"\/* Transform (x0, y0) and (x1, y1) into unit space *\/"]},{"entry":[{},"\/* using (inverse) rotate, followed by (inverse) scale *\/"]},{"entry":[{},"x0p = (x0*COS + y0*SIN)\/rh;"]},{"entry":[{},"y0p = (\u2212x0*SIN + y0*COS)\/rv;"]},{"entry":[{},"x1p = (x1*COS + y1*SIN)\/rh;"]},{"entry":[{},"y1p = (\u2212x1*SIN + y1*COS)\/rv;"]},{"entry":[{},"if (!findUnitCircles(x0p, y0p, x1p, y1p,"]},{"entry":[{},"&pcx0, &pcy0, &pcx1, &pcy1)) {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"return VG_FALSE;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},"\/* Transform back to original coordinate space *\/"]},{"entry":[{},"\/* using (forward) scale followed by (forward) rotate *\/"]},{"entry":[{},"pcx0 *= rh; pcy0 *= rv;"]},{"entry":[{},"pcx1 *= rh; pcy1 *= rv;"]},{"entry":[{},"*cx0 = pcx0*COS \u2212 pcy0*SIN;"]},{"entry":[{},"*cy0 = pcx0*SIN + pcy0*COS;"]},{"entry":[{},"*cx1 = pcx1*COS \u2212 pcy1*SIN;"]},{"entry":[{},"*cy1 = pcx1*SIN + pcy1*COS;"]},{"entry":[{},"return VG_TRUE;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Further details regarding converting an endpoint parameterization of an elliptic arc to a center parameterization of the elliptic arc may be found in the \u201cOpenVG Specification, Version 1.1,\u201d Section 18.4, Dec. 3, 2008, available at: http:\/\/www.khronos.org\/registry\/vg\/specs\/openvg-1.1.pdf, the entire content of which is incorporated herein by reference.","Geometry shader  may receive tessellated line segments from domain shader  and generate a plurality of triangle primitives based on the tessellated line segments. For example, for each of the tessellated line segments, geometry shader  may execute an instance of a geometry shader program on a shader unit of GPU , and generate a triangle primitive for the tessellated line segment based on the respective tessellated line segment. In some examples, for each of the tessellated line segments, geometry shader  may receive two vertices from domain shader  that correspond to the respective tessellated line segment, and generate a set of three vertices that correspond to a triangle primitive. In some examples, two of the vertices of the triangle primitive may be the same vertices (e.g., have the same positional coordinates) as the two received vertices. In such examples, geometry shader  may generate the third vertex based on a common vertex that is common for all tessellated line segments associated with a path segment to be rendered. The common vertex may or may not correspond to one of the endpoints of the tessellated line segments. In some examples, the common vertex may correspond to the first vertex in a set of vertices that correspond to the tessellated line segments for a path segment to be rendered.","Geometry shader  may be invoked once for each of the tessellated line segments produced by domain shader . For each of the tessellated line segments, geometry shader  may generate a triangle primitive using a common control point as a first vertex of the triangle and using the two endpoints of the respective tessellated line segment as the second and third vertices of the triangle. For example, an example was provided above where domain shader  generated the following set of vertices {0, 1, 2, 3, 4, 5} that define the following line segments: {0, 1}, {1, 2}, {2, 3}, {3, 4}, {4, 5}. For the above-listed sequence of line segments, geometry shader  may generate the following triangles: {C, 0, 1}, {C, 1, 2}, {C, 2, 3}, {C, 3, 4}, {C, 4, 5}, {C, 4, 5} where is any single vertex that is common to all of the triangles.","Rasterizer  may be configured to convert a plurality of 3D graphics primitives (e.g., points, lines, and triangles) into a plurality of pixels that correspond to the 3D graphics primitives. For example, rasterizer  may receive three vertices that correspond to a triangle primitive, and convert the three vertices into a plurality of pixels that correspond to the screen pixel locations that are covered by the triangle primitive. Screen pixel locations that are covered by the triangle primitive may include screen pixel locations that correspond to the vertices of the triangle, the edges of the triangle, and the interior of the triangle.","Pixel shader  may receive pixels from rasterizer , and generate shaded pixels based on the received pixels according to a pixel shader program. For example, for each pixel received from rasterizer , pixel shader  may execute an instance of a pixel shader program on a shader unit of GPU . In some examples, pixel shader  may execute a \u201cpass-through\u201d pixel shader program for each pixel. The \u201cpass-through\u201d pixel shader program may cause pixel shader  to, for each pixel, output a pixel that corresponds to a respective one of the input pixel. In this case, an output pixel may correspond to an input pixel if the output pixel has the same attributes as the input pixel.","In further examples, pixel shader  may generate one or more output attributes for an output pixel that are not identical to the input attributes of a respective one of the input pixels. For example, pixel shader  may perform substantive processing on one or more of the attributes of an input pixel to generate one or more attributes for an output pixel. As another example, pixel shader  may add and\/or delete attributes from a set of input attributes to generate the set of output attributes for an output pixel.","Output merger  may place pixel data received from pixel shader  into a render target (e.g., a frame buffer or a stencil buffer). In some examples, output merger  may merge the pixel data received from pixel shader  with the pixel data already stored in a render target based on a raster operation.","To perform the path filling operation, rasterizer  may rasterize each of the triangles received by geometry shader  into a common stencil buffer (e.g., a buffer stored in resources block ). During the first pass, pixel shader  may be disabled or set to a \u201cpass-through\u201d mode to pass input pixels directly to output merger . Output merger  may be configured to populate the stencil buffer such that the stencil buffer stores values which are indicative of a fill area for the path segment according to one or more stencil buffer filling techniques.","According to a first stencil buffer filling technique, for each of the rasterized primitives, output merger  may invert the values in the stencil buffer that correspond to pixels which are covered by the rasterized primitive. With this technique, after all of the primitives have been rasterized to the stencil buffer, any inverted values in the stencil buffer may represent a fill area for the path segment to be rendered.","According to a second stencil buffer filling technique, for each of the rasterized primitives, output merger  may increment values in the stencil buffer that correspond to pixels which are covered by the rasterized primitive if a vertex order for the rasterized primitive is oriented in a clockwise direction, and decrement values in the stencil buffer that correspond to pixels which are covered by the rasterized primitive if a vertex order for the rasterized primitive is oriented in a counter-clockwise direction. With this technique, after all of the primitives have been rasterized to the stencil buffer, any non-zero values in the stencil buffer may represent a fill area for the path segment to be rendered.",{"@attributes":{"id":"p-0139","num":"0142"},"figref":["FIG. 4","FIG. 4"]},"Pass 1",{"@attributes":{"id":"p-0140","num":"0000"},"ul":{"@attributes":{"id":"ul0005","list-style":"none"},"li":{"@attributes":{"id":"ul0005-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0006","list-style":"none"},"li":["1. Clear the stencil buffer and disable writing into the color buffer. Pick an arbitrary point C.","2. Break the boundary of the Polygon into sequence of directed line segments p0p1,p1p2, . . . .","3. Construct a triangle fan center at C: Cp0p1, Cp1p2, Cp2p3 . . . .","4. Draw every triangle and set the stencil operation to be INVERT(EVEN\/ODD) or INCR(NOZERO).\n\nPass 2\n","1. Draw a big quad\/triangle covering the whole screen and draw to the pixels where stencil value is not zero."]}}}},"In some examples, point p1 shown in  may be selected as the common point (C) for generating a triangle fan, and a triangle fan may be generated that includes the following triangles: {p1, p2, p3}, {p1, p3, p4}, {p1, p4, p5}, {p1, p5, p6}, {p1, p6, p7}. The target fill region for the path shown in  is the union of regions A, D and F.","As shown in , regions A, D and F are the only regions that are within an odd number of the triangles formed by the triangle fan. Thus, if these triangles are rendered according to the first stencil buffer filling technique where the values in the stencil buffer that correspond to pixels which are covered by the rasterized primitive are inverted, then after all of the primitives have been rasterized to the stencil buffer, any inverted values in the stencil buffer may correspond to the union of regions A, D and F (i.e., the fill area for the path segment to be rendered).","In addition, regions A, D and F are the only regions that are within an unbalanced number of clockwise and counter-clockwise triangles formed by the triangle fan. Regions that are within an unbalanced number of clockwise and counter-clockwise triangles may refer to regions where the total number of triangles of which the region is inside is not equal to the total number of triangles of which the region is outside. Thus, if these triangles are rendered according to the second stencil buffer filling technique where the values in the stencil buffer are either incremented or decremented depending on whether the triangle is oriented in a clockwise or counter-clockwise direction, then after all of the primitives have been rasterized to the stencil buffer, any non-zero values in the stencil buffer may correspond to the union of regions A, D and F (i.e., the fill area for the path segment to be rendered).","Further details regarding the use of a stencil buffer to fill a polygon may be found in the \u201cOpenGL Programming Guide: The Official Guide to Learning OpenGL, Version 1.1,\u201d available at: http:\/\/www.glprogramming.com\/red\/chapter14.html#name13, the entire contents of which is incorporated herein by reference.","The first pass completes after all of the primitives generated by geometry shader  have been rendered into the stencil buffer. During the second pass, a bounding box (e.g., formed from two triangle primitives) that encompasses the fill area is rendered into a render target (e.g., the frame buffer) with the stencil test enabled. The data in the stencil buffer may cause pixels inside of the fill area to light up with a fill color (specified by CPU  prior to the second rendering pass), and cause pixels that are outside of the fill area to remain dark. During the second pass, tessellation stages  and geometry shader  may be disabled. Vertex shader  may be configured to perform standard vertex shader operations (e.g., transforms) for rendering 3D graphics primitives. Pixel shader  may be configured to perform standard operations and\/or configured to operate in a \u201cpass-through\u201d mode. Once the second pass is complete, the render target (e.g., the frame buffer) may store a rasterized version of the fill area for the path segment.","The stroking operation may utilize a single-pass approach that may generally involve the following steps:\n\n","The input processing and tessellation operations are substantially similar to the input processing and tessellation operations described with respect to the filling operation, and therefore will not be described in further detail.","In addition to domain shader  evaluating parametric equations to generate positional coordinates for vertices, as described above with respect the filling operation, domain shader  may also generate normal coordinates (e.g., normal vectors or normals) for the vertices during the stroking operation. The normal coordinates generated for a particular output vertex may be indicative of a normal vector that indicates a direction which is perpendicular to a tangent of the path segment that intersects the path segment at the output vertex.","To generate the normals, domain shader  may evaluate additional parametric equations for each of the values generated by tessellator , and may output one or more normals based on each evaluation. For example, for each of the output values received from tessellator , domain shader  may evaluate one or more parametric equations at a particular value that is determined based on the respective output value to generate one or more tangent coordinates for an output vertex that corresponds to the respective output value. The tangent coordinates for an output vertex may be indicative of a direction of a tangent line of the path segment that intersects the path segment at the output vertex. Domain shader  may generate normal coordinates for each of the output vertices based on the tangent coordinates that correspond to the respective output vertex. The normal coordinates generated for a particular output vertex may be indicative of a normal vector that indicates a direction which is perpendicular to a tangent of the path segment that intersects the path segment at the output vertex.","In some cases, the normal coordinates may be output as attributes of a vertex that is output by domain shader . For example, for the stroking operation, an output vertex produced by domain shader  may include one or more attributes that are indicative of the position of the vertex, one or more attributes that are indicative of a normal associated with the vertex, and one or more attributes that are indicative of the type of path rendering primitive (e.g., a type of path segment) associated with the vertex. The normal attributes may be indicative of a normal vector for a point on the path segment that corresponds to the parameter value generated by tessellator .","For line segments, the direction of the tangent for each of the endpoints of the line segment may correspond to the direction of the line segment itself. As such, the tangent coordinates may be obtained by taking the vector difference between the end point and the starting point of the line segment (e.g., (X1\u2212X0, Y1\u2212Y0)).","To generate the normals for curved path segments (e.g., B\u00e9zier curves and elliptic arcs), the tangent formulae for the curved path segments may be used. In general, the tangent formulae for curves and elliptic arcs (which may be used to determine the normals) are the derivatives of the parametric formulas described above with respect to generating the vertices for the curves and arcs.","For example, for a cubic B\u00e9zier curve, domain shader  may generate tangent coordinates for the output vertices of the curve based on the following parametric equation:\n\n()=0*\u22123*(1)1*(\u22126*(1)*3*(1))+2*(\u22123+6*(1)*)+3*3\u2003\u2003(9)\n\nwhere t corresponds to an output value provided by tessellator , N(t) corresponds to one or more tangent coordinates that are generated for a particular output value (i.e., t), and C0, C1, C2, C3 correspond to the control points for the cubic B\u00e9zier curve. A derivative of the parametric equation for the quadratic B\u00e9zier curve provided above may be used to generate tangent coordinates for a quadratic B\u00e9zier curve in a similar fashion.\n","Alternatively, for the cubic B\u00e9zier curve, domain shader  may generate tangent coordinates for the output vertices of the curve based on the following parametric equations:\n\n()=0*\u22123*(1)1*(\u22126*(1)*3*(1))+2*(\u22123+6*(1)*)+3*3\u2003\u2003(10)\n\n()=0*\u22123*(1)1*(\u22126*(1)*3*(1))+2*(\u22123+6*(1)*)+3*3\u2003\u2003(11)\n\nwhere t corresponds to an output value provided by tessellator , x(t) corresponds to the x-coordinate of a tangent that corresponds to a particular output value (i.e., t), y(t) corresponds to the y-coordinate of the tangent that corresponds to the particular output value (i.e., t), and (X0, Y0), (X1, Y1), (X2, Y2), (X3, Y3) correspond to the control points for the cubic B\u00e9zier curve. A derivative of the parametric equations for the quadratic B\u00e9zier curve provided above may be used to generate tangent coordinates for a quadratic B\u00e9zier curve in a similar fashion.\n","For an elliptic arc path segment, domain shader  may generate tangent coordinates for the output vertices of the curve based on the following parametric equations:\n\nTanCos*sin(angle)\u2212Sin*cos(angle)\u2003\u2003(12)\n\nTanSin*sin(angle)+Cos*cos(angle)\u2003\u2003(13)\n\nwhere the parameterization angle, angle, is determined from tessellator output (i.e., t), Tanis the x-coordinate of a tangent of the elliptic arc that corresponds to a particular parameterization angle (i.e., angle), Tanis the y-coordinate of the tangent of the elliptic arc that corresponds to the particular parameterization angle (i.e., angle), rh represents the horizontal radius of the unrotated ellipse, ry represents the vertical radius of the unrotated ellipse, rvCos, rvSin, rhCos and rhSin represent rv*Cos(angle), rv*Sin(angle), rh*Cos(angle) and rh*Sin(angle), respectively, and angle represents the counter-clockwise angle of the ellipse relative to the x axis, measured prior to scaling by (rh, rv). In some examples, hull shader  may be configured to determine (e.g., precompute) cos(angle) and sin(angle) and\/or to determine (e.g., precompute) the rvCos, rvSin, rhCos and rhSin values, and to provide these values to domain shader  for use in evaluating the above-recited parametric equations for ellipses.\n","Domain shader  may, in some examples, generate a normal vector (e.g., normal coordinates) for each of the output vertices based on the tangent coordinates for the respective output vertex according to the following equation:\n\nnormal=normalize(\u2212Tan,Tan)\u2003\u2003(14)\n\nwhere normal corresponds to a normal vector for a particular vertex, Tancorresponds to the x-coordinate of a tangent of a path segment that intersects the path segment at the particular vertex, Tancorresponds to the y-coordinate of the tangent of the path segment that intersects the path segment at the particular vertex, and normalize(x,y) is a function that generates a normalized version of an input vector (x,y). A normalized version of the vector (x,y) may refer to a vector that has the same direction as vector (x,y) and a unit length (i.e., a length (e.g., norm) of one).\n","As discussed above with respect to elliptic arcs, the vertices in the patch control list may, in some examples, include data indicative of an endpoint parameterization. In such examples, hull shader  may convert the data indicative of an endpoint parameterization of the elliptic arc to data indicative of a center parameterization of the elliptic arc.","Geometry shader  may receive the line segments and the normals produced by domain shader , and generate primitives (e.g., triangles) that spatially correspond to the stroke area for each of the line segments. The stroke area for each of the line segments may collectively approximate the stroke area for the original path segment.","In general, each line segment may be defined by two consecutive points (p0, p1) on a path and the normals (n0, n1) at each of the points. To determine the stroke area for a line segment, geometry shader  may determine four corner points (u0, l0, u1, l1) of the stroke area for the line segment according to the following equations:\n\n000*StrokeWidth\u2003\u2003(15)\n\n000*StrokeWidth\u2003\u2003(16)\n\n111*StrokeWidth\u2003\u2003(17)\n\n111*StrokeWidth\u2003\u2003(18)\n\nwhere p0 and p1 are endpoints of the line segment for which the stroke area is being determined, n0 is the normal vector corresponding to p0, n1 is the normal vector corresponding to p1, and StrokeWidth is the stroke width defined by the user application and passed to GPU  (e.g., via one or more vertex attributes and\/or state commands).\n",{"@attributes":{"id":"p-0160","num":"0172"},"figref":["FIGS. 5 and 6","FIGS. 5 and 6"]},"Geometry shader  may determine whether the intersection point is outside of the stroke area (e.g., ) or inside of the stroke area (e.g., ), and generate one or more primitives that spatially correspond to the stroke area based on the determination. To determine whether the intersection point is outside of the stroke area, geometry shader  may determine whether strokewidth<min(u0c,u1c). If strokewidth<min(u0c,u1c), geometry shader  may determine that the intersection point is outside of the stroke area. Otherwise, geometry shader  may determine that the intersection point is inside of the stroke area.","If the stroke width is small enough (strokewidth<min(u0c,u1c)) so that the two line segment (u0,u1) and (l0,l1) have the same orientation, then the shape of stroke area for the line segment may be a quad (). Otherwise the shape of the stroke area for the line segment may be two head-to-head triangles (i.e., a butterfly) ().","If the intersection point is outside of the stroke area (e.g., ), then geometry shader  may generate two triangles to form a quad that spatially corresponds to the stroke area. For example, geometry shader  may generate two triangles using the following combinations of vertices {u0, u1, l1} and {l1, l0, u0}.","If the intersection point is inside of the stroke area (e.g., ), then geometry shader  may generate two triangles to form a butterfly that spatially corresponds to the stroke area. For example, geometry shader  may generate two triangles using the following combinations of vertices {u0, u1, c} and {c, l0, l1} if the {u0, u1, c} triangle is oriented in a clockwise direction, and generate two triangles using the following combinations of vertices {u0, u1, c} and {c, l1, l0} if the {u0, u1, c} triangle is oriented in a counter-clockwise direction.","To determine if the {u0, u1, c} triangle is oriented in a clockwise direction, geometry shader  may determine whether sin(a0+a1)>0 in the equations defined below. If sin(a0+a1)>0, then geometry shader  may determine that the {u0, u1, c} triangle is oriented in a clockwise direction. Otherwise, geometry shader  may determine that the {u0, u1, c} triangle is oriented in a counter-clockwise direction.","The distances u0c and u1c, which may be used to determine the shape of the stroke area and also determine the coordinates of the center point C, may be determined based on the following formulas:",{"@attributes":{"id":"p-0167","num":"0179"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"v","mo":"=","mrow":{"mi":"normalize","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"n","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"},{"mi":"n","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}],"mo":"-"}}}}},{"mrow":{"mo":["(",")"],"mn":"19"}}]},{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}}},{"mi":["n","v"],"mo":["\u2062","\u2062","\u00d7"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}],"mo":"="},{"mrow":[{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}}},{"mi":"n","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mn":"0","mo":"\u00b7","mi":"v"}}],"mo":"="}],"mo":","}},{"mrow":{"mo":["(",")"],"mn":"20"}}]},{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}},{"mi":["v","n"],"mo":["\u00d7","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}],"mo":"="},{"mrow":[{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}},{"mrow":{"mi":["v","n"],"mo":"\u00b7"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}],"mo":"="}],"mo":","}},{"mrow":{"mo":["(",")"],"mn":"21"}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}],"mo":"+"}}},{"mrow":[{"mrow":[{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}}},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}}],"mo":"\u2062"},{"mrow":[{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}}],"mo":"\u2062"}],"mo":"+"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"22"}}]},{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":["u","c"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"0"},{"mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}},"mo":"\u2062","mfrac":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mi":"u","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"},{"mi":"u","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}],"mo":"-"}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}],"mo":"+"}}}]}}],"mo":"="},{"mrow":[{"mi":["u","c"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mn":"1"},{"mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}}},"mo":"\u2062","mfrac":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mi":"u","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"},{"mi":"u","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"}],"mo":"-"}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},{"mi":"a","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}],"mo":"+"}}}]}}],"mo":"="}],"mo":","}},{"mrow":{"mo":["(",")"],"mn":"23"}}]},{"mtd":[{"mrow":{"mi":"c","mo":"=","mrow":{"mrow":[{"mi":"u","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"0"},{"mi":["n","c"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mrow":{"mn":"0","mo":"\u00b7","mi":"u"},"mn":"0"}],"mo":"-"}}},{"mrow":{"mo":["(",")"],"mn":"24"}}]}]}}},"br":{}},"If strokewidth<min(u0c,u1c), then the stroke area for the line segment may be a simple quad. In such a case, GPU  may draw two (2) triangles (u0,u1,l1) and (l1,l0,u1). In some examples, regardless of the position of p0,p1,n0,n1, when strokewidth<min(u0c,u1c), the two triangles may always be clockwise.","If strokewidth>min(u0c,u1c), then there are 2 cases. If sin(a0+a1)>0, which means triangle (u0,u1,c) is clockwise, then the triangles drawn by GPU  are (u0,u1,c) and (c,l0,l1). If sin(a0+a1)<0, then the triangles drawn by GPU  are (u1,u0,c), (c,l1,l0).","In some cases, when primitives corresponding to the stroke areas of the line segments are generated (e.g., by geometry shader ), the neighboring line segments may form a T junction if one or both of the stroke areas forms a butterfly shape (e.g. ). This is because the center point C is not at the same position for the different line segments.",{"@attributes":{"id":"p-0171","num":"0183"},"figref":"FIG. 7","b":["12","12","56"]},"Rasterizer  may rasterize each of the primitives generated by geometry shader  into a render target (e.g., the frame buffer). During the output merger stage, all pixels that are covered by the primitives generated by geometry shader  may be lit up with a stroke color (specified by the CPU prior to the rendering pass). Pixel shader  may be configured to perform standard operations and\/or configured to operate in a \u201cpass-through\u201d mode during the rendering pass. The single rendering pass completes after rendering all of the primitives generated by geometry shader . Once the rendering pass is complete, the render target (e.g., the frame buffer) may store a rasterized version of the stroke area for the path segment.","As discussed above, in addition to rendering primitives that spatially correspond to the stroke area of the path segments to be rendered, the stroking operation may also involve applying various types of end caps to the ends of a path and\/or applying various types of joins between the endpoints of interior path segments of a path. In some examples, these operations may be able to be implemented with a DX11 pipeline using one or more of the techniques described below.","Techniques are now described for rendering joins. Joins may be applied at locations where different path segments meet. In some examples, there may be three different types of joins: (1) bevel; (2) miter; and (3) round. In some examples, the type of join to be rendered may be stored in a buffer in GPU  (e.g., a patch constant buffer), and CPU  may indicate the type of join to use for rendering by placing a value indicative of the type of join into the buffer.","A join may be formed at a location or position where two path segments meet. To render a join, CPU  may place data indicative of the position where the two path segments meet and data indicative of the two tangents at that position (i.e., one tangent for each path segment) into a buffer (e.g., a vertex buffer in path data ) for consumption by GPU .","In some examples, the input path data for a join may take the following form or a similar form:",{"@attributes":{"id":"p-0177","num":"0189"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"70pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","pos.x,","pos.y,","5.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","tan0.x,","tan0.y,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","tan1.x,","tan1.y,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) },"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{},"b":["12","6"]},"In some examples, to render a join, hull shader  may convert the tangent coordinates {(tan 0.x, tan 0.y) and (tan 1.x, tan 1.y)} that correspond to the join from Cartesian coordinates to angular coordinates. In further examples, hull shader  may normalize the tangents {(tan 0.x, tan 0.y) and (tan 1.x, tan 1.y)} that correspond to the join prior to converting the Cartesian coordinates to angular coordinates. In additional examples, hull shader  may place the angular coordinates for the tangents into one or more attributes of the patch control list received by hull shader  and pass the modified patch control list to domain shader  for further processing.","As one specific example, an input patch control list received by hull shader  for a join may be as follows:",{"@attributes":{"id":"p-0180","num":"0192"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"98pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","0.4f,","0.8f,","5.0f ) } \/\/ location"]},{"entry":[{},"{ XMFLOAT3(","0.8f,","0.0f,","1.0f ) } \/\/ first tangent"]},{"entry":[{},"{ XMFLOAT3(","0.2f,","\u22120.2f,","1.0f ) } \/\/ second tangent"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) }"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{},"b":"48"},{"@attributes":{"id":"p-0181","num":"0193"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"98pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","0.4f,","0.8f,","5.0f ) } \/\/ location"]},{"entry":[{},"{ XMFLOAT3(","0.8f,","0.0f,","0.0f ) } \/\/ first tangent"]},{"entry":[{},"{ XMFLOAT3(","0.2f,","\u22120.2f,","5.5f ) } \/\/ second tangent"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) }"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}}},"In some examples, hull shader  may implement the following pseudo-code and\/or shader program code to normalize the tangents, and convert the Cartesian coordinates for the tangents into angular coordinates:",{"@attributes":{"id":"p-0183","num":"0195"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"if ( (join AND (ControlPointId == 1 or 2) ) OR (cap AND"]},{"entry":[{},"ControlPointId == 1) )"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ convert tangent to angle for faster lerping later"]},{"entry":[{},"normalizedTangent = normalize( inputPatch[ControlPointId] )"]},{"entry":[{},"angle = acos( normalizedTangent.x )"]},{"entry":[{},"if ( normalizedTangent.y < 0 )"]},{"entry":[{},"angle = 2.0f*PI \u2212 angle;"]},{"entry":[{},"\/\/ save the angle representation in the Z coordinate of the"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"control point vertex"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"output.z = a0;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0184","num":"0196"},"figref":["FIG. 8","FIG. 8","FIG. 8"],"b":"12"},"In some examples, domain shader  may receive data indicative of a join to be rendered from hull shader , generate one or more vertices that correspond to the join to be rendered, and provide the vertices to geometry shader  for further processing. The data indicative of the join to be rendered may include data indicative of the position or location where the two path segments meet, data indicative of a tangent for a first one of the two path segments at the position or location where the two path segments meet, data indicative of a tangent for a second one of the two path segments at the position or location where the two path segments meet, and data indicative of the type of path rendering primitive (e.g., a join in this case). In some examples, the data indicative of the join to render may take the form of a patch control list (e.g., the patch control list specified above).","For each of the tangents associated with the bevel join, domain shader  may generate a normal that corresponds to the respective tangent based on the data indicative of the respective tangent received by domain shader . For example, domain shader  may generate a normal for each tangent based on equation (14). The one or more vertices produced by domain shader  may include one or more attributes indicative of the common endpoint where two path segments meet (i.e., point c), one or more attributes indicative of the normals for each of the path segments at the common endpoint, and one or more attributes indicative of the type of path rendering primitive (e.g., a join in this case).","Geometry shader  may, in some examples, receive the one or more vertices from domain shader , and determine the corner points (u0, u1, l0, l1) for the endpoints of the path segments where two path segments meet based on one or more of equations (15)-(18) as described in this disclosure. In general, there are two possible triangles that may correspond to the bevel join area, (c, l1, l0) and (c, u0, u1).  illustrates an example where the (c, l1, l0) triangle corresponds to the bevel join area.","To avoid drawing an unnecessary triangle, geometry shader  may, in some examples, take the cross product of the difference vectors (u0\u2212l0) and (u1\u2212l1) and identify which triangle to draw based on the cross product of the difference vectors. In further examples, geometry shader  may take the cross product of the normals for each of the intersecting path segments at the endpoint where the two path segments meet (i.e., c), and identify which triangle to draw based on the cross product of the difference vectors. Geometry shader  may generate a triangle primitive for the identified triangle that corresponds to the bevel area and pass the triangle primitive on to one or more subsequent stages of graphics pipeline  (e.g., rasterizer ) such that GPU  renders the identified triangle.","In either of the above-mentioned examples, geometry shader  may determine which triangles to draw or render for the bevel join based on the sign of the cross product. For example, if the sign of the cross product in either of the above examples is negative, then geometry shader  may determine to draw the (c, l1, l0) triangle for the bevel join and to not draw the (c, u0, u1) triangle for the bevel join. On the other hand, if the sign of the cross product in either of the above examples is positive, then geometry shader  may determine to draw the (c, u0, u1) triangle for the bevel join and to not draw the triangle (c, l1, l0). In some examples, determining to draw a particular triangle may correspond to geometry shader  generating and outputting the particular triangle and determining not to draw a particular triangle may correspond to geometry shader  not generating and\/or not outputting the particular triangle.","Graphics pipeline  may render the one or more triangles generated by geometry shader  for the bevel join area. Once the one or more triangles have been rendered, the render target (e.g., the frame buffer) may store a rasterized version of the stroke area for a bevel join between the two path segments.",{"@attributes":{"id":"p-0191","num":"0203"},"figref":["FIG. 9","FIG. 8"],"b":"12"},"As shown in , point c may correspond to an endpoint of a path segment where two path segments meet, u0 and l0 may correspond to corner points generated based on the first path segment for the endpoint (i.e., c), and u1 and l1 may correspond to corner points generated based on the second path segment for the endpoint (i.e., c) Similar to the bevel join described above with respect to , domain shader  may receive data indicative of the join to be rendered from hull shader , generate a normal for each of the tangents associated with the join based on data indicative of the tangents received by domain shader , and provide one or more vertices that correspond to the join to be rendered to geometry shader  for further processing. The one or more vertices may include one or more attributes indicative of the common endpoint where two path segments meet (i.e., point c), one or more attributes indicative of the normals for each of the path segments at the common endpoint, and one or more attributes indicative of the type of path rendering primitive (e.g., a join in this case).","Geometry shader  may, in some examples, receive the one or more vertices from domain shader , and determine the corner points (u0, u1, l0, l1) for the endpoints of the path segments where the two path segments meet. In some examples, geometry shader  may determine the corner points (u0, u1, l0, l1) based on one or more of equations (15)-(18) as described in this disclosure.","To render a miter join, geometry shader  may determine two difference vectors according to the following equations:\n\n0=(00)\/2\u2003\u2003(25)\n\n1=(11)\/2\u2003\u2003(26)\n\nwhere v0 and v1 correspond to the two difference vectors, u0 and u1 correspond to corner points generated based on a first path segment for an endpoint where two adjacent path segments meet (i.e., c), and l0 and l1 correspond to corner points generated based on a second path segment for the endpoint where the two adjacent path segments meet (i.e., c).\n","Geometry shader  may add the two difference vectors together to determine a center direction according to the following equation:\n\n=(01)\/2\u2003\u2003(27)\n\nwhere v corresponds to the center direction, and v0 and v1 correspond to the two difference vectors calculated in equations (25) and (26).\n","Geometry shader  may determine the miter length according to the following equation:\n\nmiter length=(strokeWidth*strokeWidth)\/(4|)\u2003\u2003(28)\n\nwhere miter length corresponds to the length of the miter, and v corresponds to the center direction calculated in equation (27). As shown in , the miter length may correspond to the length between a first point and a second point. The first point may correspond to a point where the stroke areas for the path segments meet on first sides of the path segments. The second point may correspond to a point where the stroke areas for the path segments meet on second sides of the path segments opposite the first sides.\n","If the miter length is greater than the miter limit times the stroke width, then geometry shader  may replace the miter join with a bevel join. Otherwise, geometry shader  may determine the miter point according to the following equation:",{"@attributes":{"id":"p-0198","num":"0210"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"m","mo":"=","mrow":{"mi":"c","mo":"+","mrow":{"mi":"v","mo":"*","mrow":{"mo":["(",")"],"mfrac":{"msup":{"mi":"strokeWidth","mn":"2"},"mrow":{"mn":"4","mo":"*","msup":{"mrow":{"mo":["\uf603","\uf604"],"mi":"v"},"mn":"2"}}}}}}}},{"mrow":{"mo":["(",")"],"mn":"29"}}]}}}},"br":{}},"GPU  may render one or more triangles that spatially correspond to the miter area. In general, there are two possible sets of triangles that may correspond to the miter join area, {(c, l1, l0), (m, l0, l1)} and {(c, u0, u1), (m, u0, u1)}.  illustrates an example where the {(c, l1, l0), (m, l0, l1)} triangle set corresponds to the miter join area.","To avoid drawing an unnecessary triangles, geometry shader  may, in some examples, take the cross product of the difference vectors (u0\u2212l0) and (u1\u2212l1) and identify which set of triangles to draw based on the cross product of the difference vectors. In further examples, geometry shader  may take the cross product of the normals for each of the intersecting path segments at the endpoint where the two path segments meet (i.e., c), and identify which set of triangles to draw based on the cross product of the difference vectors. Geometry shader  may generate a triangle primitive for each triangle in the identified set triangle of triangles that corresponds to the miter area and pass the triangle primitives on to one or more subsequent stages of graphics pipeline  (e.g., rasterizer ) such that GPU  renders the identified set of triangles.","In either of the above-mentioned examples, geometry shader  may determine which triangles to draw or render for the miter join based on the sign of the cross product. For example, if the sign of the cross product in either of the above examples is negative, then geometry shader  may determine to draw the triangles in the {(c, l1, l0), (m, l0, l1)} triangle set for the miter join and to not draw the triangles in the {(c, u0, u1), (m, u0, u1)} triangle set for the miter join. On the other hand, if the sign of the cross product in either of the above examples is positive, then geometry shader  may determine to draw the triangles in the {(c, u0, u1), (m, u0, u1)} triangle set for the miter join and to not draw the triangles in the {(c, l1, l0), (m, l0, l1)} triangle set for the miter join. In some examples, determining to draw a triangles in a particular triangle set may correspond to geometry shader  generating and outputting the triangles in the particular triangle set and determining not to draw triangles in a particular triangle set may correspond to geometry shader  not generating and\/or not outputting triangles in the particular triangle set.","Graphics pipeline  may render the triangles generated by geometry shader  for the miter join area. Once the one or more triangles have been rendered, the render target (e.g., the frame buffer) may store a rasterized version of the stroke area for a miter join between the two path segments.",{"@attributes":{"id":"p-0203","num":"0215"},"figref":["FIG. 10","FIG. 10"]},"According to a first technique for rendering round joins, graphics pipeline  may use tessellation stages  to generate a plurality of slice approximations for the round join area. Each slice approximation may correspond to a respective slice of the round join area where each slice is defined by the common endpoint (i.e., c) and two respective points along the curved edge of the round join. To approximate the slice, graphics pipeline  may use a line segment between the two respective points along the curved edge of the round join that are associated with the slice to approximate the curvature of the curved edge of the slice. To render the round join, in such examples, graphics pipeline  may render each of the slice approximations, which together may approximate the aggregate area of the round join.","To generate the slice approximations for a round join, tessellation stages  may generate a plurality of sets of two normal vectors where each set of two normal vectors may correspond to a respective one of the slices of the round join. The plurality of sets of normal vectors may include normal vectors that are interpolated between normal vectors associated with the point (i.e., c) where the two path segments meet. Each of the normal vectors may indicate the direction of one of the points along the curved edge of the round join relative to the common endpoint. Each slice approximation may be defined by the common endpoint (i.e., c) and two normal vectors. This is the same information that graphics pipeline  uses to render bevel join areas as discussed above with respect to . Thus, graphics pipeline  may render each slice approximation using the same techniques as those described above with respect to the bevel joins.","In addition to normalizing the tangents and\/or converting the tangents from Cartesian coordinates to angular coordinates, as described above with respect to joins in general, for round joins, hull shader  may configure and cause tessellator  to generate a plurality of output values for evaluation by domain shader . For example, hull shader  may execute a patch constant function for each round join. The patch constant function may determine configuration parameters and provide such configuration parameters to tessellator  to be used by tessellator  when generating output values. For example, the patch constant function may cause hull shader  to provide tessellation factors to tessellator . The tessellation factors may specify a degree of tessellation that tessellator  is to apply to a particular tessellation domain (e.g., how finely the domain should be subdivided and\/or the number of smaller objects into which the domain should be subdivided). In some examples, hull shader  may cause tessellator  to perform 4\u00d7 tessellation for round joins. In some examples, hull shader  may specify an isoline tessellation domain and specify that tessellator  should subdivide the isoline domain into line segments.","Domain shader  may generate an output vertex for each output value received from tessellator . Each output vertex generated with respect to a particular round join may include the same position coordinates, which may correspond to the coordinates of the point where two path segments meet (i.e., point c). The coordinates for this point may be specified in the patch control list received from hull shader . The normal attributes for each output vertex generated for the join may be different. In some examples, domain shader  may generate the normal attributes for the round join using linear interpolation based on the two different angular coordinates for the two tangents included in the patch control list received from hull shader . For example, for each output value received from tessellator , domain shader  may evaluate one or more equations based on the output value received from tessellator  to determine the normal coordinates to output as attributes of a corresponding vertex.","In some examples, domain shader  may generate the normal coordinates based on one or more of the following equations:\n\nlerpedAngle=(1)*firstAngle+*secondAngle\u2003\u2003(30)\n\nnorm.=cos(lerpedAngle)\u2003\u2003(31)\n\nnorm.=\u2212sin(lerpedAngle)\u2003\u2003(32)\n\nwhere firstAngle corresponds to an angular coordinate associated with a tangent for a first path segment associated with the join at the common point where the two path segments associated with the join meet, secondAngle corresponds to an angular coordinate associated with a tangent for a second path segment associated with the join at the common point where the two path segments associated with the join meet, u corresponds to an output value provided by tessellator , and (norm.x, norm.y) corresponds to the (x,y) normal coordinates that are generated by domain shader  for the vertex.\n","Geometry shader  may process each slice approximation in the same manner as that which was discussed above with respect to the bevel join except that the two path segment normals used to generate the bevel join may be replaced by the tessellated normals generated by tessellation stages . For example, for each slice approximation, geometry shader  may generate a triangle that spatially corresponds to the slice approximation. Graphics pipeline  may render the triangles for all of the slice approximations. Once all slice approximations have been rendered, the render target (e.g., the frame buffer) may store a rasterized version of the stroke area for a join between the two path segments.","As discussed above, round joins may be tessellated into a plurality of slices using the tessellation engine. By the time a slice of the round join reaches geometry shader , the slice may be treated just like a bevel-join and a single triangle may be rendered that approximates the area of the slice. In such examples, there may be a multitude of bevel-type joins generated for a round join, so there may be more than one geometry shader instance invoked for a round join.","Compared to the second technique described below for rendering joins, the first technique described above may allow the tessellation engine to be utilized, and may achieve a predictable and a lower vertex output count from a single geometry shader instance. This may improve the performance of the system when rendering joins compared to the second technique described in further detail below.","According to a second technique for rendering round joins, geometry shader  may divide the join section into pieces of angle \u03b1 (shown in ) and may approximate the divisions by triangles. The maximum angle that allows pixel accurate rendering may be predetermined for a given strokewidth. Geometry shader  may take the vertices found on a bevel join section, and keep applying a rotation matrix from one direction to generate the vertices of a triangle fan that approximates the area of the round join. Graphics pipeline  may render the triangle fan such that the render target (e.g., the frame buffer) stores a rasterized version of the stroke area for a join between two path segments.","Techniques are now described for rendering endcaps. Endcaps may be applied at the beginning and end of a path that is formed from a plurality of path segments. In some examples, there may be two different types of endcaps: (1) square caps; and (2) round caps. In some examples, the type of endcap to be rendered may be stored in a buffer in GPU  (e.g., a patch constant buffer), and CPU  may indicate the type of endcap to use for rendering by placing a value indicative of the type of endcap into the buffer.","An endcap may be formed at the beginning or end of a path segment that corresponds to the beginning or end of a path. To render an endcap, CPU  may place data indicative of the position of the endcap (e.g., the endpoint of a path segment) and data indicative of a tangent at that position into a buffer (e.g., a vertex buffer in path data ) for consumption by GPU .","In some examples, the input path data for an endcap may take the following form or a similar form:",{"@attributes":{"id":"p-0216","num":"0228"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"70pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","pos.x,","pos.y,","6.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","tan.x,","tan.y,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) },"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{},"b":["12","6"]},"In some examples, to render an endcap, hull shader  may convert the tangent (tan.x, tan.y) that corresponds to the endcap from Cartesian coordinates to angular coordinates. In further examples, hull shader  may normalize the tangent (tan.x, tan.y) that corresponds to the endcap prior to converting the Cartesian coordinates to angular coordinates. In additional examples, hull shader  may place the angular coordinates for the tangent into one or more attributes of the patch control list received by hull shader  and pass the modified patch control list to domain shader  for further processing. In some examples, hull shader  may implement the pseudo-code and\/or shader program code discussed above with respect to joins to normalize the tangents and\/or to convert the Cartesian coordinates for the tangents into angular coordinates.","As one specific example, an input patch control list received by hull shader  for an endcap may be as follows:",{"@attributes":{"id":"p-0219","num":"0231"},"tables":{"@attributes":{"id":"TABLE-US-00013","num":"00013"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"84pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","\u22120.4f,","0.8f,","6.0f ) } \/\/ location"]},{"entry":[{},"{ XMFLOAT3(","0.8f,","0.0f,","1.0f ) } \/\/ tangent"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) }"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) }"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}},"br":{},"b":"48"},{"@attributes":{"id":"p-0220","num":"0232"},"tables":{"@attributes":{"id":"TABLE-US-00014","num":"00014"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"4","colwidth":"84pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{ XMFLOAT3(","\u22120.4f,","0.8f,","6.0f ) }, \/\/ location"]},{"entry":[{},"{ XMFLOAT3(","0.8f,","0.0f,","0.0f ) }, \/\/ tangent"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) },"]},{"entry":[{},"{ XMFLOAT3(","0.0f,","0.0f,","1.0f ) },"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}}},{"@attributes":{"id":"p-0221","num":"0233"},"figref":["FIG. 11","FIG. 11","FIG. 11"],"b":"12"},"In some examples, domain shader  may receive data indicative of a cap to be rendered from hull shader , generate one or more vertices that correspond to the cap to be rendered, and provide the vertices to geometry shader  for further processing. The data indicative of the cap to be rendered may include data indicative of the position or location where the cap is formed (e.g., the endpoint of a path segment), data indicative of a tangent for the path segment at the position or location where the cap is formed, and data indicative of the type of path rendering primitive (e.g., a cap in this case). In some examples, the data indicative of the cap to render may take the form of a patch control list (e.g., the patch control list specified above).","Domain shader  may generate a normal that corresponds to the tangent based on the data indicative of the tangent received by domain shader . For example, domain shader  may generate a normal for the tangent based on equation (14). The one or more vertices produced by domain shader  may include one or more attributes indicative of the endpoint of the path segment (i.e., point c) at which the cap is formed, one or more attributes indicative of a normal for the path segment at the endpoint (i.e., point c), and one or more attributes indicative of the type of path rendering primitive (e.g., a cap in this case).","Geometry shader  may, in some examples, receive one or more vertices from domain shader , and determine the corner points (u, l) for the endpoint of the path segment where the endcap is formed based on one or more of equations (15)-(18) as described in this disclosure. Geometry shader  may determine a vector v according to the following equation:\n\n=()\/2\u2003\u2003(33)\n\nwhere u and l correspond to corner points of a stroke area for an endpoint of a path segment.\n","Geometry shader  may rotate the vector, v, by 90 degrees to find a vector, n, according to the following equation:\n\n=()\u2003\u2003(34)\n\nwhere a=(x, y) indicates the x and y components of the vector, a, where v.y corresponds the y-component of the vector v, and where v.x corresponds to the x-component of the vector v.\n","Geometry shader  may determine new points (e.g. vertices) for a starting cap or an ending cap according to the following equations:\n\n\u2003\u2003(35)\n\n\u2003\u2003(36)\n\nwhere nu and nl are new corner points for the cap, and u and l correspond to corner points of a stroke area for an endpoint of a path segment.\n","Geometry shader  may generate one or more triangles for rendering the square cap that spatially correspond to the square cap area. For example, geometry shader  may generate two triangles (e.g., (u, l, nu) and (nu, l, nl)), that spatially correspond to the square cap area. Graphics pipeline  may render the one or more triangles generated by geometry shader  for the square cap area. Once the one or triangles have been rendered, the render target (e.g., the frame buffer) may store a rasterized version of the stroke area for a square cap.",{"@attributes":{"id":"p-0228","num":"0240"},"figref":["FIG. 12","FIG. 12"],"b":"12"},"According to a first technique for rendering round caps, graphics pipeline  may use the tessellation stages  to generate a plurality of slice approximations for the round cap area. Each slice approximation may correspond to a respective slice of the round cap area where each slice is defined by the path endpoint (i.e., c) and two respective points along the curved edge of the round cap. To approximate the slice, graphics pipeline  may use a line segment between the two respective points along the curved edge of the round cap that are associated with the slice to approximate the curvature of the curved edge of the slice. To render the round cap, in such examples, graphics pipeline  may render each of the slice approximations, which together may approximate the aggregate area of the round cap.","To generate the slice approximations for a round cap, tessellation stages  may generate a plurality of sets of two normal vectors where each set of two normal vectors may correspond to a respective one of the slices of the round cap. The plurality of sets of normal vectors may include normal vectors that are interpolated between a normal vector associated with the endpoint of the path segment (i.e., c) where the round cap is formed and a vector that points in the opposite direction of the normal vector. Each of the normal vectors may indicate the direction of one of the points along the curved edge of the round cap relative to the common endpoint. Each slice approximation may be defined by the endpoint (i.e., c) where the round cap is formed and two normal vectors. This is the same information that graphics pipeline  uses to render bevel join areas as discussed above with respect to . Thus, graphics pipeline  may render each slice approximation using the same techniques as those described above with respect to the bevel joins.","In addition to normalizing the tangents and\/or converting the tangents from Cartesian coordinates to angular coordinates, as described above with respect to caps in general, for round caps, hull shader  may configure and cause tessellator  to generate a plurality of output values for evaluation by domain shader . For example, hull shader  may execute a patch constant function for each round cap. The patch constant function may determine configuration parameters and provide such configuration parameters to tessellator  to be used by tessellator  when generating output values. The patch constant function may, for example, cause hull shader  to provide tessellation factors to tessellator . The tessellation factors may specify a degree of tessellation that tessellator  is to apply to a particular tessellation domain (e.g., how finely the domain should be subdivided and\/or the number of smaller objects into which the domain should be subdivided). In some examples, hull shader  may cause tessellator  to perform 4\u00d7 tessellation for round caps. In some examples, hull shader  may specify an isoline tessellation domain and specify that tessellator  should subdivide the isoline domain into line segments.","Domain shader  may generate an output vertex for each output value received from tessellator . Each output vertex generated with respect to a particular round cap may include the same position coordinates, which may correspond to the coordinates of the endpoint of the path segment at which the cap is formed (i.e., point c). The coordinates for this point may be specified in the patch control list received from hull shader . The normal attributes for each output vertex generated for the round cap may be different. In some examples, domain shader  may generate the normal attributes for the round join using linear interpolation. The linear interpolation may be based on the angular coordinate for the tangent included in the patch control list received from hull shader  and based on an angular coordinate derived by adding pi (e.g., 180 degrees) to the angular coordinate for the tangent included in the patch control list received from hull shader . For each output value received from tessellator , domain shader  may evaluate one or more equations based on the output value received from tessellator  to determine the normal coordinates to output as attributes of a corresponding vertex.","In some examples, domain shader  may generate the normal coordinates based on one or more of the following equations:\n\nlerpedAngle=(1)*angle+*(angle+)\u2003\u2003(37)\n\nnorm.=cos(lerpedAngle)\u2003\u2003(38)\n\nnorm.=\u2212sin(lerpedAngle)\u2003\u2003(39)\n\nwhere angle corresponds to an angular coordinate associated with a tangent for the path segment at an endpoint of the path segment at which the round cap is formed, u corresponds to an output value provided by tessellator , and (norm.x, norm.y) corresponds to the (x,y) normal coordinates that are generated by domain shader  for the endpoint of the path segment.\n","Geometry shader  may process each slice approximation in the same manner as that which was discussed above with respect to the bevel join except that the two path segment normals used to generate the bevel join may be replaced by the tessellated normals generated by tessellation stages . For example, for each slice approximation, geometry shader  may generate a triangle that spatially corresponds to the slice approximation. Graphics pipeline  may render the triangles for all of the slice approximations. Once all slice approximations have been rendered, the render target (e.g., the frame buffer) may store a rasterized version of the stroke area for a round cap.","As discussed above, round caps may be tessellated into a plurality of slices by using the tessellation engine. By the time a slice of the round cap reaches geometry shader , the slice may be treated just like a bevel-join and a single triangle may be rendered that approximates the area of the slice. In such examples, there may be a multitude of bevel-type joins generated from a round cap, so there may be more than one geometry shader instance invoked for a round cap.","Compared to the second technique described below for rendering caps, the first technique described above may allow the tessellation engine to be utilized, and may achieve a predictable and a lower vertex output count from a single geometry shader instance. This may improve the performance of the system when rendering caps compared to the second technique described in further detail below.","According to a second technique for rendering round caps, geometry shader  may divide the cap section into pieces of angle \u03b1 and approximate the divisions by triangles. The maximum angle that allows pixel accurate rendering may be predetermined for the current strokewidth. Geometry shader  may take the vertices found on a bevel join section, may keep applying a rotation matrix to one of the u or l vertices, and may create a triangle fan that approximates the area of the round cap. Graphics pipeline  may render the triangle fan such that the render target (e.g., the frame buffer) stores a rasterized version of the stroke area for the round cap.","The techniques described above for rendering joins and endcaps were generically described above as being performed by geometry shader . In some examples, all or part of the above-described techniques may be performed in one or more fixed-function and\/or programmable shader processing stages of GPU  in addition to or in lieu of geometry shader . Rasterizer  and the pixel processing pipeline stages may also be used to render the triangles that correspond to the join and endcap areas.",{"@attributes":{"id":"p-0239","num":"0251"},"figref":["FIGS. 13-16","FIGS. 13-16","FIGS. 1 & 2","FIG. 3","FIGS. 13-16"],"b":["12","40"]},{"@attributes":{"id":"p-0240","num":"0252"},"figref":"FIG. 13","b":["12","100"]},"GPU  tessellates a path segment defined by the path data into a plurality of line segments (). In some examples, tessellation stages  of GPU  may be used to perform the tessellation. GPU  renders at least one of a fill area and a stroke area for the path segment based on the plurality of line segments (). In some examples, GPU  may render both a fill area and a stroke area for the path segment based on the plurality of line segments.","The example technique shown in  generates tessellated line segments to perform GPU-accelerated path rendering. In other examples, other types of tessellated primitives may be generated to perform the GPU-accelerated path rendering, such as, e.g., tessellated points or vertices.",{"@attributes":{"id":"p-0243","num":"0255"},"figref":["FIG. 14","FIG. 14","FIG. 13"]},"GPU  receives path data (). The path data may be indicative of one or more path segments of a path to be rendered. GPU  tessellates a path segment defined by the path data into a plurality of line segments ().","GPU  generates a plurality of triangle primitives based on the plurality of line segments (). Each of the plurality of triangle primitives may be generated based on a respective one of the plurality of line segments. Each of the plurality of triangle primitives for a given path segment may share a common vertex. The other two vertices for each of the triangle primitives may correspond to the endpoints of a respective one of the plurality of line segments.","GPU  renders each of the plurality of triangle primitives into a common stencil buffer (). After rendering all of the triangle primitives into the stencil buffer, the stencil buffer may store data indicative of which pixels are inside of the fill area for the path segment. To render each of the plurality of triangle primitives into a common stencil buffer, GPU  may use one of the following techniques. According to a first technique, GPU  may, for each of the plurality of triangle primitives, invert one or more values in the stencil buffer that correspond to the respective triangle primitive. According to a second technique, GPU  may, for each of the plurality of triangle primitives, increment one or more values in the stencil buffer that correspond to the respective triangle primitive if a vertex order for the respective triangle primitive is oriented in a clockwise direction, and decrement values in the stencil buffer that correspond to the respective triangle primitive if a vertex order for the respective triangle primitive is oriented in a counter-clockwise direction.","GPU  renders one or more primitives corresponding to a bounding box for the fill area using the stencil buffer (). For example, GPU  may render one or more primitives that encompass the pixels that are inside of the fill area based on the data stored in the stencil buffer and a fill color to generate a rasterized version of the fill area for the path segment. The bounding box may encompass the pixels that are inside of the fill area for the path segment to be rendered. In some examples, the bounding box may be formed from two triangle primitives that encompass the pixels that are inside of the fill area for the path segment to be rendered. The data in the stencil buffer may cause pixels inside of the fill area to light up with a fill color (specified by CPU  prior to the second rendering pass), and cause pixels that are outside of the fill area to remain dark. Once the rendering of the bounding box has completed, the render target (e.g., the frame buffer) may store a rasterized version of the fill area for the path segment.","In some examples, process box  may be performed using tessellation stages  of GPU  (e.g., hull shader , tessellator  and\/or domain shader  of GPU ). In further examples, process box  may be performed using geometry shader  of GPU .",{"@attributes":{"id":"p-0249","num":"0261"},"figref":["FIG. 15","FIG. 15","FIG. 13"]},"GPU  receives path data (). The path data may be indicative of one or more path segments of a path to be rendered. GPU  tessellates a path segment defined by the path data into a plurality of line segments ().","GPU  generates a plurality of primitives that spatially corresponds to the stroke area for the path segment (). For example, for each of the plurality of tessellated line segments, GPU  may generate one or more primitives that spatially correspond to a stroke area for the respective line segment.","GPU  renders primitives that spatially correspond to the stroke area for the path segment (). For example, for each of the plurality of tessellated line segments, GPU  may render one or more primitives for a respective line segment based on a stroke color to generate a rasterized version of the stroke area for the path segment. Once the rendering of the primitives is complete, the render target (e.g., the frame buffer) may store a rasterized version of the stroke area for the path segment.","In some examples, process box  may be performed using tessellation stages  of GPU  (e.g., hull shader , tessellator  and\/or domain shader  of GPU ). In further examples, process box  may be performed using geometry shader  of GPU .",{"@attributes":{"id":"p-0254","num":"0266"},"figref":["FIG. 16","FIG. 16","FIG. 13"],"b":"120"},"For each of the tessellated line segments, GPU  generates a plurality of normal vectors for the respective line segment (). Each of the normal vectors may be indicative of a tangent of the path segment at a respective one of a plurality of points along the path segment. In some examples, a tangent of the path segment at a respective one of a plurality of points along the path segment may correspond to a tangent of the path segment that intersects the path segment at the respective one of the plurality of points along the path segment. Each of the plurality of points along the path segment may correspond to a respective one of the endpoints of the respective line segment. In some cases, each of the normal vectors may have a unit length. In further cases, each of the normal vectors may be represented as a set of normal coordinates which define the direction of the normal vector with respect to an origin. In some examples, GPU  may determine the normal vectors based on one or more of equations (9)-(14) as described in this disclosure.","For each of the tessellated line segments, GPU  determines a set of corner points that correspond to a stroke area for the respective line segment based on the plurality of normal vectors and a stroke width (). In some examples, the set of corner points may correspond to points u0, u1, l0, and l1 shown in . In further examples, GPU  may determine the set of corner points based on one or more of equations (15)-(18) as described in this disclosure.","For each of the tessellated line segments, GPU  may generate one or more primitives that spatially correspond to the stroke area for the respective line segment based on the corner points of the stroke area. For example, GPU  may determine the intersection point of the normal vectors (), determine if the intersection point is within the stroke area for the respective line segment (), and select triangles that correspond to the stroke area for the respective tessellated line segment based on the corner points, the intersection point, and the determination of whether the intersection point is within the stroke area for the respective line segment (). The intersection point may alternatively be referred to herein as a center point (i.e., c).","In some examples, GPU  may determine the intersection point based on one or more of equations (19)-(24) as described in this disclosure. In further examples, GPU  may determine whether the intersection point is within the stroke area for the respective line segment based on whether strokewidth<min(u0c,u1c) as described above in this disclosure.","In additional examples, GPU  may select triangles that correspond to the stroke area for the respective tessellated line segment based on the following technique. If the intersection point is outside of the stroke area (e.g., ), then GPU  may generate two triangles to form a quad that spatially corresponds to the stroke area. For example, GPU  may generate two triangles using the following combinations of vertices {u0, u1, l1} and {l1, l0, u0}.","If the intersection point is inside of the stroke area (e.g., ), then GPU  may generate two triangles to form a butterfly that spatially corresponds to the stroke area. For example, GPU  may generate two triangles using the following combinations of vertices {u0, u1, c} and {c, l0, l1} if the {u0, u1, c} triangle is oriented in a clockwise direction, and generate two triangles using the following combinations of vertices {u0, u1, c} and {c, l1, l0} if the {u0, u1, c} triangle is oriented in a counter-clockwise direction.",{"@attributes":{"id":"p-0261","num":"0273"},"figref":["FIG. 17","FIG. 17","FIGS. 1 & 2","FIG. 17"],"b":"6"},"CPU  (e.g., software application  and\/or GPU driver ) causes GPU  to tessellate a path segment into a plurality of line segments (). In some examples, in order to cause GPU  to tessellate a path segment into a plurality of line segments, CPU  may load one or both of a hull shader program and a domain shader program onto GPU , and cause the one or both of the hull shader program and the domain shader program to tessellate a path segment into a plurality of line segments in conjunction with an on-chip tessellation engine. The one or both of the hull shader program and the domain shader program may be configured to perform one or more of the techniques attributed to such programs in this disclosure. In some examples, CPU  may cause the one or both of the hull shader program and the domain shader program to tessellate a path segment into a plurality of line segments by placing data indicative of a path segment into one or more vertex buffers, and issuing a draw call with on-chip tessellation enabled.","CPU  (e.g., software application  and\/or GPU driver ) causes GPU  to render a fill area and\/or a stroke area based on tessellated line segments (). To cause GPU  to render a fill area based on tessellated line segments, CPU  may, in some examples, cause GPU  to generate a plurality of triangle primitives based on the plurality of line segments. Each of the plurality of triangle primitives may be generated based on a respective one of the plurality of line segments. In such examples, CPU  may cause GPU  to render each of the plurality of triangle primitives into a common stencil buffer such that the common stencil buffer stores data indicative of which pixels are inside of the fill area for the path segment, and to render one or more primitives that encompass the pixels that are inside of the fill area based on the data stored in the stencil buffer and a fill color to generate a rasterized version of the fill area for the path segment.","In some examples, in order to cause GPU  to generate a plurality of triangle primitives based on the plurality of line segments, CPU  may load a geometry shader program onto GPU , and cause the geometry shader program to generate a plurality of triangle primitives based on the plurality of line segments. The geometry shader program may be configured to perform one or more of the techniques attributed to the geometry shader program in this disclosure. In some examples, CPU  may cause the geometry shader program to generate the plurality of triangle primitives by placing data indicative of a path segment into one or more vertex buffers, and issuing a draw call with the geometry shader enabled.","In some examples, in order to cause GPU  to generate a plurality of triangle primitives based on the plurality of line segments, CPU  may cause GPU  to, for each of the plurality of triangle primitives, increment one or more values in the stencil buffer that correspond to the respective triangle primitive if a vertex order for the respective triangle primitive is oriented in a clockwise direction. In such examples, CPU  may cause GPU  to, for each of the plurality of triangle primitives, decrement one or more values in the stencil buffer that correspond to the respective triangle primitive if the vertex order for the respective triangle primitive is oriented in a counter-clockwise direction. In further examples, in order to cause GPU  to generate a plurality of triangle primitives based on the plurality of line segments, CPU  may cause GPU  to, for each of the plurality of line segments, invert one or more values in the stencil buffer that correspond to the respective triangle primitive.","To cause GPU  to render a stroke area based on tessellated line segments, CPU  may, in some examples, cause GPU  to, for each of the plurality of line segments, generate one or more primitives that spatially correspond to a stroke area for the respective line segment, and for each of the plurality of line segments, render the one or more primitives for the respective line segment based on a stroke color to generate a rasterized version of the stroke area for the path segment.","In some examples, in order to cause GPU  to generate the one or more primitives that spatially correspond to the stroke area for the respective line segment, CPU  may load a geometry shader program onto GPU , and cause the geometry shader program to generate a plurality of triangle primitives based on the plurality of line segments. The geometry shader program may be configured to perform one or more of the techniques attributed to the geometry shader program in this disclosure. In some examples, CPU  may cause the geometry shader program to generate the plurality of triangle primitives by placing data indicative of a path segment into one or more vertex buffers, and issuing a draw call with the geometry shader enabled.","In some examples, in order to cause GPU  to generate the one or more primitives that spatially correspond to the stroke area for the respective line segment, CPU  may cause domain shader  in GPU  to generate a plurality of normal vectors for a respective line segment. Each of the normal vectors may be indicative of a direction that is perpendicular to a tangent of the path segment at a respective one of a plurality of points along the path segment. Each of the plurality of points along the path segment may correspond to a respective one of the endpoints of the respective line segment. In such examples, CPU  may, in some examples, cause geometry shader  in GPU  to determine the corner points of a stroke area for the respective line segment based on the plurality of normal vectors and a stroke width, and to generate one or more primitives that spatially correspond to the stroke area for the respective line segment based on the corner points of the stroke area.","In some examples, the techniques of this disclosure may be used to perform path rendering on DirectX\u00ae GPUs. In further examples, the techniques of this disclosure may be implemented and tested on an OpenVG\u2122 platform and\/or may conform to OpenVG\u2122 path rendering standards. In additional examples, the techniques of this disclosure may provide a GPU accelerated solution to path rendering for DirectX\u00ae versions 9.3, 11 and 11+. DirectX\u00ae 11+ may refer to a modified DirectX\u00ae 11 architecture.","In some examples, a path may refer to a plurality of path segments, which may be, e.g., a line, an elliptic arc, a quadratic B\u00e9zier curve and a cubic B\u00e9zier curve. A path may be either \u201cclosed\u201d or not (i.e., open). A closed path may refer to a path where the last vertex is connected to the first vertex via a line and where the path forms a closed shape. An open path may refer to path where the last vertex does not necessarily connect to the first vertex. A path may overlap itself numerous times. Path rendering may be divided into two main tasks: Filling and Stroking.","Filling a path may refer to filling the interior region of a given path by the fill color. The interior region may be defined using, e.g., either even\/odd fill rules or non-zero fill rules. In some examples, the techniques of this disclosure may provide a two-pass approach that uses the VS\/HS\/DS\/GS (i.e., vertex shader\/hull shader\/domain shader\/geometry shader) on the first pass, and the VS\/PS (i.e. vertex shader\/pixel shader) on the second pass. The first pass may generate fill information in the stencil buffer, and the second pass may cover the stencil area in order to render the fill area for the path onto the frame buffer. In some examples, the two-pass approach may be implemented in a DirectX\u00ae 11 (DX11) graphics pipeline without, in some examples, any substantial modifications to the DX11 pipeline architecture.","In some examples, the path filling operation may be performed as follows:\n\n","In some examples, tessellating the path into line segments may involve using a four (4) control point patch list as the input format for path segments as described earlier in this disclosure. In further examples, tessellating the path into line segments may involve evaluating paths using domain shader  as described earlier in this disclosure. In additional examples, tessellating the path into line segments may involve finding an ellipse center for elliptic arc as described earlier in this disclosure.","In some examples, creating a triangle in every GS instance by connecting the pivot point to line segments and then rendering the triangles to the stencil buffer may involve, after the line segments are produced in the DS, using the GS to connect the predetermined pivot point to every line segment to create triangles. Rasterizer  may then rasterize these triangles onto the stencil buffer, where front facing triangles increase the stencil result and back face triangles decrease the stencil result.","In some examples, rendering the bounding box area with stencil test enabled may involve passing down two triangles covering the bounding box area of the path with stencil test enabled to light up the pixels that fall into the path fill.","Stroking a path may refer to \u201cwidening\u201d the edges of the path using a straight-line pen held perpendicularly to the path. In some examples, the techniques of this disclosure may tessellate and evaluate the path, and at each evaluated point, widen the point according to the normal at that point and create triangulation to form segments. The union of all segments may form the stroke line (e.g., the stroke area for the line).","In some examples, the techniques of this disclosure may provide a single pass approach that uses VS\/HS\/DS (i.e., vertex shader\/hull shader\/domain shader) to tessellate lines, and that uses a GS (i.e., geometry shader) to fatten the lines by the stroking width. Joins and endcaps may go through the same pipeline and be handled in the GS. The resulting triangles may then be rasterized in the same rendering pass. In some examples, the single pass approach may be implemented in a DirectX 11\u00ae (DX11) graphics pipeline without, in some examples, any substantial modifications to the DX11 pipeline architecture.","In some examples, the stroking operation may be performed as follows:\n\n","In some examples, tessellating the path into line segments may involve using a four (4) control point patch list as the input format for path segments as described earlier in this disclosure. In further examples, tessellating the path into line segments may involve evaluating paths using domain shader  as described earlier in this disclosure. In additional examples, tessellating the path into line segments may involve finding an ellipse center for elliptic arc as described earlier in this disclosure.","In some examples, fattening the line segments and creating the triangulation may involve, after the line segments are produced, using the GS to fatten every line segment by shifting the endpoints in positive and negative normal directions in the GS. The GS may then generate the triangulation of the stroke area. Joins and caps may also be handled in the GS.","In some examples, rendering the triangles with depth test enabled may involve rendering the triangle stream from the GS with depth testing enabled in order to handle overlapping portions correctly. In some examples, the stencil buffer may be used in lieu of depth buffer to mimic the depth testing functionality without allocating separate stencil and depth buffers.","Table 1 illustrates a comparison of the techniques of this disclosure implemented in different generations of DirectX\u00ae graphics pipelines. It should be noted that the properties listed in Table 1 for the techniques of this disclosure do not necessarily apply to all examples of the techniques described herein.",{"@attributes":{"id":"p-0283","num":"0301"},"tables":{"@attributes":{"id":"TABLE-US-00015","num":"00015"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Comparison of implementation of example techniques of this disclosure"},{"entry":"for different generations of DirectX\u00ae graphics pipelines."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"91pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"63pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Features",{}]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"63pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Dashes\/","Data to","Multi-",{}]},{"entry":["Product","cusps","memory","pass","Notes"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}},{"entry":["DirectX\u00ae 9.3 with","No","yes","yes","Slow performance"]},{"entry":["Compute Shader",{},{},{},"because of data"]},{"entry":[{},{},{},{},"to memory."]},{"entry":["DirectX\u00ae 11","No","no","yes",{}]},{"entry":["DirectX\u00ae 11+","Yes","no","no","Hardware changes"]},{"entry":[{},{},{},{},"needed."]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"Described below are possible combinations of algorithms that may be used to perform path rendering on a DirectX\u00ae 11 level or later graphics pipeline.","The filling operation may be represented as:\n\n","The stoking operation may be represented as:\n\n","In some examples, joins and caps may form part of the GPU input, and may be packed into a vertex buffer as part of the path data. In such examples, a CPU may find endpoint tangents of path segments, which may correspond to control point differences for curves and lines. For ellipses, the CPU may convert the ellipse into parametric form first then find endpoint tangents.","In some examples, the techniques of this disclosure may require little or no CPU involvement and\/or data manipulation. In additional examples, the techniques of this disclosure may not necessarily implement re-tessellation\/cusps and dashes. In additional examples, the total number of rendering passes may be modeled as 2*PF+PS.","Path rendering may include two stages called filling a closed path and stroking the path. A path may include one or more of the three: a line, a quadratic\/cubic B\u00e9zier curve, or an elliptic arc. Although many CPU implementations exist to render paths, and some (e.g., implemented by NVidia) may use a CPU\/GPU hybrid implementation. Rendering the paths on the CPU may be a wasteful approach that does not exploit the parallel nature of the problem. CPU\/GPU hybrid implementations may suffer from the performance loss due to device communication.","In some examples, the techniques of this disclosure provide an approach to path rendering that is a DirectX\u00ae 11 based 100% GPU rendering solution, where dashing is disabled and the paths do not have cusps or zero tangents. Over 95% of real life scenarios typically do not have cusps or zero tangents. Using the GPU, rendering time and power consumption may be significantly decreased. If dashing is needed, additional CPU operations may be used for handling the dashing between two rendering passes.","In some examples, the techniques of this disclosure may allow users of DirectX\u00ae 11 hardware to perform path rendering using DirectX\u00ae 11 hardware or with hardware that has similar performance characteristics. In further examples, the techniques of this disclosure may provide an all-GPU rendering solution to path rendering.","Although the techniques of this disclosure have been primarily described with respect to a hardware architecture that is defined by the DX 11 graphics API, the techniques of this disclosure may also be performed in hardware architectures defined according to other on-chip, tessellation-enabled graphics APIs such as, e.g., the OpenGL\u00ae graphics API (e.g., OpenGL\u00ae versions 4.0, 4.1, 4.2, 4.3 and later versions). In examples where the techniques of this disclosure are implemented in a hardware architecture defined according to the OpenGL\u00ae graphics API, one or more of the functions attributed to hull shader  in this disclosure may be performed by a tessellation control shader and\/or one or more of the functions attributed to domain shader  in this disclosure may be performed by a tessellation evaluation shader.","Further details regarding the general operation of the OpenGL\u00ae graphics pipeline may be found in \u201cThe OpenGL\u00ae Graphics System: A Specification (Version 4.3 (Core Profile)\u2014Aug. 6, 2012),\u201d Aug. 6, 2012, The Khronos Group, Inc. available at http:\/\/www.opengl.org\/registry\/doc\/glspec43.core.20120806.pdf, the entire content of which is incorporated herein by reference.","The techniques described in this disclosure may be implemented, at least in part, in hardware, software, firmware or any combination thereof. For example, various aspects of the described techniques may be implemented within one or more processors, including one or more microprocessors, digital signal processors (DSPs), application specific integrated circuits (ASICs), field programmable gate arrays (FPGAs), or any other equivalent integrated or discrete logic circuitry, as well as any combinations of such components. The term \u201cprocessor\u201d or \u201cprocessing circuitry\u201d may generally refer to any of the foregoing logic circuitry, alone or in combination with other logic circuitry, or any other equivalent circuitry such as discrete hardware that performs processing.","Such hardware, software, and firmware may be implemented within the same device or within separate devices to support the various operations and functions described in this disclosure. In addition, any of the described units, modules or components may be implemented together or separately as discrete but interoperable logic devices. Depiction of different features as modules or units is intended to highlight different functional aspects and does not necessarily imply that such modules or units must be realized by separate hardware or software components. Rather, functionality associated with one or more modules or units may be performed by separate hardware, firmware, and\/or software components, or integrated within common or separate hardware or software components.","The techniques described in this disclosure may also be stored, embodied or encoded in a computer-readable medium, such as a computer-readable storage medium that stores instructions. Instructions embedded or encoded in a computer-readable medium may cause one or more processors to perform the techniques described herein, e.g., when the instructions are executed by the one or more processors. Computer readable storage media may include random access memory (RAM), read only memory (ROM), programmable read only memory (PROM), erasable programmable read only memory (EPROM), electronically erasable programmable read only memory (EEPROM), flash memory, a hard disk, a CD-ROM, a floppy disk, a cassette, magnetic media, optical media, or other computer readable storage media that is tangible.","Computer-readable media may include computer-readable storage media, which corresponds to a tangible storage medium, such as those listed above. Computer-readable media may also comprise communication media including any medium that facilitates transfer of a computer program from one place to another, e.g., according to a communication protocol. In this manner, the phrase \u201ccomputer-readable media\u201d generally may correspond to (1) tangible computer-readable storage media which is non-transitory, and (2) a non-tangible computer-readable communication medium such as a transitory signal or carrier wave.","Various aspects and examples have been described. However, modifications can be made to the structure or techniques of this disclosure without departing from the scope of the following claims."],"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 17"}]},"DETDESC":[{},{}]}
