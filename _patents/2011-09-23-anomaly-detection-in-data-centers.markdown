---
title: Anomaly detection in data centers
abstract: Systems and methods of anomaly detection in data centers. An example method may include analyzing time series data for the data center by testing statistical hypotheses. The method may also include constructing upper and lower bounds based on the statistical hypotheses. The method may also include flagging anomalies in the time series data falling outside of the upper and lower bounds.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08688620&OS=08688620&RS=08688620
owner: Hewlett-Packard Development Company, L.P.
number: 08688620
owner_city: Houston
owner_country: US
publication_date: 20110923
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","DETAILED DESCRIPTION"],"p":["The client\/server computing environment continues to expand into web services (often referred to as \u201cWeb 2.0\u201d), with the latest iteration of Internet supported programmatic access to services and data provided by data centers. Commercial data centers can be characterized by scale and complexity. By way of illustration, individual applications (e.g., Web 2.0 applications) may operate across thousands of servers. Utility clouds may serve more than two million enterprises, each with different workload characteristics. Accordingly, data center management is a difficult task, and failing to respond to malfunctions can lead to lost productivity and profits.","Anomaly detection deployed in many data centers compare metrics (which are being monitored in the data center) to fixed thresholds. These thresholds may be determined \u201coffline,\u201d e.g., using training data, and tend to remain constant during the entire monitoring process. Static thresholds are invariant to changes in the statistical distributions of the metrics that occur over time due to man, material, machine, and processes. Thus, static thresholds do not adapt to intermittent bursts or workloads that change in nature over time. Static thresholds cannot be used to effectively identify anomalous behavior unless that behavior is considered extremely large or extremely small. These factors reduce accuracy and tend to cause false alarms.","Approaches such as Multivariate Adaptive Statistical Filtering (MASF) maintain a separate threshold for data segmented and aggregated by time (e.g., hour of day, day of week). However, these techniques assume a Gaussian data distribution for determining the thresholds. This assumption is frequently violated in practice.","Academic statistical techniques cannot be implemented at the scale of data centers and cloud computing systems, and do not work well in online environments because of the high computing overheads and use of very large amounts of raw metric information. In addition, these techniques typically need prior knowledge about the application service level objectives, service implementations, and request semantics. These techniques also tend to focus only on solving certain well-defined problems at specific levels of abstraction.","Anomaly detection may be used to understand if a system is behaving as expected or in ways that are unusual therefore and deserve further investigation and diagnosis. Online anomaly detection described herein, may be used in data center management to detect and quickly respond to actual or anticipated disruptions in service. In a data center, anomaly detection should be continuous (while the system is running) and at scale (for entire data centers).","The systems and methods disclosed herein are \u201clightweight\u201d techniques that do not rely on fixed-threshold approaches. A new windowing-based approach can be applied to observe changes in the distribution of data. In an example, statistical techniques may be implemented for analyzing data for multi-tier web applications running on server class machines.","The systems and methods disclosed herein improve system performance and availability, and may be implemented as online, closed loop management solutions that detect problems, diagnose problems to determine potential remedies or mitigation methods, and trigger and carry out solutions. The systems and methods disclosed herein are adaptable by \u201clearning\u201d workload characteristics over time, improve accuracy and reduce false alarms. These techniques also meet projected scalability needs of future data centers, are applicable to multiple contexts of data (detecting contextual anomalies), and can be applied across multiple metrics in a wide variety of different types, sizes, and complexity of data centers.","Before continuing, it is noted that as used herein, the terms \u201cincludes\u201d and \u201cincluding\u201d mean, but is not limited to, \u201cincludes\u201d or \u201cincluding\u201d and \u201cincludes at least\u201d or \u201cincluding at least.\u201d The term \u201cbased on\u201d means \u201cbased on\u201d and \u201cbased at least in part on.\u201d",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1","b":["100","100","110","120","125"]},"In an example, the data center  may include at least one host  providing a service accessed by a user via a client device . For purposes of illustration, the service may be an online data processing service executing on host  configured as a server computer. Example services may include general purpose computing services (e.g., access to applications and application data hosted on the Internet or as dynamic data endpoints for any number of client applications). Services also include interfaces to application programming interfaces (APIs) and related support infrastructure which were previously the exclusive domain of desktop and local area network computing systems, such as application engines (e.g., word processing and graphics applications), and hosted business services (e.g., package delivery and tracking, online payment systems, and online retailers).","The client device  may be any suitable computer or computing device capable of accessing the host . Host  and client  are not limited to any particular type of devices. The system  may also include a communication network , such as a local area network (LAN) and\/or wide area network (WAN). The host  and client  may be provided on the network  via a communication connection, such as via an Internet service provider (ISP). In this regard, the client  is able to access services provided in the data center in directly via the network , or via an agent, such as another network.","In an example, program code  may be implemented for monitoring the data center and detecting anomalies so that corrective action can be instituted so that the data center can provide the services to clients on a continuous or uninterrupted basis. For example, the service may be a cloud-based application service. Detecting anomalies in the data center may enable an administrator or monitoring service to proactively identify and remedy problems within the data center before those problems affect the ability of clients to access the cloud-based application service.","The program code  may be stored on computer-readable media  and executed by any suitable computing device . In an example, the program code may be implemented in machine-readable instructions (such as but not limited to, software or firmware). The machine-readable instructions may be stored on a non-transient computer readable medium and are executable by one or more processor to perform the operations described herein. It is noted, however, that the components shown in  are provided only for purposes of illustration of an example operating environment, and are not intended to limit implementation to any particular system.","The program code executes the function of the architecture of machine readable instructions as self-contained modules. These modules can be integrated within a self-standing tool, or may be implemented as agents that run on top of an existing program code. In an example, the architecture of machine readable instructions may be executed to detect anomalies in the data center.","Anomalies in data centers may manifest in a variety of different ways. In an example, an anomaly may manifest itself as a data point that is atypical with reference to the normal behavior of the data distribution. When an anomaly manifests as an atypical data point, the distribution of the data may be used to compute thresholds. Data under normal process behavior tends to oscillate within the threshold limits. Data points falling beyond and below the upper and lower thresholds, respectively, can be flagged as anomalies. These thresholds are based on assumptions about the behavior or shape of the distribution as well as a desired, false positive rate. An understanding and quantitative representation of the data distribution may be obtained by studying the historical data. This approach is known as parametric thresholding.","In another example, an anomaly may manifest itself when the distribution of data changes with time. The variability in the process over an extended period of time can be studied and analyzed using a historical data repository to estimate variability of the data, and characterize this variability and determine thresholds. This approach avoids having to make assumptions about the shape of distribution of the data. Such methods are known as non-parametric methods.","Online anomaly detection described herein computes statistics on data based on multiple time dimensions (e.g., entire past, recent past, and context based on hour of day, and day of week). These statistics are then employed to determine if specific points or windows in the data are anomalies. The algorithms have low complexity and are scalable to process large amounts of data.","The algorithms may be implemented or statistics may be employed for anomaly detection. An example is based on applying thresholds to individual data points. Another example involves measuring the change in distribution by windowing the data and using data within the window to determine anomalies.","A statistical analysis known as \u201cTukey\u201d may be utilized for anomaly detection among individual data points. The Tukey method constructs a lower threshold and an upper threshold, where the thresholds are used to flag data as anomalous. The Tukey method does not make any distributional assumptions about the data.","The Tukey method is a simple, but effective procedure for identifying anomalies. For purposes of illustration, let x, x, . . . xbe a series of observations, such as the processor utilization of a server. The data is arranged in an ascending order from the smallest to the largest observation. The ordered data is broken into four quarters, the boundary of each quarter defined by Q, Q, and Q, referred to herein as the \u201cfirst quartile,\u201d \u201csecond quartile,\u201d and \u201cthird quartile,\u201d respectively. The difference |Q\u2212Q| is referred to as the \u201cinter-quartile range.\u201d","The Tukey upper and lower thresholds for anomalies are: |t|=Q\u22123|Q\u2212Q| and Q3+3|Q\u2212Q|respectively. Observations falling outside these thresholds are referred to as \u201cserious anomalies\u201d and any observation, x, i=1, 2, . . . n, such that Q+1.5|Q\u2212Q|\u2266x\u2266Q+3.0|Q\u2212Q| is referred to as a \u201cpossible anomaly.\u201d Similarly, Q\u22123.0|Q\u2212Q|\u2266x\u2266Q\u22121.5|Q\u2212Q| indicates a possible anomaly on the lower side. The method allows the user flexibility to set desired threshold limits. For example, depending on a user's experience, the upper and lower anomaly limits can be set to, Q+k|Q\u2212Q| and Q\u2212k |Q\u2212Q|, where k is an appropriately chosen scalar. The lower and upper Tukey limits correspond to a distance of 4.5 \u03c3 (standard deviations) from the sample mean if the distribution of the data is Gaussian.","Windowing approaches identifying individual data points as anomalous can result in false alarms when, for example, sudden instantaneous spikes in processor or memory utilization are flagged. To avoid this, the windows of data including a collection of points can be examined to make a determination on the window. Thus, the point threshold approach can be extended to anomaly detection on windowed data by applying a threshold to the mean of the window of the data while making sure that the threshold takes into account the variance of the sample mean of the window. The thresholds can then be computed from the entire past history, or a subset of past windows. However, this approach may not capture all anomalies.","Instead, a new approach may be used to detect anomalies which manifest as changes in the system behavior that are inconsistent with what is expected. This approach is based on determining if the observed data is consistent with a given distribution. The hypothesis testing problem determines which of two hypotheses (e.g., the null hypothesis and the alternate hypothesis), best describes the data. The two hypotheses are each defined by a single distribution, or a collection of distributions. For purposes of illustration, let X, X, . . . Xdenote the observed sample of size n. Let Pdenote the distribution representing the null-hypothesis, and let Pdenote the distribution representing the alternate hypothesis. Then the optimal test for minimizing the probability of falsely rejecting the null hypothesis under a constraint on the probability of incorrectly accepting the null hypothesis is given by the Neyman-Pearson theorem. This theorem states that an optimal test is determining if the likelihood ratio:",{"@attributes":{"id":"p-0029","num":"0028"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mrow":[{"msub":{"mi":"P","mn":"0"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"X","mn":"1"},{"mi":"X","mn":"2"}],"mo":[",",","],"mrow":{"mi":"\u2026","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"msub":{"mi":["X","n"]}}}}},{"msub":{"mi":"P","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"X","mn":"1"},{"mi":"X","mn":"2"}],"mo":[",",","],"mrow":{"mi":"\u2026","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"msub":{"mi":["X","n"]}}}}}]},"mo":"\u2265","mi":"T"}}}},"In this inequality, P(X, X, . . . X) is the probability assigned to the observed sample under P, P(X, X, . . . X) is the corresponding probability assigned under P, and T is a threshold that can be determined based on the constraint on the probability of incorrectly accepting the null hypothesis. Selecting T is explained in more detail below.","It is noted that the alternate hypothesis may be the statement that the observed data is not drawn from the null hypothesis. Tests designed for this purpose are referred to as \u201cgoodness-of-fit\u201d or likelihood ratio tests. Here, a particular test is invoked, known as the \u201cmultinomial goodness-of-fit\u201d test, and is applied to a scenario where the data Xare discrete random variables that can take at most k values, for example {1, 2, . . . k}.","For purposes of illustration, let P=(P, P, . . . P), where \u03a3p=1 denotes the distribution corresponding to the null hypothesis (pdenotes the probability of observing i). Further, let denote the number of times i was observed in the sample X, X, . . . X, and let {circumflex over (p)}=({circumflex over (p)}, {circumflex over (p)}, . . . {circumflex over (p)}), where {circumflex over (p)}=n\/n denotes the empirical distribution of the observed sample X, X, . . . X. Then the logarithm of the likelihood ratio reduces to:",{"@attributes":{"id":"p-0033","num":"0032"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"L","mo":"=","mrow":{"mrow":[{"mi":"log","mo":"\u2062","mfrac":{"mrow":[{"munderover":{"mo":"\u220f","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"k"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msubsup":{"mover":{"mi":"p","mo":"^"},"mi":"i","msub":{"mi":["n","i"]}}},{"munderover":{"mo":"\u220f","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"k"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msubsup":{"mi":["p","i"],"msub":{"mi":["n","i"]}}}]}},{"mi":"n","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mover":{"mi":"p","mo":"^"},"mi":"i"},"mo":["\u2062","\u2062"],"mi":"log","mfrac":{"msub":[{"mover":{"mi":"p","mo":"^"},"mi":"i"},{"mi":["p","i"]}]}}}}],"mo":"="}}}}},"It is noted that the relative entropy (also known as the \u201cKullback-Leibler divergence\u201d) between two distributions Q=(q, q, . . . q) and P=(p, p, . . . p) is given by:",{"@attributes":{"id":"p-0035","num":"0034"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Q","P"],"mo":["\u2062","\u2062"],"mrow":{"mo":["\uf603","\uf604"]}}}},{"munder":{"mo":"\u2211","mi":"i"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["q","i"]},"mo":["\u2062","\u2062"],"mi":"log","mfrac":{"msub":[{"mi":["q","i"]},{"mi":["p","i"]}]}}}],"mo":"="}}}},"Thus, the logarithm of the likelihood ratio is L=n*D({circumflex over (P)}\u2225P). The multinomial goodness-of-fit test is based on the observation that if the null hypothesis P is true, then as the number of samples n grows 2*n*D({circumflex over (P)}\u2225P) converges to a chi-squared distribution with k\u22121 degrees of freedom. Therefore the test may be performed by comparing 2*n*D({circumflex over (P)}\u2225P) with a threshold that is determined based on the cumulative distribution function (cdf) of the chi-squared distribution and a desired upper bound on the false negative probability. It is noted that the term \u201cfalse positive\u201d as used herein corresponds to the event where the true outcome is not an anomaly but the algorithm declares the outcome as an anomaly. More precisely, if f is the desired false positive probability, and F_{k\u22121}(x) the cumulative distribution function of the chi-squared distribution with k\u22121 degrees of freedom, then we select the threshold T to be T=inf{x: F_{k\u22121}(x)>=1-f}, the value of x where F_{k\u22121}(x) equals or is approximately 1-f.","To apply the multinomial goodness-of-fit test for the purpose of anomaly detection, the metric being measured is quantized and discretized to a few values. For example, the percentage of processor utilization (which takes values between 0 and 100) can be quantized into 10 buckets, each of width 10. Thus the quantized series of processor utilization values takes one of 10 different values. Then the data is windowed and anomaly detection is performed for each window. To do so, we select the quantized data observed in a window, decide on a choice of the null hypothesis P, and perform the multinomial goodness-of-fit test with a threshold based on an acceptable false negative probability. If the null hypothesis is rejected, then an alert is issued that the window contained an anomaly. If the null hypothesis is accepted, then the window is declared free of anomaly.","Depending on the choice of the null hypothesis, a variety of different tests can be implemented. In an example, an anomaly test may involve setting P=(p, p, . . . p), where pis the fraction of times i appeared in the past (e.g., prior to the current window). This declares a window to be anomalous if the distribution of the metric values in that window differs significantly from the distribution of metric values in the past.","In another example, an anomaly test involves setting pto be the fraction of times i appears in the past few windows. This choice declares a window to be anomalous if the distribution of the metric values in that window differs significantly from the distribution of metric values in the recent past. This distinguishes between cases where the distribution of the metric being monitored changes in a slow or gentle manner, and where the distribution of the metric changes abruptly.","It is noted that the nature of the workload on a data center is often inconsistent. For example, the data center workload may be strongly related to the day of the week, the hour of the day, and\/or may vary based on other factors. Thus, applying the hypothesis tests as described above directly may not always yield the desired results. In such cases, the data may be put into context, e.g., by computing the null hypothesis based on the context (e.g., hour of day, day of the week, or other factor).","It is also noted that some data centers operate in multiple states. For example, the data center may encounter a very small or \u201cno load\u201d for most of the time being monitored, and then higher workloads in intermittent bursts. It is possible in these situations, that the relative entropy based approaches described above may flag the second state as anomalous. In these situations, an extension of the goodness-of-fit approach may be utilized. In an example of this extension, the test statistic is computed against several null hypotheses (instead of against only a single null hypothesis). Null hypotheses may be selected, and anomaly detection performed, using the following algorithm:",{"@attributes":{"id":"p-0042","num":"0041"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Algorithm ANOMALY DETECTION USING MULTINOMIAL"},{"entry":"GOODNESS-OF-FIT"},{"entry":"Input: (Util, N, Util, Util, n, W. T. c)"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"right"}},{"@attributes":{"colname":"2","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"1)","Set m = 0"]},{"entry":[{},"2)","Set W= 1"]},{"entry":[{},"3)","Set Stepsize = (Util\u2212 Util)\/N"]},{"entry":[{},"4)","While (W* W < n)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"right"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"a)","Set Util= Util((W\u2212 1)*W + 1 : W*"]},{"entry":[{},{},"W)"]},{"entry":[{},"b)","Set B= \u250c((Util\u2212 Util)\/Stepsize)\u2510"]},{"entry":[{},"c)","Compute {circumflex over (P)}"]},{"entry":[{},"d)","If m = 0"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2022","Set P= {circumflex over (P)}, m = 1, c= 1"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"right"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"e)","Else if (2 * W * D({circumflex over (P)}||P) < T) for any hypothesis P."]},{"entry":[{},{},"i \u2266 m,"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2022","Increment cby 1 (If more than one such i exists."]},{"entry":[{},{},"select the one with lowest D({circumflex over (P)}||P))"]},{"entry":[{},"\u2022","If c> c,"]},{"entry":[{},{},"-\u2002Declare window to be non-anomalous"]},{"entry":[{},"\u2022","Else"]},{"entry":[{},{},"-\u2002Declare window to be anomalous"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"right"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"f)","Else"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2022","Declare window to be anomalous"]},{"entry":[{},"\u2022","Increment m by 1. set P= {circumflex over (P)}. and c= 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"Where inputs to the algorithm include:\n\n","And intermediate variables include:\n\n","The algorithm may be implemented to select a current window (Step ), quantize values in the window (Step ), and compute the empirical frequency {circumflex over (P)} of the current window (Step ). It is noted that P, P, . . . Pdenote the m null hypotheses at any point in time. Next, a test-statistic involving {circumflex over (P)} and each of the Ps is computed and compared to the threshold T (Step ). If the test-statistic exceeds the threshold for all of the null-hypotheses, the window is declared anomalous, m is incremented by 1, and a new hypothesis is created based on the current window. If the smallest test-statistic is less than the threshold, but corresponds to a hypothesis that was accepted fewer than ctimes in the past, then the window is declared anomalous, but the number of appearances of that hypothesis is incremented. If neither of the two conditions is satisfied, then the window is declared non-anomalous and the appropriate book-keeping is performed.","The relative entropy based method described above is non-parametric. That is, the approach does not assume a particular form for the distribution of the data. The method can be easily extended to handle multi-dimensional time-series, thereby incorporating correlation, and can be adapted to workloads with distribution that change over time. This provides a systematic approach (based on the cdf of the chi-squared distribution) to choose a threshold which can be used to raise alarms. The approach can also be implemented to detect anomalies in multiple operating states, and for detecting contextual anomalies.","The algorithm is computationally lightweight. That is, the computation overhead for the current window statistics is negligible. Updating quantities such as mean and standard deviation can be performed in linear time, and in an online manner using very little memory, as only the sum of the observed values and the sum of the squares of the observed values need to be maintained in memory. For example, quantiles are computed for the Tukey method, and the empirical frequency of previous windows is computed for the relative entropy method. These quantities can be computed in time linear in the input, and these quantities can be well-approximated in one pass using only limited memory, without having to store all the observed data points.","Before continuing, it is noted that the data may be pre-processed prior to analyzing the data using the anomaly detection techniques described herein. Pre-processing of data may include data cleansing to remove invalid and\/or spurious data, as well as data smoothing using procedures such as moving average smoothing, Fourier transform, and\/or the Wavelet transform, to name only a few examples.","The anomaly detection techniques described herein may be used to analyze monitoring data over historical periods to make decisions. The historical period may be the entire past of the workload operation, or may include recent past values (but not the entire past). In either case, the data may be organized based on continuous history over time, or may be segregated by context (e.g. hour of day, or day or week.) The historical period can affect the results of the anomaly detection algorithms. For example, these factors may affect the null hypotheses against which the current window is evaluated.","Several factors may play a role in selecting the appropriate historical period. For example, if the workload has a periodic behavior, then recent past values can give enough statistical significance. If the pattern is based on weekly or hourly behavior, then the data may be organized by context. If the workload is long running and has exhibited apericdic behavior in the past, the entire past data can be used to \u201csmooth\u201d averages. If the workload has varying behavior that is time-dependent, or is originating from virtual machines that have been migrated or are subject to varying resource allocation in shared environments, then considering only recent windows can reduce or altogether eliminate noise from past variable behavior.","In enterprise environments with dedicated infrastructures, selecting the appropriate historical period and organization of data may be straightforward. However, in cloud and utility computing environments (with limited prior knowledge of workload behavior, high churn, and shared infrastructure for workloads), the most appropriate historical period and organization of data to choose can be challenging and expensive to determine at large scale. Instead, an alternate approach may be implemented, in which at any given time, the anomaly detection algorithm is run in multiple instances in parallel. Accordingly, each run can leverage data analyzed from a different historical period. The results from the individual runs can then be combined to provide insight and a system status indicator for the administrator.","Before continuing, it is noted that online anomaly detection described herein can be applied to continuous monitoring scenarios, and is not limited to static profiling or limited sets of historical data.","The algorithms discussed above were tested using two different types of actual data. The first data set included \u201cinjected\u201d anomalies (so that the anomalies were known) in order to validate results returned by the algorithms. The second data set (discussed below) was collected from production data center.","The first data set was collected using an experimental setup with a representative Internet service providing distributed online service implementing the core functionality of an auction site.  is a high-level block diagram illustrating the experimental setup . The experimental setup used five virtual machines (VM to VM) on a Xen platform hosted on two physical servers (Host and Host). VM, VM, and VM were created on Host. The frontend server processed or redirected service requests runs in VM. The application server handling the application logic  ran in VM. The database backend server was deployed on VM. The deployment was typical in its use of multiple VMs and the consolidation onto a smaller number of hosts.","A request load generator and an anomaly injector were running on two virtual machines (VM and VM) on Host. The generator created 10 hours of service request load for Host, where the auction site resides. The load emulated concurrent clients, sessions, and human activities. During the experiment, the anomaly injector injected 50 anomalies into the online service in Host. Those 50 anomalies were based on major sources of failures or performance issues in online services, and were injected using a uniform distribution. The virtual machine and host metrics were collected and analyzed in an anomaly detector.","Table 1 summarizes results from analyzing the processor utilizations, including recall and false positive rates (FPR) for the different techniques.",{"@attributes":{"id":"p-0057","num":"0069"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"Method","Statistics Over","Recall","FPR"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Gaussian (windowed)","Entire past","0.06","0.02"]},{"entry":[{},"Gaussian (windowed)","Recent windows","0.06","0.02"]},{"entry":[{},"Gaussian(smoothed)","Entire Past","0.58","0.08"]},{"entry":[{},"Tukey(smoothed)","Entire Past","0.76","0.04"]},{"entry":[{},"Relative entropy","Entire past","0.46","0.04"]},{"entry":[{},"Relative entropy","Recent past","0.74","0.04"]},{"entry":[{},"Relative entropy","Multiple","0.86","0.04"]},{"entry":[{},{},"Hypotheses"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}}}},"It can be seen from the data in Table 1 that the typical statistical techniques perform poorly, as compared to the multiple hypotheses relative entropy technique described herein. That is, the CPU utilization data was quantized into 33 equally spaced bins, and for the windowing techniques, the window length was set to 100. For algorithms that use only the recent past, 10 windows of data were used. For the Gaussian methods, for each window, anomaly detection was performed on the CPU utilization of each of the three virtual servers and an alarm was raised only if an anomaly was detected in at least one server. For the relative entropy methods, the sum of the test statistics of each of the servers was compared to a threshold (computed based on the sum of chi-squared random variables being a chi-squared random variable). There were total 50 anomalies injected, and in our evaluation, an alarm was raised if an anomaly was detected in a window containing the anomaly.","The second data set was collected using two different \u201creal-world\u201d customer production data centers. Data was collected over a 30 and 60 day period for each customer (CUST and CUST), respectively. Processor and memory utilization metrics were sampled every 5 minutes. The data was segmented by hour of day, and day of week for both CUST and CUST, and then analyzed using anomaly detection methods.",{"@attributes":{"id":"p-0060","num":"0072"},"figref":"FIG. 3","b":["300","1"]},"The processor utilization of one of the servers was analyzed and interleaved according to hour of the day. More specifically, for each x \u03b5{0, 1, 2, . . . 23}, all the measurements made between x hours and x+1 hours on weekdays were grouped together. The pointwise Gaussian and Tukey techniques, and the relative entropy technique with multiple hypotheses, were tested. To determine the limits for the pointwise Gaussian and Tukey techniques, the first half of the data set was used to estimate the mean, standard deviation and relevant quantiles. The thresholds were applied on the second half of the data set to detect anomalies.","The server in question had been allocated a maximum of 16 cores and thus the values of CPU utilization ranged between 0.0 and 16.0. To apply the relative entropy detector, a bin width of 2.0 was used, corresponding to 8 bins. The window size was 12 data points, corresponding to an hour. Thus the relative entropy detector, at the end of each hour, declared that window to be anomalous or otherwise.","To facilitate a direct comparison, the alarms raised by the Gaussian and Tukey methods were processed as follows. For each of the techniques, if at least one alarm is raised within one window, then the window was deemed anomalous. This enabled direct comparison of the number of windows that each of the techniques flagged as anomalous. The comparison was performed for each of the 24 hours. The results are shown in Table 2.",{"@attributes":{"id":"p-0064","num":"0076"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"8"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"28pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}},{"entry":[{},"# Anomalies","#","#",{},{},{},"Unique"]},{"entry":["Hour","(Relative","Anomalies","Anomalies","Common","Unique","Unique to","to"]},{"entry":["of day","Entropy-RE)","(Gaussian)","(Tukey)","Anomalies","to RE","Gaussian","Tukey"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"8"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"28pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["0000","6","7","7","6","0","0","0"]},{"entry":["0100","4","6","1","1","0","2","0"]},{"entry":["0200","2","4","0","0","0","2","0"]},{"entry":["0300","5","4","2","1","2","0","0"]},{"entry":["0400","5","5","2","2","0","0","0"]},{"entry":["0500","4","5","2","1","1","1","0"]},{"entry":["0600","5","7","3","3","0","2","0"]},{"entry":["0700","4","6","7","4","0","0","1"]},{"entry":["0800","6","2","3","2","3","0","0"]},{"entry":["0900","7","2","14","2","0","0","7"]},{"entry":["1000","6","2","13","2","0","0","7"]},{"entry":["1100","7","2","3","1","5","0","0"]},{"entry":["1200","4","2","2","2","2","0","0"]},{"entry":["1300","1","2","1","1","0","1","0"]},{"entry":["1400","5","5","5","4","1","0","0"]},{"entry":["1500","6","5","12","4","1","0","6"]},{"entry":["1600","4","5","2","2","1","2","0"]},{"entry":["1700","4","3","3","2","2","0","0"]},{"entry":["1800","4","3","0","0","1","0","0"]},{"entry":["1900","5","3","3","3","2","0","0"]},{"entry":["2000","3","2","0","0","2","1","0"]},{"entry":["2100","6","5","8","4","1","0","2"]},{"entry":["2200","5","4","0","0","2","1","0"]},{"entry":["2300","6","10","6","5","0","3","0"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}}]}}]}}},"The first column in Table 2 shows the hour of day that was analyzed. The next three columns indicate number of anomalies detected by the three techniques. The fifth column shows the number of anomalies detected by all techniques, and the sixth, seventh and eighth columns show the anomalies that were uniquely detected by each of the techniques. To illustrate, the sixth column shows the number of anomalies detected by the relative entropy technique, but not by the other two. In most cases, the relative entropy technique shows the number of anomalies detected using the other two techniques, and also flags a few more anomalies.","There are three notable exceptions (hours 0900, 1000 and 1500) where the Tukey method flagged more anomalies than the other techniques. A closer examination of the data corresponding to these hours reveals that the processor utilization during these hours was very low (<0.5), causing the inter-quartile range to be very small and therefore resulting in a very low upper threshold. As a result, the algorithm flagged a large number of windows as anomalous, and it is reasonable to surmise that some of these may be false alarms. The data corresponding to hour 1100 resulted in the relative entropy technique returning 5 anomalies that the other two techniques did not flag.","The typical behavior of the CPU utilization hovered between 0.0 and 2.0 with occasional spikes. But often after spiking to a value greater than 6.0 for a few measurements, usage dropped back down to a value around 2.0. But in a couple of cases, the value did not drop down entirely and remained between 4.0 and 6.0, indicating perhaps a stuck thread. The Gaussian and Tukey methods do not catch this anomaly, because the data did not manifest as an extreme value. However, the relative entropy technique described herein did identify this anomaly.","It can be seen from the above examples that the systems and methods of anomaly detection described herein are \u201clightweight,\u201d both in terms of the number of metrics to run (e.g., the volume of monitoring data continuously captured and used), and in terms of runtime complexity for executing the detection. Online anomaly detection described herein can be used to handle multiple metrics at the different level of abstraction that are present in data centers (e.g., hardware, system software, middleware, or application). Furthermore, the methods accommodate workload characteristics and patterns, including but not limited to, day of the week, hour of the day, and patterns in the workload behavior. The methods can be implemented in the dynamic nature of data center environments, including dealing with application arrivals and departures, changes in workload, and system-level load balancing through, e.g., virtual machine migration. In addition, the techniques exhibit high accuracy and a low false alarm rate.","Before continuing, it should be noted that the examples described above are provided for purposes of illustration, and are not intended to be limiting.",{"@attributes":{"id":"p-0070","num":"0082"},"figref":"FIG. 4","b":"400"},"Operation  includes analyzing time series data for the data center by testing statistical hypotheses. The statistical hypotheses correspond to different operational states of the data center. Operation  includes constructing upper and lower bounds based on the statistical hypotheses. Operation  includes flagging anomalies in the time series data falling outside of the upper and lower bounds.","The operations shown and described herein are provided to illustrate example implementations. It is noted that the operations are not limited to the ordering shown. Still other operations may also be implemented.","Further operations may include applying a multinomial goodness-of-fit test. This operation may include quantizing a metric being measured in the time series data and discretizing the metric to a few values, and windowing the time series data and analyzing each window for anomalies. Analyzing each window may include selecting the quantized data in a window, selecting a hypothesis, and performing the multinomial goodness-of-fit test with a threshold based on an acceptable false negative probability.","Further operations may also include raising an alarm that the window includes an anomaly if the hypothesis is rejected, and declaring that the window does not include an anomaly if the hypothesis is accepted.","Still further operations may include distinguishing between gentle changes in distribution of a monitored metric and abrupt changes in distribution of the monitored metric. Operations may include declaring a window to be anomalous if distribution of metric values in a window differs significantly from distribution of historical metric values.","Yet further operations may include contextualizing the time series data to factor changing load on the data center, and computing a test statistic against several null hypotheses to factor multiple states of operation of the data center.","The operations may be implemented at least in part using an end-user interface (e.g., web-based interface). In an example, the end-user is able to make predetermined selections, and the operations described above are implemented on a back-end device to present results to a user. The user can then make further selections. It is also noted that the various of the operations described herein may be automated or partially automated.","It is noted that the examples shown and described are provided for purposes of illustration and are not intended to be limiting. Still other examples are also contemplated."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1","b":"100"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
