---
title: Modular architecture having reusable front end for processing digital video data
abstract: A device is described that includes an encoder/decoder (CODEC) in which functionality is partitioned between a video front end (VFE) and a video back end (VBE). The VFE encapsulates functionality and image processing operations to support a variety of applications, and presents a flexible inter-processor by which an external master device can easily control these operations. The video back end (VBE) operates as an encoder and/or a decoder to generate encoded and/or decoded video sequences. The VFE and VBE may execute within an operating environment provided by a slave device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08159548&OS=08159548&RS=08159548
owner: QUALCOMM Incorporated
number: 08159548
owner_city: San Diego
owner_country: US
publication_date: 20030130
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This disclosure relates to techniques for processing digital video data.","With recent increases in computer processing capabilities and affordability, full motion digital video devices are becoming more widely available. In particular, digital video capabilities have been incorporated into a wide range of devices including digital televisions, digital direct broadcast systems, wireless communication devices, portable digital assistants (PDAs), laptop computers, and desktop computers. These devices can provide significant improvements over conventional analog video systems in creating, modifying, transmitting, storing, and playing full motion video sequences.","To integrate digital video capabilities, these devices often support a variety of camcorder or camera applications. For example, these devices typically include a digital viewfinder or other display, an image sensor for video data capture, and image processing functions to perform specialized image manipulation, as well as compression and decompression of the digital video data in accordance with one or more of a variety of video compression standards or processes. Providing these digital video capabilities often requires a significant amount of specialized hardware, software, or both.","In general, this disclosure describes techniques for processing digital video data, such as encoding or decoding digital video data. A device, such as an encoder, a decoder or an encoder\/decoder (CODEC), includes an innovative architecture in which functionality is partitioned between a video front end (VFE) and a video back end (VBE). The VFE encapsulates functionality and image operations to support a variety of applications, and presents a flexible inter-processor interface by which an external master device can easily control these operations.","This partitioning insulates the VBE from a variety of implementation-specific functions, such as interfacing directly with camera interface hardware, performing color conversion and other image processing functions necessary to drive viewfinder, or operations. Consequently, the techniques described herein may provide a distributed video system that eases integration of digital video capabilities within new devices. The VFE may easily be reused in different applications with any desired image sensor, display, and back-end software or firmware, or combination thereof, to easily integrate video data capabilities into new products or devices.","In one embodiment, a system comprises a video front end (VFE) having a programmable interface to receive commands, wherein the VFE captures video input data and pre-process the video input data to produce video output data in accordance with the commands. The system further comprises a video back end (VBE) to generate an encoded sequence of video data from the video output data of the VFE, and a controller to provide commands to the VFE via the interface to control the desirable pre-processing of the video input data.","In another embodiment, a device comprises a video front end (VFE) executing within an operating environment provided by the device and includes a programmable interface to receive commands from an external device. The VFE captures video input data and pre-process the video input data in accordance with the commands to produce video output data for encoding by a video back end and video display data for display by a display device.","In another embodiment, a device comprises means for programmatically receiving commands from a master device, and means for capturing and pre-processing video input data to produce video output data and video display data in accordance with the commands. The device further comprises means for generating an encoded sequence of video data from the video output data.","In another embodiment, a method comprises programmatically receiving commands from a master device via an inter-processor interface, and capturing and pre-processing video input data via a slave device in accordance with the commands to produce video output data in a first image format and video display data in a second image format. The method further comprises communicating the video output data to an encoder for generation of an encoded sequence of video data; and communicating the video display data to an output device for display.","The details of one or more embodiments are set forth in the accompanying drawings and the description below. Other features, objects, and advantages will be apparent from the description and drawings, and from the claims.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1","b":["10","12","14","16","10","10"]},"For purposes of example, digital video device  is illustrated as a wireless device, such as a cellular phone. However, the techniques described herein are not limited to wireless devices, and may be readily applied to other digital video devices. Furthermore, although illustrated in reference to a CODEC, this disclosure is not so limited and may readily be applied to encoders and decoders.","Controller  provides primary control over the components of CODEC , including VFE , and coordinates communication with the other components of digital video device . Controller  directs CODEC  to perform many of the computationally intensive tasks required for encoding and decoding digital video sequences. CODEC  may take the form of a digital signal processor (DSP), and may have a dedicated memory  for storing instructions and data. Alternatively, or in addition, CODEC  may include dedicated hardware, software, firmware, or combinations thereof. Similarly, controller  may take the form of an embedded microprocessor, specialized hardware, software, e.g., a control software module, or combinations thereof. Moreover, CODEC  and controller , as well as other components of device , may be implemented in one or more application-specific integrated circuit (ASIC), as multiple discrete components, or combinations thereof.","Digital video device  also includes a number of different peripherals, such as a display or viewfinder  and an image sensor . Under the direction of controller , CODEC  captures video input data  (VID) from image sensor , and communicates the video input data to VFE . Camera interface  is responsible for abstracting the interface details of image sensor . For example, in response to controls and configuration data  from VFE , camera interface  synchronizes horizontal and vertical reference signals in the data received from image sensor . Camera interface  may also include limited functionality to processes the video data, such as by masking pixels.","In general, VFE  of CODEC  encapsulates functionality and pre-processing operations to support a variety of camera or camcorder applications, and includes a flexible inter-processor interface for controlling these operations. The primary task of VFE  is to process incoming video input data  in real-time. VFE  receives video input data , and processes the data to produce video output data (VOD)  into acceptable format for VBE  based on commands and configuration parameters  received from controller . In addition, VFE  formats video input data  to produce video display data (VDD)  in a form suitable for display by viewfinder , which may comprise any output device for displaying the VDD, e.g., a liquid crystal display (LCD) for a camcorder or a mobile phone screen. VFE  stores video output data  and video display data  within video memory  for access by VBE  and controller , respectively. VFE  provides status information  via the inter-processor interface to indicate the status of pending commands.","VFE  may perform complex image processing operations on video input data , such as converting color video frames to black-and-white format, modifying contrast or luminance characteristics of the data, digitally enhancing or modifying lighting conditions for the captured data, performing a digital zoom operation, image sensor processing and compensation, e.g., white balancing, automatic gain control, and gamma correction, and modifying the captured video data to simulate halos, sunsets, star filters or other filter effects. In addition, VFE  may reduce the frame rate or image size of the captured video input data .","As described in further detail below, VFE  presents an inter-processor application-programming interface (API) that allows controller  to easily control and reconfigure VFE . The API provides an inter-processor interface, allowing VFE  to act as a slave to controller .","VBE  may comprise any software application, hardware unit, or the like, that encodes or decodes video data. More specifically, VBE  may utilize video output data  to generate an encoded bit stream of video sequences. When operating as an encoder, VBE  encodes video output data , and may buffer the encoded bit stream within video memory , e.g., for wireless transmission via transmitter\/receiver  and antenna . For example, VBE  may comprise a JPEG still image encoder for a digital camera, an MPEG video encoder for a digital camcorder, and the like. VBE may be, therefore, a proprietary encoder or decoder, or may processes video output data  in accordance with one or more of a variety of data compression standards, such as MPEG-1, MPEG-2, or MPEG-4 by The Moving Picture Experts Group (MPEG), QuickTime\u2122 by Apple Computer of Cupertino Calif., Video for Windows\u2122 developed by Microsoft Corporation of Redmond, Wash., Indeo\u2122 developed by Intel Corporation, RealVideo\u2122 from RealNetworks, Inc. of Seattle, Wash., and Cinepak\u2122 developed by SuperMac Inc, H.263, H.264, JPEG 2000, and the like.","Alternatively or in addition, VBE  may operate as a decoder. More specifically, VBE  may receive a bit stream of encoded video sequences from receiver\/transmitter , and process the bit stream to produce decoded video sequences for processing and display by VFE . VFE  and VBE  may exchange control signals  to trigger video processing operations. For example, controller  or VFE  may trigger encoding operations by VBE . When operating as a decoder, controller  or VBE  may trigger operations by VFE . VFE  and VBE  may be provided as standalone hardware or software modules, e.g., software modules for execution by a DSP, or combinations thereof.","Memories ,  stores instruction and data for use by controller  and CODEC , respectively. Although illustrated as separate memories, memories ,  may be a common memory device. Memories ,  may comprise read-only memory (ROM), synchronous dynamic random access memory (SDRAM), non-volatile static random access memory (SRAM), Flash memory, electrically erasable programmable read-only memory (EEPROM), and the like. Video memory  may take the form of Video Dynamic Memory Access (VDMA). As illustrated, memories ,  may be external to CODEC  and coupled to controller .","Partitioning the functionality of CODEC  into VFE  and VBE , as described, insulates VBE  for having to perform a variety of implementation-specific functions, such as interfacing directly with camera interface hardware , performing color conversion and other image processing functions necessary to drive viewfinder , or other implementation-specific operations. Consequently, VFE  may be viewed as performing implementation-specific image processing functions, while VBE  can perform implementation-independent image processing functions.","In addition, the partitioning may provide increased flexibility to ease integration of digital video capabilities within new devices. For example, the functional partitioning between VFE  and VBE  yields a distributed video system, and allows a designer to easily reuse VFE  with any desired back-end software or firmware, or combination thereof, to integrate video data capabilities into new products or devices. In this manner, new video compression standards may easily be supported by coupling VFE  with a new VBE . In other words, a designer may reuse VFE  as a common module with any desired different VBEs or other application software or firmware, even proprietary VBEs, to integrate digital video capabilities within a new device. Moreover, the flexibility and configurability of VFE  allows the VFE to be easily used with different image sensors and display devices. Consequently, VFE  may easily be reused and embedded within multiple devices with little or no change, and may ease design and production of new devices, such as a JPEG-based still digital camera, or a cellular phone that integrates MPEG-based video capture and communication.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 2","FIG. 1"],"b":["14","14","30","30","32","24","30","30","30","16","16","30","30","12","30"]},"Camera driver A interfaces directly with camera interface hardware , and programs the hardware to capture one or more video frames from image sensor . In particular, camera driver A issues commands  and, in response, receives video input data .","For example, camera driver A programmably configures camera interface hardware  to start and stop video capture. In addition, camera driver A defines an image frame dimension, e.g., lines per frame and pixels per line, and an image window for data collection, a data format, e.g., little or big Endian. Further, camera driver A may issue commands  to direct camera interface hardware  to perform initial sub-sampling along the space domain and the time domain to reduce the image size and frame rate.","Camera driver A processes video input data , and stores the processed data to video memory  () in a standard form for backend processing by VBE . Camera driver A may, for example, store the image in YCbCr (Luminance-Chrominance) 4:2:2 format, which means that the chrominance values for the image data is sub-sampled only in the horizontal direction. For example, camera driver  may process a color image or frame of size 352\u00d7288 pixels to produce a frame in which the luminance data remain 352\u00d7288, but the chrominance values are sub-sampled to a size of 176\u00d7288 pixels.","Frame rate control module B provides functionality to down sample or up sample the sequence of video data captured by image sensor  and produced by camera interface , i.e., video input data , to a desirable frame rate. Frame rate control module B may, for example, down sample or up sample the incoming video frames of video input data  by a fractional or integer factor, giving VFE  flexibility for use in a wide range of applications.","Image processing module C allows controller  to programmably select and apply frame-by-frame image processing functions to incoming video input data . For example, controller  may issue commands via API  to select functions like conversion of color video frames to black-and-white format, modify contrast or luminance characteristics of the data, digitally enhance or modify lighting conditions for the captured data, perform a digital zoom operation, image sensor processing and compensation, e.g., white balancing, automatic gain control, and gamma correction, and modify the captured video data to simulate halos, sunsets, star filters or other filter effects. Image processing module C may apply these functions to pre-process video input data  for encoding by VBE , or to post-process decoded video sequences produced by VBE . For example, image processing module C may apply these functions to enhance the decoded video sequences produced by VBE  from a received video bit stream.","Image size control module E provides functionality to down sample or up sample an image size to a desirable image size. Moreover, image size control module E may down sample the image size and retain the aspect ratio, or achieve a different desirable aspect ratio. For example, a VGE image having resolution of 640\u00d7480 may be sub-sampled to CIF format having a resolution 352\u00d7288. Image size control module E may, for example, down-sample the image size of video input data  by a fractional or integer factor, giving VFE  flexibility for use in a wide range of applications.","Viewfinder driver D provides functionality for driving viewfinder  with video display data . Viewfinder  may require video display data  in a format that is significantly different from the format of video input data  or video output data . For example, viewfinder  may require video display data  at different frame rate or image size. Viewfinder driver D may make use of frame rate control module C and image size control module E to processes video input data  and produce video display data  in a form suitable for display by viewfinder .","Color conversion module F provides functionality for converting video input data  to a different color space, e.g., a different format for representing the color image data. For example, color conversion module F may process video input data  to produce video output data  in YCbCr (Luminance-Chrominance) 4:2:2 format for use by VBE . In addition, color conversion module may also process video input data  to produce video display data  in RGB format for display by viewfinder . Moreover, color conversion module may control the color depth of the format produced, e.g., 16-bit, 18-bit, and 24-bit depth.","Controller  programmatically configures and interacts with modules  of VFE  by issuing commands in accordance with API . In one embodiment, API  supports the following commands:\n\n","To issue the above commands, controller  may write the commands to memory within CODEC . More specifically, CODEC  may include a command (CMD) register  for holding the pending command, and a command (CMD) buffer  for holding any parameters associated with the command. Upon writing a command and associated parameters to command register  and command buffer , respectfully, controller  issues an interrupt to VFE  to indicate a command is pending. In one example embodiment, command register  comprises a single 32-bit buffer to store a command header for the particular command being issued. Command buffer  comprises buffer having a size of cable of storing twenty-three 32-bit words.","VFE  utilizes message (MSG) register  to indicate the status of pending commands, e.g., whether the command has been completed, or whether an illegal command was encountered. VFE  issues interrupts to controller  to indicate the availability of new status information within message register . Controller  accesses message register  to verify that the previous command has been completely processed prior to issuing a subsequent command.","In one embodiment, message register  stores status messages in eight 32-bit words as follows:",{"@attributes":{"id":"p-0041","num":"0043"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"91pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Message","Size (words)","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Frame Message","4","End of frame status that"]},{"entry":[{},{},"encodes VOD and VDD"]},{"entry":[{},{},"information for the controller"]},{"entry":["CONFIG command","1","Indicates the CONFIG"]},{"entry":["complete message",{},"command has completed"]},{"entry":["IDLE command complete","1","Indicates the IDLE command"]},{"entry":["message",{},"has completed"]},{"entry":["ILLEGAL command","1","Indicates controller 24 issued"]},{"entry":["complete message",{},"an illegal command"]},{"entry":["Fatal error message","1","Indicates a fatal error has"]},{"entry":[{},{},"occurred"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"In one embodiment, the CONFIG command includes an extensive parameter list that allows controller  to easily programmatically configure VFE  as necessary to support the video capabilities required by device . More specifically, controller  writes command buffer  with a twenty-three (23) word parameter list, as illustrated in the following table:",{"@attributes":{"id":"p-0043","num":"0045"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"119pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Word","Configuration","Settable parameters"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Video Input Data","Frame row width, number of pixels"]},{"entry":[{},{},"per row, frame column height,"]},{"entry":[{},{},"number of rows per frame, input"]},{"entry":[{},{},"image format of VID."]},{"entry":["2","Video Output Data","Enable\/disable VDD X and Y zoom"]},{"entry":[{},{},"factors, enable\/disable byte swap,"]},{"entry":[{},{},"image format of VOD."]},{"entry":["3","Video Output Data","X and Y pixels to clip, X & Y"]},{"entry":[{},{},"clipping control, enable VBE trigger."]},{"entry":["4","Video Output Data","Specifies a bit pattern for choosing"]},{"entry":[{},{},"frames to keep and drop relative to"]},{"entry":[{},{},"VID. If bit N is set, for example, the"]},{"entry":[{},{},"Nth frame is dropped. Also specifies"]},{"entry":[{},{},"a number of bits used starting from"]},{"entry":[{},{},"the LSB."]},{"entry":["5","Video Display Data","Enable\/disable VDD X and Y zoom"]},{"entry":[{},{},"factors, enable\/disable byte swap,"]},{"entry":[{},{},"image format of VDD."]},{"entry":["6","Video Display Data","X and Y pixels to clip, X & Y"]},{"entry":[{},{},"clipping control, enable VBE trigger."]},{"entry":["7","Video Display Data","Specifies a bit pattern for choosing"]},{"entry":[{},{},"frames to keep and drop relative to"]},{"entry":[{},{},"VID. If bit N is set, for example, the"]},{"entry":[{},{},"Nth frame is dropped. Also specifies"]},{"entry":[{},{},"a number of bits used starting from"]},{"entry":[{},{},"the Least Significant Bit (LSB)."]},{"entry":["8","VOD and VDD Image","Specifies an intensity scale factor for"]},{"entry":[{},"Processing","processing VID for both VDD and"]},{"entry":[{},{},"VOD."]},{"entry":["9","Snapshot Mode","Enable\/Disable snapshot mode."]},{"entry":[{},{},"Directs VFE to receive and process a"]},{"entry":[{},{},"single frame. One frame will be"]},{"entry":[{},{},"generated for VOD and VDD."]},{"entry":["10-13","Ping-Pong Buffers","Ping-pong buffers for VOD and"]},{"entry":[{},{},"VDD."]},{"entry":["14","Camera Interface","Enable\/disable VSYNC, HSYNC,"]},{"entry":[{},"Hardware","Endian selection,"]},{"entry":["15","Camera Interface","Configuration of synchronization for"]},{"entry":[{},"Hardware","camera include rising\/falling edge"]},{"entry":[{},{},"synchronization, values of pixel"]},{"entry":[{},{},"counters and line counters for"]},{"entry":[{},{},"resynchronization."]},{"entry":["16","Camera Interface","Specify any programmable start of"]},{"entry":[{},"Hardware","frame (SOF), end of frame (EOF),"]},{"entry":[{},{},"start of line (SOL), or end of line"]},{"entry":[{},{},"(EOL) settings."]},{"entry":["17","Camera Interface","Specify behavior of HSYC during"]},{"entry":[{},"Hardware","vertical blanking period."]},{"entry":["18","Camera Interface","Course settings for VSYNC,"]},{"entry":[{},"Hardware","including line counters for VSYNC"]},{"entry":[{},{},"high and VSYNC low."]},{"entry":["19-22","Camera Interface","Specifies a value of the pixel counter"]},{"entry":[{},"Hardware","when VSYNC goes high and low, a"]},{"entry":[{},{},"value at which the line counter and"]},{"entry":[{},{},"pixel counter reset, values of the pixel"]},{"entry":[{},{},"counter for starting and stopping"]},{"entry":[{},{},"collection of data for a line, values for"]},{"entry":[{},{},"the line counter at which to start and"]},{"entry":[{},{},"stop collection of data for the frame."]},{"entry":["23","Camera Interface","Specifies a number of frames to skip"]},{"entry":[{},"Hardware","after collecting a frame, a line skip"]},{"entry":[{},{},"pattern, and a pixel skip pattern."]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0044","num":"0046"},"figref":"FIG. 3","b":["14","60","62","64","66"]},"Upon initial power-up or a hardware reset, VFE  enters INIT state . For VFE  to exit this state, controller  must issue a CONFIG command to programmatically configure VFE , as described above. Upon receiving the CONFIG command, VFE  transitions to IDLE state .","Within the IDLE state , VFE  accepts all three possible commands from controller  without generation of an error: the CONFIG command, the CAPTURE command and the IDLE command. Controller  may, for example, issue the CONFIG command to reprogram VFE . Upon receiving and processing the CONFIG command, VFE  returns to IDLE state . An IDLE command is essentially ignored as VFE  is already operating within IDLE state .","Upon receiving a CAPTURE command, VFE  transitions to CAPTURE state  and executes the parameters programmed by the most recent CONFIG command. While in CAPTURE state , VFE  starts the camera interface hardware , and begins receiving and processing video input data .","Initially, VFE  examines the parameters associated with the CAPTURE command to determine whether snapshot mode is enabled. If snapshot mode is enabled, VFE  captures a single video frame of video input data , and immediately returns to IDLE state  upon capturing the frame. If snapshot mode is not enabled, VFE  remains in CAPTURE state  and continuously receives and processes video frames.","More specifically, VFE  receives video input data , and processes the data to produce video output data  into acceptable format for VBE  based on commands and configuration parameters  received from controller . In addition, VFE  formats video input data  to produce video display data  in a form suitable for display by viewfinder , and stores video output data  within video memory  for access by VBE  or controller .","While operating in capture mode , VFE  invokes functional modules A-F based on the programmable parameters provided by controller . For example, as described above, camera driver A programmably configures camera interface hardware  to start and stop video capture. Frame rate control module B processes video input data  captured by image sensor  and produced by camera interface  to a desirable frame rate.","Image processing module C may perform complex image processing operations on video input data  based on the parameters provided by controller  via the CONFIG command. Viewfinder driver D processes video input data  from video memory  to produce video display data  in a form suitable for display by viewfinder .","Image size control module E provides functionality to down sample an image size to a desirable image size. Color conversion module F provides functionality for converting video input data  to a different color space, e.g., a different format for representing the color image data, as may be required by VBE  or viewfinder .","VFE  terminate image capture and returns to IDLE state  upon receiving an IDLE command from controller .",{"@attributes":{"id":"p-0054","num":"0056"},"figref":"FIG. 4","b":["10","24","12","25","14","70","24","12"]},"When CODEC  operates as an encoder, VFE  captures and pre-processes video input data  in accordance with the commands to produce video output data  in a first image format and video display data in a second image format (). During the process VFE  generates the video output data and the video display data in accordance with programmable formats, e.g., programmable frame rates, image sizes, and color spaces. VFE  communicates the video output data to VBE  for generation of an encoded sequence of video data (), and communicates the video display data to controller  for display on viewfinder  (). In similar fashion, VFE  may receive decoded video sequences from VBE , and process and display the decoded video sequences in accordance with commands  provided by controller .","Various embodiments have been described in which an example video encoder\/decoder (CODEC) is partitioned between a video front end (VFE) and a video back end (VBE). As described within this disclosure, the VFE encapsulates functionality and pre-processing operations to support a variety of camera or camcorder applications, and presents a flexible inter-processor by which an external master device can easily control these operations. This partitioning yields a distributed video system that insulates the VBE from a variety of implementation-specific functions, such as interfacing directly with camera interface hardware, performing color conversion and other image processing functions necessary to drive viewfinder, or other implementation-specific operations. Consequently, the techniques described herein may provide increased flexibility to ease integration of digital video capabilities within new devices. For example, a designer may easily reuse the VFE with any desired back-end software or firmware, or combination thereof, to integrate video data capabilities into new products or devices. These and other embodiments are within the scope of the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
