---
title: Programming multiple chips from a command buffer
abstract: A CPU selectively programs one or more graphics devices by writing a control command to the command buffer that designates a subset of graphics devices to execute subsequent commands. Graphics devices not designated by the control command will ignore the subsequent commands until re-enabled by the CPU. The non-designated graphics devices will continue to read from the command buffer to maintain synchronization. Subsequent control commands can designate different subsets of graphics devices to execute further subsequent commands. Graphics devices include graphics processing units and graphics coprocessors. A unique identifier is associated with each of the graphics devices. The control command designates a subset of graphics devices according to their respective unique identifiers. The control command includes a number of bits. Each bit is associated with one of the unique identifiers and designates the inclusion of one of the graphics devices in the first subset of graphics devices.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07015915&OS=07015915&RS=07015915
owner: NVIDIA Corporation
number: 07015915
owner_city: Santa Clara
owner_country: US
publication_date: 20030812
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["The present invention relates to the field of computer graphics. Many computer graphic images are created by mathematically modeling the interaction of light with a three dimensional scene from a given viewpoint. This process, called rendering, generates a two-dimensional image of the scene from the given viewpoint, and is analogous to taking a photograph of a real-world scene.","As the demand for computer graphics, and in particular for real-time computer graphics, has increased, computer systems with graphics processing subsystems adapted to accelerate the rendering process have become widespread. In these computer systems, the rendering process is divided between a computer's general purpose central processing unit (CPU) and the graphics processing subsystem. Typically, the CPU performs high level operations, such as determining the position, motion, and collision of objects in a given scene. From these high level operations, the CPU generates a set of rendering commands and data defining the desired rendered image or images. For example, rendering commands and data can define scene geometry, lighting, shading, texturing, motion, and\/or camera parameters for a scene. The graphics processing subsystem creates one or more rendered images from the set of rendering commands and data.","To maximize rendering performance, the graphics processing subsystem may include two or more graphics processing units (GPUs) operating in parallel. The graphics processing units can divide the rendering workload in a number of different ways. For example, different portions of an image can be rendered in parallel by different GPUs. The portions are then combined to produce a complete rendered image. In another example parallel rendering scheme, each GPU renders one image in a sequence of images.","Programming multiple GPUs with a CPU is one difficulty arising from parallel rendering schemes. In parallel rendering schemes, GPUs require a mixture of rendering commands common to all of the GPUs in the graphics processing subsystem and rendering commands specific to each GPU. However, programming each GPU with different rendering commands and data often requires a large allocation of system resources for each GPU. This programming overhead makes parallel rendering schemes inefficient and in some cases even limits the total number of GPUs that can be used by the graphics processing subsystem.","Therefore, it is desirable to have an efficient system and method for programming multiple graphics processing units with rendering commands while consuming a minimal amount of system resources. It is further desirable to be able to program multiple graphics processing units with both rendering commands common to all of the graphics processing units and rendering commands specific to one or more graphics processing units.","An embodiment of the invention enables the CPU to selectively program one or more graphics devices by writing a control command to the command buffer that designates a subset of graphics devices to execute one or more subsequent commands. Graphics devices that are not designated by the control command will ignore the subsequent commands until re-enabled by the CPU. The non-designated graphics devices will continue to read from the command buffer to maintain synchronization. Subsequent control commands can designate a different subset of graphics devices to execute further subsequent commands. Graphics devices include graphics processing units and graphics coprocessors.","In an embodiment, a method for programming a graphics subsystem includes communicating a first command with each of the plurality of graphics devices. The first command designates at least a first portion of the plurality of graphics devices to execute a second command subsequent to the first command. The second command is communicated with each of the plurality of graphics devices. The second command is executed only by the first portion of the plurality of graphics devices. The second command can be a device specific rendering command, or alternatively, a common rendering command. In an embodiment, the first and second commands are communicated with each of the plurality of graphics devices via a single memory aperture.","A further embodiment of the method associates a unique identifier with each of the plurality of graphics devices. The first command designates the first portion of the plurality of graphics devices according to their respective unique identifiers. In yet a further embodiment, the first command includes a plurality of bits. Each bit is associated with one of the unique identifiers and adapted to designate the inclusion of one of the plurality of graphics devices in the first portion of the plurality of graphics devices.","An embodiment of the method can be used to assign a first portion of an image to be rendered by the first portion of the plurality of graphics devices and to assign a second portion of the image to be rendered by the second portion of the plurality of graphics devices. In an alternate embodiment, the method assigns a first image to be rendered by the first portion of the plurality of graphics devices and assigns a second image to be rendered by the second portion of the plurality of graphics devices. In yet another alternate embodiment, the method assigns rendering data within a first portion of an image to be rendered by the first portion of the plurality of graphics devices and assigns rendering data within both the first portion and a second portion of the image to be rendered by the first and second portions of the plurality of graphics devices.",{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1","b":["100","100","105","105","110","105","115","120","100","125","100","100","105","110","115","120","125","160"]},"A graphics subsystem  is further connected with data bus  and the components of the computer system . The graphics subsystem  includes a graphics processing unit (GPU)  and graphics memory. Graphics memory includes a display memory  (e.g., a frame buffer) used for storing pixel data for each pixel of an output image. Pixel data can be provided to display memory  directly from the CPU . Alternatively, CPU  provides the GPU  with data and\/or commands defining the desired output images, from which the GPU  generates the pixel data of one or more output images. The data and\/or commands defining the desired output images is stored in additional memory . In an embodiment, the GPU  generates pixel data for output images from rendering commands and data defining the geometry, lighting, shading, texturing, motion, and\/or camera parameters for a scene.","In another embodiment, display memory  and\/or additional memory  are part of memory  and is shared with the CPU . Alternatively, display memory  and\/or additional memory  is one or more separate memories provided for the exclusive use of the graphics subsystem . The graphics subsystem  periodically outputs pixel data for an image from display memory  and displayed on display device . Display device  is any device capable of displaying visual information in response to a signal from the computer system , including CRT, LCD, plasma, and OLED displays. Computer system  can provide the display device  with an analog or digital signal.","In a further embodiment, graphics processing subsystem  includes one or more additional GPUs , similar to GPU . In an even further embodiment, graphics processing subsystem  includes a graphics coprocessor . Graphics processing coprocessor  and additional GPUs  are adapted to operate in parallel with GPU . Additional GPUs  generate pixel data for output images from rendering commands, similar to GPU . Additional GPUs  can operate in conjunction with GPU  to simultaneously generate pixel data for different portions of an output image, or to simultaneously generate pixel data for different output images. In an embodiment, graphics coprocessor  performs rendering related tasks such as geometry transformation, shader computations, and backface culling operations for GPU  and additional GPUs .","Additional GPUs  can be located on the same circuit board as GPU  and sharing a connection with GPU  to data bus , or can be located on additional circuit boards separately connected with data bus . Additional GPUs  can have their own display and additional memory, similar to display memory  and additional memory , or can share memories  and  with GPU . In an embodiment, the graphics coprocessor  is integrated with the computer system chipset (not shown), such as with the Northbridge chip used to control the data bus .",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIGS. 2A and 2B","b":["200","200","205","210"]},"In general, split-frame parallel rendering schemes such as that illustrated by  require GPUs to be programmed with a combination of common rendering commands, which are executed by all of the GPUs of the system, and specific rendering commands, which are executed by a subset of the GPUs of the system. In the example of , both GPUs are programmed with common rendering commands necessary to render all of the geometry and shading of the scene. The GPUs are then programmed with separate rendering commands to define clipping windows corresponding to image portions  and .",{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 2B","b":["212","212","215","240","245","240","245","240","245","215"]},"Memory map  graphically represents the range of available memory addresses in system . Memory map contains several apertures, or ranges of memory addresses used to communicate with the GPUs  and . Broadcast aperture  enables the CPU to communicate with all of the GPUs in the system  simultaneously. Commands and data written to the broadcast aperture are distributed to all of the GPUs  and , as well as any other GPUs in the system . In some systems, a bridge chip is associated with the broadcast aperture  and is adapted to copy data written to the broadcast aperture  to each GPU in the system .","In addition to the broadcast aperture , the memory map also includes a set of unicast apertures  and . Unicast apertures  and  are adapted to distribute commands and data to GPUs  and , respectively. Commands and data written to a unicast aperture will only be distributed to the GPU associated with the unicast aperture. The unicast apertures enable the CPU  to program GPUs  and  separately.","The use of broadcast and unicast apertures to program multiple GPUs introduces several limitations. First, there is typically a separate unicast aperture for each GPU in a system. As each typical unicast aperture can be 256 megabytes in size, systems with a large number of GPUs often need to reserves gigabytes of address space for the apertures. The large address space requirements can limit the performance of systems, and in extreme cases limit the potential number of GPUs in a system, particularly with 32-bit systems that are often limited to , gigabytes of total address space. Additionally, some systems require that the GPUs operating in parallel be synchronized. To prevent de-synchronization, when the CPU writes commands and data to one unicast aperture, the CPU must also write null commands and padding data to all of the other unicast apertures. This makes programming individual GPUs very inefficient.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 3","FIG. 1","FIG. 3"],"b":["300","305","310","305","310","315","315","305","310","315","110","315","305"]},"Command buffer  stores sets of rendering commands, such as rendering command , and sets of rendering data, such as rendering data . In one embodiment, a rendering command is associated with rendering data. The rendering command defines the set of rendering processes to be performed by the GPU on an associated rendering data. In a further embodiment, the rendering data is stored in the command buffer  adjacent to the corresponding rendering command.","The CPU  writes rendering commands and data sets to the command buffer . The command buffer  can include a number of rendering commands and data sets. The CPU  writes commands and data sets into the command buffer  at the location determined by \u201cput\u201d pointer . Following each CPU write into the command buffer , the CPU  increments the put pointer  to the next unused location in the command buffer . In an embodiment, a driver software program executed by the CPU  translates high-level rendering commands from a rendering application into commands and data sets, which are then written into the command buffer . In a further embodiment, the driver software program receives high-level rendering commands via an application programming interface, for example DirectX\u2122 or OpenGL\u2122.","The GPU  reads commands and data sets from the command buffer . The GPU  reads commands and data sets from the command buffer  at the location determined by \u201cget\u201d pointer . Following each GPU read from the command buffer , the GPU  increments the get pointer  to the location of the next command or data set in the command buffer .","The CPU  and GPU  can access the command buffer independently. In an embodiment, the CPU  periodically adds new commands and data sets to the command buffer . Simultaneously, the GPU  reads processes commands and data sets previously stored by the CPU  continuously. Provided the CPU  stays sufficiently far ahead of the GPU , the GPU  is able to render images without any idle time waiting for the CPU . In an embodiment, the CPU  writes commands and data sets for frames several frames ahead of the frame being rendered by the GPU .","In an embodiment, the command buffer is limited in size. As an example, a typical command buffer is five megabytes in size. When either the get pointer  or put pointer  reaches the end of the command buffer , the pointer is reset to the location of the beginning of the command buffer . In this manner, the command buffer  \u201cwraps around,\u201d enabling the CPU and GPU to access the command buffer  in a continuous loop.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 4","b":["400","400","0","405","1","410","415","420","450","420","460","420","450","460"]},"Command buffer includes common rendering commands and data sets , which are to be read and executed by all of the GPUs. To program a subset of the GPUs in the system separately, the CPU writes a Set Device Mask (SDM) command  to the command buffer . The SDM command  designates the subset of GPUs to execute subsequent GPU-specific rendering commands in the command buffer, such as rendering commands . As discussed below, GPUs that are not designated by the SDM command  will ignore the GPU-specific rendering commands. However, as discussed below, the non-designated GPUs will continue to read from the command buffer to maintain synchronization. A different subset of GPUs can be designated by a second SDM command  to execute another group of GPU-specific rendering commands. Following one or more groups of GPU-specific rendering commands, command buffer  includes an SDM command  designating all of the GPUs in the system. One or more groups of common rendering commands following SDM command  will then be executed by all of the GPUs.","In an embodiment, the SDM command  includes a device mask designating the GPUs that will execute subsequent rendering commands. In this embodiment, each GPU is assigned a unique identifier. In a further embodiment, these identifier is assigned to each GPU (and a graphics coprocessor, if provided) by a software driver upon system initialization. Each identifier corresponds to a single bit in the device mask. If a bit in the device mask is asserted, then the associated GPU is designated to execute subsequent rendering commands. Conversely, a negated bit instructs a GPU to ignore subsequent rendering commands until its associated bit is reasserted.","For example, SDM command  includes a device mask with a value of \u201c10 . . . 0\u201d This device mask indicates that GPU-, , should execute subsequent rendering commands , while GPUs  and  will ignore rendering commands . It should be noted that the device mask included with the SDM commands can include any number of bits, thereby enabling the separate programming of any number of GPUs. Further, the device mask can have any combination of asserted or negated bits. This enables the CPU to program two or more GPUs simultaneously. For example, a device mask of \u201c100001111\u201d would indicate that GPUs , , , , and  are to execute subsequent rendering commands, while GPUs , , , and  are to ignore subsequent rendering commands until their corresponding device mask bits are reasserted.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 5","b":["500","500","505","530","505","510","510","510","515","515","510","515","517","510"]},"Front end  includes a command receive unit  for receiving a rending command and data  from the command buffer. Command receive unit  determines whether the received rendering command is an instruction or a method. Rendering command  can be classified as either an instruction or a method. Instructions are rendering commands that determine the program flow executed by the GPU . Examples of instructions include a jump instruction, which sets the get pointer to a new, non-consecutive location; a no op instructions, which does nothing and is used as a placeholder; and call and return functions, which are used to enter and exit subroutines of rendering commands. The SDM command is also classified as an instruction. Methods are rendering commands that determine the pixel data output by the GPU. In embodiment , the front end  executes instructions and the GPU core executes methods.","Upon receiving an instruction, the command receive unit  forwards the instruction to the instruction decoder . Methods are similarly forwarded to method cache  to be retrieved and executed by the GPU core , subject to the SDM instruction. Upon receiving a SDM instruction, instruction decoder  compares the device mask with its own assigned identifier. If the associated bit of the device mask is negated, the instruction decoder  disables the link between command receive unit  and method cache . This causes all subsequent methods received by the GPU  to be discarded and ignored.","During the time when GPU  is ignoring rendering methods, the front end  continues to retrieve rendering commands from the command buffer and to execute instructions. For example, instruction decoder  can update the get pointer  if indicated by a jump, call, or return instruction. In this manner, the GPU state stays synchronized with the other GPUs, even when the methods of rendering commands are being ignored. Upon receiving a subsequent SDM instruction having the bit associated with GPU  reasserted, instruction decoder  re-enables the link between the command receive unit  and the instruction cache . As a result, subsequently received methods are added to the cache  and are processed by the GPU core .",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIGS. 6A and 6B","b":["600","600","605","610","615","620","630","625","605","610","615","620","625","600"]},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 6B","b":["635","640","620","640","620","640","620","645","620","615","640","645","615","615","650","655","610","605"]},"Following the programming of GPU-specific commands using commands sets , , , and , a SDM command with a device mask of \u201c1111\u201d is used to enable simultaneous programming of all of the GPUs. Common rendering commands  for rendering the scene are executed by all of the GPUs. Following the rendering of the separate portions of the output image, an embodiment of the invention assembles these portions into a complete output image. Blit commands  are used to copy the portions rendered by GPUs , , and  to the display memory of GPU . Because each image portion must be copied to a different location in the display memory of GPU , a further embodiment of blit commands  includes a set of SDM commands to selectively program GPUs , , and  with different copy commands. GPU  outputs the assembled image to display device .",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIGS. 7A and 7B","FIG. 7A"],"b":["700","705","705","0","705","710","710","1","0","1","710","715","2","715","2","2","0","1"]},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 7B"},"Command buffer  illustrates an example of the programming used to implement this geometry culling. Command set  includes a SDM command designating a first set of GPU-specific commands. These GPU-specific commands include a command setting the clip region for a first GPU to a first portion of the screen to be rendered by this GPU. Command set  also includes rendering commands and data for rendering an object visible or potentially visible in the assigned clip region.","Similarly, command set  includes a SDM command designating a second set of GPU-specific commands. The second set of GPU-specific commands include a command setting a second clip region for a second GPU to a second portion of the screen to be rendered by this GPU. In this example, the object is not visible or potentially visible in the second clip region. Thus, unlike the command set , rendering commands for this object are omitted from command set . Command set  includes a SDM command enabling simultaneous programming of the first and second GPUs. Command set  further includes common rendering commands and data for rendering the remaining elements of the scene.","This invention provides a very efficient way to program multiple GPUs and an optional graphics coprocessing without consuming an exorbitant amount of system resources. In a typical embodiment, only a single memory aperture is needed to program any number of devices. Although the invention has been discussed with respect to specific examples and embodiments thereof, these are merely illustrative, and not restrictive, of the invention. Though the invention is discussed with reference to several parallel rendering schemes, the invention can be used in any application where different hardware devices are used to render images. For example, some content may be encrypted for security or for digital rights management. A decryption-capable graphics device can be programmed to render the encrypted content, while other graphics devices in the system render the non-encrypted content. Thus, the scope of the invention is to be determined solely by the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The invention will be described with reference to the drawings, in which:",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIGS. 2A and 2B"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIGS. 6A and 6B"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIGS. 7A and 7B"}]},"DETDESC":[{},{}]}
