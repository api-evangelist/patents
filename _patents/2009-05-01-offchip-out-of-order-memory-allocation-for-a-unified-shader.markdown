---
title: Off-chip out of order memory allocation for a unified shader
abstract: Systems and methods for dynamically allocating memory for thread processing may reduce memory requirements while maintaining thread processing parallelism. A memory pool is allocated to store data for processing multiple threads that does not need to be large enough to dedicate a fixed size portion of the memory pool to each thread that may be processed in parallel. Fixed size portions of the memory pool are dynamically allocated and deallocated to each processing thread. Different fixed size portions may be used for different types of threads to allow greater thread parallelism compared with a system that requires allocating a single fixed portion of the memory pool to each thread. The memory pool may be shared between all of the thread types or divided to provide separate memory pools dedicated to each particular thread type.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08407443&OS=08407443&RS=08407443
owner: NVIDIA Corporation
number: 08407443
owner_city: Santa Clara
owner_country: US
publication_date: 20090501
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This application is a continuation of U.S. patent application Ser. No. 11\/382,888, filed May 11, 2006. The subject matter of this related application is hereby incorporated by reference.","1. Field of the Invention","Embodiments of the present invention generally relate to memory allocation for multithreaded processing and, more specifically, to dynamically allocating per-thread memory from a memory pool.","2. Description of the Related Art","Conventional multithreaded processing systems use off-chip memory to store data for each thread being processed. An amount of memory needed to store the greatest amount of data needed for a thread is needed for each of the threads that may be processed in parallel by the multithreaded processing system. Therefore, the total amount of memory needed to process the threads may be larger than is practical to dedicate to the thread processing. Increasing the off-chip memory to accommodate the memory needed for all of the threads may increase the cost of producing the processing system. In order to reduce the cost, in some conventional systems the amount of memory allocated to the threads is limited and the number of the threads that can be processed in parallel is limited by disabling some of the thread processors. In those systems, the processing performance of the multithreaded processing units may be reduced since fewer threads are processed in parallel.","Accordingly, there is a desire to allow as many threads as possible to execute in parallel even when an amount of memory equal to the greatest amount of memory needed by any of the threads is not allocated for each thread.","The current invention involves new systems and methods for dynamically allocating per-thread memory from a memory pool. A memory pool is allocated to store data for processing multiple threads. Fixed size portions of the memory pool are dynamically allocated and deallocated to each processing thread. Therefore, the memory pool is efficiently used to process as many threads in parallel as possible without requiring that the memory pool be large enough to dedicate a fixed size portion of the memory pool to each thread that may be processed in parallel. Therefore, the processing performance increases as the amount of memory allocated for the memory pool increases. Furthermore, different fixed size portions may be used for different types of threads to allow greater thread parallelism compared with a system that requires allocating a single fixed portion of the memory pool to each thread, where the single fixed size portion is equal to the largest amount of memory needed by any thread (of all of the thread types). The memory pool may be shared between all of the thread types or divided to provide a memory pool dedicated to each particular thread type.","Various embodiments of a method of the invention for processing threads in a multithreaded processor to execute a shader program include receiving a thread launch request for a first thread, determining that the first thread requires a memory allocation to execute the shader program in the multithreaded processor, obtaining an available memory offset specifying an allocation unit within a memory pool allocated for processing the threads, wherein a size of the allocation unit is based on a largest amount of memory needed by any thread to execute the shader program in the multithreaded processor, and writing the available memory offset in an entry of a thread table to allocate the allocation unit within the memory pool to the first thread.","Various embodiments of the invention include a system for multiple execution threads. The system includes a thread table, a multithreaded processing unit, and a memory allocation unit. The thread table is configured to store a memory offset for each one of the multiple execution threads. The multithreaded processing unit is configured to process the multiple execution threads using the memory allocated to the multiple execution threads. The memory allocation unit is configured to allocate allocation units from a memory pool to the multiple execution threads and deallocate the allocation units as each one of the multiple execution threads completes execution of a shader program, wherein the memory allocation unit is further configured to deallocate allocation units in either the same or a different order than the allocation units are allocated.","In the following description, numerous specific details are set forth to provide a more thorough understanding of the present invention. However, it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details. In other instances, well-known features have not been described in order to avoid obscuring the present invention.","Systems and methods for dynamically allocating memory to store data for thread processing may reduce memory allocation requirements while maintaining thread processing parallelism. A memory pool is allocated for processing multiple threads that does not need to be large enough to dedicate a fixed size portion of the memory pool to each thread that may be processed in parallel, where the fixed size portion is the largest amount of memory needed by any thread. Fixed size portions of the memory pool are dynamically allocated and deallocated to each processing thread to allow the greatest number of threads to run in parallel based on the memory pool size. Different fixed size portions may be used for different types of threads to allow greater thread parallelism compared with a system that requires allocating a single fixed portion of the memory pool to each thread. The memory pool may be shared between all of the thread types or divided to provide separate memory pools dedicated to each particular thread type.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 1","b":["100","110","170","100","110","114","112","112","115","115","112","115"]},"A graphics device driver, driver , interfaces between processes executed by host processor , such as application programs, and a programmable graphics processor , translating program instructions as needed for execution by graphics processor . Driver  also uses commands to configure sub-units within graphics processor . Specifically, driver  determines the largest amount of per-thread local memory and stack memory needed by any active shader program. Driver  then allocates a block of local memory and stack memory, local memory block  and stack memory block , respectively, that are large enough to provide the required memory for every thread that may execute in parallel by graphics processor . Per-thread local memory is used to store intermediate results computed during execution of a thread. The largest amount of per-thread stack memory may be determined based on application programming interface (API) imposed limits for nesting levels that specify a maximum stack depth for use during multithreaded processing.","When the amount of memory needed for local memory block  and stack memory block  is not available or would detrimentally impact the performance of graphics processor , driver  may reduce the allocation sizes for local memory block  and\/or stack memory block  and per-thread memory allocation units within graphics processor  will dynamically adapt to the lower memory allocations. In conventional systems, particularly conventional systems lacking the ability to dynamically adapt to various memory allocations, a driver may reduce the number of threads that can be processed in parallel to match the memory allocations, thereby reducing overall processing throughput.","Host computer  communicates with graphics subsystem  via system interface  and a graphics interface  within a graphics processor . Data received at graphics interface  can be passed to a front end  or written to a local memory  through memory controller . Graphics processor  uses graphics memory to store graphics data and program instructions, where graphics data is any data that is input to or output from components within the graphics processor. Graphics memory can include portions of host memory , local memory , register files coupled to the components within graphics processor , and the like.","Graphics processor  includes, among other components, front end  that receives commands from host computer  via graphics interface . Front end  interprets and formats the commands and outputs the formatted commands and data to an IDX (Index Processor) . Some of the formatted commands are used by programmable graphics processing pipeline  to initiate processing of data by providing the location of program instructions or graphics data stored in memory. IDX , programmable graphics processing pipeline  and a raster operations unit  each include an interface to memory controller  through which program instructions and data can be read from memory, e.g., any combination of local memory  and host memory .","IDX  optionally reads processed data, e.g., data written by raster operations unit , from memory and outputs the data, processed data and formatted commands to programmable graphics processing pipeline . Programmable graphics processing pipeline  and raster operations unit  each contain one or more programmable processing units to perform a variety of specialized functions. Some of these functions are table lookup, scalar and vector addition, multiplication, division, coordinate-system mapping, calculation of vector normals, tessellation, calculation of derivatives, interpolation, and the like. Programmable graphics processing pipeline  and raster operations unit  are each optionally configured such that data processing operations are performed in multiple passes through those units or in multiple passes within programmable graphics processing pipeline . Programmable graphics processing pipeline  and raster operations unit  also each include a write interface to memory controller  through which data can be written to memory.","In a typical implementation, programmable graphics processing pipeline  performs geometry computations, rasterization, and pixel computations. Therefore, programmable graphics processing pipeline  is programmed to operate on surface, primitive, vertex, fragment, pixel, sample or any other data. For simplicity, the remainder of this description will use the term \u201csamples\u201d to refer to graphics data such as surfaces, primitives, vertices, pixels, fragments, or the like.","Samples output by programmable graphics processing pipeline  are passed to raster operations unit , which optionally performs near and far plane clipping and raster operations, such as stencil, z test, and the like, and saves the results or the samples output by programmable graphics processing pipeline  in local memory . When the data received by graphics subsystem  has been completely processed by graphics processor , an output  of graphics subsystem  is provided using an output controller . Output controller  is optionally configured to deliver data to a display device, network, electronic control system, other computing system , other graphics subsystem , or the like. Alternatively, data is output to a film recording device or written to a peripheral device, e.g., disk drive, tape, compact disk, or the like.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 2","FIG. 1"],"b":["150","135","150"]},"Samples, such as surfaces, primitives, or the like, are received from IDX  by programmable graphics processing pipeline  and stored in a vertex input buffer  including a register file, FIFO (first in first out) memory, cache, or the like (not shown). The samples are broadcast to execution pipelines , four of which are shown in . Each execution pipeline  includes at least one multithreaded processing unit, to be described further herein. The samples output by vertex input buffer  can be processed by any one of the execution pipelines . A sample is accepted by an execution pipeline  when a processing thread within the execution pipeline  is available to process the sample. Each execution pipeline  signals to vertex input buffer  when a sample can be accepted or when a sample cannot be accepted. In one embodiment of the present invention, programmable graphics processing pipeline  includes a single execution Pipeline  containing one multithreaded processing unit. In other embodiments of the present invention, programmable graphics processing pipeline  includes a plurality of execution pipelines .","Driver  may disable an execution pipeline  when the execution pipeline  was identified to have one or more non-functioning sub-units. Disabling a non-functioning execution pipeline  allows graphics processor  to be used to process graphics data, possibly with lower performance than a fully functional graphics processor . In some embodiments of the present invention, driver  may also disable an execution pipeline  or limit the number of threads an execution pipeline  processes in parallel in order to reduce the amount of memory needed for local memory block  and\/or stack memory block . Each enabled execution pipeline  is assigned a corresponding identifier and local memory block  and stack memory block  do not include memory for disabled execution pipelines  to provide improved memory utilization.","Execution pipelines  may receive first samples, such as higher-order surface data, and tessellate the first samples to generate second samples, such as vertices. Execution pipelines  may be configured to transform the second samples from an object-based coordinate representation (object space) to an alternatively based coordinate system such as world space or normalized device coordinates (NDC) space. Each execution pipeline  may communicate with texture unit  using a read interface (not shown in ) to read program instructions, stack data, and graphics data such as texture maps from local memory  or host memory  via memory controller  and a texture cache . Texture cache  is used to improve memory read performance by reducing read latency. In one embodiment of the present invention, texture cache  is omitted. In another embodiment of the present invention, a texture unit  is included in each execution pipeline . Alternatively, each execution pipeline  has a dedicated instruction read interface to read program instructions from local memory  or host memory  via memory controller .","Execution pipelines  output processed samples, such as vertices, that are stored in a vertex output buffer  including a register file, FIFO memory, cache, or the like (not shown). Processed vertices output by vertex output buffer  are received by a primitive assembly\/setup unit . Primitive assembly\/setup unit  calculates parameters, such as deltas and slopes, to rasterize the processed vertices and outputs parameters and samples, such as vertices, to a raster unit . Raster unit  performs scan conversion on samples, such as vertices, and outputs samples, such as fragments, to a pixel input buffer . Alternatively, raster unit  resamples processed vertices and outputs additional vertices to pixel input buffer .","Pixel input buffer  outputs the samples to each execution pipeline . Samples, such as pixels and fragments, output by pixel input buffer  are each processed by only one of the execution pipelines . Pixel input buffer  determines which one of the execution pipelines  to output each sample to depending on an output pixel position, e.g., (x,y), associated with each sample. In this manner, each sample is output to the execution pipeline  designated to process samples associated with the output pixel position. In an alternate embodiment of the present invention, each sample output by pixel input buffer  is processed by one of any available execution pipelines .","Each execution pipeline  signals to pixel input buffer  when a sample can be accepted or when a sample cannot be accepted. Program instructions configure programmable computation units (PCUs) within an execution pipeline  to perform operations such as tessellation, perspective correction, texture mapping, shading, blending, and the like. Processed samples are output from each execution pipeline  to a pixel output buffer . Pixel output buffer  optionally stores the processed samples in a register file, FIFO memory, cache, or the like (not shown). The processed samples are output from pixel output buffer  to raster operations unit .",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 3","FIG. 2"],"b":["240","300","240","300","300","320","225","300","160","260","141"]},"One characteristic of the system disclosed in , , and  is that it may be configured to embody a SIMD (single instruction multiple data) architecture, where a thread is assigned to each sample processed in the one or more execution pipelines . Therefore, a single program may be used to process several sets of samples. Streaming multithreaded controller  receives samples or pointers to samples stored in pixel input buffer  and vertex input buffer . Streaming multithreaded controller  receives a pointer to a program to process one or more of the samples.","In one embodiment of the present invention, streaming multithreaded controller  assigns a thread (threadID) to each sample to be processed. A thread includes a pointer to a program instruction (program counter), such as the first instruction within the program, thread state information, and storage resources for storing intermediate data generated when processing the sample, i.e., a portion of local memory block . In other embodiments of the present invention, rather than assigning a different threadID to each thread, streaming multithreaded controller  assigns a threadID to several threads that are processed as a group. However, there are points in a program (i.e., branches) where threads in a thread group are allowed to \u201cdiverge\u201d from one another so that one or more threads may execute instructions on their respective samples that do not need to be executed by the other threads in the thread group. Stack memory  may be used to store processing state information for a portion of threads in a group when one or more threads in the thread group diverge. Divergent threads in a thread group may be synchronized at various points in the program to guarantee that some level of synchronized processing may be achieved at those points. Once all of the threads in the thread group are synchronized, the threads resume execution in lock-step, i.e. each sample is processed by the same sequence of instructions in a SIMD manner.","Streaming multithreaded controller  includes a memory allocation unit , address registers , and thread tables . Each thread table  may correspond to a single multithreaded processing unit . A thread table  includes an entry for each thread that may be processed in parallel by a multithreaded processing unit . Memory allocation unit  allocates a portion of memory, local memory block  and\/or stack memory block , to initiate execution of a thread, as described in conjunction with . Memory allocation unit  also deallocates the portion(s) of memory when execution of the thread is complete, as described in conjunction with . Multithreaded processing units  notify memory allocation unit  when execution of a thread is complete.","Address registers  store base addresses of local memory block  and stack memory block , as described in conjunction with . Offsets relative to the base addresses are stored in an entry of thread table  by memory allocation unit  when the portions of memory are allocated to a thread. The base addresses and offsets are combined and provided to a multithreaded processing unit  by streaming multithreaded controller  to process the thread. This provides each thread with a unique memory allocation within local memory block  and\/or stack memory block . In embodiments of the present invention that include two or more execution pipelines , each execution pipeline  has a unique identifier that is combined with the base address and offset to produce an address within a portion of local memory block  or stack memory block  allocated to the particular execution pipeline , as described in conjunction with .",{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 4A","b":["141","142","141","140","240","142","140","240","140","417","297","141","142"]},{"@attributes":{"id":"p-0051","num":"0050"},"figref":["FIG. 4B","FIG. 4A","FIG. 4B","FIG. 4B"],"b":["141","141","142"]},"Local memory block  includes a pool of memory for each enabled execution pipeline . For example, a first portion of local memory block , execution pipeline local pool  is allocated to a first execution pipeline  and another portion of local memory block  is allocated to another execution pipeline . An allocation unit  is the amount of memory allocated to each thread and the amount of memory included in allocation unit  is the largest amount of local memory needed by any active shader program. Within stack memory block , the amount of memory included in an allocation unit is the largest amount of stack memory needed by any active shader program.","The unique identifier for a particular execution pipeline  may be used to locate the pool of memory within local memory block  allocated for that particular execution pipeline . Specifically, the pool of memory allocated to an execution pipeline , execution pipeline local pool  or , may be addressed by combining local base  with the unique identifier for the execution pipeline . Entries within the particular local pool allocated to a thread may be addressed using the memory offset corresponding to the thread (read from a thread table ) and the load\/store address specified by the program instruction.","Each execution pipeline local pool includes an allocation unit  for each thread that may be processed in parallel. In some embodiments of the present invention, each execution pipeline local pool includes 24 allocation units . In one embodiment of the present invention, an execution pipeline  may be configured to process fewer threads in parallel due to non-functional sub-units or when graphics processor  is configured in a low-power or low performance mode. Similarly, one or more execution pipelines  may be completely disabled in which case an execution pipeline local pool is not allocated to those one or more execution pipelines . Therefore, local memory block  is allocated between fewer execution pipelines , providing each enabled execution pipeline  with more local memory to process more threads in parallel.","Using a single size allocation unit  for all shader types is advantageous because all threads can process any shader type and allocation units  may be allocated and deallocated out of order, as described in conjunction with . Using a single pool of memory, such as execution pipeline local pools  and  is advantageous since threads processing a particular shader type may use a large share or a small share of the pool, dynamically adapting to the processing needs of a particular shader program.",{"@attributes":{"id":"p-0056","num":"0055"},"figref":["FIG. 5A","FIG. 3"],"b":["335","335","320","214","220","335","500","530","510","520","540","330","530","410","113","410","410"]},"Memory offset counter  is initialized to zero and is incremented by the value in allocation size register  whenever an allocation unit  is allocated to a thread. Memory offset counter  wraps through zero when it overflows rather than saturating. Thread counter  is also initialized to zero and increments whenever an allocation unit  is allocated to a thread. Thread counter  represents the number of entries in thread tables . Memory offset counter  and thread counter  are both reset to zero when the size of allocation unit  is changed, i.e., when allocation size register  is written. In some embodiments of the present invention, memory offset counter  is 24 bits and increments in an allocation size of 16 bytes for local memory block . In some embodiments of the present invention, memory offset counter  is 15 bits and increments in an allocation size of 128 bytes for stack memory block .","Memory offset FIFO  is a deallocation buffer that stores memory offsets for allocation units  that have been deallocated and are available for allocation to launch another thread. The number of entries in memory offset FIFO  is equal to the number of entries in thread tables . The width of offset FIFO  matches the width of memory offset counter . Memory offset FIFO  is reset to empty when the size of allocation unit  is changed.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIG. 5B","FIG. 5B"],"b":["141","142","550","500","552","500","500","580"]},"If, in step  memory allocation controller  determines that the thread requires a memory allocation, then in step  memory allocation controller  determines if an allocation unit  is available. An allocation unit  is available when memory offset FIFO  is not empty, i.e., when a memory offset is stored in memory offset FIFO . If, in step  memory allocation controller  determines that an allocation unit  is available, then in step  memory allocation controller  pops a (deallocated) memory offset stored in an entry of memory offset FIFO . In step  memory allocation controller  writes the popped memory offset into an available entry in a thread table  and proceeds directly to step  since the memory allocation is complete.","If, in step  memory allocation controller  determines that an allocation is not available, then in step  memory allocation controller  determines if all of the threads are allocated. Memory allocation controller  may determine whether or not all of the threads are allocated by reading thread counter  and comparing the value of thread counter to a limit specifying the maximum number of threads that may be processed in parallel. The limit may be programmed by driver  in order to reduce the amount of memory needed for local memory block  or stack memory block . When all of the threads are allocated, all of the entries in thread tables  are occupied with active threads and memory allocation controller  returns to step  to wait until a thread completes execution and deallocates its allocation unit . When memory allocation controller  cannot allocate memory for a thread launch request it indicates that a launch is not available, effectively stalling further thread launch requests.","If in step  memory allocation controller  determines if all of the threads are not allocated, then in step  an allocation unit  is available. A memory offset corresponding to the allocation unit  has not been pushed into memory offset FIFO  since this is the first allocation of the allocation unit  following a change to allocation size register  or a reset. In step  memory allocation controller  reads memory offset counter  and writes the value to an available entry in a thread table . In step  memory allocation controller  updates memory offset counter  by adding the value of allocation size register  to the value in memory offset counter . The value of memory offset counter  then corresponds to the next available allocation unit . Once the memory offset counter  overflows, the memory offset values will be obtained from memory offset FIFO , until allocation size register  is changed or memory allocation unit  is reset.","In step  memory allocation controller  updates thread counter , incrementing the value in thread counter  to indicate that an allocation unit  has been allocated to another thread. Memory allocation controller  then proceeds to step  and the memory allocation for the thread launch request is complete.",{"@attributes":{"id":"p-0064","num":"0063"},"figref":["FIG. 5C","FIG. 5C"],"b":["141","142","590","335","300","591","500","410","500","596"]},"If, in step  memory allocation controller  determines that an allocation unit  was allocated to the thread, then in step  memory allocation controller  reads an entry of a thread table  corresponding to the thread ID to obtain the memory offset stored for the thread. In step  memory allocation controller  pushes the memory offset onto memory offset FIFO  to deallocate the allocation unit  making the allocation unit  available for allocation to another thread. In step  the deallocation is complete.","An advantage of the memory allocation and deallocation methods described in conjunction with , B, and C is that allocation units  may be allocated and deallocated in any order. Therefore, a first thread that requires a longer time to execute will not prevent other threads from receiving a memory allocation, even when the first thread received a memory allocation before the other threads. Furthermore, an allocation unit  may be allocated to any thread type since it is sized to support the largest memory requirement. All allocation units  within a single pool may be allocated to a single thread type or to a variety of thread types, as needed to process the samples received from pixel input buffer  and vertex input buffer .",{"@attributes":{"id":"p-0067","num":"0066"},"figref":["FIG. 6A","FIG. 3"],"b":["335","335","600","630","610","330","530","630","410","113"]},"Pointer registers  store a head pointer and a tail pointer for a local memory pool that are used to configure the local memory pool as a ring buffer. Unlike the embodiment of memory allocation unit  described in conjunction with , B, and C, the \u201cout of order\u201d memory allocation unit , allocation units  may not be allocated and deallocated out of order. However, the die area needed to implement this embodiment is less than the \u201cout of order\u201d memory allocation unit . The head pointer and tail pointer are both reset to zero when memory allocation unit  is reset or when the size of allocation unit  is changed, i.e., when allocation size register  is written. Memory allocation unit controller  also indicates that the ring buffer is empty, i.e., not full, to distinguish for the case when the head and tail pointers are equal and the ring buffer is full.","The tail pointer indicates the oldest in-use memory pool allocation, i.e., the memory offset of the oldest allocated allocation unit . The head pointer indicates the next free memory pool allocation, i.e., the memory offset of the first available allocation unit . In some embodiments of the present invention, the read pointer and the tail pointer are each 23 bits and represent an allocation unit  size of 16 bytes for local memory block . In some embodiments of the present invention, the read pointer and the tail pointer are each 14 bits and represent an allocation unit  size of 128 bytes for stack memory block . The width of entries in thread tables  matches the width of the associated memory pool head and tail pointers.",{"@attributes":{"id":"p-0070","num":"0069"},"figref":["FIG. 6B","FIG. 6B"],"b":["141","142","650","600","652","600","600","664"]},"If, in step  memory allocation controller  determines that the thread requires a memory allocation, then in step  memory allocation controller  determines if an allocation is available. An allocation is available when the tail pointer and head pointer stored in pointer registers  are not equal and the ring buffer is not full. If, in step  memory allocation controller  determines that an allocation unit  is available, then in step  memory allocation controller  writes the head pointer into an available entry in a thread table . In step  memory allocation controller  updates the head pointer, increasing it by the value of allocation size register . When the head pointer is increased and overflows, the head pointer value wraps rather than saturates. The value of the head pointer stored in pointer registers  then corresponds to the next available allocation unit .","In step  memory allocation controller  determines if the tail pointer equals the head pointer, and, if so, in step  memory allocation controller  indicates that the ring buffer is full. Memory allocation controller  then proceeds to step  and the memory allocation for the thread launch request is complete. If, in step  memory allocation controller  determines that the tail pointer does not equal the head pointer, then memory allocation controller  proceeds directly to step .","If, in step  memory allocation controller  determines that an allocation is not available, then memory allocation controller  returns to step  to wait until a thread completes execution and deallocates its allocation unit . When all of the threads are allocated, all of the entries in thread tables  are occupied with active threads.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":["FIG. 6C","FIG. 6C"],"b":["141","142","690","335","300","691","600","410","600","696"]},"If, in step  memory allocation controller  determines that an allocation unit  was allocated to the thread, then in step  memory allocation controller  indicates that the ring buffer is not full. The entry corresponding to the thread ID becomes available to store another memory offset, e.g., head pointer value, thereby making an allocation unit  available for allocation to another thread. In step  memory allocation controller  updates the tail pointer by increasing it by the value of allocation size register . When the tail pointer is increased and overflows, the tail pointer value wraps rather than saturates. The value of the tail pointer stored in pointer registers  then corresponds to the oldest in-use memory pool allocation. In step  the deallocation is complete.","An advantage of the methods for allocating and deallocating memory for threads as described in conjunction with  and C is that allocation size changes, changes to the value stored in allocation size register  may be pipelined. Therefore, all of the allocation units  do not need to be deallocated before allocation size register  is written with a different value. However, the previous value stored in allocation size register  does need to be retained until the tail pointer is updated to equal the value of the head pointer at the time allocation size register was written. Furthermore, an allocation unit  may be allocated to any thread type since it is sized to support the largest memory requirement. All allocation units  within a single pool may be allocated to a single shader thread type or to a variety of shader thread types, as needed to process the samples received from pixel input buffer  and vertex input buffer .","Sharing a memory pool between different shader thread types may be undesirable when the memory requirement of the different shader thread types is not similar. For example, when one of the shader thread types require a large memory allocation, a portion of each allocation unit  will be unused for the other shader thread types. As allocation unit  increases to accommodate the largest shader thread type allocalton, fewer allocation units  will fit within the memory pool, reducing the number of threads that may be processed in parallel. Therefore, thread processing throughput may decrease when a single size allocation unit  is used for all shader thread types. An alternative embodiment of the present invention, includes different memory pools for each shader type and an allocation unit size may be specified for each shader type.",{"@attributes":{"id":"p-0078","num":"0077"},"figref":["FIG. 7A","FIG. 4A","FIG. 7A","FIGS. 7A"],"b":["141","141","142"]},"In the shared memory scheme described in conjunction with  a single memory pool is allocated to an enabled execution pipeline  and the memory pool sized is the same for each enabled execution pipeline . In the dedicated memory pool scheme shown in , local memory block  includes a pool of memory for each shader type rather than for each enabled execution pipeline , e.g., local vertex pools , local geometry pools , and local pixel pools . The memory pools may be sized differently for each shader type, therefore a different base address is used for each memory pool e.g., local vertex pools base , local geometry pools base , and local pixel pools base . The shader type may be used to locate the pool of memory within local memory block  allocated for that particular shader type. Each shader type memory pool is divided into equal portions that are each allocated to an enabled execution pipeline . Memory pools are not allocated to disabled execution pipelines  in order to better utilize local memory block  and stack memory block .","The unique identifier for a particular execution pipeline  may be used to locate the pool of memory for a shader type within local memory block  allocated for that particular execution pipeline . For example, a first portion of local pixel pools , local pixel pool  is allocated to a first execution pipeline  and another portion of local pixel pools , local pixel pool  is allocated to a last execution pipeline . Similarly, a first portion of local geometry pools , local geometry pool  is allocated to the first execution pipeline  and another portion of local geometry pools , local geometry pool  is allocated to the last execution pipeline . Finally, a first portion of local vertex pools , local vertex pool  is allocated to the first execution pipeline  and another portion of local vertex pools , local vertex pool  is allocated to the last execution pipeline .","Each dedicated shader type memory pool has a corresponding base address, e.g., local vertex pools base , local geometry pools base , and local pixel pools base . A particular local pixel pool allocated to an execution pipeline  may be addressed by combining local pixel pools base  with the unique identifier for the execution pipeline . Entries within the particular local pool allocated to a thread may be addressed using the memory offset corresponding to the thread (read from a thread table ) and the load\/store address specified by the program instruction.",{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIG. 7B","FIG. 7A"],"b":["711","240","750","750","410","141"]},{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 7C","FIG. 7A"],"b":["721","240","760","760","410","141"]},{"@attributes":{"id":"p-0084","num":"0083"},"figref":["FIG. 7D","FIG. 7A"],"b":["731","240","770","770","410","141"]},"Using different size allocation units, e.g., vertex unit , geometry unit , and pixel unit , for each shader types is advantageous because memory within local memory block  and\/or stack memory block  is not necessarily wasted for shader types that need less memory than the maximum amount of memory needed by any of the shader types. The methods of allocating and deallocating memory for threads \u201cin order\u201d or \u201cout of order,\u201d described in conjunction with , C, B, and C may be used with memory pools dedicated for each shader type.",{"@attributes":{"id":"p-0086","num":"0085"},"figref":["FIG. 8A","FIG. 3","FIG. 5A"],"b":["335","800","320","214","220","500","500","830","810","820","840","330"]},"Allocation size registers  is programmed by driver  and stores the sizes of each shader type allocation, e.g., vertex unit , geometry unit , and pixel unit . Before the size of an allocation unit may be changed, all allocation units for the shader type should be deallocated, i.e., all of the threads of the shader type should complete processing. Rather than having a single memory offset count, such as memory offset counter , this embodiment of memory allocation unit  includes a memory offset counter for each shader type in memory offset counters . Memory offset counters  are initialized to zero and the counter for a particular shader type is incremented by the corresponding value stored in allocation size registers  whenever an allocation unit is allocated to a thread for the particular shader type. Memory offset counters  wrap through zero when they overflow rather than saturating.","Rather than having a single thread counter, such as thead counter , this embodiment of memory allocation unit  includes a thead counter for each shader type in thread counters . Each counter may represent the maximum number of allocation units in the local pool corresponding to one shader type. For example, a vertex thread counter has a maximum value equal to the number of vertex units  within the local vertex pools allocated to execution pipelines  that are supported by memory allocation unit . Each thread counter within thread counters  is initialized to zero and increments whenever an allocation unit for a shader type is allocated to a thread to process the shader type. A memory offset counter in memory offset counters  and a thread counter in thread counters  are both reset to zero when the size of the allocation unit corresponding to the shader type is changed, i.e., when a register in allocation size registers  is written.","Memory offset FIFOs  each store memory offsets for allocation units that have been deallocated for one shader type and are available for allocation to launch another thread for the shader type. The number of entries in a memory offset FIFO  is equal to the maximum number of allocation units in the local pool corresponding to one shader type. The width of each offset FIFO  matches the width of memory offset counters . A memory offset FIFO  for a particular shader type is reset to empty when the size of the allocation unit for that shader type is changed.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":["FIG. 8B","FIG. 3"],"b":["335","335","850","830","860","330"]},"Like pointer registers  of , pointer registers  store a head pointer and a tail pointer that are used to configure a local memory pool as a ring buffer. However, pointer registers  store a head pointer and a tail pointer for each shader type memory pool to configure each shader type memory pool as a ring buffer. Unlike the embodiment of memory allocation unit  described in conjunction with , B, C, and A, the \u201cout of order\u201d memory allocation units , shader type allocation units may not be allocated and deallocated out of order. However, the die area needed to implement this embodiment is less than the \u201cout of order\u201d memory allocation unit  shown in . The head pointers and tail pointers are reset to zero when memory allocation unit  is reset. The head pointer and tail pointer for a shader type are both reset to zero when the size of the shader type allocation unit is changed, i.e., when the corresponding register in allocation size registers  is written. Memory allocation unit controller  also indicates that the ring buffer for a shader type is empty, i.e., not full, to distinguish for the case when the head and tail pointers are equal and the ring buffer for the shader type is full.","Persons skilled in the art will appreciate that any system configured to perform the method steps of , C, B, or C, or their equivalents, is within the scope of the present invention. Systems and methods for dynamically allocating memory for thread processing may reduce memory requirements while maintaining thread processing parallelism. A memory pool is allocated to store data for processing multiple threads that does not need to be large enough to dedicate a fixed size portion of the memory pool to each thread that may be processed in parallel. Fixed size portions of the memory pool are dynamically allocated and deallocated to each processing thread. Different fixed size portions may be used for different types of threads to allow greater thread parallelism compared with a system that requires allocating a single fixed portion of the memory pool to each thread. The memory pool may be shared between all of the thread types or divided to provide separate memory pools dedicated to each particular thread type.","While the foregoing is directed to embodiments of the present invention, other and further embodiments of the invention may be devised without departing from the basic scope thereof, and the scope thereof is determined by the claims that follow. The foregoing description and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense. The listing of steps in method claims do not imply performing the steps in any particular order, unless explicitly stated in the claim.","All trademarks are the respective property of their owners."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["So that the manner in which the above recited features of the present invention can be understood in detail, a more particular description of the invention, briefly summarized above, may be had by reference to embodiments, some of which are illustrated in the appended drawings. It is to be noted, however, that the appended drawings illustrate only typical embodiments of this invention and are therefore not to be considered limiting of its scope, for the invention may admit to other equally effective embodiments.",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 4B","FIG. 4A"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 5A","FIG. 3"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5C"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 6A","FIG. 3"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 6C"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 7A","FIG. 4A"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 7B","FIG. 7A"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 7C","FIG. 7A"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 7D","FIG. 7A"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIGS. 8A and 8B","FIG. 3"]}]},"DETDESC":[{},{}]}
