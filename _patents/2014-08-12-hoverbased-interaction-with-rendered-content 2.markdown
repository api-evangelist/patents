---
title: Hover-based interaction with rendered content
abstract: Disclosed are techniques and systems for enabling “hover-based” interaction with content that is rendered on a display of a viewing device. A process may include rendering content on a display, detecting an object hovering in front of a front surface of the display, and in response to detecting the object, determining a location on the front surface of the display corresponding to a position of the object. The determined location on the front surface of the display may then be used to determine a portion of the content that is rendered at the location or within a threshold distance from the location, and a magnified window of the portion of the content may then be displayed in a region of the display. The portion of the content within the magnified window may be actionable by responding to user input when the user input is provided within the magnified window.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09594489&OS=09594489&RS=09594489
owner: Microsoft Technology Licensing, LLC
number: 09594489
owner_city: Redmond
owner_country: US
publication_date: 20140812
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Example One","Example Two","Example Three","Example Four","Example Five","Example Six","Example Seven","Example Eight","Example Nine","Example Ten","Example Eleven","Example Twelve","Example Thirteen","Example Fourteen","Example Fifteen","Example Sixteen","Example Seventeen","Example Eighteen","Example Nineteen","Example Twenty","Example Twenty-One","Example Twenty-Two","CONCLUSION"],"p":["Desktop computers once reigned as the most common personal computer configuration, leading software developers to create content designed for optimal rendering on a desktop display. For example, website developers often favor rich, dense content for a web page so that the display \u201creal estate\u201d on a viewing device can be utilized to its fullest extent. One factor driving website developers toward rich, dense web page content is the fact that third party entities are willing to pay for their content (e.g., advertisements) to be provided on a content provider's web page. This means that content providers effectively lose money when they choose to leave empty space on a web page.","Designing content that is rich and dense is generally a nonissue with desktop displays. For instance, an average user whose eyes are positioned roughly a foot away from a 19 inch desktop display is capable of unassisted reading of dense content rendered on the display, and is further able to navigate and browse the content by manipulating an on-screen cursor with a mouse or a similar pointing device.","As computing technology has advanced, however, computing devices having a small form factor have become ubiquitous. For example, many individuals own a smart phone (typically with a display size in the range of about 4 to 5 inches) and take it with them everywhere they go. Furthermore, consumers are now becoming familiar with the practice of surfing the Internet from the comfort of their own living room on a home television (TV) display. In either scenario, at least some content that is rendered on the user's display may be difficult to read and\/or select when attempting to interact with the content. With respect to small form factor devices, readability and\/or selectability issues stem from rendering dense content on a small display. A similar issue arises in the living room TV scenario when a user is situated at a substantial distance from the display that makes it difficult to read and\/or select content provided in a rich, dense layout. As a consequence, users continue to experience frustration when navigating and browsing content on their consumer devices.","Described herein are techniques and systems for enabling \u201chover-based\u201d interaction with content that is rendered on a display of a viewing device. The term \u201chover,\u201d (sometimes called \u201cthree-dimensional (3D) touch\u201d) is used to describe a condition where an object is positioned in front of, but not in contact with, the front surface of the display, and is within a predetermined 3D space or volume in front of the display. Accordingly, a hovering object may be defined as an object positioned in front of the display of the computing device within the predetermined 3D space without actually contacting the front surface of the display. The dimensions of the 3D space where hover interactions are constrained, and particularly a dimension that is perpendicular to the front surface of the display, may depend on the size of the display and\/or the context in which the display used, as will be described in more detail below.","In some embodiments, a process of enabling hover-based interaction with content includes rendering the content on a display, detecting an object in front of, but not in contact with, a front surface of the display, and in response to detecting the object, determining a location on the front surface of the display that is spaced a shortest distance from the object relative to distances from the object to other locations on the front surface. The determined location on the front surface of the display may then be used to determine a portion of the content that is rendered at the location or within a threshold distance from the location, and a magnified window of the portion of the content may then be displayed in a region of the display. In some embodiments, the portion of the content within the magnified window is actionable by responding to user input when the user input is provided within the magnified window. Systems and computer-readable media for implementing the aforementioned process are also disclosed herein.","By displaying a magnified window in a region of the display in response to detecting an object hovering in front of the display, a user may experience enhanced browsing and navigation of rendered content. Specifically, the rendered content may remain at a lowest zoom level (i.e., zoomed out), and the user may conveniently identify portions of the rendered content that are of interest to the user without changing the zoom level of the rendered content. In other words, the magnified window feature eliminates the steps required to pinch and zoom (and potentially pan) the content in order to find, read, and\/or select content rendered on the display, saving the user time and eliminating frustration when browsing content. Upon finding an interesting portion of the content via the magnified window, the user may then have the ability to zoom to the portion of interest via a user input command. Moreover, the magnified window feature also enables content providers to continue to design content that is rich and dense without expending resources on \u201cmobile\u201d versions of their content (e.g., mobile sites) that tend to remove content from their site, which in turn leads to lost revenue.","In some embodiments, the actionable content that is rendered on a display of a viewing device is configured to respond to received hover interactions by modifying the rendered content and\/or rendering additional content in response to the detected hover interactions. In this scenario, hover-based interaction with the rendered content may be enabled by a process that includes rendering content on a display, detecting an object in front of, but not in contact with, a front surface of the display, and in response to detecting the object, identifying a pointer event associated with a portion of the content underneath the object. A display-related function associated with the identified pointer event may be determined and performed to modify the rendered portion of the content and\/or render additional content on the display. In some embodiments, the hover interaction from the object may be provided within the magnified window such that the portion of the content in the magnified window is modified and\/or additional content is rendered within the magnified window as it would be outside of the magnified window.","This Summary is provided to introduce a selection of concepts in a simplified form that is further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.","Embodiments of the present disclosure are directed to, among other things, techniques and systems for enabling \u201chover-based\u201d interaction with content that is rendered on a display of a viewing device. Although examples are provided herein predominantly with reference to a mobile computing device (e.g., a smart phone), it is to be appreciated that the techniques and systems are not limited to mobile devices. For instance, viewing devices that may benefit from the techniques disclosed herein may include, without limitation, mobile devices (e.g., smart phones, tablet computers, portable media players, wearable computers, etc.), as well as television (TV) displays, displays implemented within moving vehicles (e.g., navigation displays in automobiles, aircraft, etc.), and the like. In this sense, displays described herein over which hover interactions may be detected may be mobile (e.g., integrated into a mobile computing device, vehicle, etc.) or situated (e.g., wall mounted displays).","The characteristics of the hover-based input that may be provided to the variety of devices contemplated herein may vary with the size of the device, the context of the device's use, and\/or the hardware (e.g., sensors) enabling such hover-based input. For example, a TV display in a living room may have a large screen size, may be stationary, and may utilize an image capture device (e.g., a depth camera) to detect hover interactions. By contrast, a small, mobile device, such as a smart phone, may utilize a sensor or sensor array embedded in the display itself (e.g., a capacitive-based touch screen sensor with proximity sensing capabilities). It is to be appreciated that, no matter the device type, sensors, or context of use, \u201chover,\u201d as used herein, may reference a physical state of an object that is positioned within a predetermined 3D space in front of the display without actually contacting the front surface of the display. The dimensions of the predetermined 3D space may be defined by a two-dimensional (2D) area on the display and a distance in a direction perpendicular to the front surface of the display. In this sense, objects that are positioned outside of the 2D area on the display, contacting the display, or beyond a threshold distance in a direction perpendicular to the front surface of the display may be considered to not be in a hover state.","The techniques and systems described herein may be implemented in a number of ways. Example implementations are provided below with reference to the following figures.","Example Computing System",{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 1","FIG. 1"],"b":["100","100","102","100"]},"The computing device  may be implemented as any number of computing devices (nonlimiting examples of which are shown in ) including a mobile phone (smart phone), a tablet computer, an electronic book (e-book) reader, a laptop computer, a netbook computer, a television, a set-top box couple to a display, a game console coupled to a display, a navigation device (e.g., global positioning system (GPS) device), an vehicle-mounted display, a wearable computer (e.g., a smart watch), a medical imaging device, digital camera and\/or video recorder, and so on.","The computing device  may be equipped with one or more processors  and system memory . Depending on the exact configuration and type of computing device, the system memory  may be volatile (e.g., random access memory (RAM)), non-volatile (e.g., read only memory (ROM), flash memory, etc.), or some combination of the two. The system memory  may include, without limitation, an operating system , a browser module , program data , and a local content store  accessible to the processor(s) .","The operating system  may include a component-based framework  that supports components (including properties and events), objects, inheritance, polymorphism, reflection, and provides an object-oriented component-based application programming interface (API), such as that of the Win32\u2122 programming model and the .NET\u2122 Framework commercially available from Microsoft\u00ae Corporation of Redmond, Wash. The API provided by the component-based framework  may comprise a set of routines, protocols, and\/or tools associated with the operating system  and\/or an application program of the operating system  that provides an interface with the operating system  and\/or associated application programs.","The operating system  may further include a hover interface module  configured to enable hover-based interaction with a display of the computing device  and the content rendered thereon. In general, the operating system  may be configured with one or more stacks to drive a standard class of human interface devices (HIDs) (e.g., keyboards, mice, etc.) as well as enabling touch-screen input (i.e., contact-based input with an associated display). The hover interface module  additionally enables the computing device  to determine and interpret hover-based input received from objects (e.g., a user's finger or hand, a stylus, a pen, a wand, etc.) that hover in front of an associated display, and to perform display-related functions pertaining to the hover-based input. In order to determine and interpret hover-based input from an object, the hover interface module  may rely on one or more additional hardware and\/or software components of the computing device , such as the browser module  and one or more hardware sensors of the computing device  that are configured to detect a hovering object (i.e., an object in front of, but not contacting, the display of the computing device ).","The browser module  may be configured to receive content, and to render the received content via a browser (e.g., a web browser) on a display of the computing device . Execution of the browser module  may, for example, provide access to a website by rendering web pages served by the website on an associated display. The browser module  may be further configured to interact with the hover interface module  via the API of the operating system  for enabling hover-based interaction with content rendered via the browser. The content to be rendered may comprise documents, applications, web content, and the like, which may be received\/accessed from the local content store  when the content is stored locally on the computing device , or from remote sources, such as from the other computing devices  shown in  (e.g., content provider servers).","In some embodiments, the content received by the browser module  may comprise web page content based on hyper text markup language (HTML) code that configures the content to be \u201cactionable\u201d in that the content is responsive to user input. Any suitable scripting language (e.g., JavaScript, Jscript, European Computer Manufacturers Association script (ECMAScript), etc.) or program (e.g., Java applet) may be utilized for enabling actionable content, including content that may be linked to hover functionality. In this sense, the content received by the browser module  may be coded with event-driven programming languages to register event handlers\/listeners on element nodes inside a document object model (DOM) tree for any type of content. One suitable event model that may be utilized for making content actionable is the World Wide Web Consortium (W3C) model for pointer events, including hover events.","In an illustrative example, the content received by the browser module  may comprise web page content that includes selectable (i.e., actionable) text that responds to selection input by modifying the selected text with highlighting, text selection grippers, or other suitable display-based modification. As another example, the content on a web page may include links (e.g., hyperlinks) to other web pages or sites, video or audio playback buttons for embedded video\/audio content, and so on. Accordingly, upon selection of such actionable content, the content may respond by navigating to another webpage or playing back video\/audio files, respectively. When hover events are associated with portions of the content, those portions may be actionable by changing in appearance (i.e., display modification) or by rendering additional content (e.g., a drop down menu, pop-up bubble with information about the content) in response to a cursor being positioned over the content, and these display modifications and\/or additional content may disappear from the display when the cursor is moved away from the hover-enabled content.","The computing device  may also include additional data storage devices (removable and\/or non-removable) such as, for example, magnetic disks, optical disks, or tape. Such additional storage is illustrated in  by removable storage  and non-removable storage . Computer-readable media, as used herein, may include, at least, two types of computer-readable media, namely computer storage media and communication media. Computer storage media may include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, or other data. The system memory , removable storage  and non-removable storage  are all examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, electrically erasable programmable read-only memory (EEPROM), flash memory or other memory technology, compact disk read-only memory (CD-ROM), digital versatile disks (DVD), or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other non-transmission medium that can be used to store the desired information and which can be accessed by the computing device . Any such computer storage media may be part of the device .","In some embodiments, any or all of the system memory , removable storage  and non-removable storage  may store programming instructions, data structures, program modules and other data, which, when executed by the processor(s) , implement some or all of the processes described herein.","In contrast, communication media may embody computer-readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave, or other transmission mechanism. As defined herein, computer storage media does not include communication media.","The computing device  may also include one or more input devices  such as a keyboard, pointing devices (e.g., mouse, touch pad, joystick, etc.), a pen, stylus, or wand, a touch screen (e.g., capacitive, resistive, infrared, surface acoustic wave (SAW), optical), a camera (e.g., 3D sensor), a proximity sensor, a microphone, etc., through which a user may enter commands and information into the computing device . Although the input device(s)  are shown in  to be within the computing device , it is to be appreciated that the input device(s)  may be physically embedded within the computing device  (e.g., a touch screen), or the input device(s)  may be peripheral devices that are removably coupled to the computing device  through either a wired or wireless connection (e.g., a peripheral camera-based input device). Accordingly, the input device(s)  may be coupled to the processor(s)  through a wired connection (e.g., a universal serial bus (USB) interface), or a wireless user input interface such as WiFi or Bluetooth\u00ae.","In some embodiments, the input device(s)  may include one or more proximity-based sensors  configured to detect an object hovering in front of a display of the computing device . The proximity-based sensor(s)  enable the computing device  to differentiate between contact-based touch events and non-contact (i.e., hover) interactions, rather than merely detecting objects near the display and resolving the detected object as a contact0based touch event. In this sense, the computing device  may be considered to be \u201chover-capable\u201d because it may detect hover interactions and touch\/contact interactions in a mutually exclusive manner.","The proximity sensor(s)  may include any suitable proximity sensing technology. One illustrative example of a suitable proximity sensing technology is a capacitive sensor or sensor array configured to detect an object hovering in front of the display of the computing device . Such a capacitive sensor or sensor array may include a two-dimensional (2D) grid of electrodes substantially spanning an area of the display screen of the computing device  with voltage applied to the electrodes so that the electrodes are configured to measure capacitance changes at each electrode. Capacitance changes at the electrodes may be influenced by an object (such as a human finger) in proximity to the electrodes such that a location on the front surface of the display that the object is closest to can be pinpointed based on electrodes that measure corresponding capacitance changes. In order to sense a hovering object, a capacitive sensor or sensor array may be based at least in part on self capacitance, which is known to provide stronger signal sensing as compared to mutual capacitance sensors so that an object may be detected in front of the front surface of the display without the object contacting the display. A proximity sensor  based on a combination of self capacitance and mutual capacitance may enjoy the benefits of both types of capacitive sensors, namely proximity sensing and multi-touch (i.e., detecting multiple touch locations at the same time), respectively. In some instances, the proximity sensor(s)  may be configured to detect an object in front of the display that is at a distance within the range of about 0.001 inches to about 8 inches from the front surface of the display in a direction perpendicular to the front surface.","One example of a relatively \u201clong range\u201d input device  configured to detect an object positioned in front of the display of the computing device  is a depth camera (e.g., the Kinect\u00ae sensor used with the Xbox\u00ae console system from Microsoft\u00ae Corporation of Redmond, Wash.). A depth camera may be configured to capture image data and depth information using any suitable technique such as time-of-flight (ToF), structured light imaging, stereo imaging, and the like. In some instances, the proximity sensor(s)  with longer range sensing capabilities may be configured to detect an object in front of the display that is at a distance within the range of about 20 inches to about 170 inches from the front surface of the display.","It is to be appreciated that the input device(s)  are not limited to the examples described above, and any suitable proximity sensor(s)  may be used to detect an object hovering in front of a display of the computing device , including, but not limited to, inductive, magnetic, ultrasonic, or other suitable proximity sensors .","The computing device  may also include output device(s) , such as a display  (e.g., a liquid crystal display (LCD), plasma, rear projection, etc.), one or more speakers, a printer, or any other suitable output device coupled communicatively to the processor(s) . The output device(s)  may generally be configured to provide output to a user of the computing device . In some embodiments, the output device(s)  may be integrated into the computing device  (e.g., an embedded display ), or provided externally as a peripheral output device  (e.g., a peripheral display ).",{"@attributes":{"id":"p-0054","num":"0053"},"figref":["FIG. 1","FIG. 1","FIG. 1"],"b":["134","132","102","132","134","134","136","134","138","132","138"]},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 1","b":["140","132","132","140","132","128","118","132","140","110","108","108","138","136","110","138","138","118","138"]},"When a hover event is detected, the hover interface module  may cause performance of a display-related function that is reflected on the display  of the computing device . Display-related functions that may be performed in response to detection of a hover event include, without limitation, displaying a magnified window  of a portion of the content  (e.g., a portion of the content  underneath the object), modifying the display of the portion of the content , and\/or rendering additional content in association with the portion of the content . The portion of the content  rendered within the magnified window  of  may represent a portion of the content  that is rendered at a location within the area  or within a threshold distance from such a location (e.g., just above the location of the object). It is to be appreciated that the hover interaction capability of the computing device  may be turned \u201con\u201d or \u201coff\u201d via user settings or a similar user configuration of the device  in instances where hover interaction is not desired.","The computing device  may operate in a networked environment and, as such, the computing device  may further include communication connections  that allow the device to communicate with the other computing devices , such remotely located content providers. The communication connections  are usable to transmit and\/or receive data, such as content that may be stored in the local content store .",{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 2","FIG. 2"],"b":["200","102","202","132","102","202","204","202","202","206","1","206","2","206","206","102","102","206","208","206","102","208","102","208"]},{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIG. 3A","FIG. 1","FIG. 3A","FIG. 1","FIG. 3B","FIG. 3A"],"b":["102","132","138","138","102","138","102"]},{"@attributes":{"id":"p-0060","num":"0059"},"figref":["FIGS. 3A and 3B","FIG. 3A","FIGS. 3A and 3B","FIG. 3B","FIG. 3B","FIG. 3A","FIG. 3B"],"b":["102","102","102","102","300","132","102","300","132","300","132","132","300","132"]},{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 3C","FIGS. 3A and 3B","FIG. 3D","FIG. 3C","FIG. 3D","FIGS. 3C and 3D"],"b":["102","302","132","102","102","302","302","300","132","300","302","300","302","300","102","128","132","128","302","300","102","102","128","300","132","128","102","302","300","128","302","302"]},{"@attributes":{"id":"p-0062","num":"0061"},"figref":["FIG. 3C","FIG. 3D"],"b":["304","300","132","302","132","304","118","302","128","304","118","132","108","128","304","304","300","132","302","300","302","304","300","132"]},{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 3C","FIG. 3C"],"b":["118","306","138","304","306","138","102","304","306","118","138","304","302","306","304","302","306","302","304"]},{"@attributes":{"id":"p-0064","num":"0063"},"figref":["FIG. 3E","FIGS. 3A-3D","FIG. 1","FIG. 3E","FIGS. 3C and 3D","FIG. 3C","FIG. 4","FIG. 3C"],"b":["102","142","132","302","302","142","306","138","142","142","142","306","138","142","132","142","142","110","142","142","142"]},"In some embodiments, the magnified window  is of a width, w, that may be less than an overall width of the display . In one example, the width, w, is no greater than about 75% of the width of the display . In another example, the width, w, is no greater than about 50% of the width of the display . In yet another example, the width, w, is no greater than about 25% of the width of the display . A restriction on the width, w, to being a fraction of the width of the display  may allow for optimal magnification of the portion  of the content  that is rendered within the magnified window , and it may facilitate selectively browsing the content in a left-to-right manner, or vice versa.","In some embodiments, the region in which the magnified window  is displayed may include a bottom boundary that is located a predetermined distance, b, from the location  on the front surface  corresponding to the object . For example, the predetermined distance, b, may be within the range of about 0.2 inches to about 0.5 inches. In another example, the predetermined distance, b, may be no greater than about 1 inch. Rendering the magnified window  at a predetermined distance, b, above the location  may prevent the object  from obstructing the user's view of the content within the magnified window  or a portion thereof.","In some embodiments, the hover interface module  may identify an input gesture from the object  before causing the display of the magnified window . In this sense, the magnified window  may be displayed in response to receipt of the input gesture, which may take any suitable form. One example input gesture that may trigger the display of the magnification window  is in the form of the object  remaining in a first position shown in  for a predetermine period of time. \u201cRemaining in the first position\u201d may comprise hovering in front of the front surface  within a predetermined area  for the predetermined period of time. The predetermined area  may be circumscribed around the location  so that if the object  wavers slightly, it may be considered to have \u201cremained in the first position.\u201d The predetermined period of time that the object  is to remain in the first position may be within a range of about 50 milliseconds to about 100 milliseconds. In other embodiments, the predetermined period of time may be no greater than about 2000 milliseconds. In this scenario, a user may provide an input gesture by holding a finger in a hover position within the predetermined area  for a predetermined period of time, and in response, the hover interface module  may cause display of the magnified window  to provide enhanced browsing of the content .","Although the magnified window  shown in  is of a rectangular shape, it is to be appreciated that the magnified window  may comprise any suitable shape, such as circular, triangular, square, hexagonal, or any type of polygonal shape suitable for containing a magnified view of a portion  of the content .",{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIG. 4","FIGS. 3A-3E","FIG. 4"],"b":["102","302","142","142","302","300","132","142","300","132","142","132","300","132","142","110","142","142","306","142"]},"In some embodiments, the user input provided within the magnified window , as illustrated in , may comprise a hover interaction from the object . For example, the object  may hover over the content rendered within the magnified window  at a distance from the front surface  of the display , and the actionable content, if coded to respond to hover events, may respond to the hover-based user input by performing a display-related function, such as changing the appearance of the content (e.g., underlining the text \u201cStore Clerk Thwarts Robbery\u201d), displaying additional content (e.g., a pop-up with information about the content, a drop down menu, etc.), and so on.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 5A","FIGS. 3-4","FIG. 5B","FIGS. 5A and 5B","FIG. 5A"],"b":["102","302","300","132","300","102","302","302","300","302","142","132","302","132","132","118","302","300","302","300","142","132","302","300","142","302","132","302","142","302","138","300","132","302","302","300","138","302","102"]},{"@attributes":{"id":"p-0072","num":"0071"},"figref":["FIG. 6","FIGS. 3-5","FIG. 4","FIG. 6"],"b":["102","302","142","142","302","300","132","142","302","300","132","142","142","132","302","300","132","132","142","138","132","142","302","300","132","142","110"]},"In some embodiments, the user input provided within the magnified window  may comprise a hover interaction from the object . For example, the object  may hover over the content rendered within the magnified window  at a distance from the front surface  of the display , and the actionable content, if coded to respond to hover events, may respond to the hover-based user input by performing a display-related function, such as changing the appearance of the content (e.g., highlighting the circle of the video playback button), displaying additional content, and so on.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":["FIG. 7A","FIG. 7B","FIGS. 7A and 7B"],"b":["102","302","1","300","132","142","102","302","2","300","132","142","142","302","300","142","142","118","112","300","132","302","1","300","142","142","302","300","2","142","300","128","302","300","132"]},{"@attributes":{"id":"p-0075","num":"0074"},"figref":["FIG. 8A","FIG. 8B","FIGS. 8A and 8B"],"b":["102","302","800","800","142","132","102","302","302","300","132","302","300","302","300","142","132","302","800","132","110","800","132","138","136","134","800","142","302","136","800","142","302","138","132","138","132","800","302","132","142"]},"In some embodiments, other criteria may be utilized to selectively render the magnified window  on the display . One example criterion may be that the object  moves across the front surface  of the display  above a predetermined speed (i.e., the object moves too fast). This criterion was alluded to while describing the movement of the object  below a predetermined speed with reference to . That is, when the object  moves in a hovering state across the front surface  of the display  below a predetermined speed, the magnified window  may move together with the object  to a new region of the display, but when the object exceeds the predetermined speed, the magnified window  may disappear from the display . Another example criterion for disappearing the magnified window  may be that the object  contacts the front surface  o the display  outside of the region where the magnified window  is displayed. Yet another example criterion for disappearing the magnified window  may be that the object  has moved away from the front surface  in the z-direction beyond a threshold distance from the front surface  in the z-direction. In any case, there may be instances where the magnified window  is displayed and when it is not, and the above described criteria may be utilized to determine those instances in which to disappear the object  from the display.",{"@attributes":{"id":"p-0077","num":"0076"},"figref":["FIG. 9","FIG. 9"],"b":["102","302","800","132","118","304","302","300","304","800","800","800","304","118","142","302","142","142","132","302","304","142","800","132","142","800","142","138","138","302","304","138","138"]},{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 10A","b":["102","302","304","132","302","142","304","302","300","132","304","142","118","118","304"]},{"@attributes":{"id":"p-0079","num":"0078"},"figref":["FIG. 10C","FIGS. 10A and 10B"],"b":["102","304","300","132","132","304","302","142","138"]},{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 11","b":["102","302","132","302","138","102","302","302","300","132"]},{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 11","b":["302","118","302","1100"]},{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIG. 11","FIG. 11"],"b":["118","110","102","302","132","302","102","302"]},"For further illustration, Table 1 shows an example of the primary \u201ccontact\u201d logic that may be utilized by the hover interface module  to determine how to respond to an object  interacting with the display  via a combination of hover-based input and touch-based input when the magnified window  is not currently displayed.",{"@attributes":{"id":"p-0084","num":"0083"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"77pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Initial State","Change","Reaction"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["No contacts on web","New Contact1 comes in","Contact1 becomes"]},{"entry":["browser desktop site","range","primary"]},{"entry":["Contact1 is primary","New Contact2 comes in","No reaction"]},{"entry":[{},"range"]},{"entry":[{},"Contact1 is still hovering","Contact2 becomes"]},{"entry":[{},"and Contact2 touches","primary"]},{"entry":[{},"Contact2 is out of range","Contact1 does not"]},{"entry":[{},"and Contact3 enters","become primary but"]},{"entry":[{},{},"Contact3 is primary"]},{"entry":[{},{},"Once the primary goes"]},{"entry":[{},{},"away, there is no"]},{"entry":[{},{},"primary until a new"]},{"entry":[{},{},"contact comes in range"]},{"entry":[{},{},"Existing contacts Never"]},{"entry":[{},{},"become primary"]},{"entry":[{},{},"Once the state returns"]},{"entry":[{},{},"to \u201cNo Contacts\u201d, the"]},{"entry":[{},{},"table becomes"]},{"entry":[{},{},"applicable again"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"Additionally, the following are example event ordering scenarios that may be followed by the hover interface module  in response to various interaction between the object  and the display :","Touch Down:","Touching down on an element rendered on the front surface  of the display  may produce the following sequence of events on the hit tested node of the WM_PointerDown message: mousemove, pointerover, mouseover, mouseenter, pointerdown, mousedown.","Lifting Up:","Lifting up from an element rendered on the front surface  of the display  may produce the following sequence of events on the hit tested node of the WM_PointerUp message: pointerup, mouseup, pointerout, mouseout, mouseleave.","Moving the Contact (Object  Remains In-Contact):","Moving the contact on the screen while in-contact (after touching down) may produce the following sequence:\n\n","Here, the [ ] brackets indicate events that fire when the new hit-test result is not equal the previous hit-test result. These events are fired at the previous hit-test result. The { } braces indicate events that fire when the update transitions in\/out of the bounds of an element.","Moving the Contact\u2014HOVER:","Produce coordinate updates without being in contact with the screen (near field input devices\/objects). The sequence of events is as follows:\n\n","Moving the Contact Causing Manipulation to Begin:","When direct manipulation takes over the primary contact for the purposes of manipulation (signaled by a WM_POINTERCAPTURECHANGE message), then the following events may be dispatched: pointerout, mouseout, mouseleave, pointercancel, mouseup. Here, the \u201cmouseup\u201d event targets the HTML element (window).","Example Processes",{"@attributes":{"id":"p-0097","num":"0102"},"figref":"FIGS. 12, 13, and 14"},{"@attributes":{"id":"p-0098","num":"0103"},"figref":["FIG. 12","FIG. 1"],"b":["1200","302","142","1200","100","110","118","128","132"]},"At , the browser module  may render content  on the display  of the computing device . As described above, at least some of the content  may be actionable by responding to user input. For instance, the content  rendered on the display  at  may comprise web page content that includes, without limitation, some or all of interactive text (e.g., selectable text), links (e.g., hyperlinks), soft buttons (e.g., video\/audio playback buttons), and the like, that, in response to user input, may cause performance of a navigation function (e.g., navigating the browser to a different web page upon selection of a link), a display-related function (e.g., modifying the display of the content , displaying additional content, etc.), and so on.","At , the proximity sensor(s)  may detect an object  hovering in front of the display . That is, the object  may be in front of, but not in contact with, a front surface  of the display  at a distance from the front surface  such that the proximity sensor(s)  may detect the object . In one illustrative example, the proximity sensor(s)  comprise a capacitive sensor array embedded within or behind the display , and the signal strength of the capacitive sensor array may be sufficient to detect objects  in proximity (e.g., within the range of about 0.001 inches to about 8 inches) to the front surface .","At , the hover interface module  may determine a location  on the front surface  of the display  corresponding to the object's position relative to the front surface  of the display . In some embodiments, the hover interface module  may receive the location  from data obtained from the proximity sensor(s)  (e.g., a position of a particular electrode of the proximity sensor(s) ). In other embodiments, the hover interface module  may access the program data  to obtain a pixel location(s) corresponding to a position of the object  detected by the proximity sensor(s) . In any case, the location  may be spaced a shortest distance from the object  relative to distances from the object  to other locations on the front surface  of the display . In this manner, the object's position may be resolved to the location  based on a direction from the object  to the front surface  of the display  that is perpendicular to the front surface .","In some embodiments, the hover interface module  may determine whether the location  is within a control area  of a browser so as to selectively respond to hovering objects  within the control area , but not respond to objects  outside of the control area . For example, an object  hovering over a navigation bar of a web browser rendered on the display  may be determined to be positioned outside of the control area . In some embodiments, the hover interface module  may further determine whether an input gesture is received from the object  when in a hover state. For example, if the object  remains within an area  surrounding the location  for a predetermined period of time (e.g., 50 milliseconds), it may be determined that an input gesture has been provided by the object .","At , the hover interface module  may determine a portion  of the content  that is rendered at the location  or within a threshold distance, h, from the location . The portion  is to be displayed within a magnified window  for facilitating readability of the portion  for a user of the computing device . As such, the portion  is to correspond to the location  in that it is a portion of the content  that is in relatively close proximity to the location . In this sense, the portion  of the content  determined\/selected at  may be directly underneath the object  (i.e., at the location ), or at least within a threshold distance, h, of from the location  (e.g., directly above the object , as shown in ).","At , the hover interface module  may display a magnified window  in a region of the display that contains the portion  of the content. The portion  rendered within the magnified window  may be rendered in actionable form (i.e., the portion  within the magnified window  may be actionable by responding to user input when the user input is provided within the magnified window ). The process  facilitates convenient browsing of the content  rendered on the display , especially in circumstances where the content  is rich and dense, making readability and selectability an issue on some displays .","For further illustration, Table 2 shows the hover interaction logic that may be utilized by the hover interface module  to determine how to respond to an object  interacting with the display  via a combination of hover-based input and touch-based input.",{"@attributes":{"id":"p-0106","num":"0111"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"84pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Initial State","Change","Reaction"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["No contacts on web","New Contact1","Contact1 gets magnified"]},{"entry":["browser desktop site,","comes in range","window (display magnified"]},{"entry":["zoomed at default value",{},"window)"]},{"entry":["Contact1 is hovering with","Contact1 ","If content is actionable,"]},{"entry":["the magnified window and","single ","browser takes the"]},{"entry":["user finds interesting area","taps","action;"]},{"entry":["of the page",{},"If there is no action,"]},{"entry":[{},{},"magnified window is"]},{"entry":[{},{},"removed\/hidden and all"]},{"entry":[{},{},"normal browser"]},{"entry":[{},{},"functionalities resume"]},{"entry":[{},{},"as if the device is not"]},{"entry":[{},{},"hover-capable"]},{"entry":["Contact1 is hovering with","Contact1","Page is zoomed at that area"]},{"entry":["the magnified window and","double","as if it was pinched and"]},{"entry":["user finds interesting area","taps","zoomed on a touch screen"]},{"entry":["of the page",{},"device"]},{"entry":["Contact1 is hovering with","New Contact2","No reaction"]},{"entry":["the magnified window","comes in range"]},{"entry":[{},"Contact1 is","No reaction"]},{"entry":[{},"still hovering"]},{"entry":[{},"and Contact2"]},{"entry":[{},"touches"]},{"entry":[{},"Contact2 is","No reaction"]},{"entry":[{},"out of range"]},{"entry":[{},"and Contact3"]},{"entry":[{},"enters"]},{"entry":["Contact1 is hovering with","Contact1 ","Hide the Magnified"]},{"entry":["the Magnified Window","leaves","Window"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},{"@attributes":{"id":"p-0107","num":"0112"},"figref":["FIG. 13","FIG. 1","FIG. 12"],"b":["1300","302","142","132","302","1300","100","118","128","132","1300","1210","1200"]},"At , the hover interface module  may determine that the object  has moved below a predetermined speed across the front surface  of the display  while maintaining a spaced relationship with the front surface  of the display . The predetermined speed may be set such that an object  moving too fast (e.g., at or above the predetermined speed) across the front surface  in a hovering manner may cause a previously displayed magnified window  to disappear from the display . In order to determine that the object  is moving across the front surface  of the display , the hover interface module  may leverage\/access data from the proximity sensor(s)  that indicate detected locations corresponding to the object , and may further reference a clock or similar timer to determine a speed of the object's movement across the front surface .","At , the hover interface module  may display the magnified window  (previously rendered in a first region of the display ) in another region of the display  in response to the detected object movement at . This may be performed at time intervals that make it look to the naked eye of a user like the magnified window  is moving with the movement of the object . Each new location of the object  may cause movement of the magnified window  to a new region of the display  at . The process  may allow a user to drag\/move an object  in a spaced relationship over the front surface  of the display  to browse different portions of the rendered content .",{"@attributes":{"id":"p-0110","num":"0115"},"figref":["FIG. 14","FIG. 1"],"b":["1400","142","302","300","132","1400","100","118","128","132"]},"At , the proximity sensor(s)  may detect an object  hovering in front of the display  that is rendering content . That is, the object  may be in front of, but not in contact with, a front surface  of the display  at a distance from the front surface  such that the proximity sensor(s)  may detect the object .","At , the hover interface module  may display a magnified window  in a region of the display that contains a portion  of the content  in actionable form that corresponds to the position of the object  detected at .","At , the hover interface module  may determine (based on data received from the proximity sensor(s) ) that the object  has moved farther away from the front surface  of the display  in a direction perpendicular to the front surface  (i.e., the z-direction shown in ).","At , the hover interface module  may decrease a magnification level of the portion  of the content  within the magnified window  such that the magnified window  zooms out to reveal more of the content  within the magnified window  when the object  moves farther away from the front surface .","At  the hover interface module  may determine (based on data received from the proximity sensor(s) ) that the object  has moved closer to the front surface  of the display  in a direction perpendicular to the front surface  (i.e., the z-direction shown in ).","At , the hover interface module  may increase the magnification level of the portion  of the content  within the magnified window  such that the magnified window  zooms in to reveal less of the content  within the magnified window  when the object  moves closer to the front surface .","The environment and individual elements described herein may of course include many other logical, programmatic, and physical components, of which those shown in the accompanying figures are merely examples that are related to the discussion herein.","Other architectures may be used to implement the described functionality, and are intended to be within the scope of this disclosure. Furthermore, although specific distributions of responsibilities are defined above for purposes of discussion, the various functions and responsibilities might be distributed and divided in different ways, depending on circumstances.","A method comprising: rendering content (e.g., web content, document content, application content, etc.) on a display; detecting an object (e.g., finger, hand, pen, stylus, wand, etc.) in front of, but not in contact with, a front surface of the display; determining, at least partly in response to the detecting the object, a location on the front surface of the display that is spaced a shortest distance from the object relative to distances from the object to other locations on the front surface of the display; determining a portion of the content that is rendered at the location or within a threshold distance from the location; and displaying, in a region of the display, a magnified window of the portion of the content.","The method of Example One, wherein the portion of the content includes one or more interactive elements comprising at least one of an embedded link, a video playback button, or an audio playback button, and wherein individual ones of the one or more interactive elements are configured to respond to user input (e.g., touch-based input, hover-based input, etc.) when the user input is provided within the magnified window.","The method of any of the previous examples, alone or in combination, wherein the user input comprises the object contacting the front surface of the display on the individual ones of the one or more interactive elements within the magnified window.","The method of any of the previous examples, alone or in combination, wherein the magnified window comprises a browser window rendering the portion of the content.","The method of any of the previous examples, alone or in combination, wherein the detecting the object in front of, but not in contact with, the front surface of the display comprises determining an input gesture (e.g., the object hovering around a location for a predetermined period of time, a symbol\/sign created by the object, a swiping or movement-based gesture, etc.) from the object.","The method of any of the previous examples, alone or in combination, wherein the input gesture is determined by: detecting that the object is at a first position that is within a threshold distance from the front surface measured in a direction perpendicular to the front surface; and determining that the object is within a predetermined area of the first position for a predetermined period of time, the predetermined area being parallel to the front surface of the display.","The method of any of the previous examples, alone or in combination, wherein the front surface of the display comprises a top portion, a bottom portion, a left side, and a right side, a positive vertical direction pointing toward the top portion, and wherein the region includes a bottom boundary that is at a predetermined distance from the location in the positive vertical direction.","The method of any of the previous examples, alone or in combination, further comprising: determining that the object has moved farther away from the front surface of the display in a direction perpendicular to the front surface; and in response to the determining that the object has moved farther away from the front surface, decreasing a magnification level of the portion of the content within the magnified window.","The method of any of the previous examples, alone or in combination, wherein the region has a width that is no greater than about 75% of a width of the display.","The method of any of the previous examples, alone or in combination, wherein the location is a first location, the method further comprising: determining that the object has moved below a predetermined speed across the front surface of the display while maintaining a spaced relationship with the front surface of the display; and in response to the determining that the object has moved, moving the magnified window with the object across the front surface of the display to another region of the display, wherein the magnified window after the moving contains another portion of the content that is rendered at, or within a threshold distance from, a new location on the front surface of the display corresponding to a position of the object after having moved across the front surface of the display.","The method of any of the previous examples, alone or in combination, further comprising causing the magnified view to disappear from the display in response to at least one of: (i) determining that the object moves outside of a control area (e.g., a browser control area) of the display, (ii) determining that the object moves across the front surface of the display above a predetermined speed, (iii) determining that the object contacts the front surface of the display outside of the region, or (iv) determining that the object has moved away from the front surface of the display in a direction perpendicular to the front surface of the display beyond a threshold distance from the front surface of the display measured along the direction.","The method of any of the previous examples, alone or in combination, further comprising: determining that the location is within a threshold distance from a boundary of a control area (e.g., a browser control area) of the display; determining that the object has moved across the front surface of the display while maintaining a spaced relationship with the front surface of the display to a new location that is closer to the boundary of the control area relative to a distance from the location to the boundary of the control area; and in response to the determining that the object has moved to the new location, panning the portion of the content within the magnified window to reveal another portion of the content that is rendered closer to the boundary of the control area relative to a distance from the portion of the content to the boundary of the control area.","The method of any of the previous examples, alone or in combination, further comprising: detecting a first contact from the object on the front surface of the display at the location and a second contact from the object on the front surface of the display at the location, the second contact being detected within a threshold period of time from the detecting the first contact; and in response to the detecting the first contact and the second contact, rendering, on the display, a zoomed-in view of the content around the location.","A system comprising: a display configured to display content (e.g., web content, document content, application content, etc.); one or more sensors (e.g., proximity sensor(s)) configured to detect an object (e.g., finger, hand, pen, stylus, wand, etc.) in front of, but not in contact with, a front surface of the display; one or more processors; and memory storing computer-executable instructions that, when executed by the one or more processors, cause the one or more processors to perform acts comprising: determining, at least partly in response to detecting the object in front of, but not in contact with, the front surface of the display, a location on the front surface of the display that is spaced a shortest distance from the object relative to distances from the object to other locations on the front surface of the display; determining a portion of the content that is rendered at the location or within a threshold distance from the location; and causing a presentation, in a region of the display, of a magnified window of the portion of the content.","The system of Example Fourteen: wherein the portion of the content includes one or more interactive elements comprising at least one of an embedded link, a video playback button, or an audio playback button, and wherein individual ones of the one or more interactive elements are configured to respond to user input (e.g., touch-based input, hover-based input, etc.) when the user input is provided within the magnified window.","The system of any of the previous examples, alone or in combination, wherein the user input comprises the object contacting the front surface of the display on the individual ones of the one or more interactive elements within the magnified window.","The system of any of the previous examples, alone or in combination, wherein the magnified window comprises a browser window rendering the portion of the content.","The system of any of the previous examples, alone or in combination, wherein the one or more sensors are further configured to determine a distance between the front surface of the display and the object in a direction perpendicular to the front surface of the display, the acts further comprising: determining that the object has moved farther away from the front surface in the direction; and in response to the determining that the object has moved farther away from the front surface, decreasing a magnification level of the portion of the content within the magnified window.","The system of any of the previous examples, alone or in combination, wherein the location is a first location, the acts further comprising: determining that the object has moved below a predetermined speed across the front surface of the display while maintaining a spaced relationship with the front surface of the display; and in response to the determining that the object has moved, moving the magnified window with the object across the front surface of the display to another region of the display, wherein the magnified window after the moving contains another portion of the content that is rendered at, or within a threshold distance from, a new location on the front surface of the display corresponding to a position of the object after having moved across the front surface of the display.","One or more computer-readable storage media comprising memory storing a plurality of programming instructions that are executable by one or more processors of a computing device to cause the computing device to perform acts comprising: rendering content (e.g., web content, document content, application content, etc.) on a display; detecting an input gesture (e.g., an object hovering around a location for a predetermined period of time, a symbol\/sign created by the object, a swiping or movement-based gesture, etc.) from an object (e.g., finger, hand, pen, stylus, wand, etc.) in front of, but not in contact with, a front surface of the display; determining, at least partly in response to the detecting the input gesture, a location on the front surface of the display that is spaced a shortest distance from the object relative to distances from the object to other locations on the front surface of the display; determining a portion of the content that is rendered at the location or within a threshold distance from the location; and displaying, in a region of the display, a magnified window of the portion of the content.","A system comprising: means for displaying content (e.g., web content, document content, application content, etc.); one or more means for detecting (e.g., a proximity sensor(s)) an object (e.g., finger, hand, pen, stylus, wand, etc.) in front of, but not in contact with, a front surface of the means for displaying; one or more means for executing computer-executable instructions (e.g., processor(s), including, for example, hardware processor(s) such as central processing units (CPUs), system on chip (SoC), etc.); and means for storing computer-executable instructions (e.g., memory, computer readable storage media such as RAM, ROM, EEPROM, flash memory, etc.) that, when executed by the one or more means for executing computer-executable instructions, cause the one or more means for executing computer-executable instructions to perform acts comprising: determining, at least partly in response to detecting the object in front of, but not in contact with, the front surface of the means for displaying, a location on the front surface of the means for displaying that is spaced a shortest distance from the object relative to distances from the object to other locations on the front surface of the means for displaying; determining a portion of the content that is rendered at the location or within a threshold distance from the location; and causing a presentation, in a region of the means for displaying, of a magnified window of the portion of the content.","The system of Example Twenty-One, wherein the one or more means for detecting the object are further configured to determine a distance between the front surface of the means for displaying and the object in a direction perpendicular to the front surface of the means for displaying, the acts further comprising: determining that the object has moved farther away from the front surface in the direction; and in response to the determining that the object has moved farther away from the front surface, decreasing a magnification level of the portion of the content within the magnified window.","In closing, although the various embodiments have been described in language specific to structural features and\/or methodological acts, it is to be understood that the subject matter defined in the appended representations is not necessarily limited to the specific features or acts described. Rather, the specific features and acts are disclosed as example forms of implementing the claimed subject matter."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The detailed description is described with reference to the accompanying figures. In the figures, the left-most digit(s) of a reference number identifies the figure in which the reference number first appears. The same reference numbers in different figures indicates similar or identical items.",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 3B","FIG. 3A"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 3C","FIG. 3A"]},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 3D","FIG. 3B","FIG. 3C"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3E"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 4","FIGS. 3A-3E"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 5A","FIGS. 3-4"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 5B","FIG. 5A"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 7B"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 8B","FIG. 8A"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 10A"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 10B","FIG. 10A"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 10C","FIGS. 10A and 10B"]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 14"}]},"DETDESC":[{},{}]}
