---
title: Network based virtualization performance
abstract: The disclosed embodiments support improvements in network performance in networks such as storage area networks. This is particularly important in networks such as those implementing virtualization. These improvements, therefore, support improved mechanisms for performing processing in network devices such as switches, routers, or hosts. These improvements include various different mechanisms which may be used separately or in combination with one another. These mechanisms include methods and apparatus for processing traffic in an arbitrated loop, performing striping to support fairness and/or loop tenancy, performing configuration of network devices such as switches to enable virtualization to be performed closest to the storage device (e.g., disk), ascertaining a CPU efficiency that quantifies the impact of virtualization on a processor, and configuring or accessing a striped volume to account for metadata stored in each storage partition.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08644174&OS=08644174&RS=08644174
owner: Cisco Technology, Inc.
number: 08644174
owner_city: San Jose
owner_country: US
publication_date: 20091005
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","BACKGROUND","SUMMARY","DESCRIPTION OF EXAMPLE EMBODIMENTS"],"p":["This application is a Divisional Application and claims priority of U.S. patent application Ser. No. 11\/115,518, entitled \u201cMethods and Apparatus for Improving Network Based Virtualization Performance,\u201d by Bhandari et al, filed on Apr. 26, 2005, which is incorporated herein by reference for all purposes.","1. Technical Field","The present disclosure relates generally to network technology. More specifically, the disclosure relates to network management and improving network based virtualization performance in a network implementing virtualization.","2. Description of the Related Art","The concept of virtual memory has traditionally been used to enable physical memory to be virtualized through the translation between physical addresses in physical memory and virtual addresses in virtual memory. Recently, the concept of \u201cvirtualization\u201d has been implemented in storage area networks through various mechanisms. Generally, a storage area network is a high-speed special-purpose network that interconnects different data storage devices and associated data hosts on behalf of a larger network of users. However, although a SAN enables a storage device to be configured for use by various network devices and\/or entities within a network, data storage needs are often dynamic rather than static.","Within a storage area network, it is possible to couple a set of hosts (e.g., servers or workstations) to a pool of storage devices (e.g., disks). In SCSI parlance, the hosts may be viewed as \u201cinitiators\u201d and the storage devices may be viewed as \u201ctargets.\u201d A storage pool may be implemented, for example, through a set of storage arrays or disk arrays. Each disk array further corresponds to a set of disks. Rather than enabling all hosts to access all disks, it is desirable to enable the dynamic and invisible allocation of storage (e.g., disks) to each of the hosts via the disk arrays. In other words, physical memory (e.g., physical disks) may be allocated through the concept of virtual memory (e.g., virtual disks). This allows one to connect heterogeneous initiators to a distributed, heterogeneous set of targets (storage pool) in a manner enabling the dynamic and transparent allocation of storage.","Virtualization interconverts physical storage and virtual storage in a storage area network. The hosts (initiators) see virtual disks as targets. The virtual disks represent available physical storage in a defined but somewhat flexible manner. Virtualization provides hosts with a representation of available physical storage that is not constrained by certain physical arrangements\/allocation of the storage.","Virtualization in the storage subsystem is one of the most common storage virtualization solutions in use today. Through this approach, virtual volumes are created over the storage space of a specific storage subsystem (e.g., disk array). Creating virtual volumes at the storage subsystem level provides host independence, since virtualization of the storage pool is invisible to the hosts. In addition, virtualization at the storage system level enables optimization of memory access and therefore high performance. However, such a virtualization scheme typically will allow a uniform management structure only for a homogenous storage environment and even then only with limited flexibility. Further, since virtualization is performed at the storage subsystem level, the physical-virtual limitations set at the storage subsystem level are imposed on all hosts in the storage area network. Moreover, each storage subsystem (or disk array) is managed independently. Virtualization at the storage level therefore rarely allows a virtual volume to span over multiple storage subsystems (e.g., disk arrays), thus limiting the scalability of the storage-based approach.","Another approach to virtualization in common use is the host-based approach. When virtualization is implemented on each host, it is possible to span multiple storage subsystems (e.g., disk arrays). The host-based approach has an additional advantage, in that a limitation on one host does not impact the operation of other hosts in a storage area network. However, virtualization at the host-level requires the existence of a software layer running on each host (e.g., server) that implements the virtualization function. Running this software therefore impacts the performance of the hosts running this software. Another key difficulty with this method is that it assumes a prior partitioning of the available storage to the various hosts. Since such partitioning is supported at the host-level and the virtualization function of each host is performed independently of the other hosts in the storage area network, it is difficult to coordinate storage access across the hosts. The host-based approach therefore fails to provide an adequate level of security. Due to this security limitation, it is difficult to implement a variety of redundancy schemes such as RAID which require the \u201clocking\u201d of memory during read and write operations. In addition, when mirroring is performed, the host must replicate the data multiple times, increasing its input-output and CPU load, and increasing the traffic over the SAN.","Virtualization in a storage area network appliance placed between the hosts and the storage, referred to as \u201cnetwork-based virtualization,\u201d solves some of the difficulties of the host-based and storage-based approaches. The storage appliance globally manages the mapping and allocation of physical storage to virtual volumes. Typically, the storage appliance manages a central table that provides the current mapping of physical to virtual. Thus, the storage appliance-based approach enables the virtual volumes to be implemented independently from both the hosts and the storage subsystems on the storage area network, thereby providing a higher level of security. Moreover, this approach supports virtualization across multiple storage subsystems.","As set forth above, network-based virtualization (NBV) offloads the virtualization tasks such as mapping and locking from the host (or storage appliances) to the intelligent network. Specifically, virtualization tasks are implemented at a network device such as a switch. One method and system of implementing virtualization in a storage area network by a network device such as a switch are disclosed in application Ser. No. 10\/056,238, entitled \u201cMethods and Apparatus for Implementing Virtualization of Storage within a Storage Area Network,\u201d filed on Jan. 23, 2002, by Gai et al and application Ser. No. 10\/242,374, entitled \u201cMethods and Apparatus for Implementing Exchange Management for Virtualization of Storage within a Storage Area Network,\u201d filed on Sep. 11, 2002, by Chandrasekaran, et al.","While network-based virtualization offloads the virtualization tasks to the intelligent network, this requires further processing to be performed within the network. As a result, network-based virtualization often substantially impacts the performance within the network. The key drawback of many implementations of this architecture is that every input\/output (I\/O) of every host must be sent through the storage area network appliance, causing significant performance degradation and a storage area network bottleneck. This is particularly disadvantageous in systems supporting a redundancy scheme such as RAID, since data must be mirrored across multiple disks. In another storage appliance-based approach, the appliance makes sure that all hosts receive the current version of the table. Thus, in order to enable the hosts to receive the table from the appliance, a software shim from the appliance to the hosts is required, adding to the complexity of the system. Moreover, since the software layer is implemented on the host, many of the disadvantages of the host-based approach are also present.","In view of the above, it would be beneficial if network-based virtualization performance could be improved.","Various embodiments support improvements in network performance in a system implementing network-based virtualization. This is particularly important in networks implementing virtualization within network devices such as switches (or routers). These improvements, therefore, support improved mechanisms for performing processing in network devices such as switches, routers, or hosts. The improvements set forth below may be implemented separately or in combination with one another.","In accordance with a first aspect, methods and apparatus for processing traffic in an arbitrated loop in a Fibre Channel network are set forth. More particularly, the embodiments disclosed support the implementation of loop fairness within an arbitrated loop, as well as the configuration of loop tenancy associated with the arbitrated loop. When fairness is implemented or enabled within the arbitrated loop, a requesting entity on the arbitrated loop may send an arbitration request forcing a transmitting entity that is transmitting frames on the arbitrated loop to relinquish control of the arbitrated loop. Loop tenancy is generally understood to refer to the maximum number of frames that a port can send before it has to relinquish control of the loop if another entity has sent an arbitration request.","In accordance with one embodiment, the implementation of fairness and loop tenancy are mutually exclusive. In other words, the enabling of fairness within an arbitrated loop enables an entity on the arbitrated loop to gain control of the arbitrated loop immediately, while loop tenancy enables a transmitting entity (e.g., port) receiving an arbitration request to send up to a maximum number of frames before it must relinquish control of the arbitrated loop. Thus, when fairness is not set, a port such as a Fabric Loop (FL) port may determine when it should relinquish control in accordance with the loop tenancy configuration.","In accordance with yet another embodiment, methods and apparatus for processing traffic in an arbitrated loop of a network are disclosed. First, it is ascertained whether a switch implementing network-based virtualization is coupled to the arbitrated loop. When a switch implementing network-based virtualization is coupled to the arbitrated loop, fairness is enabled. Specifically, a fairness indicator associated with the arbitrated loop is set, where the fairness indicator indicates that fairness is enabled when the fairness indicator is in a first state and indicates that fairness is disabled when the fairness indicator is in a second state. The fairness indicator is also associated with an interface of the switch that is coupled to the arbitrated loop. When a switch implementing network-based virtualization is not coupled to the arbitrated loop, a loop tenancy associated with the arbitrated loop is configured.","In accordance with one embodiment, the loop tenancy is configured by ascertaining an average I\/O size associated with the arbitrated loop and determining a number of simultaneous operations on the loop. The loop tenancy is then configured such that it is directly proportional to the average I\/O size and inversely proportional to the number of simultaneous operations on the loop.","In accordance with another embodiment, methods and apparatus for processing traffic in an arbitrated loop of a network are set forth to support the implementation of fairness within an arbitrated loop. Specifically, a status of a fairness indicator associated with the arbitrated loop is identified, where the fairness indicator indicates that fairness is enabled when the fairness indicator is in a first state and indicates that fairness is disabled when the fairness indicator is in a second state. A requesting entity on the arbitrated loop is enabled to send an arbitration request when the fairness indicator is in the first state, the arbitration request forcing a transmitting entity that is transmitting frames on the arbitrated loop to relinquish control of the arbitrated loop. However, when the fairness indicator is in the second state, entities on the arbitrated loop are prevented from sending an arbitration request.","In accordance with yet another embodiment, a switch having a plurality of interfaces configured to process traffic in an arbitrated loop of a network includes a processor and a memory, as well as a data structure or register including a fairness indicator associated with each of the plurality of interfaces of the switch. The fairness indicator associated with each interface indicates that fairness is enabled for the corresponding interface when the fairness indicator is in a first state and indicates that fairness is disabled for the corresponding interface when the fairness indicator is in a second state.","In accordance with a second aspect, striping is performed to maximize the throughput in a network such as a network supporting network-based virtualization. Striping is a technique used for spreading data over multiple storage devices (e.g., disk drives). Striping is commonly performed to speed up operations that retrieve data from disk storage. For instance, when data is \u201cstriped\u201d across multiple disk drives, the data is broken into units and spread across the disk drives (or those which are available). Striping generally entails receiving an input or output request from a host, and obtaining or storing the data, respectively, by simultaneously \u201cstriping\u201d across multiple storage devices (e.g., disks), which are often referred to as \u201ccolumns.\u201d The stripe size refers to the size of a stripe of data that is stored in a column. For instance, each disk may be referred to as a \u201ccolumn\u201d and the amount of data that is stored in each \u201ccolumn\u201d before moving to the next is the stripe size or \u201cstripe width.\u201d In a network supporting virtualization, the input\/output request identifying a virtual storage location is therefore converted to a physical storage location for each stripe of data. For instance, the virtual storage location may refer to a \u201cvolume\u201d which may include data stored in a single disk partition or multiple partitions on one or more physical drives.","In a Fibre Channel network in which network-based virtualization is implemented, a host sends a request such as a read or write request that identifies a virtual storage location. The network device (e.g., switch) receiving the request converts the virtual storage location to one or more physical storage locations before the read\/write is striped across the physical storage locations. An operation such as a write or read operation consists of a host-side exchange and a disk-side exchange. Specifically, the host-side exchange is performed between the host and network device (e.g., switch), while the disk-side exchange is performed between the network device and storage devices (e.g., disks). While a sequence is a set of one or more related frames, an exchange is one or more non-concurrent sequences for a single operation. One system supporting exchange management in a SAN implementing virtualization is disclosed in application Ser. No. 10\/056,238, entitled \u201cMethods and Apparatus for Implementing Virtualization of Storage within a Storage Area Network,\u201d filed on Jan. 23, 2002, by Gai et al.","In accordance with one embodiment, methods and apparatus for performing striping include identifying a stripe size, the stripe size being a size of data to be written to or read from one of the plurality of columns. A host IO size is determined, where the host IO size is a size of data to be received from or transmitted to a host, thereby enabling the data to be stored to or read from storage including a plurality of columns. The host IO size is then set to identify an amount of data to be received from or transmitted to the host. Data is obtained from the host or transmitted to the host, where the size of the data obtained or transmitted conforms to the host IO size. Striping is performed across the plurality of columns for the data obtained from the host or transmitted to the host such that data written to or read from one of the plurality of columns conforms to the stripe size.","In accordance with another embodiment, the host IO size is calculated using the stripe size, the remaining amount of data to be transmitted, and the number of columns. Specifically, a minimum of the size of the remaining data associated with the host IO and the product of the stripe size and the number of columns is identified. When the minimum is a size of the remaining data associated with the host IO, the host IO size is the size of the remaining data. Alternatively, when the minimum is a product of the stripe size and the number of columns, the host IO size is the product of the stripe size and the number of columns.","In accordance with another embodiment, methods and apparatus for performing striping across a plurality of columns includes receiving a command from a host, where the command is a request to store or retrieve data and the command indicates a size of the data to be stored or retrieved. It is ascertained whether the size of the data associated with the command is greater than a product of a configured stripe size and number of the plurality of columns. When the size of the data associated with the command is not greater than the product of the configured stripe size and the number of columns, striping is performed according to the configured stripe size. When the size of the data associated with the command is greater than the product of the configured stripe size and the number of columns, a host IO size is determined and set, and data conforming to the host IO size is obtained from the host or transmitted to the host by performing striping across a plurality of columns, where the data written to or read from each of the plurality of columns conforms to the configured stripe size.","In accordance with another embodiment, the host IO that is received identifies a virtual storage location and the plurality of columns are associated with a plurality of physical storage locations. For instance, in a storage area network, virtual storage locations may be referred to as virtual logical units (VLUNs), while physical storage locations may be referred to as physical logical units (PLUNs).","In accordance with a third aspect, virtualization within a network is supported by enabling virtualization functionality to be performed at a network device (e.g., switch) closest to the pertinent target (e.g., disk). This may be accomplished by configuring the appropriate information for various targets on multiple switches, rather than requiring a particular disk to be served by a specific switch. Once the switches are configured with the appropriate information, the switches may send advertisements advertising both a virtual and physical address associated with each disk. From the advertisement, a host may send a read or write command to the switch that it deems to be closest to it.","In accordance with one embodiment, methods and apparatus for supporting virtualization in a network include sending by a network device such as a switch an advertisement including device information for one or more devices, where the device information for each of the devices identifies a physical address and a virtual address, thereby enabling a host receiving the advertisement to obtain the physical address associated with the virtual address for one of the devices. Once the host sends a command identifying the physical address, the network device receives the command(s) and forwards the command(s) to the appropriate physical address(es).","In accordance with another embodiment, a network supporting virtualization includes multiple switches configured with the same device information, thereby enabling each of the switches to service a host that it is closest to. In this manner, each switch has the virtual-physical address information to support any request received from a host. For instance, two or more switches may be configured to store device information for a plurality of devices, where the device information for each of the plurality of devices identifies a physical address and a virtual address. In addition, each of the switches is configured to send an advertisement including the device information for at least one of the plurality of devices, thereby enabling a host receiving the advertisement to obtain the physical address associated with the virtual address for one of the plurality of devices. Configuration may be performed statically, as well as dynamically.","In accordance with a fourth aspect, the \u201cCPU efficiency\u201d of a CPU may be ascertained. This may be accomplished by measuring data associated with the utilization of the CPU during host inputs and\/or outputs such as those performed in a network implementing virtualization. In this manner, the impact of virtualization on a CPU may be determined.","In accordance with one embodiment, the I\/O throughput associated with the CPU is determined by measuring an amount of total data input and\/or output during a particular period of time. The CPU time for the CPU to complete the set of inputs and\/or outputs associated with the data during the period of time is also ascertained. The CPU time is divided by the test period of time to obtain the CPU utilization. The I\/O throughput is then divided by the CPU utilization to obtain the CPU efficiency associated with the CPU.","In accordance with a fifth aspect, striping is performed to account for metadata stored at the beginning of partitions in storage devices such as disks. This may be accomplished by configuring a network device such as a switch to accurately calculate the start address of a partition, the data region within the partition, or the metadata region within the partition. In this manner, the speed with which memory may be accessed is improved.","In accordance with one embodiment, methods and apparatus for configuring a striped volume in which both metadata and data are stored in a storage area network are disclosed to enable the start address of a partition in a storage volume to be ascertained. First, the striped volume in which both metadata and data are stored is identified. In addition, the size of the metadata region stored for each partition in the striped volume and the stripe size for data stored in the storage area network are ascertained. A start address for a partition in the striped volume may then be determined. The start address for the partition in the striped volume is a stripe-aligned address at which data is stored less a sum of the metadata region size for the partition. The start address for the partition may or may not be stripe-aligned.","In accordance with another embodiment, methods and apparatus for configuring a striped volume in which both metadata and data are stored in a storage area network are set forth to enable the application data start address to be ascertained. First, the striped volume in which both metadata and data are stored is identified. The size of the metadata stored for each partition in the striped volume is ascertained. In addition, the stripe size for data stored in the storage area network is also ascertained. An application data start address identifying a start address at which data is stored is then ascertained, where the application data start address is the sum of the start address for the partition in the striped volume and the metadata region size for the partition. The start address at which data is stored is a stripe-aligned address.","These and other features and advantages of the disclosed embodiments will be presented in more detail in the following specification and the accompanying figures, which illustrate by way of example the principles of the disclosed embodiments.","In the following description, numerous specific details are set forth in order to provide a thorough understanding of the disclosed embodiments. It will be obvious, however, to one skilled in the art, that the disclosed embodiments may be practiced without some or all of these specific details. In other instances, well-known process steps have not been described in detail in order not to unnecessarily obscure the disclosed embodiments.","In accordance with various embodiments, network-based virtualization performance is improved. This may be accomplished through a variety of performance improvement schemes, which may be used separately or in combination with one another. In the description below, each of these performance improvement schemes will be described separately.","In accordance with one aspect, loop fairness may be enabled or disabled within an arbitrated loop within a Fibre Channel network. Alternatively, a loop tenancy associated with the arbitrated loop may be configured. When fairness is implemented or enabled within the arbitrated loop, a requesting entity on the arbitrated loop may send an arbitration request forcing a transmitting entity that is transmitting frames on the arbitrated loop to relinquish control of the arbitrated loop. If fairness is not set, then the corresponding Fabric Loop (FL) port coupled to the transmitting entity determines when it should relinquish control of the loop. Loop tenancy is generally understood to refer to the maximum number of frames that a port can send before it has to relinquish control of the loop if another entity has sent an arbitration request. Thus, when loop tenancy is configured, a transmitting entity coupled to the FL port can send up to the maximum number of frames before it must relinquish control of the arbitrated loop to the entity that has sent the arbitration request.","The arbitrated loop is a very common topology in a Fibre Channel network. The arbitrated loop may, for example, be used to communicate with targets in a Storage Area Network (SAN). Specifically, in an arbitrated loop implemented in a Fibre Channel network, up to 127 devices may be attached to a loop, but only two devices can communicate with one another at the same time. To communicate with a device that is several hops down the loop, each device repeats the data to its adjacent node.","Typically, when a device is ready to transmit data in an arbitrated loop, it first must arbitrate and gain control of the Loop. It does this by transmitting the Arbitrate (ARBx) Primitive Signal, where x=the Arbitrated Loop Physical Address of the device. Once a device receives its own ARBx Primitive Signal, it has gained control of the Loop and can now communicate with other devices by transmitting an Open (OPN) Primitive Signal to a destination device. Once this happens, there essentially exists point-to-point communication between the two devices. All other devices in between simply repeat the data.","When fairness is not enabled, there is no limit on how long a device may retain control of the Loop. This demonstrates the \u201cchannel\u201d aspect of Fibre Channel. There is, however, an Access Fairness Algorithm. Generally, when fairness is enabled, the Access Fairness Algorithm prohibits a device from arbitrating again until all other devices have had a chance to arbitrate.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 1","b":["102","104","106","108","110","112","102"]},"In addition, in accordance with one embodiment, the concept of \u201cloop fairness\u201d is implemented. Specifically, a requesting entity on the loop may send an arbitration request forcing another transmitting entity that is transmitting frames on the arbitrated loop to relinquish control of the arbitrated loop at any time when fairness is enabled for that particular port (e.g., FL port) of the switch that is coupled to the arbitrated loop. For instance, a fairness indicator may indicate whether fairness is enabled or disabled. The fairness indicator may be set for one or more ports associated with a particular switch. For instance, the fairness indicator may be set in a first state to indicate that fairness is enabled and set in a second state to indicate that fairness is disabled.","When fairness is not enabled for a particular loop (e.g., the corresponding fairness indicator associated with a port of the switch is not set), loop tenancy is configured for the arbitrated loop. As set forth above, loop tenancy generally refers to the maximum number of frames that a port such as a Fabric Loop (FL) port can send before it has to relinquish control of the loop if another entity has sent an arbitration request.","The configuration of fairness indicator(s) for a particular switch may be accomplished via software and\/or hardware provided in the switch. For instance, a MAC device  of the switch  may be responsible for storing and\/or accessing fairness indicators for the switch . Similarly, the MAC device  may support the configuration of the fairness indicators for the switch .","As set forth above, a fairness indicator may be associated with each interface of a switch. The fairness indicator(s) may be stored in a variety of data structures and formats. Moreover, fairness indicator(s) may be stored in one or more data structures associated with one or more interfaces of a switch.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 2","FIG. 2"],"b":["202","204","206","204"]},"In accordance with one embodiment, software associated with the MAC device can control the fairness on a particular port of the switch. For instance, the MAC device may export an application programming interface (API), which enables a software driver to instruct various interfaces of the switch to implement fairness (or not implement fairness) on the corresponding arbitrated loop. For instance, the software driver may submit a parameter via the API to the MAC device that indicates whether fairness is to be enabled\/disabled for a particular interface or interfaces. In response, the MAC device updates the fairness data structure(s) or register(s), as appropriate.","As set forth above, the fairness indicator (or bit) may be set by an intelligent application. For instance, the application may provide the fairness indicator for one or more ports of a particular switch by sending a set of parameters via an API, as set forth above. The intelligent application may ascertain whether the fairness indicator is to be set (e.g., enabled) for each arbitrated loop in a network.","Fairness within an arbitrated loop may be controlled via a variety of methods.  is a process flow diagram illustrating one method of controlling fairness on interfaces of a switch in accordance with one embodiment. This process may be performed for one or more arbitrated loops in a particular network. In this example, the process is performed for each arbitrated loop in the network (e.g., SAN), as shown at . As set forth above, the fairness setting for each arbitrated loop (and associated switch interface) may be established via a parameter through the API. In or to initialize these fairness parameters (or settings) for the switch interfaces at , it is determined whether the arbitrated loop has a switch owned by network-based virtualization at . In other words, the process determines whether a switch is coupled to the arbitrated loop. If so, then it is determined whether that switch performs virtualization functionality (e.g., virtual-physical address mapping).","If the loop has a switch owned by network-based virtualization, the fairness parameter or indicator is initialized to indicate that loop fairness is enabled for the loop (and corresponding port of the switch) at . If the loop does not have a switch owned by network-based virtualization, a loop fairness parameter is not set for the loop at . However, loop tenancy is configured as shown at blocks -. Specifically, an average I\/O size for the loop is determined at block . For instance, the average I\/O size may be ascertained by sampling the number of frames transmitted via the loop during a period of time and dividing the number of frames by that time period. The number of simultaneous operations on the loop is also determined at block . For instance, the number of connections associated with each entity on the loop may be identified to ascertain the total number of simultaneous operations on the loop. The loop tenancy is then statically or dynamically configured such that it is a) directly proportional to the average I\/O size and b) inversely proportional to the number of simultaneous operations on the loop. The loop tenancy may be periodically updated as shown at block  by performing steps -. For instance, the average I\/O size and number of simultaneous operations on the loop may be sampled every second. Once ascertained, the loop tenancy may be rounded, as appropriate.","The method described above with respect to  enables throughput in a SAN to be maximized for arbitrated loops. For instance, the method enables the loop tenancy to be modified to accommodate a large average I\/O size by increasing the loop tenancy. Similarly, the method accommodates a large number of simultaneous operations on the loop by reducing the loop tenancy.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 4A"},"In contrast,  is a diagram illustrating the throughput of an arbitrated loop over time using a method of controlling fairness in an arbitrated loop in accordance with an embodiment such as that described above with reference to . Since an intelligent application may dynamically turn fairness on or off for a particular interface, throughput may be optimized via an intelligent application.","In accordance with another aspect, the throughput of striped volumes is maximized in a system such as that implementing network-based virtualization. Specifically, random I\/Os to disk significantly degrade the performance of the system, as compared to sequential I\/Os. This is due, in part, to the slow speed with which the spindle moves to access a memory location of a disk. Thus, performance is improved by setting the size of the data transmitted between the host and network device (e.g., switch), which will be referred to as the \u201chost IO size,\u201d to optimize performance. This enables the number of random I\/Os to disk to be reduced. In order to illustrate the distinction between prior art methods of striping and the disclosed embodiments, striping will be described with reference to  and .",{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 5A","b":["502","504","506","508","510","512","514","516","518","520","522"]},"When the disks are ready to receive data in the case of a write command, the switch sends a corresponding XFR_RDY command to the host at  indicating that the entire amount of data (e.g., the entire amount corresponding to the initial command) can now be transferred by the host to the switch (in accordance with a write operation). The host then transfers the entire amount of data to the switch at . The data is then broken up by the switch and striped across the columns at , ,  during one or more parallel operations during which data is striped across the columns, , .","During the striping process in a system implementing network-based virtualization, a host I\/O often results in random I\/Os to the disks. For example, a 64 MB write to a striped volume with stripe size 64 KB and number of columns 8 would result in 128 I\/Os to each column. Depending upon when these I\/Os arrive to a disk, they might result in the disk seeking non-sequential memory locations. Thus, in accordance with various embodiments, network-based virtualization functionality is designed to avoid causing random I\/Os to disks if the host is attempting a sequential I\/O. This is accomplished, in part, by splitting a host I\/O into smaller host I\/Os. Specifically, the host side I\/O size is chosen to optimize performance and avoid any non-sequential memory access to the physical disks.",{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 5B","b":["534","536","538","540","542","544","546","548","550"]},"In accordance with one embodiment, instead of sending a XFR_RDY command to the host indicating that the entire amount of data can be transferred, the switch sends a XFR_RDY command to the host at  indicating that the host IO size is the optimum host I\/O size. This may be accomplished, for example, through an iterative process until all data has been transferred. The data conforming to the host IO size is then transmitted by the host at  (in accordance with a write operation). The data is then striped at , ,  across the disks, as shown. This process may then be repeated until all data has been transferred.",{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 6","b":["602","604","606","608","610","602","610","612","614","616","610"]},"The method described with reference to  results in optimal performance. This may be understood by determining that the average host I\/O size should be approximately the product of the stripe size and the number of columns to obtain optimal performance. (This equation may also be used to calculate the stripe size). In other words, if the average host I\/O size is too small, then all of the disk spindles will not be used in parallel. Similarly, if the average host I\/O size is too big, then this would result in non-sequential I\/Os to the disk.","In accordance with yet another aspect, configuration of network devices (e.g., switches) within a network implementing network-based virtualization is performed to enable the network device (e.g., switch) that is closest to the storage devices (e.g., disks) to perform virtualization functions such as mirroring. This is particularly important, since each host side IO generally results in multiple disk side IOs.",{"@attributes":{"id":"p-0080","num":"0079"},"figref":["FIG. 7","FIG. 7"],"b":["702","704","706","708","708","710","704","704","710","704","710"]},"As set forth above, the configuration of network devices such as switches is performed to enable virtualization functions to be performed by the switch closest to the pertinent node(s). More specifically, the same configuration information is stored among multiple switches, enabling each of the configured switches to process traffic for the same virtual storage devices. Such a network configuration may be performed statically or dynamically. An example data structure for storing configuration information and an example method for optimizing performance will be described in further detail below with reference to  and , respectively.","The configuration information configured for each switch may be stored using a variety of data structures or registers.  is a diagram illustrating an example table configured on a switch in accordance with one embodiment. Each switch stores device information for a plurality of devices (e.g., storage devices), where the device information for each of the devices identifies both a physical address and a virtual address. In this example, each virtual storage device  is identified, as well as the physical address(es)  for the virtual storage device . In a Fibre Channel network, a World Wide Name (WWN) is associated with each device. Thus, the World Wide Name (WWN) may also be identified, as shown at .",{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 9","b":["902","904","906","908","910","912"]},"In order to implement the method described above with reference to , each switch is configured with the device information for various devices (e.g., storage devices), as set forth above. In addition, the switches are configured to send an advertisement including the device information for at least one of the devices, thereby enabling a host receiving the advertisement to obtain the physical address associated with the virtual address for one of the plurality of devices. Thus, a single advertisement may include device information for one or more devices. In addition, the switches may be adapted for receiving a message from a host identifying a physical address and processing the message to access the physical address.","Alternatively, the switch need only advertise that it services particular virtual addresses, thereby enabling a host to send a command to the switch by identifying only the virtual address. The switch may then perform the appropriate virtual-physical address mapping to complete the command requested by the host.","In accordance with another aspect, the \u201cCPU efficiency\u201d of a CPU may be ascertained. This may be accomplished by measuring data associated with the utilization of the CPU during host inputs and\/or outputs such as those performed in a network implementing virtualization. In this manner, the impact of virtualization on a CPU may be determined.",{"@attributes":{"id":"p-0087","num":"0086"},"figref":"FIG. 10","b":["1002","1004","1006","1008","1010"]},"In accordance with another aspect, striping is performed to account for metadata stored at the beginning of partitions in storage devices such as disks. This may be accomplished by configuring a network device such as a switch to accurately calculate the start address of a partition, the data region within the partition, or the metadata region within the partition. In this manner, the speed with which memory may be accessed is improved.",{"@attributes":{"id":"p-0089","num":"0088"},"figref":"FIG. 11","b":["1102","110","1104"]},"Applications are usually written so that they perform I\/Os aligned to a stripe unit. Thus, the start address for application data should be aligned to the stripe unit size. If the start address for application data is not aligned to the stripe unit size, all I\/O operations from the application would result in unaligned physical disk I\/Os. Due to the slow speed with which a disk rotates, this will significantly degrade performance.","In order to improve performance in a system in which metadata is stored, configuration is performed to take into account the metadata region.  is a diagram illustrating a striped volume in which metadata is stored in accordance with one embodiment. In this example, the partition  includes a metadata region  and a data region . In accordance with various embodiments, a striped volume is configured to account for the metadata.","In accordance with one embodiment, a striped volume in which both metadata and data are stored in a storage area network is configured to enable the start address of a partition in a storage volume to be ascertained. First, the striped volume in which both metadata and data are stored is identified. In addition, the size of the metadata region stored for each partition in the striped volume and the stripe size for data stored in the storage area network are ascertained. A start address for a partition in the striped volume may then be determined, where the start address for the partition in the striped volume is a stripe-aligned address at which data is stored less a sum of the metadata region size for the partition.","In accordance with another embodiment, a striped volume in which both metadata and data are stored in a storage area network is configured to enable the application data start address to be ascertained. First, the striped volume in which both metadata and data are stored is identified. The size of the metadata stored for each partition in the striped volume is ascertained. In addition, the stripe size for data stored in the storage area network is also ascertained. An application data start address identifying a start address at which data is stored is then ascertained, where the application data start address is the sum of the start address for the partition in the striped volume and the metadata region size for the partition.","The above-described embodiments may be implemented separately or in combination with one another. While the embodiments set forth above may be applied in a SAN, these examples are merely illustrative, and therefore the embodiments disclosed herein may be applied in other networks, as well. Similarly, while some of the embodiments disclosed are described with reference to a Fibre Channel network, the disclosed embodiments may be implemented in other types of networks.","An apparatus (e.g. switch or router) may be specially constructed for the disclosed purposes, or may be a general purpose programmable machine selectively activated or reconfigured by a computer program stored in memory. The processes presented herein are not inherently related to any particular switch or other apparatus.","Generally, the disclosed techniques may be implemented on software and\/or hardware. For example, it can be implemented in an operating system kernel, in a separate user process, in a library package bound into network applications, on a specially constructed machine, or on a network interface card.","A software or software\/hardware hybrid route optimization system may be implemented on a general-purpose programmable machine selectively activated or reconfigured by a computer program stored in memory. Such programmable machine may be a network device designed to handle network traffic. Such network devices typically have multiple network interfaces including frame relay, ISDN, and wireless interfaces, for example. Specific examples of such network devices include routers and switches. For example, the systems may be specially configured switches such as the MDS series of Fibre Channel switches, including Cisco MDS series 9200 and 9500 available from Cisco Systems, Inc. of San Jose, Calif. A general architecture for some of these machines will appear from the description given below. In an alternative embodiment, the methods and systems may be implemented on a general-purpose network host machine such as a personal computer or workstation. Further, the disclosed embodiments may be at least partially implemented on a card (e.g., an interface card) for a network device or a general-purpose computing device.","Referring now to , a network device  suitable for implementing the disclosed techniques includes a master central processing unit (CPU) , interfaces , and a bus  (e.g., a PCI bus). When acting under the control of appropriate software or firmware, the CPU  may be responsible for implementing specific functions associated with the functions of a desired network device. For example, when configured as an intermediate router, the CPU  may be responsible for analyzing frames, encapsulating frames (or packets), and forwarding frames for transmission to a set-top box. The CPU  preferably accomplishes all these functions under the control of software including an operating system (e.g. Windows NT), and any appropriate applications software.","CPU  may include one or more processors  such as a processor from the Motorola family of microprocessors or the MIPS family of microprocessors. In an alternative embodiment, processor  is specially designed hardware for controlling the operations of network device . In a specific embodiment, a memory  (such as non-volatile RAM and\/or ROM) also forms part of CPU . However, there are many different ways in which memory could be coupled to the system. Memory block  may be used for a variety of purposes such as, for example, caching and\/or storing data, programming instructions, etc.","The interfaces  are typically provided as interface cards (sometimes referred to as \u201cline cards\u201d). Generally, they control the sending and receiving of data frames over the network and sometimes support other peripherals used with the network device . Among the interfaces that may be provided are Fibre Channel ports, Ethernet interfaces, frame relay interfaces, cable interfaces, DSL interfaces, token ring interfaces, and the like. In addition, various very high-speed interfaces may be provided, such as fast Ethernet interfaces, Gigabit Ethernet interfaces, ATM interfaces, HSSI interfaces, POS interfaces, FDDI interfaces, ASI interfaces, DHEI interfaces and the like. Generally, these interfaces may include ports appropriate for communication with the appropriate media. In some cases, they may also include an independent processor and, in some instances, volatile RAM. The independent processors may control such communications intensive tasks as frame switching, media control and management. By providing separate processors for the communications intensive tasks, these interfaces allow the master microprocessor  to efficiently perform routing computations, network diagnostics, security functions, etc.","Although the system shown in  illustrates one example network device, it is by no means the only network device architecture on which the disclosed embodiments can be implemented. For example, an architecture having a single processor that handles communications as well as routing computations, etc. is often used. Further, other types of interfaces and media could also be used with the network device.","Regardless of the network device's configuration, it may employ one or more memories or memory modules (such as, for example, memory block ) configured to store data, program instructions for the general-purpose network operations and\/or other information relating to the functionality of the techniques described herein. The program instructions may control the operation of an operating system and\/or one or more applications, for example.","Because such information and program instructions may be employed to implement the systems\/methods described herein, the disclosed embodiments relate to machine-readable media that include program instructions, state information, etc. for performing various operations described herein. Examples of machine-readable media include, but are not limited to, magnetic media such as hard disks, floppy disks, and magnetic tape; optical media such as CD-ROM disks; magneto-optical media; and hardware devices that are specially configured to store and perform program instructions, such as read-only memory devices (ROM) and random access memory (RAM). Examples of program instructions include both machine code, such as produced by a compiler, and files containing higher level code that may be executed by the computer using an interpreter.","In the above description, the term \u201cframe\u201d is used throughout. However, the term \u201cframe\u201d is intended to be used interchangeably with the term \u201cpacket.\u201d Accordingly, the term \u201cframe\u201d is intended to be interpreted broadly rather than narrowly.","While the disclosed embodiments have been particularly shown and described with reference to specific embodiments thereof, it will be understood by those skilled in the art that changes in the form and details of the disclosed embodiments may be made without departing from the spirit or scope of the disclosed embodiments. For instance, it will be appreciated that at least a portion of the functions described herein could be performed by one or more devices, e.g., by a microprocessor, by a cluster of microprocessors, etc. Considering these and other variations, the scope of the disclosed embodiments should be determined with reference to the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 4B","FIG. 3"]},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
