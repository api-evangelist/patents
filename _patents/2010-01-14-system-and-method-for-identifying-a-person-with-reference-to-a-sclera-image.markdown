---
title: System and method for identifying a person with reference to a sclera image
abstract: A method for obtaining an identification characteristic for a subject includes acquiring an image of an eye of the subject, segmenting the eye image into different regions, extracting features in a sclera region segmented from the eye image, and generating data identifying at least one feature extracted from the sclera region of the eye image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08768014&OS=08768014&RS=08768014
owner: Indiana University Research and Technology Corp.
number: 08768014
owner_city: Indianapolis
owner_country: US
publication_date: 20100114
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["GOVERNMENT INTEREST","PRIORITY CLAIM","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This invention was made with government support under contract N00014-07-1-0788 awarded by the Office of Naval Research. The government has certain rights in the invention.","This application claims priority from International Application PCT\/US10\/20991, which is entitled \u201cSYSTEM AND METHOD FOR IDENTIFYING A PERSON WITH REFERENCE TO A SCLERA IMAGE,\u201d and was filed on Jan. 14, 2010. This application claims further priority from U.S. Provisional Application No. 61\/144,508 filed on Jan. 14, 2009 and from U.S. Provisional Application No. 61\/260,451 which was filed on Nov. 12, 2009.","The system and method described below relate to the identification of a person or an animal with reference to external physical characteristics of the person or animal, and, more specifically, with reference to externally observable physical characteristics of one or more eyes of the person or animal.","Systems for identifying persons through intrinsic human traits have been developed. These systems operate by taking images of a physiological trait of a person and comparing information stored in the image to image data corresponding to the imaged trait for a particular person. When the information stored in the image has a high degree of correlation to the relevant data previously obtained for a particular person's trait, positive identification of the person may be obtained. These biometric systems obtain and compare data for physical features, such as fingerprints, voice, facial characteristics, iris patterns, hand geometry, retina patterns, and hand\/palm vein structure. Different traits impose different constraints on the identification processes of these systems. For example, fingerprint recognition systems require the person to be identified to contact an object directly for the purpose of obtaining fingerprint data from the object. Similarly, retina pattern identification systems require a person to allow an imaging system to scan the retinal pattern within one's eye for an image capture of the pattern that identifies a person. Facial feature recognition systems, however, do not require direct contact with a person and these biometric systems are capable of capturing identification data without the cooperation of the person to be identified.","One trait especially suited for identification is sclera patterns in a person's eye. The human eye sclera provides a unique trait that changes little over a person's lifetime. It also provide multi-layer information that can be used for liveness test. It is important to design a method to segment and match the sclera pattern accurately and robustly.","A method has been developed that obtains an identification characteristic from the sclera of a subject's eye. The method includes acquiring an image of an eye of a subject, segmenting the eye image into different regions, extracting features in a sclera region segmented from the eye image, and generating data identifying at least one feature extracted from the sclera region of the eye image.","A system that implements the method also obtains an identification characteristic from the sclera of a subject's eye. The system includes a digital camera configured to acquire an image of an eye of a subject, a digital image processor configured to segment the eye image into different regions, to extract features in a sclera region segmented from the eye image, and to generate data identifying at least one feature extracted from the sclera region of the eye image, and a database for storage of identifying data.","The method and system discussed below use patterns in the sclera of an eye, especially a human eye, for identification. Therefore, the present invention provides an identification technique based on the recognition of the unique features of the sclera, referred to herein as \u201cSclera Recognition\u201d. In general, the method of identification includes illuminating an eye, obtaining an image of the eye (sclera, iris, and pupil), segmenting the image, extracting features from the sclera region, registering those extracted features, and generating a template. This template may be stored and compared to templates obtained from eye images of other subjects to identify the subsequent subject as being the same subject from which the stored template was obtained.","An illustration of a human eye is shown in . The eye  includes a pupil  surrounded by an iris . A limbic boundary  separates the iris  from the sclera region . A medial point  identifies the area where a tear duct is typically located and the lateral point  identifies an outside edge of the image. Within the sclera  are blood vessels  that form patterns. These patterns have been determined to be sufficiently unique that may be used to identify a subject.","A method for identifying a person from an image of a person's eye is shown in . The process  begins with an acquisition of a color image of a subject's eye (block ). Imaging of an eye may include illumination of the eye in near infrared, infrared, visible, multispectral, or hyperspectral frequency light. The light may be polarized or non-polarized and the illumination source may be close or remote from the eye. A light source close to an eye refers to a light source that directly illuminates the eye in the presence of the subject. A remote light source refers to a light source that illuminates the eye at a distance that is unlikely to be detected by the subject. As noted below, adjustments may be made to the image to compensate for image deformation that may occur through angled image acquisition or eye movement. Thus, the eye image may be a frontal image or a deformed image. The image acquisition may be performed with a digital camera having an adequate resolution for imaging blood vessels within the subject's eye.","The process of  continues by segmenting the image into various regions (block ) with an example segmentation process depicted in . The image may be downsampled to a smaller size before further processing occurs (block ). In the embodiment of , the downsampling produces a downsampled image 1\/25the size of the original image, but different amounts of downsampling may be used depending upon the original image size and the available processing hardware.","The binary data representing pixels of the eye image are converted from an initial red, green, blue (RGB) color space, to an intermediate luma, red-difference, blue-difference (YCrCb) color space, and then into a hue, saturation, brightness value (HSV) color space (block ) using transformations listed below.",{"@attributes":{"id":"p-0023","num":"0022"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"Y"}},{"mtd":{"msub":{"mi":["C","R"]}}},{"mtd":{"msub":{"mi":["C","B"]}}}]}},{"mrow":[{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mi":".299"},{"mi":".587"},{"mi":".114"}]},{"mtd":[{"mrow":{"mo":"-","mi":".169"}},{"mrow":{"mo":"-","mi":".331"}},{"mi":".499"}]},{"mtd":[{"mi":".499"},{"mrow":{"mo":"-","mi":".418"}},{"mrow":{"mo":"-","mi":".0813"}}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"R"}},{"mtd":{"mi":"G"}},{"mtd":{"mi":"B"}}]}}],"mo":"\u2061"},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mn":"0"}},{"mtd":{"mn":"128"}},{"mtd":{"mn":"128"}}]}}],"mo":"+"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"1"}}]},{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mi":"H"}},{"mtd":{"mi":"S"}},{"mtd":{"mi":"V"}}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"msup":{"mi":"tan","mrow":{"mo":"-","mn":"1"}},"mo":"\u2062","mfrac":{"msub":[{"mi":["C","B"]},{"mi":["C","R"]}]}}}},{"mtd":{"msqrt":{"mrow":{"msubsup":[{"mi":["C","R"],"mn":"2"},{"mi":["C","B"],"mn":"2"}],"mo":"+"}}}},{"mtd":{"mi":"Y"}}]}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"2"}}]}]}}}},"In Equation 1, the red (R), green (G), and blue (B) numeric values corresponding to each pixel undergo a cross product matrix transform with the weighting matrix of equation 1. The numeric RGB values in equation 1 are in a range of 0 to 255, but larger or smaller ranges using modified matrix coefficients are possible for alternative binary image formats. The resulting matrix is then adjusted by adding 128 to each of the Cr and Cb values, resulting in a YCrCb matrix. The YCrCb matrix is then transformed into an HSV matrix using the transformations listed in equation 2. The transformations listed above are repeated for each pixel in the eye image, producing an image in the HSV color space. Both the original RGB and the transformed HSV color space values are used in different steps of the segmentation process of .","The process of  continues by estimating the area of the sclera within the HSV image (block ). The estimated sclera area is determined using a combination of two different techniques. One technique is rooted in the observation that the eye image includes both a \u201cskin\u201d portion, including the eyelids, and a \u201cnon-skin\u201d portion containing the sclera. Using color distance maps, the skin area of the image is determined, and the inverse portions of the image are then interpreted as being the sclera. Two example color distance map (CDM) equations are listed below.",{"@attributes":{"id":"p-0026","num":"0025"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"msub":{"mi":"CDM","mn":"1"},"mo":"=","mrow":{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mn":"1","mo":","}},{"mtable":{"mtr":[{"mtd":{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mi":"R","mo":">","mn":"95"},{"mi":"G","mo":">","mn":"40"},{"mi":"B","mo":">","mn":"20"}],"mo":[",",",",","]}}},{"mtd":{"mrow":{"mrow":{"mrow":{"mrow":[{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["R","G","B"],"mo":[",",","]}}},{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["R","G","B"],"mo":[",",","]}}}],"mo":"-"},"mo":">","mn":"15"},"mo":","}}}]}}},{"mtd":{"mrow":{"mrow":[{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":["R","G"],"mo":"-"}},"mo":">","mn":"15"},{"mi":["R","G"],"mo":">"},{"mi":["R","B"],"mo":">"}],"mo":[",",","]}}}]}}]},{"mtd":[{"mrow":{"mn":"0","mo":","}},{"mi":"else"}]}]}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"3"}}]},{"mtd":[{"mrow":{"msub":{"mi":"CDM","mn":"2"},"mo":"=","mrow":{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mn":"1","mo":","}},{"mtable":{"mtr":[{"mtd":{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mi":"R","mo":">","mn":"220"},{"mi":"G","mo":">","mn":"210"},{"mi":"B","mo":">","mn":"170"}],"mo":[",",",",","]}}},{"mtd":{"mrow":{"mrow":{"mrow":{"mrow":[{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["R","G","B"],"mo":[",",","]}}},{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["R","G","B"],"mo":[",",","]}}}],"mo":"-"},"mo":">","mn":"15"},"mo":","}}}]}}},{"mtd":{"mrow":{"mrow":[{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":["R","G"],"mo":"-"}},"mo":"\u2264","mn":"15"},{"mi":["R","B"],"mo":">"},{"mi":["B","G"],"mo":">"}],"mo":[",",","]}}}]}}]},{"mtd":[{"mrow":{"mn":"0","mo":","}},{"mi":"else"}]}]}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"4"}}]},{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"S","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mn":"1","mo":","}},{"mrow":{"mrow":{"mrow":[{"msub":{"mi":"CDM","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"msub":{"mi":"CDM","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"OR"},"mo":"=","mn":"0"}}]},{"mtd":[{"mrow":{"mn":"0","mo":","}},{"mi":"else"}]}]}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"5"}}]}]}}},"br":{},"sub":["2 ","2 "]},"Another method of producing a sclera map is rooted in the observation that the sclera is also known as the \u201cwhite\u201d portion of the eye. Using the HSV values image values, each pixel in the image is assigned a 0 or 1 value according to the threshold equation below.",{"@attributes":{"id":"p-0028","num":"0027"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"S","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mn":"1","mo":","}},{"mtable":{"mtr":[{"mtd":{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mi":"if","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":"H","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},"mo":"\u2264","msub":{"mi":["th","h"]}}}},{"mtd":{"mrow":{"mrow":{"mi":"and","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},"mo":"\u2264","msub":{"mi":["th","s"]}}}}]}}},{"mtd":{"mrow":{"mrow":{"mi":"and","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":"V","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}}},"mo":"\u2265","msub":{"mi":["th","v"]}}}}]}}]},{"mtd":[{"mrow":{"mn":"0","mo":","}},{"mi":"else"}]}]}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"6"}}]}}}},"br":[{},{},{},{}],"sub":["h","s","v ","h","x=1","h","h","s","x=1","s","s","v","x=1","v","v"],"in-line-formulae":[{},{},{},{},{},{}],"i":["th","t","p","x","T","th","t","p","x","T","th","t","p","x","T"],"sup":["t","t","t"]},"In Equations 7-9, p(x) is the normalized histogram of the hue image, p(x) is the normalized histogram of the saturation image, and p(x) is the normalized histogram of the value image. The fixed threshold values T, T, and Tare chosen to be \u2153, \u2156, and \u2154, respectively, matching the preferred thresholds discussed above. The result S(x,y) is the binary sclera map produced with the HSV method.","Morphological operations are applied to each binary sclera map Sand Sin order to eliminate stray pixels that do not match the surrounding pixels. The preferred result of the morphological operations are two contiguous regions in each binary sclera map corresponding to the portions of the sclera  on the left and right side of the iris  as depicted in .","Continuing to refer to , a convex hull calculation is applied to each binary sclera map (block ). The convex hull is the minimal convex set of points that contains the entire original set. It can be visualized as the boundary of the set of points that contains all of the points, without requiring a concave segment, or as if an elastic band were stretched around the set of points. In the case of the sclera maps Sand S, the convex hull is formed around the set of points determined to be in the sclera region of the image.","The complete estimated sclera region is formed by selectively combining the binary maps Sand Safter the convex hull operation has been completed (block ). The regions to be selected for the combined binary sclera map are chosen based on homogeneity of the pixel colors from the original image that correspond to the sclera regions of each binary sclera map. The sclera map region that corresponds to the most homogeneous color distribution in the original downsampled image is chosen to represent the sclera area. The homogeneity is determined using the equation below.",{"@attributes":{"id":"p-0033","num":"0032"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"r","mo":"=","mrow":{"mi":"arg","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"mi":"\u2148","mo":"|","mrow":{"mi":"min","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munder":{"mo":"\u2211","mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}},"mo":"\u2208","msub":{"mi":["S","i"]}}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},"mo":"-","msub":{"mi":["m","i"]}}},"mn":"2"}}}}}}},"mo":","}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"10"}}]}}}},"br":{},"sub":"i "},"An example of two binary sclera maps and a combined estimated sclera area map  is depicted in . The first sclera image  is shown as an example of the binary sclera map S, and the second sclera image  is an example of the binary sclera map S. Binary sclera map  contains a left sclera portion , and right sclera portion , as does binary sclera map  at  and , respectively. The homogeneity of each sclera region from binary sclera maps  and  is calculated using equation 10 and the color values from the original downsampled image that correspond to the locations in each sclera region. In the example of , the fused estimated sclera region  combines the left sclera region  of binary sclera map  with the right sclera portion  of binary sclera map . The fused sclera region  of  is merely presented as one possible example of an estimated sclera area, and the method of  produces different results for different images. For example, the homogenous regions could both be contained in either Sor S.","Referring again to , the fused sclera region map forms the top and bottom boundaries for initiating eyelid and iris detection (block ). Because the sclera is much lighter than the iris area, edge detection may be used to identify the edges of the limbic boundary between the iris and the sclera. After the initial boundaries are detected, the edges defining the sclera, iris, and eyelid regions may be further refined using Fourier active contour techniques known to the art. An alternative method uses two dimensional polynomial curves to model the eyelids. Any eyelashes that extend into the sclera region of the image are also detected and removed. These eyelash portions are modeled as high edge areas with a light background. The refinements removing the iris, eyelid, and eyelash elements further define the estimated portion of the downsampled image that corresponds to the sclera. An example of a segmented sclera image is depicted in  at  and . The iris  is also segmented in the eye image (block ). If the sclera is of primary concern, the iris may be segmented using a circular estimated region placed between the left and right portions of the refined estimated sclera region.","The refined estimated binary sclera region forms an image mask pattern (block ). This mask is then upsampled back to the size of the original image (block ). In the example of , the upsampling ratio would increase the original mask by a factor of 25 to reverse the downsampling. The binary image mask is aligned with the original image, and the portions of the original image that match the binary mask are preserved, resulting in a segmented sclera portion of the original image (block ).","Returning to the process of , the segmented sclera image contains features such as vein patterns, vein lines, and extrema points that are enhanced to improve feature detection (block ). The surface of an eye is often highly reflective, which makes focusing of an imaging device photographing the eye difficult. The result is that features within the sclera region may be blurred, and have a low contrast ratio in the image. In order to enhance feature patterns, a Gabor filtering technique may be used to differentiate the features from the surrounding sclera. The Gabor filtering process applies the Gabor filter of equation 11 using the transformation of equation 12 on the segmented sclera image.",{"@attributes":{"id":"p-0038","num":"0037"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y","\u03d1","s"],"mo":[",",",",","]}}},{"msup":[{"mi":"\u2147","mrow":{"mo":"-","mrow":{"mi":"\u03c0","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mrow":{"msup":[{"mrow":{"mo":["(",")"],"mrow":{"mi":"x","mo":"-","msub":{"mi":"x","mn":"0"}}},"mn":"2"},{"mrow":{"mo":["(",")"],"mrow":{"mi":"y","mo":"-","msub":{"mi":"y","mn":"0"}}},"mn":"2"}],"mo":"+"},"msup":{"mi":"s","mn":"2"}}}}}},{"mi":"\u2147","mrow":{"mrow":{"mrow":[{"mo":"-","mn":"2"},{"mi":"\u2148","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"cos","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"\u03d1","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"x","mo":"-","msub":{"mi":"x","mn":"0"}}}}},{"mi":"sin","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"\u03d1","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"y","mo":"-","msub":{"mi":"y","mn":"0"}}}}}],"mo":"+"}}}],"mo":["\u2062","\u2062","\u2062"],"mi":"\u03c0","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":","}}],"mo":"\u2062"}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"11"}}]},{"mtd":[{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"4.4em","height":"4.4ex"}}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["I","F"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y","\u03b8","s"],"mo":[",",",",","]}}},{"mrow":[{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y","\u03b8","s"],"mo":[",",",",","]}}}],"mo":"*"}],"mo":"="}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"12"}}]}]}}},"br":{},"sub":["F ","F "]},"Two example Gabor filter sets are depicted in . The first filter set  is an even Gabor filter set with multiple orientations , , , and . The second filter set  is an odd Gabor filter set with multiple orientations , , , and . Either the even or odd filter set may be used in the transformation of equation 11.","The multiple Gabor filtered images are fused into a vein-boosted image F(x, y) using the following equation.\n\n()=\u221a{square root over (\u03a3\u03a3(()))}\u2003\u2003Equation 13\n","An example of a portion of the sclera image without Gabor filtering is depicted in  at . The image includes vein features . An example Gabor filtering process using the even filter set  is applied, and the individual results are fused using Equation 13 to produce results  with vein structure .","The Gabor filtered image is converted to a binary image using an adaptive threshold, which is determined based on the distribution of filtered pixel values via the following equations.",{"@attributes":{"id":"p-0043","num":"0042"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mn":"1","mo":","}},{"mrow":{"mrow":{"mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},"mo":">","msub":{"mi":["th","b"]}},"mo":","}}]},{"mtd":[{"mrow":{"mn":"0","mo":","}},{"mi":"else"}]}]}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"14"}}]},{"mtd":[{"mrow":{"msub":{"mi":["th","b"]},"mo":"=","mrow":{"mi":"arg","mo":"\u2062","mrow":{"mrow":{"mo":["{","}"],"mrow":{"mrow":{"mrow":{"mi":"t","mo":["\u2062","\u2062"],"mrow":[{"mo":["\uf603","\uf604"],"mi":"min"},{"munderover":{"mo":"\u2211","mrow":{"mi":"x","mo":"=","mn":"1"},"mi":"t"},"mo":"\u2062","mrow":{"msub":{"mi":["P","edge"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}}}]},"mo":"-","msub":{"mi":["T","B"]}},"mo":"|"}},"mo":"."}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"15"}}]}]}}},"br":{},"sub":["b","b ","edge","b "],"figref":"FIG. 8","b":["812","814"]},"Referring to the example process of , the sclera features contained within the binary enhanced image are extracted using a line segment descriptor technique (block ). The thickness of sclera features, including the thickness of veins in the sclera, varies depending upon the dilation or constriction of the veins. This variability results in veins appearing thicker or thinner in unpredictable ways, and some thinner veins disappear when constricted. Binary morphological operations known to the art reduce the detected vein structure to a single-pixel wide skeleton, and remove the branch points where multiple veins overlap. The branch points are removed because sclera veins move relative to each other over time, leading to changes in branch points that could produce inaccurate matching results. The morphological operations leave a set of single-pixel wide lines representing the vein structure, with one example depicted in  at  with single-pixel wide veins .","The line segment descriptor technique continues with a line parsing sequence. The line parsing sequence converts the curved lines representing sclera vein features into a series of linear elements that may be stored in a computer database. The original vein features are approximated by line segments, and the line segments are recursively split into smaller segments until the vein features are substantially linear.","An example of a line segment in the parsing sequence is depicted in . A fixed central reference point , usually the center of the pupil , is used as a central point from which radial lines such as line  extend. The use of a known central point allows for correct relative positions of vein features to be recorded even if the eye moves to a different position relative to the imaging device. Each radial line  intersects the center point of a linear element . The linear element  approximates a non-linear section of a vein feature . The linear element  is described by the polar coordinate  of its center point, its length, and the angle  of the linear element  from a horizontal line  (\u00f8). The polar coordinate of the center of linear element  is the radius of radial line  and the angle  of the radial line (\u03b8) from a horizontal line . By storing the identifying elements for each linear element , the vein features present in the sclera may be extracted and stored in a computer readable manner. The coordinates (x, y) locating the pupil's center  are also stored, providing an absolute position from which each linear element  may be referenced by polar coordinates.","During eye image acquisition, the eye may move or the camera may be positioned at an angle with respect to the eye being imaged. These factors affect the location of the sclera patterns presented inside the image. To remove these effects, sclera template registration is performed (block ). The location of the limbic boundary, pupil center, limbic center, medial, and\/or lateral may be used to define a location of features\/patterns and further used for registration of the features\/patterns. Sclera region of interest (ROI) selection achieves global translation, rotation, and scaling-invariance. In addition, due to the complex deformation that can occur in the vein patterns, the registration scheme accounts for potential changes in vein patterns while maintaining recognition patterns with acceptable false-positive rates.","A technique for registering the sclera template features based on random sample consensus (RANSAC) is an iterative model-fitting method that can register the sclera features. The RANSAC method registers the coordinates of the center points  of each linear element  used to model the sclera veins. The center point coordinates and angles, but not the lengths of the linear descriptors are registered in order to prevent false-accepts due to over-fitting the registered features.","When an eye has been registered via the registration process in block , an identification system may use the registered template to perform matching between the stored template and an image of a candidate eye. This process commonly occurs in biometric authentication systems where a user is registered with the identification system, and the user authenticates with the identification system at a later time. The registration minimizes the minimum distance between the recorded test template and the target templates that are acquired later for matching with the test template. This reduces artificially introduced false accepts because different parameters are used for registration than are used for matching, so the preferred registration and preferred matching is different for templates that should not match. The registration process randomly chooses two points\u2014one Sfrom the test template, and one Sfrom the target template. The registration process also randomly chooses a scaling factor and a rotation value, based on apriori knowledge of the template database. Using these values, a fitness value for the registration using these parameters is calculated for each segment in the image using the segment's polar coordinates r and \u03b8 and the line segment's angle \u00f8. The test template parameter Sand target template parameter S, are defined below.",{"@attributes":{"id":"p-0050","num":"0049"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["S","xi"]},"mo":"=","mrow":{"mrow":[{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["\u03b8","xi"]}}},{"mtd":{"msub":{"mi":["r","xi"]}}},{"mtd":{"msub":{"mi":["\u2205","xi"]}}}]}},{"mstyle":[{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mo":"\u2062"}],"mo":["\u2062","\u2062","\u2062","\u2062"],"mi":"and","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"msub":{"mi":["S","yj"]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["\u03b8","yj"]}}},{"mtd":{"msub":{"mi":["r","yj"]}}},{"mtd":{"msub":{"mi":["\u2205","yj"]}}}]}}],"mo":"="}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"16"}}]}}}},"br":{},"sub":["0 ","0","0 ","0 ","0 "]},{"@attributes":{"id":"p-0051","num":"0050"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"msub":{"mi":"\u03c6","mn":"0"},"mo":"=","mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["x","o"]}}},{"mtd":{"msub":{"mi":["y","o"]}}},{"mtd":{"msub":{"mi":["s","o"]}}},{"mtd":{"msub":{"mi":["\u2205","o"]}}}]}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"17"}}]},{"mtd":[{"mrow":{"msub":{"mi":["x","o"]},"mo":"=","mrow":{"mrow":[{"msub":[{"mi":["r","xi"]},{"mi":["\u03b8","xi"]}],"mo":["\u2062","\u2062","\u2062"],"mi":"cos","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"msub":[{"mi":["r","yj"]},{"mi":["\u03b8","yj"]}],"mo":["\u2062","\u2062","\u2062"],"mi":"cos","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":"-"}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"18"}}]},{"mtd":[{"mrow":{"msub":{"mi":["y","o"]},"mo":"=","mrow":{"mrow":[{"msub":[{"mi":["r","xi"]},{"mi":["\u03b8","xi"]}],"mo":["\u2062","\u2062","\u2062"],"mi":"sin","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"msub":[{"mi":["r","yj"]},{"mi":["\u03b8","yj"]}],"mo":["\u2062","\u2062","\u2062"],"mi":"sin","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":"-"}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"19"}}]}]}}},"br":{},"sub":["x ","y ","0"]},{"@attributes":{"id":"p-0052","num":"0051"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["S","x"]},{"mi":["S","y"]}],"mo":","}}},{"munder":{"mrow":{"mi":["arg","min"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"msub":{"mi":"\u03c6","mn":"0"}},"mo":"\u2062","mrow":{"mover":{"mi":"D","mo":"~"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["S","x"]},{"mi":["S","y"]},{"mi":"\u03c6","mn":"0"}],"mo":[",",","]}}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"20"}}]},{"mtd":[{"mrow":{"mrow":[{"mover":{"mi":"D","mo":"~"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["S","x"]},{"mi":["S","y"]},{"mi":"\u03c6","mn":"0"}],"mo":[",",","]}}},{"munder":{"mo":"\u2211","mrow":{"msub":{"mi":["x","i"]},"mo":"\u2208","mi":"Test"}},"mo":"\u2062","mrow":{"mi":"min","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"Dist","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["S","xi"]},{"mi":"\u03c6","mn":"0"}],"mo":","}}},"mo":",","msub":{"mi":["S","y"]}}}}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"21"}}]}]}}},"br":{},"sub":["xi","0"]},{"@attributes":{"id":"p-0053","num":"0052"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["S","xi"]},{"mi":"\u03c6","mn":"0"}],"mo":","}}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msup":{"mi":"cos","mrow":{"mo":"-","mn":"1"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":{"mi":"r","mrow":{"mrow":{"mi":["xi","cos"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"msub":{"mi":["\u03b8","xi"]}},"mo":"+","msub":{"mi":["x","o"]}}},"mrow":{"msub":[{"mi":["s","o"]},{"mi":["r","xi"]}],"mo":"\u2062"}}}}}},{"mtd":{"mfrac":{"msub":{"mi":"r","mrow":{"mrow":{"mi":"xicos","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u03b8","xi"]}},"mo":"+","msub":{"mi":["x","o"]}}},"mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["\u03b8","xi"]},{"mi":["\u2205","o"]}],"mo":"+"}}}}}},{"mtd":{"msub":{"mi":["\u2205","xi"]}}}]}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"22"}}]}}}},"br":[{},{},{},{}],"sub":["xi ","xi ","xi","y","j","xi","yj","xi","yj","o","o","o","o"],"in-line-formulae":[{},{},{},{}],"i":["S",",S","{d","S",",S","d","S",",S","x","y","x","y"],"sup":["2","2","2","2"]},"Where, Test is the set of descriptors in the stored test template, Target is the set of descriptors in the newly acquired target template, Sis the first descriptor used for registration, Sis the second descriptor, \u03c6is the set of offset parameter values, f(S, \u03c6) is a function that modifies the descriptor with the given offset values, S is the scaling factor, and is the rotation value which is determined by the sclera image resolution and system application. The process performs some number of iterations, recording the values \u03c6that are minimal in D(S, S).","A template for future comparisons is generated from the extracted features (block ). The template may be, for example, a bit map of the sclera region that identifies the features, a list of features with positional information about each feature, or a set of descriptors for the extracted features. To generate the template, the location of the registered extrema points or a set of descriptors for the features are saved. Descriptors refer to the model parameters for the detected feature edges that were obtained through known curve fitting techniques, wavelets, neural network, filtering methods, and other pattern recognition methods. The parameters of the fitted curves are saved as descriptors for the extrema points. The template may be represented in a binary, integer, or floating number format. The template may now be used to identify another image of an eye as corresponding to or not corresponding to the template. The template generation process described above is merely illustrative of an appropriate process for modeling an image of the eye. Alternative processes include using a set of area, line, and\/or point descriptors; a set of wavelet co-efficiencies, magnitudes, phases, or a combination thereof; and a set of vectors and\/or matrices.","An identification or matching process (block , ) may now be performed by repeating the eye image processing (block  to ) to obtain another eye image and generate a template for the image, and then compare the generated template for the second image to a stored template to determine whether the two templates correspond to one another. The templates used in the comparison may not be completely accurate. For example, the heuristics used in segmenting the sclera may result in inaccuracies in the edge areas of the segmented sclera. As depicted in , each sclera template is weighted to discount the areas  near the edge of each template region where the inaccuracies occur. The central portion of the sclera  is weighted more heavily.","The matching process compares the line segments Sin the stored template with line segments Sstored in the template generated from the second eye image. The matching process produces a match score m(S, S) for each line segment in the stored template using the equation below.",{"@attributes":{"id":"p-0058","num":"0057"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"m","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["S","i"]},{"mi":["S","j"]}],"mo":"\u2062"}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"w","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["S","i"]}}},{"mi":"w","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["S","j"]}}}],"mo":"\u2062"},"mo":","}},{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["S","i"]},{"mi":["S","j"]}],"mo":","}}},"mo":"\u2264","msub":{"mi":["D","match"]}}}},{"mtd":{"mi":"and"}}]}}]},{"mtd":[{"mrow":{"mn":"0","mo":","}},{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":["\u2205","i"]},{"mi":["\u2205","j"]}],"mo":"-"}},"mo":"\u2264","msub":{"mi":["\u2205","match"]}}}},{"mtd":{"mi":"else"}}]}}]}]}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"25"}}]}}}},"br":{},"sub":["i","j","i ","j ","match ","match ","match ","match ","i ","match ","match ","j","i","j","i","j","i ","j ","match ","match","i","j"],"figref":"FIG. 2","b":["708","704","712"]},"The matching scores m(Si, Sj) for individual line segments are summed to produce an overall matching score M using the equation below.",{"@attributes":{"id":"p-0060","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"M","mo":"=","mfrac":{"mrow":[{"msub":{"mo":"\u2211","mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}},"mo":"\u2208","mi":"Matches"}},"mo":"\u2062","mrow":{"mi":"m","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["S","i"]},{"mi":["S","j"]}],"mo":","}}}},{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":{"mo":"\u2211","mrow":{"mi":["i","Target"],"mo":"\u2208"}},"mo":"\u2062","mrow":{"mi":"w","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["S","i"]}}}},{"msub":{"mo":"\u2211","mrow":{"mi":["j","Test"],"mo":"\u2208"}},"mo":"\u2062","mrow":{"mi":"w","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["S","j"]}}}}],"mo":","}}}]}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"26"}}]}}}},"br":{},"figref":["FIG. 2","FIG. 2"]},"A system that may be used to implement the image processing method described above is shown in . The system  includes a digital camera , a digital image processor , and a database . The digital camera, which may generate color or grayscale images, is located at a position where a subject may be standing or seated. The camera need not be positioned where the subject is aware of the camera and, thus, cooperative for providing an image of the subject's eye. The camera may be, for example, a Sony DSLR-A100 camera, although any high resolution digital camera is appropriate. Other cameras that may be used include near infrared, infrared, visible, multispectral, and hyperspectral cameras. The digital image processor  may be a general purpose microprocessor or a special purpose digital signal processor (DSP). The processor is provided with appropriate interface circuitry for retrieving the image signal from the camera or a stored template from the database . Instructions to be executed by the processor  may be stored in an internal memory of the processor or in an external memory coupled to the processor in a known manner. Execution of the stored instructions by the processor  results in the system  performing an image processing method similar to the one described above with reference to . A template generated by the processor  may be stored in the database  for future comparisons or the generated template may be compared to a stored template to determine whether a subject being imaged corresponds to a subject having a template stored in the database . Database  may be any appropriate data management system and storage media, such as a database management system having a hard disk drive or other non-volatile memory. The templates stored in the database  may be indexed with reference to extrema points or types of fitted curves.","In another embodiment, a system and method may use structure within an iris as well as patterns within a sclera to improve recognition accuracy and increase the degree of the freedom in subject recognition. The use of iris and sclera features for subject identification is referred to herein as \u201ciris and sclera multimodal recognition\u201d. A method for implementing iris and sclera multimodal recognition includes eye illumination, eye image acquisition (sclera, iris, and pupil), image segmentation, feature extraction, feature registration, and template generation. This method is similar to the one described above except the image segmentation retains the iris in the acquired image, the feature extraction includes structure within the iris, and the template generation identifies sclera patterns and iris structure. The feature extraction of iris could be wavelet based method, descriptor based method, and\/or spatial-domain method. As described above, a stored template may be compare to a template obtained from another acquired eye image to identify the subject in the second image as corresponding to or not corresponding to the subject for the stored template.","The comparison of templates in the iris and sclera multimodal system may use feature level fusion, template level fusion, and\/or score level fusion. For example, the sclera and iris regions may be processed separately and the templates generated for each separate region may then be stored for later comparison. Templates generated from a later acquired image for both the iris and sclera areas may be separately compared to one or more stored templates to generate a pair of matching scores. If both matching scores are higher than the matching thresholds, the subjects are deemed the same. If one of the scores does not meet or exceed the matching threshold, the context of the recognition scenario may be used to determine the criteria for a match. For example, in a highly secured situation, one low matching score may be sufficient to evaluate a subject as not corresponding to the subject for a stored template. In a less secured scenario, such as access to a home computer, one matching score exceeding one threshold by a predetermined percentage may be adequate to declare the subjects as corresponding to one another. In a similar manner, sclera recognition may be combined with face recognition, skin tissue recognition, or some other biometric characteristic recognition system to improve recognition accuracy for the system.","Those skilled in the art will recognize that numerous modifications can be made to the specific implementations described above. Therefore, the following claims are not to be limited to the specific embodiments illustrated and described above. The claims, as originally presented and as they may be amended, encompass variations, alternatives, modifications, improvements, equivalents, and substantial equivalents of the embodiments and teachings disclosed herein, including those that are presently unforeseen or unappreciated, and that, for example, may arise from applicants\/patentees and others."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 9","FIG. 2"]}]},"DETDESC":[{},{}]}
