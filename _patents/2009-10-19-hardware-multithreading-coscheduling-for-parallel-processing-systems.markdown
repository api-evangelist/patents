---
title: Hardware multi-threading co-scheduling for parallel processing systems
abstract: A method, information processing system, and computer program product are provided for managing operating system interference on applications in a parallel processing system. A mapping of hardware multi-threading threads to at least one processing core is determined, and first and second sets of logical processors of the at least one processing core are determined. The first set includes at least one of the logical processors of the at least one processing core, and the second set includes at least one of a remainder of the logical processors of the at least one processing core. A processor schedules application tasks only on the logical processors of the first set of logical processors of the at least one processing core. Operating system interference events are scheduled only on the logical processors of the second set of logical processors of the at least one processing core.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08484648&OS=08484648&RS=08484648
owner: International Business Machines Corporation
number: 08484648
owner_city: Armonk
owner_country: US
publication_date: 20091019
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"p":["This invention was made with Government support under Contract No.: HR0011-07-9-0002 awarded by Defense Advanced Research Projects Agency (DARPA). The Government has certain rights in this invention.","The present invention generally relates to the field of data processing, and more particularly relates to application and event scheduling in a hardware multi-threading environment.","Parallel computing is the simultaneous execution of the same task (split up and specially adapted) on multiple processors in order to obtain faster execution. Parallel computing is based on the fact that the process of solving a problem usually can be divided into smaller tasks, which may be carried out simultaneously with some coordination. Parallel applications can include some segments of instructions that must be executed serially on each node using a single thread, and other segments of instructions that can be executed in parallel on each node using multiple threads. That is, each node utilizes a single processor while executing the serial code segments and spawns threads to other processors on that node while executing the parallel code segments.","One problem with parallel computing environments and parallel applications is that a parallel application is susceptible to operating system (O\/S) interference or jitter. O\/S jitter is an event that is caused by the O\/S that preempts or interrupts a parallel application from utilizing its assigned CPU for a period of time. Examples of these jitter events are the scheduling of daemon processes and the handling of asynchronous events such as interrupts. O\/S jitter results in degradation of the performance of the parallel application.","One embodiment of the present invention provides a computer implemented method for managing operating system interference on applications in a parallel processing system. According to the method, a mapping of hardware multi-threading threads to at least one processing core is determined, and first and second sets of logical processors of the at least one processing core are determined. The first set includes at least one of the logical processors of the one processing core, and the second set includes one or more of a remainder of the logical processors of the at least one processing core. An operating system executing on a processor schedules application tasks only on the logical processors of the first set of logical processors of the one processing core. Operating system interference events are scheduled only on the logical processors of the second set of logical processors of the one processing core. xxx","Another embodiment of the present invention provides an information processing system for managing operating system interference on applications in a parallel processing system. The information processing system includes a memory and a processor that is communicatively coupled to the memory. An operating system interference manager is communicatively coupled to the memory and the processor. The operating system interference manager determines a mapping of hardware multi-threading threads to at least one processing core. First and second sets of logical processors of the at least one processing core are determined. The first set includes at least one of the logical processors of the one processing core, and the second set includes one or more of a remainder of the logical processors of the at least one processing core. An operating system executing on the processor schedules application tasks only on the logical processors of the first set of logical processors of the one processing core. Operating system interference events are scheduled only on the logical processors of the second set of logical processors of the one processing core.","Parallel-Distributed Processing System",{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 1","FIG. 1"],"b":["100","100","102","104","106","108","102","104","110","112","114","116","118","120","122","124","126","128","130","132","134","136","106","108","122","124","102","104","102","104","138","102","104"]},"Information Processing System",{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 2","FIG. 1"],"b":["102","102","102","102","202"]},"The computer  includes several physical processors  and  that are communicatively coupled to the main memory  and the channel controller  via the system bus . In this embodiment, each physical processor  and  comprises one or more hardware threads  (e.g., SMT thread). A hardware thread  is a unit of software execution on a multiprocessing computer such as the information processing system . A hardware thread  is treated like an independent processor by the software executing on the computer . In this description, \u201chardware thread\u201d and \u201cSMT thread\u201d are used interchangeably.","The computer  executes software programs such as applications  in units of execution called \u201cprocesses\u201d (i.e., process threads) that include all the processor registers, code segment and offset registers, data segment and offset registers, stack segment and offset registers, flag registers, instruction pointer registers, program counters, and the like that are needed for the execution of software programs. For efficiency, \u201cprocesses\u201d are often organized further into one or more process threads, where each process thread of a process individually possesses all of the attributes needed for execution, except that a thread shares memory with all of the other threads of the same process to reduce the overhead of operating system switches from process thread to process thread (\u201ccontext switches\u201d).","The computer  also includes a mass storage interface , network adapter hardware , and an I\/O adapter . An input\/output bus  connects these components. The mass storage interface  is used to connect mass storage devices  to the information processing system . One specific type of data storage device is a computer readable medium such as a Compact Disc (\u201cCD\u201d) drive, which may be used to store data to and read data from a CD  or DVD. Another type of data storage device is a hard disk configured to support, for example, JFS type file system operations.","In this embodiment, the main memory  is volatile memory such as random access memory (\u201cRAM\u201d). The main memory  comprises one or more applications , an operating system (\u201cO\/S\u201d) , multiple logical processors (\u201cLP\u201d)  and , a scheduler , an O\/S interference\/jitter manager , SMT thread mapping information , and interference\/jitter source information .","The O\/S interference manager  reduces O\/S interference\/jitter effect on application processors while still maintaining core utilization and throughput. Achieving maximum utilization and throughput in an SMT environment involves avoiding cases in which two workloads have to execute serially on two separate cores. In general, it is more efficient to execute both workloads in parallel on the same core, particularly when the workloads do not use the same core resources (e.g., a floating point unit) at the same time. If the workloads do not share any core resources, they might execute at full speed without any impact on each other (assuming no other conflicts, such as cache or memory bus contention).","The O\/S interference manager  improves performance of the parallel applications  by minimizing the de-synchronization among application tasks caused by hardware, O\/S, runtime, and management system activities that are external to the applications . In one embodiment, the O\/S interference manager  is a co-scheduler that operates with root authority which allows the O\/S interference manger  to make privileged changes to the O\/S state to effect co-scheduling of O\/S jitter. The SMT thread mapping information  identifies the particular SMT threads  that are mapped to a given physical processor  and . The interference\/jitter source information  identifies the sources of O\/S interference\/jitter on a physical processor  and .","The operating system  is the layer of system software that schedules process threads via the scheduler  and provides functions for making system resources available to process threads, including memory access, access to input\/output resources, and the like. The operating system  also controls allocation and authorization for access to computer resources. The operating system  performs low-level basic tasks such as recognizing input from a keyboard, sending output to a display screen, keeping track of files and directories on a magnetic disk drive, and controlling peripheral devices such as disk drives and printers. The operating system  is also responsible for security, ensuring that unauthorized users do not access the system and that threads access only resources that they are authorized to access. Operating systems useful for scheduling threads  in a multi-threaded computer are multi-threading operating systems, examples of which include UNIX, Linux, Microsoft NT, AIX, and IBM's i5os.","In this embodiment, the physical processors  and  of the information processing system  are capable of running in a simultaneous multi-threading (\u201cSMT\u201d) mode. In an SMT mode the physical processors  and  are capable of simultaneously accepting instructions from more than one thread of execution. In particular, SMT allows the processor hardware on a chip to be shared among multiple process threads of a multi-threaded workload. SMT is a technique that lets multiple process independent threads issue instructions to a single physical processor in a single processing cycle. An example of a processor that implements SMT is IBM's Power5 processor.","The logical processor  or , in this embodiment, is an operating system structure for scheduling process threads for execution. That is, rather than scheduling threads for execution on a physical processor or a virtual processor, the operating system  schedules process threads for execution on a logical processor  and . Scheduling a process thread on a logical processor  and  provides convenient structure and processing in which the process thread appears, from the point of view of the thread, to have at its disposal all of the resources of an entire logical partition.","A logical processor  or , however, is logically an entire processor (despite the fact that it is only active for a portion of the CPU cycles available on the physical processor  or ). A process thread running on a logical processor  or  appears, therefore, from its point of view, to have all the resources of an entire independent computer. That is, the logical processor  or  is the object upon which the scheduler  in the operating system  runs user threads (looking from the operating system down).","The operating system , logical processors  and , O\/S interference manager , SMT thread mapping information , and interference source information  in the exemplary embodiment of  are shown in the main memory  (e.g., RAM). However, in further embodiments, some or all components of such software are stored in non-volatile memory such as the mass storage device , electrically erasable programmable read-only memory space (\u201cEEPROM\u201d or \u201cFlash memory\u201d), RAM drives, and the like.","The network adapter hardware  provides an interface to a network  for implementing data communications with other computers. Such data communications may be carried out, for example, through data communications networks such as IP networks or in any other way. Communications adapters implement the hardware level of data communications through which one computer sends data communications to another computer, directly or through a network. Examples of communications adapters useful for determining availability of a destination in embodiments of the present invention include modems for wired dial-up communications, Ethernet (IEEE 802.3) adapters for wired network communications, and 802.11 adapters for wireless network communications. Embodiments of the present invention are able to be adapted to work with any data communications connections including present day analog and\/or digital techniques or via a future networking mechanism.","Although the exemplary embodiments of the present invention are described in the context of a fully functional computer system, further embodiments are capable of being distributed as a program product via a CD  and its equivalents, floppy disk, or other form of recordable media, or via any type of electronic transmission mechanism.","Managing O\/S Interference","As discussed above, parallel applications are susceptible to operating system (O\/S) interference or jitter. The O\/S interference manager  improves the performance of the parallel applications by minimizing the de-synchronization among application tasks caused by interference events (i.e., hardware, O\/S, runtime, and management system activities that are external to the applications). The O\/S interference manager  is aware of the details of SMT threads (i.e., hardware threads) and logical processors (CPUs) on a system  via the SMT thread mapping information . The O\/S interference manager  also takes into account possible interference between two or more SMT threads that share resources on the same core (e.g., physical processors  and ) during co-scheduling and synchronization of parallel tasks. The O\/S interference manager  exploits the additional hardware threads, cores, and\/or logical CPUs that previously have not been efficiently exploited to off-load non-application related activities, (i.e., jitter events) and improve the performance of the applications. In other words, the O\/S interference manager  utilizes the SMT thread mapping information  to select a range of logical CPUs that can be dynamically allocated to manage non-application related interruptions in a synchronized manner.","In one embodiment, the O\/S interference manager  analyzes the SMT architecture of the system(s)  and  to determine an SMT thread mapping . For example,  shows an exemplary SMT architecture in accordance with one embodiment of the present invention. As shown, multiple physical processing cores  and  each comprise multiple SMT threads. In the illustrated example, a first physical core  comprises SMT threads  to  and a second physical code  comprises SMT threads  to . Each of the SMT threads of each physical core  and  is mapped to a logical CPU (such as LP  and LPN ) by the O\/S .","The O\/S interference manager  determines the SMT architecture and mapping and stores this information in the SMT thread mapping information . Alternatively, the SMT thread mapping information  can be previously generated and this information  can be accessed to determine the architecture and mapping. Although the example of  shows an \u201cSMT-4\u201d mode in which each physical core has four logical CPUs capable of executing four SMT threads, further embodiments of the present invention are applicable to any \u201cSMT-X\u201d mode, where X>1.","The O\/S interference manager , for one or more of the physical processors  and , identifies a set of logical CPUs from the logical CPUs associated with the physical cores  and  that comprise the least amount of O\/S interference jitter. For example, the O\/S interference manager  analyzes\/monitors each of the logical CPUs  to  of the first physical core  of  to detect O\/S interference\/jitter events. Based on this analysis\/monitoring, the O\/S interference manager  identifies the logical CPUs with the least amount of jitter events. In the example of , logical CPU  and logical CPU  are identified by the O\/S interference manager  as the logical CPUs with the least amount of O\/S interference (from logical CPUs  to ). The O\/S interference manager  then groups one or more of these identified logical CPUs  and  into a set of interference free CPUs for executing an application  of the physical core . One or more of the remaining logical CPUs  and  are then grouped into a set of O\/S interference CPUs where the O\/S jitter events are to occur.","In another embodiment, one or more additional sets of logical CPUs are created from the remaining set of CPUs for handling application tasks, O\/S interference events, and\/or other processes (such as, but not limited to, file system management daemons). While the exemplary embodiment of  shows that two of the logical CPUs of each physical core have been designated as interference free CPUs and the remaining two logical CPUs have been designated as O\/S interference CPUs, any other possible combinations can be designated as long as there is at least one interference free logical CPU and at least one O\/S interference logical CPU.","Once the set of O\/S interference CPUs is identified for a given physical core , the O\/S interference manager  binds the application tasks associated with that physical core  to one or more of the O\/S interference free CPUs  and . For example, an O\/S system call is used to bind the application tasks to one or more of the O\/S interference free CPUs  and . Also, the O\/S scheduling priority of the application can be adjusted (i.e., increased). This adjusting of the O\/S scheduling priority of the application  (i.e., making it more favored) decreases the likelihood that the application  will be preempted by more favored process or thread.","The O\/S interference manager  also identifies the jitter events associated with the physical core . This information, in this embodiment, is stored in the interference source information . Based on identifying the jitter events, the O\/S interference manager  moves\/schedules the jitter events to operate on one or more of the O\/S interference CPUs  and . For example, the O\/S interference manager  masks device interrupts on the O\/S interference free CPUs  and . This redirects the device interrupts to one or more of the O\/S interference CPUs  and . The O\/S interference manager  also moves\/schedules third party daemons and system daemons to the O\/S interference free CPUs  and . Jitter events such as timers, particularly timers that cannot be migrated from an O\/S interference free CPU  to an O\/S interference CPU , are synchronized by the O\/S interference manager  using a globally synchronized clock. For example, if the timers are not synchronized, even a single instance of a timer will slow down the entire application . Synchronizing all N instances of the timer effectively makes these instances a single instance from a jitter point of view, resulting in the application only slowing down one time rather than N times. In another example, the O\/S interference manager  uses a global clock to synchronize a timer, such as the decrementer (i.e., global tick), on all CPUs (logical and physical) in the system to reduce the aggregate jitter effect.","In addition to identifying jitter events associated with the physical core , the O\/S interference manager  also identifies the jitter events associated with each of the applications  to be operated on the physical core . This information can also be stored in the interference source information . Among these application jitter events the O\/S interference manager  identifies the events that are limited to individual process threads, such as a Low-Level Application Programming Interface (LAPI) timer, and moves\/schedules these offending process threads to one or more of the O\/S interference CPUs  and . Any remaining sources of jitter events associated with an application can be tuned by the O\/S interference manager . For example, the O\/S interference manager  can reduce the frequency of a decrementer interrupt by increasing the interval of the decrementer on the O\/S interference free CPUs  and  to avoid interruptions of the applications  running on those logical CPUs  and .","In addition to creating a class of interference and jitter-free logical CPUs, the O\/S interference manager  also manages the interference experienced by an application  executing on one or more of the O\/S interference free CPUs  and  that is caused by O\/S interference\/jitter from another SMT thread  on the same physical core . Examples of this type of O\/S interference\/jitter are SMT thread resource contention, chip-level resource contention (e.g., cache), and node-level resource contention (e.g., memory bus, disk, and adapter).","In this embodiment, the O\/S interference manager  manages O\/S interference\/jitter by limiting or reducing this interference. For example, the O\/S interference manager  co-schedules the O\/S interference by allowing the O\/S interference event to only run for relatively small configurable windows of time, such as 1%-5% of the cycles, which affords the application 95%-99% of the cycles with little or no chance on shared resources. The O\/S interference manager  then utilizes a global clock to synchronize these configurable windows across all nodes used by the application . In one example, the O\/S interference manager  co-schedules the OS\/interference using favored and unfavored windows on one or more of the O\/S interference CPUs  and  to minimize device interrupts generated by the O\/S interference to a small window of time such as about 3% of total cycles. In another example, the O\/S interference manager  co-schedules the O\/S Interference using favored and unfavored windows on one or more of the O\/S interference CPUs  and  to limit potential SMT sister thread interference to a small window of time such as about 3% of total cycles.","The favored co-scheduling windows (which are configured larger) and unfavored co-scheduling windows (which are configured smaller) are created by the O\/S interference manager , for example, by using local and global run queues (LRQs and GRQs) and modifying the O\/S dispatch code to dispatch the interference events based on the favored and unfavored co-scheduling windows. In this embodiment, the interference events are forced onto a GRQ before the application  runs. Some processes (such as the application ) are prevented from being forced onto the GRQ. In one embodiment, the interference events are forced onto the GRQ by an O\/S command. With respect to modifying the dispatch code, the O\/S interference free CPUs  and  are effectively commandeered by the application  (due to the binding and scheduling priority adjustment). However, the modified dispatch code allows the O\/S interference CPUs  and  to dispatch work from both the GRQ and LRQ during an unfavored window. As such, during the favored windows (typically 95%-99% of the cycles) the interference\/jitter on the O\/S interference CPUs  and  cannot interfere (directly or indirectly) with the application . In one embodiment, the O\/S interference manager  notifies the O\/S dispatch code which CPUs are intended for interference\/jitter. The O\/S interference manager  supports per-thread movement from the local to global queue to allow co-scheduling individual threads within an application  that have interference\/jitter impact (e.g., LAPI timer threads). The O\/S interference manager  also supports per-thread movement from the global to local run queue to avoid co-scheduling response time-sensitive threads (e.g., file system management daemon).","O\/S interference\/jitter can further be managed by the application  performing SMT hardware priority adjustment to bias core resources in favor of the O\/S interference free CPUs  and . For example, the application  can raise the priority of the O\/S interference free CPUs  and . In one embodiment, the O\/S interference manager  lowers the priority of the O\/S interference CPUs  and . Adjusting this priority minimizes SMT sister thread interference and ensures that more resources (e.g., FPU) are available to the O\/S interference free CPUs  and . Adjusting SMT hardware priority helps make the O\/S interference free CPUs  and  interference free.","Accordingly, embodiments of the present invention improve parallel application performance by utilizing additional logical CPUs that are not used by applications. A set of logical CPUs are selected based on the mapping of SMT threads to physical cores such that these selected logical CPUs can be dynamically allocated to handle non-application related interruptions in a synchronized manner. The logical CPUs selected to mange O\/S interference and the logical CPUs reserved for applications share physical resources to reduce the interference\/jitter effect on the application CPUs while still maximizing core utilization and throughput.","Operational Flow Diagrams",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 4","FIG. 4"],"b":["402","404","404","102","406","408"]},"The O\/S interference manager, at step , identifies a set of SMT threads\/logical CPUs from the SMT threads\/logical CPUs on the processor that are associated with the least amount of interference\/jitter sources. The O\/S interference manager, at step , designates the set of SMT threads\/logical CPUs as O\/S interference free logical CPUs where the applications are to execute. The O\/S interference manager, at step , designates one or more of the remaining SMT threads\/logical CPUs as O\/S interference logical CPUs where O\/S interference\/jitter events are to be handled. One or more additional sets of logical CPUs can be created from the remaining SMT threads\/logical CPUs. These one or more sets can be used to manage application tasks, O\/S interference events, and\/or other processes (such as file system management daemons). The control flow then exits.",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 5","FIG. 5"],"b":["502","504","504","505","506"]},"The O\/S interference manager, at step , moves third-party and system daemons to the O\/S interference logical CPUs. The O\/S interference manager, at step , migrates timers from the O\/S interference free logical CPUs to the O\/S interference logical CPUs. The O\/S interference manager, at step , synchronizes timers, system daemons, third-party daemons, and other O\/S events using a globally synchronized clock. The O\/S interference manager, at step , identifies sources of interference\/jitter within the application(s) running on the O\/S interference free logical CPU(s). The O\/S interference manager, at step , moves the identified sources (process threads) of interference limited to individual process threads to the O\/S interference logical CPUs. The O\/S interference manager, at step , tunes any remaining sources of interference\/jitter on the O\/S interference free logical CPUs. The O\/S interference manager, at step , performs operations to limit the interference to the application caused by O\/S interference events running on another SMT thread. The control flow then exits.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 6","FIG. 5","FIG. 6"],"b":["520","602","606","608","610","612","614"]},{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 7","FIG. 7","FIG. 7"],"b":["702","704","706","702","708","710","712","704","704","706","708","714","708","706","716","718","720","722","714","704","710","712","708","724","726"]},"While there has been illustrated and described what are presently considered to be the preferred embodiments of the present invention, it will be understood by those skilled in the art that various other modifications may be made, and equivalents may be substituted, without departing from the true scope of the present invention. Additionally, many modifications may be made to adapt a particular situation to the teachings of the present invention without departing from the central inventive concept described herein. Furthermore, one embodiment of the present invention may not include all of the features described above. Therefore, it is intended that the present invention not be limited to the particular embodiments disclosed, but that the invention include all embodiments falling within the scope of the appended claims."],"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIGS. 4-6"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
