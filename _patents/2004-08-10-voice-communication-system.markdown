---
title: Voice communication system
abstract: A voice communication system, in which the real space is associated with a virtual space and a relative location and direction of a communication partner in the real space can be grasped as bodily sensations, is provided. A client  comprises a GPS receiver  and a magnetic sensor  which detects a location of a user of the client  itself in the real space, a presence provider  which sends the location detected by the detection means to a server apparatus, a space modeler  which calculates a location of the user in the virtual space based on the location of the user himself and locations of the other users in the real space, and an audio renderer  which controls sound effects based on the locations of the users in the virtual space.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07634073&OS=07634073&RS=07634073
owner: Hitachi, Ltd.
number: 07634073
owner_city: Tokyo
owner_country: JP
publication_date: 20040810
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CLAIM OF PRIORITY","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["The present application claims priority from Japanese Patent Application JP 2004-155733 filed on May 26, 2004, the content of which is hereby incorporated by reference into this application.","The present invention relates to a technique by which people talk with one another mainly in voice through a medium.","Japanese Patent Laid-Open Publication No. 2002-236031 (hereinafter, referred to as Patent Document 1) discloses a navigation system in which the GPS technique is used to display relative positional information of a user of a portable telephone and his communication partner based on positional information of that user and positional information of the communication partner.","As a conference system using a virtual space, there is FreeWalk, which is a conference system developed by Kyoto University. See, for example, NAKANISHI, Hideyuki, YOSHIDA, Chikara, NISHIMURA, Toshikazu and ISHIDA, Toru, \u201cFreeWalk: Support of Non-formal Communication Using Three-dimensional Virtual Space\u201d, IPSJ Journal, Vol. 39, No. 5, pp. 1356-1364, 1998 (hereinafter, referred to as Non-patent Document 1) and Nakanishi, H., Yoshida, C., Nishimura, T. and Ishida, T., \u201cFreeWalk: A 3D Virtual Space for Casual Meetings\u201d, IEEE Multimedia, April-June 1999, pp. 2028 (hereinafter, referred to as Non-patent Document 2).","FreeWalk is a system in which users of the conference system share a virtual space by three-dimensional graphics, as an image seen from his viewpoint or from a viewpoint that is near to his viewpoint but able to see himself within the range of vision. Three-dimensional graphics is a technique for simulating a three-dimensional space by computer graphics, and, for example, OpenGL (http:\/\/www.opengl.org\/), which is de facto standard, and Direct 3D of Microsoft Corporation are APIs (Application Programming Interfaces) for achieving that end. An image of a conversational partner is shot by a video camera and projected in real time on a virtual screen located in the image seen from, for example, the user's viewpoint. Further, each user can move free in this virtual space. Namely, each user can change his location in this virtual space, using a pointing device or keys of a keyboard. In Non-patent documents 1 and 2, voice is damped as distance increases, but those documents do not mention the below-mentioned three-dimensional audio technique.","Moreover, there is Somewire, which is a conference system developed by Interval Research Corporation. See, for example, U.S. Pat. No. 5,889,843 (hereinafter, referred to as Patent Document 2), U.S. Pat. No. 6,262,711 B1 (hereinafter, referred to as Patent Document 3), and Singer, A., Hindus, D., Stifelman, L., and White, S., \u201cTangible Progress: Less Is More In Somewire Audio Spaces\u201d, ACM CHI '99 (Conference on Human Factors in Computing Systems), pp. 104 to 112, May 1999 (hereinafter, referred to as Non-patent Document 3). Somewire is a system in which users of the conference system share a virtual system and users in the same space can talk with one another. In Somewire, voice is reproduced by high quality stereo audio. Further, Somewire has an intuitive tangible interface, since it employs GUI (Graphical User INterface) that can control a location of a conversational partner in the virtual space by moving a doll-like figure. In Somewire, voice is not damped as distance increases, and the three-dimensional audio technique is not employed.","Furthermore, there is a conference system using the distributed 3D audio technique developed by Hewlett-Packard Company. See, for example, Low, C. and Babarit, L., \u201cDistributed 3D Audio Rendering\u201d, 7th International World Wide Web Conference (WWW7), 1998, http:\/\/www7.scu.edu.au\/programme\/fullpapers\/1912\/com1912.htm (hereinafter, referred to as Non-patent Document 4). The distributed 3D audio technique is a technique that applies a three-dimensional audio technique to a networked system (so-called distributed environment). The three-dimensional audio technique is a technique of simulating a three-dimensional acoustic sp ace, and, for example, Open AL (http:\/\/www.opengl.org\/) prescribed by Loki Entertainment Software Inc. and others and DirectSound 3D of Microsoft Corporation, EAX2.0 (http:\/\/www.atc.dreative.com\/algorithms\/eax20.pdf) of Creative technology, Ltd. are mentioned as APIs for achieving that end. Using the three-dimensional audio technique, it is possible to simulate a direction and distance of a sound source seen from a listener, in sound reproduction using speakers such as headphones or 2- or 4-channel speakers, and to locate the sound source in an acoustic space. Further, by simulating acoustic properties such as reverberation, reflection by an object such as a wall, sound absorption by air depending on distance, sound interception by an obstacle, and the like, it is possible to express an impression of existence of a room and an impression of existence of an object in a space. The three-dimensional audio technique is one of stereo phone reproduction systems. In addition to the three-dimensional audio technique, the stereo phone reproduction systems include simple stereo phone reproduction techniques. For example, may be mentioned a stereo phone reproduction technique that differentiates sound volumes between left and right speakers in headphones to reproduce a plurality of sounds separately.","Sometimes, even if a communication partner on a portable telephone is in a location near to a person (i.e., a location that can be seen from the person), it is difficult for that person to find the communication partner. For example, in a congested amusement park or a downtown station, even if a person is talking with a communication partner through a portable telephone within seeing distance, it is difficult to find the communication partner in a crowd and to approach him. Further, in a construction site or the like, sometimes it is necessary to grasp a working position (station) of an unseen cooperating worker.","Further, in the case where a communication partner in a virtual space (i.e., a communication partner with whom a person is communicating through a medium) exists near in the real space, sometimes communication partner's media sound generated by the three-dimensional audio technique and direct sound in the real space are heard in different directions or at different distances. As a result, there occurs an unfavorable situation that a person turns his face in a different direction when he responds to a hail from a communication partner existing near to him in the real sp ace.","Patent Document 1 displays a location of a communication partner on a map, but does not consider making a partner's location recognized through voice. Further, in the convention systems described in Patent Documents 2 and 3 and Non-patent documents 1-4, a communication partner's location in the real space is not considered.","The present invention has been made taking the above situation into consideration. An object of the present invention is to provide a voice communication system in which the real space is associated with a virtual space, and a relative location and direction of a communication partner in the real space can be grasped as bodily sensations.","To solve the above problems, the present invention calculates locations of a plurality of users in a virtual space, based on positional information of each user in the real space.","For example, the present invention provides a voice communication system for realizing conversation between a plurality of users through a virtual space.","The voice communication system comprises a server apparatus which manages respective locations of the users in a real space, and a plurality of client terminals used respectively by the users.","Each of the client terminals comprises: a location detection means which detects positional information relating to a location of a user of the client terminal itself in the real space; a client sending means which sends the positional information of the user of the client terminal itself in the real space to the server apparatus, with the positional information being detected by the location detection means; a client receiving means which receives positional information relating to a location of each of the other users than the user of the client terminal itself in the real space from the server apparatus; a space modeling means which calculates respective locations of the users in the virtual space, based on the positional information of the user of the client terminal itself and the positional information of each of the other users; and a sound control means which controls sound effects applied to a voice of each of the other users, based on the locations calculated by the space modeling means.","The server apparatus comprises: a server receiving means which receives the positional information of a user of a client terminal in the real space from the client terminal, for each of the plurality of client terminals; a storing means which stores the positional information of each of the users in the real space, with the positional information being received by the server receiving means; and a server sending means which sends the positional information of other users than a user of a client terminal to said client terminal, for each client terminal of the client terminals, with the positional information being stored in the storing means.","Now, embodiments of the present invention will be described.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 1","b":["201","202","203","110","120","130","101"]},"Although three clients exist in the present embodiment, the number of clients is not limited to three and may be two, four, or more. Further, in the present embodiment, the network  consists of a single domain. However, it is possible that a network consists of a plurality of domains, and the domains are connected with one another to enable communication extending over a plurality of domains. In that case, there exist a plurality of presence servers , a plurality of SIP proxy servers , and a plurality of registration servers .","Next, will be described a hardware configuration of the voice communication system.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 2","b":["201","202","203","110","120","130"]},"Each of the clients ,  and  can be implemented by an ordinary computer system comprising a CPU  which executes data processing and calculation according to programs, a memory  from which the CPU  can directly read and write, an external storage  such as a hard disk, a communication unit  for data communication with an external system, an input unit , and an output unit . For example, a portable computer system such as PDA (Personal Digital Assistant), a wearable computer, or PC (Personal Computer) may be mentioned. The input unit  and the output unit  will be described in detail later, referring to .","Each of the presence server , the SIP proxy server  and the registration server  can be implemented as an ordinary computer system at least comprising a CPU  which executes data processing and calculation according to programs, a memory  from which the CPU  can directly read and write, an external storage  such as a hard disk, and a communication unit  for data communication with an external system. For example, a server or a host computer may be mentioned.","The below-mentioned functions of the above-mentioned apparatuses will be each realized when the CPU  executes a certain program (in the case of the client ,  or , a program for a client; in the case of the presence server , a program for the presence server; in the case of the SIP proxy server , a program for the proxy server; and in the case of the registration server , a program for the registration server) loaded onto or stored in the memory .","Next, referring to , will be described the input unit  and the output unit  of the client  and functional components of the client . The clients  and  have similar configurations to the client .","As the input unit , the client  has a microphone , a camera , a GPS receiver , a magnetic sensor , and an operation unit (not shown). As the output unit , the client  has headphones  adapted for the three-dimensional audio technique and a display . The GPS receiver  receives GPS signals from at least three GPS satellites. And for those (at least three) GPS satellites, the GPS receiver  measures a distance between the client  and each GPS satellite and a rate of change of the distance, to calculate a current location of a user who carries the client  in the real space. The magnetic sensor  detects the magnetic field of the earth, and, based on the detection result, calculates a direction (a compass direction) of the user carrying the client  in the real space. Instead of the magnetic sensor , may be used a gyrocompass which detects an angle of rotation of a movable body.","As the functional components, the client  comprises: an audio encoder , an audio renderer , a video encoder , a graphics renderer , a space modeler , a presence provider , an audio communication unit , a video communication unit  and a session control unit .","The audio encoder  converts voice into a digital signal. The audio renderer  performs processing (such as reverberation and filtering) resulting from properties of a virtual space, using the three-dimensional audio technique. The video encoder  converts an image into a digital signal. The graphics renderer  performs processing resulting from the properties of the virtual space. The space modeler  receives positional information and directional information in the real space from the GPS receiver  and the magnetic sensor , to calculate presence such as user's location and direction in the virtual space. The presence provider  sends and receives user's positional information and directional information in the real space to and from the presence server . The audio communication unit  sends and receives an audio signal in real time to and from another client. The video communication unit  sends and receives a video signal in real time to and from another client. The session control unit  controls a communication session between the client  and another client or the presence server , through the SIP proxy server .","Here, the virtual space is a virtually-created space for conference or conversation between a plurality of users, and is managed by the presence server . When a user enters a certain virtual space, the presence server  sends information on the properties of the virtual space, and positional information and directional information in the real space with respect to the other users existing in the virtual space. Then, the space modeler  stores the sent information and the positional information and the directional information of the user of the client  itself in the real space into the memory  or the external storage . Here, the positional information and the directional information are inputted from the GPS receiver  and the magnetic sensor  respectively. The properties of the virtual space include the size of the space, the height of the ceiling, the reflectance ratios\/colors\/textures of the walls and the ceiling, the reverberation properties, and the sound absorption rate owing to air in the space, for example. Among them, the reflectance ratios of the walls and the ceiling, the reverberation properties and the sound absorption rate owing to air in the space are auditory properties, the colors and textures of the walls and the ceiling are visual properties, and the size of the space and the height of the ceiling are both auditory and visual properties.","Next, operation of each function will be described in the order of presence, voice and image.","As for presence, the GPS receiver  and the magnetic sensor  calculate the location and direction of the user of the client  itself in the real space, and input the positional information and the directional information of the user in question to the space modeler . The space modeler  holds properties of the virtual space (such as the size of the space and reverberation properties) and the positional information and the directional information of the other users (existing in the virtual space) in the real space, in the memory  or the external storage . Those properties and the positional information and the directional information are sent in advance from the presence server . Based on the properties of the virtual space and the positional information of the user of the client  itself and the other users, the space modeler  maps the real space to the virtual space. In the case where the virtual space includes the user of the client  itself and a plurality of other users, a user who is nearer to the user of the client  itself in the real space is arranged by the space modeler  at a location nearer to the user of the client  in the virtual space also. The mapping from the real space to the virtual space may be a linear mapping, in which positional information in the real space is scaled down into locations in the virtual space, or a non-linear mapping. A non-linear mapping will be described in the following.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 4","FIG. 4","FIG. 4","FIG. 4"],"b":["201","201"]},"In that case, the space modeler  converts a distance d from another user into arctan(d\/r) (r: a constant), i.e., the length (multiplied by a constant) of an arc on the sphere s. In detail, the first other user existing at the location a (its distance from the user of the client  itself is a length of a line segment extending from u to a) in the real space is mapped into (located at) a location a\u2032 (its distance from the user of the client  itself is a length of an arc ranging from u to a\u2032) in the virtual space. Similarly, the space modeler  maps (locates) the second other user existing at the location b in the real space into a location b\u2032 in the virtual space, and the third other user existing at the location c in the real space into a location c\u2032 in the virtual space. Namely, for each point in the plane p, the space modeler  performs coordinate transformation from the plane p as the real space onto the sphere s as the virtual space. In the above description, it is assumed, for the sake of illustration on the page (figure), that all the users other than the user of the client  itself exist on the above-mentioned cutting plane line. However, even in the case where two or more users other than the user of the client  do not exist on a same line including the user of the client , similar mapping is possible in a three-dimensional space.","Further, in the case where a user other than the user of the client  exists at infinity, the user in question is mapped to (located at) the location d\u2032 in the virtual space. Thus, by mapping infinity into a point of a finite distance, it is possible to talk with another user existing in the same virtual space even if that user is at the longest distance. Further, the space modeler  performs mapping into each location a\u2032, b\u2032, c\u2032, d\u2032 in a state that the upper half of the sphere s as the virtual space is stretched flat.","Further, as a property of the virtual space, the space modeler  holds a radius r (or the radius r multiplied by a constant) of the sphere s as the virtual space, in the memory  or the external storage . Using the radius r of the sphere s, which is held in the memory or the like , , the space modeler  sets the sphere s as the virtual space. The property of the virtual space, i.e., the radius r of the sphere s is managed by the presence server  and notified to the space modeler  of each client. In other words, for all the users existing in the same virtual space, the radius r of the sphere s as the virtual space coincides. As a result, it is possible to make users' senses of distance coincide.","Further the sphere q is the virtual space of the third other user existing at the location c in the real space. Similarly to the space modeler  of the user of the client , the space modeler  of the third other user uses arctan(x) to map (locate) the user of the client  existing at the location u in the real space into a location u\u2033 in the real space.","Then, using the directional information of each user who has mapped into the virtual space, the space modeler  sets a direction of each user. In the case where the direction of the magnetic sensor  does not coincide with the direction of the user (when, for example, a mounting position of the magnetic sensor  is not fixed), or in the case where the magnetic sensor  does not indicate a correct direction owing to magnetic disturbance, it is possible to perform the following operation. For example, in order to make the magnetic sensor  indicate a correct direction, the user turns in a specific direction (for example, in the north) and pushes a reset button on the operation unit  (See ). The space modeler  receives a signal from the reset button and corrects output from the magnetic sensor such that the direction at that point of time is taken for the above-mentioned specific direction. Further, instead of the above-described correction based on an absolute direction (a specific direction), it is possible to consider a method in which another user's direction in the real space is made coincident with his direction in the virtual space. For example, the user turns his face to another user existing in the neighborhood and pushes the reset button, to correct output of the magnetic sensor  such that the direction in the real space is made coincident with the relative direction in the virtual space. In the case where a plurality of correction methods are prepared in the client, the user first selects a method and then pushes the reset button.","The space modeler  sends the positional information and the directional information of the user of the client  itself in the real space to the presence server  through the presence provider . Further, the space modeler  receives the positional information and the directional information of the other users in the real space from the presence server . Namely, the space modeler  receives the positional information and the directional information of the other users through the network , and accordingly it is inevitable delays and jitters occur with respect to the locations and the directions of the other users in the virtual space. On the other hand, a delay and jitters scarcely occur in the location and the direction of the user of the client  itself since the GPS receiver  and the magnetic sensor  directly input information to the space modeler .","As for voice, the microphone  collects voice of the user of the client  and sends the collected voice to the audio encoder . The audio encoder  converts the received voice into a digital signal and outputs the digital signal to the audio renderer . Further, the audio communication unit  sends and receives an audio signal or signals in real time to and from one or more other clients, and outputs the received audio signal or signals to the audio renderer .","Into the audio renderer , digital output signals outputted from the audio encoder  and the audio communication unit , are inputted. Then, using the three-dimensional audio technique, the audio render  calculates how voices of other users (communication partners) are heard in the virtual space, based on the auditory properties of the virtual space and the locations (mapped into the virtual space) of the user of the client  itself and the other users. In the following, referring to , will be described the audio renderer  in detail.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIG. 5","FIG. 5"],"b":["1","2","1","11","1","3","11","1","4","2","1","5","1","2","302","303","1"]},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 6","b":["216","216","201","216","61","221","221","201","221","216","215"],"sub":["i","i","i"]},"Then, for each sound source, the audio renderer  uses the inputted coordinates to calculate the distance and angle (azimuth) between the user of the client  itself and that sound source (S). Here, it is assumed that the user of the client  itself is at the center (coordinates (0, 0)) of the virtual space. Then, the audio renderer  specifies HRIR corresponding to the distance and the angle (asimuth) between the user of the client  itself and each sound source out of HRIR values stored in advance in the memory  or the external storage  (S). Here, the audio renderer  may use HRIR values calculated by interpolation of the HRIR values stored in the memory  or the like.","Then, the audio renderer  performs convolution calculation using the signal string inputted in S and the left channel HRIR of the HRIR specified in S, to generate a left channel signal (S). Then, the audio renderer  adds the respective left channel signals acquired from all the sound sources (S). Further, the audio renderer  performs convolution calculation using the signal string inputted in S and the right channel HRIR of the HRIR specified in S, to generate a right channel signal (S). Then, the audio renderer  adds the respective right channel signals acquired from all the sound sources (S).","Next, the audio renderer  adds reverberation to the left channel signal obtained from the addition (S). Namely, the audio renderer  calculates the reverberation based on how sound changes (impulse response) according to the properties of the virtual space. As methods of calculation of reverberation, may be mentioned a calculation method called FIR (Finite Impulse Response) and IIR (Infinite Impulse Response). These methods are fundamental methods relating to a digital filter, and description of them is omitted here. Further, similarly to the left channel, the audio renderer  adds reverberation to the right channel signal obtained from the above-mentioned addition (S). Although the specification of HRIR (S) and the calculations of reverberation (S and S) are performed for each packet as described above, the convolution calculations (S and S) each generate a part to be carried forward to the next packet. As a result, it is necessary to hold a specified HRIR or a signal string inputted until processing of the next packet.","Thus, by performing processing such as volume control, superposition of reverberation and reflection, filtering and the like on user's (i.e., communication partner's) voice outputted from the audio communication unit , the audio renderer  controls sound effects to obtain sound to be heard at the location of the user of the client  itself in the virtual space. In other words, by performing processing resulting from the properties of the virtual space and a relative location with respect to a communication partner, voice is oriented and reproduced. As a result, a direction of a communication partner whose voice can not be heard directly can be easily grasped through the bodily senses.","Here, it is possible that the audio renderer  performs the processing resulting from the properties of the virtual space, such as reverberation and filtering, on its own user's voice outputted from the audio encoder , if necessary, and thereafter performs rendering of the voice at the position of the head of the user of the client . Its own user's voice generated by the audio renderer  is outputted to the headphones  to be heard by the user himself. When the user of the client  itself hears direct sound of his voice, sometimes the user receives a strange impression, and, in particular, a large delay disturbs the user in his vocalization. Thus, usually, the user of the client  itself is prevented from hearing his own voice. However, it is possible that the user of the client  itself is prevented from hearing the direct sound and made to hear only reverberation of delay within the limit of 10 ms. Thus, it is possible to make the user of the client  itself have bodily sensations relating to the location of the user himself in the virtual space and the size of the virtual sp ace.","As for image, the camera  shoots the head of the user, and the shot images are successively sent to the video encoder . Then, the video encoder  converts the images into a digital signal and outputs the signal to the graphics renderer . Further, the video communication unit  sends and receives a video signal (or signals) in real time to and from one or a plurality of other clients, and outputs the video signal (or signals) to the graphics renderer . Next, the graphics renderer  receives digital output signals from the video encoder  and the video communication unit .","Then, the graphics renderer  calculates (coordinate transformation) how communication partners are seen in the virtual space, based on the visual properties of the virtual space and the locations of the communication partners and the user himself in the virtual space. Those properties and the locations are held by the space modeler . Next, with respect to the communication partners' images outputted from the video communication unit , the graphics renderer  performs processing resulting from the properties of the virtual space, from the viewpoint of the location of the user himself, based on the above-mentioned calculation, to generate image data to be outputted onto a display screen. The image generated by the graphics renderer  is outputted to the display  and reproduced into an image seen from the viewpoint of the user of the client . The user refers to output of the display  at need.",{"@attributes":{"id":"p-0068","num":"0067"},"figref":["FIG. 7","FIG. 4"],"b":["220","201","202","203","201","411","201","412","413","302","303","221","219","201","201","201","221","231","232","201","420"]},"Thus, it is possible to express positional relations between the user of the client  itself and the other users (the client  and ) as communication partners in the virtual space. Further, by fixing the direction of the user of the client  itself in the forward direction, consistency between voice and graphics display is ensured, and locations and directions of the other users can be grasped as bodily sensations. Further, another user existing behind the user of the client  itself can be displayed, and thus favorably, a risk of overlooking another user approaching the user of the client  from the rear is small.","Although not shown in the figure, a scale may be shown on the display , and thus the distance to another user in the virtual space can be accurately expressed. For example, it is considered to use radio buttons or the like to select a scale out of a plurality of candidates, or to use a scroll bar slider to continuously change a scale. When the scale of the displayed plan view is changed immediately after operation of such buttons or a scroll bar slider, it is possible to see the state of distant things, to confirm the location of the user of the client  itself in a room (the virtual space), or to inspect the neighborhood in detail.","Further, although not shown, an image of its own user shot by the camera  of the client  is pasted on the abutter  by texture mapping, an image of the first other user shot by the camera  of the client  on the abutter , and an image of the second other user shot by the camera  of the client  on the abutter . When a user as a communication partner turns, also the texture is turned. Accordingly, it is possible to grasp directions toward which the first and second users face in the virtual space.","For real time voice or image communication, RTP (Real-time Transport Protocol) is used. RTP is a protocol described in the document RFC 3550 issued by IETF (Internet Engineering Task Force). When delay increase is allowable to some degree in voice or image communication, then, it is possible that a communication proxy server for voice or image communication is provided additionally and the audio communication unit  or the video communication unit  communicates voice or image with another client through the communication proxy server.","Hereinabove, the client  of  has been described. In the client , the microphone , the camera , the GPS receiver , the magnetic sensor , the headphones  and the display  are realized by hardware. On the other hand, the audio encoder  and the video encoder  are realized by software, hardware or their combination. Further, the audio communication unit , the video communication unit , the space modeler  and the session control unit  are ordinarily realized by software.","Next, referring to , examples of the clients ,  and  will be described.","A client shown in  has a size and functions near to a PDA or a handheld computer. A client body  comprises a camera , a display , an operation unit , an antenna  and a GPS receiver . Further, a headset connected to the body  comprises headphones , a microphone  and a magnetic sensor . In the case where the magnetic sensor  is provided in the headphones  (for example, on an upper part of a head band), a user can put on the magnetic sensor  at an almost constant angle with the user. The operation unit  has instruction buttons - which inputs various instructions to the client . Among the instruction buttons -, there is a reset button for adjusting a direction of the magnetic sensor  provided in the headphones  when a user puts on the headset. Although the headset shown in the figure is wired to the body , the headset may be connected through Bluetooth or IrDA (infrared) wirelessly. Further, the client is connected to the network  by means of the antenna  through a wireless LAN.","A client shown in  is an example of wearable computer. A client body  that looks like bows of a pair of spectacles is provided with a microphone , a camera , headphones , a display , a GPS receiver  and a magnetic sensor . The display  is a head mounted display, and forms a virtual image several ten centimeters ahead of a user who wears the client body , or forms a three-dimensional image ahead of the user. Further, the client of  has an operation unit  (not shown) connected by wire or wirelessly.","Next, referring to , will be described procedures in the client .",{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 9","b":["201","101","223","120","901","120","130","130","110","130","130","120"]},"Further, as for communication between the presence provider  of the client  and the presence server , it is possible to use a SUBSCRIBE message of SIP prescribed in the document RFC 3265 of IETF. SUBSCRIBE message is an even request message that previously requests reception of a notification at the time of event occurrence. The presence provider  requests the presence server  to notify an event that has occurred with respect to a room list and an attendance list. In the case where the presence provider  uses a SUBSCRIBE message, the presence provider  communicates with the presence server  through the session control unit  and the SIP proxy server .","Next, the presence provider  receives the room list from the presence server  (S). Here, in the case where a SUBSCRIBE message was used in S, then, the room list is received in the form of a NOTIFY message as the above-mentioned event notification message. Then, the presence provider  shows the received room list on the display  (S).",{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 10","b":["201","220","222","201","226","1001","222","110","1002","201","201","321","322","221","221","302","303","222","302","303"]},"Or, a SUBSCRIBE message of SIP may be used for sending an entrance message. Namely, a SUBSCRIBE message whose recipient is the selected room is used as an entrance message. A SUBSCRIBE message requests notification of events (for example, entrance, exit and movement of a user, and changes in the properties of the virtual space) occurred in the virtual space of the selected room.","Next, the presence provider  receives an attendance list listing users (other than the user of the client  itself) who are now in the selected room from the presence server  (S). When a SUBSCRIBE message is used as the entrance message, the attendance list in the form of a NOTIFY message corresponding to the SUBSCRIBE message is sent to the presence provider . It is assumed that the attendance list includes at least user identification information of the users in the room other than the user of the client  itself, their positional information and directional information in the real space, and the virtual space properties of the designated room. The virtual space properties includes the radius r of the sphere s as the virtual space shown in  or the radius r multiplied by a constant (hereinafter, referred to as a virtual space radius or the like).","Although a procedure which exits a room is not shown, the presence provider  receives an exit instruction from the user and sends an exit message including the user identification information to the presence server .",{"@attributes":{"id":"p-0085","num":"0084"},"figref":"FIG. 11","b":["221","231","232","1101","221","302","303","1101","1102","231","232"]},"In the case where the received positional information and the like are same as the positional information and the like stored in the memory or the like, i.e., the user of the client  itself neither moves nor changes his direction in the real space (NO in S), the space modeler  returns to S without performing the following processing.","In the case where the received positional information and the like are different from the positional information and the like stored in the memory or the like, i.e., the user of the client  itself moves or changes his direction in the real space (YES in S), the space modeler  stores the received positional information and the like into the memory or the like. Then, using the positional information and the like after the movement, the space modeler  changes the mapping or the direction of the user in the virtual space (S). The mapping into the virtual space is the non-linear mapping (described in ) between the real space and the virtual space. The space modeler  locates the user of the client  itself at the center of the virtual space, and locates again the locations of the users existing in the same virtual space other than the user of the client  by the non-linear mapping.","Next, the space modeler  notifies the audio renderer , the graphics renderer  and the presence provider  of the positional information and the like after the movement (S). As described referring to , the audio renderer  calculates how voices of the communication partners are heard at the location and direction of the user of the client  in the virtual space. Here, the mentioned location and direction have been mapped onto the virtual space based on the positional information and the like in the real space. Then, based on the calculation, the audio renderer  performs processing such as volume control, reverberation, filtering and the like on the voices of the other users (the communication partners) outputted from the audio communication unit , and controls sound effects to obtain sound to be heard by the user of the client  at his location in the virtual space and updates the three-dimensional sound. Further, the graphics renderer  changes the viewpoint based on the location and direction of the user of the client  in the virtual space. Here, the mentioned location and direction have been mapped onto the virtual space based on the positional information and the like in the real space. And, the graphics renderer  calculates how the communication partners are seen in the virtual space (See ). Then, the graphics renderer  generates image data to output on the screen as a view seen from that location in that direction, and updates the display screen.","Next, the presence provider  notifies the presence server  of the positional information and the like in the real space after the movement (S). When the SIP protocol is used, a NOTIFY message is used. A NOTIFY message is usually sent as a result of receiving a SUBSCRIBE message. Thus, it is considered that, when the presence server  receives an entrance message from the client , the presence server  sends not only the attendance list but also a SUBSCRIBE message corresponding to the above-mentioned NOTIFY message. Receiving the positional information and the like in the real space, which have been notified from the presence provider , the presence server  updates the positional information and the like of the user in question in the attendance list.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 12","b":["110","201"]},"The space modeler  receives the positional information and the like of a user of another client from the presence server  through the presence provider  (S). The presence server  notifies (sends) the positional information and the like sent from the client  in S of  to the other clients than the client , i.e., the sender. Then, the space modeler  stores the notified positional information and the like into the memory or the like. Further, using the notified positional information and the like, the space modeler  maps the other users into the virtual space or change the directions of the other users (See ). Then, the space modeler  notifies the audio renderer  and the graphics renderer  of the positional information and the like in the virtual space after movement (S). As described with respect to S of , based on the notified location and direction of another user, the audio renderer  and the graphics renderer  update the three-dimensional sound of that user and the display screen.","Next, will be described a functional configuration and procedures of the presence server . The registration server  and the SIP proxy server  are similar to ones in the conventional communication using SIP, and their description is omitted here.",{"@attributes":{"id":"p-0093","num":"0092"},"figref":["FIG. 13","FIGS. 9 and 10"],"b":["110","110","111","112","113","114","114","110","110","114","302","303"]},{"@attributes":{"id":"p-0094","num":"0093"},"figref":"FIG. 14","b":["110","110","110","111","1411","112","111","1412"]},"In the case where the message is a login message, the processing unit  instructs the interface unit  to send a room list to the client of the message source (S). The interface unit  sends the room list to the client of the message source. Thereafter, the procedure returns to S, to await a next message.","In the case where the massage is an entrance message, the processing unit  adds the user of the message source to the attendance list of the designated room (S). Namely, the processing unit  adds the identification information of the user in question and the positional information and the directional information of the user in the real space to the attendance list. Next, the processing unit  instructs the interface unit  to send the identification information and the positional information and the directional information of all the attendance (except for the user in question) of the designated room to the client as the message source. Further, the processing unit  instructs the interface unit  to send the virtual space properties of the designated room to the client as the message source. The virtual space properties include the radius r of the sphere s as the virtual space shown in  or the radius r multiplied by a constant (hereinafter, referred to as the virtual space radius or the like). According to the above instructions, the interface unit  sends those pieces of information to the client as the message source (S). Then, the procedure goes to S described below.","In the case where the message is a movement message, the processing unit  updates the positional information and the directional information of (the user of) the client as the message source in the real space, in the attendance list (S). The positional information and the directional information are included in the movement message. Then, the processing unit  instructs the interface unit  to notify the identification information and the positional information and the directional information of the client as the message source to the clients of all the attendance of the room in question (except for the client as the message source) (S). According to the instruction, the interface unit  sends those pieces of information to the clients, and returns to S. This is same with the case of the entrance message (S).","In the case where the message is an exit message, the processing unit  deletes the user of the client as the message source from the attendance list (S). Then, the processing unit  instructs the interface unit  to notify the clients of all the attendance of the room in question (except for the client as the message source) of the exit of the user in question from the room (S). According to the instruction, the interface unit  sends the information to the clients, and returns to S.","Although not shown, the presence server  may receive a request (input) from an administrator of the presence server  to change the virtual space properties. For example, the judgment unit  receives an instruction inputted from the input unit  of the presence server  that the virtual space radius or the like should be changed. This instruction includes identification information which identifies a room as an object of the change and the virtual space radius or the like after the change. Then, the processing unit  changes the virtual space radius or the like stored in the storage unit  with respect to the room as the object of the change. Then, the processing unit  reads the attendance list stored in the storage unit  and notifies the changed virtual space radius or the like to the clients of all the users in the room as the object of the change. The space modeler of each client notified of the change maps each user in the real space onto the sphere s (shown in ) having the changed virtual space radius or the like.","Hereinabove, the present embodiment has been described.","According to the present embodiment, a relative location and direction of a communication partner in the real space can be easily grasped through voice (media sound) of the communication partner as bodily sensations. Accordingly, users can have a natural conversation with one another in a virtual space and in the real space.","In the voice communication system of the present embodiment, each user is mapped onto a virtual space, based on a location and a direction of that user in the real space. As a result, even when a communication partner is at a distant place where his voice (direct sound) can not be heard in the real space, a relative location and direction of the communication partner can be easily grasped through voice (media sound) of the communication partner as bodily sensations. Thus, it is possible to easily find and approach the communication partner in a crowd.","Further, in the present embodiment, a direction in which a communication partner exists in the real space coincides with a direction in a virtual space. Accordingly, when a communication partner is at a point-blank distance from which his voice (direct sound) can be heard, it does not happen that the voice (direct sound) in the real space and voice (media sound) in the virtual sound are heard in different directions from each other. Thus, there does not occur an unfavorable situation that a person turns his face in a different direction when he responds to a hail from a communication partner.","The present invention is not limited to the above-described embodiment, and can be variously changed within the scope of the invention.","For example, the client  of the above embodiment is provided with the camera , the video encoder , and the like and outputs image data of the virtual space to the display . However, the voice communication system according to the present invention is a system using voice communication mainly. Thus, the client  does not need to output image data of the virtual space to the display . In that case, the client  does not have a camera , a video encoder , a display , and the like.","Further, in the present embodiment, the graphics renderer  uses a plan view (two-dimensional data) to express a virtual space (See ). However, it is possible that the graphics renderer  uses a three-dimensional graphics technique to display a virtual space more clearly. In other words, based on three-dimensional data stored in the memory  or the external storage , such as the size of the space, properties (for example, materials of walls and a ceiling) of the virtual space, and locations and directions of the user of the client  and the other users in the virtual space, the space modeler  can generate a two-dimensional image to be shown on the display .","Further, the audio renderer  can perform the following processing on another user's (communication partner's) voice (media sound) outputted from the audio communication unit . For example, the audio renderer  may perform filtering on media sound so as to have impulse response that is impossible in the case of real voice (direct sound). Or, the audio renderer  may add reverberation that is different from reverberation of the real voice (direct sound) to another user's (communication partner's) voice (media sound) so that the sense of distance from the sound source can be recognized. Or, the audio renderer  may add noise to another user's (communication partner's) voice (media sound). In that case, even when a user as a communication partner is at a point-blank distance from which his real voice (direct sound) can be heard in the real space, it is easily judged whether communication partner's voice is real sound or media sound.","Further, in the case where a communication partner is at a distance from which his real voice (direct sound) can be heard in the real space, the communication partner's real voice (direct sound) and voice (media sound) outputted from the audio communication unit  are both heard. In that case, when a delay of the media sound is small, the media sound is used for orientation. On the other hand, when a delay of the media sound is too large, the media sound is heard, for example, like an independent sound source having no relation with the direct sound, thus causing confusion. Thus, in the case where a communication partner exists within a predetermined point-blank distance, the audio renderer  may control a delay time of communication partner's voice (media sound) to be within a certain range. When a delay of the media sound is larger than the direct sound and within a certain range, the media sound is heard as reverberation (echo) of the direct sound. In that case, the direct sound is used for orientation and occurrence of confusion can be prevented. Further, the audio renderer  may lower sound volume of voice (media sound) of a communication partner existing at a point-blank distance, by a certain amount or at a certain rate. In that case, the sound volume can balance with sound volume of a communication partner at a long distance from which only media sound can be heard.","A wireless communication technique Bluetooth may be used for judging whether a communication partner exists at a point-blank distance from which direct sound can be heard in the real space. Namely, when data can be sent and received using Bluetooth, then it is judged that the communication partner exists at a point-blank distance.","The client of the present embodiment uses the GPS receiver  and the magnetic sensor  to detect a location and direction of its user (client). However, a sensor network may be used for detecting a location and direction of a user (client). When a sensor network is used, user's location and direction can be detected even when the user uses the client indoors.","In the present embodiment, each client directly performs voice communication and makes three-dimensional voice from voice inputted from another client (See ). However, in the case where processing and communication performance of a client is lower, such processing may be performed by a server. In other words, a sound server may be added newly to the network configuration shown in . In the following, will be described an embodiment having a sound server.",{"@attributes":{"id":"p-0112","num":"0111"},"figref":["FIG. 15","FIG. 1","FIG. 15","FIG. 3","FIG. 6"],"b":["140","201","202","203","216","215","140"]},{"@attributes":{"id":"p-0113","num":"0112"},"figref":"FIG. 16","b":["140","140","141","142","143","144","140","141","144","141","144","141","142","134","144","140","141","144"]},"Further, the sound server  further comprises a space modeler . The space modeler  receives a location of each user in the real space and properties of a virtual space (such as a virtual space radius or the like) from the presence server , and maps (locates) the location of each user onto the virtual space by processing similar to the processing of the space modeler  of the client  shown in .","Each audio receiving unit  receives voice inputted from the audio communication unit  of the client concerned. Each audio renderer  makes three-dimensional voice and outputs two-channel (left and right channels) signal data (a signal string) corresponding to the client concerned to the mixers  associated with respective clients. Namely, based on a location of each user in the virtual space arranged by the space modeler , each audio renderer  performs processing similar to the processing by the audio renderer  of the client shown in , i.e., reception of sound source input (S of ), calculation of a distance and an angle (S), specifying of HRIR (S) and convolution calculation (S and S). Each mixer  receives two-channel signal data from each audio renderer  and performs processing similar to the processing of the audio renderer  of the client shown in , i.e., mixing (S and S) and reverberation calculation (S and S). Then, each mixer  outputs two-channel signal data to the corresponding audio sending unit . Each audio sending unit  sends the received two-channel signal data to the corresponding client.","Next, will be described processing by the presence server  and the clients. When the presence server  notifies a user name (or names), a location (or locations) of a user (or users) concerned, and the virtual space radius or the like to the client (or clients) concerned, in the steps S, S and S, the presence server  also notifies these pieces of information to the sound server . Thus, when each client enters a room, that client performs voice communication with a predetermined communication port of the sound server  (or with a communication port notified from the presence server  at the time of entrance). Namely, the audio communication unit  of each client sends a one-channel voice stream to the sound server , and receives a two-channel voice stream from the sound server .","Next, will be described processing by the sound server . Each audio receiving unit  associated with a client receives and buffers a voice stream from that client, to send signal data, which is synchronized (associated) with voice streams of all other input clients, to the audio renderer  associated with that client. A method of this buffering (Play-out buffering) is described in the following document, for example.","Colin Perkins: RTP: Audio and Video for the Internet, Addison-Wesley Pub Co; 1st edition (Jun. 11, 2003)","Then, based on the location of each user in the virtual space arranged by the space modeler , each audio renderer  performs the processing of distance\/angle calculation, specification of HRIR and convolution calculation (S-S and S in ). Then, each mixer  performs the mixing (S and S in ) and the reverberation calculation (S and S in ), and outputs two-channel signal data corresponding to the client concerned. Each audio sending unit  sends the two-channel signal data to the client concerned. Thus, even in the case where processing performance of clients is low, it is possible to realize three-dimensional voice.","Further, the presence server  may have the functions of the above-described sound server . In other words, without providing a sound server , the presence server  not only manages locations of the users, virtual space properties, and the like, but also performs the above-described processing of the sound server ."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 8B"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 16"}]},"DETDESC":[{},{}]}
