---
title: Image processing system providing selective arrangement and configuration for an image analysis sequence
abstract: A computer-implemented method of processing a selected image using multiple processing operations is provided. An image analysis sequence having multiple processing steps is constructed. The image analysis sequence is constructed in response to receipt of multiple processing operation selections. Individual processing steps in the image analysis sequence are associated with a processing operation that is indicated in a corresponding processing operation selection. The processing steps are arranged in response to receipt of arrangement information that relates to a selective arrangement of the processing steps. At least one of the processing steps in the image analysis sequence is configured such that the processing operation associated with the processing step processes a specified input image to generate an output image when the processing step is performed. A display signal is generated for display of the output image at a display device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08577079&OS=08577079&RS=08577079
owner: Molecular Devices, LLC
number: 08577079
owner_city: Sunnyvale
owner_country: US
publication_date: 20110902
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This invention relates to image processing and more particularly to identifying and measuring objects in an image.","To extract meaningful data from biological images, researchers may execute a series of image processing and measurement operations on one or more biological images. Researchers apply processing and measurement operations to a biological image as a series of steps. Operation categories may include operations for modifying, manipulating, and measuring the biological images. Each category may include multiple operations configurable by a variety of parameters. As a result, many permutations of image processing and measurement sequences are possible.","Known image process and measurement systems may provide atomized operations or pre-defined image analysis sequences. Pre-designed image analysis sequences may not provide the flexibility to modify the sequence or the individual steps of the sequence. Additionally, while atomized operations may provide relatively more control over the image analysis sequence, researchers may have difficulty identifying how choices for the arrangement and configuration of the individual operations in the analysis sequence affect the analysis as a whole.","Therefore, a need exists for an image analysis system that provides feedback relating to the particular arrangement and configuration of the individual operations in the sequence.","A computer-implemented method of processing a selected image using multiple processing operations is provided. An image analysis sequence having multiple processing steps is constructed. The image analysis sequence is constructed in response to receipt of multiple processing operation selections. Individual processing steps in the image analysis sequence are associated with a processing operation that is indicated in a corresponding processing operation selection. The processing steps are arranged in response to receipt of arrangement information that relates to a selective arrangement of the processing steps. At least one of the processing steps in the image analysis sequence is configured such that the processing operation associated with the processing step processes a specified input image to generate an output image when the processing step is performed. A display signal is generated for display of the output image at a display device.","An image analysis system for processing a selected image is also provided. A processing operation library provides multiple processing operations that respectively process the selected image when the processing operations are executed. An image analysis sequence module constructs an image analysis sequence having multiple processing steps in response to receipt of multiple processing operation selections. The individual processing steps in the image analysis sequence are associated with a processing operation that is indicated in a corresponding processing operation selection. The image analysis sequence module arranges the processing steps in the image analysis sequence in response to receipt of arrangement information that relates to a selective arrangement of the processing steps. The image analysis sequence module also configures at least one of the processing steps in the image analysis sequence module in response to receipt of configuration information such that the processing operation associated with the processing step processes a specified input image to generate an output image when the processing step is performed. A display signal is generated for display of the output image at a display device.","An image analysis system and method are provided. The image analysis system provides selective arrangement and configuration of steps in an image analysis sequence. The image analysis system also advantageously provides for the display of the results of each step in the image analysis sequence. If a user is dissatisfied with the results of a step in the image analysis sequence, the user may reconfigure that step or add additional steps to the sequence in order to achieve the desired results.","Referring to , an example of an implementation of an image analysis system  is shown. The image analysis system  includes various modules for creating and executing an image analysis sequence . As seen in , the image analysis system  includes: a memory module  that stores the images  processed by the image analysis system ; a processing module  having one or more processing units  that executes instructions related to processing and analyzing the images ; and a user interface module  that receives user input related to the image analysis sequence  and that displays information related to the image analysis sequence  and processing results. The user interface module  may receive the user input from one or more user input devices . The user interface module  may display information related to the image analysis sequence  on a display device . For example, the user interface module  may generate a display signal that includes a user interface (), and the user interface may include the results of the image analysis sequence .","The image analysis system  also includes: an image analysis sequence module  that maintains the image analysis sequence  under construction; and a processing operation library  having multiple processing operations and processing operation categories for processing and analyzing the images . In response to receipt of user input, the image analysis sequence module  constructs the image analysis sequence , arranges the processing steps  of the image analysis sequence , and configures the processing steps  of the image analysis sequence . Accordingly, the user input may include selections for the processing operations, arrangement information, and configuration information for selective construction, selective arrangement, and selective configuration of the image analysis sequence .","The image analysis system  may also include, as shown by way of example in : an image selection module  that provides selective access to the images  to be processed; a flow control module  that provides selective configuration of the order of execution of the processing steps  in the image analysis sequence ; a variable control module  for creating variables for use as input parameters in the processing steps ; and an external interface module  that manages communications between the image analysis system  and an external system  in signal communication with the image analysis system . The images  stored at the memory module  may be, for example, TIFF images (Tagged Image File Format) although other image formats may be selectively employed.","As seen in , the image analysis sequence module  maintains the image analysis sequence  under construction. The image analysis sequence  includes multiple processing steps  for processing and analyzing one or more images . In this example, the individual processing step  of the image analysis sequence  may be associated with a processing operation in the processing operation library . Corresponding processing operation selections may respectively indicate the processing operations for the processing steps . Additionally, the processing steps  may provide access to operational parameters  thus allowing a user to selectively configure the execution of the processing operations.","The processing operations may be selectively configured via inputs, process the inputs, and generate outputs when executed. The outputs for the processing operations may be, for example, processed output images, groups of objects identified in an image, measurement data, classification labels, and statistical data for the measurement data. The outputs of a processing step  in the image analysis sequence  may be selected as the inputs in another processing step  in the image analysis sequence .","The processing operation library , in this example, includes various processing operation categories each having multiple image operations. The processing operation library shown in  includes, for example: image processing operations ; object processing operations ; classification operations ; measurement operations ; and measurement analysis operations .","Image processing operations  relate to processing operations that process the image data in an image . For example, image processing operations  may include operations to adjust the pixels in an image  such as, e.g.: an operation to invert an image ; an operation to remove bright regions of an image ; an operation to remove dark regions of an image ; and an operation to respectively adjust the intensity of the pixels in the image . Image processing operations  may also include operations that operate on multiple images . For example, the image processing operations  may include operations that compare two images  such as, e.g.: an image processing operation that generates a difference image by subtracting one image  from another image ; an image processing operation  that generates a ratio image by taking the ratio of one image  to another; and an image processing operation  that determines a change in fluorescence between two images . An image processing operation  may also generate more than one image . For example, a color un-mixing operation may separate an image  into its component colors, i.e., generate three images  each respectively corresponding to the red, green, and blue (RGB) channels of the image . Other image processing operations  may include, for example: an operation to correct for uneven illumination in an image ; an operation to generate a projection image from an image  acquired through a focus; and operations for smoothing an image  and unsharp masking an image . It will be understood that additional or alternative image processing operations  may selectively be employed.","Object processing operations  relate to processing operations that identify and modify objects in an image . Object identification operations may include both object detection operations and object segmentation operations. Object detection operations determine whether an object is present at a location in an image  and identify a set of objects for an image ; this process may be referred to as object detection. Object segmentation operations determine, for example, which pixels in an image  are associated with a detected object; this process may be referred to as object segmentation. Object modification operations  may, for example, may modify the segmentation (i.e., the set of pixels) associated with a detected object. Additional or alternative object processing operations  may be selectively employed.","The object identification operations, in this example, may send information relating to the identified objects to the memory module  for storage in respective data structures (not shown). The object data structures may include, for example, information relating to the position of the object in the image , the set of objects an object belongs to, and the segmentation for the object (i.e., the image pixels associated with the object). The object segmentation operations  may, for example, determine a pixel run list for a detected object. A pixel run list is a list of pixel runs for an object. A pixel run includes an (x, y) pixel coordinate and the number of consecutive pixels along the horizontal x-axis that are associated with a detected object. The pixel run list may also be extended for three-dimensional objects distributed across a series of two-dimensional images  by adding a third z-coordinate to the pixel run. Object segmentations may be generated from an image  using, for example, a local or adaptive threshold, graph cut procedures, template matching or template fitting, a watershed applied to the image , an initial set of seed segmentations, machine learning techniques, etc. Object detection can be performed using, for example, with or without object segmentation techniques, using, for example, template matching or template fitting, machine learning or trained systems, peak detection, and the like.","Referring to  and , two examples of object detection and object segmentation are shown. The images in  and  correspond to a biological sample imaged under different illumination conditions. The image in  was acquired under one illumination condition to reveal a cytoplasm marker. The image in  was acquired under a different illumination condition to reveal a nuclear marker. As seen in , the image includes two blob-shaped elements and that correspond to the cells in the biological sample. Similarly, in , the image includes two oval-shaped elements and that correspond to the nuclei for the cells in the biological sample.","An object detection operation may determine that two objects\u2014and in and in FIG. B\u2014are present in each of the images and based on the blob-shaped elements and in  and the oval-shaped elements and in . Accordingly, the object detection operation may create a respective object set for each image: a first object set for the image in  that includes two blob-shaped objects and ; and a second object set for the image in  that includes the two oval-shaped objects and . Further, because the objects -and -are different representations for the same cells in the biological sample, the object detection operation may identify and store a relationship between the objects -and -. For example, the object identification operation may identify: a relationship between the first object in  and the first object in ; and a relationship between the second object in  and the second object in . Identifying relationships between objects identified in different images  () may allow the image analysis system  to track objects across a series of images . Additionally, an object segmentation operation may determine which pixels in the images and of  and  correspond to each blob-shaped object and and each oval-shaped object and respectively. In this way, the image analysis system may use an object identified in one image when processing and analyzing another image. As shown in  for example, the second object in  may be used to determine the maximum pixel intensity in  within the pixel area  for the object.","Referring back to , the processing operation library , in this example, also includes various object processing operations  to modify objects in an image , i.e., adjust the segmentation associated with an object. As an example, an object modification operation  may expand or shrink the segmentation for the object by respectively adding pixels to or removing pixels from the segmentation associated with the object.","Object processing operations  may further include operations to find objects in an image  and create a new set of objects for the image  based on one or more criteria. For example, a filtering operation as part of the object processing operations  may create a new set of objects for an image based on the size, shape, or the texture of the segmentation associated with an object.","Object processing operations  may also create new images  based on the objects detected in an image  and the segmentations associated with the detected objects. For example, an object processing operation  may create a binary image based on an object set for an image  where the pixel intensity of a pixel in the binary image equals 1 if the corresponding pixel is associated with an object and equals 0 if the corresponding pixel is not associated with an object. A binary image is an image where each pixel in the image is one of two possible colors (e.g. black and white).","The processing operation library , in this example, also includes measurement operations . Measurement operations  relate to operations that measure various properties of the identified objects in an image . The measurement operations  may include, for example, operations to measure the size, shape, texture, and pixel intensity of segmentations respectively associated with detected objects in an image . Measurement operations  may also measure objects across multiple images . For example, an object measurement operation  may determine the velocity of an object moving through a biological sample. As another example, an object measurement operation may determine a ratio of pixel intensities for objects in a series of images  that are acquired under different illumination conditions as discussed above. The measurement operations  may store measurements associated with identified objects or object sets at the memory module of the image analysis system . Additional measurement operations  may include, for example, volumetric measurements of objects collected in a z-series of images as well as measurement operations to measure biologically relevant values (e.g., nuclear intensity, vesicle count, neuronal branches, etc.).","In addition to measurement operations , the processing operation library , in this example, includes measurement analysis operations  that relate to operations for analyzing the measurement data and generating representations of the measurement data. For example, the measurement analysis operations  may include operations to perform curve fitting, peak detection, and other statistical analyses on the measurement data for the objects in an image. The measurement analysis operations  may also include operations to generate, for example, graphical displays of the measurement data or data related to the statistical analyses of the measurement date. For example, measurement analysis operations  may create graphs, charts, tables, histograms, and other graphical representations of the measurement data for visual presentation of the information.","The processing operation library , in this example, also includes classification operations , which relate to operations that classify (or categorize) identified objects in an image . The classification operations  may classify identified objects based on, for example, the measurement data associated with the objects (e.g., size, shape, texture, pixel color, pixel intensity, etc.). Various automated, semi-automated, or machine learning approaches may be employed to classify the identified objects based on the measurement data. Automated clustering techniques may be selectively employed for object classification, e.g., clustering, self-organizing maps, neural networks, Bayesian-Markov chains, etc. The classification operations  may label an object to identify the class or category the object belongs to. The memory module  may store the classification label in the data structure for the object.","It will be understood that, in this example, a user may set an output image (or series of output images) generated by one processing operation of one image processing step  as an input image parameter  (or series of input images) for a processing operation of a subsequent image processing step . For example, if an image inversion operation generates an inverted image as an output image, then inverted image may be set as the input image parameter  for an object detection operation to detect objects in the inverted image. Likewise, an object (or object set) identified by one operation may be set as an input parameter  for a subsequent operation. For example, a find object operation may generate a set of objects in an image that match an illumination condition, and the set of objects matching the illumination condition may be set as an input parameter  for a subsequent grayscale operation. Similarly, the measurement data set generated by a measurement operation  may be set as an input data set parameter  for a subsequent measurement analysis operation .","The image analysis system  may also include a flow control module  that may be used to control the flow of the image analysis sequence . The flow control module  may provide sequence flow options that implement, for example, a loop in the image analysis sequence  such that one or more processing steps  in the image analysis sequence  are repeated when the sequence  is executed. The flow control module  may also provide sequence flow options to implement, for example, conditional execution of the image analysis sequence  such that different processing steps  are executed depending upon whether a condition is satisfied. As another example, the flow control module  may additionally provide sequence flow options to implement interrupts during execution of the image analysis sequence  so that the image analysis system  may receive user input before continuing execution of the image analysis sequence . When the flow control module  interrupts execution of the image analysis sequence , the user may, for example: set or modify input parameters  for a processing step ; adjust the current display of the image ; select measurement data, a subset of objects in an object set, or regions of interest on an image  for further processing and analysis. Additional or alternative interactive steps  may be selectively employed. When the user has finished, the user may instruct the image analysis system  to continue executing the image analysis sequence  by selecting, for example, a \u201cContinue\u201d button. A user may adjust the flow control settings for an image analysis sequence  using, for example, scripts or programmatic statements supplied to the image analysis system . Flow control statements may also be implemented, for example, as steps  in the image analysis sequence  with start value, end value, and increment as the parameters  for the flow control step. In turn, one or more image processing steps may be associated with the flow control step for execution in accordance with the flow control parameters . Flow control steps may include, for example, looping steps, \u201cfor\/next\u201d steps, \u201cif\/then\/else\u201d steps, \u201crepeat until\u201d steps, etc. As an example, a flow control step  may be included in an image analysis sequence  to grow an object by four pixels ten times (i.e., loop ten times) or, alternatively, grow an object until (i.e., repeat until) the object is one hundred pixels wide).","The image analysis system  may additionally include a variable control module . As mentioned above, users may configure the processing operations associated with the processing steps  of the image analysis sequence  using various input parameters . The values for the input parameters  may be fixed (e.g., fixed numerical values) or variable. The variable control module  provides options to define variables for use as input parameters  for the processing operation of the processing step . As an example, the image analysis sequence  may include a processing step  for a measurement operation that measures the maximum pixel intensity of segmentations for detected objects in an image . A user may define a variable that equals, for example, the maximum intensity value divided by two (i.e., var=Intensity\u00f72). The variable may then be set as the value for an input parameter  in a step for a filter operation that filters objects in an image  based on the respective intensities of the object segmentations.","Still referring to , the image analysis system  may also include an image selection module  for managing access to images  processed and analyzed by the image analysis system . As discussed above, output images may be used as input images for processing operations of subsequent image processing steps  in the image analysis sequence . The image selection module  provides access to images  other than those currently being processed and analyzed. The image selection module  may provide direct access to a particular image  in an image series based on, for example, a particular time point (e.g., time point  or time point ) or z-position (e.g. z-position  or z-position ). Additionally, the image selection module  may provide relative access to an image in an image series (e.g., current time point minus one, current time point minus ten, current z-position minus one, z-position minus 10, etc.). The image selection module  may also provide access to an image  in an image series based on a combination of direct and relative values (e.g., current time point minus one and z-position ). The image selection module  may also provide access to images external to the image analysis system at an external system .","The external system  may be, for example, a file system, a database, or a network (e.g., the Internet). Accordingly, the image selection module  may retrieve images using, for example, a filename, a uniform resource identifier (URI) such as a uniform resource locator (URL), or a database query. The image analysis system  may be in signal communication with additional or alternative external systems  and may employ additional or alternative approaches to retrieving images.","The external system  may also be, for example, a bioanalytical instrument that images biological samples to generate biological images. The bioanalytical instrument may be, for example, a high-content screening system that performs cellular imaging to generate microscopy images. Accordingly, the image analysis sequence module  of the image analysis system  may receive microscopy images from the bioanalytical instruments. The image analysis system  may be in signal communication with additional or alternative bioanalytical instruments that image biological samples.","The external system  may also be an auxiliary system that includes auxiliary image processing modules that may assist some of the processing operations during execution of the image analysis sequence . The image analysis system  may exchange image data and measurement data with these auxiliary systems and auxiliary image processing modules during execution of the image analysis sequence . The auxiliary image processing modules may include, for example, MetaMorph\u00ae Microscopy Automation & Image Analysis Software, ImageJ, Matlab\u00ae, and the like. The image analysis system  may communicate with these auxiliary image processing modules via the appropriate application programming interface (API) for the modules. The image analysis system  may be in signal communication with additional or alternative auxiliary systems and image processing modules.","The image analysis system  may be in signal communication with the external system  in a wired or wireless fashion via an external communication interface . Accordingly, the external communication interface  may be any type of external bus or communication interface such as, for example, universal serial bus (USB), Ethernet port, or wireless transceiver that exchanges wireless communications with the external system .","The image analysis system  also includes a user interface module  that receives user input related to the creation, modification, and execution of the image analysis sequence . The user interface module  also displays information related to the image analysis sequence  and the results of the image analysis sequence . The user interface module  may be in signal communication with a display device  and one or more user input devices . The display device  may be any device capable of converting electrical signals into a visually perceivable form. For example, the display device  may be, but is not limited to, a liquid crystal display (LCD), a cathode-ray tube (CRT) display, an electroluminescent display (ELD), a heads-up display (HUD), a plasma display panel (PDP), an organic light emitting diode (OLED) display, a vacuum fluorescent display (VFD), and the like. The user interface devices  may include, for example, a keyboard, a keypad, a pointing device (joystick, stylus, mouse, touchpad, touchscreen, trackball, and the like), and other input devices suitable for providing user input to the image analysis system.","Referring now to , an example of an implementation of a user interface  for an image analysis system  is shown. As seen in , the user interface  includes various components for creating and configuring an image analysis sequence  and viewing the results of the image analysis sequence . In this example, the user interface  includes: an operation toolbar  that provides the operations available for the image analysis sequence; an image analysis sequence  that displays the steps  of the image analysis sequence under construction; an operation result display  the displays the results for the currently selected step  in the image analysis sequence ; and an output image sequence display  that displays an output image sequence . The output image sequence  includes the output images  generated by the processing operations respectively associated with the processing steps  in the image analysis sequence . The user interface  may also include a component (not shown) to display the measurement analysis results (i.e., the graphs, charts, tables, histograms, etc. for the measurement data).","The operation toolbar  may include sub-components for selecting an operation to include in the image analysis sequence . The sub-components may be associated with the operation categories in the processing operation library  (). In this example, the operation toolbar  includes a sub-component  associated with the image processing operations  for modifying an image. The operation toolbar  also includes sub-components  associated with the object processing operations , e.g., a sub-component for operations that identify objects in an image (i.e., detected and segment objects) and a sub-component for operations that modify objects in an image. The operation toolbar , in this example, also includes a sub-component  associated with the image selection module  that provides access to images processed and analyzed by the image analysis sequence . Additionally, a user may use the image selection module , in this example, to manage sets of images  (). For example, a user may add an output image generated by a step  in the image analysis sequence  to a set of images. The operation toolbar  may also include sub-components (not shown) for the measurement operations , measurement analysis operations , and classification operations  ().","When a user selects an operation from the operation toolbar , the selected operation is added as a step  in the image analysis sequence . As seen in , the steps -of the image analysis sequence , in this example, respectively correspond to the output images -displayed in the output image sequence display  in the order of their execution. A user may add, remove, rearrange, or reconfigure steps  in the image analysis sequence . A user may add steps  to the image analysis sequence  by selecting a new operation from the operation toolbar . A user may remove steps  from the image analysis sequence  by, for example, selecting the \u201cX\u201d button  on the step or, in an alternative implementation, dragging the step out of the image sequence listing. A user may rearrange the steps  in the image analysis sequence by, for example, dragging a step to a new position in the image analysis sequence . A user may reconfigure a step  in the image analysis sequence by adjusting the parameters  of the step. The steps  in the image sequence  may be collapsible such that the parameters  for the step are displayed when the step is not collapsed\u2014e.g., steps -(steps -)\u2014and hidden when the step is collapsed\u2014e.g., step (step ).","One of the input parameters  may be, for example, an input parameter  that specifies the source of the input data for the processing operation associated with the step . The input data for the input parameter  may be, for example, data from a previous step  in the image analysis sequence  such as, for example, an output image (or set of images), an identified object (or set of identified objects), or measurement data. As seen in the example user interface  of , the input parameter for the \u201cSmooth\u201d step (step ) in the image analysis sequence  is an image and originates on \u201cChannel .\u201d The input parameter for the \u201cUnsharpen Mask\u201d (step ) in the image analysis sequence  of  is the output image of the \u201cSmooth\u201d step ","Additionally, the user interface  in the example shown, the steps  of the image analysis sequence  include a button  to test (or run) the execution of a step  in the image analysis sequence. The user interface , in this example, also includes a button  to test all of the steps  in the image analysis sequence  under construction. When a user selects a button  to test one of the steps  in the image analysis sequence , the image analysis system  executes the processing operation associated with the step using the input data (e.g., an input image) that is set as the input parameter  for the step. The processing operation for the step  may generate output as a result. The output of an executed processing operation may be, for example, an output image (or set of output images), a detected object (or set of detected objects) detected in the image, or measurement data. The user interface , in this example, also includes a button  to test the entire image analysis sequence  in which the image analysis system  iterates over each step  in the image analysis sequence and executes the processing operations respectively associated with the steps.","The user interface may display the results of a selected step  in the image analysis sequence  in a results display component . In the example shown, the results display  displays the input image  for the selected processing step (step , \u201cThreshold\u201d) next to the output image  for the processing step. In this way, a user may determine whether the output image  is satisfactory. If the user determines that the output image  is not satisfactory, then the user may adjust the parameters  for the selected processing step or add additional steps to the image analysis sequence. The user may add additional steps  to the image analysis sequence  in order to use a different input image for the selected processing step . As shown by way of example in , the \u201cThreshold\u201d step (step ) in the image analysis sequence  is selected, and the results display component  displays the input image  for the processing step next to the output image  generated by the processing operation associated with the processing step.","Additionally, the user interface , in this example, includes an output image sequence display  to display an output image sequence . In this example, the output image sequence displays the output images  generated by the processing operations associated with the processing steps  of the image analysis sequence . The output image sequence display  may display the output images  as thumbnail images simultaneously and arrange the output image sequence  in sequential order according to the processing step  the output images  are respectively associated with. As seen in the example image analysis sequence  of , the output image sequence display  displays four output images . The first output image (image ) corresponds to the sample image selected for the \u201cExample Source\u201d step (step ); the second output image (image ) corresponds to the output image for the \u201cSmooth\u201d processing step (step ); the third output image (image ) corresponds to the output image for the \u201cUnsharpen Mask\u201d processing step (step ); and the fourth output image (image ) corresponds to the output image for the \u201cThreshold\u201d processing operation in step (step ). In this example, the measurement step (step ) may include parameters for the selecting one or more measurement operations or measurement analysis operations to perform on the objects of the images.","In this way, the image analysis system  advantageously displays the results of the individual processing steps in the image analysis sequence  simultaneously. If the user is dissatisfied with the results of the image analysis sequence , the output image sequence display  enables the user to identify relatively quickly which step  in the image analysis sequence may cause the unsatisfactory output image . Having identified the suspect step  in the image analysis sequence , a user may adjust the parameters  of the step or add additional steps to the image analysis sequence as discussed above. Further, displaying the input image  next to the output image  in the results display advantageously enables a user to configure and test a selected step  in the image analysis sequence. If the user is dissatisfied with the output image  for the selected step , the user may adjust the selected step or the image analysis sequence  as discussed above and retest the selected step. The user may repeat these procedures until satisfactory results are achieved. If the image processing and object processing results for the image analysis sequence  are satisfactory, a user may add additional steps  to the image analysis sequence such as, for example, steps associated with classification operations, measurement operations, and measurement analysis operations. Again, if the user is dissatisfied with the results of the classification, measurement, or measurement analysis operations, the user may modify the image analysis sequence  or any step in the image analysis sequence to achieve the desired results.","In some implementations, an image processing step  may be color coded based on the emission wavelength of the input image. The user interface  may display the step  as tinted with the color of the input image, e.g., the background for the image processing step  may be colored accordingly. The color associated with the image processing step  may also be passed down to subsequent image processing steps, which may be similarly tinted in turn. For example, if an input image to a \u201csmooth\u201d operation has an emission wavelength of around  nm (i.e., blue), then the step  for the smooth operation may be tinted blue in the user interface . Additionally, the output image for the \u201csmooth\u201d operation may also have a blue emission wavelength such that subsequent steps  that use the output image of the \u201csmooth\u201d operation as an input image are also tinted blue in the user interface . The backgrounds of the output images  in the output image sequence display  may also be tinted and color-coded accordingly.","Once a user determines the image analysis sequence  is satisfactory, the image analysis sequence may be saved and stored at the memory module  of the image analysis system . The image analysis sequence  may be saved as, for example, an XML file. The XML file may include, for example, a structured list of the processing steps  in the image analysis sequence, the processing operations associated with each processing step, the parameters  for the processing steps, and other information relating to the image analysis sequence. A user may then select the image analysis sequence  as an individual step when creating subsequent image analysis sequences. The image analysis sequence  may also be shared by transmitting the image analysis sequence to other image analysis systems for use at those systems.","Referring to , an alternative results display component  for displaying an input image  and output image  is shown. Instead of displaying the input image  and the output image  next to each other, the alternative display component , in this example, aligns the input image and the output image on top of each other such that the input image and the output image are in a stacked arrangement. A horizontally sliding vertical divider  splits the stacked images  and  into a left portion  and a right portion . The display component  in this alternative example displays one of the images on one side of the divider and displays the other image on the opposite side of the divider. In the example shown in , the input image  is displayed to the left of the divider , and the output image  is displayed to the right of the divider . Sliding the divider  horizontally reveals more of one image and less of another image. As shown by way of example in  and , as the divider  slides horizontally leftward, more of the output image  is revealed. Sliding the divider  horizontally rightward, in these examples, will reveal more of the input image . In this way, users may advantageously focus their attention on a region in the input image  and output image , slide the divider  across the region, and compare the changes between the input image and the output image.","Referring now to , illustrate how a user may construct an image analysis sequence  using the image analysis system . The processing steps in the image analysis sequence , in this example, process a sample source image  to identify and measure objects in the image.","Referring to , the first step  in the image analysis sequence  is shown. In this example, the first processing step  (step , \u201cExample Source\u201d) selects a sample source image  for processing. As seen in , the input parameters  for the image selection step  indicate that the image at time point , z-position , and stage position  should be selected as the sample source image for the image analysis sequence . The image selection step , in this example, also includes a \u201cSelect\u201d button  to load the sample source image  in the results display . As seen in , the sample source image  includes multiple objects  a user may want to identify and measure. As discussed above, the user may identify objects  in the image  by adding an object processing step to the image analysis sequence  such as, for example, a threshold operation to compare the pixels in the sample source image to a predetermined threshold.","Referring to , an object processing step  (step , \u201cThreshold\u201d) has been added to the image analysis sequence . A user may configure the parameters  of the threshold step as shown. The results display displays the input image  (i.e., the selected sample source image ) and the output image  for the threshold operation when the \u201cTest\u201d button  is selected. In this example, a user may determine that the results of the threshold operation are not satisfactory because some objects  are undesirably merged together in the output image . Accordingly, the user may determine that image processing operations are needed to adjust the sample source image  before the threshold step .","As shown in , the threshold step  in  has been replaced with an image processing step  (step , \u201cUnsharpen Mask\u201d). The user may configure the parameters  for the unsharpen masking step  and select the \u201cTest\u201d button  to view the results of the image processing step. The results display  presents both the input image  (i.e., the selected sample source image ) and the output image  for the unsharpen masking operation. In this example, the user may determine that the resulting output image  for the unsharpen masking step  is not satisfactory and that an additional image processing step is needed before the unsharpen masking step .","As seen in , the unsharpen masking step  in  has been replaced with an another image processing step  (step , \u201cSmooth\u201d). Like before, the user may configure parameters  of the smoothing step  and select the \u201cTest\u201d button  to view the results. The results display  present both the input image  (i.e., the selected sample source image ) and the output image  for the smoothing step . In this example, the user may determine that the resulting output image  is satisfactory and may be set as the input image for a subsequent unsharpen masking operation.","In , the unsharpen masking step  (step , \u201cUnsharpen Mask\u201d) has been added back to the image analysis sequence . As seen in , the input image (\u201cSource\u201d) for the unsharpen masking step  (step ) is set to \u201cSmooth,\u201d which sets the output image  of the smoothing step  (step ) as the input image for the unsharpen masking step. The user may configure the parameters  of the unsharpen masking operation and select the \u201cTest\u201d button  to view the results. The results display presents the input image  and the output image  for the unsharpen masking step . In this example, the user may determine that the resulting output image  is satisfactory. Accordingly, the user may set the output image  as the input image for a subsequent threshold operation to identify the objects in the image.","As seen in , the threshold step  (step , \u201cThreshold\u201d) has been added back to the image analysis sequence  to identify the objects in the input image . The image processing steps  and  (step  and step ), in this example, adjust the selected sample source image  to improve the results of the threshold operation. As seen in , the input image for the threshold step  (step ) is set to \u201cUnsharpen Mask,\u201d which sets the output image  of the unsharpen masking step  (step ) as the input image for the threshold step . The user may configure the parameters  of the threshold step  and select the \u201cTest\u201d button  to view the results. The results display  presents the input image  and the output image  for the threshold step . In this example, because the image analysis sequence  includes image processing step  and  before the threshold step , the output image  for the threshold operation in  includes distinct objects  that are not undesirably merged together as seen in the output image  for the threshold operation in . Therefore, a user may determine that the output image  for the threshold step  in  is satisfactory and that the objects identified in the image are ready to be measured and analyzed.","In , an object processing step  (step , \u201cFilter\u201d) has been added to the image analysis sequence  to filter the identified objects  in the output image . As seen in , the input image for the filter step  (step ) is set to \u201cThreshold,\u201d which sets the output image  for the threshold operation (step ) as the input image for the filter step. The user may configure the parameters  for the filter step  and select the \u201cTest\u201d button  to selectively filter the identified objects  in the input image . In this example, the filter parameter is set to filter the objects based on object size, and the parameters for the minimum and maximum object size have been respectively set to 100 and 2000. Accordingly, the filter operation, in this example, will filter out identified objects  that fall outside the specified minimum and maximum object size. The resulting output image  for the filter operation is display in the results display . As seen in the example output image , the filter operation has removed the highlighting from objects  falling outside the specified minimum and maximum object size.","Additionally, the image sequence  may include a measurement analysis step (not shown) that counts the number of identified objects having a particular size and generates a graph  that includes the results. In , the results display  includes a bar graph that graphs the number of objects in the filtered output image  that have a particular size. The bar graph  in the example shown also includes an indicator  for the minimum object size and an indicator  for the maximum object size that illustrate how many objects fall outside of the specified range.","Referring now to , a flowchart  of example method steps for selectively arranging and configuring an image analysis sequence having multiple processing steps is shown. As discussed above, processing steps may include image processing steps, object processing steps, measurement steps, classification steps and measurement analysis steps. Each processing step may be respectively associated with a processing operation (e.g., image processing operations, object processing operations, measurement operations, classification operations, and measurement analysis operations). As the image analysis sequence is constructed, individual processing steps of the image may be configured using one or more input parameters. One of the input parameters may specify the input image for the step. Additionally, while the image analysis sequence is under construction, the steps of the image analysis sequence may be tested. The steps may be tested by executing them individually and observing the results for each step or, additionally or alternatively, by executing the entire image analysis sequence and observing the results for each step in the image analysis sequence as well as the overall results. The input image and output image for a step in the image analysis sequence may be displayed next to each other for comparison. Additionally, all of the output images for the steps of the image analysis sequence may be consecutively displayed in a list so that a user may observe how the output image for one step in the sequence affects the output images for subsequent steps in the sequence. If a user is dissatisfied with the results of any step in the image analysis sequence, the user may modify the image analysis sequence by reconfiguring one or more of the steps, or adding steps to or removing steps from the image analysis sequence.","Referring to , a selection for a sample source image is received, and the sample source image is loaded for subsequent processing (step ). The selection may specify one image or multiple images in a set of images. The selection for the sample source image may specify and image directly (e.g., image number ) or relatively (e.g., a current image minus 1).","Once the sample source image has been selected, a selection for an image processing operation may be received which may be added to the image analysis sequence as an image processing step (step ). As discussed above, an image processing operation may adjust the image data in an image for subsequent processing. Configuration information may be received to selectively configure the execution of the image processing step (step ). When the image processing step is configured, the image processing step may be tested (step ), and the results for the image processing step may then be obtained and displayed (step ). If the results for the image processing step are unsatisfactory (step ), a selection for a new processing operation may be received and added to the image analysis sequence as a new image processing step (step ) or new configuration information for the image processing step may be received (step ) to modify the image analysis sequence.","Once the results for the image processing steps are satisfactory (step ), a selection for an object identification operation may be received, and added as an object processing step (step ). As discussed above, object identification steps may detected objects in an image and determine, for example, which pixels in the image are associated with the identified objects (i.e., object segmentation). Configuration information may be received to selectively configure the execution of the object identification step (step ). When the object identification step is configured, the object identification step may be tested (step ), and the results for the object identification step may then be obtained and displayed (step ). If the results of the object identification step are not satisfactory (step ), the image analysis sequence may be modified. New selections or new configuration information may be received for an image processing step or an object identification step (steps - and -).","Referring to , a selection for an object modification operation may be received and added as an object processing step to the image analysis sequence (step ), when the results for the object identification operations are satisfactory (step ). As discussed above, object modification steps may, for example, adjust the image data for a segmentation associated with an object. Configuration information may be received to selectively configure the execution of the object modification step (step ). When the object modification step is configured, the object modification step may be tested (step ), and the results for the object modification step may then be obtained and displayed (step ). If the results for the object modification step are not satisfactory (step ), the image analysis sequence may be modified. New selections or new configuration information may be received for an image processing step, an object identification step, or an object modification step (steps -, -, and -).","When the results of the object modification steps are satisfactory (step ), a selection for a measurement operation may be received and added as a measurement step to the image analysis sequence (step ). As discussed above, measurement steps may measure the identified objects in an image. Configuration information may be received to selectively configure the execution of the measurement step (step ). When the measurement step is configured, the measurement step may be tested (step ), and the results for the measurement step may then be obtained and displayed (step ). If the results of the measurement step are not satisfactory (step ), the image analysis sequence may be modified. New selections or new configuration information may be received for an image processing step, an object identification step, an object modification step, or a measurement step (s steps -, -, -, and -).","As seen in , a selection for a classification operation may be received and added as a classification step to the image analysis sequence (step ) once the results for the measurement operations are satisfactory (step ). Classification steps may classify or categorize detected objects in an image. Configuration information may be received to selectively configure the execution of the classification step (step ). When the classification step is configured, the classification step may be tested (step ), and the results for the classification step may then be obtained and displayed (step ). If the results of the classification step are not satisfactory (step ), the image analysis sequence may be modified. New selections or new configuration information may be received for an image processing step, an object identification step, an object modification step, a measurement step, or a classification step (-, -, -, -, and -).","If the results for the classification steps are satisfactory (step ), the image analysis sequence may be tested with a new sample source image. A selection for a new sample source image may be received and the new sample source image may be loaded for subsequent processing (step ). The image analysis sequence may then be executed on the new sample source image (step ), and the results for the original sample source image and the new sample source image may be compared (step ). If the results for the new sample source image are unsatisfactory (step ), the image analysis sequence may be modified as described above. If the results for the new sample source image are satisfactory (step ), then the image analysis sequence may be executed over a series of images in an image data set.","Referring to , a selection for an image data set is received (step ). The image data set may include a series of images for processing and analysis using the image analysis sequence under construction. The image analysis sequence under construction may be executed for each image in the image data set (step ), and the results may be obtained and displayed (step ). If the results of the image analysis sequence for the image data set are unsatisfactory (step ), the image analysis sequence may be modified as described above. If the results of the image analysis sequence for the image data set are satisfactory (step ), then the image analysis sequence may be saved (step ) and used to process additional images and image data sets.","It will be understood that the method set forth above may be performed to create a variety of different image analysis sequences that process and analyze biological images for a variety of applications. Some example applications include: analyzing cell images acquired under varying illumination conditions (i.e., on multiple channels) to determine whether objects identified in one channel overlap objects identified in another channel; measuring a change in intensity of objects across a time-domain series of images; measuring relative changes in intensity by selecting an image relative to a time point (e.g., current time point minus one) and comparing it to the image for the current time point; processing and analyzing user-defined regions of interest by receiving user input identifying the regions of an image to process and analyze; and correcting image properties (e.g., shading) using a reference image.","It will be understood and appreciated that one or more of the processes, sub-processes, and process steps described in connection with , A-B, , A-C, A-G, and A-D may be performed by hardware, software, or a combination of hardware and software on one or more electronic or digitally-controlled devices. The software may reside in a software memory (not shown) in a suitable electronic processing component or system such as, for example, one or more of the functional systems, devices, components, modules, or sub-modules schematically depicted in . The software memory may include an ordered listing of executable instructions for implementing logical functions (that is, \u201clogic\u201d that may be implemented with in digital form such as digital circuitry or source code, or in analog form such as analog source such as an analog electrical, sound, or video signal). The instructions may be executed within a processing module, which includes, for example, one or more microprocessors, general purpose processors, combinations of processors, DSPs, or ASICs. Further, the schematic diagrams describe a logical division of functions having physical (hardware and\/or software) implementations that are not limited by architecture or the physical layout of the functions. The example systems described in this application may be implemented in a variety of configurations and operate as hardware\/software components in a single hardware\/software unit, or in separate hardware\/software units.","The executable instructions may be implemented as a computer program product having instructions stored therein which, when executed by a processing module of an electronic system (e.g., an image analysis system  in ), direct the electronic system to carry out the instructions. The computer program product may be selectively embodied in any non-transitory computer-readable storage medium for use by or in connection with an instruction execution system, apparatus, or device, such as a electronic computer-based system, processor-containing system, or other system that may selectively fetch the instructions from the instruction execution system, apparatus, or device and execute the instructions. In the context of this document, computer-readable storage medium is any non-transitory means that may store the program for use by or in connection with the instruction execution system, apparatus, or device. The non-transitory computer-readable storage medium may selectively be, for example, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, or device. A non-exhaustive list of more specific examples of non-transitory computer readable media include: an electrical connection having one or more wires (electronic); a portable computer diskette (magnetic); a random access memory (electronic); a read-only memory (electronic); an erasable programmable read only memory such as, for example, Flash memory (electronic); a compact disc memory such as, for example, CD-ROM, CD-R, CD-RW (optical); and digital versatile disc memory, i.e., DVD (optical). Note that the non-transitory computer-readable storage medium may even be paper or another suitable medium upon which the program is printed, as the program can be electronically captured via, for instance, optical scanning of the paper or other medium, then compiled, interpreted, or otherwise processed in a suitable manner if necessary, and then stored in a computer memory or machine memory.","It will also be understood that the term \u201cin signal communication\u201d as used in this document means that two or more systems, devices, components, modules, or sub-modules are capable of communicating with each other via signals that travel over some type of signal path. The signals may be communication, power, data, or energy signals, which may communicate information, power, or energy from a first system, device, component, module, or sub-module to a second system, device, component, module, or sub-module along a signal path between the first and second system, device, component, module, or sub-module. The signal paths may include physical, electrical, magnetic, electromagnetic, electrochemical, optical, wired, or wireless connections. The signal paths may also include additional systems, devices, components, modules, or sub-modules between the first and second system, device, component, module, or sub-module.","The foregoing description of implementations has been presented for purposes of illustration and description. It is not exhaustive and does not limit the claimed inventions to the precise form disclosed. Modifications and variations are possible in light of the above description or may be acquired from practicing the invention. The claims and their equivalents define the scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":["FIG. 2B","FIG. 2A"]},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 4B","FIG. 4A"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 4C","FIG. 4A"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 5B","FIG. 5A"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 5C","FIG. 5B"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 5D","FIG. 5C"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 5E","FIG. 5D"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 5F","FIG. 5E"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 5G","FIG. 5F"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 6B","FIG. 6A"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 6C","FIG. 6B"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 6D","FIG. 6C"]}]},"DETDESC":[{},{}]}
