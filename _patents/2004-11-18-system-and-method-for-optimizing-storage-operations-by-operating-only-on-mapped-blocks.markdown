---
title: System and method for optimizing storage operations by operating only on mapped blocks
abstract: A system for optimizing storage operations by operating only on mapped blocks may include a first and a second set of one or more storage devices, a virtual device client and a virtual device server. The virtual device server may be configured to aggregate storage in the first set of one or more storage devices into a virtual storage device, and make the virtual device accessible to the virtual device server. In preparation for a synchronization operation, the virtual device server may obtain a map identifying one or more in-use regions of the virtual storage device from the virtual device client. The virtual device server may then perform the synchronization operation by copying the one or more in-use regions of the virtual storage device to the second set of one or more storage devices.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07293154&OS=07293154&RS=07293154
owner: Symantec Operating Corporation
number: 07293154
owner_city: Cupertino
owner_country: US
publication_date: 20041118
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["1. Field of the Invention","This invention relates to computer systems and, more particularly, to the management of synchronization operations within storage environments employing storage virtualization.","2. Description of the Related Art","Many business organizations and governmental entities rely upon applications that access large amounts of data, often exceeding a terabyte or more of data, for mission-critical applications. Often such data is stored on many different storage devices, which may be heterogeneous in nature, including many different types of devices from many different manufacturers.","Configuring individual applications that consume data, or application server systems that host such applications, to recognize and directly interact with each different storage device that may possibly be encountered in a heterogeneous storage environment would be increasingly difficult as the environment scaled in size and complexity. Therefore, in some storage environments, specialized storage management software and hardware may be used to provide a more uniform storage model to storage consumers. Such software and hardware may also be configured to add storage features not present in individual storage devices to the storage model. For example, features to increase fault tolerance, such as data mirroring, snapshot\/fixed image creation, replication, or data parity, as well as features to increase data access performance, such as disk striping, may be implemented in the storage model via hardware or software.","Some of the added storage features, such as the ability to attach additional mirrors to a storage device, or to replicate data at a remote location, may require a synchronization or data copying operation from a set of source storage devices to a set of target storage devices. For example, a newly attached mirror may have to be synchronized with the existing mirror or mirrors of a logical volume being used by a file system. In some cases, a large amount of storage may have been reserved for use at a storage device such as a logical volume, not all of which may be actually in use at the time that a synchronization operation is performed. For example, a mirror of a logical volume may comprise several hundred gigabytes of disk storage, of which only a few tens of gigabytes may be mapped (e.g., into files, directories and file system metadata) by the file system using the logical volume at the time a new mirror is attached. Mapping information identifying the in-use portions of the source storage devices may be available at an application layer (e.g., at a file system), but may not be directly visible at a lower-level storage management layer responsible for performing the synchronization operation (e.g., at a volume manager). The synchronization operation may therefore typically include the copying of large amounts of storage that may not be in use. It may be desirable to make the synchronization operations more efficient by restricting the data blocks copied to those that are in use.","Various embodiments of a system and method for optimizing storage operations by operating only on mapped blocks are disclosed. According to a first embodiment, a system may include a first and a second set of one or more storage devices, a virtual device client and a virtual device server. The virtual device server may be configured to aggregate storage in the first set of one or more storage devices into a virtual storage device, and make the virtual device accessible to the virtual device server. The virtual device client, such as a file system, may then manage storage within the virtual device using metadata (e.g., file system metadata such as super blocks, inode lists, and free block tables) that may be inaccessible from the virtual device server. Not all the storage of the virtual device may be in use at any given time, and the metadata maintained at the virtual device client may include a map of the storage regions that are in use (or such a map may be derived from the metadata). In preparation for a synchronization operation, the virtual device server may obtain a map identifying one or more in-use regions of the virtual storage device from the virtual device client. The virtual device server may then perform the synchronization operation by copying the one or more in-use regions of the virtual storage device to the second set of one or more storage devices, instead of copying both the in-use and unused regions.","Various kinds of virtualization functions may be provided by the virtual device server in different embodiments. In some embodiments, block virtualization may be employed, e.g., the virtual device may be a logical volume, such as a mirrored logical volume, and the virtual device server may be a volume manager. The virtual device client may be a file system in one embodiment, and a replication manager in another. The synchronization operation may be a mirror synchronization after a mirror attach, a replication operation, a data migration operation, or a recovery operation. In some embodiments, the virtual device server may be configured to revalidate the map after copying the data, for example to identify any changes that may have occurred during the synchronization operation.","In some embodiments, the virtual device server may perform one or more operations to provide a consistent view of unused regions of the virtual device, in addition to synchronizing the in-use regions. According to one such embodiment, the virtual device server may be configured to perform a virtual zeroing operation on a portion of the first set of storage devices that does not overlap with any in-use region of the virtual storage device, and on a portion of the second set of storage devices that does not overlap with a copy of an in-use region of the virtual storage device. In another embodiment, the virtual device server may be configured to identify a request to read a block from a portion of the first set of storage devices that does not overlap with any in-use region as an uninitialized read request, and to copy the block requested in the uninitialized read request to the second set of one or more storage devices.","While the invention is susceptible to various modifications and alternative forms, specific embodiments are shown by way of example in the drawings and are herein described in detail. It should be understood, however, that drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, the invention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1","b":["100","150","150","130","120","150","110","150","110","110","130","150","140","140","120"]},"Virtual device client  may maintain a map  identifying in-use regions  (i.e., A and B) of the address space of virtual device . In-use regions may represent the subset of the total storage allocated for virtual device  that may contain valid data useful to virtual device client , i.e., data that is used to provide the functionality supported by virtual device client . Unused regions A-C (collectively, regions ) of virtual device  may represent storage that has been allocated or reserved for use by virtual device client , but does not currently contain useful data. Virtual device server  may be configured to perform a synchronization operation requiring a copying of data from storage device set A to storage device set B, for example in response to a configuration change request. As described below in further detail, virtual device server  may optimize the synchronization operation by obtaining information contained within map  from virtual device client , and copying only the in-use regions  to storage device set B rather than the entire storage allocated to virtual device .","Virtual device server  may present virtual storage device  using a variety of virtualization primitives in different embodiments, such as virtual blocks or virtual objects such as files, as described in more detail below. In one embodiment, block-based virtualization may be employed, as shown in . That is, storage devices  may be block devices , and virtual device server  may be a volume server (or a volume manager)  configured to aggregate storage at block devices  into a logical volume  (which may also be referred to herein as a volume). Virtual device client  may be termed a volume client  in such an embodiment.","Generally speaking, a block device may comprise any hardware or software entity that provides a collection of linearly addressed data blocks that can be read or written. For example, in one embodiment a physical block device  may be a single disk drive configured to present all of its sectors as an indexed array of blocks. It is contemplated that any suitable type of storage device may be configured as a block device, such as fixed or removable magnetic media drives (e.g., hard drives, floppy or Zip-based drives), writable or read-only optical media drives (e.g., CD or DVD), tape drives, solid-state mass storage devices, or any other type of storage device. In some embodiments, a block device may also be a logical or virtual storage device resulting from a mapping of blocks of one or more physical storage devices, as described in greater detail below.","Hardware devices configured to provide a collection of linearly addressed data blocks may generally be referred to as physical block devices, and logical or virtual storage devices so configured may generally be referred to as logical or virtual block devices. It is contemplated that in some embodiments, data blocks may be uniformly sized across different physical and logical block devices, while in other embodiments physical and logical block devices may employ different block sizes. It is also contemplated that in some embodiments, block sizes may vary among particular physical block devices and\/or particular logical block devices, or even within a given block device.","A block device may differ from a file in that it may not require use of a file system for access; that is, a consumer of a block device may read or write blocks directly to the device, bypassing any file system that may be in use. In some embodiments, a block device  presented by an operating system for use by a consumer may present relatively few primitives through which the device may be manipulated. For example, in one embodiment a block device  may support open, close, read and write primitives, plus a few miscellaneous control and query primitives. In contrast, file systems may provide a richer set of primitives, such as support for creating and removing files, appending to files, creating and removing directories, etc. Typical interfaces to block devices may allow for higher raw throughput and greater concurrency than typical interfaces to single files of a file system. Block devices  that are physical storage devices, such as disks or tape drives, may be configured to present some form of SCSI interface, though other interfaces are possible and contemplated.","Generally speaking, a volume  may comprise a block device that may be presented directly for use by a block device consumer, e.g., a volume client . In one embodiment, a volume client  may be a file system or an application (such as a database application, for example) that can directly use block devices. As described in greater detail below, in some embodiments employing block device virtualization, a given volume  may be associated with several logical or physical block devices. In such embodiments, each block device included in the logical organization of a given volume or virtualized block device may be referred to as a storage object or logical storage object.","A volume may differ from a block device interface implemented in a hardware device or that is accessed through a system disk driver, in that the latter block devices may not present a system-independent block device interface that can be opened for direct use by a consumer. Instead, a system-dependent disk driver may be required to access such block devices. In embodiments employing block virtualization, such a disk driver may be generally unaware of block virtualization and may in some instances present a barrier to using some virtualization techniques, whereas a volume implementing various block virtualization features may be directly accessible by a consumer without the issues presented by such disk drivers.","A volume manager, such as volume server , may introduce virtualization of blocks, e.g. in response to a configuration command from a system administrator, creating some number of virtualized block devices out of one or more physical or logical block devices. (In some embodiments, devices such as disk arrays and virtualization switches may also be configured to perform block virtualization.) In one embodiment of block virtualization, one or more layers of software and\/or hardware rearrange blocks from one or more block devices, such as disks, and add various kinds of functions. The resulting rearranged collection of blocks may then be presented to a block device consumer, such as an application or a file system, as one or more aggregated devices with the appearance of one or more basic disk drives. That is, the more complex structure resulting from rearranging blocks and adding functionality may be presented as if it were one or more simple arrays of blocks, or logical block devices. It is noted that a virtualized block device may also be referred to as a logical block device, and that in some embodiments, multiple layers of virtualization may be implemented. That is, one or more block devices may be mapped into a particular virtualized block device, which may be in turn mapped into still another virtualized block device, allowing complex storage functions to be implemented with simple block devices.","In various embodiments, block virtualization can support the creation of virtualized block devices implementing numerous different types of storage functions. For example, in one embodiment a virtualized block device may implement device striping, where data blocks may be distributed among multiple physical or logical block devices, and\/or device spanning, in which multiple physical or logical block devices may be joined to appear as a single large logical block device. In some embodiments, virtualized block devices may provide mirroring and other forms of redundant data storage, the ability to create a snapshot or static image of a particular block device at a point in time, and\/or the ability to replicate data blocks among storage systems connected through a network such as a local area network (LAN) or a wide area network (WAN), for example. Additionally, in some embodiments virtualized block devices may implement certain performance optimizations, such as load distribution, for example, and\/or various capabilities for online reorganization of virtual device structure, such as online data migration between devices. Block virtualization may provide any or all of these capabilities in a fashion transparent to virtualized block device consumers. That is, virtualized block devices may appear as generic storage devices to consumers such as file systems and applications.","Volume server  may provide functions such as configuration management of virtualized block devices and distributed coordination of block device virtualization. For example, in one embodiment volume server  may be aware of the type and quantity of physical storage devices, such as physical block devices , that are available within a storage system. In various embodiments, the virtualization functions provided by volume server  may be provided at different levels in the storage hierarchy between a volume client  and physical block devices .","For example, in one embodiment, volume clients  may be provided with a description of a virtualized block device and may be configured to directly access constituent block devices comprising the virtualized device. Such virtualization may also be referred to as host-based or client-based virtualization. In response to a request to configure a virtual block device, for example according to a desired set of virtualization features, volume server  may be configured to build a volume description that describes how a collection of storage objects compliant with the desired features maps to underlying physical block devices. The volume description identifying a particular volume  may be distributed to one or more volume clients . In one embodiment, such a volume description may be a tree of storage objects such as described in greater detail below in conjunction with the description of . Each volume client  may be configured to interact with volume server  for certain functions, for example management or administrative functions. For typical block read and write activity, each volume client  may be configured to interact directly with various block devices  according to the volume description distributed by volume server .","The structure of the volume , for example as indicated by its corresponding storage object tree, may indicate to a given volume client  how the volume relates to one or more underlying physical storage devices. In one embodiment, the leaf nodes of such a tree may correspond to one or more physical block devices such as block devices , and the root node of such a tree may be a logical block device through which the volume is accessed by a consumer. Distribution of a virtualized block device as a volume to one or more volume clients  may also be referred to as distributed block virtualization. In some embodiments, after volume server  has distributed a volume description of a given virtual block device to a given volume client  as a particular volume , the given volume client  may interact with that particular volume  to read and write blocks without further involvement on the part of volume server , as described above. That is, the given volume client  may use the structure of the particular volume  to transform I\/O requests generated by various consumers of that volume  into I\/O requests directed to specific physical storage devices, such as block devices .","In some embodiments, details of block virtualization may not be directly available to individual volume clients . In some such embodiments, the virtualization function of volume server  may be implemented in a device or layer of abstraction in between volume clients  and block devices , such as a switch or virtualization appliance. Such virtualization may also be referred to as switch-based or appliance-based virtualization.","Additionally, in some embodiments, multiple layers of virtualization may be employed, for example at the host level as well as at the switch or appliance level. In such embodiments, some aspects of virtualization may be visible to volume clients , as in the host-based model, while some aspects may be implemented transparently by an intermediate device, as in the switch-based model. Further, in some multilayer embodiments, the virtualization details of one block device (e.g., one volume ) may be fully defined to a volume client  (i.e., without further virtualization at the switch layer), while the virtualization details of another block device (e.g., another volume) may be partially or entirely transparent to volume client .","One embodiment of a virtualized block device that may be presented to a volume client  as a volume  is illustrated in . In the illustrated embodiment, virtualized block device  includes a volume block device  that includes logical block devices  and . In turn, logical block device  includes logical block devices  and , while logical block device  includes logical block device . Logical block devices , ,  may map to physical block devices A-C of .","Virtualized block device  may in its entirety represent the structure of the data comprising a given volume , which data may be physically stored in physical block devices A-C. Volume block device  may be configured to be mounted within a file system or presented to an application or other volume consumer as the interface through which the consumer may interact with given volume . Each block device that maps to or includes another block device may include an interface whereby the mapping or including block device may interact with the mapped or included device. For example, this interface may be a software interface whereby data and commands for block read and write operations is propagated from lower levels of the virtualization hierarchy to higher levels and vice versa.","Additionally, a given block device may be configured to map the logical block spaces of subordinate block devices into its logical block space in various ways in order to realize a particular virtualization function. For example, in one embodiment, virtualized block device  may be configured as a mirrored volume, in which a given data block written to virtualized storage device  is duplicated, and each of the multiple copies of the duplicated given data block are stored in respective block devices. In one such embodiment, volume block device  may be configured to receive an operation to write a data block from a consumer of corresponding volume . Volume block device  may duplicate the write operation and issue the write operation to both logical block devices  and , such that the block is written to both devices. In this context, logical block devices  and  may be referred to as mirrored plexes, mirror devices, or simply mirrors. In various embodiments, volume block device  may read a given data block stored in duplicate in logical block devices  and  by issuing a read operation to one mirror device or the other, for example by alternating devices or defaulting to a particular device. Alternatively, volume block device  may issue a read operation to multiple mirror devices and accept results from the fastest responder.","One or more additional mirrors or plexes may be added to a mirrored logical volume, such as volume , to support an enhanced level of availability and\/or to support functionality such as snapshots.  illustrates an addition (via a mirror attach operation) of a third plex C to a mirrored volume  containing two existing mirrored plexes A and B. Prior to the addition of plex C, mirrored plexes A and B may contain identical copies of the data of volume . Subsequent to the attach, a synchronization operation may be performed, i.e., data from one or both of the pre-existing plexes A-B may be copied to the newly attached plex in order to ensure that all three plexes eventually contain the same data.","As described above and shown in , in some embodiments a virtualized block device  may employ multiple layers of virtualization. For example, in the embodiment described above where logical block devices  and  function as mirror devices, it may be the case that underlying physical block devices A-C have dissimilar performance characteristics; specifically, devices A-B may be slower than device C.","In order to balance the performance of the mirror devices, in one embodiment, logical block device  may be implemented as a striped device in which data is distributed between logical block devices  and . For example, even- and odd-numbered blocks of logical block device  may be mapped to logical block devices  and  respectively, each of which may be configured to map in turn to all or some portion of physical block devices A-B respectively. In such an embodiment, block read\/write throughput may be increased over a non-striped configuration, as logical block device  may be able to read or write two blocks concurrently instead of one. Numerous striping arrangements involving various distributions of blocks to logical block devices are possible and contemplated; such arrangements may be chosen to optimize for various data usage patterns such as predominantly sequential or random usage patterns.","In another aspect illustrating multiple layers of block virtualization, in one embodiment physical block device C may employ a different block size than logical block device . In such an embodiment, logical block device  may be configured to translate between the two physical block sizes and to map the logical block space define by logical block device  to the physical block space defined by physical block device C. In some instances, the logical block space of logical block device  need not be contiguously mapped to blocks of physical block device C; an arbitrary mapping may be used.","Numerous other possible configurations of block devices are contemplated that may incorporate more or fewer layers of virtualization to realize within a given instance of virtualized block device  virtualization functions similar to or different from those described above. For example, volume block device  may employ a greater number of mirror devices, striping may occur higher in the hierarchy than mirroring, certain logical block devices may be configured to perform snapshots of other devices, certain logical block devices may span multiple physical block devices, etc.","In one embodiment, volume server  may be configured to read and update configuration information corresponding to volume descriptions (such as a storage object tree corresponding to a given volume) from a configuration database. The configuration information in the database may establish the logical configuration of data on the physical storage devices  (e.g., block devices A-C). For example, such configuration information may indicate how various logical and physical block devices are divided, striped, mirrored, etc. In one embodiment, the configuration information may be stored on the devices (e.g., block devices A-C) that are being virtualized. It is contemplated that in some embodiments, configuration of a given virtualized block device may be managed and\/or stored in data structures other than trees of objects. For example, in one embodiment, tables may be used to map virtual block devices to physical storage.","As noted above, the configuration associated with a virtual block device may change over time, such as to add or remove mirrors; migrate data to new storage; increase or decrease the size of the device; create, manipulate, or remove snapshots; add structure for a new capability; etc. In some embodiments, if the volume description of a given volume  is distributed to more than one volume client , any changes that affect the structure of the given volume  may need to be coherently coordinated among the relevant volume clients . In one embodiment volume server  may be configured to coordinate such changes. For example, volume server  may be configured to coordinate quiescence of those volume clients  to which the given volume  is distributed, in order to temporarily suspend activity to given volume . Volume server  may further distribute changes to the structure of given volume  to relevant volume clients  in an effectively atomic fashion, such that either all or none of the relevant clients  receive the changes.","In some embodiments, volume server  may be configured to distribute all defined volumes  to each volume client  present within a system. Such embodiments may be referred to as symmetric distributed block virtualization systems. In other embodiments, specific volumes may be distributed only to respective volume clients , such that at least one volume  is not common to two volume clients . Such embodiments may be referred to as asymmetric distributed block virtualization systems.","As noted earlier, a virtual device server , such as volume server , may receive a configuration command (e.g., through a command-line interface or via a graphical user interface or GUI) from an administrator to create a virtual device  out of one or more physical or logical block devices. In some embodiments, the configuration command may specify the amount of storage (e.g., in blocks, kilobytes or megabytes) to be allocated or set aside from the underlying block devices for virtual device . The allocated amount of storage may be chosen by the administrator based upon various factors, such as a corporate or data center storage allocation policy (e.g., \u201ca volume to be used for a file system should provide 100 GB of storage\u201d), or an expectation of future use. In many instances it may be hard to anticipate future storage space requirements for a given virtual device, and a generous amount of space may therefore be allocated to avoid frequent reconfiguration requests if space usage increases.","Having been provided access to virtual device , virtual device client  may organize the allocated space in a manner suitable for the specific functionality supported or required by the virtual device client . For example, as illustrated in  for one embodiment, virtual device client  may be a file system , which may use a logical volume  provided by a volume manager  to store files, directories, and other file system objects such as file system metadata. The files and directories may be used to store the data of one or more applications , such as a web server application, an e-mail application, or a database management application. Metadata for file system , as described in greater detail below, may include private data used by file system  to manage the allocated space and to provide services (e.g., file I\/O operations, file and directory lookups, file creation and truncation, etc.), to applications  in an efficient manner. File system metadata objects may not be directly accessible from, volume manager  or applications . File system  may be a single-system file system in one embodiment and a clustered file system in another embodiment. In addition, in some embodiments, metadata for file system  may be maintained at a file system metadata server (e.g., at an object metadata server in a storage environment employing object storage devices), which may be distinct from one or more servers at which the data of the file system may reside.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 6","FIG. 6","FIG. 6"],"b":["240","240","500","610","620","625","630"]},"Super block  may be used to store several pieces of general information about file system , such as the size of the underlying volume, the file system type, file system block size, one or more file system status indicators, file usage statistics, and pointers to other metadata objects such as free block table  and free inode table . Data containers (i.e., files and directories or folders) of file system  may be managed using a data structure called an inode that contains or points to information required to translate file addresses (e.g., logical offsets within a given file) to block addresses (i.e., addresses within the virtual address space of a volume ). Inodes may also contain other file and directory attributes and properties (e.g., user and group ownership, modification times, access permissions and access control lists). The inodes of file system  may be organized as an array or list, such as inode list , and each inode may be identified by its index within the list. An inode representing a file, such as inode  in , may contain a data block address or pointer specifying the block address of the file's data. (In some embodiments, variable-length extents may be used as the unit of file allocation instead of using fixed-length blocks. An extent may identify a region of one or more contiguous data blocks by using the starting and ending block addresses of the contiguous blocks). For large files, an inode (e.g., inode ) may point to one or more indirect blocks, which may in turn contain pointers to other indirect blocks or to data blocks. An inode representing a directory (e.g., inode ) may point to a special kind of data block containing directory entries that in turn point to inodes for the files contained within the directory (e.g., inode  may represent a file in the directory represented by inode ). A free inode table  may contain pointers to free inodes (i.e., inodes not currently representing any file or directory) within inode list .","Free blocks within the underlying volume  (i.e., blocks that do not contain metadata and that are not mapped to a file by any inode) may be accessible via free block table , i.e., free block table  may provide pointers or contain data structures representing the set of unused blocks of volume . When a user of an application  requests that a new file be created within file system , a free data block may be obtained by the file system using free block table  and associated with a free inode from inode list . When a file is deleted, its data block or blocks may be marked as free (i.e., free block table  may be modified to point to the data block or blocks of the file being deleted), and its inode may be marked as being unused (i.e., free inode table  may be modified to point to the inode). It is noted that free inode table  may be implemented using any suitable data structure, such as a bitmap, linked list or hash table, in different embodiments. Extent-based representations of free blocks may be used in some implementations to reduce the number of entries that may be required within free block table .","Many file systems may have a fast method of computing whether a given data block is in-use or free. Such a method may be used by the file system, for example, for internal operations such as efficient management of file growth. In some log-structured file systems, free blocks may be identified simply as blocks after a current write-point within the file system. In the embodiment illustrated in , a representation of the in-use regions of volume  (corresponding to regions A and B shown in ) may be derived using free block table  and the knowledge of the size of the volume maintained within super block . That is, any block of volume  that is not represented within free block table  may be considered an in-use block. In some embodiments, file system  (or another virtual device client ) may support one or more specific application programming interfaces or APIs that provide a representation or map of the in-use regions. In other embodiments, file system  may simply provide a copy of its free block table  via an API, allowing the caller of the API to derive the address ranges of the in-use regions. It is noted that the organization of file system metadata (or the metadata of other virtual device clients ) may differ from that described above, while still supporting a provision of a map identifying in-use regions of the underlying virtual or physical storage devices. For example, in one embodiment a linked list, a tree, or any other suitable data structure may be used instead of a free block table, and structures other than inodes may be used to represent files and\/or directories.","As described previously, volume server  may perform a synchronization operation on volume  from time to time, for example if a new mirror is attached to volume , if a replication operation is to be performed on volume , or if there is a crash during a regular write to a mirrored or replicated volume (which requires mirror consistency recovery). In preparation for the synchronization operation, in some embodiments volume server  may invoke one or more of the APIs described above to obtain or derive the in-use regions of the address space corresponding to volume . Depending on the specific virtualization features being supported within logical volume , volume server  may perform an additional translation step or steps to convert the in-use address ranges to physical address ranges on block devices . Such additional translation steps may be required, for example, in an environment employing multiple levels of virtualization, or where volume client  may not be provided with a physical layout of volume . Volume server  may then copy only the in-use regions of volume  to storage device set B to complete the desired synchronization operation. Using a single block-level mapping of in-use storage provided by a file system  or other virtual device client  to restrict the amount of data copied during synchronization may be more efficient than, for example, obtaining a list of all the directories and file contained in the file system, and then recursively traversing the directory structure, copying each directory and each file at each level of the directory structure. Using the mapping of in-use storage may also be more efficient than copying all the blocks, which is a traditional method employed in block-level mirroring operations.","In some embodiments, volume server  may also maintain a modification map (e.g., a bitmap) indicative of modifications as seen at the volume server, that may have been made to one or more mirrors of a mirrored logical volume. In such embodiments, e.g., during a volume-level synchronization operation, volume server  may use a combination of an in-use map and the modification map to avoid copying modified blocks that are no longer in use. For example, if a file or files is created and then removed, the corresponding blocks may be marked as modified in the modification map, but may still be identified as not being in use according to the in-use map. Such blocks, corresponding to the files that were created and then deleted, may not be copied by volume server  during the synchronization.","Volume clients other than file systems may also provide mapping information identifying in-use regions of a given volume to optimize replication operations.  is a block diagram illustrating one embodiment where a volume client in the form of a replication manager  provides mapping information on a logical volume (primary replication log volume A) to expedite synchronization required for replication of a primary storage system  at a replica storage system .","Storage within block devices A-C at a primary storage system  may be aggregated into one or more volumes  by a volume server . In order to prevent a complete loss of data at primary storage system (e.g., in the event of a natural disaster or a terrorist attack), a disaster recovery plan may be implemented. The disaster recovery plan may include a replication of volumes  at a replica storage system . A primary component (A) of recovery manager , incorporated within primary storage system , may coordinate the replication operation across a replication link  with a secondary component B of recovery manager , incorporated within replica storage system . In some embodiments, primary and replica storage systems may be physically separated to provide a more robust level of disaster recovery, e.g., primary storage system  may be located in a different city or even a different country than replica storage system . In such embodiments, replication link  may be a relatively slow link, for example over a WAN or over the Internet. It may therefore be desirable to limit the amount of data transferred over replication link .","Some applications, such as database management applications, may impose certain consistency requirements governing the sequence in which a set of write operations on different volumes  may be performed at primary storage system . For example, in order to preserve the ACID (atomicity, consistency, isolation, and durability) properties required of an online transaction processing system, a write operation may first have to be performed at a database log volume before a corresponding write operation is performed at a second volume containing database user tables. Such a strict ordering of writes may be required to allow the database management system to recover from a failure or an aborted transaction to a consistent database state. Replication write operations (i.e., write operations performed on block devices D-F to create replica volumes) may be performed asynchronously with respect to write operations at source volumes in some embodiments. In order to be able to provide the required transaction processing functionality from replica storage system  (e.g., in the event of loss of service at primary storage system ), replication manager  may be required to ensure that write ordering is preserved during replication. That is, in some embodiments replication manager  may be required to perform replication write operations at a set of replica volumes in the same sequence in which the corresponding write operations were performed at the respective source volumes. Such a requirement may be known as a \u201cwrite order fidelity\u201d requirement.","In order to satisfy write order fidelity requirements, in some embodiments replication manager  may utilize a primary replication log A at primary storage system , which may be mirrored (e.g., via a mirror attach) as a secondary replication log B at replica storage system . A replication log  (i.e., A or B) may store a sequence of entries or records, where each entry contains details of a particular data write operation\u2014for example, the address at which a write operation is to be performed, the contents of the data updated, etc. An entry for each data write targeted at a data volume configured for replication may be entered in replication log A, which may itself be configured as a special metadata volume. In some embodiments, an entry in a replication log  may include an explicit ordering indicator, such as a sequence number. Entries for database log writes and for user table writes may be created at primary replication log A by primary replication manager component A, sequenced by the database management system in the order required for database consistency to be maintained. Replication manager A may maintain a replication log header A that may contain a mapping of the portions of replication log A that contain valid data (e.g., the entries that may represent writes performed at primary storage system  since an earlier replication operation). For example, in one implementation the portion of replication log  used for storing entries representing write operations may be managed as a circular buffer, and replication log header A may include a record of the starting and ending entry positions of a region within the circular buffer containing write entries that have not yet been replicated. Data writes at block devices A-C for source volumes  may be performed by replication manager component A in an appropriate consistency-preserving order after the corresponding entries have been made in replication log A.","At some appropriate point in time suitable for a replication operation, for example, according to a replication scheduling policy, replication manager component A may attach secondary replication log B as a mirror to the volume containing replication log A, and the two mirrors may be synchronized by a volume server . In preparation for the mirror synchronization, volume server  may send a request to replication manager  for a mapping of in-use regions of replication log A, i.e., the regions containing write entries that have not yet been replicated at replica storage system . Replication manager  may provide a representation of replication log header A to volume server , which may copy only the in-use regions to replica storage system . Thus, instead of copying the entire replication log, only replication log header A and entries for write operations W, W, W, . . . WN within in-use regions of replication log A may be copied over replication link . Replication manager component B may then perform replication write operations in the same sequence (W, W, W, . . . WN) on block devices D-F, thus satisfying write order fidelity requirements. Any service (e.g., a service similar to replication manager ) that deploys a data update store such as a log (e.g., similar to the replication log described above) may utilize the above technique of using in-use mappings during synchronization operations. It is noted that a replication manager may be any software module or modules capable of supporting the replication functionality described above, which module or modules may be hosted at one or more computer hosts at primary and replica storage systems.","A mapping of in-use regions may also be used by a replication manager  during several other operations related to replication. For example, such a mapping may be used during initial synchronization of a replica, and may also be of use in cases where replication processing has been disabled for a long time (e.g., due to a long-term connection failure), resulting in the filling up of replication log A. In such cases where the replication log A has filled up, a resynchronization may require a copy of the underlying volume (instead of copying from the replication log). A modification map (e.g., a bitmap) representing modified regions of the volume may be employed to reduce the amount of copying required in such cases during the resynchronization of the replica. However, the in-use map may still be used (in combination with the modification map) to distinguish between in-use and free blocks within modified regions identified by the bitmap. Further, if a file has been written (causing a modification) and is then deleted (causing the blocks to no longer be in-use), the modified region corresponding to the file may not need to be copied if an in-use map is utilized. In-use maps may also be similarly used during mirror recovery after a crash or after transient storage failures.","The replication log volumes corresponding to replication log A may be termed content-aware volumes, as they may contain a map or header identifying their valid or in-use data blocks. Similar content-aware volumes may also be employed in other virtualization functions, such as during optimized snapshot operations or fast mirror resynchronization (FMR) operations, where, for example, data updates that have occurred within a specified time period since a previous snapshot update may be logged within one or more volumes. The technique described above, i.e., a provision of mapping information to a volume manager identifying in-use regions of a volume address space to optimize synchronization operations, may be used in various embodiments employing different types of content-aware volumes.","In one embodiment, mapping information identifying in-use regions of a volume address space may be provided to reduce the total amount of data copied to a backup storage device (such as a tape drive) during a backup operation. For example, some backup servers may be configurable to back up data either at a file level or at a block or \u201craw device\u201d level. Prior to performing a backup operation for a designated set of storage devices at a block level, the backup server may obtain mapping information (e.g., from one or more file systems), indicating the specific subset of blocks of the storage devices that are in use, and may copy only the in-use blocks to a backup storage device. Such an optimized block-level backup operation may be more efficient than a more conventional file-based backup operation, where, for example, the backup server may be required to traverse the directories or folders of one or more file systems and copy each file (or each file modified since a previous backup operation) individually to the backup storage device.","In addition to being used in block virtualization environments as described above, the technique of providing metadata identifying subsets of storage suitable for copying during a synchronization operation may also be employed in storage environments employing other kinds of virtualization, such as object-based virtualization. In an object virtualization environment, a virtual device server  may be configured to organize storage within storage devices  as higher-level logical objects (such as files) instead of using the block-based interface described above. Virtual storage may be named, managed, and made accessible using any desired base object as implemented by a virtual object device server, such as a file object or a database table object. Thus, in one embodiment, an object storage consumer may be presented with a virtual storage device  consisting of a collection of named files, and may perform file-based operations (such as reads from a file, writes to a file, increasing the size of a file, truncating a file, etc.) directly on the virtual storage device. Object-based virtualization may thus allow the offloading of functionality traditionally performed at a host computer system (such as the translation of a file name and offset within a file to a block device address) to a storage device such as an object storage device or OSD that may be optimized to perform the needed storage operations, freeing up resources at the host computers. In addition, once virtual objects have been created and configured, a virtual object device server may distribute metadata on the virtual objects to object storage consumers, allowing the object storage consumers to perform input\/output (I\/O) operations on the virtual objects without further interaction with virtual object device server. An object storage consumer may maintain a mapping similar to map , identifying in-use objects or in-use regions within an object device. In preparation for a synchronization operation, a virtual object device server may obtain the mapping from the object storage consumer, and may copy only the in-use objects or regions.",{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 8","b":["100","130","140","120","510","755","810","130","120","140","840","150","850"]},"In some embodiments, storage consumers such as application  may continue to perform I\/O on a virtual device client  while the synchronization operation is performed, or one or more I\/O operations may be in progress at the time the synchronization operation is begun. As a result, the mapping used by virtual device server  may be out-of-date when the synchronization operation is completed; i.e., there may be more or fewer in-use data blocks within a source volume  at the end of the synchronization operation than there were at the beginning, depending on the kind of I\/O (creates\/appends\/deletes etc.) performed or completed during the interim. In such embodiments, volume server  may be configured to revalidate the mapping after the completion of the synchronization operation, as shown in block  of . For example, a volume server  may retain the original mapping identifying the in-use regions of volume  provided by a file system  prior to the synchronization operation, and may request a second mapping after the synchronization has been completed. If the in-use regions identified using the second mapping differ from the in-use regions identified using the first mapping, in some embodiments, volume server  may be configured to attempt one or more resynchronization operations (blocks , ) to update the copied version of the data blocks in accordance with the latest changes at a source volume . In some rare cases, the entire region (e.g., a few megabytes) involved in recovery may need to be resynchronized. However, such cases may be infrequent enough that the overhead for such resynchronization may typically be fairly low.","In some embodiments, a virtual device server  may be configured to provide a consistent view of unused regions of a virtual device  (e.g., regions  of map ) across the source and target storage device sets A and B, in addition to synchronizing the in-use regions of virtual device  across the two sets of storage devices. Under normal operating conditions, the contents of an unused or unmapped block of data within virtual device  may not affect any operations of, or functionality provided by, a virtual client  such as file system . However, under certain error conditions (e.g., when a file system recovery after a system crash is interrupted by a second system crash), a virtual device client may attempt to access unused or uninitialized data blocks of virtual device , and may perform one or more operations based on the contents of the unused data blocks, which may result in data corruption or metadata corruption. In order to reduce any harmful consequences of accesses to unused or uninitialized data, a technique called virtual zeroing may be employed (blocks  and  of ) in some embodiments. In virtual zeroing, the unused regions of source and target storage devices may be \u201cvirtually\u201d filled with zeroes; that is, any request to read a block from an unused region of a virtual device may be trapped before an actual physical read operation on the underlying physical storage devices is performed, and a block filled with zeroes may be returned to the requester. It is noted that virtual zeroing may not require physical writing of data blocks of unused regions of virtual device  within storage devices ; instead, an indication or map of the unused regions as being filled with zeroes may be maintained as part of the metadata of virtual device , and may be distributed along with the remaining metadata to virtual device clients in some embodiments.","A second technique, called \u201csynchronize-mirrors-on-read\u201d, may also be employed to make unused regions of a virtual device  consistent with each other across the source and target storage device sets A and B in some embodiments. As illustrated in , when a request to perform a read operation on a block of virtual device  is received (block ) at a virtual device server  after a synchronization operation on device  has been performed, the virtual device server may check whether the requested block belongs to an in-use region (block ). If the requested block is not from an in-use region, the request may be identified as a request to read uninitialized data. The data stored in the requested block may be copied from the source storage device set A to target storage device set B (block ), and the data may be returned to the requester (block ). This may ensure that actions taken as a result of accessing an unused or uninitialized data block from the source set of storage devices A may be repeatable if the unused or uninitialized data block were later read from the copy stored at the synchronized set of storage devices B. In addition, a \u201csynchronize-mirrors-on-read\u201d technique may also be employed for virtual device  during file system recovery operations, so that any reads performed by the file system would result in consistency recovery at the block layer. Such a technique may be used in one embodiment, for example, in reconstructing a corrupted bitmap of in-use blocks. In some embodiments, a virtual device client such as a file system may explicitly request that a \u201csynchronize-mirrors-on-read\u201d technique be used, for example during recovery of a corrupted bitmap. While the \u201csynchronize-mirrors-on-read\u201d technique is in use, the in-use map may not be utilized in some embodiments (i.e., the use of the in-use map may be suspended temporarily).","It is noted that a synchronization operation may be required as result of a change (such as a mirror addition) in the configuration of a single virtual device  in some embodiments, while in other embodiments the synchronization may be between two or more existing volumes or devices. A synchronization operation may also be performed as a recovery operation after a failure in one embodiment, or to support a data migration (for example, from one data center to another) in another embodiment. It is also noted that in some embodiments, multiple virtual device clients  (such as file system ) may share space within a given virtual device , and virtual device server  may be configured to obtain a mapping of in-use regions from each virtual device client in such embodiments. In one embodiment, the technique of employing an in-use map as described above may be used where multiple volumes (which may collectively be referred to as a volume set) may be configured for use with a single file system.","In some embodiments, the virtual device server  may be configured to divide the virtual storage device  into smaller partitions, and to perform synchronization in smaller steps (e.g., one step for each partition). An in-use map corresponding to a given partition, or to the whole virtual storage device, may be obtained prior to each step, and used to identify blocks of the partition that are to be copied during the step. Revalidation of the map (and possible resynchronization of the partition) may be performed for each step. By dividing the synchronization operation into smaller steps in this manner, the likelihood of the maps being invalidated, and the overhead of any required resynchronizations, may be reduced.","In general, a virtual device server  may be any device or software module capable of providing virtualization functionality as described above, such as a server computer system, including one or more processors and one or more system memories. Some virtual device server functionality may be spread over multiple computer servers or hosts in some embodiments, or may be provided via devices such as virtualization switches or intelligent disk arrays. To provide high availability for virtual device server functionality, virtual device server  may be configured to run on a cluster of nodes, where a failure at one node may result in the virtual device server functionality running on that node to be taken over at another node.","A virtual device client  may be any type of device capable of interacting with a given virtual device  for data storage and retrieval. For example, in one embodiment a virtual device client  may be a server computer system, including one or more processors and one or more system memories, where the server system is configured to execute software such as one or more operating systems and\/or applications. In another embodiment, a virtual device client  may be a client computer system configured to access a given virtual device  via a separate server computer system. A virtual device client  may also be hosted within a virtualization switch that provides additional layers of virtualization on top of a virtual device . In other embodiments, a virtual device client  may be an embedded system configured to use application specific integrated circuit (ASIC) or field-programmable gate array (FPGA) technology to execute operations whereby a given virtual device  may be accessed. In some embodiments a virtual device client  and a virtual device server  may be co-located within the same server. Numerous other configurations of virtual device servers , and virtual device clients  are possible and contemplated.",{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 10","b":["1000","1010","130","120"]},"Although the embodiments above have been described in considerable detail, numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
