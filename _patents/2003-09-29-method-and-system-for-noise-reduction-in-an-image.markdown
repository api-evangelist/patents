---
title: Method and system for noise reduction in an image
abstract: In a specific embodiment of the present disclosure, a source image is smoothed to create a smoothed image, and an edge detector is used to create an edge layer. A blending controller is used to control a blending between the source image and the smoothed image. The blended destination image maintains detail while eliminating unwanted noise.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07668396&OS=07668396&RS=07668396
owner: Vixs Systems, Inc.
number: 07668396
owner_city: Toronto, Ontario
owner_country: CA
publication_date: 20030929
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","FIELD OF THE DISCLOSURE","DESCRIPTION OF THE PREFERRED EMBODIMENT(S)"],"p":["Video images, and especially analog video signals can be corrupted by varied types of temporal and spatial noise during acquisition, transmission, and recording of the image. Typical types of noise include thermal noise, single frequency modulation distortion noise, and impulse noise. Noise reduction techniques that apply linear or non-linear filters on video signals can reduce the amount of noise. One such technique is to apply a low-pass filter on the video signal. However, simple low-pass filtering tends to produce over-smoothed video that appears blurry. Other filters such as Wiener filters, Kalman filters are better at removing one or more of spatial noise or temporal noise but can be expensive in terms of implementation and device costs.","Therefore, a method of noise reduction that overcomes these problems would be useful.","The present disclosure relates to data processing, and more specifically to image and video processing.","The use of the same reference symbols in different drawings indicates similar or identical items.","In a specific embodiment of the present disclosure, a source image is smoothed to create a smoothed image, and an edge detector is used to create an edge layer. A blending controller is used to control a blending between the source image and the smoothed image. The blended destination image maintains detail while eliminating unwanted noise. Specific implementations of the present disclosure are better understood with reference to .",{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 1","FIG. 1","FIG. 2"],"b":"100"},"System  comprises noise filter , edge detector  and blending controller . In addition, system  includes memory (not specifically shown) for storing image information including source image , smoothed layer , edge layer , and destination layer . The layers are accessible by the noise filter , edge detector  and blending controller .","A first image layer is received at step . Referring to , source layer  is an example of such a first image layer. The source layer  is one of three component layers, along with layers  and , which make up the source image . Examples of types of component layers - include RGB component layers, YUV component layers, and component layers of any other color spaces. The system  receives source image  by receipt of a video stream or by accessing a memory location.","The source providing the source image can be a head end device, a TV receiver, a Video Cassette Recorder, a DVD (Digital Versatile Disk) player, or other video sources.","Upon receipt of the source image , each image layer - is processed independently. For purposes of discussion, data flow with respect to  will be discussed with respect to one of the source layers, source layer . In addition, it will be appreciated that the layer information may be stored and processed as frames or partial frames, such as line buffers depending upon a systems specific implementation. For ease of discussion, it will be assumed the image information is stored as entire frames.","At step , a first edge layer is determined based on the first image layer. With reference to , source layer  is processed by the edge detector  to determine the edge layer .","The edge layer  comprises a plurality of memory locations corresponding to the plurality of pixels of an image. The edge layer  contains a pixel edge indicator for each pixel that indicates whether a pixel is associated with an edge of an image. In one embodiment, a pixel edge indicator is a Boolean representation indicating the presence or absence of an edge. For example, a positive Boolean pixel edge indicator would indicate that a specific pixel is part of an image edge.","The edge detector  can detect edges by determining a gradient for each pixel location. For example, the horizontal and vertical gradient of a pixel can be calculated using the equations\n\nGrad(1)\u2212(1); and\n\nGrad(1)\u2212(1).\n","A rectangular-to-polar conversion, such as M(i,j)=SQRT(Grad_x+grad_y), can then be performed to get a magnitude of the edge. Alternatively, the square root operation can be removed and the magnitude compared to a predefined edge-level that controls what is considered an edge, and ultimately controls how many details will be preserved in a final destination layer. For example, if the magnitude is larger than the predefined value of the edge-level, then the corresponding pixel is said to be an edge pixel. In other embodiments, the edge detector  can determine the presence of an edge solely based on a pixel's horizontal or vertical edge component.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 3","FIG. 3","FIG. 4"],"b":["212","130"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 4","FIG. 4"],"b":["214","212"]},"For example, the number of Boolean edge pixels in layer  within +\/\u2212 pixels of pixel P,) is indicated by the value 5 in layer . This value is stored in the lower 4-bits of the pixel P(,) in the weighted edge layer . The number of edge pixels within the box  of Boolean edge layer  is 12. The number of these pixels that are two pixels away from the pixel location P(,) is determined by subtracting the number of edge pixels within the box  from the edge pixels within the box , which results in a value of 7. This value is stored in the upper 4-bits of pixel P(,) in layer . Therefore the weighted pixel value of pixel P(,) is \u201c75\u201d. It will be appreciated that many other schemes for determining and\/or storing weighted edge values are possible.","Returning to , at step  the first image layer is blended with a first other layer based upon the first edge layer. In one embodiment, the first other layer is the source layer .","The blending controller  of  is used to implement the blending, and uses information of edge layer  to blend the source layer  with the smoothed layer  to preserve edges and fine structures in the source image layer . When the edge layer contains only Boolean edge information one of two blending ratios can be implemented by the blending controller  at each pixel location. However, typically, the ability to blend a pixel based on one of only two blending ratios will not provide enough blending options to provide a destination image with an enhanced image.","To provide additional levels of blending, a weighted edge layer, such as is illustrated in  can be used by the blending controller  to select one of more than two blending ratios with respect to the blending of a specific pixel.  discloses a specific blending method for use with weighted edge values.","At step , a determination is made whether the pixel edge value labeled WEIGHT is greater than a variable T. WEIGHT represent the number of edge pixels within +\/\u22121 pixel of the pixel being scaled. With respect to , this would be the value stored at the lower 4 bits of a pixel location. If WEIGHT is greater than threshold T, flow proceeds to step , where the source image pixel is copied directly to the destination layer, such as destination layer . Otherwise, flow proceeds to step .","At step , a determination is made whether the pixel edge value WEIGHT is greater than T. If so, flow proceeds to step , where the source image pixel is blended with the smoothed image at a ratio of 3:1. Otherwise, flow proceeds to step .","At step , a determination is made whether the pixel edge value WEIGHT is greater than T. If so, flow proceeds to step :, where the source image pixel is blended with the smoothed image at a ratio of 1:1. Otherwise, flow proceeds to step .","At step , a determination is made whether the pixel edge value labeled WEIGHT is greater than a variable T. WEIGHT represent the number of edge pixels at +\/\u22122 pixels of the pixel being scaled. With respect to , this would be the value stored at the upper 4 bits of a pixel location. If WEIGHT is greater than the value of X4 flow proceeds to step , where the source image pixel is blended with the smoothed image at a ratio of 1:3. Otherwise, flow proceeds to step .","At step , the destination pixel is set equal to the smoothed pixel.","At step , a determination is made whether there is another pixel. If so, flow proceeds to step  to process the next pixel, otherwise the flow ends.","The variables T, T, T, and T are predetermined, and as such can be preset or user defined variables. In another embodiment, the variables T through T can be statistically determined based upon the source image. In a specific embodiment, the variables T to T are set to 7, 3, 1, and 3 respectively.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 6"},"At step , a first image layer of an image is received. In a manner similar to step  of .","At step , the first other layer is determined. Typically, the first other layer is determined by noise filter , which filters the source layer to provide a smoothed image. Noise filter  can be any type of noise filter, but will typically be either a low-pass filter or median filter depending upon the cost-performance ratio considerations of system . In one embodiment, a low-pass filter consisting of a five-tap horizontal filter and a five-tap vertical filter is used. Different coefficients can be used depending upon a desired noise level. In one embodiment, three noise levels implemented by the noise filters have cut-off frequencies of 0.7 fs, 0.5 fs, and 0.3 fs. An intermediate smoothing layer can be formed by applying the low-pass filter on the horizontal direction and storing the results in memory, with a final smoothed layer including filtering in the vertical direction being formed prior to blending. A 2-dimensional median filter can be used supporting three sizes: 1\u00d71, 3\u00d73, and 5\u00d75.","At step , a first edge layer is determined in a manner similar to that discussed with respect to step  of .","At step , the first image and the first other layer are blended in a manner similar to that discussed with respect to step  of .",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 7","b":["41","42","43","21","22","23"]},"Step  is similar to step  but receives a second source image layer instead of the first source image layer.","Step  is similar to step , but a second edge layer based on the second source image layer is determined.","Step  is similar to step , but the second source image layer is blended with the second other layer instead of the first source image layer being blended with the first layer. The result of step  is a second blended video layer.","At step , a composite image combining the first and second blended video layers is provided. It will be appreciated that typically, additional steps, analogous to steps - will be performed to generate a third blending layer from which a composite image is formed.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 8","b":["500","510","512","514","522","520","524","526"]},"The input output (I\/O) adapter  can be further connected to various peripherals such as disk drives , printer , removable storage devices , as well as other standard and proprietary I\/O devices.","The user interface adapter  can be considered to be a specialized I\/O adapter. The adapter  is illustrated to be connected to a mouse , and a keyboard . In addition, the user interface adapter  may be connected to other devices capable of providing various types of user control, such as touch screen devices.","The communications interface adapter  is connected to a bridge  such as is associated with a local or a wide area network, and a modem . By connecting the system bus  to various communication devices, external access to information can be obtained.","The multimedia controller  will generally include a video graphics controller capable of generating smoothed images in the manner discussed herein that can be displayed, saved, or transmitted. In a specific embodiment illustrated the multimedia controller  can include a system of , which can be implemented in hardware or software. Software implementations can be stored in any on of various memory locations, including RAM  and ROM , in addition software implementation software can be stored in the multimedia controller . When implemented in software, the system of  may be a data processor within the controller  for executing instruction, or it maybe a shared processor, such as CPU .","The preceding detailed description of the figures, reference has been made to the accompanying drawings which form a part thereof, and to which show by way of illustration specific embodiments in which the invention may be practiced. It will be appreciated that many other varied embodiments that incorporate the teachings herein may be easily constructed by those skilled in the art. For example, intermediate edge layers can be used to derive the final edge layer used by the blending controller . Once such intermediate layer would contain pixel information that indicates horizontally adjacent pixel information. For example,  illustrates an intermediate table, where each pixel stores the number of edge pixels within +\/\u22121 horizontal pixel in the lower four-bits of the byte, and the number of edge pixels at +\/\u22122 horizontal pixels in the upper four-bits of the byte. Such an intermediate layer allows for efficient calculation of the final edge layer. For example, the number of edge pixels within +\/\u2212 pixels for a pixel P(x, y) can be determined by adding the lower four bits of pixels P(x, y\u22121), P(x,y), and P(x, y+1). In a similar manner, the number of edge pixels at +\/\u22122 pixels for a pixel P(x, y) is determined by adding the upper four bits of P(x, y\u22122), P(x, y\u22121), P(x,y), P(x, y+1), and P(x, y+2) to the lower four bits of P(x, y\u22122) and P(x, y+2). Utilizing an intermediate layer in this fashion reduces the computations needed to calculate the weighted edge values by reusing the horizontal edge data. Accordingly, the present disclosure is not intended to be limited to the specific form set forth herein, but on the contrary, it is intended to cover such alternatives, modifications, and equivalents, as can be reasonably included within the spirit and scope of the invention. The preceding detailed description is, therefore, not to be taken in a limiting sense, and the scope of the present disclosure is defined only by the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present disclosure may be better understood, and its features and advantages made apparent to those skilled in the art by referencing the accompanying drawings.",{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIGS. 6 and 7"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
