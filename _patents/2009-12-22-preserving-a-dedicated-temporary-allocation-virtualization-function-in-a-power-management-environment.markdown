---
title: Preserving a dedicated temporary allocation virtualization function in a power management environment
abstract: A mechanism is provided for temporarily allocating dedicated processors to a shared processor pool. A virtual machine monitor determines whether a temporary allocation associated with an identified dedicated processor is long-term or short-term. Responsive to the temporary allocation being long-term, the virtual machine monitor determines whether an operating frequency of the identified dedicated processor is within a predetermined threshold of an operating frequency of one or more operating systems utilizing the shared processor pool. Responsive to the operating frequency of the identified dedicated processor failing to be within the predetermined threshold, the virtual machine monitor either increases or decreases the frequency of the identified dedicated processor to be within the predetermined threshold of the operating frequency of the one or more operating systems utilizing the shared processor pool and temporarily allocates the identified dedicated processor to the shared processor pool.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08595721&OS=08595721&RS=08595721
owner: International Business Machines Corporation
number: 08595721
owner_city: Armonk
owner_country: US
publication_date: 20091222
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The present application relates generally to an improved data processing apparatus and method and more specifically to mechanisms for preserving dedicated temporary allocation virtualization functions in a power management environment.","There is an emerging customer requirement for better power and thermal management in server systems. Customers increasingly expect systems to behave in such a way as to be power-efficient. Customers also want the ability to set policies that trade off power and performance in order to meet their particular objectives. For example, customers want to be able to over-provision their installations relative to the nominal maximum power and temperature values of the systems that they install but be able to take advantage of the variability in workloads and utilization to ensure that the systems operate correctly and within the limits of the available power and cooling.","IBM\u00ae's EnergyScale\u2122 controls the power and temperature of running systems in a performance-aware manner under the direction of a set of policies and objectives specified through EnergyScale\u2122's user interfaces. To do so, EnergyScale\u2122 implements detailed, periodic measurement of processor core power and temperature, measurement of the power consumed by the entire system board as well as any plugged-in processor cards and measurement of the memory power and temperature to the system. EnergyScale\u2122 uses the results of these measurements to adjust the system's operation and configuration to meet specified objectives for power, temperature, and performance by using closed-loop feedback control operating in real time.","One of the tools used by EnergyScale\u2122 to control power is to adjust the frequency and voltage of the processor chips and cores in the system to control the power dissipation as a function of the user specified energy scale policy. Early EnergyScale\u2122 designs required that the voltage and frequency of all central processing units (CPUs) in the system maintained at the same value. As the EnergyScale\u2122 design and implementation became more sophisticated, it became possible to have cores in a system running at different frequencies and voltages and allowed the implementation of more sophisticated power savings algorithms.","However, many multi-threaded applications are written assuming that all CPUs that the application runs on are running at the same frequencies and such applications may not function properly when running on processors at different frequencies. To avoid such application problems, one possible design is to run the processors of a logical partition at the same frequency. This design also requires that all processors in the shared pool run at the same frequency, because it is not possible with currently known technologies to monitor the work and change frequencies at the rate at which micro-partitions are dispatched.","In one illustrative embodiment, a method, in a data processing system, is provided for temporarily allocating one or more dedicated processors to a shared processor pool. The illustrative embodiment sends an indication to a virtual machine monitor that an idle dedicated processor is available for temporary allocation to a shared processor pool, thereby forming an identified dedicated processor in response to processor temporary allocation being enabled in the logically partitioned data processing system. The illustrative embodiment determines whether the temporary allocation associated with the identified dedicated processor is long-term or short-term. The illustrative embodiment determines whether an operating frequency of the identified dedicated processor is within a predetermined threshold of an operating frequency of one or more operating systems utilizing the shared processor pool in response to the temporary allocation being long-term. The illustrative embodiment either increases or decreases the frequency of the identified dedicated processor to be within the predetermined threshold of the operating frequency of the one or more operating systems utilizing the shared processor pool in response to the operating frequency of the identified dedicated processor failing to be within the predetermined threshold of the operating frequency of the one or more operating systems utilizing the shared processor pool. The illustrative embodiment then allocates the identified dedicated processor to a shared processor pool.","In other illustrative embodiments, a computer program product comprising a computer useable or readable medium having a computer readable program is provided. The computer readable program, when executed on a computing device, causes the computing device to perform various ones, and combinations of, the operations outlined above with regard to the method illustrative embodiment.","In yet another illustrative embodiment, a system\/apparatus is provided. The system\/apparatus may comprise one or more processors and a memory coupled to the one or more processors. The memory may comprise instructions which, when executed by the one or more processors, cause the one or more processors to perform various ones, and combinations of, the operations outlined above with regard to the method illustrative embodiment.","These and other features and advantages of the present invention will be described in, or will become apparent to those of ordinary skill in the art in view of, the following detailed description of the example embodiments of the present invention.","In known dedicated temporarily allocation functions, a temporarily allocated central processing unit (CPU) may be running at a different frequency from CPUs of a shared processor pool. Current designs require that the frequency of the temporarily allocated CPU must be the same as the frequency of the processors of the shared processor pool. If the frequency difference between the CPU of the temporarily allocating partition and the shared processor pool is large, the time scale required to change the frequency to match the shared processor pool frequency may exceed the time scale of temporary allocation intervals, thus the temporary allocation function is defeated. Even if the temporary allocation is delayed when the temporarily allocated CPU is joining the shared processor pool, the temporarily allocating partition expects that the CPU becomes immediately available when the temporarily allocating partition has work to dispatch on the CPU. In general, once the temporarily allocating partition has work to dispatch on the temporarily allocated CPU, a delay of even a few milliseconds before the temporarily allocating partition can use the CPU again is unacceptable.","The illustrative embodiments provide a mechanism for allowing a temporarily allocated processor to be temporarily allocated to a shared processor pool operating at a different frequency to thereby preserve the dedicated temporary allocation virtualization function in a power management environment. In one illustrative embodiment, the dedicated temporarily allocation function is limited so that dedicated processor partitions and shared processor partitions may run at any frequency. In another illustrative embodiment, the range of frequencies at which the temporarily allocating and shared processor pool CPUs is limited so that temporary allocation of an idle CPU from a dedicated processor partition may occur.","Thus, the illustrative embodiments may be utilized in many different types of data processing environments including a distributed data processing environment, a single data processing device, or the like. In order to provide a context for the description of the specific elements and functionality of the illustrative embodiments,  are provided hereafter as example environments in which aspects of the illustrative embodiments may be implemented. While the description following  will focus primarily on a single data processing device implementation of a mechanism that allows a temporarily allocated processor to be temporarily allocated to a shared processor pool operating at a different frequency, this is only an example and is not intended to state or imply any limitation with regard to the features of the present invention. To the contrary, the illustrative embodiments are intended to include distributed data processing environments and embodiments in which a temporarily allocated processor may be allowed to temporarily allocate to a shared processor pool operating at a different frequency.","With reference now to the figures and in particular with reference to , example diagrams of data processing environments are provided in which illustrative embodiments of the present invention may be implemented. It should be appreciated that  are only examples and are not intended to assert or imply any limitation with regard to the environments in which aspects or embodiments of the present invention may be implemented. Many modifications to the depicted environments may be made without departing from the spirit and scope of the present invention.","In the illustrative embodiments, a computer architecture is implemented as a combination of hardware and software. The software part of the computer architecture may be referred to as microcode or millicode. The combination of hardware and software creates an instruction set and system architecture that the rest of the computer's software operates on, such as Basic Input\/Output System (BIOS), Virtual Machine Monitors (VMM), Hypervisors, applications, etc. The computer architecture created by the initial combination is immutable to the computer software (BIOS, etc), except through defined interfaces which may be few.","Referring now to the drawings and in particular to , there is depicted a block diagram of a data processing system with which aspects of the illustrative embodiments may advantageously be utilized. As shown, data processing system  includes processor units -. Each of processor units -includes a processor and a cache memory. For example, processor unit contains processor and cache memory , and processor unit contains processor and cache memory ","Processor units -are connected to main bus . Main bus  supports system planar  that contains processor units -and memory cards . System planar  also contains data switch  and memory controller\/cache . Memory controller\/cache  supports memory cards  that include local memory  having multiple dual in-line memory modules (DIMMs).","Data switch  connects to bus bridge  and bus bridge  located within native I\/O (NIO) planar . As shown, bus bridge  connects to peripheral components interconnect (PCI) bridges  and  via system bus . PCI bridge  connects to a variety of I\/O devices via PCI bus . As shown, hard disk  may be connected to PCI bus  via small computer system interface (SCSI) host adapter . Graphics adapter  may be directly or indirectly connected to PCI bus . PCI bridge  provides connections for external data streams through network adapter  and adapter card slots -via PCI bus .","Industry standard architecture (ISA) bus  connects to PCI bus  via ISA bridge . ISA bridge  provides interconnection capabilities through NIO controller  having serial connections Serial 1 and Serial 2. A floppy drive connection, keyboard connection, and mouse connection are provided by NIO controller  to allow data processing system  to accept data input from a user via a corresponding input device. In addition, non-volatile RAM (NVRAM) , connected to ISA bus , provides a non-volatile memory for preserving certain types of data from system disruptions or system failures, such as power supply problems. System firmware  is also connected to ISA bus  for implementing the initial Basic Input\/Output System (BIOS) functions. Service processor  connects to ISA bus  to provide functionality for system diagnostics or system servicing.","The operating system (OS) is stored on hard disk , which may also provide storage for additional application software for execution by a data processing system. NVRAM  is used to store system variables and error information for field replaceable unit (FRU) isolation. During system startup, the bootstrap program loads the operating system and initiates execution of the operating system. To load the operating system, the bootstrap program first locates an operating system kernel image on hard disk , loads the OS kernel image into memory, and jumps to an initial address provided by the operating system kernel. Typically, the operating system is loaded into random-access memory (RAM) within the data processing system. Once loaded and initialized, the operating system controls the execution of programs and may provide services such as resource allocation, scheduling, input\/output control, and data management.","The illustrative embodiment may be embodied in a variety of data processing systems utilizing a number of different hardware configurations and software such as bootstrap programs and operating systems. The data processing system  may be, for example, a stand-alone system or part of a network such as a local-area network (LAN) or a wide-area network (WAN). As stated above,  is intended as an example, not as an architectural limitation for different embodiments of the present invention, and therefore, the particular elements shown in  should not be considered limiting with regard to the environments in which the illustrative embodiments of the present invention may be implemented.","With reference now to , a block diagram of an exemplary logically partitioned platform is depicted in which the illustrative embodiments may be implemented. The hardware in logically partitioned platform  may be implemented, for example, using the hardware of data processing system  in .","Logically partitioned platform  includes partitioned hardware , operating systems , , , , and virtual machine monitor . Operating systems , , , and  may be multiple copies of a single operating system or multiple heterogeneous operating systems simultaneously run on logically partitioned platform . These operating systems may be implemented, for example, using OS\/400, which is designed to interface with a virtualization mechanism, such as partition management firmware, e.g., a hypervisor. OS\/400 is used only as an example in these illustrative embodiments. Of course, other types of operating systems, such as AIX\u00ae and Linux\u00ae, may be used depending on the particular implementation. Operating systems , , , and  are located in logical partitions , , , and , respectively.","Hypervisor software is an example of software that may be used to implement platform (in this example, virtual machine monitor ) and is available from International Business Machines Corporation. Firmware is \u201csoftware\u201d stored in a memory chip that holds its content without electrical power, such as, for example, a read-only memory (ROM), a programmable ROM (PROM), an erasable programmable ROM (EPROM), and an electrically erasable programmable ROM (EEPROM).","Logical partitions , , , and  also include partition firmware loader , , , and . Partition firmware loader , , , and  may be implemented using IPL or initial boot strap code, IEEE-1275 Standard Open Firmware, and runtime abstraction software (RTAS), which is available from International Business Machines Corporation.","When logical partitions , , , and  are instantiated, a copy of the boot strap code is loaded into logical partitions , , , and  by virtual machine monitor . Thereafter, control is transferred to the boot strap code with the boot strap code then loading the open firmware and RTAS. The processors associated or assigned to logical partitions , , , and  are then dispatched to the logical partition's memory to execute the logical partition firmware.","Partitioned hardware  includes a plurality of processors -, a plurality of system memory units -, a plurality of input\/output (I\/O) adapters -, and storage unit . Each of the processors -, memory units -, NVRAM storage , and I\/O adapters - may be assigned to one of multiple logical partitions , , , and  within logically partitioned platform , each of which corresponds to one of operating systems , , , and .","Virtual machine monitor  performs a number of functions and services for logical partitions , , , and  to generate and enforce the partitioning of logical partitioned platform . Virtual machine monitor  is a firmware implemented virtual machine identical to the underlying hardware. Thus, virtual machine monitor  allows the simultaneous execution of independent OS images , , , and  by virtualizing all the hardware resources of logical partitioned platform .","Service processor  may be used to provide various services, such as processing of platform errors in logical partitions , , , and . Service processor  may also act as a service agent to report errors back to a vendor, such as International Business Machines Corporation. Operations of the different logical partitions may be controlled through a hardware system console . Hardware system console  is a separate data processing system from which a system administrator may perform various functions including reallocation of resources to different logical partitions.","Those of ordinary skill in the art will appreciate that the hardware in  may vary depending on the implementation. Other internal hardware or peripheral devices, such as flash memory, equivalent non-volatile memory, or optical disk drives and the like, may be used in addition to or in place of the hardware depicted in . Also, the processes of the illustrative embodiments may be applied to a multiprocessor data processing system, without departing from the spirit and scope of the present invention.","Again, the issue with known dedicated temporarily allocation functions is that the temporarily allocated processor(s) may be running at a very different frequency from processors in a shared processor pool. The illustrative embodiments provide a mechanism for allowing a temporarily allocated processor to be temporarily allocated to a shared processor pool operating at a different frequency to thereby preserve the dedicated temporary allocation virtualization function in a power management environment.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 3","b":["300","310","320","330","340","310","312","314","316","320","322","324","326","330","332","334","336","340","342","344","346","300","310","320","330","340"]},"LPARs , , , and  may communicate with one another through virtualization layer . Virtualization layer  may be software that performs communications and resource management to allow multiple instances of OSs , , , and  to run on logically partitioned data processing system  at the same time. Virtualization layer  performs tasks such as processor time slice sharing, memory allocation, or the like. Virtualization layer  may be, for example, a hypervisor or a virtual machine monitor, such as virtual machine monitor  or .","In this example, logically partitioned platform  may comprise dedicated LPARs  and , shared LPARs  and , and processors , , , , , , , and  within partitioned hardware  under control of virtualization layer . Processors  and  may be dedicated resources and may be assigned to dedicated LPAR  as whole units by virtualization layer . Processors  and  may also be dedicated resources and may be assigned to dedicated LPAR  as whole units by virtualization layer . However, processors , , , and  may be part of shared processor pool  and may be configured by virtualization layer  based on the requirements of shared LPARs  and . That is, virtualization layer  may allocate one or more of processors , , , and  from shared processor pool  to shared LPARs  and .","In allocating processors , , , , , , , and  to LPARs , , , and  each processor may be allocated and configured to run at the frequency of the OS executing on each of LPARs , , , and . For example, processors  and  allocated to LPAR  may be running at one frequency of OS , while processors  and  allocated to LPAR  may be running at a second frequency of OS , while processors , , , and  in the shared processor pool are running at a third frequency of OSs  and . However, when OS  and  on LPARs  and , respectively, have no work to perform on processors , , , or , one or more of the dedicated processors , , , and  may be temporarily allocated to shared processor pool .","In one illustrative embodiment, the temporary allocation of one or more of processors , , , and  by LPARs  or  is differentiated based on whether the processor is idle but not folded or idle as a result of folding. Processor folding is a technique used by an OS to steer work away from one or more of its allocated processors. That is, as the processor utilization of a partition decreases below a threshold, the OS will fold an allocated processor such that no work is dispatched and no interrupts are directed to the folded processor. Folding\/unfolding decisions are evaluated by the OS on a time-scale of seconds. Processor folding in micro-partitions helps with the performance of the shared processor pool by reducing dispatching. Processor folding in dedicated processor partitions helps with power savings and\/or improved temporary allocation to the shared processor pool.","As an example of the folding\/unfolding decisions made by an operating system, an operating system, such as OS , evaluates whether folding is enabled on LPAR  every n seconds. If OS  determines that folding is enabled for LPAR , then OS  determines whether the workload for processors  and  is below a certain threshold. If OS  determines that the workload for processors  and  is below the predetermined threshold, then OS  chooses either processor  or , for this example processor , for folding and prevents any further workload to be queued up for processor , disables interrupts to processor , or the like, in order that processor  will finish all current workload and become idle. Alternatively, if OS  determines that processor  is folded and the workload for processor  is above a certain threshold, then OS  chooses processor  for unfolding, enables interrupts to processor , and allows work to be queued for processor , or the like.","Thus, in this illustrative embodiment, an allocated processors temporary allocation occurs when OS  and\/or OS  has no work to do on their respectively allocated one or more of processors , , , and . A potential processor temporary allocation is \u201clong-term\u201d if the allocated processor is idle as a result of a processor folding and \u201cshort-term\u201d if the allocated processor is idle but not folded. For a potential temporary allocation that is \u201clong-term\u201d, the OS will tolerate long delays (up to hundreds of milliseconds) before it regains control of its allocated processor. This is because the OS makes folding decisions on a time-scale of seconds. For a potential temporary allocation that is a short-term, the temporarily allocating OS expects to gain immediately on the processor if the OS wants to execute work on its allocated processor.","For example, if OS  determines that the workload on processor  or LPAR  has dropped below a threshold, OS  may decide to fold the processor , as described above. When processor  becomes idle and the processors temporary allocation is enabled in data processing system , then OS  determines whether processor  is idle due to folding, then OS  sends an indication to virtualization layer  that processor  is available for a \u201clong-term\u201d temporary allocation. If OS  determines that processor  is idle but not due to folding, then OS  sends an indication to virtualization layer  that processor  is available for a \u201cshort-term\u201d temporary allocation. Upon receiving the notification, virtualization layer  identifies the current operating frequency of processor .","In this illustrative embodiment, if the temporary allocation is a \u201clong-term\u201d temporary allocation, then virtualization layer  determines the operating frequency of the OSs utilizing shared processor pool  to which virtualization layer  is attempting to allocate processor . If the operating frequency of the OSs utilizing shared processor pool  is approximately equal as the operating frequency of processor , then virtualization layer  allocates processor  to shared processor pool . In the illustrative embodiments, the term approximately equal may mean that the operating frequency of processor  is within a predetermined threshold of the operating frequency of the OSs in the shared LPARs. If the operating frequency of the OSs utilizing shared processor pool  is not approximately equal to the operating frequency of processor , then virtualization layer  either increases or decreases the frequency of processor  to be approximately the same as the operating frequency of the OSs utilizing shared processor pool  and allocates processor  to shared processor pool .","If however, the temporary allocation is a \u201cshort-term\u201d temporary allocation, then virtualization layer  determines the operating frequency of the OSs utilizing shared processor pool  to which virtualization layer  is attempting to allocate processor . If the operating frequency of the OSs utilizing shared processor pool  is approximately equal to the operating frequency of processor , then virtualization layer  allocates processor  to shared processor pool . If the operating frequency of the OSs utilizing shared processor pool  is not approximately equal to the operating frequency of processor , then virtualization layer  does not allocate processor . Whether shared processor pool  has been allocated to processor  on a \u201clong-term\u201d basis or a \u201cshort-term\u201d basis, the OSs utilizing shared processor pool  may execute workload on processor  until a request is received in virtualization layer  from OS  indicating that the temporarily allocated processor is needed.","Upon receiving the notification, virtualization layer  determines whether the temporary allocation was \u201clong-term\u201d or \u201cshort-term\u201d. If the temporary allocation was \u201cshort-term\u201d, then virtualization layer  interrupts all work on processor  and hands control of processor  back to OS . If the temporary allocation was \u201clong-term\u201d, virtualization layer  returns processor  to its original operating frequency, if needed, and hands control of processor  back to OS .","In another illustrative embodiment, the temporary allocation of one or more of processors , , , and  by LPARs  or  is also based on whether the potential processor temporary allocation is \u201clong-term\u201d if the allocated processor is idle as a result of a processor folding and \u201cshort-term\u201d if the allocated processor is idle but not folded. However, some \u201cshort-term\u201d temporary allocations may be allowed based on the difference between the operating frequency of the temporarily allocated processor and the operating frequency of the OSs utilizing shared processor pool  to which virtualization layer  is attempting to allocate processor .","Similar to the previous embodiment, if OS  determines that the workload on processor  has dropped below a threshold, OS  may decide whether the workload drop is a result of the processor  folding. If OS  determines that processor  is idle due to folding, then OS  sends an indication to virtualization layer  that processor  is available for a \u201clong-term\u201d temporary allocation. If OS  determines that processor  is idle but not due to folding, then OS  sends an indication to virtualization layer  that processor  is available for a \u201cshort-term\u201d temporary allocation. Once OS  determines whether the temporary allocation is to be either \u201clong-term\u201d or \u201cshort-term\u201d, OS  sends a notification to virtualization layer . Upon receiving the notification, virtualization layer  identifies the current operating frequency of processor  (Fded) and the operating frequency of the OS in the shared LPAR (Fsha) to which virtualization layer  is attempting to allocate processor .","In this illustrative embodiment, if the operating frequency of the OSs utilizing shared processor pool  is approximately equal to the operating frequency of processor , then virtualization layer  allocates processor  both for a \u201clong-term\u201d basis and for a \u201cshort-term\u201d potential temporary allocation. If the current operating frequency of processor  (Fded) is greater than the operating frequency of the OSs utilizing shared processor pool  (Fsha), then no temporary allocation occurs for a \u201cshort-term\u201d potential temporary allocation. Temporary allocation does occur for a \u201clong-term\u201d potential temporary allocation. Virtualization layer  drops the frequency and the corresponding voltage of processor  to Fsha for the temporary allocation. Increasing the frequency takes a longer period of time because the OS may deal with processor  taking a second or so to recover to Fded and the time it takes to increase the frequency is tolerated by the OS. If the current operating frequency of processor  (Fded) is less than the operating frequency of the OSs utilizing shared processor pool  (Fsha), then temporary allocation occurs for potential \u201clong-term\u201d and \u201cshort-term\u201d temporary allocation. Virtualization layer  increases the frequency to Fsha before temporary allocation occurs. The increase in frequency may take a longer period of time if voltage also has to be adjusted. However, the frequency is quickly dropped to Fded when the temporarily allocating LPAR wants to schedule work on the temporarily allocated processor.","Whether the shared LPAR has been allocated processor  on a \u201clong-term\u201d basis or a \u201cshort-term\u201d basis, the shared LPAR may execute workload on processor  until a request is received in virtualization layer  from OS  indicating that the temporarily allocated processor is needed. Upon receiving the notification, virtualization layer  determines whether the temporary allocation was \u201clong-term\u201d or \u201cshort-term\u201d. If the temporary allocation was \u201cshort-term\u201d and the frequency was not changed, then virtualization layer  interrupts all work on processor  and hands control of processor  back to OS . If the temporary allocation was \u201cshort-term\u201d and the frequency was increased or changed, then virtualization layer  interrupts all work on processor , changes the frequency of processor  back to its original operating frequency, and hands control of processor  back to OS . For a \u201clong-term\u201d temporary allocation, after the temporarily allocating partition requests the temporarily allocated CPU back, virtualization layer  returns processor  to its original operating frequency, if needed, and hands control of processor  back to OS . For a \u201clong-term\u201d temporary allocation, virtualization layer  may leave the temporarily allocated processor in the shared processor pool until the current unit of work is completed and\/or until some period of time expires because the temporarily allocating OS does not expect the CPU back immediately. If virtualization waits for some period of time to expire and the current unit of work has still not completed, then virtualization layer  may interrupt all work on processor , change the frequency of processor  back to its original operating frequency, and hand control of processor  back to OS . Additionally, if a condition arises requiring a \u201clong-term\u201d temporarily allocated processor to be immediately reclaimed, virtualization layer  may choose to reclaim processor  immediately, as in the case of a \u201cshort-term\u201d temporary allocation, change the frequency of processor  back to its original operating frequency, if necessary, and hand control back to OS .","In yet another illustrative embodiment, virtualization layer  may be preprogrammed to always allow processor temporary allocation and, thus, maintain the operating frequencies of OSs within dedicated LPARS which are enabled to temporarily allocated processors (Fded) to be within a relative frequency (\u0394f) of the operating frequency of the OSs utilizing shared processor pool  (Fsha). The relative frequency (\u0394f) may be any frequency range where frequency is adjustable without changing the voltage. For example, virtualization layer  first determines whether dedicated LPARs  and  are enabled to temporarily allocate their dedicated processors , , , and , respectively, to shared processor pool . If virtualization layer  determines that LPARs  and  have processor temporary allocation enabled, then virtualization layer  determines an operating frequency of the OSs utilizing shared processor pool  (Fsha), an operating frequency of OS  in LPAR  (Fded), and an operating frequency of OS  in LPAR  (Fded). In order that processor temporary allocation may always occur such that changing frequency between Fdedand Fsha and\/or Fdedand Fsha does not require voltage adjustments, virtualization layer  maintains the operating frequency of OS  in LPAR  (Fded) and the operating frequency of OS  in LPAR  (Fded) to be within a relative frequency (\u0394f) of the operating frequency of the OSs utilizing shared processor pool  (Fsha).","With virtualization layer  maintaining Fdedand Fdedto be within the relative frequency (\u0394f) of Fsha, virtualization layer  may make very rapid decreases and increases in the operating frequencies of processor , , , or  when temporarily allocating to shared processor pool  or when returning processor , , , or  back to OS  or . Virtualization layer  maintains the operating frequency of OS  in LPAR  (Fded) and the operating frequency of OS  in LPAR  (Fded) to be within a relative frequency (\u0394f) of the operating frequency of the OSs utilizing shared processor pool  (Fsha) and provides for always allowing temporary allocation both in \u201cshort-term\u201d and \u201clong-term\u201d temporary allocations. However, the drawback of virtualization layer  maintaining Fdedand Fdedto be within Fsha is that power savings is not as dramatic if voltage cannot be adjusted.","As will be appreciated by one skilled in the art, the present invention may be embodied as a system, method, or computer program product. Accordingly, aspects of the present invention may take the form of an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a \u201ccircuit,\u201d \u201cmodule\u201d or \u201csystem.\u201d Furthermore, aspects of the present invention may take the form of a computer program product embodied in any one or more computer readable medium(s) having computer usable program code embodied thereon.","Any combination of one or more computer readable medium(s) may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be, for example, but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, device, or any suitable combination of the foregoing. More specific examples (a non-exhaustive list) of the computer readable medium would include the following: an electrical connection having one or more wires, a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CDROM), an optical storage device, a magnetic storage device, or any suitable combination of the foregoing. In the context of this document, a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system, apparatus, or device.","A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein, for example, in a baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms, including, but not limited to, electro-magnetic, optical, or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate, propagate, or transport a program for use by or in connection with an instruction execution system, apparatus, or device.","Computer code embodied on a computer readable medium may be transmitted using any appropriate medium, including but not limited to wireless, wireline, optical fiber cable, radio frequency (RF), etc., or any suitable combination thereof.","Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages, including an object oriented programming language such as Java\u2122, Smalltalk\u2122, C++, or the like, and conventional procedural programming languages, such as the \u201cC\u201d programming language or similar programming languages. The program code may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer, or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).","Aspects of the present invention are described below with reference to flowchart illustrations and\/or block diagrams of methods, apparatus (systems) and computer program products according to the illustrative embodiments of the invention. It will be understood that each block of the flowchart illustrations and\/or block diagrams, and combinations of blocks in the flowchart illustrations and\/or block diagrams, can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer or other programmable data processing apparatus, create means for implementing the functions\/acts specified in the flowchart and\/or block diagram block or blocks.","These computer program instructions may also be stored in a computer readable medium that can direct a computer, other programmable data processing apparatus, or other devices to function in a particular manner, such that the instructions stored in the computer readable medium produce an article of manufacture including instructions that implement the function\/act specified in the flowchart and\/or block diagram block or blocks.","The computer program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other devices to cause a series of operational steps to be performed on the computer, other programmable apparatus, or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions\/acts specified in the flowchart and\/or block diagram block or blocks.","Referring now to , these figures provide flowcharts outlining example operations of temporarily allocating one or more dedicated processors to a shared processor pool in accordance with an illustrative embodiment. While the following figures are described in relation to only one processor being temporarily allocated to a shared processor pool, one of ordinary skill in the art would realize that the operation may be performed with any number of dedicated processor for any number of partitions without departing from the spirit and scope of the invention.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 4","b":["402","402","402","404","404","404","404","406","406","408","406","410","412"]},{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 5","b":["502","502","502","502","504","504","506","508","502"]},"If at step  the OS determines that the workload for the plurality of processors fails to be below the first predetermined threshold, then the OS determines whether the workload is above a second predetermined threshold (step ). If at step  the OS determines that the workload fails to be above the second predetermined threshold, then the operation returns to step . If at step  the OS determines that the workload is above the second predetermined threshold, then the OS determines whether there is at least one dedicated processor that is folded (step ). If at step  the OS determines that there is no dedicated processor that is folded, then the operation returns to step . If at step  the OS determines that there is at least one processor that is folded, then the OS selects one of the at least one processors that is folded for unfolding (step ). The OS then may direct interrupts to the selected processor and allows work to be queued for selected processor (step ), with the operation returning to step  thereafter.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 6","b":["602","604","604","606"]},"If at step  the operating frequency of the identified dedicated processor fails to be approximately equal to the operating frequency of the OSs utilizing the shared processor pool, the virtualization layer determines whether the temporary allocation of the dedicated processor is either a \u201clong-term\u201d temporary allocation or a \u201cshort-term\u201d temporary allocation (step ). If at step  the virtualization layer determines that the temporary allocation is a \u201clong-term\u201d temporary allocation, then the virtualization layer either increases or decreases the frequency of identified dedicated processor to be approximately the same as the operating frequency of the OSs utilizing shared processor pool and allocates identified dedicated processor on a \u201clong-term\u201d basis to the shared processor pool (step ), with the operation ending thereafter. If at step  the virtualization layer determines that the temporary allocation is a \u201cshort-term\u201d temporary allocation, then virtualization layer does not allocate the identified dedicated processor to the shared processor pool (step ), with the operation ending thereafter.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 7","b":["702","702","702","702","704"]},"If at step  the virtualization layer determines that the temporary allocation was a \u201clong-term\u201d temporary allocation, then the virtualization layer prevents any new workload to be sent to identified dedicated processor by the OS on the shared logical partition (LPAR) and waits for the current workload to finish execution on identified dedicated processor (step ). Once the workload is completed, the virtualization layer returns the identified dedicated processor to its original operating frequency, if needed, and hands control of identified dedicated processor back to OS (step ), with the operation terminating thereafter. If at step  the virtualization layer determines that the temporary allocation was a \u201cshort-term\u201d temporary allocation, then the virtualization layer interrupts all work on the identified dedicated processor and hands control of the identified dedicated processor back to OS (step ). The virtualization layer then sends a notification to the OS of the shared LPAR indicating that none of the requested work on identified dedicated processor completed (step ), with the operation terminating thereafter.",{"@attributes":{"id":"p-0076","num":"0075"},"figref":"FIG. 8","b":["802","804","804","806"]},"If at step  the operating frequency of the identified dedicated processor fails to be approximately equal to the operating frequency of the OSs utilizing the shared processor pool, the virtualization layer determines whether the temporary allocation of the dedicated processor is either a \u201clong-term\u201d temporary allocation or a \u201cshort-term\u201d temporary allocation (step ). If at step  the virtualization layer determines that the temporary allocation is a \u201clong-term\u201d temporary allocation, then the virtualization layer either increases or decreases the frequency of identified dedicated processor to be approximately the same as the operating frequency of the OSs utilizing the shared processor pool and allocates identified dedicated processor on a \u201clong-term\u201d basis to the shared processor pool (step ), with the operation ending thereafter. If at step  the virtualization layer determines that the temporary allocation is a \u201cshort-term\u201d temporary allocation, then the virtualization layer determines whether the operating frequency of the identified dedicated processor is greater than or less than the operating frequency of the OSs utilizing the shared processor pool (step ).","If at step  the operating frequency of the identified dedicated processor is greater than the operating frequency of the OSs utilizing the shared processor pool, then the virtualization layer does not allocate the identified dedicated processor to the shared processor pool (step ), with the operation ending thereafter. If at step  the operating frequency of the identified dedicated processor is less than the operating frequency of the OSs utilizing the shared processor pool, then the virtualization layer increases the frequency of identified dedicated processor to be approximately the same as the operating frequency of the OSs utilizing the shared processor pool and allocates identified dedicated processor on a \u201cshort-term\u201d basis to the shared processor pool (step ), with the operation ending thereafter.",{"@attributes":{"id":"p-0079","num":"0078"},"figref":"FIG. 9","b":["902","902","902","902","904"]},"If at step  the virtualization layer determines that the temporary allocation was a \u201clong-term\u201d temporary allocation, then the virtualization layer prevents any new workload to be sent to the identified dedicated processor by the OS on the shared LPAR and waits for the current workload to finish execution on the identified dedicated processor (step ). Once the workload is completed, the virtualization layer returns the identified dedicated processor to its original operating frequency, if needed, and hands control of identified dedicated processor back to OS (step ), with the operation terminating thereafter. If at step  the virtualization layer determines that the temporary allocation was a \u201cshort-term\u201d temporary allocation, then the virtualization layer interrupts all work on the identified dedicated processor, changes the frequency of the identified dedicated processor back to its original operating frequency, if needed, and hands control of the identified dedicated processor back to OS (step ). The virtualization layer then sends a notification to the OS of the shared LPAR indicating that none of the requested work on identified dedicated processor completed (step ), with the operation terminating thereafter.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 10","b":["1002","1002","1002","1004","1004","1004","1006","1008","1010","1010"]},"The flowchart and block diagrams in the figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present invention. In this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that, in some alternative implementations, the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved. It will also be noted that each block of the block diagrams and\/or flowchart illustration, and combinations of blocks in the block diagrams and\/or flowchart illustration, can be implemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.","Thus, the illustrative embodiments provide mechanisms for allowing a temporarily allocated processor to be temporarily allocated to a shared processor pool operating at a different frequency to thereby preserve the dedicated temporary allocation virtualization function in a power management environment. In one illustrative embodiment, the dedicated temporarily allocation function is limited so that dedicated processor partitions and shared processor partitions may run at any frequency. In another illustrative embodiment, the range of frequencies at which the temporarily allocating and shared processor pool CPUs is limited so that temporary allocation of an idle CPU from a dedicated processor partition can always occur.","As noted above, it should be appreciated that the illustrative embodiments may take the form of an entirely hardware embodiment, an entirely software embodiment or an embodiment containing both hardware and software elements. In one example embodiment, the mechanisms of the illustrative embodiments are implemented in software or program code, which includes but is not limited to firmware, resident software, microcode, etc.","A data processing system suitable for storing and\/or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus. The memory elements can include local memory employed during actual execution of the program code, bulk storage, and cache memories which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.","Input\/output or I\/O devices (including but not limited to keyboards, displays, pointing devices, etc.) can be coupled to the system either directly or through intervening I\/O controllers. Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems, cable modems and Ethernet cards are just a few of the currently available types of network adapters.","The description of the present invention has been presented for purposes of illustration and description, and is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. The embodiment was chosen and described in order to best explain the principles of the invention, the practical application, and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS","p":["The invention, as well as a preferred mode of use and further objectives and advantages thereof, will best be understood by reference to the following detailed description of illustrative embodiments when read in conjunction with the accompanying drawings, wherein:",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
