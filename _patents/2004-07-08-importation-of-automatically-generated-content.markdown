---
title: Importation of automatically generated content
abstract: The present invention is directed to a system for automatically recording information indicative of actions of an author in completing steps in an overall task performed on a user interface. Recording systems are used to record the steps taken to perform the task on different computers having different configurations. The recorded steps are then imported into an authoring component where the recorded steps are arranged into a desired content.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07036079&OS=07036079&RS=07036079
owner: Microsoft Corporation
number: 07036079
owner_city: Redmond
owner_country: US
publication_date: 20040708
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS"],"p":["The present invention is a continuation-in-part of co-pending related U.S. patent application Ser. No. 10\/337,745, filed Jan. 7, 2003, entitled ACTIVE CONTENT WIZARD: EXECUTION OF TASKS AND STRUCTURED CONTENT; Reference is made to U.S. patent applications Ser. No. 10\/887,058, filed Jul. 8, 2004, entitled AUTOMATIC TEXT GENERATION; and U.S. patent applications Ser. No. 10\/887,414, filed Jul. 8, 2004, entitled AUTOMATIC IMAGE CAPTURE FOR GENERATING CONTENT, and assigned to the same assignee as the present invention.","The present invention deals with generating content, such as help content. More specifically, the present invention deals with importation of automatically generated content indicative of actions of a user on a user interface.","The Graphical User Interface (GUI) is a widely used interface mechanism. GUI's are very good for positioning tasks (e.g. resizing a rectangle), visual modifier tasks (e.g. making something an indescribable shade of blue) or selection tasks (e.g. this is the one of a hundred pictures I want rotated). The GUI is also good for speedy access to quick single step features. An application's GUI is a useful toolbox that is organized from a functional perspective (e.g. organized into menus, toolbars, etc) rather than a task oriented perspective (e.g. organized by higher level tasks that users want to do, such as \u201cmake my computer secure against hackers\u201d).","However, GUIs present many problems to the user as well. Using the toolbox analogy, a user has difficulty finding the tools in the box or figuring out how to use the tools to complete a task composed of multiple steps. An interface described by single words, tiny buttons and tabs forced into an opaque hierarchy does not lend itself to the way people think about their tasks. The GUI requires the user to decompose the tasks in order to determine what elements are necessary to accomplish the task. This requirement leads to complexity. Aside from complexity, it takes time to assemble GUI elements (i.e. menu clicks, dialog clicks, etc). This can be inefficient and time consuming even for expert users.","One existing mechanism for addressing GUI problems is a written help procedure. Help procedures often take the form of Help documents, PSS (Product support services) KB (Knowledge base) articles, and newsgroup posts, which fill the gap between customer needs and GUI problems. They are analogous to the manual that comes with the toolbox, and have many benefits. These benefits include, by way of example:\n\n","However, Help documents, PSS KB articles and newsgroups have their own set of problems. These problems include, by way of example:\n\n","Another existing mechanism for addressing GUI problems is a Wizard. Wizards were created to address the weaknesses of GUI and written help procedures. There are now thousands of wizards, and these wizards can be found in almost every software product that is manufactured. This is because wizards solve a real need currently not addressed by existing text based help and assistance. They allow users to access functionality in a task-oriented way and can assemble the GUI or tools automatically. Wizards allow a program manager and developer a means for addressing customer tasks. They are like the expert in the box stepping the user through the necessary steps for task success. Some wizards help customers setup a system (e.g. Setup Wizards), some wizards include content with features and help customers create content (e.g. Newsletter Wizards or PowerPoint's AutoContent Wizard), and some wizards help customers diagnose and solve problems (e.g. Troubleshooters).","Wizards provide many benefits to the user. Some of the benefits of wizards are that:\n\n","However, wizards too, have their own set problems. Some of these problems include, there are many more tasks that people try to accomplish than there are wizards for accomplishing them. Wizards and IUI (Inductive User Interfaces) do not teach customers how to use underlying GUI and often when the Wizard is completed, users are unsure of where to go next. The cost of authoring of wizards is still high and requires personnel with technical expertise (e.g. software developers) to author the Wizard.","Further, all of these types of content suffer from yet another problem. The steps that must be taken to perform any given task may change based on the configuration of the computer on which the task is to be performed. For instance, changing the background display (or \u201cwallpaper\u201d) on a computer may require the user to perform different steps, depending on the operating system of the user's computer. In fact, the steps required may even be different if the version number of the operating system is different. Similarly, the steps may be different depending on the network configuration of the computer (e.g., depending on whether the computer is on a network domain or on a workgroup). This requires the user to author fairly complicated branching logic in the written content. Also, the user may find it quite cumbersome to navigate through a complicated branching help text to perform necessary steps.","Thus, authoring all of these types of content that describe procedures to be taken by a user, is often error prone. It is quite easy to miss steps, to describe steps incorrectly, or to lose track of what step is currently being described in a long sequence of UI manipulations. However, this written procedural help content is extremely common. Such help content often ships with products, on-line help content is provided for product support teams, and procedures inside companies are often documented in this way for specific business processes. Thus, this type of information is difficult to author and often contains errors.","In addition, end users must typically follow the steps that have been authored. It can be difficult to read step-by-step text, and then search the UI for the particular control element being described and then to take the proper action with respect to that control element. It has been found that many users find this such a burden that they simply scan the first one or two steps of the text, and then try their best to determine which UI elements need to be actuated next, barely referring back to the written text steps. It has also been found that the eye can find and recognize pictures much more easily than it can read a word, mentally convert the word into a picture, and then find the corresponding UI control element. Yet, in the past, this is exactly what was done, as an author must painstakingly take screenshots of each step, crop the images, and paste them into a document in the right place, in order to have any type of visual depiction of an action to be taken.","One embodiment of the present invention addresses some of the problems of Wizards, Help, Knowledge base articles and troubleshooters by providing a content component that allows for an easy way to author thousands of tasks (or wizards), and either integrate with the GUI and teach the user how to use the GUI to execute the task or to execute the task on behalf of the user. In one specific embodiment, the present invention deals with authoring active content wizard (ACW) scripts, and with the text and images that are part of an ACW script.","The present invention is directed to a system for automatically recording information indicative of actions of an author in completing steps in an overall task performed on a user interface. Recording systems are used to record the steps taken to perform the task on different computers having different configurations. The recorded steps are then imported into an authoring component where the recorded steps are arranged into a desired content.","In one embodiment, the recording system records images corresponding to the author's actions on the user interface. The recording system can then pass the recorded images to an authoring component where an author can generate text corresponding to the images to describe the actions. The images can also be published embedded in the text, if desired.","In one embodiment, the recording system includes a text generator that automatically generates text corresponding to the images. This text can then be used to form a text document, which provides instructions or other information to a user. During or after the process of generating the text document, the text can be edited using an editor to enhance the comprehensibility of the document.","The present invention deals with automatically recording content indicative of a user action on a user interface. Prior to describing the present invention in greater detail, one exemplary environment in which the invention can be used will be discussed.",{"@attributes":{"id":"p-0030","num":"0041"},"figref":"FIG. 1","b":["100","100","100","100"]},"The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like.","The invention may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices.","With reference to , an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer . Components of computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","Computer  typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer . Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules , and program data .","The computer  may also include other removable\/non-removable volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in , provide storage of computer readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that, at a minimum, they are different copies.","A user may enter commands and information into the computer  through input devices such as a keyboard , a microphone , and a pointing device , such as a mouse, trackball or touch pad. Other input devices (not shown) may include a joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . In addition to the monitor, computers may also include other peripheral output devices such as speakers  and printer , which may be connected through an output peripheral interface .","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a hand-held device, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on remote computer . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.",{"@attributes":{"id":"p-0041","num":"0052"},"figref":["FIG. 2","FIG. 2","FIG. 2"],"b":["200","200","207","203","207","210","212","214","203","220","230","200","205","200","205","203","235","201","235","240","245","245"]},"User Interface  is, in one embodiment, a conventional graphical user interface with controls that allow a user to take actions to perform a task. The user interface  is illustratively displayed on display device  shown in . This type of graphical user interface (GUI) is a widely used interface mechanism.","Recording component  is in one embodiment an application program that allows the author , or another user, to perform a task on the user interface , and records the tasks by capturing images of each step in the task. As is described in more detail below, while the author  is performing the steps associated with the task on the user interface , the recording component  records information about what controls and windows the author interacts with on the user interface . This information is illustratively provided to the text generator  to automatically generate the text in a document, such as a help document.","The recording component  interacts with the user interface  through the hook component  and the user interface (UI) automation component . These components can be separate from the recording component , or in some embodiments these components can be integral with the recording component .","The hook component  is, in one embodiment, a module or component within an operating system that is used by the computer. When a hook is set for mouse clicks, for example, information indicative of the mouse click (such as a message) is forwarded to the hook component  where it is consumed, and after its associated images have been recorded by the recording component , it is played back for other components in the computer that have registered to receive mouse clicks. Therefore, generally, the hook component  acts as a buffer between the operating system and the target application.","The hook component  can be configured to look for substantially any input action, such as the type of signal received, e.g. single click, double click, right or left click, keyboard action, touch-sensitive screen input, etc. Once the information representing the action is recorded by the recording component , the information representing the mouse click (or whatever action is recorded) is then played back by the hook component  to the application. One reason for this is that the user may take a second action before the first action is recorded. The second action may well cause the state of the user interface to change, and thus result in improper recording of the first action. By consuming the first mouse message and playing it back once recording is complete, this ensures that the first action will be recorded properly.","It should also be noted that the functions performed by the hook component  (i.e., listening for mouse clicks and playing them back) are illustratively performed on separate threads. This ensures that all user interface actions (e.g., mouse clicks, keyboard actions etc.) will be properly recorded and played back without missing any. Further, the record and playback mechanism of hook component  can illustratively override any timeout features that are implicit within the operating system. This can be necessary if the timeout period of the operating system is too short to allow for proper recording of the action.","User interface automation component  is illustratively a computer program configured to interpret the atomic steps for the overall task performed by the author or user through the user interface . In one embodiment, user interface automation component  is a GUI automation module implemented using Microsoft User Interface Automation by Microsoft Corporation of Redmond, Wash. This module provides a programmatic way to access information about the visible user interface, and to programmatically interact with the visible user interface. However, depending on the system setup, the user interface automation component  can be implemented using any application that is able to programmatically navigate a graphical user interface and to detect (and optionally programmatically navigate the GUI to perform and execute) commands on the user interface.","User interface automation component  thus detects each of the steps associated with the desired task performed on the user interface  by author  (or another user) in task order. For instance, as is described in greater detail below, when the task requires the user to click a button on the GUI to display a new menu or window, user interface automation component  determines which control is located at the position of the mouse cursor on user interface  and its size and its parent window. The recording component  uses information from hook component  (e.g., the type, name and state of the control) to record the name and properties of the control that was used to perform the step. This information is provided from the user interface automation component  and hook component  to the recording component  such that the recording component  can record the image of the button or the control that was used by the author to perform the step. Obtaining the image is described in greater detail below with respect to .","Text generation component  is a program or module configured to generate natural language text that describes the actions executed or performed during the recording process. The text generation component  uses the recorded images and other information recorded by the recording component  to search database  and to choose a correct template or entry from the text database  that corresponds to the recorded step.","Text database  is illustratively a database or other information storage system that is searchable by the text generator . Text database  contains information related to the controls that are available on the user interface . This information can include, for example, the name of the control, the type of control, the action performed on the control, and a textual description of the action as a natural language sentence.","In some embodiments the textual description for the entry is provided in multiple languages. When the textual description is provided in multiple languages, a language identifier is provided with each entry that allows the correct language to be selected.","However, depending on the needs of the system, other information can be provided in the text database . In one embodiment, some entries in the text database  have information related to two or more actions exemplified by multiple controls that are performed in sequence. Where multiple actions on multiple controls are represented by a single entry in the text database  the text for the entry contains natural language descriptions of the action performed on both controls as a single sentence. By combining the description of the two commands as a single sentence, the readability of the final text document is improved.","In one embodiment, the text database  is written in Extensible Markup Language (XML). The data for each entry can be stored as a series of subentries, where each subentry of the entry refers to an individual piece of information that is needed to identify the task. However, other formats can be used for storing the data.","In one embodiment, the text generation component  looks at two or more of the recorded actions when searching for entries in the text database . This can be done in order to provide a more fluid text document. For instance, good procedural documentation often combines more than one step into a single sentence as an enhancement to readability. If the text generation component  identifies two or more that match the recorded information in the text database , the text generation component  can use any known method to determine which entry in the database to choose, such as by disambiguating the entries based on scoring each entry, and selecting the entry that has the highest score.","According to one embodiment, based on the type of the control actuated on the user interface, and the performed action, the text generation component  searches the text database  for an entry that matches the executed control type and action. Once a match is identified in the text database , the text generation component  obtains the associated natural language description of the action from the text database , and places it as a sentence instruction in the generated text document . In an alternative embodiment, the text generation component  can also generate an executable version of the text document based on the information provided by the UI automation module .","When choosing a textual description from the text database , the text generation component can also look to the state of the control. This can be important when the control is a checkbox or an expandable or collapsible tree. In this case merely clicking on the box may not be appropriate to describe the action, as the action on the control is the same regardless of the desired result. Therefore, in these cases, the new state of the control will influence the selected text. For example, if the control is a check box and it is to be deselected, the text matched would be based on the new state of the control plus the control's name.","Text editor  is an editor configured to correct, change, or add information or text to the automatically generated text . Depending on the resultant text generated by text generator , and the actions performed by the author, it may be necessary to edit the text to further enhance its understandability. Therefore, text editor  receives the generated text , and allows the author  to edit the generated text.","Text editing may be required, for example, because of a grammatical necessity or because one of the recorded steps required a user action, and the system did not request the description of the user action at the time it was recorded. In such a case (when a user input is required), while performing the task to be recorded according to one embodiment, the text generator  only provides a space in the text for the author to provide an instruction\/description of what the user should do at this step.","For example, assume that the task being performed by the user and recorded by the recording component is to change the background paneling on the computer screen. This requires the user to choose a pattern for the background. Therefore, the text that is returned by the text database for a recorded user action to change the background can be \u201cPlease select [insert description of action]\u201d, where the author will then edit the text to read \u201cPlease select the desired background from the list.\u201d Also during the editing stage the author  can provide a description of the overall task if this was not provided prior to recording the task. Once the text has been edited the final text  is output from the authoring tool  and is stored in an appropriate storage mode that allows for the final text to be retrieved by a user when desired.",{"@attributes":{"id":"p-0061","num":"0072"},"figref":["FIG. 3","FIG. 3","FIG. 4","FIG. 4"],"b":["200","201","210","400","201","402","410","201","406","201","240","408","201","410"]},"Referring again to , once author  has started recording component , the system simply waits for a user to take an action on user interface . It will be noted that  shows that the user is author , but the user could be a different user as well.","Once the user has taken an action on user interface  (such as by manipulating a control element on the user interface) hook component  receives a message or other signal indicative of the user action. As discussed above, with respect to hook component , hook component  consumes the message and places it on a queue for recording. The user taking an action on UI  is indicated by block  in .","Recording component  then receives image identifying information from UI automation component . This is indicated by block  in . In one illustrative embodiment, UI automation component  provides recording component  with a number of items of information that allow recording component  to record images on the display screen which represent, or correspond to, the action taken by the user at user interface . In one illustrative embodiment, these items of information are the position of the control element on the display screen that the user has actuated or otherwise manipulated, the size of that control element, and the parent window that contains the control element.","Recording component  then obtains actual image information indicative of the screen shots associated with the user interface  and corresponding to, or reflecting, the action taken by the user. This is indicated by block  in .","In order to perform this step, recording component  can do a number of things in order to enhance the operation of the system. For instance, recording component  may determine that it would be helpful to record actual image information (or the actual screen shot) of more than just the control element manipulated by the user. This may be true, for example, if there is more than one similar control element currently on the display being manipulated by the user. Assume, for instance, that the user has clicked an \u201cOK button\u201d on the user interface. However, there may be more than one \u201cOK button\u201d on the display screen at that time. Therefore, in order to disambiguate among the various \u201cOK buttons\u201d, recording component  may obtain the actual screen shot information for not only the particular \u201cOK button\u201d manipulated by the user, but for a desired number of pixels around that \u201cOK button\u201d. This provides an image with greater context than simply an image of the control itself.","Similarly, recording component  may also record the screen shot image of the entire parent window that contains the control element. Of course, this contains a great deal of extra context which can be used to specifically identify the control element that the user has manipulated.","In order to determine whether additional context needs to be recorded by recording component , recording component  can make this determination using any of a wide variety of different techniques. For instance, recording component  can deploy heuristics that will identify an amount of context to be recorded. The heuristics may be based on the size and shape of the control element manipulated, the particular function of the control element manipulated, the position of the control element on the screen (for instance, if the control element is in the upper left hand corner recording component  may take more pixels on the lower and right hand sides of the control element), or the heuristic can simply reflect a fixed number of pixels which are to be taken around the control element, regardless of where it is located and what functions are performed by the control element.","Recording component  can obtain the actual screen shot image information using any known technique. For example, in most operating systems, there are published application programming interfaces (APIs) that allow an application or other computing component to obtain the screen shot information currently being displayed. Therefore, in one illustrative embodiment, recording component  simply makes an API call to obtain the information, once it knows the coordinates of the screenshot image information it desires, and the amount of context information and optionally the parent window of the control element.","Having obtained the actual image information, recording component  records it for later use. This is indicated by block  in . Of course, it will also be noted at this point that recording component  can record other information provided by UI automation component . For instance, UI automation component  illustratively provides recording component  with the control name, the control type, the action performed on the control, the type of manipulation performed (such as mouse click, mouse wheel rotation, keyboard keystrokes, touch pad input, etc.). This information can all be recorded by recording component .","In accordance with one embodiment of the present invention, text generation component , in conjunction with text database , automatically generates text associated with the images captured, and associated with the action taken by the user on user interface . In the embodiment in which these items are used, recording component  sends the actual image information captured to text generation component . This is indicated by block  in . The automatically generated text illustratively provides a written procedure which corresponds to step by step instructions for each user manipulation of user interface  in order to perform an overall task that requires multiple manipulations of user interface .","One embodiment for automatically generating text is described below with respect to . Briefly, in order to generate this text, text generation component  can use any suitable method. In one illustrative method, text generation component  searches text data store  for entries that correspond to the information received from recording component . For instance, text data store  may illustratively be an XML database containing a plurality of entries that include the type of control or other item manipulated by the user on user interface , the type of action, and a text corresponding to that action. Of course, other data storage methods can be used to implement data store , and data store  can contain additional or different information as well.","For example, assume that the information received from the recording component  indicates that the user has clicked on (or otherwise invoked) an \u201cOK button\u201d. Then, text generation component  searches text data store  for an entry that matches this type of action. Once a match is found, text generation component  retrieves the text from that entry in text data store  that describes that type of action. The text may, for instance, simply say \u201cclick OK\u201d.","In any case, text generation component  illustratively automatically generates text describing the user action taken on user interface  and recorded by recording component . This is indicated by block  in .","The generated text is indicated by block  in . In one illustrative embodiment, the images recorded by recording component  are automatically embedded in the generated text , or are at least associated with the generated text  such that they can be recalled and displayed in conjunction with one another later in the process.","Next, the image data recorded by recording component  and the automatically generated text is provided to editor component . The images recorded by recording component  and automatically generated text are illustratively displayed on a display screen at editor  such that author  can generate text corresponding to those images. Displaying of the images and the text generated by generation component  is indicated by block  in .","The author can then modify the automatically generated text or generate new text. This is indicated by block  in . Finally, the final text  is output or saved according to a desired format or schema. The final text  can optionally include the captured images embedded therein. This is indicated by block  in .","In order to set up system  to automatically generate text, the author activates recording component  by first opening a window similar to the one illustrated in . At this point the author can edit the portion of the screen indicated by lines  and , to include information such as a title of the document being created and any introductory information regarding the task. However, this information can be added to the text document during later editing.","As the system  begins to record images, UI automation component  determines the available user interface elements on the user interface . Also the recording component  provides an indication on the user interface of what control is currently identified as the control being accessed using information provided from the UI automation component . This highlighting of the control is illustrated by reference number  in .",{"@attributes":{"id":"p-0080","num":"0091"},"figref":"FIG. 7","b":["460","210","230"]},"Once the information related to the recorded step has been received by the text generator component , the text generator component  proceeds to search the text database  for entries that match the received command. This is indicated by block . In one embodiment, text database  is an XML database containing a plurality of entries that includes the type of control or other item interacted with, the type of action, a new state of the control (e.g. checked, unchecked, expanded, collapsed, etc.) and a corresponding text for the action. However, other data storage methods can be used to hold the text. Further, other information can be held in text database . An example of a portion of the text database according to one embodiment is provided below in Table 1.",{"@attributes":{"id":"p-0082","num":"0093"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<EnglishTemplate actionTypeID=\u201cvalue\u201d"]},{"entry":[{},"controlTypeID=\u201ccheck box\u201d ActionText=\u201cSelect\u201d"]},{"entry":[{},"specialValueID=\u201cchecked\u201d>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<Sentence>Select the <tag id=\u201c1\u201d><\/tag>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"checkbox<\/Sentence><\/EnglishTemplate>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<EnglishTemplate actionTypeID=\u201cinvoke\u201d"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"controlTypeID=\u201cbutton\u201d ActionText=\u201cClick\u201d>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<Sentence>Click <tag"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"id=\u201c1\u201d><\/tag><\/Sentence><\/EnglishTemplate>"]},{"entry":[{},"\u2002<EnglishTemplate actionTypeID=\u201cinvoke\u201d"]},{"entry":[{},"controlTypeID=\u201clist item\u201d ActionText=\u201cDouble-click\u201d>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<Sentence>In the <tag id=\u201c2\u201d><\/tag> list, double-"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"click <tag id=\u201c1\u201d><\/tag><\/Sentence><\/EnglishTemplate>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<EnglishTemplate actionTypeID=\u201cexpand_collapse\u201d"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"controlTypeID=\u201ctree item\u201d ActionText=\u201cExpand\u201d"]},{"entry":[{},"specialValueID=\u201cexpanded\u201d>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<Sentence>Click the minus sign next to <tag"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"id=\u201c1\u201d><\/tag>to collapse"]},{"entry":[{},"it<\/Sentence><\/EnglishTemplate>"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"For example, assuming that the information received from the recording component for the command was action type=\u201cinvoke\u201d control type=\u201cbutton\u201d control name=\u201cclick OK\u201d\u201d, then the text generation component  searches the text database  and finds an entry that matches this information. Then it retrieves the text from the entry corresponding to \u201cclick OK\u201d. Obtaining the text associated with the matched entry is illustrated at block .","During the recording of the step in question, if the author designated the step a user action step by selecting the user action button  on the user interface  shown in , or if the entry in the text database  indicates that the action is a user action, the text generating component  can, in one embodiment, prompt the author to add a description of the action to the obtained text. This is illustrated at block . The author can then provide the desired text at block . However, the author can ignore this step and add the information later during the editing stage. Any added text is added to text  at block .","If there is no user action required, or the necessary user action information has been provided by the author, the text generator  adds the newly obtained text to the text document. This is illustrated at block .","An example of the generated text is illustrated in  by reference numbers \u2013. This text provides the user with the step-by-step instructions for the desired task. The text can be generated as described with respect to text database  and text generation component , or according to any method that allows for the automatic generation of text from received input commands. The automatically generated text can then be presented to the author, along with the captured images, for editing.",{"@attributes":{"id":"p-0087","num":"0098"},"figref":["FIG. 9","FIG. 9"],"b":["201","240","426","428","426","235","201","428","210"]},"In the embodiment in which text is automatically generated, that text is shown at  in display portion , and it can be edited by the author using editor component  (one screenshot of which is shown in ). Thus, the author can highlight each of the actions or other items displayed on display portion . The images associated with the highlighted item are displayed in display portion . Therefore, in the embodiment shown in , the author has highlighted action number two which corresponds to actuating the Accessibility Options control and the corresponding images are displayed in display portion . The user can then enter text or modify text, as desired, in order to obtain a full description of the step performed by the user at user interface . In the embodiment shown in , the user has actuated the Accessibility Option control  on user interface . It can be seen that recording component  has obtained not only the control box  corresponding to the Accessibility Options control, but a larger context box  containing a number of pixels surrounding the Accessibility Options button . Context box  displays additional context around Accessibility Options control  such that it can be more easily located on the screen.",{"@attributes":{"id":"p-0089","num":"0100"},"figref":"FIG. 9","b":["210","434","430","205"]},"It will be appreciated that the present invention, as discussed to this point, can be used in a wide variety of different ways. For instance, the present invention can be used to generate content (such as help content) in which the captured images are embedded in the text or in the help text. One example of this is shown in . It can be seen that each step in a process not only contains text describing what to do to accomplish that step, but a visual image indicating where that step is to be performed. In this embodiment, in which the invention is used to generate embedded images in text, the final text  is output with embedded images. This is indicated by the optional block  in .","However, the present invention need not be used to embed images in text. Instead, the present invention can simply be used to display the captured images to an author, where the author is generating a written description of the steps taken and for which images are captured. For instance, the author may be generating text describing a process by which a virus is to be repaired or removed from a computer. The author may not wish to include embedded images in that text. In that case, the images are simply displayed and optionally the automatically generated text is also displayed to the author, and the author can either generate text from scratch or modify the automatically generated text, in an embodiment in which it is provided.","In any case, final text  will illustratively be created in, or translated into, whatever schema the content will finally be published in. This can, for example, be Microsoft Assistance mark up language (MAML), HTML, or some other XML format.",{"@attributes":{"id":"p-0093","num":"0104"},"figref":"FIG. 11","b":["500","245"]},"Therefore, even if images indicative of the steps to be performed are captured, and even if text is automatically or manually generated to describe those steps, the steps may well change based on the particular operating system being run by the computer or based on any other differences in configuration of the computer. In fact, the steps required may even be different if the version number of the operating system, or other software run by the computer, is different. Of course, a wide variety of other differences in configuration can make the steps required to perform a given task different as well. For instance, the user interface can differ for different states of the machine. By way of example, the sequence of user interface steps to connect to a remote machine can be different depending on whether the computer is on a network domain or on a work group.","Therefore, to automatically record the steps required to perform a given task, the recording system shown in  should record the steps on machines configured with all the different configurations that the content is intended for. The recorded steps for performing the task, recorded on all these different configurations, should then be combined into one overall content set that describes how to perform the task under the different configurations. Optionally, the system that eventually displays the content to the user will detect the configuration of the user's system and display only the relevant content (e.g., only those steps relevant to the end user).","Thus, system  shows a first computer  and a second computer  each of which includes a recording system  such as that shown in . Computer  is illustratively configured according to a first configuration designated herein as configuration A. Computer , on the other hand is configured according to a second configuration designated herein as configuration B.","The configurations A and B can be any type of different configurations that affect the steps required to perform any given task that is to be recorded, and for which content is to be authored. Therefore, by way of example, configuration A might be a computer that is on a network domain, while configuration B is a computer on a work group. Similarly, configuration A might be a computer running on a first operating system, while configuration B is a computer running on a second operating system. Similarly, configuration A might be a computer operating on one version of an operating system while configuration B is a computer operating on a different version of the same operating system. Other, different configurations can be used as well, as desired by the author of the content. It should also be noted, of course, that computers  and  can actually be different computers or computers installed on virtual machines.","Recording systems  shown in  can be similar to that shown in  and they are correspondingly numbered. However, as will be described in greater detail below, the automatic text generation portion  can be disposed on authoring computer , in which case only one automatic text generation portion  is required.","Computers  and  are illustratively connected to an authoring computer . Authoring computer  illustratively includes an importer mechanism  and a content editor component (such as editor component  described with respect to ).","Authoring computer  can illustratively be either computer  or , or a different computer. Similarly, computer  can run on the same operating system as one of computers  and , or on a different operating system. In addition, as mentioned above, editor component  can be provided with automatic text generation system , or it can simply be the editor component  described with respect to .","In operation, recording systems  on computers  and  allow a user to perform tasks on the user interfaces associated with each of computers  and , while recording systems  record and store the user interface steps that are taken to perform the desired task. Recording systems  thus illustratively record screen shot images corresponding to the actions taken by the user, and can also optionally automatically generate text corresponding to those images, as described above.","Recording systems  then illustratively format the recorded steps into a format that is acceptable by importer component . For instance, recording system  on computer  will illustratively record a series of steps conducted by a user on the user interface of computer  to perform the given task and format those recorded steps into recorded fragment A (also designated by numeral ) according to an XML format. Similarly, recording system  on computer  will illustratively record steps and format them into a recorded fragment B (also designated by numeral ) according to an XML format.","Recorded fragments  and  are then provided from computers  and  to importer component . Importer component  is shown on computer , but it will of course be appreciated that importer component  may be a component which has functionality distributed among the various computers shown in system , or which resides discretely from all of those computers, or which is provided on a different one of the computers, other than computer . In any case, importer component  can be any suitable importing mechanism for receiving recorded fragments  and  and providing them to editor component  for presentation to the user.","Importer component  illustratively stores recorded fragments  and  on recording computer  and imports them into editor component  in one of a variety of different ways. This can be accomplished, for example, by importing fragments  and  through a shared directory. Similarly, it can be done by storing recorded fragments  and  on disk or another external memory device wherein that external memory device is physically transported to computer  where fragments  and  are loaded into editor component . Similarly, computer  can be used remotely to operate computers  and  and then store recorded fragments  and  on a clipboard or other shared application space which can be accessed by computer . One embodiment of such a shared space is the Windows Clipboard system provided by Microsoft Corporation of Redmond, Wash.","In the embodiment in which fragments  and  are provided using a shared application space, computer  reads the fragments  and  from the shared application space and imports them into editor component . For instance, in the embodiment in which the Windows Clipboard application space is used, a program referred to as Remote Desktop also provided by the Microsoft Corporation of Redmond, Wash., allows the clipboard space to be shared between remote and local computers (such as between computers  and  and computer ).","In any case, importer component  is used to import recorded fragments  and  into editor component . In the embodiment in which the recording systems  on computers  and  include automatic text generating system , the recorded fragments  and  will include the automatically generated text. Alternatively, the text can be automatically or manually generated at editor component .","Editor component  displays the fragments  and  to the user and thus allows appropriate conditions to be inserted by the user. For instance, the embodiment of final text  illustrated in  shows recorded fragment  and recorded fragment  inserted in the overall text  after condition statements  and  have been inserted by the user. Condition statement , for instance, is \u201cCondition: If configuration A, then:\u201d. This indicates that the steps indicated by recorded fragment  are to be displayed to the user or performed automatically if the computer is configured in configuration A.","Condition  states \u201cCondition: if configuration B, then:\u201d. This indicates that if the computer is configured according to configuration B, then the steps indicated by recorded fragment  are to be displayed to the user or performed.","Of course, it will also be appreciated that the author can delete or modify the text in any other desired way as well. This can be done using conventional editing techniques on editor component .","Table 2 shows an exemplary XML document formed from recordings from two different configurations. The two XML fragments are recorded on computers where one runs on a network domain and the other on a network workgroup. Note that the condition=\u201cNetwork_connection: domain\u201d attribute is marked up to handle the if-then logic for determining which fragment to run.",{"@attributes":{"id":"p-0111","num":"0122"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}},"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"<task>"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<title>Add a new user to the computer<\/title>"]},{"entry":[{},"<introduction>When you add a user to your computer, you are allowing that individual"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"to have access to files and programs on your computer.<\/introduction>"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<commandStep>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<command>control.exe userpasswords<\/command>"]},{"entry":[{},"<description>Open User Accounts in Control Panel<\/description>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<\/commandStep>"]},{"entry":[{},"<!--- *** This section was recorder on a machine that's on a network domain *** --\/>"]},{"entry":[{},"<stepGroup condition=\u201cNetwork_connection:domain\u201d>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<uiActionsStep><actionRef id=\u201c0\u201d\/><actionRef id=\u201c1\u201d\/>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<description>On the <ui>Users<\/ui> tab, click Add<\/description>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<\/uiActionsStep>"]},{"entry":[{},"<uiActionsStep><actionRef id=\u201c2\u201d\/>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<description>Follow the instructions in the wizard to add a new user<\/description>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<\/uiActionsStep>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<\/stepGroup>"]},{"entry":[{},"<!--- *** This section was recorder on a machine that's on a workgroup *** --\/>"]},{"entry":[{},"<stepGroup condition=\u201cNetwork_connection:workgroup\u201d>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<uiActionsStep><actionRef id=\u201c3\u201d\/>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<description>Click <ui>Create a new account<\/ui><\/description>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<\/uiActionsStep>"]},{"entry":[{},"<uiActionsStep><actionRef id=\u201c4\u201d\/>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<description>Type a name for the new user account<\/description>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<\/uiActionsStep>"]},{"entry":[{},"<uiActionsStep><actionRef id=\u201c5\u201d\/>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<description>Click Next<\/description>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<\/uiActionsStep>"]},{"entry":[{},"<uiActionsStep><actionRef id=\u201c6\u201d\/>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<description>Click either Computer Administrator or Limited depending on the type"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"of account you want to assign the new user<\/description>"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<\/uiActionsStep>"]},{"entry":[{},"<uiActionsStep><actionRef id=\u201c7\u201d\/>"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"245pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<description>Click create<\/description>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<\/uiActionsStep>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"<\/stepGroup>"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"<\/task>"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Thus, it can be seen that the present invention allows an author to record all or parts of macros (or another series of steps to perform a given task) on different machines under different configurations, and then to assemble the recorded pieces on one authoring machine to arrive at a final content. This allows the macros to be recorded on different machines, but the main authoring steps can be performed at one place. This renders authoring of content less expensive and less complex, and more highly automated, than prior systems.","Although the present invention has been described with reference to particular embodiments, workers skilled in the art will recognize that changes may be made in form and detail without departing from the spirit and scope of the invention."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0018","num":"0029"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0030"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0020","num":"0031"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0021","num":"0032"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0022","num":"0033"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0023","num":"0034"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0024","num":"0035"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0025","num":"0036"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0026","num":"0037"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0027","num":"0038"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0028","num":"0039"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
