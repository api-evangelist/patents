---
title: Haptic spatialization system
abstract: A system is provided that controls a haptic effect experienced at a peripheral device. The system receives a haptic effect definition including haptic data. The system further receives spatialization data including: a distance of the haptic effect; a direction of the haptic effect; or a flow of the haptic effect. The system further includes modifying the haptic effect definition based on the received spatialization data. The system further includes sending a haptic instruction and the modified haptic effect definition to the peripheral device. The system further includes causing one or more haptic output devices to produce one or more haptic effects based on the modified haptic effect definition at the peripheral device in response to the haptic instruction.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09164587&OS=09164587&RS=09164587
owner: Immersion Corporation
number: 09164587
owner_city: San Jose
owner_country: US
publication_date: 20141112
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application claims priority of U.S. Provisional Patent Application Ser. No. 61\/904,342, filed on Nov. 14, 2013, the disclosure of which is hereby incorporated by reference.","One embodiment is directed generally to a device, and more particularly, to a device that produces haptic effects.","Video games and video game systems have become extremely popular. Video game devices or controllers typically use visual and auditory cues to provide feedback to a user. In some interface devices, kinesthetic feedback (such as active and resistive force feedback) and\/or tactile feedback (such as vibration, texture, and heat) is also provided to the user, more generally known collectively as \u201chaptic feedback\u201d or \u201chaptic effects.\u201d Haptic feedback can provide cues that enhance and simplify a user's interaction with a video game controller, or other electronic device. Specifically, vibration effects, or vibrotactile haptic effects, may be useful in providing cues to users of video game controllers or other electronic devices to alert the user to specific events, or provide realistic feedback to create greater sensory immersion within a simulated or virtual environment.","Other devices, such as medical devices, automotive controls, remote controls, and other similar devices where a user interacts with a user input element to cause an action, also benefit from haptic feedback or haptic effects. For example, and not by way of limitation, user input elements on medical devices may be operated by a user outside the body of a patient at a proximal portion of a medical device to cause an action within the patient's body at a distal end of the medical device. Haptic feedback or haptic effects may be employed to alert the user to specific events, or provide realistic feedback to the user regarding an interaction of the medical device with the patient at the distal end of the medical device.","One embodiment is a system that controls a haptic effect experienced at a peripheral device. The system receives a haptic effect definition including haptic data. The system further receives spatialization data including: a distance of the haptic effect; a direction of the haptic effect; or a flow of the haptic effect. The system further includes modifying the haptic effect definition based on the received spatialization data. The system further includes sending a haptic instruction and the modified haptic effect definition to the peripheral device. The system further includes causing one or more haptic output devices to produce one or more haptic effects based on the modified haptic effect definition at the peripheral device in response to the haptic instruction.","One embodiment is a system that provides haptic feedback that is experienced at a peripheral device, such as a game controller or gamepad. In an embodiment, a spatialization engine can receive haptic data, such as a haptic effect definition, and can modify the haptic data based on spatialization data, where spatialization data can include one or more parameters. Thus, the spatialization engine can localize or spatialize haptic effects. More specifically, the spatialization engine can produce a haptic effect that conveys a position, distance, velocity, flow, and\/or direction of the haptic effect by scaling or attenuating the haptic effect on an actuator or motor based on the position, distance, velocity, flow, and\/or direction of the haptic effect. As one of ordinary skill in the relevant art would appreciate, by \u201cattenuating\u201d a haptic effect, the spatialization engine can reduce a magnitude, frequency, and\/or duration of the haptic effect based on an intended position, distance, velocity, flow, and\/or direction of the haptic effect. The spatialization engine can further produce a haptic effect that conveys movement on a controller, gamepad, or other peripheral device by delaying a playback of the haptic effect, or scaling the haptic effect, on different actuators or motors. The spatialization engine can be a component of an API or library, or can be implemented in firmware for a controller, gamepad, or other peripheral device.","In one embodiment, a spatialization engine can receive a haptic effect definition. The spatialization engine can modify the haptic effect definition based on one or more spatialization parameters, where the modified haptic effect definition can be identified as a spatialization haptic effect definition. In one embodiment, the spatialization haptic effect definition can be divided into a plurality of spatialization haptic effect definition components, where each spatialization haptic effect definition component can be sent to a separate actuator or motor of a peripheral device, where each actuator or motor can cause a component of the overall spatialization haptic effect to be experienced at a user input element of the peripheral device or otherwise within the peripheral device. The spatialization engine can scale or delay one or more of the spatialization haptic effect components based on spatialization data, such as one or more spatialization parameters. In another embodiment, the spatialization haptic effect definition can be sent to each actuator or motor of the peripheral device, where each actuator or motor can cause a spatialization haptic effect to be experienced at a user input element of the peripheral device or otherwise within the peripheral device. The spatialization engine can further scale or delay one or more of the spatialization haptic effects based on spatialization data, such as one or more spatialization parameters. Such spatialization parameters can include one or more parameters that define a position, distance, velocity, flow, and\/or direction of a haptic effect. In one embodiment, the spatialization data (e.g., the one or more spatialization parameters) can be modified based on a detected motion and\/or position of the peripheral device. For example, when the peripheral device is rotated or shaken, or when the peripheral device is moved to a different location, the spatialization data (e.g., the one or more spatialization parameters) are modified. Based on the modified spatialization data, the spatialization data can further modify the haptic effect definition, so that the user experiences modified spatialization haptic effects. Examples of modified spatialization haptic effects can include spatialization haptic effects with a modified attenuation, scaling, or delay.","In one embodiment, a haptic effect definition can be authored to include a plurality of haptic effect definition components. The spatialization engine can modify the haptic effect definition, where the haptic effect definition can be divided into the authored plurality of haptic effect definition components, where each authored haptic effect definition component can be sent to a separate actuator or motor of a peripheral device, where each actuator or motor can cause a component of the overall haptic effect to be experienced at a user input element of the peripheral device or otherwise within the peripheral device. This way, the haptic effect can convey a sense of spatialization. In an alternate embodiment, rather than sending a spatialization haptic effect definition (or a multiple spatialization haptic effect definition components) to multiple actuators or motors of a peripheral device, the spatialization engine can send the spatialization haptic effect definition (or multiple spatialization haptic effect definition components) to multiple peripheral devices. In an alternate embodiment, a peripheral device can be a wearable haptic device, rather than a controller or gamepad, where a wearable haptic device is a device that a user may wear on a body or that can be held by a user, such as a wrist band, headband, eyeglasses, ring, leg band, an array integrated into clothing, and that includes a mechanism to generate haptic effects.",{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 1","b":["10","10","10","10","10","10","12","22","12","22","10","14","22","14"]},"A computer-readable medium may be any available medium that can be accessed by processor  and may include both a volatile and nonvolatile medium, a removable and non-removable medium, a communication medium, and a storage medium. A communication medium may include computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism, and may include any other form of an information delivery medium known in the art. A storage medium may include RAM, flash memory, ROM, erasable programmable read-only memory (\u201cEPROM\u201d), electrically erasable programmable read-only memory (\u201cEEPROM\u201d), registers, hard disk, a removable disk, a compact disk read-only memory (\u201cCD-ROM\u201d), or any other form of a storage medium known in the art.","In one embodiment, memory  stores software modules that provide functionality when executed by processor . The modules include an operating system  that provides operating system functionality for system , as well as the rest of an overall device in one embodiment. The modules further include a haptic spatialization module  that generates a spatialization haptic effect experienced at a peripheral device. In certain embodiments, haptic spatialization module  can comprise a plurality of modules, where each module provides specific individual functionality for generating a spatialization haptic effect experienced at a peripheral device. System  will typically include one or more additional application modules  to include additional functionality, such as peripheral firmware which can provide control functionality for a peripheral device, such as a controller .","System , in embodiments that transmit and\/or receive data from remote sources, further includes a communication device , such as a network interface card, to provide mobile wireless network communication, such as infrared, radio, Wi-Fi, or cellular network communication. In other embodiments, communication device  provides a wired network connection, such as an Ethernet connection or a modem.","System  is operably connected to controller . Controller  is a peripheral device used to provide input to system . Controller  can be operably connected to system  using either a wireless connection or a wired connection. Controller  can further include a local processor which can communicate with system  using either a wireless connection or a wired connection. Alternatively, controller  may be configured to not include a local processor, and all input signals and\/or output signals associated with controller  can be handled and processed directly by processor  of system .","Controller  can further include one or more digital buttons, one or more analog buttons, one or more bumpers, one or more directional pads, one or more analog or digital sticks, one or more driving wheels, and\/or one or more user input elements that can be interacted with by a user, and that can provide input to system . Controller  can also include one or more analog or digital trigger buttons (or \u201ctriggers\u201d) that can further be interacted with by the user, and that can further provide input to system . As is described below in greater detail, controller  can further include a motor, or another type of actuator or haptic output device, configured to exert a bi-directional push\/pull force on at least one trigger of controller .","Controller  can also include one or more actuators, or other types of haptic output devices. The local processor of controller , or, processor  in embodiments where controller  does not include a local processor, may transmit a haptic signal associated with a haptic effect to at least one actuator of controller . The actuator, in turn, outputs haptic effects such as vibrotactile haptic effects, kinesthetic haptic effects, or deformation haptic effects, in response to the haptic signal. The haptic effects can be experienced at a user input element (e.g., a digital button, analog button, bumper, directional pad, analog or digital stick, driving wheel, or trigger) of controller . Alternatively, the haptic effects can be experienced at an outer surface of controller . The actuator includes an actuator drive circuit. The actuator may be, for example, an electric motor, an electro-magnetic actuator, a voice coil, a shape memory alloy, an electro-active polymer, a solenoid, an eccentric rotating mass motor (\u201cERM\u201d), a linear resonant actuator (\u201cLRA\u201d), a piezoelectric actuator, a high bandwidth actuator, an electroactive polymer (\u201cEAP\u201d) actuator, an electrostatic friction display, or an ultrasonic vibration generator. An actuator is an example of a haptic output device, where a haptic output device is a device configured to output haptic effects, such as vibrotactile haptic effects, electrostatic friction haptic effects, kinesthetic haptic effects, or deformation haptic effects, in response to a drive signal. In alternate embodiments, the one or more actuators within controller  can be replaced by some other type of haptic output device.","Controller  can further include one or more speakers. The local processor of controller , or, processor  in embodiments where controller  does not include a local processor, may transmit an audio signal to at least one speaker of controller , which in turn outputs audio effects. The speaker may be, for example, a dynamic loudspeaker, an electrodynamic loudspeaker, a piezoelectric loudspeaker, a magnetostrictive loudspeaker, an electrostatic loudspeaker, a ribbon and planar magnetic loudspeaker, a bending wave loudspeaker, a flat panel loudspeaker, a heil air motion transducer, a plasma arc speaker, and a digital loudspeaker.","Controller  can further include one or more sensors. A sensor can be configured to detect a form of energy, or other physical property, such as, but not limited to, sound, movement, acceleration, bio signals, distance, flow, force\/pressure\/strain\/bend, humidity, linear position, orientation\/inclination, radio frequency, rotary position, rotary velocity, manipulation of a switch, temperature, vibration, or visible light intensity. The sensor can further be configured to convert the detected energy, or other physical property, into an electrical signal, or any signal that represents virtual sensor information, and controller  can send the converted signal to the local processor of controller , or, processor  in embodiments where controller  does not include a local processor. The sensor can be any device, such as, but not limited to, an accelerometer, an electrocardiogram, an electroencephalogram, an electromyograph, an electrooculogram, an electropalatograph, a galvanic skin response sensor, a capacitive sensor, a hall effect sensor, an infrared sensor, an ultrasonic sensor, a pressure sensor, a fiber optic sensor, a flexion sensor (or bend sensor), a force-sensitive resistor, a load cell, a LuSense CPS, a miniature pressure transducer, a piezo sensor, a strain gage, a hygrometer, a linear position touch sensor, a linear potentiometer (or slider), a linear variable differential transformer, a compass, an inclinometer, a magnetic tag (or radio frequency identification tag), a rotary encoder, a rotary potentiometer, a gyroscope, an on-off switch, a temperature sensor (such as a thermometer, thermocouple, resistance temperature detector, thermistor, or temperature-transducing integrated circuit), microphone, photometer, altimeter, bio monitor, camera, or a light-dependent resistor.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 2","FIG. 1","FIG. 3","FIGS. 2 and 3","FIG. 4"],"b":["100","100","30","100","100","100","102","110","114","118","122","124"]},{"@attributes":{"id":"p-0064","num":"0063"},"figref":["FIG. 4","FIG. 4"],"b":["100","101","104","106","100","108","104","105","105","100","108","100","104","104","106","104","106","104","106"]},"A housing  of controller  is shaped to easily accommodate two hands gripping the device, either by a left-handed user or a right-handed user. Those skilled in the art would recognize that controller  is merely an example embodiment of a controller of similar shape and size to many \u201cgamepads\u201d currently available for video game console systems, such as a Microsoft\u00ae Xbox One\u2122 controller or a PlayStation\u00ae DualShock\u2122 controller, and that controllers with other configurations of user input elements, shapes, and sizes may be used, including but not limited to controllers such as a Wii\u2122 remote or Wii\u2122 U Controller, Sony\u00ae SixAxis\u2122 controller or Sony\u00ae Wand controller, as well as controllers shaped as real life objects (such as tennis rackets, golf clubs, baseball bats, and the like) and other shapes, or controllers with a display or head-mounted display.","Controller  includes several user input elements, including an analog or digital stick , a button , and a trigger . As used herein, user input element refers to an interface device such as a trigger, button, analog or digital stick, or the like, which is manipulated by the user to interact with host computer . As can be seen in , and as known to those skilled in the art, more than one of each user input element and additional user input elements may be included on controller . Accordingly, the present description of a trigger , for example, does not limit controller  to a single trigger. Further, the block diagram of  shows only one (1) of each of analog or digital stick , button , and trigger . However, those skilled in the art would understand that multiple analog or digital sticks, buttons, and triggers, as well as other user input elements, may be used, as described above.","As can be seen in the block diagram of , controller  includes a targeted actuator or motor to directly drive each of the user input elements thereof as well as one or more general or rumble actuators ,  operably coupled to housing  in a location where a hand of the user is generally located. More particularly, analog or digital stick  includes a targeted actuator or motor  operably coupled thereto, button  includes a targeted actuator or motor  operably coupled thereto, and trigger  includes a targeted actuator or motor  operably coupled thereto. In addition to a plurality of targeted actuators, controller  includes a position sensor operably coupled to each of the user input elements thereof. More particularly, analog or digital stick  includes a position sensor  operably coupled thereto, button  includes a position sensor  operably coupled thereto, and trigger  includes a position sensor  operably coupled thereto. Local processor  is operably coupled to targeted actuators , ,  as well as position sensors , ,  of analog or digital stick , button , and trigger , respectively. In response to signals received from position sensors , , , local processor  instructs targeted actuators , ,  to provide directed or targeted kinesthetic effects directly to analog or digital stick , button , and trigger , respectively. Such targeted kinesthetic effects are discernible or distinguishable from general or rumble haptic effects produced by general actuators ,  along the entire body of the controller. The collective haptic effects provide the user with a greater sense of immersion to the game as multiple modalities are being simultaneously engaged, e.g., video, audio, and haptics. Further details of a controller configured to produce haptics are described in greater detail in application Ser. No. 14\/258,644, filed Apr. 22, 2014, entitled \u201cGAMING DEVICE HAVING A HAPTIC-ENABLED TRIGGER,\u201d herein incorporated by reference in its entirety.",{"@attributes":{"id":"p-0068","num":"0067"},"figref":["FIG. 5","FIG. 1","FIG. 1","FIGS. 2"],"b":["10","500","510","520","500","510","500","520","500","520","520","30","100","3","4"]},"Device  includes game input management code . Game input management code  includes a set of computer-readable instructions that manage input provided by controller  in the context of a game application, or other type of application, executed within device . Device  further includes peripheral input application programming interface (\u201cAPI\u201d) . Peripheral input API  includes a set of computer-readable functions or routines that allow game input management code  to interact with peripheral firmware  in order to receive and manage input provided by controller . Device  further includes rumble API . Rumble API includes a set of computer-readable functions or routines that allow game input management code  to interact with peripheral firmware  in order to transmit rumble instructions to one or more rumble motors, or rumble actuators, of controller  (e.g., rumble motors L and R, as illustrated in ). A rumble instruction can cause a rumble motor, or rumble actuator, of controller  to produce a general or rumble haptic effect.","Device  further includes haptic effect API  (identified in  as \u201cAPI\u201d). Haptic effect API  includes a set of computer-readable functions or routines that are exposed to game input management code , and that allow game input management code  to interact with peripheral firmware  in order to transmit haptic instructions to controller , such as trigger instructions to one or more triggers of controllers  (e.g., triggers L and R, as illustrated in ). A haptic instruction can cause one or more targeted motors, or targeted actuators, of controller  to produce a haptic effect at one or more user input elements of controllers . A trigger instruction is a specific type of haptic instruction that can cause one or more targeted motors, or targeted actuators, of controller  (e.g., motors L and R, as illustrated in ) to produce a trigger haptic effect at one or more triggers of controllers  (e.g., triggers L and R, as illustrated in ). A trigger haptic effect is a specific type of haptic effect that is experienced at a trigger of a controller, such as controller . Haptic effect API  can store one or more trigger haptic effect definitions. A haptic effect definition is a data structure that includes haptic data, such as a haptic signal, that is pre-defined and that can be stored within a storage, such as a haptic file or haptic stream, and that can be sent to one or more rumble motors, rumble actuators, targeted motors, or targeted actuators, to produce a haptic effect at a component, or user input element, of controller . The haptic data can include one or more attributes of the corresponding haptic effect, where the attributes can be stored as parameters. Example parameters of a haptic effect definition include an amplitude parameter, a frequency parameter, a waveform parameter, an envelope parameter, a magnitude (or strength) parameter, and a duration parameter. A trigger haptic effect definition is a specific type of haptic effect definition that can be sent to one or more motors, or actuators, of controller  (e.g., motors L and R, as illustrated in ) to produce a trigger haptic effect at one or more triggers of controllers  (e.g., triggers L and R, as illustrated in ).","According to the embodiment, Haptic effect API  can allow game input management code  to interact with direct playback\/crossover , trigger engine , and spatialization engine , and can further manage direct playback\/crossover , trigger engine , and spatialization engine  according to requests invoked by game input management code . Further, haptic effect API  can store data required for communication with peripheral firmware , and required for generation of one or more trigger haptic effects. In an alternate embodiment, haptic effect API  can reside within peripheral firmware  rather than device . Haptic effect API  is further described below in greater detail in conjunction with .","Device  further includes direct playback\/crossover . Direct playback\/crossover  receives haptic data as input, produces haptic data as output, and transmits haptic data to one or more targeted motors, or targeted actuators, of controller  (e.g., motors L and R, as illustrated in ). In certain embodiments, direct playback\/crossover  can output the input haptic data directly, without modifying a format of the input haptic data. This results in an \u201cas-is\u201d playback of the input haptic data. In other embodiments, direct playback\/crossover  can convert the haptic data that is input from a first format to a second format, and can further output the converted haptic data. Depending on the type of playback, direct playback\/crossover  can optionally use a programmable crossover to convert the haptic data. By converting the haptic data, device  can \u201cdeconstruct\u201d the haptic effect and playback the haptic effect at multiple actuators faithfully. In one embodiment, the format of the haptic data can be a Haptic Elementary Stream (\u201cHES\u201d) format. A HES format is a file or data format for representing haptic data that can be streamed to a device. The haptic data can be represented in a manner that is identical or similar to how uncompressed sound is represented, although the haptic data can be encrypted within the HES format. Thus, the haptic data can be stored in a haptic file or haptic stream, where a format of the haptic file or haptic stream is an HES format. In other words, the HES format can be used by the haptic file or haptic stream to represent the haptic data in a haptic format. In an alternate embodiment, direct playback\/crossover  can reside within peripheral firmware  rather than device . Direct playback\/crossover  is further described below in greater detail in conjunction with , , , , , , and .","Device  further includes trigger engine . Trigger engine  can receive haptic data, such as a trigger haptic effect definition, and can modify the haptic data based on data, such as trigger data (e.g., trigger data  as illustrated in ) received from controller . Trigger data is data that includes one or more parameters that indicate a position and\/or range of one or more triggers of controller  (e.g., triggers L and R as illustrated in ). Trigger engine  can further transmit haptic instructions to controller . For example, trigger engine  can transmit trigger instructions to one or more triggers of controller  (e.g., triggers L and R, as illustrated in ). As previously described, a trigger instruction can cause one or more targeted motors, or targeted actuators, of controller  (e.g., motors L and R, as illustrated in ) to produce a trigger haptic effect at one or more triggers of controllers  (e.g., triggers L and R, as illustrated in ). Thus, in one embodiment, by modifying the haptic data of the trigger haptic effect definition, trigger engine  can cause a specific trigger haptic effect to be experienced at a trigger based on a position and\/or range of the trigger. In another embodiment, by modifying the haptic data of the trigger haptic effect definition, trigger engine  can scale a trigger haptic effect for one or more targeted motors, or targeted actuators, of controller  (e.g., motors L and R, as illustrated in ) based on a position and\/or range of the trigger. Trigger engine  can further store one or more haptic effect definitions, such as trigger haptic effect definitions. In an alternate embodiment, trigger engine  can reside within peripheral firmware  rather than device .","Device  further includes spatialization engine  (identified in  as \u201cspatialisation engine\u201d). Spatialization engine  can receive haptic data, such as a trigger haptic effect definition, and can modify the haptic data based on spatialization data. Spatialization data can include data that indicates a desired direction and\/or flow of a haptic effect, such as a trigger haptic effect. In certain embodiments, spatialization engine  can receive spatialization data that includes a direction and\/or flow from game input management code . Further, spatialization data can also include one or more positions of one or more hands of a user located on controller . In certain embodiments, spatialization engine  can receive spatialization data that includes one or more hand positions from controller . Further, in certain embodiments, spatialization engine  can receive spatialization data that includes a position of a user's character within a game application as communicated by game input management code .","According to the embodiment, spatialization engine  can modify the haptic data so that a haptic effect, such as a trigger haptic effect, is scaled for one or more rumble motors, or rumble actuators, of controller  (e.g., rumble motors L and R, as illustrated in ), and that the haptic effect is also scaled for one or more targeted motors, or targeted actuators, of controller  (e.g., motors L and R, as illustrated in ). In other words, spatialization engine  can modify the haptic data that is sent to each motor or actuator, and thus, modify the haptic effect that is experienced at each motor or actuator, in order to convey a sense of direction and flow of an overall haptic effect. For example, in order to emphasize a haptic effect experienced at a motor or actuator, spatialization engine  may scale one or more portions of the haptic effect. For example, spatialization engine  may scale haptic data that is sent to the motor or actuator that causes the haptic effect to be experienced, causing the haptic effect to be more pronounced (e.g., increased magnitude, duration, etc.). Additionally, spatialization engine  may scale haptic data that is sent to other motors or actuators, causing other haptic effects that are experienced at those motors or actuators to be less pronounced (e.g., decreased magnitude, duration, etc.). In certain embodiments, spatialization engine  can modify the haptic data in real-time. Further, in certain embodiments, spatialization engine  can have non-linear relationships between inputs and motor, or actuator, outputs in order to exaggerate an overall trigger haptic effect. In an alternate embodiment, spatialization engine  can reside within peripheral firmware  rather than device . Spatialization engine  is further described below in greater detail in conjunction with , , and .","Device  further includes encoder . Encoder  encodes haptic data received from direct playback\/crossover , trigger engine , and\/or spatialization engine  into a format. In one embodiment, the format can be an HES format. Encoder  further transmits the encoded haptic data to peripheral firmware .","Peripheral firmware  includes decoder and crossover . Decoder and crossover  receives the encoded haptic data from encoder  and decodes the encoded haptic data. In certain embodiments, decoder and crossover  computes a programmable crossover in order to decode the encoded haptic data. In some of these embodiments, decoder and crossover  computes the programmable crossover in real-time. Peripheral firmware  further includes trigger control . Trigger control  is a low-level control API for one or more targeted motors, or targeted actuators, of controller  (e.g., motors L and R, as illustrated in ). Trigger control  can receive a trigger instruction from device , can convert the trigger instruction into a low-level trigger instruction for a specified targeted motor, or targeted actuator, of controller , and can transmit the low-level trigger instruction to the specified targeted motor, or targeted actuator, of controller . The low-level trigger instruction can cause the specified targeted motor, or targeted actuator, to produce a trigger haptic effect at a specified trigger of controller .","Peripheral firmware  further includes trigger data . Trigger data , as previously described, is data that includes one or more parameters, such as one or more parameters that indicate a position and\/or range of one or more triggers of controller  (e.g., triggers L and R as illustrated in ). Trigger data  can be received from controller  by peripheral firmware . Peripheral firmware  can further store trigger data , and can further transmit trigger data  to device . Peripheral firmware  further includes other gamepad functions , which are functions of controller  that can be managed by peripheral firmware . Such functions can include wired\/wireless communications, input reporting, protocol implementation, power management, etc. Peripheral firmware  further includes rumble control . Rumble control  is a low-level control API for one or more rumble motors, or rumble actuators, of controller  (e.g., rumble motors L and R, as illustrated in ). Rumble control  can receive a rumble instruction from device , can convert the rumble instruction into a low-level rumble instruction for a specified rumble motor, or rumble actuator, of controller , and can transmit the low-level trigger instruction to the specified rumble motor, or rumble actuator, of controller .","Controller  includes triggers L and R. Controller  further includes gear boxes L and R and motors L and R. Motor L and gearbox L are operably coupled to trigger L within controller . Likewise, motor R and gearbox R are operably coupled to trigger R within controller . When motor L receives a trigger instruction, motor L and gearbox L collectively cause a trigger haptic effect to be experienced at trigger L. Likewise, when motor R receives a trigger instruction, motor R and gearbox R collectively cause a trigger haptic effect to be experienced at trigger R. According to the embodiment, peripheral firmware  sends trigger instructions to motors L and R of controller  using drive electronics . Controller  further includes potentiometers L and R. Potentiometer L can detect a position and\/or range of trigger L, and can further send the detected position and\/or range of trigger L to peripheral firmware  as trigger data. Likewise, potentiometer R can detect a position and\/or range of trigger R, and can further send the detected position and\/or range of trigger R to peripheral firmware  as trigger data. In one embodiment, potentiometers L and R can each be replaced with another type of position sensor, such as a hall effect sensor. Controller  further includes rumble motors L and R. When rumble motor L receives a rumble instruction, rumble motor L causes a haptic effect to be experienced along a left body of controller . Likewise, when rumble motor R receives a rumble instruction, rumble motor R cause a haptic effect to be experienced along a right body of controller . According to the embodiment, peripheral firmware  sends rumble instructions to rumble motors L and R of controller  using rumble drive electronics .","In an alternate embodiment, one or more targeted motors, or targeted actuators, can be operably coupled to one or more user input elements (such as one or more digital buttons, one or more analog buttons, one or more bumpers, one or more directional pads, one or more analog or digital sticks, one or more driving wheels) of controller . According to the alternate embodiment, peripheral firmware  can sends instructions to the one or more targeted motors or targeted actuators, causing the one or more targeted motors or targeted actuators to produce haptic effects that are experienced at the one or more user input elements of controller .",{"@attributes":{"id":"p-0081","num":"0080"},"figref":["FIG. 6","FIG. 1"],"b":["600","10","600","600","610","610","600","620","610","620","620"]},"User interface  further includes effect definitions . According to the embodiment, the user can save a modified haptic effect definition as a new haptic effect definition, where the new haptic effect definition is displayed within effect definitions . The new haptic effect definition can be stored within a haptic file or haptic stream. In one embodiment, a format of the haptic file or haptic stream can be an HES format. The new haptic effect definition can further be exported to an external haptic file or external haptic stream. User interface  further includes a play button . Interacting with play button  can cause the system to output a haptic effect at a controller that can be operably controlled to user interface . The haptic effect can be a selected pre-defined haptic effect definition or a selected new haptic effect definition.","User interface  further includes trigger engine area . Trigger engine area  is an editable visual area that can visualize a trigger haptic effect that is generated by a trigger engine (such as trigger engine  of ). As previously described, a trigger engine can receive a trigger haptic effect definition and can modify the trigger haptic effect definition based on a position and\/or range of a trigger of a controller. Thus, trigger engine area  can display a visualization of the trigger, including an actual position of the trigger. Further, trigger engine area  can display a position and\/or range of the trigger that is defined for a trigger haptic effect definition, where the position and\/or range can cause the trigger engine to modify the trigger haptic effect definition. A user can edit the position and\/or range of the trigger that is defined for the trigger haptic effect definition. User interface  further includes spatialization engine area . Spatialization engine area  is an editable visual area that can visualize a haptic effect that can be originally generated by the trigger engine and that can be further modified by a spatialization engine (such as spatialization engine  of ). As previously described, the spatialization engine can modify the haptic effect definition so that a haptic effect is scaled for one or more targeted motors, targeted actuators, rumble motors, or rumble actuators, of a controller. Thus, spatialization engine area  can display a visualization of the controller. The spatialization engine area  can further display a visualization of the haptic effect experienced at each targeted motor, targeted actuator, rumble motor, or rumble actuator of the controller. A user can edit a scaling of the haptic effect that is experienced at each targeted motor, targeted actuator, rumble motor, or rumble actuator of the controller.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":["FIG. 7","FIG. 1"],"b":["10","700","700","710","720","710","720","720","710","720","730","710","730"]},"The crossover input warp algorithm can reside either in the device itself, or reside on the opposite side of a communications link, executing on a processor different from that of the device. The crossover input warp algorithm may also separate the input data (haptic or audio) into two bands, where lower frequencies are separated and then optionally further transformed before being applied to one or more actuator outputs, and higher frequencies are separated and then optionally transformed before being applied to a number of actuators distinct from those used for the lower-frequency separated data. This type of data separation could occur on an arbitrary number of frequency bands and actuator outputs. In alternate embodiments, the input data (audio or haptic) can be separated into multiple overlapping frequency regions, which are then each optionally transformed and applied to a number of output actuators. Another set of embodiments could create a number of signal strength bands, where the input data (audio or haptic) is separated according to output power or strength (such as through peak detection, RMS calculations, etc.), and these separated data streams are each applied to one or more distinct sets of actuators. In alternate embodiments, the input data (audio or haptic) can be separated according to output power or strength (such as through peak detection, RMS calculations, etc.) into distinct but overlapping data streams, instead of completely distinct streams, where the strength filtering algorithms capture overlapping regions of strength, optionally apply the transformations and apply each of the outputs to a number of output actuators.","The system can further send the encoded audio effect definition or the encoded haptic effect definition to a human interface device (\u201cHID\u201d) interpreter  that resides on controller . HID interpreter  receives and interprets the encoded audio effect definition or the encoded haptic effect definition in order to provide a haptic effect at a trigger of controller . In one embodiment, a system can further modify the encoded audio effect definition or the encoded haptic effect definition using a trigger engine (such as trigger engine  of ) and\/or a spatialization engine (such as spatialization engine  of ) before the system sends the encoded audio effect definition or the encoded haptic effect definition to HID interpreter  of controller .",{"@attributes":{"id":"p-0087","num":"0086"},"figref":["FIG. 8","FIG. 1"],"b":["10","800","800"]},"Once a user of the system has authored a spatialization haptic effect using audio authoring component , the user can preview the spatialization haptic effect. The preview functionality can allow for further customization of the spatialization haptic effect. Upon previewing the spatialization haptic effect, the system can send the authored audio effect definition to four-channel output driver , where four-channel output driver  can stream the audio effect definition as four channels of audio data. In one embodiment, four-channel output driver  can be a four-channel ASIO output driver. In an alternate embodiment, four-channel output driver  can be replaced by another driver that streams the audio effect definition as any plural number of channels of audio data, such as six or eight channels of audio data.","Further, the system can send the audio stream to audio-to-haptic converter , where audio-to-haptic converter  can convert the audio effect definition of the audio stream into a haptic effect definition using a haptic conversion algorithm. In one embodiment, each separate channel of the audio effect definition that corresponds to a motor, or actuator, can be converted into a channel of a haptic effect definition. Example haptic conversion algorithms are described in the following patents or patent applications (all of which are hereby incorporated by reference in their entirety): U.S. Pat. No. 7,979,146; U.S. Pat. No. 8,000,825; U.S. Pat. No. 8,378,964; U.S. Pat. App. Pub. No. 2011\/0202155; U.S. Pat. App. Pub. No. 2011\/0215913; U.S. Pat. App. Pub. No. 2012\/0206246; U.S. Pat. App. Pub. No. 2012\/0206247; U.S. Pat. App. Pub. No. 2013\/0265286; U.S. Pat. App. Pub. No. 2013\/0131851; U.S. Pat. App. Pub. No. 2013\/0207917; U.S. Pat. App. Pub. No. 2013\/0335209; U.S. Pat. App. Pub. No. 2014\/0064516; U.S. patent application Ser. No. 13\/661,140; U.S. patent application Ser. No. 13\/785,166; U.S. patent application Ser. No. 13\/788,487; U.S. patent application Ser. No. 14\/078,438; U.S. patent application Ser. No. 14\/078,442; U.S. patent application Ser. No. 14\/078,445; U.S. patent application Ser. No. 14\/051,933; U.S. patent application Ser. No. 14\/020,461; U.S. patent application Ser. No. 14\/020,502; U.S. patent application Ser. No. 14\/277,870; and U.S. patent application Ser. No. 14\/467,184.","The system can further send the converted haptic effect definition to HES multi-channel encoder , where multi-channel encoder  can encode the converted haptic effect definition into an external format, such as an HES format. The system can further send the encoded and converted haptic effect definition to trigger controller interface (\u201cI\/F\u201d)  that resides on controller . Trigger controller I\/F  can receive and interpret the encoded and converted haptic effect definition in order to preview the authored spatialization haptic effect at a trigger of controller .","In this embodiment, the system can provide audio authoring component , where audio authoring component  is identical to audio authoring component . Once a user of the system has authored a spatialization haptic effect using audio authoring component , the user can save the spatialization haptic effect. Upon saving the spatialization haptic effect, the system can export the audio effect definition as separate audio files . In one embodiment where the audio effect definition includes four channels, audio files  can include four audio files. In an alternate embodiment, where the audio effect definition includes another number of channels, audio files  can include that number of separate audio files. In certain embodiments, audio files  can be a Waveform Audio File (\u201cWAV\u201d) format. The system can further send audio files  to a HES encoder graphical user interface (\u201cGUI\u201d) , where HES encoder GUI  can encode audio files  into a single audio file. In one embodiment, the audio file can be an HES format. Further, the system can send the audio file to audio-to-haptic converter , where audio-to-haptic converter  can convert the audio effect definition of the audio file into a haptic effect definition using a haptic conversion algorithm. In one embodiment, each separate channel of the audio effect definition that corresponds to a motor, or actuator, can be converted into a channel of a haptic effect definition. The system can further send the converted haptic effect definition to HES multi-channel encoder , where multi-channel encoder  can encode the converted haptic effect definition into an external format, such as an HES format. The system can further store the encoded and converted haptic effect definition within a haptic file . In one embodiment, haptic file  can be an HES file.",{"@attributes":{"id":"p-0092","num":"0091"},"figref":["FIG. 9","FIG. 1"],"b":["10","900"]},"Once a user of the system has authored a spatialization haptic effect using audio authoring component , the user can preview the spatialization haptic effect. Upon previewing the spatialization haptic effect, the system can send the authored audio effect definition to single-channel output driver , where single-channel output driver  can stream the audio effect definition as a single channel of audio data. In one embodiment, single-channel output driver  can be a single-channel ASIO output driver. Further, the system can send the audio stream to audio-to-haptic converter , where audio-to-haptic converter  can convert the audio effect definition of the audio stream into a haptic effect definition using a haptic conversion algorithm. In one embodiment, each separate channel of the audio effect definition that corresponds to a motor, or actuator, can be converted into a channel of a haptic effect definition. Even further, the system can send the converted haptic effect definition to crossover GUI , where crossover GUI  can apply a crossover input warp algorithm to separate the converted haptic effect definition into three different channels that can be mapped to three different outputs (such as: (1) a low-frequency rumble motor, or rumble actuator; (2) a medium-frequency rumble motor, or rumble actuator; or (3) a high-frequency targeted motor, or targeted actuator).","The system can further send the converted haptic effect definition to HES multi-channel encoder , where multi-channel encoder  can encode the converted haptic effect definition into an external format, such as an HES format. The system can further send the encoded and converted haptic effect definition to trigger controller I\/F  that resides on controller . Trigger controller I\/F  can receive and interpret the encoded and converted haptic effect definition in order to preview the authored trigger haptic effect at a trigger of controller .","In this embodiment, the system can provide audio authoring component , where audio authoring component  is identical to audio authoring component . Once a user of the system has authored a spatialization haptic effect using audio authoring component , the user can save the spatialization haptic effect. Upon saving the spatialization haptic effect, the system can export the audio effect definition as a single audio file . In certain embodiments, audio file  can be a WAV format. The system can further export crossover settings . The system can further send audio file  to a HES encoder GUI , where HES encoder GUI  can encode audio file  and crossover settings  into a single audio file. In one embodiment, the audio file can be an HES format. The system can further send the audio file to HES single-channel and crossover encoder , where single-channel and crossover encoder can encode the audio file into an external format, such as an HES format. The system can further store the encoded audio file within a haptic file . In one embodiment, haptic file  can be an HES file.",{"@attributes":{"id":"p-0096","num":"0095"},"figref":["FIG. 10","FIG. 1"],"b":["10","1000","1000","1000","1000","1000"]},"According to the embodiment, the system can send the four channels of the haptic effect definition included within haptic file  to strength control , where strength control  can modify a strength, or magnitude, of the haptic data included within each channel of the haptic effect definition. The system can then send the four channels of the haptic effect definition to front\/back (\u201cF\/B\u201d) spatialization , where F\/B spatialization  can modify the haptic data included within each channel of the haptic effect definition based on spatialization data. The spatialization data can include a direction and\/or flow of a haptic effect. In one embodiment, the direction and\/or flow of the haptic effect can be a frontwards or backwards direction. Further, spatialization data can include one or more hand positions. According to the embodiment, F\/B spatialization  can modify the haptic data included within each channel so that a haptic effect is scaled for each motor, or actuator. The system can then send channel LR to low rumble motor  (identified in  as \u201cLowR motor\u201d), and can further send channel MR to medium rumble motor  (identified in  as \u201cMidR motor\u201d). The haptic data contained within channel LR can cause low rumble motor  to produce a general or rumble haptic effect, and the haptic data contained within channel MR can cause medium rumble motor  to produce a general or rumble haptic effect.","The system can further send channels LT and RT to left\/right (\u201cL\/R\u201d) spatialization , where L\/R spatialization  can modify the haptic data included within channels LT and RT based on spatialization data. The spatialization data can include a direction and\/or flow of a haptic effect. In one embodiment, the direction and\/or flow of the haptic effect can be a left or right direction. Further, spatialization data can include one or more hand positions. According to the embodiment, L\/R spatialization  can modify the haptic data included within each channel so that a haptic effect is scaled for each motor, or actuator. The system can then send channel LT to left trigger targeted motor  (identified in  as \u201cLT motor\u201d), and can further send channel RT to right trigger targeted motor  (identified in  as \u201cRT motor\u201d). The haptic data contained within channel LT can cause left trigger targeted motor  to produce a trigger haptic effect at a left trigger, and the haptic data contained within channel RT can cause right trigger targeted motor  to produce a trigger haptic effect at a right trigger.",{"@attributes":{"id":"p-0099","num":"0098"},"figref":["FIG. 11","FIG. 1"],"b":["10","1100","1100","1100","1100","1100"]},"According to the embodiment, the system can send the channel of the haptic effect definition included within haptic file , and the one or more crossover parameters also included within haptic file , to programmable crossover . Programmable crossover  can apply a crossover input warp algorithm using the one or more crossover parameters to separate the channel into three different channels: a low-frequency channel; a medium-frequency channel; and a high-frequency channel. The low-frequency channel includes a portion of the haptic data included within the haptic effect definition that includes one or more low frequencies. The medium-frequency channel includes a portion of the haptic data included within the haptic effect definition that includes one or more medium frequencies. The high-frequency channel includes a portion of the haptic data included within the haptic effect definition that includes one or more high frequencies.","The system can then send the three channels of the haptic effect definition to F\/B spatialization , where F\/B spatialization  can modify the haptic data included within each channel of the haptic effect definition based on spatialization data. The spatialization data can include a direction and\/or flow of a haptic effect. In one embodiment, the direction and\/or flow of the haptic effect can be a frontwards or backwards direction. Further, spatialization data can include one or more hand positions. According to the embodiment, F\/B spatialization  can modify the haptic data included within each channel so that a haptic effect is scaled for each motor, or actuator. The system can then send the low frequency channel to low rumble motor  (identified in  as \u201cLowR motor\u201d), and can further send the middle frequency channel to medium rumble motor  (identified in  as \u201cMidR motor\u201d). The haptic data contained within the low-frequency channel can cause low rumble motor  to produce a general or rumble haptic effect, and the haptic data contained within the medium-frequency channel can cause medium rumble motor  to produce a general or rumble haptic effect.","The system can further send the high-frequency channel to L\/R spatialization , where L\/R spatialization  can modify the haptic data included within the high frequency channel based on spatialization data. In one embodiment, the direction and\/or flow of the haptic effect can be a left or right direction. Further, spatialization data can include one or more hand positions. According to the embodiment, L\/R spatialization  can modify the haptic data included within the channel so that a haptic effect is scaled for each motor, or actuator. The system can then send the high-frequency channel to left trigger targeted motor  (identified in  as \u201cLT motor\u201d), and can also send the high-frequency channel to right trigger targeted motor  (identified in  as \u201cRT motor\u201d). The haptic data contained within the high-frequency channel can cause left trigger targeted motor  to produce a trigger haptic effect at a left trigger, and the haptic data contained within the high-frequency channel can cause right trigger targeted motor  to produce a trigger haptic effect at a right trigger.",{"@attributes":{"id":"p-0103","num":"0102"},"figref":["FIG. 12","FIG. 1"],"b":["10","1200","1200","1200","1200"]},"According to the embodiment, the system can send the four channels of the audio effect definition included within audio file  to audio-to-haptic converter , where audio-to-haptic converter  can convert the audio effect definition into a haptic effect definition using a haptic conversion algorithm. In one embodiment, each separate channel of the audio effect definition can be converted into a channel of a haptic effect definition. In the illustrated embodiment: channel LR can be converted using a peak\/decimation filter with a range of less than 60 hertz (\u201cHz\u201d); channel MR can be converted using a peak\/decimation filter with a value of 60 Hz; and channels LT and RT can each be converted using a peak\/decimation filter with a range of 200 Hz-2 kHz.","The system can further send the four channels of the converted haptic effect definition to encoder\/decoder , where encoder\/decoder  can encode each channel of the converted haptic effect definition into an external format, such as an HES format. The system can then send the four encoded channels of the converted haptic effect definition to F\/B spatialization , where F\/B spatialization  can modify the converted haptic data included within each encoded channel of the converted haptic effect definition based on spatialization data. The spatialization data can include a direction and\/or flow of a haptic effect. In one embodiment, the direction and\/or flow of the haptic effect can be a frontwards or backwards direction. Further, spatialization data can include one or more hand positions. According to the embodiment, F\/B spatialization  can modify the converted haptic data included within each encoded channel so that a haptic effect is scaled for each motor, or actuator. The system can then send encoded channel LR to low rumble motor  (identified in  as \u201cLowR motor\u201d), and can further send encoded channel MR to medium rumble motor  (identified in  as \u201cMidR motor\u201d). The converted haptic data contained within channel LR can cause low rumble motor  to produce a general or rumble haptic effect, and the converted haptic data contained within channel MR can cause medium rumble motor  to produce a general or rumble haptic effect.","The system can further send encoded channels LT and RT to L\/R spatialization , where L\/R spatialization  can modify the converted haptic data included within encoded channels LT and RT based on spatialization data. The spatialization data can include a direction and\/or flow of a haptic effect. In one embodiment, the direction and\/or flow of the haptic effect can be a left or right direction. Further, spatialization data can include one or more hand positions. According to the embodiment, L\/R spatialization  can modify the haptic data included within each channel so that a haptic effect is scaled for each motor, or actuator. The system can then send channel LT to left trigger targeted motor  (identified in  as \u201cLT motor\u201d), and can further send channel RT to right trigger targeted motor  (identified in  as \u201cRT motor\u201d). The haptic data contained within channel LT can cause left trigger targeted motor  to produce a trigger haptic effect at a left trigger, and the haptic data contained within channel RT can cause right trigger targeted motor  to produce a trigger haptic effect at a right trigger.",{"@attributes":{"id":"p-0107","num":"0106"},"figref":["FIG. 13","FIG. 1"],"b":["10","1300","1300","1300","1300"]},"According to the embodiment, the system can send the channel of the audio effect definition included within audio file , and, in one embodiment, the one or more crossover parameters also included within audio file , to programmable crossover . Programmable crossover  can apply a crossover input warp algorithm (in one embodiment, using the one or more crossover parameters) to separate the channel into three different channels: a low-frequency channel; a medium-frequency channel; and a high-frequency channel. Programmable crossover  can further convert the audio effect definition into a haptic effect definition using a haptic conversion algorithm. In one embodiment, each separate channel of the audio effect definition can be converted into a channel of a haptic effect definition. In the illustrated embodiment: the low-frequency channel can be converted using a peak\/decimation filter with a range of less than 60 hertz (\u201cHz\u201d); the medium-frequency channel can be converted using a peak\/decimation filter with a value of 60 Hz; and the high-frequency channel can each be converted using a peak\/decimation filter with a range of 200 Hz-2 kHz.","The system can further send the three channels of the converted haptic effect definition to encoder\/decoder , where encoder\/decoder  can encode each channel of the converted haptic effect definition into an external format, such as an HES format. The system can then send the three channels of the haptic effect definition to F\/B spatialization , where F\/B spatialization  can modify the haptic data included within each channel of the haptic effect definition based on spatialization data. The spatialization data can include a direction and\/or flow of a haptic effect. In one embodiment, the direction and\/or flow of the haptic effect can be a frontwards or backwards direction. Further, spatialization data can include one or more hand positions. According to the embodiment, F\/B spatialization  can modify the haptic data included within each channel so that a haptic effect is scaled for each motor, or actuator. The system can then send the low-frequency channel to low rumble motor  (identified in  as \u201cLowR motor\u201d), and can further send the middle-frequency channel to medium rumble motor  (identified in  as \u201cMidR motor\u201d). The haptic data contained within the low-frequency channel can cause low rumble motor  to produce a general or rumble haptic effect, and the haptic data contained within the medium-frequency channel can cause medium rumble motor  to produce a general or rumble haptic effect.","The system can further send the high-frequency channel to L\/R spatialization , where L\/R spatialization  can modify the haptic data included within the high-frequency channel based on spatialization data. In one embodiment, the direction and\/or flow of the haptic effect can be a left or right direction. Further, spatialization data can include one or more hand positions. According to the embodiment, L\/R spatialization  can modify the haptic data included within the channel so that a haptic effect is scaled for each motor, or actuator. The system can then send the high frequency channel to left trigger targeted motor  (identified in  as \u201cLT motor\u201d), and can also send the high frequency channel to right trigger targeted motor  (identified in  as \u201cRT motor\u201d). The haptic data contained within the high frequency channel can cause left trigger targeted motor  to produce a trigger haptic effect at a left trigger, and the haptic data contained within the high frequency channel can cause right trigger targeted motor  to produce a trigger haptic effect at a right trigger.",{"@attributes":{"id":"p-0111","num":"0110"},"figref":["FIG. 14","FIG. 5","FIG. 5"],"b":["1400","1400","507","506","1400"]},"User interface  includes flow . Flow  allows a user to programmatically manage a flow of a haptic effect. A flow is a temporal start-of-playback offset modification to delay playback on individual targeted motors, targeted actuators, rumble motors, or rumble actuators of a controller. Alternatively, a flow can be a duration modification to modify a duration of a haptic effect experienced at targeted motors, targeted actuators, rumble motors, or rumble actuators of a controller. For example, a flow can be defined so that haptic playback first begins on a left targeted motor or targeted actuator, then subsequently begins on a middle rumble motor or rumble actuator, and then further begins on a right targeted motor or targeted actuator. In this example, a flow of the overall haptic effect is left-to-right, as a user of a controller first experiences the haptic playback of the overall haptic effect at the left of the controller, then at the middle of the controller, and then at the right of the controller. A flow can be from left to right or vice-versa, front to back or vice-versa, or a combination of the two. Thus, a flow can define a haptic playback vector. Flow  can be visualized within user interface  as an arrow that can be placed horizontally, vertically, or diagonally within user interface . Thus, by interacting with flow , a user can modify one or more delays applied to various motors or actuators of the controller to stagger haptic playback.","User interface  further includes direction . Direction  allows a user to programmatically modify a direction of a haptic effect. A direction is a magnitude (or strength) modification to emphasize a front-back and\/or left-right bias (or balance) among various motors or actuators of a controller. Alternatively, a direction can be a frequency modification. For example, a direction can be defined so that haptic playback of the haptic effect is the strongest at the right of the controller. Direction  can be visualized within user interface  as a point within a two-dimensional grid or space defined by two axes. Thus, by interacting with direction , a user can modify magnitudes (or strengths) applied to various motors or actuators to emphasize a left-right and\/or front-back bias (or balance).","User interface  further includes strength . Strength  allows a user to programmatically modify a magnitude (or strength) of an overall haptic effect either before or during playback. Strength  can be visualized within user interface  as a slider. Thus, by interacting with strength , a user can modify an overall magnitude (or strength) of a haptic effect. User interface  further includes play speed . Play speed  allows a user to programmatically modify a play speed, or rate, at which a system (such as system  of ) processes a haptic effect definition of a haptic effect in order to playback the haptic effect. Play speed  can be visualized within user interface  as a slider. Thus, by interacting with play speed , a user can modify a play speed, or rate, of a haptic effect. User interface  further includes loop . Loop  allows a user to programmatically modify whether a playback of a haptic effect loops or not. Loop  can be visualized within user interface  as a button. Thus, by interacting with loop , a user can control a looping of a haptic effect. Further details of a spatialization engine are further described below in greater detail in conjunction with .",{"@attributes":{"id":"p-0115","num":"0114"},"figref":"FIG. 15","b":["1500","1500"]},"According to the embodiment, haptic effect API  can be accessed by application , which is a software application, such as a game application, that can be executed on a system (such as system  of ). Further, haptic effect API  can access an effect library , where effect library  can include one or more haptic effect definitions, such as haptic effect definition  (identified in  as \u201ceffect \u201d). As previously described, an example of a haptic effect definition is a trigger haptic effect definition. Further, haptic effect API  includes one or more device definitions, such as device definition  (identified in  as \u201cdevice \u201d). A device definition includes device data that defines a hardware device, such as a controller, gamepad, or other peripheral device, where a haptic effect is to be played. Haptic effect API  further includes one or more timer definitions, such as timer definition  (identified in  as \u201ctimer \u201d). A timer definition includes timer data that defines a time period where all haptic effect definitions registered to a specific hardware device are updated. Haptic effect API  further includes trigger definition  (identified in  as \u201ctrigger \u201d). A trigger definition includes trigger data that defines a trigger of a specific hardware device. Haptic effect API  further includes protocol definition  (identified in  as \u201cprotocol \u201d). A protocol definition describes a protocol of a communication interface used by haptic effect API  to communicate with a specific hardware device. Using protocol definition , haptic effect API  can communicate with device firmware  (identified in  as \u201cFW \u201d), where device firmware  is firmware for the specific hardware device. Using device firmware , haptic effect API  can further communicate with hardware device  (identified in  as \u201cHW \u201d), where hardware device  is the specific hardware device.","In one embodiment, application  can access device definition  to acquire a target hardware device (i.e., HW ) where a haptic effect is to be played. By accessing device definition , application  can further access timer definition , trigger definition , and protocol definition . Application  can further access haptic effect definition  from effect library  to instantiate a haptic effect. Application  can further cause the haptic effect be played at the target hardware device (i.e., HW ) by sending an instruction to the target hardware device (i.e., HW ) via haptic effect API  and FW .",{"@attributes":{"id":"p-0118","num":"0117"},"figref":["FIG. 16","FIG. 15"],"b":["1600","1600","1500","1610","1610","1620"]},"The architecture further includes trigger engine . As previously described, trigger engine  can receive a trigger haptic effect definition and can modify the trigger haptic effect definition based on trigger data, such as a position and\/or range of a trigger of a controller. The architecture further includes trigger hardware interface  (identified in  as \u201ctrigger HW interface \u201d). Trigger hardware interface  is a communication interface that allows trigger engine  to receive trigger data from a peripheral device, such as a controller or gamepad. The architecture further includes spatialization engine . As previously described, spatialization engine  can modify a haptic effect definition, such as a trigger haptic effect definition, so that a haptic effect, such as a trigger haptic effect, is scaled for one or more targeted motors, targeted actuators, rumble motors, or rumble actuators, of a controller. The architecture further includes basis effect rendering engine . Basis effect rendering engine  renders a haptic effect, such as a trigger haptic effect, for a motor or actuator based on a haptic effect definition, such as a trigger haptic effect definition. The architecture further includes actuator hardware interface  (identified in  as \u201cactuator HW interface \u201d). Actuator hardware interface  is a communication interface that allows basis effect rendering engine  to send haptic data included within the rendered haptic effect to a motor or actuator to cause the motor or actuator to play the haptic effect.",{"@attributes":{"id":"p-0120","num":"0119"},"figref":"FIG. 17","b":["1710","1720","1730","1740","1730","1740","1710","1720","1730","1740","1710","1720","1710","1720","1730","1740","1710","1720","1710","1720","1730","1740"]},{"@attributes":{"id":"p-0121","num":"0120"},"figref":["FIG. 18","FIG. 5","FIG. 18"],"b":["510","1800","1800","1800","1800","1801","1801","1800","1802","1802","1801","1802","1800","1803","1803","1800","1804","1804","1800","1820","1810"]},{"@attributes":{"id":"p-0122","num":"0121"},"figref":["FIG. 19","FIG. 1","FIG. 19","FIG. 19","FIG. 18"],"b":["10","1900","1900","1900","1910","1910","1910","1800","1910","1910","1910"]},"One type of a built-in haptic effect definition is static haptic effect definition  (identified in  as \u201cstatic \u201d). Static haptic effect definition  is a set of one or more periodic or magnitude sweep effect definitions that produce a static haptic effect that does not change over time. Examples include a car crash, a rocket launcher, and a user interface confirmation. Static haptic effect definition  can be called directly by application  based on events within a game. A static haptic effect produced by static haptic effect definition  can be used as a trigger haptic effect.","Another type of a built-in haptic effect definition is dynamic haptic effect definition  (identified in  as \u201cdynamic \u201d). Dynamic haptic effect definition  is an algorithm that receives one or more parameters  as input and produces a continuously changing haptic effect (i.e., a dynamic haptic effect). Examples include an engine's revolutions per minute (\u201cRPM\u201d), a snowboard, and an explosion. A static haptic effect definition can be turned into a dynamic haptic effect definition by including a vector (i.e., distance and direction), and an input position\/state of one or more buttons or axes). A dynamic haptic effect can be based on game variables that can be passed from application . A dynamic haptic effect can also be based on controller input, such as trigger input.","Another type of a built-in haptic effect definition is direct control haptic effect definition  (identified in  as \u201cdirect control \u201d). In a direct control scenario, direct control haptic effect definition  can be defined in a way that allows direct rendering to the output device, with very little processing applied to direct control haptic effect definition  as it travels through core effect library . In this scenario, direct control haptic effect definition  can include a number of distinct data channels that corresponds to, and maps exactly to, a number of output actuators on an output device. Alternately, direct control haptic effect definition  can contain a number of distinct data channels that exceeds the number of available output actuators on the output device, and core effect library  can select a number of channels, where each channel is selected such that it best maps to a particular actuator in the output device, and core effect library  can then transmit the selected channels' data to the mapped actuators.","The system further includes core effect library  (identified in  as \u201ccore19\u201d). Core effect library  includes one or more haptic effect definitions  (identified in  as \u201cFX \u201d). Haptic effect definitions  can include trigger haptic effect definitions  (identified in  as \u201ctrigger effects \u201d). Examples of haptic effect definitions can include explosion haptic effect definitions, RPM haptic effect definitions, snowboard haptic effect definitions, and other haptic effect definitions. Core effect library further includes mixer  (identified in  as \u201cmixer\/prioritization \u201d). Mixer  can mix or prioritize one or more haptic effect definitions.","The system further includes low-level API . Low-level API  can receive an instruction to play a haptic effect based on a haptic effect definition, and can convert the instruction to a low-level instruction that can be interpreted by a controller . An example of low-level API  is Xbox\u00ae API  by Microsoft Corporation, and an example of controller  is Xbox\u00ae controller  by Microsoft Corporation.",{"@attributes":{"id":"p-0128","num":"0127"},"figref":["FIG. 20","FIG. 1"],"b":["2000","10","2000","2000","2010","2010","2000","2020","2020","2020"]},"User interface  further includes timeline . According to the embodiment, a user can select a haptic effect preset displayed within open effects , and timeline  can display a graphical representation of the haptic effect definition that is represented by the selected haptic effect preset. In the illustrated embodiment, the haptic effect definition includes four channels, with each channel including haptic data that is mapped for a specific output (e.g., (1) targeted motor or actuator for a right trigger; (2) targeted motor or actuator for a left trigger; (3) right rumble motor or actuator; and (4) left rumble motor or actuator), and each channel being displayed along the timeline. However, in other embodiments, the haptic effect definition can include any number of channels. Further, a user can modify one or more channels of the selected haptic effect definition by interacting with one or more display elements within timeline . By modifying one or more channels of a haptic effect definition, one can modify one or more attributes of a corresponding haptic effect.","User interface  further includes effect properties . Effect properties  is an editable visual area that can visualize a trigger haptic effect that is generated by a trigger engine (such as trigger engine  of ). As previously described, a trigger engine can receive a trigger haptic effect definition and can modify the trigger haptic effect definition based on a position and\/or range of a trigger of a controller. Thus, effect properties  can display a visualization of the trigger, including an actual position of the trigger. Further, effect properties  can display a position and\/or range of the trigger that is defined for a trigger haptic effect definition, where the position and\/or range can cause the trigger engine to modify the trigger haptic effect definition. A user can edit the position and\/or range of the trigger that is defined for the trigger haptic effect definition. Further, effect properties  can display a list of triggers for a controller, so the user can edit the trigger that is defined for the trigger haptic effect definition. Even further, effect properties  can display a magnitude (or strength) of the trigger haptic effect definition, and a user can modify the magnitude (or strength).","User interface  further includes spatialization . Spatialization  is an editable visual area that can visualize a haptic effect that is originally generated and further modified by a spatialization engine (such as spatialization engine  of ). As previously described, the spatialization engine can modify the haptic effect definition so that a haptic effect is scaled for one or more targeted motors, targeted actuators, rumble motors, or rumble actuators, of a controller. Thus, spatialization  can display a visualization of the controller. Spatialization  can further display a visualization of the haptic effect experienced at each targeted motor, targeted actuator, rumble motor, or rumble actuator of the controller. A user can edit a scaling of the haptic effect that is experienced at each targeted motor, targeted actuator, rumble motor, or rumble actuator of the controller, as well as edit a scaling of a source of the haptic effect.",{"@attributes":{"id":"p-0132","num":"0131"},"figref":"FIG. 21","b":["2100","2100","3","8","2100"]},{"@attributes":{"id":"p-0133","num":"0132"},"figref":["FIG. 22","FIG. 1"],"b":["10","2200","2200","2210","2220","2230"]},"User interface  includes plotter . Plotter  takes a haptic effect definition specified by a user as input, and sends the haptic data includes within the haptic effect definition through adapter layer  to trigger API layer . Trigger API layer  sends back individual channel data that plotter  displays within user interface . Render  takes input from controller GUI  and starts a haptic player render loop. The input is routed through adapter layer , which has callbacks setup with trigger API layer  to and relay controller input  (such as button and trigger input) sent from controller . Adapter layer  can also communicate with plotter  while the render loop is running to update user interface . Controller GUI  can also select controller  using controller selector , and can show what is connected. Controller GUI  can also set up a trigger activation point. Further, importer\/exporter  can take input audio files and convert them to a haptic file. In one embodiment, an audio file is a WAV file. Further, adapter layer  can be embedded within user interface , or can be a separate library. When adapter layer  is a separate library, adapter layer  can be a separate C++ library.",{"@attributes":{"id":"p-0135","num":"0134"},"figref":["FIG. 23","FIG. 1","FIG. 23"],"b":["10","2300","2300","2300","2300","2301","2301"]},"The system further includes haptic engine . Haptic engine  is a high-level API that can utilize a low level API to perform the playing of a haptic effect, and to add haptic effects to game application . Haptic engine  can load, start, stop, and render a haptic effect. Haptic engine  can interface with haptic effect parser  to parse\/get information about a haptic effect. Haptic engine  can further interface with haptic mixer  to start or stop an effect and modify a mixer buffer. Haptic engine  can further interface with haptic device handler  to get a device handle of, and render haptic effects on, a controller, gamepad, or other peripheral device.","The system further includes haptic effect parser . Haptic effect parser  includes an API that can load a haptic effect in memory, verify its format, and obtain information about the haptic effect, such as size, duration, and haptic data. The system further includes haptic mixer . Haptic mixer  supports playback of multiple haptic effects at the same time. The system further includes haptic device handler . Haptic device handler  can initiate and manage communication with a controller, gamepad, or other peripheral device. Haptic device handler  can interface with a Universal Serial Bus (\u201cUSB\u201d) communication layer and obtain a device handle of the controller, gamepad, or other peripheral device. Haptic device handler  can further initialize several state machine structures critical for haptic effect playback.","The system further includes trigger haptic report handler . Trigger haptic report handler  can package haptic data into USB HID packets according to a trigger communication protocol. The system further includes platform compliant USB HID library . Platform compliant USB HID library  includes one or more computer-readable routines to interface with USB HID and Bluetooth HID class of controllers, gamepads, or other peripheral devices. The system further includes peripheral firmware  (identified in  as \u201cgamepad firmware \u201d). Peripheral firmware  is firmware for a controller, gamepad, or other peripheral device. The system further includes peripheral input reader  (identified in  as \u201cgamepad input reader \u201d). Peripheral input reader  receives peripheral input that is sent by the controller, gamepad, or other peripheral device. Peripheral input reader  further interprets the peripheral input and sends the peripheral input to game application .",{"@attributes":{"id":"p-0139","num":"0138"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0140","num":"0139"},"figref":["FIG. 24","FIG. 24","FIG. 24"],"b":["2400","2400","2400","2400","2405","2405","2400","2405","2405","2405"]},{"@attributes":{"id":"p-0141","num":"0140"},"figref":["FIG. 24","FIG. 24","FIG. 24"],"b":["2410","2410","2415","2415","2415","2420","2420","2420","2435","2425","2410","2415","2420"]},{"@attributes":{"id":"p-0142","num":"0141"},"figref":["FIG. 24","FIG. 24","FIG. 24","FIG. 24","FIG. 24","FIG. 24","FIG. 24"],"b":["2425","2425","2425","2425","2430","2430","2430","2440","2410","2400","2435","2435","2440","2440","2450","2450","2425","2430","2435","2440","2450"]},{"@attributes":{"id":"p-0143","num":"0142"},"figref":["FIG. 24","FIG. 26","FIG. 24"],"b":["2460","2461","2462","2463","2464","2465","2470","2470","2470","2460","2470","2410","2415","2425","2430","2405","2425","2435","2440","2450","2460","2470"]},"In one embodiment, a controller, gamepad, or other peripheral device, can have a customized protocol for conveying haptic data and for driving individual motors or actuators. Accordingly, an audio driver can be provided that receives an audio file that includes a haptic effect authored as an audio effect definition from an audio authoring component, and that sends the audio data included within the audio file to the controller, gamepad, or other peripheral device. In one embodiment, the audio authoring component can be a \u201cPro Tools\u00ae\u201d product by Avid Technology, Inc. The audio driver can get loaded during a boot up process. The audio driver can expose a necessary number of audio channels in order to make haptic effect definitions possible for using all the motors or actuators in the controller, gamepad, or other peripheral device. The audio driver can further work in user space, and can be accessible to all user space audio editing\/playback applications. The audio driver can further read the audio data that an audio authoring component sends to the controller, gamepad, or other peripheral device. The audio driver can further perform necessary processing on the audio data being presented and can convert the audio data into haptic data, such as actuator drive values. The audio driver can further communicate the haptic data to the controller, gamepad, or other peripheral device over a communication interface.","According to the embodiment, a controller, gamepad, or other peripheral device, can include four actuators. Two actuators can be used as trigger actuators influencing haptic feedback on triggers. The trigger actuators can be bi-directional. Two kinds of direction events can happen with the trigger actuators: PUSH and PULL. The PUSH and PULL directions can be relative to a user's finger on the trigger. Two other actuators can be used as rumble actuators influencing general haptic feedback or rumble feedback within the controller, gamepad, or other peripheral device. The rumble actuators can be uni-directional. More specifically, the rumble actuators can spin in either a clockwise direction or a counter-clockwise direction, but not both directions. The direction of the motion can be dependent on the controller and\/or the drive electronics of the controller.","In this embodiment, the following channel layout can be chosen for the audio driver:",{"@attributes":{"id":"p-0147","num":"0146"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Channel Number","Channel Purpose"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"0","Push channel for left trigger"]},{"entry":[{},"1","Pull channel for left trigger"]},{"entry":[{},"2","Push channel for right trigger"]},{"entry":[{},"3","Pull channel for right trigger"]},{"entry":[{},"4","Left rumble"]},{"entry":[{},"5","Right rumble"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"In one embodiment, an audio format chosen for a 16-bit PCM can be 44.1 KHz. The audio driver can receive the audio data from an audio authoring component, convert the audio data into haptic data (e.g., drive values), and communicate the haptic data to the controller accordingly.",{"@attributes":{"id":"p-0149","num":"0148"},"figref":["FIG. 25","FIG. 26"],"b":["2500","2500","2500","2510","2510","2511","2510","2520","2530","2540","2520","2530","2540","2540","2510","2540","2500","5"]},{"@attributes":{"id":"p-0150","num":"0149"},"figref":["FIG. 26","FIG. 26"],"b":["2600","2600","2600","2605","2615","2625","2625","2625"],"br":[{},{}],"in-line-formulae":[{},{},{},{}]},"Subsequently, trigger protocol packet manager  obtains drive values for all the actuators (e.g., all four actuators) and packages the drive values as data packets, such as USB HID packets, according to a trigger communication protocol. Further, XPC handler  receives the data packets from trigger protocol packet manager  and sends the data packets to XPC service , which is a background service. At , XPC service  receives the data packets and, at , sends the data packets to  to a controller  (identified in  as \u201chaptic trigger gamepad \u201d), over a USB interface.",{"@attributes":{"id":"p-0152","num":"0151"},"figref":["FIG. 27","FIG. 1","FIG. 27","FIG. 27","FIG. 1","FIGS. 2","FIG. 5"],"b":["10","2700","2700","2710","2710","2700","2710","2700","2710","2710","30","100","3","4","520"]},"Device  includes effect library , where effect library  can include one or more haptic effect definitions. In the embodiment, these haptic effect definitions can be identified as unspatialized haptic effect definitions, as they are haptic effect definitions that have not been modified by a spatialization engine. Device  further includes game , where game  is a software application, such as a game application, that can be executed on the system. According to the embodiment, game  can generate one or more spatialization parameters, where the one or more spatialization parameters can define a position, distance, velocity, direction, and\/or flow of a haptic effect defined by a haptic effect definition that is stored within effect library .","Device  further includes spatialization engine  (identified in  as \u201chaptic spatialization engine \u201d), where effect library  can send one or more unspatialized haptic effect definitions to spatialization engine , and where game  can send one or more spatialization parameters to spatialization engine . Spatialization engine  can receive the one or more unspatialized haptic effect definitions, and can modify the one or more unspatialized haptic effect definitions based on the one or more spatialization parameters. According to the embodiment, spatialization engine  can modify the one or more unspatialized haptic effect definitions, so that one or more haptic effects are scaled or attenuated for one or more actuators  of controller , where the one or more modified haptic effect definitions can be identified as spatialized haptic effect definitions. In other words, spatialization engine  can modify the haptic effect definition that is sent to each actuator of actuators , and thus, modify the haptic effect that is experienced at each actuator of actuators , in order to convey a sense of position, distance, velocity, direction, and\/or flow of the haptic effect. Spatialization engine  can subsequently send the one or more spatialized haptic effect definitions to controller . Controller  can subsequently send each spatialized haptic effect definition to each actuator of actuators , where each actuator can produce a spatialized haptic effect.",{"@attributes":{"id":"p-0155","num":"0154"},"figref":["FIG. 28","FIG. 1","FIG. 28","FIG. 28","FIG. 1","FIGS. 2","FIG. 5"],"b":["10","2800","2800","2810","2810","2800","2810","2800","2810","2810","30","100","3","4","520"]},"Device  includes effect library , where effect library  can include one or more haptic effect definitions, identified as unspatialized haptic effect definitions. Device  further includes game , where game  is a software application, such as a game application, that can be executed on the system. According to the embodiment, game  can generate one or more spatialization parameters, where the one or more spatialization parameters can define a position, distance, velocity, flow, and\/or direction of a haptic effect defined by a haptic effect definition that is stored within effect library .","Controller  includes spatialization engine  (identified in  as \u201chaptic spatialization engine \u201d), where effect library  can send one or more unspatialized haptic effect definitions to spatialization engine , and where game  can send one or more spatialization parameters to spatialization engine . Spatialization engine  can receive the one or more unspatialized haptic effect definitions, and can modify the one or more unspatialized haptic effect definitions based on the one or more spatialization parameters, where the one or more modified haptic effect definitions are identified as spatialized haptic effect definitions. Spatialization engine  can subsequently send each spatialized haptic effect definition to each actuator of actuators , where each actuator can produce a spatialized haptic effect.",{"@attributes":{"id":"p-0158","num":"0157"},"figref":"FIG. 29","b":["2900","2900","2900","2900"]},{"@attributes":{"id":"p-0159","num":"0158"},"figref":"FIG. 30","b":["3000","3000","3000"]},{"@attributes":{"id":"p-0160","num":"0159"},"figref":"FIG. 31","b":["3100","3100","3100"]},{"@attributes":{"id":"p-0161","num":"0160"},"figref":"FIG. 32","b":["3200","3200","3200"]},{"@attributes":{"id":"p-0162","num":"0161"},"figref":"FIG. 33","b":["3300","3300","3300"]},{"@attributes":{"id":"p-0163","num":"0162"},"figref":"FIG. 34","b":["3400","3400","3400"]},{"@attributes":{"id":"p-0164","num":"0163"},"figref":"FIG. 35","b":["3500","3500","3500"]},{"@attributes":{"id":"p-0165","num":"0164"},"figref":"FIG. 36","b":["3600","3600","3600"]},{"@attributes":{"id":"p-0166","num":"0165"},"figref":"FIG. 37","b":["3700","3700","3700"]},{"@attributes":{"id":"p-0167","num":"0166"},"figref":"FIG. 38","b":["3800","3800","3800"]},{"@attributes":{"id":"p-0168","num":"0167"},"figref":"FIG. 39","b":["3900","3900","3800"]},{"@attributes":{"id":"p-0169","num":"0168"},"figref":"FIG. 40","b":["4000","4000","400"]},"Thus, in one embodiment, a location of a haptic effect can be conveyed by playing the haptic effect on only a left trigger, or only on a right trigger, based on a spatialization haptic effect definition. Further, in another embodiment, short-effect (e.g., approximately 50-200 ms) movement can be conveyed by playing the haptic effect on different actuators with small delays (e.g., approximately 50-100 ms), based on a spatialization haptic effect definition. Even further, in another embodiment, long-effect (e.g., approximately greater than 200 ms) movement can be conveyed by inversely ramping the haptic effect on different actuators, based on a spatialization haptic effect definition. Further, in the aforementioned embodiments, an identical haptic effect is played at the different actuators based on a spatialization haptic effect definition. However, in an alternate embodiment, distinct haptic effects can be played at the different actuators based on a spatialization haptic effect definition.","In one embodiment, a distance of a spatialization haptic effect can be conveyed by a spatialization engine using: (1) attenuation; (2) \u201cspreading\u201d or \u201cscattering\u201d; and\/or (3) timing. Regarding attenuation, a spatialization haptic effect definition can define different haptic attenuation characteristics depending on a number of dimensions (e.g., one dimension, two dimensions, or three dimensions) in which the haptic effect travels. For example, a haptic effect that travels through a rail or rod can travel through one dimension. As another example, a haptic effect that travels through a floor or a table can travel through two dimensions. As another example, a haptic effect that travels through the ground can travel through three dimensions. Further, different frequencies of a haptic effect can attenuate differently. For example, higher frequencies can attenuate more rapidly. Regarding \u201cspreading\u201d or \u201cscattering,\u201d a haptic effect can be diminished over distance due to the magnitude, or strength, of the haptic effect dissipating over multiple dimensions, where the reduction of magnitude may be frequency-dependent. A spatialization engine can mix a window of previous force values to diminish the haptic effect. A window size may depend on a distance of a haptic effect. Regarding timing, a haptic effect that is a vibrotactile haptic effect that travels through solid media (e.g., ground) can travel faster than sound through air. For example, a distant explosion within a game can be felt as a vibration within the peripheral device before the audio of the explosion is heard.","An attenuation of a spatialization haptic effect is now described in greater detail. In accordance with an embodiment, a haptic effect can have a position within a gaming application or other type of software application. The position of the haptic effect can be an absolute position, where a user of a peripheral device can also have a position within the gaming application or other type of software application. Alternatively, the position of the haptic effect can be a relative position, where the position of the haptic effect is relative to a position of a user of a peripheral device within the gaming application or other type of software application. Further, a haptic effect can lose magnitude, or strength, over a distance because the haptic effect can be \u201cabsorbed\u201d by other objects or surfaces within the gaming application or other type of software application. Further, a haptic effect can also attenuate due to \u201cspreading\u201d or \u201cscattering.\u201d Examples of such haptic effects can include: explosions; footsteps; stampedes; distance heavy rolling vehicles (e.g., trains, buses, trucks, tanks); distant traffic; indirect crashes; or general indirect impacts.","In one embodiment, the attenuation of a haptic effect can be one-dimensional. In one-dimensional attenuation of a haptic effect, there is no \u201cspreading\u201d or \u201cscattering.\u201d A haptic effect can lose a certain fraction of magnitude, or strength, per unit distance due to absorption based on the following formula:\n\n\n\nwhere \u201cy\u201d is an attenuated magnitude, or strength, of a haptic effect; \u201cx\u201d is an original (i.e., un-attenuated) magnitude, or strength, of the haptic effect; \u201cF\u201d is an absorption factor over a reference absorption distance (i.e., a haptic effect attenuates by 1\/F over a reference absorption distance); \u201cr\u201d is a distance over which the haptic effect travels; and \u201cD\u201d is a reference absorption distance.\n","Examples of one-dimension attenuation of a haptic effect can include: a vibrotactile haptic effect from a large and wide underground source; or a haptic effect traveling through a rail or rod.","In another embodiment, the attenuation of a haptic effect can be two-dimensional. In two-dimensional attenuation of a haptic effect, there is additional attenuation as compared to one-dimensional attenuation due to the magnitude, or strength, of the haptic effect \u201cspreading\u201d or \u201cscattering\u201d within two dimensions. A haptic effect can lose a certain fraction of magnitude, or strength, per unit distance due to absorption and spreading based on the following formula:",{"@attributes":{"id":"p-0176","num":"0175"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"y","mo":"=","mrow":{"mo":"{","mtable":{"mtr":[{"mtd":[{"mi":"x"},{"mrow":{"mrow":{"mi":["if","r"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},"mo":"\u2264","mi":"R"}}]},{"mtd":[{"mrow":{"msup":{"mi":"xF","mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","r"],"mo":"-"}},"mo":"\/","mi":"D"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":["R","r"]}}}},{"mrow":{"mrow":{"mi":["if","r"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},"mo":">","mi":"R"}}]}]}}}}},"br":{}},"Examples of two-dimension attenuation of a haptic effect can include: a haptic effect traveling across a floor or a table; a vibrotactile haptic effect originating from highway traffic, a passing train, a convey, a stampede, or from some other long ground-level source; or a vibrotactile haptic effect from a long and narrow underground source.","In another embodiment, the attenuation of a haptic effect can be three-dimensional. In three-dimensional attenuation of a haptic effect, there is additional attenuation as compared to two-dimensional attenuation due to the magnitude, or strength, of the haptic effect \u201cspreading\u201d or \u201cscattering\u201d within three dimensions. A haptic effect can lose a certain fraction of magnitude, or strength, per unit distance due to absorption and spreading based on the following formula:",{"@attributes":{"id":"p-0179","num":"0178"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"y","mo":"=","mrow":{"mo":"{","mtable":{"mtr":[{"mtd":[{"mi":"x"},{"mrow":{"mrow":{"mi":["if","r"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},"mo":"\u2264","mi":"R"}}]},{"mtd":[{"msup":{"mrow":{"msup":{"mi":"xF","mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","r"],"mo":"-"}},"mo":"\/","mi":"D"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":["R","r"]}}},"mn":"2"}},{"mrow":{"mrow":{"mi":["if","r"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},"mo":">","mi":"R"}}]}]}}}}},"br":{}},"An example of a three-dimensional attenuation of a haptic effect includes a haptic effect traveling through a ground from a small source (e.g., point).","According to an embodiment, general attenuation can be represented using the following formula:",{"@attributes":{"id":"p-0182","num":"0181"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"y","mo":"=","mrow":{"mo":"{","mtable":{"mtr":[{"mtd":[{"mi":"x"},{"mrow":{"mrow":{"mi":["if","r"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},"mo":"\u2264","mi":"R"}}]},{"mtd":[{"msup":{"mrow":{"msup":{"mi":"xF","mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","r"],"mo":"-"}},"mo":"\/","mi":"D"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":["R","r"]}}},"mi":"P"}},{"mrow":{"mrow":{"mi":["if","r"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},"mo":">","mi":"R"}}]}]}}}}},"br":{}},"A flow of a spatialization haptic effect is now described in greater detail. In accordance with an embodiment, a spatialization haptic effect can have a velocity (i.e., a speed and direction). The velocity of the spatialization haptic effect can be identified as a \u201cflow.\u201d In one embodiment, an overall haptic effect can be generated, where the haptic effect includes multiple haptic effect components, where each haptic effect component corresponds to an actuator of multiple actuators for a peripheral device. Each haptic effect component can be played by each actuator to generate the overall haptic effect, where the overall haptic effect conveys a \u201cflow.\u201d One example of a spatialization haptic effect is a \u201cwhizzing\u201d haptic effect, which is a haptic effect that moves from one set of actuators to another. Examples of whizzing haptic effects can include: a nearby passing vehicle; a nearby whizzing bullet; a general nearby passing object. Another example of a spatialization haptic effect is a \u201cbouncing\u201d haptic effect, which is a haptic effect that bounces repeatedly between two sets of actuators. Examples of bouncing haptic effects can include: a magic spell buildup; or an energy buildup. Yet another example of a spatialization haptic effect is a \u201cspinning\u201d haptic effect, which is a haptic effect that spins clockwise or counter-clockwise within a controller, gamepad, or other peripheral device, or around a user within a game. Examples of spinning haptic effects can include: a magic spell buildup; an energy buildup; a \u201cspin-o-rama\u201d; or a vortex.",{"@attributes":{"id":"p-0184","num":"0183"},"figref":"FIG. 41","b":["4100","4100"]},{"@attributes":{"id":"p-0185","num":"0184"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"delay","mo":"=","mfrac":{"mi":["delay_factor","speed"]}}}}},"In accordance with an embodiment, a spatialization haptic effect can have a direction. A direction can determine which actuators to use to generate the spatialization haptic effect.",{"@attributes":{"id":"p-0187","num":"0186"},"figref":"FIG. 42","b":["4200","4200","4200","4200","4200","4200","4200","4200","4200","4200","4200","4200","4200","4200","4200","4200"]},"Further, in one embodiment, a spatialization engine can target spatialization haptic effects at a left trigger actuator or a right trigger actuator at run-time. Examples of such spatialization haptic effects include experiencing left or right rumble strips in a racing game; or experiencing a left punch or a right punch in a boxing game.",{"@attributes":{"id":"p-0189","num":"0188"},"figref":["FIG. 43","FIG. 1","FIG. 43"],"b":"16"},"The flow begins and proceeds to . At , a haptic effect definition is received. The haptic effect definition includes haptic data. The flow then proceeds to .","At , spatialization data is received. The spatialization data can include one or more spatialization parameters. The one or more spatialization parameters can include at least one of: a position of a haptic effect; a distance of the haptic effect; a velocity of the haptic effect; a direction of the haptic effect; or a flow of the haptic effect. The flow then proceeds to .","At , the haptic effect definition is modified based on the received spatialization data. In certain embodiments, the haptic effect definition can be divided into one or more haptic effect definition components. In some of these embodiments, at least one of the following can be scaled or attenuated based on the spatialization data: a magnitude of the haptic data of at least one haptic effect definition component; a frequency of the haptic data of at least one haptic effect definition component; or a duration of the haptic effect data of the at least one haptic effect definition component. In other embodiments, at least one haptic output device can be caused to delay a playback of at least one haptic effect based on the spatialization data. In certain embodiments, the one or more haptic effect definition components can be distinct. In other embodiments, the one or more haptic effect definition components can be identical. In certain embodiments, a motion, change in position, or change in orientation of the peripheral device can be detected, the spatialization data can be modified based on the detected motion, and the modified haptic effect definition can be subsequently modified based on the modified spatialization data. The flow then proceeds to .","At , a haptic instruction and the modified haptic effect definition are sent to a peripheral device. In certain embodiments, the one or more haptic effect definition components can also be sent to the peripheral device. In certain embodiments, the peripheral device can be a controller or gamepad. In embodiments where the modified haptic effect definition is subsequently modified, the subsequently modified haptic effect definition can be sent to the peripheral device. The flow then proceeds to .","At , the haptic instruction causes one or more haptic output devices to produce one or more haptic effects based on the modified haptic effect definition at the peripheral device. In certain embodiments, the haptic instruction can cause the one or more haptic output device to produce one or more haptic effects based on the one or more haptic effect definition components. Further, in certain embodiments, the haptic instruction can cause the one or more haptic output device to produce the one or more haptic effects at one or more user input elements of the peripheral device. In certain embodiments, at least one user input element can be one of: a digital button; an analog button; a bumper; a directional pad; an analog or digital stick; a driving wheel; or a trigger. Further, in certain embodiments, at least one haptic output device can be an actuator. In embodiments where the modified haptic effect definition is subsequently modified, the haptic instruction causes the one or more haptic output devices to produce one or more modified haptic effects based on the subsequently modified haptic effect definition at the peripheral device","In certain embodiments, the haptic instruction can cause a plurality of actuators to output the one or more haptic effects at multiple distinct attenuations based on the modified haptic effect definition. In other embodiments, the haptic instruction can cause a plurality of actuators to output the one or more haptic effects by inversely ramping attenuation based on the modified haptic effect definition. In other embodiments, the haptic instruction can cause a plurality of rumble actuators and targeted actuators to output the one or more haptic effects by inversely ramping attenuation from a rumble actuator to a targeted actuator based on the modified haptic effect definition. In other embodiments, the haptic instruction can cause a plurality of rumble actuators and targeted actuators to output the one or more haptic effects by inversely ramping attenuation from a targeted actuator to a rumble actuator based on the modified haptic effect definition. In other embodiments, the haptic instruction can cause a plurality of actuators to output the one or more haptic effects with a delay based on the modified haptic effect definition. In other embodiments, the haptic instruction can cause a plurality of rumble actuators and trigger actuators to output the one or more haptic effects with a delay from a rumble actuator to a targeted actuator based on the modified haptic effect definition. In other embodiments, the haptic instruction can cause a plurality of rumble actuators and trigger actuators to output the one or more haptic effects with a delay from a targeted actuator to a rumble actuator based on the modified haptic effect definition. In other embodiments, the haptic instruction can cause a plurality of actuators to output the one or more haptic effects with a delay in a clockwise or counter-clockwise order based on the modified haptic effect definition. The flow then ends.","Thus, in one embodiment, a system can provide spatialization haptic effects that are experienced at a peripheral device, such as a controller or gamepad. By generating a spatialization haptic effect, the system can generate a haptic effect that can be either scaled or delayed at each motor or actuator of the peripheral device, so that the spatialization haptic effect includes a sense of distance, directionality and\/or flow. By incorporating spatialized haptic feedback experienced at a peripheral device, and in particular, spatialized haptic feedback experienced at a user input element of the peripheral device, such as a trigger, into a gaming application that is executed by the system, a more realistic and immersive gaming experience can be provided.","The features, structures, or characteristics of the invention described throughout this specification may be combined in any suitable manner in one or more embodiments. For example, the usage of \u201cone embodiment,\u201d \u201csome embodiments,\u201d \u201ccertain embodiment,\u201d \u201ccertain embodiments,\u201d or other similar language, throughout this specification refers to the fact that a particular feature, structure, or characteristic described in connection with the embodiment may be included in at least one embodiment of the present invention. Thus, appearances of the phrases \u201cone embodiment,\u201d \u201csome embodiments,\u201d \u201ca certain embodiment,\u201d \u201ccertain embodiments,\u201d or other similar language, throughout this specification do not necessarily all refer to the same group of embodiments, and the described features, structures, or characteristics may be combined in any suitable manner in one or more embodiments.","One having ordinary skill in the art will readily understand that the invention as discussed above may be practiced with steps in a different order, and\/or with elements in configurations which are different than those which are disclosed. Therefore, although the invention has been described based upon these preferred embodiments, it would be apparent to those of skill in the art that certain modifications, variations, and alternative constructions would be apparent, while remaining within the spirit and scope of the invention. In order to determine the metes and bounds of the invention, therefore, reference should be made to the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Further embodiments, details, advantages, and modifications will become apparent from the following detailed description of the preferred embodiments, which is to be taken in conjunction with the accompanying drawings.",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 31"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 37"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 38"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 39"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 40"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 41"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 42"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 43"}]},"DETDESC":[{},{}]}
