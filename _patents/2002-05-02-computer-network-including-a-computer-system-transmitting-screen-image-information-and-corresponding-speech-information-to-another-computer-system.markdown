---
title: Computer network including a computer system transmitting screen image information and corresponding speech information to another computer system
abstract: A described computer network includes a first computer system and a second computer system. The first computer system transmits screen image information and corresponding speech information to the second computer system. The screen image information includes information corresponding to a screen image intended for display within the first computer system. The speech information conveys a verbal description of the screen image. When the screen image includes one or more objects (e.g., menus, dialog boxes, icons, and the like) having corresponding semantic information, the speech information includes the corresponding semantic information. The second computer system responds to the speech information by producing an output (e.g., human speech via an audio output device, a tactile output via a Braille output device, and the like). The semantic information conveyed by the output allows a visually-impaired user of the second computer system to know intended purposes of the objects. The second computer system may also receive user input, generate an input signal corresponding to the user input, and transmit the input signal to the first computer system. The first computer system may respond to the input signal by updating the screen image. The semantic information conveyed by the output enables the visually-impaired user to properly interact with the first computer system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07103551&OS=07103551&RS=07103551
owner: International Business Machines Corporation
number: 07103551
owner_city: Armonk
owner_country: US
publication_date: 20020502
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF SPECIFIC EMBODIMENTS"],"p":["1. Field of the Invention","This invention relates generally to computer networks, and, more particularly, to computer networks including multiple computer systems, wherein one of the computer systems sends screen image information to another one of the computer systems.","2. Description of the Related Art","The United States government has enacted legislation that requires all information technology purchased by the government to be accessible to the disabled. The legislation establishes certain standards for accessible Web content, accessible user agents (i.e., Web browsers), and accessible applications running on client desktop computers. Web content, Web browsers, and client applications developed according to these standards are enabled to work with assistive technologies, such as screen reading programs (i.e., screen readers) used by visually impaired users.","There is one class of applications, however, for which there is currently no accessible solution for visually impaired users. This class includes applications that allow computer system users (i.e., users of client computer systems, or \u201cclients\u201d) to share a remote desktop running on another user's computer (e.g., on a server computer system, or \u201cserver\u201d). At least some of these applications allow a user of a client to control an input device (e.g., a keyboard or mouse) of the server, and display the updated desktop on the client. Examples of these types of application include Lotus\u00ae Sametime\u00ae, Microsoft\u00ae NetMeeting\u00ae, Microsoft\u00ae Terminal Service, and Symantec\u00ae PCAnywhere\u00ae on Windows\u00ae platforms, and the Distributed Console Access Facility (DCAF) on OS\/2\u00ae platforms. In these applications, bitmap images (i.e., bitmaps) of the server display screen are sent to the client for rerendering. Keyboard and mouse inputs (i.e., events) are sent from the client to the server to simulate the client user interacting with the server desktop.","An accessibility problem arises in the above described class of applications in that the application resides on the server machine, and only an image of the server display screen is displayed on the client. As a result, there is no semantic information at the client about the objects within the screen image being displayed. For example, if an application window being shared has a menu bar, a sighted user of the client will see the menu, and understand that he or she can select items in the menu. On the other hand, a visually impaired user of the client typically depends on a screen reader to interpret the screen, verbally describe that there is a menu bar (i.e., menu) displayed, and then verbally describe (i.e., read) the choices on the menu.","With no semantic information available at the client, a screen reader running on the client will only know that there is an image displayed. The screen reader will not know that there is a menu inside the image and, therefore, will not be able to convey that significance or meaning to the visually-impaired user of the client.","Current attempts to solve this problem have included use of optical character recognition (OCR) technology to extract text from the image, and create an off-screen model for processing by a screen reader. These methods are inadequate because they do not provide semantic information, are prone to error, and are difficult to translate.","A computer network is described including a first computer system and a second computer system. The first computer system transmits screen image information and corresponding speech information to the second computer system. The screen image information includes information corresponding to a screen image intended for display within the first computer system. The speech information conveys a verbal description of the screen image, and, when the screen image includes one or more objects (e.g., menus, dialog boxes, icons, and the like) having corresponding semantic information, the speech information includes the corresponding semantic information.","The second computer system may receive the speech information, and respond to the received speech information by producing an output (e.g., human speech via an audio output device, a tactile output via a Braille output device, and the like). When the screen image includes an object having corresponding semantic information, the output conveys the semantic information. The semantic information conveyed by the output allows a visually-impaired user of the second computer system to know intended purposes of the one or more objects in the screen image.","The second computer system may also receive user input, generate an input signal corresponding to the user input, and transmit the input signal to the first computer system. In response to the input signal, the first computer system may update the screen image. Where the user of the second computer system is visually impaired, the semantic information conveyed by the output enables the visually-impaired user to properly interact with the first computer system.","Illustrative embodiments of the invention are described below. In the interest of clarity, not all features of an actual implementation are described in this specification. It will, of course, be appreciated that in the development of any such actual embodiment, numerous implementation-specific decisions must be made to achieve the developers' specific goals, such as compliance with system-related and business-related constraints, which will vary from one implementation to another. Moreover, it will be appreciated that such a development effort might be complex and time-consuming, but would nevertheless be a routine undertaking for those of ordinary skill in the art having the benefit of this disclosure.",{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1","b":["100","102","104","104","106","104","104","102","106"]},"As will become evident, the computer network  requires only 2 computer systems to operate as described below: the server , and one of the clients, either the client A or client B. Thus, in general, the computer network  includes 2 or more computer systems.","As indicated in , the server  provides screen image information and corresponding speech information to the client A, and receives input signals and responses from the client A. In general, the server  may provide screen image information and corresponding speech information to any client, or all clients, of the computer network , and receive input signals from any one of the clients.","In general, the screen image information is information regarding a screen image generated within the server , and intended for display within the server  (e.g., on a display screen of a display system of the server ). The corresponding speech information conveys a verbal description of the screen image. The speech information may include, for example, general information about the screen image, and also any objects within the screen image. Common objects, or display elements, include menus, boxes (e.g., dialog boxes, list boxes, combination boxes, and the like), icons, text, tables, spreadsheets, Web documents, Web page plugins, scroll bars, buttons, scroll panes, title bars, frames split bars, tool bars, and status bars. An \u201cicon\u201d is a picture or image that represents a resource, such as a file, device, or software program. General information about the screen image, and also any objects within the screen image, may include, for example, colors, shapes, and sizes.","More importantly, the speech information also includes semantic information corresponding to objects within the screen image. As will be described in detail below, this semantic information about the objects allows a visually-impaired user of the client A to interact with the objects in a proper, meaningful, and expected way.","In general, the server  and the clients A\u2013B communicate via signals, and the communication medium  provides means for conveying the signals. The server  and the clients A\u2013B may each include hardware and\/or software for transmitting and receiving the signals. For example, the server  and the clients A\u2013B may communicate via electrical signals. In this case, the communication medium  may include one or more electrical cables for conveying the electrical signals. The server  and the clients A\u2013B may each include a network interface card (NIC) for generating the electrical signals, driving the electrical signals on the one or more electrical cables, and receiving electrical signals from the one or more electrical cables. The server  and the clients A\u2013B may also communicate via optical signals, and communication medium  may include optical cables. The server  and the clients A\u2013B may also communicate via electromagnetic signals (e.g., radio waves), and communication medium  may include air.","It is noted that communication medium  may, for example, include the Internet, and various means for connecting to the Internet. In this case, the clients A\u2013B and the server  may each include a modem (e.g., telephone system modem, cable television modem, satellite modem, and the like). Alternately, or in addition, communication medium  may include the public switched telephone network (PSTN), and clients A\u2013B and the server  may each include a telephone system modem.","In the embodiment of , the computer network  is a client-server computer network wherein the clients A\u2013B rely on the server  for various resources, such as files, devices, and\/or processing power. It is noted, however, that in other embodiments, the computer network  may be a peer-to-peer network. In a peer-to-peer network embodiment, the server  may be viewed as a \u201cmaster\u201d computer system by virtue of generating the image information and the speech information, providing the screen image information and the speech information to one or more of the clients A\u2013B, and receiving input signals and\/or responses from the one or more of the clients A\u2013B. In receiving the screen image information and the speech information from the server , and providing input signals and\/or responses to the server , the one or more of the clients A\u2013B may be viewed as a \u201cslave\u201d computer system. It is noted that in a peer-to-peer network embodiment, any one of the computer systems of the computer network  may be the master computer system, and one or more of the other computer systems may be slaves.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 2","FIG. 1","FIG. 2","FIG. 1"],"b":["102","104","104","102","102","102","104","104"]},"In the embodiment of , the server  includes a distributed console access application , and the client A includes a distributed console access application . The distributed console access application  receives screen image information generated within the server , and provides the screen image information to the distributed console access application  via a communication path or channel  formed between the server  and the client A. Suitable software embodiments of the distributed console access applications  and the distributed console access application  are known and commercially available.","The screen image information is information regarding a screen image generated within the server , and intended for display to a user of the server . Thus the screen image would expectedly be displayed on a display screen of a display system of the server . The screen image information may include, for example, a bit map representation of the screen image, wherein the screen image is divided into rows and columns of \u201cdots,\u201d and one or more bits are used to represent specific characteristics (e.g., color, shades of gray, and the like) of each of the dots.","In the embodiment of , the distributed console access application  within the client A is coupled to a display system  including a display screen . The distributed console access application  receives the screen image information from the distributed console access application  within the server , and provides the screen image information to the display system . The display system  uses the screen image information to display the screen image on the display screen . For example, the display system  may use the screen image information to generate picture elements (pixels), and display the pixels on the display screen .","It is noted that where the server  includes a display system similar to that of the display system  of the client A, the screen image is expectedly displayed on the display screens of the user  and the client A at substantially the same time. (It is noted that communication delays between the server  and the client A may prevent the screen image from being displayed on the display screens of the user  and the client A at exactly the same time.)","The communication path or channel  is formed through the communication medium  of . It is also noted that where the communication medium  of  includes the Internet, the server  and the client A may, for example, communicate via software communication facilities called sockets. In this situation, a socket of the client A may issue a connect request to a numbered service port of a socket of the server . Once the socket of the client A is connected to the numbered service port of the socket of the server , the client A and the server  may communicate via the sockets by writing data to, and reading data from, the numbered service port.","In the embodiment of , the server  includes an assistive technology application . In general, assistive technology applications are software programs that facilitate access to technology (e.g., computer systems) for visually impaired users. When executed within the server , the assistive technology application  produces the screen image information described above, and provides the screen image information to the distributed console access application .","During execution, the assistive technology application  also produces speech information corresponding to the screen image information. In the embodiment of FIG. , the speech information conveys human speech which verbally describes general attributes (e.g., color, shape, size, and the like) of the screen image and any objects (e.g., menus, dialog boxes, icons, text, and the like) within the screen image, and also includes semantic information conveying the meaning, significance, or intended purpose of each of the objects within the screen image. The speech information may include, for example, text-to-speech (TTS) commands and\/or audio output signals. Suitable assistive technology applications are known and commercially available.","In the embodiment of , the assistive technology application  provides the speech information to a speech application program interface (API) . The speech application program interface (API)  provides a standard means of accessing routines and services within an operating system of the server . Suitable speech application program interfaces (APIs) are known and commonly available.","In the embodiment of , the server  also includes a generic application . As used herein, the term \u201cgeneric application\u201d refers to a software program that produces screen image information, but does not produce corresponding speech information. When executed within the server , the generic application  produces the screen image information described above, and provides the screen image information to the distributed console access application . Suitable generic applications are known and commercially available.","During execution, the generic application  also produces accessibility information, and provides the accessibility information to a screen reader . Further, the screen reader  may monitor the behavior of the generic application , and produce accessibility information dependent upon the behavior of the generic application . In general, a screen reader is a software program that uses screen image information to produce speech information, wherein the speech information includes semantic information of objects (e.g., menus, dialog boxes, icons, and the like) within the screen image. This semantic information allows a visually impaired user to interact with the objects in a proper, meaningful, and expected way. The screen reader  uses the received accessibility information, and the screen image information available within the server , to produce the above described speech information. The screen reader  provides the speech information to the speech application program interface (API) . Suitable screen reading applications (i.e., screen readers) are known and commercially available.","It is noted that the server  need not include both the assistive technology application , and the combination of the generic application  and the screen reader , at the same time. For example, the server  may include the assistive technology application , and may not include the generic application  and the screen reader . Conversely, the server  may include the generic application  and the screen reader , and may not include the assistive technology application . This is supported by the fact that in a typical multi-tasking computer system operating environment, only one software program is actually being executed at any given time.","In the embodiment of , the distributed console access application  of the server  and the distributed console access application  of the client A are configured to cooperate such that the user of the client A is able to interact with the server  as if the user were operating the server  locally. As shown in , the client A includes an input device . The input device  may be for example, a keyboard, a mouse, or a voice recognition system. When the user of the client A activates the input device  (e.g., presses a keyboard key, moves a mouse, or activates a mouse button), the input device  produces one or more input signals (i.e., \u201cinput signals\u201d), and provides the input signals to the distributed console access application . The distributed console access application  transmits the input signals to the distributed console access application  of the server .","The distributed console access application  provides the input signals to either the assistive technology  or the generic application  (e.g., just as if the user activated a similar input device of the server ). In response to the input signals, the assistive technology  or the generic application  typically responds to the input signals by updating the screen image information, and proving the updated screen image information to the distributed console access application  as described above. As a result, a new screen image is typically displayed on the display screen  of the client A.","For example, where the input device  is a mouse used to control the position of a pointer displayed on the display screen  of the display system , the user of the client A may move the mouse to position the pointer over an icon within the displayed screen image. Where the icon represents a software program (e.g., the assistive technology program  or the generic application ), the user of the client A may initiate execution of the software program by activating (i.e., clicking) a button of the mouse. In response, the distributed console access application  of the server  may provide the mouse click input signal to the operating system of the server , and operating system may initiate execution of the software program. During this process, the screen image, displayed on the display screen  of the client A, may be updated to reflect initiation of the software program execution.","In the embodiment of , the speech application program interface (API)  provides the speech information, received from the assistive technology application  and the screen reader  (at different times), and provides the speech information to a speech information transmitter  within the server . The speech information transmitter  transmits the speech information to a speech information receiver  of the client A via a communication path or channel  formed between the server  and the client A, and via the communication medium  of . It is noted that in the embodiment of , the communication path  is separate and independent from the communication path  described above. The speech information receiver  provides the speech information to a text-to-speech (TTS) engine .","As described above, the speech information may include text-to-speech (TTS) commands. In this situation, the text-to-speech (TTS) engine  converts the text-to-speech (TTS) commands to audio output signals, and provides the audio output signals to an audio output device . The audio output device  may include, for example, a sound card and one or more speakers. As described above, the speech information may include also include audio output signals. In this situation, the text-to-speech (TTS) engine  may simply pass the audio output signals to the audio output device .","The speech information transmitter  may also transmit audio information (e.g., beeps) to the speech information receiver  of the client A in addition to the speech information. The text-to-speech (TTS) engine  may simply pass the audio information to the audio output device .","When the user of the client A is visually impaired, the user may not be able to see the screen image displayed on the display screen  of the client A. However, when the audio output device  produces the verbal description of the screen image, the visually-impaired user may hear the description, and understand not only the general appearance of the screen image and any objects within the screen image (e.g., color, shape, size, and the like), but also the meaning, significance, or intended purpose of any objects within the screen image as well (e.g., menus, dialog boxes, icons, and the like). This ability for a visually-impaired user to hear the verbal description of the screen image and to know the meaning, significance, or intended purpose of any objects within the screen image allows the user of the client A to interact with the objects in a proper, meaningful, and expected way.","The various components of the server  typically synchronize their actions via various handshaking signals, referred to generally herein as response signals, or responses. In the embodiment of , the audio output device  may provide responses to the text-to-speech (TTS) engine , and the text-to-speech (TTS) engine  may provide responses to the speech information receiver .","As indicated in , the speech information receiver  within the client A may provide response signals to the speech information transmitter  within the server  via the communication path or channel . The speech information transmitter  may provide response signals to the speech application program interface (API) , and so on.","It is noted that the speech information transmitter  may transmit speech information to, and receive responses from, multiple clients. In this situation, the speech information transmitter  may receive the multiple responses, possibly at different times, and provide a single, unified, representative response to the speech application program interface (API)  (e.g., after the speech information transmitter  receives the last response).","As indicated in , the server  may also include an optional text-to-speech (TTS) engine , and an optional audio output device . The speech information transmitter  may provide speech information to the optional text-to-speech (TTS) engine , and the optional text-to-speech (TTS) engine  and audio output device  may operate similarly to the text-to-speech (TTS) engine  and the audio output device , respectively, of the client A. The speech information transmitter  may receive a response from the optional text-to-speech (TTS) engine , as well as from multiple clients. As described above, the speech information transmitter  may receive the multiple responses, possibly at different times, and provide a single, unified, representative response to the response to the speech application program interface (API)  (e.g., after the speech information transmitter  receives the last response).","It is noted that the speech information transmitter  and\/or the speech information receiver  may be embodied within hardware and\/or software. A carrier medium  may be used to convey software of the speech information transmitter  to the server . For example, the server  may include a disk drive for receiving removable disks (e.g., a floppy disk drive, a compact disk read only memory or CD-ROM drive, and the like), and the carrier medium  may be a disk (e.g., a floppy disk, a CD-ROM disk, and the like) embodying software (e.g., computer program code) for receiving the speech information corresponding to the screen image information, and transmitting the speech information to the client A.","Similarly, a carrier medium  may be used to convey software of the speech information receiver  to the client A. For example, the client A may include a disk drive for receiving removable disks (e.g., a floppy disk drive, a compact disk read only memory or CD-ROM drive, and the like), and the carrier medium  may be a disk (e.g., a floppy disk, a CD-ROM disk, and the like) embodying software (e.g., computer program code) for receiving the speech information corresponding to the screen image information from the server , and providing the speech information to an output device of the client A (e.g., the audio output device  via the TTS engine ).","In the embodiment of , the server  is configured to the transmit screen image information, and the corresponding speech information, to the client A. It is noted that there need not be any fixed timing relationship between the transmission and\/or reception of the speech information and the screen image information. In other words, the transmission and\/or reception of the speech information and the screen image information need not be synchronized in any way.","Further, the server  may send speech information to the client A without updating the screen image displayed on the display screen  of the client A (i.e., without sending corresponding screen image information). For example, where the input device  of the client A is a keyboard, the user of the client A may enter a key sequence via the input device  that forms a command to the screen reader  in the server  to \u201cread the whole screen.\u201d In this situation, the key sequence input signals may be transmitted to the server , and passed to the screen reader  in the server . The screen reader  may respond to the command to \u201cread the whole screen\u201d by producing speech information indicative of the contents of the current screen image. As a result, the speech information indicative of the contents of the current screen image may be passed to the client A, and the audio output device  of the client A may produce a verbal description of the contents of the current screen image. During this process, the screen image, displayed on the display screen  of the client A, expectedly does not change, and no new screen image information is transferred from the server  to the client A. In this situation, the screen image transmitting process is not involved.",{"@attributes":{"id":"p-0054","num":"0053"},"figref":["FIG. 3","FIG. 2","FIG. 1","FIG. 3","FIG. 2","FIG. 2","FIG. 2","FIG. 2","FIG. 2","FIG. 2"],"b":["102","104","102","104","100","102","104","220","208","210","212","216","218","214"]},"In the peer-to-peer embodiment, any one the computer systems of the computers network  may generate and provide the screen image information and the speech information to one or more of the other computer systems, and receive input signals and\/or responses from the one or more of the other computer systems, and thus be viewed as the master computer system as described above. In this situation, the one or more of the other computer systems are considered slave computer systems.","In the embodiment of , the distributed console access application  of the server  is replaced by a distributed console access application , and the distributed console access application  of the client A is replaced by a distributed console access application . The distributed console access application  of the server  and the distributed console access application  of the client A are identical, and separately configurable to transmit or receive screen image information and input signals as described above. In place of the speech information transmitter  of , the server  includes a speech information transceiver . In place of the speech information receiver , the client A includes a speech information transceiver . The speech information transceiver  and the speech information transceiver  are identical, and separately configurable to transmit or receive speech information and responses as described above. It is noted that in , the server  includes the optional text-to-speech (TTS) engine and the optional audio output device  of .",{"@attributes":{"id":"p-0057","num":"0056"},"figref":["FIG. 4","FIG. 2","FIG. 2","FIG. 4"],"b":["102","104","228","400","230","402","400","402"]},"When the Braille output device  produces the Braille characters, the visually-impaired user of the client A may understand not only the general appearance of the screen image and any objects within the screen image (e.g., color, shape, size, and the like), but also the meaning, significance, or intended purpose of any objects within the screen image as well (e.g., menus, dialog boxes, icons, and the like). This ability allows the visually-impaired user to interact with the objects in a proper, meaningful, and expected way.","The particular embodiments disclosed above are illustrative only, as the invention may be modified and practiced in different but equivalent manners apparent to those skilled in the art having the benefit of the teachings herein. Furthermore, no limitations are intended to the details of construction or design herein shown, other than as described in the claims below. It is therefore evident that the particular embodiments disclosed above may be altered or modified and all such variations are considered within the scope and spirit of the invention. Accordingly, the protection sought herein is as set forth in the claims below."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The invention may be understood by reference to the following description taken in conjunction with the accompanying drawings, in which like reference numerals identify similar elements, and in which:",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 3","FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 4","FIG. 2"]}]},"DETDESC":[{},{}]}
