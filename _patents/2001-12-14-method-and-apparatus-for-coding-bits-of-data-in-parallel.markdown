---
title: Method and apparatus for coding bits of data in parallel
abstract: A method and apparatus for encoding multiple bits in parallel wherein outputs are generated recursively. During each clock cycle, the encoder processes multiple bits and generates outputs consistent with those generated sequentially over multiple clock cycles in a conventional convolutional encoder. In one embodiment, input data is stored in multiple memory storage units, which are then each uniquely addressed to provide data to parallel encoders.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06954885&OS=06954885&RS=06954885
owner: Qualcomm Incorporated
number: 06954885
owner_city: San Diego
owner_country: US
publication_date: 20011214
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["REFERENCE TO CO-PENDING APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF VARIOUS EMBODIMENTS"],"p":["The present Application for Patent is related to U.S. patent application Ser. No. 09\/957,820, entitled \u201cMethod and Apparatus for Coding Bits of Data in Parallel,\u201d filed on Sep. 20, 2001, now U.S. Pat. No. 6,701,482, issued Mar. 2, 2004 to Salvi et al., assigned to the assignee hereof, and hereby expressly incorporated by reference.","1. Field of the Invention","The present invention relates to data communications. More particularly, the present invention relates to coding multiple bits of data in parallel (e.g., using a multiple-port memory) to significantly reduce delays associated with coding.","2. Description of the Related Art","In a typical digital communications system, data is processed, modulated, and conditioned at a transmitter unit to generate a modulated signal that is then transmitted to one or more receiver units. The data processing may include, for example, formatting the data into a particular frame format, coding the formatted data with a particular coding scheme to provide error detection and\/or correction at the receiver units, channelizing (i.e., covering) the coded data, and spreading the channelized data over the system bandwidth. The data processing is typically defined by the system or standard being implemented.","At the receiver unit, the transmitted signal is received, conditioned, demodulated, and digitally processed to recover the transmitted data. The processing at the receiver unit is complementary to that performed at the transmitter unit and may include, for example, despreading the received samples, decovering the despread samples, and decoding the decovered symbols to recover the transmitted data.","The ability to correct transmission errors enhances the reliability of a data transmission. Many digital communications systems employ a convolutional code or a Turbo code to provide error correction capability at the receiver units. Convolutional codes operate on serial data, one or a few bits at a time. There are a variety of useful convolutional codes, and a variety of algorithms for decoding the received coded information sequences to recover the original data. Turbo coding specifically is a parallel-concatenated convolutional coding scheme. A concatenated code is a cascaded combination of two or more codes and is used to provide additional error correction capabilities. For a concatenated code, the code bits between the coding stages may be interleaved (i.e., reordered) to provide temporal diversity, which can further improve performance. An entire packet or frame of code bits is typically stored before the reordering is performed. The reordered code bits are then serially retrieved and coded by the next coding stage.","Conventionally, convolutional and Turbo coding is performed serially on an input bit stream. For each clock cycle, one data bit is provided to the encoder and two or more code bits are generated depending on the code rate of the encoder. Some of the code bits may then be punctured (i.e., deleted) to obtain code bits at other code rates.","Digital multiple access communications systems typically transmit data in packets or frames to allow for efficient sharing of system resources among active users. For services that cannot tolerate long delays (e.g., voice, video), the packets are selected to be short in duration (e.g., 10 msec) and the codes are accordingly selected to have shorter processing delays. However, for improved coding efficiency, it is desirable to process and code larger sized packets, which can result in longer processing delays using the conventional technique that serially codes data. The long processing delays may adversely impact the performance of the communications system. For example, a particular user or data rate may be selected for a particular data transmission based on the conditions of the communications link. If the processing delays are excessively long, the link conditions may have changed by the time of the data transmission, and performance may be compromised or adversely affected.","As can be seen, techniques that can be used to efficiently code data with shorter processing delays are highly desirable.","According to one aspect, a method of generating addresses for an interleaver in a wireless communication system includes incrementing a counter to a counter value, the counter value for generating an interleaver address, if the counter value corresponds to an invalid interleaver address, adjusting the counter value to a next valid address, and generating an address based on the adjusted counter value.","In another aspect, an address generation apparatus for an interleaver in a wireless communication system including a counter, and a plurality of address generators each coupled to the counter, each of the plurality of address generators having a memory storage device coupled to the counter, storing a plurality of counter values with corresponding counter offset values, and a second counter coupled to the memory storage device, adapted to add the counter offset value to a previously generated address.","In still another aspect, a data encoder includes a plurality of memories for storing sequential input information bits, a plurality of interleavers for scrambling the input information bits, a first encoder coupled to a first of the memories, the first encoder adapted to encode the sequential input information bits, and a second encoder coupled to the plurality of memories, the second encoder adapted to encode the interleaved input information bits.","In yet another aspect, a method of encoding data includes receiving a plurality of input bits, and during a single system clock cycle: calculating a first set of state values based on the plurality of input bits, calculating a second set of state values based on the plurality of input bits and the first set of state values, calculating a third set of state values based on the plurality of input bits, and the first and second sets of state values, and generating a set of encoded outputs based on the first, second, and third sets of state values.","Other aspects and embodiments of the invention are described below.","Coding Multiple Bits in Parallel",{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 1","b":["100","110","112","114","114","116","118","120"]},"At a receiver unit , the transmitted signal is received by an antenna  and provided to a Receiver (RCVR) . Within receiver , the received signal is amplified, filtered, downconverted, quadrature demodulated, and digitized to provide samples. The samples are despread, decovered, and demodulated by a Demodulator (DEMOD)  to generate demodulated symbols. A decoder  then decodes the demodulated symbols and (possibly) reorders the decoded data to recover the transmitted data. The processing performed by demodulator  and decoder  is complementary to the processing performed at transmitter unit . The recovered data is then provided to a data sink .","The signal processing described above supports transmissions of voice, video, packet data, messaging, and other types of communication in one direction. A bi-directional communications system supports two-way data transmission. However, the signal processing for the other direction is not shown in  for simplicity.","Communications system  can be a Code Division-Multiple Access (CDMA) system, a Time Division-Multiple Access (TDMA) communications system (e.g., a GSM system), a Frequency Division-Multiple Access (FDMA) communications system, or other multiple access communications system that supports voice and data communication between users over a terrestrial link.","The use of CDMA techniques in a multiple access communications system is disclosed in U.S. Pat. No. 4,901,307, entitled \u201cSPREAD SPECTRUM MULTIPLE ACCESS COMMUNICATION SYSTEM USING SATELLITE OR TERRESTRIAL REPEATERS,\u201d and U.S. Pat. No. 5,103,459, entitled \u201cSYSTEM AND METHOD FOR GENERATING WAVEFORMS IN A CDMA CELLULAR TELEPHONE SYSTEM.\u201d Another specific CDMA system is disclosed in U.S. patent application Ser. No. 08\/963,386, entitled \u201cMETHOD AND APPARATUS FOR HIGH RATE PACKET DATA TRANSMISSION,\u201d filed Nov. 3, 1997 now U.S. Pat. No. 6,574,211, issued Jun. 3, 2003 to Padovani et al. (hereinafter referred to as the High Data Rate (HDR) system). These patents and patent application are assigned to the assignee of the present invention and incorporated herein by reference.","CDMA systems are typically designed to conform to one or more standards such as the \u201cTIA\/EIA\/IS-95-A Mobile Station-Base Station Compatibility Standard for Dual-Mode Wideband Spread Spectrum Cellular System\u201d (hereinafter referred to as the IS-95-A standard), the \u201cTIA\/EIA\/IS-98 Recommended Minimum Standard for Dual-Mode Wideband Spread Spectrum Cellular Mobile Station\u201d (hereinafter referred to as the IS-98 standard), the standard offered by a consortium named \u201c3rd Generation Partnership Project\u201d (3GPP) and embodied in a set of documents including Document Nos. 3G TS 25.211, 3G TS 25.212, 3G TS 25.213, and 3G TS 25.214 (hereinafter referred to as the W-CDMA standard), and the \u201cTR-45.5 Physical Layer Standard for cdma2000 Spread Spectrum Systems\u201d (hereinafter referred to as the CDMA-2000 standard). New CDMA standards are continually proposed and adopted for use. These CDMA standards are incorporated herein by reference.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 2","b":["200","200","114","1","200","212","214","216","212","214","214","216","214","212"]},"A conventional convolutional encoder receives and codes data serially, one bit at a time (i.e., per clock cycle). For communications systems that transmit data in large packets, the serial coding of data can result in long processing delays. Moreover, for a concatenated coder made up of multiple convolutional encoders coupled in cascade, the processing delays can be excessively long, especially if the outer and inner convolutional encoders both code bits serially.","In one aspect, a convolutional encoder is capable of receiving and coding multiple (M) bits in parallel. This capability allows the convolutional encoder to code a packet of data in approximately (1\/M)the amount of time required by a conventional convolutional encoder. The benefits are more pronounced for a concatenated coder (e.g., a Turbo coder) when each of the individual convolutional encoders processes bits in parallel.","According to another aspect, an interleaver is capable of storing and providing multiple bits of data in parallel. The interleaver may be implemented using, for example, a multi-port memory. When used in combination with the convolutional encoders described herein, the interleaver can further reduce the processing delays since data can be written to, and read from the interleaver in a fraction of the time.","For clarity, an exemplary embodiment is now described for an encoder used for a downlink data transmission in the communications system described in the aforementioned U.S. patent application Ser. No. 08\/963,386, now U.S. Pat. No. 6,574,211 (i.e., the HDR system). The HDR system employs a concatenated code comprised of an outer convolutional code, interleaving, and an inner convolutional code. The HDR system also defines two packet formats having the properties listed in Table 1.",{"@attributes":{"id":"p-0047","num":"0046"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},{},"Packet","Packet",{}]},{"entry":[{},"Parameters","Format 1","Format 2","Units"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Total bits\/packet","1024","2048","bits"]},{"entry":[{},"Outer convolutional encoder"]},{"entry":[{},"Input data bits\/packet","1018","2042","bits"]},{"entry":[{},"Code-tail bits\/packet","4","4","bits"]},{"entry":[{},"Outer code rate","\u00bd","\u2154"]},{"entry":[{},"Outer code puncture pattern","(1111)","(1011)"]},{"entry":[{},"Output code bits\/packet","2044","3069","bits"]},{"entry":[{},"Interleaver depth","2048","3072","bits"]},{"entry":[{},"Inner convolutional encoder"]},{"entry":[{},"Input code bits\/packet","2044","3069","bits"]},{"entry":[{},"Code-tail bits\/packet","4","3","bits"]},{"entry":[{},"Inner code rate","\u00bd","\u00be"]},{"entry":[{},"Inner code puncture pattern","(111111)","(111001)"]},{"entry":[{},"Output code bits\/packet","4096","4096","bits"]},{"entry":[{},"Overall code rate","\u00bc","\u00bd"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}]}}},"In the HDR system, the outer convolutional encoder implements a rate \u00bd convolutional code defined by the following polynomial generator matrix: \n\n","The inner convolutional encoder in the HDR system implements a rate \u00bd convolutional code defined by the following polynomial generator matrix: \n\n",{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 3","b":["300","310","310","312","314","314","312","314","314","314","316","316","316","314","314","318","312","316"],"sub":["oa ","ob","oa ","ob"]},"The code bits in the outputs yand yof outer convolutional encoder  may be punctured (not shown in  for simplicity). The unpunctured code bits are then provided to interleaver  and reordered. The reordered code bits v are then provided to an inner convolutional encoder  that implements equation (2) and generates two outputs yand y. Within encoder , the code bits v are provided a summer  that couples in cascade with registers A and B. The outputs from summer  and registers A and B are summed by summers A and B to implement the numerator of the second element in the polynomial generator matrix expressed in equation (2). The output from register A is provided to summer  to implement the denominator of the second element in equation (2). The input code bits v are provided as the first output yand the output from summer B comprises the second output y.","Conventionally, the data bits u are provided serially to encoder  and the code bits v are also provided serially to encoder . For each input data bit, outer convolutional encoder  generates two code bits. Interleaver  receives and stores the code bits, and provides the code bits serially to inner convolutional encoder . The coding of the bits in a serial manner results in long processing delays.","The convolutional encoder of one embodiment is capable of coding multiple bits in parallel to significantly shorten the coding delays. For each clock cycle, multiple (e.g., M) data bits can be received and coded to generate multiple code bits. For a rate \u00bd encoder, 2M code bits are generated for the M data bits. M can be selected to be any number such as, for example, 4, 8, 16, 32, and so on. Various alternate embodiments of such a convolutional encoder are described below.","Many digital communications systems, such as the HDR system, transmit data in packets. The number of bits in a packet (i.e., the packet size) is selected based on a number of criteria such as, for example, the data rate, the amount of data to transmit, the processing delays requirements, and so on. To allow the decoder at the receiver unit to start at a known state at the beginning of each packet, which shortens the decoding time and improves performance, the encoder is initialized to a known state (e.g., all zeros) at the start of each packet. The initialization is achieved by inserting a set of code tail bits at the end of the preceding packet. The code-tail bits are selected such that the encoder is set to the known state.","In one embodiment, the convolutional encoder of the exemplary embodiment is implemented with a look-up table. Referring to , outer convolutional encoder  may be viewed as a state machine with a 4-bit state defined by the outputs of registers A through D. To generate the contents of the look-up table, the M input data bits at time index n can be represented by a vector U, the 2M code bits can be represented by a vector Y, and the current encoder state can be represented by a vector X. The next state Xfor the encoder and the encoder output vector Ycan be expressed as:",{"@attributes":{"id":"p-0056","num":"0055"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"14pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"Data","Code-tail"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"X= \u0192(X, U)","X= 0","Eq (3)"]},{"entry":[{},"Y= g(X, U)","Y= g(X, U)","Eq (4)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"Equations (3) and (4) can be computed for all possible combinations of input data bits and encoder states. For example, for equation (4), the output code bits can be computed for the input vector U=0 . . . 00 and an encoder state of X=0 . . . 00, an input vector U=0 . . . 01 and the encoder state of X=0 . . . 00, and so on, and an input vector U=1 . . . 11 and the encoder state of X=0 . . . 00. The output code bits can then be computed for all possible combination of the input vector Uand an encoder state of X=0 . . . 01. The process then continues until all combinations of input vector and encoder state are computed. Equation (3) can also be computed in a similar manner.","The results from the computations for equations (3) and (4) can be stored to a memory that implements a look-up table. The required memory size is dependent on the number of data bits to be coded in parallel and the particular polynomial generator matrix being implemented. For example, if eight data bits are to be coded in parallel with the convolutional code expressed in equation (1), a memory having a size of 12 address bits and 20 data bits (i.e., 4096\u00d720) can be used. The 12-bit address is composed of 8 input data bits and 4 bits for the current encoder state. The 20-bit output includes 16 code bits and 4 bits for the next encoder state.","Once the memory has been properly defined, the input data vector Uand the current encoder state Xcan be provided to the address input of the memory, which then provides the output vector Yand the next encoder state X. The next encoder state Xis appropriately stored for use with the next input data vector U.","In another embodiment, the convolutional encoder is implemented with a state machine. The encoder state and output can be expressed as shown in equations (3) and (4). Each of equations (3) and (4) can be recursively solved, and the resulting equations are then implemented in hardware, software, or a combination thereof. The recursive equations for the encoder may be solved as follows. Let X=[xxxx] denotes the transposed state vector and udenotes the input data bit at time index 0. The next state and output of the encoder can then be expressed as:\n\n,\u2003\u2003Eq (5)\n\n.\u2003\u2003Eq (6)\n\nwhere A, B, C, and D are scalar, vectors, and matrix that are dependent on the particular polynomial generator matrix being implemented. The encoder state equation (5) can be recursively solved as follows: \n\n\nThe encoder output equation (6) can also be recursively solved in similar manner.\n","Equations (5) and (6) are used to code one data bit u at a time. A similar set of equations can be derived for coding M data bits in parallel. For example, for coding 8 data bits in parallel (i.e., M=8), the transpose of the input data vector at time index n can be defined as U=[uuuuuuuu], and the transpose of the output code vector can be defined as Y=[yyyyyyyy]. Using the defined vector notations for Uand Y, equations (5) and (6) can be expressed as:\n\n1+FX,\u2003\u2003Eq (7)\n\n=HX.\u2003\u2003Eq (8)\n\nwhere F, G, H, and I are vectors and matrices that are dependent on the particular polynomial generator matrix being implemented, the current encoder state X, and the input data vector U. Equation (7) is used to generate the next encoder state Xafter M data bits have been coded, and equation (8) is used to generate the encoder outputs Yfor the input vector U.\n","To determine F, G, H, and I in equations (7) and (8), equations (5) and (6) can be solved recursively using various techniques and the results from the recursive computations can be used to implement equations (7) and (8). For example, a table can be used to tabulate the state and outputs of the encoder for each input data bit. The entries in the table can then be used to implement equations (7) and (8), as described below.","Table 2 shows the encoder states and outputs after eight input data bits uthrough uhave been serially provided to convolutional encoder  in , which implements equation (1). As shown in , registers A through D initially store the values of x, x, x, and x, respectively. On the first clock cycle, the first data bit uis provided to encoder , and the output of summer  is computed as x+x+u, which is stored in the second row, second column in Table 2. The encoder outputs are computed as y=uand y=(x+x+u)+x+x+x=x+x+x+u. (Each summer  performs modulo-2 addition.) On the next clock cycle, the values from summer  and registers A through C are shifted into regissters A through D, respectively. The next data bit uis provided to the encoder, and the output of summer  is computed as x+x+u, which is stored in the third row, second column in Table 2. The encoder outputs are computed as y=uand y=(x+x+u)+x+x+(x+x+u)=x+x+x+x+u+u. The processing continues until the eighth data bit uis received and processed.","The encoder output vector Y=[yyyyyyyy] corresponds to the input vector U=[uuuuuuuU] and is generated based on the entries in the last column in Table 2. The encoder state Xafter the eighth data bit uhas been coded is generated based on the entries in the last row in Table 2. As shown in Table 2, the encoder output vector Yand the next encoder state Xare each a function of the current encoder state X=[xxxx] and the input vector U. For the data phase, the encoder output vector Yis simply a function of the input vector U (i.e., Y=U).",{"@attributes":{"id":"p-0065","num":"0064"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"8"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"49pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}},{"entry":["u","1","x","x","x","x","y","y"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["u","x+ x+ u","x","x","x","x","u","x+ x+"]},{"entry":[{},{},{},{},{},{},{},"x+ u"]},{"entry":["u","x+ x+ u","x+ x+ u","x","x","x","u","x+ x+ x+"]},{"entry":[{},{},{},{},{},{},{},"x+ u+ u"]},{"entry":["u","x+ x+ u","x+ x+ u","x+ x+ u","x","x","u","x+ x+ x+"]},{"entry":[{},{},{},{},{},{},{},"u+ u+ u"]},{"entry":["u","x+ x+ x+","x+ x+ x+","x+ x+ u","x+ x+ u","x","u","x+ x+ u+"]},{"entry":[{},"u+ u","u+ u",{},{},{},{},"u+ u+ u"]},{"entry":["u","x+ x+ u+","x+ x+ u+","x+ x+ x+","x+ x+ u","x+ x+ u","u","x+ u+ u+"]},{"entry":[{},"u+ u","u+ u","u+ u",{},{},{},"u+ u+ u"]},{"entry":["u","x+ x+ u+","x+ x+ u+","x+ x+ u+","x+ x+ x","x+ x+ u","u","x+ u+ u+"]},{"entry":[{},"u+ u","u+ u","u+ u","u+ u",{},{},"u+ u+ u"]},{"entry":["u","x+ x+ x+","x+ x+ u+","x+ x+ u+","x+ x+ u+","x+ x+ x+","u","x+ u+ u+"]},{"entry":[{},"u+ u+ u+","u+ u","u+ u","u+ u","u+ u",{},"u+ u+ u"]},{"entry":[{},"u"]},{"entry":["u","x+ x+ x+","x+ x+ x+","x+ x+ u+","x+ x+ u+","x+ x+ u+","u","x+ u+ u+"]},{"entry":[{},"u+ u+ u+","u+","u+ u","u+ u","u+ u",{},"u+ u+ u"]},{"entry":[{},"u","u+ u+ u"]},{"entry":[{},{},"x+ x+ x+","x+ x+ x+","x+ x+ u+","x+ x+ u+"]},{"entry":[{},{},"u+ u+ u+","u+ u+ u+","u+ u","u+ u"]},{"entry":[{},{},"u","u"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}}]}}}}},"Referring back to Table 1, the outer convolutional encoder in the HDR system receives 1018 data bits and four code-tail bits for each packet in packet format . If eight bits are coded in parallel, 128 clock cycles are used to code one packet of data. The first 127 clock cycles are used to code 1016 data bits (i.e., 127\u00d78=1016), and the 128clock cycle is used to code the remaining two data bits and four code-tail bits. The first 127 clock cycles are referred to as the \u201cdata phase,\u201d and the last clock cycle is referred to as the \u201ccode-tail phase.\u201d","The outer convolutional encoder receives 2042 data bits and four code-tail bits for each packet in packet format . If eight bits are coded in parallel, 256 clock cycles are used to code one packet of data. The first 255 clock cycles are used to code 2040 data bits (i.e., 255\u00d78=2040), and the 256clock cycle is used to code the remaining two data bits and four code-tail bits. The first 255 clock cycles are referred to as the data phase, and the last clock cycle is referred to as the code-tail phase.","Table 3 shows the encoder states and outputs after two data bits uand uand four code-tail bits have been serially provided to convolutional encoder  in FIG. . Again, registers A through D initially store the values of x, x, x, and x, respectively. On the first two clock cycles, the two data bits, uand u, are serially provided to the encoder. The encoder states xthrough xand the encoder outputs yand yare computed in similar manner as described above. Thus, the second and third rows of Table 3 are identical to the second and third rows of Table 2. On the third clock cycle, the first code-tail bit having a value of x+xis provided to the encoder. The value of the code-tail bit is selected such that the output of summer  is equal to zero, which is used to flush out the convolutional encoder. The encoder outputs are computed as y=x+xand y=x+u+u. On the next clock cycle, the values from summer  and registers A through C are shifted into registers A through D, respectively. The second code-tail bit is selected to be x+x+x+u, again to set the output of summer  to zero and flush out the encoder. The processing continues, with the last two bits provided to the encoder having values of zero.","As shown in Table 3, the encoder outputs Yand Yare both functions of the input vector U and the current encoder state X. For the code-tail phase, the next encoder state Xis set to a known state of all zeros (i.e., X=[0 0 0 0].",{"@attributes":{"id":"p-0070","num":"0069"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"8"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"49pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 3"},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}},{"entry":["u","1","x","x","x","x","y","y"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["u","x+ x+ u","x","x","x","x","u","x+ x+"]},{"entry":[{},{},{},{},{},{},{},"x+ u"]},{"entry":["u","x+ x+ u","x+ x+ u","x","x","x","u","x+ x+ x+"]},{"entry":[{},{},{},{},{},{},{},"x+ u+ u"]},{"entry":["x+ x","0","x+ x+ u","x+ x+ u","x","x","x+ x","x+ u+ u"]},{"entry":["x+ x+","0","0","x+ x+ u","x+ x+ u","x","x+ x+","x+ x+"]},{"entry":["x+ u",{},{},{},{},{},"x+ u","x+ u"]},{"entry":["x+ x+","0","0","0","x+ x+ u","x+ x+ u","x+ x+","x+ x+ u"]},{"entry":["u+ u",{},{},{},{},{},"u+ u"]},{"entry":["x+ x+ u","0","0","0","0","x+ x+ u","x+ x+ u","x+ x+ u"]},{"entry":["0","0","0","0","0","0","0","0"]},{"entry":["0","0","0","0","0","0","0","0"]},{"entry":[{},{},"0","0","0","0"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}}]}}}}},{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 4","FIG. 4"],"b":["400","400","310","340","3"]},"Within convolutional encoder , the input data bits are provided in parallel as a data vector U to an encoder state machine , a data phase output generator , and a code-tail phase output generator . Encoder state machine  also receives the current encoder state X and determines the new encoder state based on the received inputs vector U and the current encoder state X. Encoder state machine  can implement, for example, the last row in Table 2.","Data phase output generator  and code-tail phase output generator  also receive the current encoder state X and determine the encoder outputs for the data phase and the code-tail phase, respectively, based on the received inputs X and U. Data phase output generator  can implement, for example, the last two columns in Table 2, and code-tail output generator  can implement, for example, the last two columns in Table 3. The first and second outputs, Yand Y, from data phase output generator  are provided to multiplexers (MUXes) A and B, respectively. Similarly, the first and second outputs, Yand Y, from code-tail phase output generator  are provided to multiplexers A and B, respectively. Multiplexers A and B provide the outputs Yand Y, respectively, from data phase output generator  when operating in the data phase and the outputs Yand Y, respectively, from code-tail phase output generator  when operating in the code-tail phase.","To implement a convolutional encoder that continuously codes input data bits as they are received, without having to reset the encoder state at the start of each packet, only encoder state machine  and data phase output generator  are needed. For communications systems (e.g., the HDR system) in which data is sent in packets and code-tail bits are used to reset the convolutional encoder to a known state at the start of each packet, code-tail phase output generator  and multiplexers  are used to provide the required encoder outputs.","The design of encoder state machine  and data phase output generator  is dependent on the particular polynomial generator matrix to be implemented and the number of data bits to be coded in parallel. The design of code-tail phase output generator  is dependent on the polynomial generator matrix, the number of data bits to be coded in parallel, and the particular frame format (i.e., the number of data and code-tail bits to be coded in the code-tail phase). A specific design of convolutional encoder  is now described below.",{"@attributes":{"id":"p-0076","num":"0075"},"figref":"FIG. 5A","b":["500","500","510","520","510","520","410","420","4","510","512","512","514","514","520","522","522"]},"As shown in , the eight input data bits, uthrough u, are provided in parallel to the inputs to encoder state machine  and data phase output generator , each of which also receives the current encoder state defined by xthrough x. Each AND gate  within encoder state machine  selectively couples to the inputs u-uand x-x, as defined by the last row in Table 2. For example, AND gate A couples to the inputs x, x, x, u, u, u, and u, as defined by the entry in the last row, third column (x) in Table 2. The outputs of AND gates A through D couple to the inputs of registers A through D, respectively. The outputs of registers A through D comprise the state machine outputs xthrough x, respectively.","Similarly, each AND gate  within data phase output generator  selectively couples to the inputs u-uand x-x, as defined by the last column in Table 2. For example, AND gate A couples to the inputs x, x, x, and u, as defined by the entry in the second row, last column (y) in Table 2. The inputs uthrough ucomprise the encoder outputs ythrough y, respectively (not shown in  for simplicity), and the outputs of AND gates A through H comprise the encoder outputs ythrough y, respectively.",{"@attributes":{"id":"p-0079","num":"0078"},"figref":"FIG. 5B","b":["530","540","540","1","2","530","540","540","430","440","440","4","530","532","532","540","542","542","540","544","544"],"sub":["c ","d ","oa","ob"]},"Encoder state machine , data phase output generator , code-tail phase output generator , and multiplexers A and B in  form a specific implementation of convolutional encoder . This specific implementation is used to implement the polynomial generator matrix expressed in equation (1) and for the packet formats described in Table 1.","For packet format , 1018 data bits are provided to convolutional encoder  over 128 clock cycles. For each of the first 127 clock cycles, eight data bits are provided to encoder , and multiplexers A and B are selected to provide the outputs Yand Yfrom data phase output generator . On the 128clock cycle, the remaining two data bits, four code-tail bits, and two zeros are provided to encoder . Registers A through D are reset to zero (synchronously), and multiplexers A and B are selected to provide the outputs Yand Yfrom code-tail phase output generator . For packet format , 2042 data bits are provided to convolutional encoder  over 256 clock cycles. For each of the first 255 clock cycles, corresponding to the data phase, eight data bits are coded in parallel and multiplexers A and B provide the outputs Yand Y, respectively. On the 256clock cycle, corresponding to the code-tail phase, two data bits, four code-tail bits, and two zeros are coded in parallel and multiplexers A and B provide the outputs Yand Y, respectively.","The specific implementation shown in  is described to provide a clearer understanding. It will be noted that different implementations can also be contemplated and are within the scope of the present invention. Moreover, a different design is typically used for a different polynomial generator matrix, a different number of input data bits, or different packet formats.","In similar manner, another convolutional encoder can be designed to implement the polynomial generator matrix expressed in equation (2). In an embodiment, the convolutional encoder is designed to receive and code four code bits in parallel. Equations (5) and (6) for the next encoder state and outputs, respectively, can be recursively solved in the manner described above.","Table 4 shows the encoder states and outputs after four input code bits vthrough vhave been serially provided to convolutional encoder  in FIG. . Registers A and B initially store the values of xand x, respectively. On the first clock cycle, the first code bit vis provided to encoder , and the output of summer  is computed as x+v, which is stored in the second row, second column in Table 4. The encoder outputs are computed as y=vand y=(x+v)+x+x=x+v. On the next clock cycle, the values from summer  and register A are shifted into registers A and B, respectively. The next code bit vis provided to encoder , and the output of summer  is computed as x+v+v, which is stored in the third row, second column. The outputs are computed as y=vand y=(x+v+v)+(x+v)+x=x+v. The processing continues until the fourth code bit vis received and processed.","The encoder output vector Yis generated based on the entries in the last column in Table 4. The encoder state Xafter the fourth code bit vhas been coded is generated based on the entries in the last row in Table 4. As shown in Table 4, the encoder output vector Yand the next encoder state Xare each a function of the current encoder state X=[xX] and the input vector V. For the data phase, the encoder output vector Yis simply a function of the input vector V.",{"@attributes":{"id":"p-0086","num":"0085"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 4"},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["v","1","x","x","y","y"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["v","x+ v","x","x","v","X+ v"]},{"entry":["v","x+ v+ v","x+ v","x","v","X+ v"]},{"entry":["v","x+ v+","x+ x+ u","x+ v","v","x+ v+ v"]},{"entry":[{},"v+ v"]},{"entry":["v","x+ v+","x+ v+","x+ x+ u","v","x+ v+"]},{"entry":[{},"v+ v+","v+ v",{},{},"v+ v"]},{"entry":[{},"v","x+ v+","x+ v+"]},{"entry":[{},{},"v+ v+ v","v+ v"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}}}},"Referring back to Table 1, the inner convolutional encoder in the HDR system receives 2044 code bits and four code-tail bits for each packet in packet format . If four bits are coded in parallel, 512 clock cycles are used to code one packet. The first 511 clock cycles are used to code 2044 code bits (i.e., 511\u00d74=2044), and the 512clock cycle is used to code the four code-tail bits. The convolutional encoder receives 3079 code bits and three code-tail bits for each packet in packet format . If four bits are coded in parallel, 768 clock cycles are used to code one packet of data. The first 767 clock cycles are used to code 3068 code bits (i.e., 767\u00d74=3068), and the 768clock cycle is used to code the last code bit and three code-tail bits.","Table 5 shows the states and outputs of the inner convolutional encoder for the code-tail phase for packet format . On the first clock cycle, the first code-tail bit of having a value of x, is provided to the encoder. The code-tail bit value is selected such that the output of summer  is equal to zero. The encoder outputs are computed as y=xand y=x+x. The processing continues in similar manner for the remaining three code-tail bits.",{"@attributes":{"id":"p-0089","num":"0088"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"63pt","align":"center"}}],"thead":{"row":[{"entry":[{},"TABLE 5"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"6","align":"center","rowsep":"1"}}]},{"entry":[{},"v","1","x","x","y","y"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"6","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"63pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"x","0","x","x","x","x+ x"]},{"entry":[{},"0","0","0","x","0","x"]},{"entry":[{},"0","0","0","0","0","0"]},{"entry":[{},"0","0","0","0","0","0"]},{"entry":[{},{},{},"0","0"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"6","align":"center","rowsep":"1"}}]}]}}]}}},"Table 6 shows the states and outputs of the inner convolutional encoder for the code-tail phase for packet format . On the first clock cycle, the last code bit vis provided to the encoder, and the encoder states xand xand outputs yand yare computed in similar manner as described above. The second row of Table 6 is thus identical to the second row of Table 4. On the second clock cycle, the first code-tail bit having a value of x+vis provided to the encoder. The code-tail bit value is selected such that the output of summer  is equal to zero. The encoder outputs are computed as y=x+vand y=v. The processing continues in similar manner for the remaining code-tail bits.",{"@attributes":{"id":"p-0091","num":"0090"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 6"},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["v","1","x","x","y","y"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["v","x+ v","x","x","v","x+ v"]},{"entry":["x+ v","0","x+ v","x","x+ v","v"]},{"entry":["0","0","0","x+ v","0","x+ v"]},{"entry":["0","0","0","0","0","0"]},{"entry":[{},{},"0","0"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}}}},{"@attributes":{"id":"p-0092","num":"0091"},"figref":"FIG. 6","b":["600","600","610","620","640","640","1","2"]},"As shown in , four input code bits, vthrough v, are provided in parallel to the inputs of encoder state machine  and output generator , each of which also receives the current encoder state defined as X=[xx]. Each AND gate  within encoder state machine  selectively couples to the inputs v-vand x-x, as defined by the last row in Table 4. For example, AND gate A couples to the inputs x, v, v, v, v, and v, as defined by the entry in the last row, third column (x) in Table 4. The outputs of AND gates A and B couple to the inputs of registers A and B, respectively. The outputs of registers A and B comprise the state machine outputs xand x, respectively.","Similarly, each AND gate  within output generator  selectively couples to the inputs v-vand x-x, as defined by the last two columns in Tables 4 through 6. For example, AND gate A couples to the inputs xand vand generates y(the second row, last column in Table 4), AND gate B couples to the inputs xand xand generates y(the second row, last column in Table 5), and AND gate C couples to the inputs xand vand generates y(the second row, last column in Table 6). The other encoder outputs are generated as indicated in Tables 4 through 6.","Multiplexer A includes 3\u00d71 multiplexers A through D that provide the first encoder outputs ythrough y, respectively, for inner convolutional encoder . During the data phases, ythrough yare provided through multiplexers A through D, respectively. During the code-tail phase, multiplexers A through D respectively provide ythrough yfor packet format  and ythrough yfor packet format . Similarly, multiplexer B includes 3\u00d71 multiplexers A through D that provide the second encoder outputs ythrough y, respectively, for inner convolutional encoder . During the data phases, ythrough yare provided through multiplexers A through D, respectively. During the code-tail phase, multiplexers A through D respectively provide ythrough yfor packet format  and ythrough yfor packet format .","Another aspect of the invention provides an interleaver capable of storing multiple code bits generated in parallel by the outer convolutional encoder and providing multiple code bits in parallel to the inner convolutional encoder. Referring back to , an interleaver is coupled between the outer and inner convolutional encoders. The interleaver is designed to store one or more packets of code bits. After an entire packet has been stored, the code bits are then retrieved in a read order that is different than the write order to achieve interleaving of the code bits. If no interleaving is desired, the code bits can be retrieved from the interleaver in the same order.","The outer convolutional encoder of the exemplary embodiment can be designed to receive and code M data bits in parallel and generate M\u2022R code bits, where R is related to the code rate of the outer convolutional encoder (e.g., R=2 for a rate \u00bd encoder). To expedite processing and reduce delays, the interleaver can be designed to store M\u2022R code bits from the outer convolutional encoder in parallel as the code bits are generated by the encoder. Similarly, the inner convolutional encoder can be designed to receive and code N code bits in parallel. Again, to expedite processing and reduce delays, the interleaver can be designed to provide at least N code bits in parallel to the inner convolutional encoder on a single read operation.","The code bits from each of the outer and inner convolutional encoders may be punctured to provide code bits at other code rates. For example, referring back to Table 1, the outputs from the outer convolutional encoder is unpunctured for packet format  to obtain a code rate of \u00bd and punctured for packet format  to obtain a code rate of \u2154. Similarly, the outputs from the inner convolutional encoder is unpunctured for packet format  to obtain a code rate of \u00bd and punctured for packet format  to obtain a code rate of \u00be. The interface between the encoder and the interleaver can be designed to efficiently achieve the symbol puncturing.",{"@attributes":{"id":"p-0099","num":"0098"},"figref":["FIG. 7A","FIG. 7A"],"b":["700","700","710","710","710"],"sub":["1 ","W","1 ","R","1 ","P"]},"An address generator  receives an input address ADDR, generates the necessary addresses for each active port, and provides the generated addresses to the address inputs Athrough Aof memory . Although not shown in  for simplicity, address generator  further generates one or more control signals that direct memory  to perform a write or read operation.","In an embodiment, memory  is configured as a two-dimensional memory having a number of rows and a number of columns. In an embodiment, code bits are written to sequential rows in memory . For efficiency, the width of each row can correspond to the width of each port (i.e., C bits). This allows up to W rows of code bits to be written to the W write ports of memory  for each write operation. Once the code bits for an entire packet have been stored to memory  the code bits can be retrieved from the memory. In an embodiment, code bits are also read from memory  by rows. For the embodiment shown in , up to R rows of code bits can be retrieved from the R read ports for each read operation.","Various designs can be used to provide code bits from interleaver  to the inner convolutional encoder. The particular design to implement is dependent on the particular system requirements. In one design, R multiplexers A through R are coupled to the R read ports Qthrough Q, respectively. For each read operation, up to R rows of code bits are retrieved from memory  and provided to multiplexers A through R, which also receive the control signals ADthrough AD, respectively. Each multiplexer  receives the C code bits, selects one of the code bits based on the respective control signal AD, and provides the selected code bit to the multiplexer output. The control signals ADthrough ADselect a particular code bit from each retrieved row of code bits. R multiplexers  can thus be used to provide up to R code bits in parallel to the inner convolutional encoder.","For a clearer understanding, a specific design of the interleaver is now described for used with the outer and inner convolutional encoders described above in , B, and . In the above encoder designs, the outer convolutional encoder receives and codes 8 data bits in parallel in one clock cycle to generate 16 code bits, and the inner convolutional encoder receives and codes 4 code bits in parallel. In this specific interleaver design, an 8-port memory is employed, with four ports being used for receiving code bits in write operations and four ports being used for providing code bits in read operations. In this design, each port is capable of receiving or providing 8 bits in parallel. Thus, for this specific design, up to 32 code bits can be written to the interleaver in a write operation, and up to 32 code bits can be read from the interleaver in a read operation.",{"@attributes":{"id":"p-0104","num":"0103"},"figref":"FIG. 7B","b":["732","732","732","732","732","732","732","732"],"sub":["1 ","4"]},{"@attributes":{"id":"p-0105","num":"0104"},"figref":["FIG. 7C","FIG. 7C"],"b":["1011","2","732","732","732","732"],"sub":["1 ","3"]},"The address generator provides the proper addresses for writing the unpunctured code bits to sequential rows in the memory. One address is generated for each active port used for writing the code bits. Thus, the address generator generates four addresses for port Dthrough Dwhen no puncturing is performed and generates three addresses for port Dthrough Dwhen puncturing is performed.","To provide four code bits in parallel to the inner convolutional encoder, four rows of code bits are retrieved from the memory and provided to four 8\u00d71 multiplexers. Each multiplexer also receives a respective 3-bit control signal ADthat selects a particular bit in the retrieved row to provide to the inner convolutional encoder. The address for each retrieved bit may thus be partitioned into two parts, with the first part identifying a particular row in the memory and the second part identifying a particular location within the row. The first part of the address is provided to the appropriate address input of the memory and the second part is provided as the control signal AD. The first and second parts of the address are generated in accordance with the particular interleaving scheme defined by the system or standard being implemented.","The interleaver of the exemplary embodiment can also be implemented using other memories. For example, a single-port memory unit or multiple memory units can be used to concurrently store and provide multiple bits in parallel. For a single-port memory unit, multiple write operations may be used to store the generated code bits, and multiple read operations may also be used to retrieve the required code bits. In designs employing multiple memory units, each memory unit may be operated similar to a port (or a pair of ports) of the multi-port memory. Thus, numerous designs can be used to implement the interleaver and are within the scope of the present invention.","In the embodiments described above, an interleaver is used between the outer and inner convolutional encoders. This configuration is used to implement a Turbo encoder, which can provide certain advantages. In other encoder designs, interleaving after the outer convolutional encoder may not be necessary, and a memory may not be needed after the outer convolutional encoder or may simply be used as a buffer.","The concatenated encoder of the exemplary embodiment can be operated in various manners. In one specific design, the encoder is operated to code one packet of data at a time. Referring back to , a particular packet of data can be coded by the outer convolutional encoder and stored to the interleaver. After an entire packet has been coded by the outer convolutional encoder, the code bits are retrieved from the interleaver and coded by the inner convolutional encoder. Once the entire packet has been coded by the inner convolutional encoder, the next packet is coded by the outer convolutional encoder. This design reduces the memory requirement for the interleaver, which may be desirable in some applications.","In another specific design, the interleaver is implemented with the capacity to store two or more packets of code bits. For example, the memory used to implement the interleaver can be partitioned into two banks, with each memory bank being capable of storing an entire packet of code bits. The two memory banks allow the outer and inner convolutional encoders to operate on two packets concurrently. The outer convolutional encoder codes a first packet and stores the code bits for this packet to one memory bank. After the entire first packet has been stored to memory, the outer convolutional encoder codes a second packet and stores the code bits for this packet to the second memory bank. While the outer convolutional encoder codes and stores the code bits for the current packet to one memory bank, the inner convolutional encoder can retrieve and code the code bits for the previous packet from the other memory bank. This design can reduce the processing delays.",{"@attributes":{"id":"p-0112","num":"0111"},"figref":"FIG. 8","b":["800","800","114","1","800","810","820","830","810","802","850"]},"In the embodiment shown in , processing unit  includes an input interface , a multi-bit encoder , an output interface , and a control unit . Input interface  generates addresses and control signals for buffer , receives data provided by buffer  in response to the generated addresses and control signals, and routes the received data to multi-bit encoder . Multi-bit encoder  implements the output and inner convolutional encoders and may be implemented with one or more look-up tables or one or more encoders such as the one described above in FIG. . When operated as an outer convolutional encoder, multi-bit encoder  codes the data from input interface  and provides the generated code bits to memory . And when operated as an inner convolutional encoder, multi-bit encoder  codes the code bits from memory  and provides the generated code bits to output interface . Output interface  then provides the coded data to buffer .","Control unit  receives various control information such as, for example, the particular data packet to code, the location of the packet in buffer , the packet format, the coding scheme to use, the location to store the coded packet in buffer , and so on. Control unit  then directs input interface  to retrieve the appropriate data bits from buffer , directs encoder state machine  to use the appropriate coding scheme, and further directs output interface  to provide the coded data to the appropriate location in buffer .","Address generator  generates the appropriate addresses for both writing code bits to memory  and reading code bits from the memory. Address generator  can be implemented with logic, a look-up table, or some other designs.","Memory  stores the code bits generated by multi-bit encoder  and also provides the stored code bits to multi-bit encoder . By properly generating the addresses, memory  can be operated to provide interleaving of the code bits. Memory  can be implemented with a multi-port memory, as described above, or with one or more memory units.",{"@attributes":{"id":"p-0117","num":"0116"},"figref":"FIG. 9","b":["912","914","916","918"]},"In the embodiment shown in , an entire packet is coded by the first coding scheme and stored before subsequent coding by a second coding scheme. This allows for interleaving of the code bits, as described above. Thus, a determination is made whether the entire packet has been coded, at step . If the answer is no, the process returns to step  and another M (or less) data bits are received.","Otherwise, if the entire packet has been coded, a number of (N) code bits is retrieved from the memory, at step , and coded in parallel in accordance with the second (e.g., convolutional) coding scheme to generate a number of (NR) code bits, at step . Again, the number of code bits generated by the second coding scheme is dependent on the particular code rate of the scheme. And again, zero of more of the generated code bits may be punctured with a second puncturing scheme, at step , to provide code bits at another code rate. The unpunctured code bits are then provided as coded data to the next processing unit (e.g., modulator  in FIG. ), at step .","For efficiency and reduced delays, W words may be stored in parallel (e.g., via W write ports) to the memory, and R words may be retrieved in parallel (e.g., via R read ports) from the memory. The W words allow for parallel storage of the unpunctured code bits from the first coding scheme and the R words allow for N code bits to be provided in parallel to the second coding scheme. The memory may be operated in the manner described above to achieve interleaving of the code bits. For example, W words may be written to sequential rows in the memory and R words may be read from permutated rows in the memory.","The encoder and interleaver of the exemplary embodiment can be used to greatly shorten the coding time. By coding M data bits in parallel with the outer convolutional encoder and N code bits in parallel with the inner convolutional encoder, the overall coding delays can be significantly reduced. The interleaver of the invention supports parallel coding with its ability to receive multiple code bits for a write operation and to provide multiple code bits for a read operation. The improvement in the processing delays for a specific design, with M=8 and N=4 and for packet formats  and  in the HDR system, is shown in Table 7.",{"@attributes":{"id":"p-0122","num":"0121"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"center"}}],"thead":{"row":{"entry":[{},"TABLE 8"]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Packet format 1","Packet format 2"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"parallel","serial","parallel","serial"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"63pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Outer convolutional encoder",{},{}]},{"entry":["Input bits","1018","2042"]},{"entry":["Code-tail bits","4","4"]},{"entry":["Total input bits","1022","2046"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["Clock cycles needed","128","1024","256","2048"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"63pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Inner convolutional encoder",{},{}]},{"entry":["Input bits","2044","3069"]},{"entry":["Code-tail bits","4","3"]},{"entry":["Total input bits","2048","3072"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Clock cycles needed","512","2048","768","3072"]},{"entry":"Coding time (20 MHz clock)"},{"entry":["Outer encoder (\u03bcsec)","6.4","51.2","12.8","102.4"]},{"entry":["Inner encoder (\u03bcsec)","25.6","102.4","38.4","153.6"]},{"entry":["Total coding time (\u03bcsec)","32.0","153.6","51.2","256.0"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"For the specific design shown in Table 8, the overall coding delays are reduced by a factor of 4.8 for delays provided by the encoder and interleaver of the present invention provide numerous advantages. Some of these advantages are briefly described below.","First, shorter processing delays may be used to support certain types of services, such as voice and video, which have more stringent delays requirements. The shorter processing delays may thus allow for use of more efficient coding schemes for delay sensitive applications.","Second, shorter processing delays can improve system performance. For example, if a particular user or data rate is selected for a particular transmission based on the conditions of the communications link, which are determined at a particular time, shorter processing delays increase the likelihood that the link conditions have not changed by the time of the data transmission. Link conditions typically vary over time, and longer processing delays increase the likelihood that the link conditions have changed by the time of the data transmission, which can then result in degraded performance.","Third, shorter processing delays can improve the capacity of some communications systems. For example, in the HDR system, power control data is multiplexed with the traffic data and transmitted to the user terminals. Shorter processing delays allow for more accurate control of the transmit power of the user terminals, which can increase the system capacity and improve performance.","Fourth, shorter processing delays allow sequential sharing of a hardware resource (i.e., the encoder) in one processing time slot (i.e., the forward link slot in an HDR system) by multiple transmitting entities (i.e., three users in a three sector system) to reduce the overall area of the hardware design.","For clarity, certain aspects and embodiments of the encoder of the invention have been described specifically for the forward link in the HDR system. However, the invention can also be used in other communications systems that employ the same, similar, or different coding schemes. For example, the encoder of the invention can be used to implement a convolutional encoder capable of receiving and coding multiple data bits in parallel. The encoder of the invention can also be used to implement a concatenated encoder, such as a Turbo encoder, that is capable of receiving and coding multiple data bits in parallel. The specific design of the encoder is dependent on various factors such as, for example, the particular polynomial generator matrix being implemented, the number of bits to code in parallel, the packet format, the use of code-tail bits, and so on.","The encoder of the invention can be advantageously used in a base station or a user terminal (e.g., a mobile unit, a telephone, and so on) of a communications system. The coding for the forward link (i.e., downlink) and reverse link (i.e., uplink) may be different, and is typically dependent on the particular CDMA system or standard being implemented. Thus, the encoder of the invention is typically designed specially for the particular application for which it is used.","Referring to the specific design shown in Tables 2 and 3, the next states and outputs for the outer convolutional encoder can be generated with functions having up to seven terms. Referring to the specific design shown in Tables 4 through 6, the next states and outputs for the inner convolutional encoder can be generated with functions having up to five terms. These functions can be easily generated using logic gates in a manner known in the art. The other elements of the outer and inner convolutional encoders (e.g., registers, multiplexers) can also be implemented in a manner known in the art.","Some or all of the elements described above for the encoder of the present invention (e.g., multi-bit encoder, input and output interfaces, control unit, encoder state machine, output generator, multiplexer, and so on) can be implemented within one or more Application Specific Integrated Circuits (ASICs), Digital Signal Processors (DSPs), Programmable Logic Device (PLD), Complex PLD (CPLD), controllers, micro-controllers, microprocessors, other electronic units designed to perform the functions described herein, or a combination thereof. Some or all of the elements of the encoder of the invention can also be implemented using software or firmware executed on a processor.","The memories and memory units such as the ones used to implement the interleaver of the present invention can be implemented with various memory technologies such as, for example, Random Access Memory (RAM), Dynamic RAM (DRAM), Flash memory, and others. The memory unit can also be implemented with storage elements such as, for example, a hard disk, a CD-ROM drive, and others. Various other implementation of the memory units are possible and within the scope of the present invention.","Recursive Coding of Multiple Bits in Parallel","According to an alternate embodiment, encoders are configured in parallel to provide twice the amount of output data, wherein multiple bits are processed by the encoder. The increase in data output is particularly applicable to a high data rate communication system wherein frames are to be encoded quickly. The exemplary embodiment encodes multiple bits per clock cycle, thus meeting the time constraints of a data transmission. This embodiment avoids the use of one encoder per sector by sharing a single encoder over multiple sectors. Alternate embodiments may implement any number of encoders in parallel. By sharing the encoding section across sectors, the speed of the individual encoder may be less strict.","According to one aspect of the exemplary embodiment frame buffer memories store multiple copies of each frame. A parallel Look Up Table (LUT) and multiplier circuits are used to implement the turbo interleaver address generators. The design uses AND-XOR trees to implement parallel encoding. The bit puncturing\/reordering is also done in parallel subsequent to the encoding process.",{"@attributes":{"id":"p-0135","num":"0134"},"figref":"FIG. 10","b":["1000","1000","1000","1002","1002","1004","1004","1004","1004","1004","1004","1004"]},"Terminals  in the coverage area may be fixed (i.e., stationary) or mobile. As shown in , various terminals  are dispersed throughout the system. Each terminal  communicates with at least one and possibly more base stations  on the downlink and uplink at any given moment depending on, for example, whether soft handoff is employed or whether the terminal is designed and operated to (concurrently or sequentially) receive multiple transmissions from multiple base stations. Soft handoff in CDMA communications systems is well known in the art and is described in detail in U.S. Pat. No. 5,101,501, entitled \u201cMethod and system for providing a Soft Handoff in a CDMA Cellular Telephone System,\u201d which is assigned to the assignee of the present invention.","The downlink refers to transmission from the base station to the terminal, and the uplink refers to transmission from the terminal to the base station. In the exemplary embodiment, some of terminals  have multiple receive antennas and others have only one receive antenna. In , base station A transmits data to terminals A and J on the downlink, base station B transmits data to terminals B and J, base station C transmits data to terminal C, and so on.","According to an exemplary embodiment, a wireless communication system is adapted for encoding information for transmission using multiple convolutional encoders configured in parallel. Each of the individual encoders has a similar structure and are coupled via an interleaver. The parallel encoders provide a multiple number of outputs, i.e., for two encoders in parallel; the combination provides twice as many output values. A selection is then made at the output for those output values that will be used in further processing. Multiple bits are processed through the parallel encoders. Processing within each encoder is performed in parallel.","The exemplary embodiment processes multiple bits per system clock cycle, for example, four bits per cycle. The encoder of the exemplary embodiment is implemented using a combination of hardware and software. The hardware is used to store and process information input bits. The software includes instructions for controlling the hardware, and other encoding computations, e.g. generating the interim values during the encoding process.",{"@attributes":{"id":"p-0140","num":"0139"},"figref":["FIG. 11","FIG. 11"],"b":["1500","1500","1502","1552","1522","1552","1522"],"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"G","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"D"}},{"mo":["[","]"],"mrow":{"mn":"1","mo":"\u2062","mtable":{"mtr":{"mtd":[{"mfrac":{"mrow":[{"msub":{"mi":"n","mn":"0"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"D"}},{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"D"}}]}},{"mfrac":{"mrow":[{"msub":{"mi":"n","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"D"}},{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"D"}}]}}]}}}}],"mo":"="}},{"mrow":{"mi":"Eq","mo":["\u2062","\u2062"],"mstyle":{"mtext":"\u2003"},"mrow":{"mo":["(",")"],"mn":"9"}}}]}}}},"br":[{},{},{},{}],"in-line-formulae":[{},{},{},{},{},{}],"i":["d","D","+D","+D","n","D","+D+D","n","D","+D+D","+D"],"sup":["2","3","3","2","3"],"sub":["0","1"]},"Each of the constituent encoders ,  includes a plurality of registers, specifically within encoder  are registers , , and , and within encoder  are registers , , and . Initially, the states of the registers within constituent encoders ,  are set to zero. Each encoder ,  is clocked via an input switch , , respectively. Information bits are provided as input to the first encoder  via switch . The input information bits include Nbits, which is effectively the number of bits into the encoder . The input information bits are further provided to a turbo interleaver , wherein the bits are interleaved, i.e., scrambled, to increase the accuracy of the transmission of data. The output of the turbo interleaver  is provided to the second encoder  via switch . The operation of each of the encoders  and  is similar and therefore the following discussion only details the operation of encoder . Alternate embodiments may implement different types of encoders for each encoder included in turbo encoder block .","The input to the encoder  is provided to a switch, wherein the switch is controlled by a system clock (not shown). The information bits are clocked once for each of the Ndata bit periods with the switch up; then, clocked multiple times for each of the tail bit periods with the switch down. According to one embodiment, the information bits are clocked 6 times for the tail bit period, including 3 clocks for each encoder , . The encoded data output symbols are generated by clocking the constituent encoders ,  Ntimes with the switches in the up positions and puncturing the outputs according to a predetermined puncturing pattern. The output for encoder  is generated in the sequence: X, Y, Y, X\u2032, Y\u2032, Y\u2032. According to the exemplary embodiment, symbol repetition is not implemented in generation of the output symbol. The turbo encoder  generates tail output symbols which are appended to the encoded data output symbols. The tail output symbols are generated after the constituent encoders ,  have been clocked Ntimes.","Operation of the turbo interleaver  is designed to produce a functional equivalent result as if each of the sequence of input bits was sequentially written to an array at a sequence of addresses, wherein the sequence is then read out from another sequences of addresses defined by a predetermined interleaving procedure or protocol. The interleaver operation is further detailed with respect to FIG. .","Continuing with , one node of the switch  is coupled to the input. A second node of the switch  is coupled to an exclusive OR (XOR) gate . The output of XOR gate  is coupled to a series of registers or delay elements , , . Each delay element has an associated state, wherein, information stored in delay element  is referred to as in \u201cstate ;\u201d information stored in delay element  is referred to as in \u201cstate 1;\u201d and information stored in delay element  is referred to as in \u201cstate 2.\u201d The output of delay element  is identified as \u201cS0;\u201d the output of delay element  is identified as \u201cS1;\u201d an the output of delay element  is identified as \u201cS2.\u201d","The outputs of delay elements  and  are each coupled to inputs to an XOR gate . The output of XOR gate  is then coupled to a third node of the input switch  and to an input of XOR gate . The output of XOR gate  is further coupled to an input to an XOR gate . Other inputs to XOR  are received from each of the individual outputs of delay elements , , and . The output of XOR gate  is still further coupled to an input to XOR gate . Other inputs to XOR gate  are received from the individual outputs of delay elements  and .","The output of the encoder  includes an X component directly from the input switch , a parity bit output Yfrom XOR gate , and a second parity bit output Ycomponent from the output of XOR gate . The outputs X, Y, and Yare each provided to a symbol puncturing and repetition unit .","Functionally, the configuration of encoder  implements the following equations:\n\n\u2003\u2003Eq (13)\n\n=[I\u2295(1\u2295S2)]\u22950+2\u2003\u2003Eq (14)\n\n=[I\u2295(1\u2295S2)]\u22950\u22951\u22952\u2003\u2003Eq (15)\n\nwherein I represents the input information bits, S, S, and S represent the outputs of delay elements , , and , respectively, and the operation \u2295 represents the logical XOR operation. By applying the associative and distributive rules of digital logic, the Equations (10) and (11) may be reduced to:\n\n=I\u2295S1\u2295S0\u2003\u2003Eq (16)\n\n=I\u2295S0.\u2003\u2003Eq (17)\n","According to the exemplary embodiment, the turbo encoder has two stages. During the first stage, the frame is read in from an external source. The Cyclic Redundancy Check (CRC) is also calculated during the first stage. During the second stage the frame is encoded, punctured and repeated. The code rate for the turbo encoder may be \u2153 or \u2155.","During the second stage, four bits are received at the encoder , wherein the four bits are processed in parallel, so as to increase the throughput of the encoder. Effectively, although the input information bits I[]:I[] are presented concurrently to encoder , the input information bits are processed as if presented to the encoder  serially. This is accomplished by recursively applying the Equations (16) and (17) to the input data. During an individual system clock cycle, the values of the states are determined, i.e., S[]:S[], S[]:S[], S[]:S[], respectively.",{"@attributes":{"id":"p-0150","num":"0149"},"figref":"FIG. 12","b":["1300","1302","0"],"br":[{},{}],"in-line-formulae":[{},{}],"i":["x","i+","x","i","c","mod "],"sup":"n"},"Continuing with , Most Significant Bit (MSB) information from the value of the counter is provided to the ADD circuitry . The ADD circuitry  increments the MSB value of the counter and provides the result to multiply unit . In one embodiment, the resultant value is modified so as to provide only a predetermined number of bits as output. The Least Significant Bit (LSB) information from the value of the counter is provided to Lookup Table (LUT)  and bit reverse unit . The LSB information is used to address the LUT , wherein the value stored in that location is also provided to the multiply unit . The inputs to multiply unit  are multiplied together and the product provided to selection unit . In one embodiment, the multiply unit  provides only a portion of the product as output to selection unit , such as the LSB portion of the product. The bit reverse unit  performs a bit reverse operation, similar to that discussed hereinabove, on the LSB portion of the counter value. The output of the bit reverse unit  is provided to the selection unit . According to the exemplary embodiment, the input to the selection unit  received from the multiply unit  is used as an LSB portion, and the input received from the bit reverse unit  is used as an MSB portion. The selection unit  also determines if the resultant output address is a valid address. If the address is not valid, the selection unit discards the result, wherein on the next counter increment, a new address is generated. Alternate embodiments may implement alternate interleaving schemes applied between the parallel convolutional encoders.","Note that the encoder  of  may be shared by multiple modulator blocks within a wireless transceiver and therefore, the encoder of the exemplary embodiment encodes multiple bits per clock cycle thus satisfying the speed requirements of a high speed data transmission system. For example, as illustrated in , the functional operation of encoder  encodes four bits per clock cycle, wherein the encoder  is designed to encode a maximum size frame in approximately 32 \u03bcs using a 40 MHz clock. As discussed hereinabove, the encoder  operates in two stages. During the first stage, a frame is read out from an external source and the CRC is calculated. During the second stage, the frame is encoded, punctured, and repeated. As used in the description of the exemplary embodiment, a frame is a data transmission unit having an overhead portion and a payload portion.",{"@attributes":{"id":"p-0153","num":"0152"},"figref":"FIG. 13","b":["1100","1100","1100","1132","1130","1128","1130","1132"],"sub":["0","1"]},"As discussed hereinabove, the CRC generator  operates during the first state, wherein a 16 bit CRC is computed on the packet currently being processed. A packet includes a payload, a CRC portion and a tail portion. One embodiment supports variable length packets. As the data is read at 16 bits per clock cycle, the CRC generator  computes the CRC every cycle. By the end of the first stage, the CRC is ready. At this point, the CRC is written into the Memory Storage Unit (MEM)  and also into four memory storage devices MEM,  to . Also during the first stage, the information bits are provided to the MEMs  to . The information bits are clocked to the MEMs  to , wherein 16 bits are clocked each clock cycle. Note that in the exemplary embodiment MEMs  to  include four memories, however, alternate embodiments may include alternate numbers of memories. The MEMs  to  receive addressing control information from address generator  and counter , which are each coupled to inputs to a multiplexor . The output of the multiplexer  provides the control signal to the MEMs  to . The address generator  increments the addressing for storage of four values. During a write operation to the MEMs  to , each of the MEMs  to  receives the same address. During a read operation from the MEMs  to , each of the MEMs  to  receives a different address. As illustrated in , the MEM  feeds one of the parallel encoders , while the MEMs  to  feed a second parallel encoder . From the parallel encoders  and , each of which provide output sets of X, Y, and Y, the output bits are provided to a symbol repetition and puncturing block, such as block  as in FIG. .","As illustrated in , information bits I[]:I[] are presented to an encoder , similar to encoders  and . The encoder  includes a look ahead state generator  for applying Equations (16) and (17) to the input information bits I[]:I[]. The look ahead state generator  generates the state information and stores the states S[], S[], S[] in a register or memory storage device . The state information is updated on each system clock cycle. Prior to storing the first values, the memory storage device  is initialized to predetermined state values. The state values S[]:S[], S[]:S[], S[]:S[] are then provided to multi-bit output generators , . The input information bits I[]:I[] are provided as the outputs X[]:X[]. The multi-bit output generator  generates the outputs Y[]:Y[]; while the multi-bit output generator  generates the outputs Y[]:Y[]. The multi-bit output generators  and  recursively calculate values based on Equations (16) and (17) given hereinabove.","As discussed hereinabove, the address generation of the exemplary embodiment provides four read addresses to four turbo interleaver memories , . . . , . The turbo interleaving addresses do not have a discernible pattern, and therefore, it is desirable to generate four copies of each address to obtain a read throughput of 4 bits per clock. Each of the interleaver memories , . . . ,  provide one 16 bit word as a read word; one bit is selected from each 16 bit read word via multiple 16:1 multiplexers. In the exemplary embodiment, each interleaver , . . . ,  is coupled to a multiplexer , . . . , , respectively. The 4 bits (i.e., one bit from each interleaver , . . . , ) are then passed to the second encoder .","The total encode time is the time it takes to read the bits into the memories during the first stage plus the time to encode during the second stage. For example, consider a frame size of 4096 bits, wherein the approximate number of cycles to encode the frame is given as: \n\n\nTherefore, for a system having a 40 MHz system clock, a 4096 bit frame will take approximately 32 \u03bcs to encode, which is within a target 40 \u03bcs encode time period.\n","As described hereinabove, the two stage encoder provides the whole packet residing in an internal memory structure. In such structure the input information is provided to the encoder via a read port capable of processing four bits, i.e., quad read port. An external frame source memory is generally one read port, and therefore an alternate method is used to encode the frame from this memory directly. The exemplary embodiment provides a recursive processing of information multiple information bits per clock cycle in order to provide four encoded bits each clock cycle.","The CRC generator  and parallel encoders  and  operate on data at rates greater than 1 bit per clock cycle. The exemplary embodiment implements an AND-XOR tree structure throughout to allow parallel processing. Alternate embodiments may implement any logical structure that recursively implements the Equations (13), (14), and (15). Each AND-XOR tree is given a unique two dimensional array of bits which determine the taps of the AND-XOR tree. For example, consider the parallel encoders , , wherein each includes an internal 3-bit state with different XOR taps for the parity bit outputs, i.e., Y, Y. Each encoder ,  encodes 4 bits per clock cycle in the parallel implementation, wherein a \u2153 rate encoder will produce 12 bits of data per clock, i.e., 4 X bits, 4 Ybits, 4 Ybits. Each output bit is dependent on all 4 input bits as well as the current state. Each encoder includes 3 AND-XOR trees that generate the next two groups of 4 bit output values as well as the next 3 bit state. The X output is directly provided from the input to the encoder, and is not provided through an AND-XOR tree.","In the exemplary embodiment, multiple valid addresses are required per clock cycle. According to the exemplary embodiment, the multiple addresses include four addresses. Four independent circuits are used to generate the four independent read addresses. For encoder , 4 input bits are used per clock cycle. These 4 input bits come from four different interleaver address locations in the 4 frame memories, and therefore 4 address generators provide the 4 addresses.","As an example of the recursive operation performed by encoders  (and also ) of , and detailed in the specific operation of , consider the following application. The states generated and stored in elements ,  and  are identified as states S, S, and S, respectively. The calculation for each state on a given iteration is determined by the following set of equations.\n\n1\u2003\u2003Eq (20)\n\n1\u2003\u2003Eq (21)\n\n1\u2003\u2003Eq (22)\n\nwherein n is the iteration index. The encoder  has received an input I[], corresponding to the input at iteration 0. Correspondingly, each of the elements , , and  have been initialized to a values S[], S[], and S[]. In this case, for iteration n=1, the equations are implemented as:\n\n[[[]\u2003\u2003Eq (23)\n\n[[]\u2003\u2003Eq (24)\n\n[[]\u2003\u2003Eq (25)\n\nwherein the input values and state values for n=0 (at initialization). Similarly, on iteration n=2, the values from iteration n=1 are stored in the elements , , and  and are used to calculate state values as:\n\n[[[]\u2003\u2003Eq (26)\n\n[[]\u2003\u2003Eq (27)\n\n[[].\u2003\u2003Eq (28)\n\nUsing the previously generated values and relationships, Equations (26), (27) and (28) result in:\n\n[[[]\u2003\u2003Eq (29)\n\n[[[]\u2003\u2003Eq (30)\n\n[[]\u2003\u2003Eq (31)\n\n[[[[]\u2003\u2003Eq (32)\n\n[[]\u2003\u2003Eq (33)\n\n[[].\u2003\u2003Eq (34)\n\nThe results for iteration n=3 are given as:\n\n[[[][]\u2003\u2003Eq (35)\n\n[]=[]\u2295([]\u2295[]\u2295[])\u2295[]\u2003\u2003Eq (36)\n\n[[]\u2003\u2003Eq (37)\n\n[[[[]\u2003\u2003Eq (38)\n\n[[]\u2003\u2003Eq (39)\n\n[[[][].\u2003\u2003Eq (40)\n\nSimilarly, the results for iteration n=4 are given as:\n\n[[[[]\u2003\u2003Eq (41)\n\n[]=[]\u2295([]\u2295[]\u2295[])\u2295[]) Eq (42)\n\n[]=[]\u2295([]\u2295[]\u2295[])\u2295[]\u2003\u2003Eq (43)\n\n[[]\u2003\u2003Eq (44)\n\n[[[[[[]\u2003\u2003Eq (45)\n\n[[]\u2003\u2003Eq (46)\n\n[[[[]\u2003\u2003Eq (47)\n\nNote that some iterations result in similar state calculation relationships that may be exploited in encoder design and operation.\n","Continuing with operation of the encoder , during the first stage, memories within the encoder are written with the same data at the same memory addresses. During the second stage, the memories are read from independently at different addresses.","Returning to , the circuit of  produces one address per clock cycle. The input counter is a power of two, and therefore, some addresses may be produced that are out of the range defined by the turbo interleaver block size. The invalid addresses are detected and skipped by the address generator. A pipeline register may be inserted half way through the address generation circuit to increase the speed of operation.","A turbo interleaver address generation circuit  according to one embodiment is illustrated in FIG. . An enable signal and a packet size indicator are provided to an address pointer . The output of the address pointer  is provided to parallel circuit paths, and to LUTs ,  which are used to increment the address values. The append units ,  add 1 bit to the 2 bits received from each of LUTs , , respectively. The outputs of append units ,  are provided to adders , , respectively. The result of the add operation is then provided to multiplexers , . An enable signal is provided to each of the multiplexers , , which each produces 12 bits. The output of multiplexers ,  are provided to a delay element , , the output of which is fed back to adders , . The outputs of delay elements ,  are provided to a network of delay elements including turbo encoder LUTs , . The 7 MSBs of the output of delay elements ,  are provided to delay elements , . The 5 LSBs are provided to both the LUTs ,  and the delay elements , . The outputs of delay elements  and  are coupled to inputs of a multiplier coupled to delay element . The outputs of delay elements ,  are coupled to inputs of a multiplier gate coupled to delay element . The output of delay element  is coupled to a bit reverse unit . The output of delay element  is coupled to a bit reverse unit . Each path is finally provided to a delay element , , respectively.","According to one embodiment, the valid addresses are divided into four groups. Each of counter values resulting in a valid address is determined as well as those counter values that will result in an invalid address. The mapping of counter values to addresses is stored in the LUTs , . For each individual LUT, when the counter value increments to a value corresponding to an invalid address, the LUT outputs an appropriate offset value to provide the next counter value corresponding to a valid address. In this way, the address generator only generates valid addresses. The process avoids unnecessary address calculations, i.e., calculation of invalid addresses that are later discarded.","The address generation circuitry of  may be applied to an encoder configuration such as encoder  of FIG. . Encoder  is responsive to an external memory which provides the frame to be encoded. Five copies are made of the input data and stored in each of memories , , , , and , named respectively MEM , MEM , MEM , MEM , and MEM . MEM  provides 4 sequential bits to encoder . The addresses within MEM  are accessed sequentially. The encoder  provides 4 bit outputs for each of X, Y, and Y.","Address generators , , , and  are coupled to MEM , MEM , MEM , and MEM , respectively. The MEM , MEM , MEM , and MEM  each provide one bit to parallel encoder . The parallel encoder  also provides 4 bit outputs for each of X, Y, and Y.","The address generators , , , and  produce unique series of address locations for each of the associated memories. For example, in one scheme, address generator  produces address locations , , , etc.; address generator  produces address location , , , etc.; address generator  produces address location , , , etc.; address  produces address location , , , etc. When the address generated exceeds the block size of the interleaver, the address generator skips this address.",{"@attributes":{"id":"p-0169","num":"0168"},"figref":"FIG. 17","b":["2000","2002","16","2004","2006","2008","2010","2002"]},"The present invention provides a method of encoding multiple bits in parallel, using a recursive method of processing the various outputs. During each clock cycle, the encoder processes multiple bits and generates outputs consistent with those that would be generated sequentially in a conventional convolutional encoder. In one embodiment, input data is stored in multiple memory storage units, which are then each uniquely addressed to provide data to the two parallel encoders, e.g., embodying a turbo encoder.","Thus, a novel and improved method and apparatus for encoding multiple bits in parallel, using a recursive method of processing the various outputs has been presented. Addresses are generated for the interleaving operation by use of multiple memory storage devices, wherein a counter is used for generation of interleaver addresses and a mapping is provided to identify invalid addresses. Those of skill in the art would understand that the data, instructions, commands, information, signals, bits, symbols, and chips that may be referenced throughout the above description are advantageously represented by voltages, currents, electromagnetic waves, magnetic fields or particles, optical fields or particles, or any combination thereof. Those of skill would further appreciate that the various illustrative logical blocks, modules, circuits, and algorithm steps described in connection with the embodiments disclosed herein may be implemented as electronic hardware, computer software, or combinations of both. The various illustrative components, blocks, modules, circuits, and steps have been described generally in terms of their functionality. Whether the functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans recognize the interchangeability of hardware and software under these circumstances, and how best to implement the described functionality for each particular application. As examples, the various illustrative logical blocks, modules, circuits, and algorithm steps described in connection with the embodiments disclosed herein may be implemented or performed with a (DSP), (ASIC), a Field Programmable Gate Array (FPGA) or other programmable logic device, discrete gate or transistor logic, discrete hardware components such as, e.g., registers and First In First Out FIFO, a processor executing a set of firmware instructions, any conventional programmable software module and a processor, or any combination thereof designed to perform the functions described herein. The processor may advantageously be a microprocessor, but in the alternative, the processor may be any conventional processor, controller, microcontroller, programmable logic device, array of logic elements, or state machine. The software module could reside in RAM, flash memory, Read Only Memory (ROM), Erasable Programmable ROM (EPROM), Electrically Erasable Programmable ROM (EEPROM), registers, hard disk, a removable disk, a CD-ROM, or any other form of storage medium known in the art. An exemplary processor is advantageously coupled to the storage medium so as to read information from, and write information to, the storage medium. In the alternative, the storage medium may be integral to the processor. The processor and the storage medium may reside in an ASIC. The ASIC may reside in a telephone or other user terminal. In the alternative, the processor and the storage medium may reside in a telephone or other user terminal. The processor may be implemented as a combination of a DSP and a microprocessor, or as two microprocessors in conjunction with a DSP core, etc.","Preferred embodiments of the present invention have thus been shown and described. It would be apparent to one of ordinary skill in the art, however, that numerous alterations may be made to the embodiments herein disclosed without departing from the spirit or scope of the invention. Therefore, the present invention is not to be limited except in accordance with the following claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The features, nature, and advantages of the present invention will become more apparent from the detailed description set forth below when taken in conjunction with the drawings in which like reference characters identify correspondingly throughout and wherein:",{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 5A and 5B"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIGS. 7B and 7C"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 17"}]},"DETDESC":[{},{}]}
