---
title: Method and system for remapping processing elements in a pipeline of a graphics processing unit
abstract: A method and system for remapping units that are disabled to active units in a 3-D graphics pipeline. Specifically, in one embodiment, a method remaps processing elements in a pipeline of a graphics pipeline unit. Graphical input data are received. Then the number of enabled processing elements are determined from a plurality of processing elements. Each of the enabled processing elements are virtually addressed above a translator to virtually process the graphical input data. Then, the virtual addresses of each of the enabled processing elements are mapped to physical addresses of the enabled processing elements at the translator. The graphical input data are physically processed at the physical addresses of the enabled processing elements. In addition, each of the enabled processing elements are physically addressed below the translator to further process the graphical input data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08711156&OS=08711156&RS=08711156
owner: Nvidia Corporation
number: 08711156
owner_city: Santa Clara
owner_country: US
publication_date: 20040930
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED UNITED STATES PATENT APPLICATION","FIELD OF THE INVENTION","BACKGROUND ART","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This application is related to U.S. patent application Ser. No. 10\/876,340 by Michael Diamond, filed on Jun. 23, 2004, entitled \u201cA System and Method for Testing and Configuring Semiconductor Functional Circuits\u201d, and assigned to the assignee of the present invention. To the extent not repeated herein, the contents of this related patent application are hereby incorporated herein by reference.","Embodiments of the present invention relate to graphics processors. More specifically, embodiments of the present invention relate to remapping pipelined processing elements in a pipeline of a graphics processor.","Graphics processing is an important feature of modern high performance computing systems. In graphic processing, mathematical procedures are implemented to render, or draw, graphic primitives, e.g., a triangle or a rectangle, on a display to produce desired visual images. Real time graphics processing requires high speed processing of graphic primitives to produce visually pleasing moving images.","The rendering of three-dimensional graphical images is of interest in a variety of electronic games and other applications. Rendering is the general term that describes the overall multi-step process of transitioning from a database representation of a three-dimensional object to a two-dimensional projection of the object onto a viewing surface, e.g., computer display.","The rendering process involves a number of steps, such as, for example, setting up a polygon model that contains the information which is subsequently required by shading\/texturing processes, applying linear transformations to the polygon mesh model, culling back facing polygons, clipping the polygons against a view volume, scan converting\/rasterizing the polygons to a pixel coordinate set and shading\/lighting the individual pixels using interpolated or incremental shading techniques.","Graphics Processing Units (GPUs) are specialized integrated circuit devices that are commonly used in graphics systems to accelerate the performance of a 3-D rendering application. GPUs are commonly used in conjunction with a central processing unit (CPU) to generate three-dimensional images for one or more applications executing on a computer system. Modern GPUs typically utilize a graphics pipeline for processing data.",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1","b":["100","102","102","104","104","103","105","104","106","106"]},"The 2 dimensional co-ordinates of the vertices of the graphics primitives are supplied to a rasterizer . The rasterizer  determines the positions of all of the pixels within the graphics primitives. This is typically performed along raster (horizontal) lines that extend between the lines that define the graphics primitives. The rasterizer  also generates interpolated colors, depths and other texture coordinates for each pixel. The output of the rasterizer  is referred to as rasterized pixel data.","The rasterized pixel data are applied to a shader  that adds texture, color, and optical features related to fog and illumination to the rasterized pixel data to produce shaded pixel data. The shader  includes a texture engine  that modifies the rasterized pixel data to have desired texture and optical features. The texture engine  can be implemented using a hardware pipeline that can process large amounts of data at very high speed. The shaded pixel data is input to a Raster Operations Processor  (Raster op in ) that performs color blending on the shaded pixel data. The result from the Raster Operations Processor  is frame pixel data that is stored in a frame buffer memory  by a frame buffer interface . The frame pixel data can be used for various processes such as being displayed on a display . Frame pixel data can be made available as required by way of the frame buffer interface .","The stages of the traditional GPU pipeline architecture illustrated in  may be typically optimized for high-speed rendering operations (e.g., texturing, lighting, shading, etc.) using a widely implemented graphics programming API (application programming interface), such as, for example, the OpenGL\u2122 graphics language, Direct3D\u2122, and the like. The architecture of the graphics processing unit  is configured as a multi-stage deep pipeline architecture in order to maximize the overall rendering throughput of the pipeline. Generally, deep pipeline architectures have sufficient data throughput (e.g., pixel fill rate, etc.) to implement fast, high quality rendering of even complex scenes.","A particular issue in the GPU processing unit of  is that manufacturing integrated circuits including the GPU is an expensive, resource intensive activity, in which numerous computational components are included in a single integrated circuit unit. Conventionally, integrated circuits are manufactured in wafers comprising a number of die, with each die comprising an integrated circuit having numerous functional components. The number of die that are functionally acceptable from a given wafer is referred to as the yield from the wafer. Yields for wafers with high performance die with a large number of components can be very low.","As a result, it is desirable to increase the yield for a given number of die in order to eliminate waste, save cost, and speed-up the effective manufacturing time.","Accordingly, the present invention provides, in various embodiments, a method and system for remapping processing elements to active units in a graphics processing unit. The present invention provides for higher yields when manufacturing the graphics processing unit by remapping defective processing elements. In addition, the present invention provides for more flexible testing of graphics processing units through the ability to disable processing elements that are not defective. Further, the present invention can promote the efficient use of processing elements in the graphics processing unit through the ability to enable and disable processing elements in a graphics processing unit.","Specifically, in one embodiment, a method is disclosed that remaps processing elements in a pipeline of a graphics processing unit. The method begins by accessing graphical input data at the beginning of the graphics processing unit. Then, the number of enabled processing elements from a plurality of processing elements that function identically is determined. Each of the enabled processing elements are virtually addressed above a translator to virtually process the graphical input data. The present method then maps each of the virtual addresses to physical addresses of each of the enabled processing elements at the translator. In that way, graphical input data are physically processed at the physical addresses of the enabled processing elements. Further, each of the enabled processing elements are physically addressed below the translator to further process the graphical input data.","In another embodiment, a system for remapping processing elements in a pipeline of a graphics processing unit is disclosed. The system includes a host, a cache distributor and a translator. The host receives graphical input data from a central processing unit (CPU). In addition, the host determines the number of enabled processing elements from a plurality of processing elements that function identically. The cache distributor is coupled to receive the graphical input data from the host. The cache distributor assigns the graphical input data to virtual addresses of cache entries in a memory cache that correspond with virtual representations of the enabled processing elements. The translator is coupled to receive the graphical input data from the cache distributor. The translator maps virtual addresses to physical addresses of the cache entries that correspond with the enabled processing elements. Additionally, the cache distributor processes the graphical input data at the virtual addresses of the cache entries. Moreover, modules below the translator in the vertex pipeline address physical addresses of cache entries that correspond to the enabled processing elements.","In its various embodiments, the present invention can significantly expand the functionality and yield of a graphics processing unit by remapping and disabling processing elements and taking care to not reference or send graphical input data to those processing elements that are disabled through the use of a mapping table. In particular, embodiments of the present invention are able to remap and disable processing elements in a graphics processing unit during testing to quickly isolate functional processing elements.","Reference will now be made in detail to the preferred embodiments of the present invention, examples of which are illustrated in the accompanying drawings. While the invention will be described in conjunction with the preferred embodiments, it will be understood that they are not intended to limit the invention to these embodiments. On the contrary, the invention is intended to cover alternatives, modifications and equivalents, which may be included within the spirit and scope of the invention as defined by the appended claims. Furthermore, in the following detailed description of embodiments of the present invention, numerous specific details are set forth in order to provide a thorough understanding of the present invention. However, it will be recognized by one of ordinary skill in the art that the present invention may be practiced without these specific details. In other instances, well-known methods, procedures, components, and circuits have not been described in detail as not to unnecessarily obscure aspects of the embodiments of the present invention.","In general, embodiments of the present invention are capable of remapping processing elements in a pipeline of a graphics processing unit. The graphics processing unit includes a 3-D graphics pipeline. Specifically, the present invention provides for higher yields when manufacturing the graphics processing unit by remapping defective processing elements. In addition, the present invention provides for more flexible testing of graphics processing units through the ability to disable processing elements that are not defective. Further, the present invention can promote the efficient use of pipelined, processing elements that function identically by enabling and disabling the processing elements in a graphics processing unit. Embodiments of the present invention and their benefits are further described below.","Although embodiments of the present invention are disclosed within a graphics pipeline, other embodiments are well suited for implementation within similar pipelines of varying nomenclature that render pixelated data, such as video pipelines, and the like, etc.","Notation and Nomenclature:","Some portions of the detailed descriptions, which follow, are presented in terms of procedures, steps, logic blocks, processing, and other symbolic representations of operations on data bits within a computer memory. These descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. A procedure, computer executed step, logic block, process, etc., is here, and generally, conceived to be a self-consistent sequence of steps or instructions leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually, though not necessarily, these quantities take the form of electrical or magnetic signals capable of being stored, transferred, combined, compared, and otherwise manipulated in a computer system. It has proven convenient at times, principally for reasons of common usage, to refer to these signals as bits, values, elements, symbols, characters, terms, numbers, or the like.","It should be borne in mind, however, that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussions, it is appreciated that throughout the present invention, discussions utilizing terms such as \u201caccessing,\u201d or \u201cdetermining,\u201d or \u201caddressing,\u201d or \u201cmapping,\u201d or \u201cprocessing,\u201d or the like, refer to the action and processes of a computer system (e.g., computer system  of ), or similar electronic computing device, that manipulates and transforms data represented as physical (electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.","Computer System Platform:","With reference now to , a block diagram of an exemplary computer system  is shown upon which embodiments of the present invention can be implemented, in accordance with one embodiment of the present invention. Computer system  includes central processor unit , main memory  (e.g., random access memory), chip set  with north bridge  and south bridge , removable data storage device , input device , signal communications port , and graphics subsystem  which is coupled to display . Computer system  includes several busses for communicatively coupling the components of computer system . Communication bus  (e.g., a front side bus) couples north bridge  of chipset  to central processor unit . Communication bus  (e.g., a main memory bus) couples north bridge  of chipset  to main memory . Communication bus  (e.g., the Advanced Graphics Port interface) couples north bridge of chipset  to graphic subsystem . Communication buses - (e.g., PCI bus) couple south bridge  of chip set  to removable data storage device , input device , signal communications port , respectively. Graphics subsystem  includes graphics processor  and frame buffer .","The components of computer system  cooperatively operate to provide versatile functionality and performance. The operating characteristics of functional components included in computer system  can change dynamically. In one exemplary implementation, the components of computer system  cooperatively operate to provide predetermined types of functionality, even though some of the functional components included in computer system  may be defective. Communications bus , , , ,  and  communicate information. Central processor  processes information. Main memory  stores information and instructions for the central processor . Removable data storage device  also stores information and instructions (e.g., functioning as a large information reservoir). Input device  provides a mechanism for inputting information and\/or for pointing to or highlighting information on display . Signal communication port  provides a communication interface to exterior devices (e.g., an interface with a network). Display device  displays information in accordance with data stored in frame buffer . Graphics processor  processes graphics commands from central processor  and provides the resulting data to graphics buffers  for storage and retrieval by display monitor .","The operational configurations of the functional components included in computer system  are flexibly adaptable to meet a variety of objectives. For example, operational configurations of the functional components included in computer system  are configurable to maintain execution of a type of function even if some of the functional components are disabled. In one exemplary implementation, central processor  and graphics processor  are still capable of executing the same type of processing functions and main memory  stores information even though some of the functional components (e.g., floating point component, pixel shader component, memory cell component, etc) are disabled. In one embodiment, the processors include a plurality of functional components for performing processing operations. The operational characteristics of the functional components can be altered. In one embodiment, the processors include a plurality of functional components for performing processing operations, wherein defective functional components included in the plurality of functional components are disabled. The processors also include a workflow control component for dispensing workflow to enabled processing components and preventing distribution of workflow to the disabled defective components. In one exemplary implementation, computer system  can continue to provide full functionality even though the functionality may be provided at a reduced performance level (e.g., slower).","It is appreciated that the present invention can be implemented in a variety of embodiments. In one exemplary implementation the present invention can be utilized in processing systems utilized to provide a variety of graphics applications including video games. For example, the present invention can be utilized to disable defective components in a game console, personal computer, personal digital assistant cell phone or any number of platforms for implementing a video game. It is also appreciated that references to video game application implementations are exemplary and the present invention is not limited to these implementations.","Method and System for Remapping Processing Elements in a Pipeline:","Accordingly, embodiments of the present invention are capable of remapping processing elements in a pipeline of a graphics processing unit. The processing elements can provide any pipelined functionality within the graphics processing unit. Although embodiments of the present invention are directed to generic processing elements, the following description is provided in relation to vertex processing engines (VPEs), as the processing element, in a vertex pipeline for illustration purposes only.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 3A","FIG. 3A"],"b":["300","300","390"]},"The system A includes a host\/front end  that is, in part, analogous to the host interface\/frontend  of . In general, the host\/front end  receives input data (e.g., raw graphics data and instructions from a CPU) and sends the input data down the vertex pipeline of the graphics pipeline unit. In the present embodiment, the host\/front end  includes a host , a front end , and a cache distributor .","The host\/front end  performs multiple functions to move the input data through the vertex pipeline. For purposes of clarity, only those functions pertinent to the present invention are discussed. In the present embodiment, the host  receives graphical input data from a CPU. In addition, the host  determines the number of enabled VPEs from a plurality of VPEs that are available in a vertex pipeline of a graphics pipeline unit.","The plurality of VPEs that are enabled are referenced virtually by the host . That is, the host  does not know which physical VPEs of the plurality of VPEs are enabled, but does know the number of VPEs that are enabled, and references these virtually.","In one embodiment, the host  determines the number of enabled VPEs by accessing a plurality of fuses . Each of the plurality of fuses corresponds to a physical VPE. In the present embodiment, an intact fuse indicates that a corresponding VPE is enabled. Alternatively, a blown, or set, fuse indicates that a corresponding VPE is disabled. Typically, this process is irreversible.","In one embodiment, the VPEs are tested during the fabrication process to determine whether they meet specifications. Those VPEs that do not meet specifications can be disabled by setting a fuse. The fuse can be set by breaking a physical, electrical fuse connection, (e.g., by a laser) in one embodiment. In this manner, when a corresponding fuse is set, the defective VPE can be taken out of the vertex pipeline and is not used for processing data. That is, the defective VPE is remapped within the pipeline so that the defective VPE is not used for processing data.","The present embodiment is able to accommodate remapping of the VPEs in a vertex pipeline through the use of the plurality of fuses . For example, a defective VPE may be disabled so that units within the vertex pipeline will not reference the disabled VPE or send the disabled VPE any work. In addition, a VPE that is fully functional may be disabled to distinguish between similarly manufactured graphical processing units, or to promote efficiency.","In another embodiment, the host  determines the number of enabled VPEs through a software override . The software override  indicates the number of VPEs that are available for referencing and work. That is, the software override  indicates to the host  the number of VPEs that are enabled. In addition, the software override  indicates to the cache distributor  how many VPEs are enabled, which of the physical VPEs are enabled, and which are disabled. This process is reversible by disengaging the software override.","The host\/front end  also includes an optional front end  that is coupled to the host . One of the functions of the front end  is to convert the graphical input data to a format compatible with the vertex pipeline, including the plurality of VPEs, and the remaining units of the graphics pipeline unit.","The host\/front end  also includes a cache distributor  that is coupled to receive the graphical input data from the front end , or alternatively from the host . The cache distributor  assigns the graphical input data to each of the virtualized VPEs. As such, the cache distributor  is able to perform load balancing when assigning the graphical input data to the vertex pipeline for processing.","In one embodiment, the cache distributor  assigns and sends the graphical input data to virtual addresses of cache entries in a memory cache. Each of the virtualized cache entries correspond with virtual representations of the enabled VPEs, as will be fully described in .","The system A also includes a vertex attribute buffer (VAB)  coupled to receive the graphical input data from the cache distributor . The VAB is coupled to the plurality of vertex processing engines  (VPE , VPE , on up to the n-th VPE ). In particular, in the present embodiment, one of the functions of the VAB is to map the virtual addresses of the virtualized cache entries to physical addresses of the cache entries that correspond with the enabled VPEs. That is, the VAB acts as a translator. This is performed using a mapping or translation table, in one embodiment. As such, VAB  is capable of processing the graphical input data at the physical addresses of the cache entries representative of the physical VPEs. That is, the graphical input data is processed at the physical VPEs that are enabled. The VPEs perform mathematical operations on the vertices of the polygon shape (e.g., triangles) used for producing graphics primitives. That is, the VPEs can place, orient, animate, color, and light every object and surface that needs to be drawn in an image. As such, the VAB  in combination with the vertex processing engines generate and maintain a plurality of vertex attribute states (e.g., position, normal, colors, texture coordinates, etc.) for the graphics primitives.","In addition, for all following units down the vertex pipeline and the remaining units in the graphics pipeline unit, only physical addresses to the cache entries corresponding to the enabled VPEs are used. In this way, these following units can treat the plurality of VPEs as if none of them were removed or disabled. That is, no change to the following units need to be implemented, since these units are only given reference to physical VPEs as designed. Specifically, modules below the VAB  in the vertex pipeline address the physical addresses of the cache entries. As such, none of the references to VPEs to and from these downstream units will access a disabled VPE, because references to the disabled VPE are not sent down the vertex pipeline. That is, to these downstream units, it appears as if the disabled VPEs are idle.","Now referring to some downstream modules in the vertex pipeline, the system A also includes a view port culling module (VPC)  that is coupled to receive processed graphics data from the plurality of VPEs . One of the functions of the VPC  is to cull processed graphics data corresponding to triangles that are not viewed on the display. For example, the VPC  is able to perform back face culling, which discards triangles that are facing away from the view camera and will not be displayed.","The system A also includes a color assembly module . The color assembly module  is coupled to receive the processed graphics data from the VPC  for assembling color data in the vertex pipeline. That is, color data from each of the VPEs are assembled and assigned to corresponding triangles to create the image.","The system A also includes a setup module  that is coupled to receive the processed graphics data for pixelating the processed graphics data. That is, the setup module  begins the process for transforming the graphics primitives to be displayed on pixels of a display. The setup module  begins the remaining process implemented by the graphics pipeline unit, to include, in part, rasterizing, texture mapping, fogging, alpha blending, etc.","Now referring to , a block diagram illustrates the VAB  and the plurality of VPEs  in more detail. The VAB  includes a mapper  for accessing a mapping table . The mapper  maps the virtual representations of the virtualized VPEs that are enabled to physical addresses of the plurality of VPEs, and more specifically, to physical representations of the VPEs that are enabled. That is, the mapper  in the VAB  is able to translate references to virtualized VPEs by units above the VAB  (e.g., the host , front end , and cache distributor ) to references to physical VPEs for units below the VAB .","Specifically, the VAB  maps the references to virtual addresses of the virtualized cache entries made by the units above the VAB (e.g., cache distributor ) to physical addresses of the cache entries that correspond with the enabled VPEs. That is, the VAB  translates the virtual addresses to physical addresses. Translation is enabled through the mapper  in the VAB , in one embodiment. The mapper  in the VAB  accesses the mapping table  to map virtual addresses of virtualized cache entries to physical addresses of physical cache entries in a cache memory  that correspond with the enabled VPEs on a one-to-one basis. As shown in , the mapper  is coupled to the cache memory .","The cache memory  includes cache entries that each correspond to the plurality of VPEs that support the vertex pipeline (e.g., VPE , , on up to the n-th VPE ). For example, each of the plurality of VPEs  correspond to eight entries in the cache memory , in one exemplary embodiment. Other embodiments are well suited to any number of cache entries that correspond to a particular VPE. Graphics data is loaded into the cache entries of the cache memory  for processing by the corresponding VPEs. By setting the cache entries to the VPEs appropriately, load balancing can be achieved.","Table 1 illustrates exemplary entries for the mapping table  in the case where all the physical VPEs of a vertex pipeline are enabled. For instance, if the vertex pipeline includes six VPEs, each of which are associated with 8 cache entries, then there are 48 cache entries in the mapping table . In Table 1, sequential references from the cache distributor  are translated to the cache entries and the VPEs that are enabled in a round robin fashion. For example, as work is being distributed to the VPEs, a reference to virtual cache entry  by the cache distributor  is mapped to a reference to physical cache entry  by the VAB  and units below the VAB . A reference to virtual cache entry  by the cache distributor  is mapped to a reference to physical cache entry  by the VAB  and units below the VAB , and so on. Since all the VPEs are enabled, the mapping repeats every six cache entries. Other embodiments are well suited to load balancing using other load balancing schemes, such as random assigning, or assigning consecutive cache entries to one VPE, etc.",{"@attributes":{"id":"p-0055","num":"0054"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Entries for Mapping Table with all VPEs Enabled"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Virtual","Physical","Corresponding","Corresponding"]},{"entry":[{},"Cache","Cache","Virtual","Physical"]},{"entry":[{},"Entry","Entry","VPE","VPE"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"0","0","VPE-0","VPE-0"]},{"entry":[{},"1","1","VPE-1","VPE-1"]},{"entry":[{},"2","2","VPE-2","VPE-2"]},{"entry":[{},"3","3","VPE-3","VPE-3"]},{"entry":[{},"4","4","VPE-4","VPE-4"]},{"entry":[{},"5","5","VPE-5","VPE-5"]},{"entry":[{},"6","6","VPE-0","VPE-0"]},{"entry":[{},"7","7","VPE-1","VPE-1"]},{"entry":[{},"8","8","VPE-2","VPE-2"]},{"entry":[{},"9","9","VPE-3","VPE-3"]},{"entry":[{},"* * *","* * *","* * *","* * *"]},{"entry":[{},"42","42","VPE-0","VPE-0"]},{"entry":[{},"43","43","VPE-1","VPE-1"]},{"entry":[{},"44","44","VPE-2","VPE-2"]},{"entry":[{},"45","45","VPE-3","VPE-3"]},{"entry":[{},"46","46","VPE-4","VPE-4"]},{"entry":[{},"47","47","VPE-5","VPE-5"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}]}}},"In another example,  illustrates the mapping between the virtualized VPEs  and the physical VPEs  in which a physical VPE is disabled. As shown in , in a VAB  that is able to access six physical VPEs (VPE-, VPE-, VPE-, VPE-, VPE-, and VPE-), only five VPEs are enabled. In , the physical VPE- is disabled, as shown by the dotted lines surrounding the physical representation of VPE-.","As such, virtually there are five VPEs that are enabled. The virtualized VPEs are as follows: VPE-, VPE-, VPE-, VPE-, and VPE-. These virtualized VPEs are referenced by the units above the VAB  (e.g., host , front end , and cache distributor ). Virtually, there is no reference to a sixth possible VPE that was disabled, since those units above the VAB  treat VPEs virtually and only are aware of the number of VPEs that are enabled. That is, these units do not necessarily also know the total number of VPEs in the plurality of VPEs  that support the vertex pipeline. As such, the units above the VAB  only reference the virtual addresses of the five virtualized VPEs. As described previously, in one case, the virtual addresses for a virtualized VPE correspond to virtual cache entries.","Table 2 illustrates exemplary entries for the mapping table  in the case where one VPE is disabled (e.g., physical VPE ) in a plurality of six VPEs of a vertex pipeline. In Table 2, for instance, if each of the six VPEs is associated with 8 cache entries, then there are 48 cache entries in the mapping table . However, since physical VPE- is disabled, only 40 cache entries are used in the mapping table . As in Table 1, sequential references from the cache distributor (e.g., cache distributor  of ) are translated to the cache entries and the VPEs that are enabled in a round robin fashion. For example, as work is being distributed to the VPEs, a reference to virtual cache entry  by the cache distributor  is mapped to a reference to physical cache entry  (physical VPE-) by the VAB  and units below the VAB . A reference to virtual cache entry  by the cache distributor  is mapped to a reference to physical cache entry  (physical VPE-) by the VAB  and units below the VAB . Cache entries for physical VPE- are skipped since physical VPE- is disabled. As such, a reference to virtual cache entry  by the cache distributor  is mapped to a reference to physical cache entry  (physical VPE-) by the VAB  and units below the VAB , and so on. As shown in Table 2, the physical cache entries corresponding to VPE- that is disabled are not referenced.",{"@attributes":{"id":"p-0059","num":"0058"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Entries for Mapping Table with 5 of 6 VPEs Enabled"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Virtual","Physical","Corresponding","Corresponding"]},{"entry":[{},"Cache","Cache","Virtual","Physical"]},{"entry":[{},"Entry","Entry","VPE","VPE"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"0","0","VPE-0","VPE-0"]},{"entry":[{},"1","1","VPE-1","VPE-1"]},{"entry":[{},"2","3","VPE-2","VPE-3"]},{"entry":[{},"3","4","VPE-3","VPE-4"]},{"entry":[{},"4","5","VPE-4","VPE-5"]},{"entry":[{},"5","6","VPE-0","VPE-0"]},{"entry":[{},"6","7","VPE-1","VPE-1"]},{"entry":[{},"7","9","VPE-2","VPE-3"]},{"entry":[{},"8","10","VPE-3","VPE-4"]},{"entry":[{},"9","11","VPE-4","VPE-5"]},{"entry":[{},"* * *","* * *","* * *","* * *"]},{"entry":[{},"35","42","VPE-0","VPE-0"]},{"entry":[{},"36","43","VPE-1","VPE-1"]},{"entry":[{},"37","45","VPE-2","VPE-3"]},{"entry":[{},"38","46","VPE-3","VPE-4"]},{"entry":[{},"39","47","VPE-4","VPE-5"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 5","b":"500"},"At , the present embodiment receives the graphical input data. For instance, the graphical input data includes the raw graphics data from the CPU that is executing an application program. The graphical input data can include instructions for processing the graphical input data through the vertex pipeline.","In one embodiment, before accessing the graphical input data, a first VPE from the plurality of VPEs is removed or disabled. That is, the first VPE is disabled. In one case, the first VPE is removed or disabled by blowing (e.g., setting) a validity fuse that corresponds to the first VPE. When the validity fuse or memory cell is blown (e.g., set), the first VPE is disabled. In another case, the first VPE is removed or disabled through a software override. The software override provides for re-enabling the VPE by disengaging the software override. This is useful for testing purposes, for example.","At , the present embodiment determines the number of enabled VPEs from a plurality of VPEs. The plurality of VPEs support the vertex pipeline. By referencing virtualized VPEs, a better approach to remapping VPEs that are disabled is achieved, since each of the units in the vertex pipeline do not need logic to determine which of the VPEs are enabled and which of the VPEs are disabled in order to reference the enabled VPEs.","In one embodiment, the number of enabled VPEs is determined by checking the status of a corresponding validity fuse for each of the plurality of VPEs. In one case, a blown, or set, fuse indicates a VPE is disabled, and an intact fuse indicates an enabled VPE. Other embodiments are well suited to reversing the status of a VPE when checking the fuses. In another case, the number of enabled VPEs is determined by recognizing a software override that indicates how many VPEs are disabled in the plurality of VPEs.","More specifically, the present embodiment determines the number of cache entries that correspond to the enabled VPEs. As such, the present embodiment is able to virtually address the VPEs by virtually addressing the corresponding cache entry.","By virtually addressing the VPEs, only the number of VPEs that are enabled need be known at this stage. As such, at , the present embodiment virtually addresses each of the enabled VPEs above a VAB to virtually process the graphical input data. That is, the present embodiment is able to perform load balancing of the graphical input data between the enabled VPEs. More specifically, load balancing can be performed when translating sequential references (data and instructions) from the cache distributor for distribution between the cache entries and corresponding VPEs.","At , the present embodiment maps the virtual addresses of each of the enabled VPEs that are virtualized to physical addresses of the enabled VPEs in the plurality of VPEs at the VAB. That is, the present embodiment, maps virtual representations of cache entries in a cache memory corresponding to the enabled VPEs that are virtualized to physical representations of the cache entries in the cache memory corresponding to the enabled VPEs. As such, references to the enabled VPEs are translated from the virtualized addresses of the cache entries that are virtualized to a physical address of physical cache entries by using a translation or mapping table. In the present embodiment, there is a one-to-one mapping of the virtual cache entries to the physical cache entries.","In one embodiment, load balancing is performed by setting the mapping table appropriately, as described previously. For instance, sequential references from the cache distributor in the vertex pipeline can be translated in a round robin fashion to distribute the graphical input data between the cache entries of the VPEs that are enabled.","In still another embodiment, context switching is provided through the use of the mapping table. That is, states of the plurality of VPEs can be stored for context switching between different windows of a display. As such, varying numbers of VPEs can be employed depending on the context status of the VPEs that are enabled.","In still another embodiment, the efficient use of VPEs is possible by enabling and disabling VPEs in a graphics processing unit depending on the load on the graphics processing unit. That is, if the load is light, then fewer numbers of VPEs need to be used to process the graphical input data. On the other hand, if the load is heavy, then a greater number of VPEs need to be used to process the graphical input data. This is accomplished using the mapping table.","At , the present embodiment physically processes the graphical input data at the physical addresses of the enabled VPEs. In addition, at , the present embodiment physically addressing each of the enabled VPEs, and their corresponding cache entries, below the VAB to further process the graphical input data. By using the mapping table, references to the VPEs at each of the units in the vertex pipeline and the graphical processing unit is more efficient since only one unit, the VAB, need only contain logic for determining which VPEs are removed or disabled. That is, units above the VAB reference only the virtualized VPEs and units below the VAB reference the physical VPE. The VAB provides the necessary translation between the virtual and physical domains.","As an advantage, the present embodiment is capable of increasing yields of a manufactured chip by remapping VPEs that are disabled for various reasons (product differentiation, defective VPEs, etc.). In addition, in the testing environment, VPEs that are fully functional can be disabled and re-enabled for testing to determine performance impact of varying numbers of VPEs in the vertex pipeline.","Accordingly, the present invention provides, in various embodiments, a method and system for remapping processing elements in a pipeline of a graphics processing unit. The present invention provides for higher yields when manufacturing the graphics processing unit by disabling and remapping defective vertex processing engines. In addition, the present invention provides for more flexible testing of graphics processing units through the ability to disable vertex processing engines that are not defective. Further, the present invention can promote the efficient use of vertex processing engines in the graphics processing unit through the ability to enable and disable vertex processing engines in a graphics processing unit.","The foregoing descriptions of specific embodiments of the present invention have been presented for purposes of illustration and description. They are not intended to be exhaustive or to limit the invention to the precise forms disclosed, and obviously many modifications and variations are possible in light of the above teaching. The embodiments were chosen and described in order to best explain the principles of the invention and its practical application, to thereby enable others skilled in the art to best utilize the invention and various embodiments with various modifications are suited to the particular use contemplated. It is intended that the scope of the invention be defined by the claims appended hereto and their equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings, which are incorporated in and form a part of this specification, illustrate embodiments of the present invention and, together with the description, serve to explain the principles of the invention:","Prior Art  shows a diagram depicting the various stages of a traditional prior art pipeline.",{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
