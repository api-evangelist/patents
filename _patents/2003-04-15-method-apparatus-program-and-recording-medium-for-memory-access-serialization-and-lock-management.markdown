---
title: Method, apparatus, program and recording medium for memory access serialization and lock management
abstract: Each of CPUs has the function of performing store forwarding (SF) when the address regions of a pair of store and load instructions coincide with each other. Each CPU stops SF and performs store forwarding avoidance (SFA) when the two address regions do not coincide with each other but have an overlap therebetween. Each of SF and SFA is executed with priority over out-of-order execution. Each CPU performs SFA effective in limiting out-of-order execution with respect to a predetermined store instruction on a program and a load instruction mated to the store instruction and given after the store instruction, and ensures that data relating to the store instruction can be observed from other CPUs.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06938131&OS=06938131&RS=06938131
owner: International Business Machines Corporation
number: 06938131
owner_city: Armonk
owner_country: US
publication_date: 20030415
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["DETAILED DESCRIPTION OF THE INVENTION","(2) Queue Lock","(3) Composite Lock","Example 1 of Composite Lock","Example 2 of Composite Lock","Example 3 of Composite Lock","PROBLEMS TO BE SOLVED BY THE INVENTION","SUMMARY OF THE INVENTION","PREFERRED EMBODIMENT","ADVANTAGES OF THE INVENTION","DESCRIPTION OF SYMBOLS"],"p":["1. Field of the Invention","The present invention relates to a method, an apparatus, a program and a recording medium for memory access serialization and lock management and, more particularly, to a method, an apparatus, a program and a recording medium for performing memory access serialization and lock management so as to ensure the desired reliability with which store instructions and load instructions relating to memory access are serialized no matter what the load instruction out-of-order execution function of the CPU.","2. Background Art","Software for servers uses multiple threads for processing requests from a plurality of clients. In general, such thread-parallel software enables parallel processing using multiple processors, i.e., simultaneous execution of a number of processings. In multithread processing, updating of the same data through a plurality of threads can occur frequently. In such a situation, a synchronization mechanism may be used for ensuring data consistency. In Java\u00ae (a trademark of Sun Microsystems, Inc.) that is multithread-capable on language level, two kinds of synchronization mechanisms are supported: the synchronized method and the synchronized block. Today, many software programs for servers such as middleware are written in Java\u00ae. Therefore the performance of the two synchronization mechanisms in Java\u00ae greatly influences the performance of servers.","The applicant of the present invention proposed the tasuki lock as an algorithm for an improved synchronization mechanism in an object management system (Published Unexamined Patent Application No. 2000-76086). The tasuki lock is characterized in that spin-wait, which is a weak point in a thin lock, is eliminated while the advantage of the thin lock, i.e., the advantage that only one atomic instruction suffices, is maintained. The tasuki lock is the best algorithm among those presently conceivable, and Java\u00ae virtual machines in which the tasuki lock is implemented are well known.","The tasuki lock in an object management system will be described along with other lock methods. To synchronize operations for access to an object in a program in which a plurality of threads are operated, codes of the programs are formed in such a manner that the object is locked before access, access is then made, and the object unlocked after the access. As a method of implementation of this object locking, a spin lock and a queue lock are well known. A combination of these methods (hereinafter referred to as a composite lock) has also been proposed.","(1) Spin Lock","A spin lock is a lock method in which the state of a lock is managed by storing identifiers for threads executing locking on an object in correspondence with the object. In the spin lock, when a thread T fails to acquire a lock on an object o, that is, if another thread S has already locked the object o, locking is repeatedly attempted until success is attained in locking. Typically, locking or unlocking is performed as described below by using an atomic machine instruction such as compare_and_swap.",{"@attributes":{"id":"p-0010","num":"0008"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"10 \/* lock *\/"]},{"entry":[{},"20 while (compare_and_swap(&o->lock, 0, thread_id (\u2009))=\u2009=0)"]},{"entry":[{},"30 \u2003yield(\u2009);"]},{"entry":[{},"40 \/* access to o *\/"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},". . ."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"50 \/* unlock*\/"]},{"entry":[{},"60 o->lock=0;"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"Referring to Table 1, locking is performed at the twentieth and thirtieth lines. Yield( ) is effected until a lock is acquired. Yield( ) comprises stopping the execution of the current thread and handing over control to the scheduler. Ordinarily, the scheduler selects one of the other executable threads and makes the selected thread run. Thereafter, the scheduler again makes the preceding thread run, and the execution of the while statement is repeated until success is attained in lock acquisition. In the case where \u201cyield\u201d exists, not only wasting of CPU resources but also a dependence of the implementation on the scheduling method in the platform cannot be avoided and, therefore, it is difficult to write a program so that the program operates as expected. The condition compare_and_swap in the while statement at the twentieth line is such that the content of the field o->lock prepared for the object o and 0 is compared and, if the result of comparison is true, the ID (thread_id( )) of the thread is written to the field. The state where 0 is stored in the field prepared for the object o indicates that there is no thread locking the object. Therefore, when unlocking is performed at the sixtieth line, 0 is stored in o->lock. This field is, for example, a filed of one word for, but may have any number of bits sufficient for storing the identifier of the thread.","A queue lock is a lock method in which threads executing access to an object are managed by using a queue. In the queue lock, when a thread T fails to lock an object o, it suspends by setting itself in a queue of the object o. An unlocking code includes a code for checking whether or not the queue is empty. If the queue is not empty, one thread is taken out from the queue and is resumed. Such a queue lock is implemented integrally with the scheduling mechanism of an operating system (OS) and is provided as an application programming interface (API) of the OS. Semaphore and Mutex are a typical example of a means for such a queue lock. In a queue lock, one word does not suffice as a space overhead. Ordinary, several ten kilobytes are required for a space overhead. It is also to be noted that some lock is acquired or released in a locking or unlocking function since the queue, which is a common resource, is operated.","A multithread-compatible program is written so that access to a common resource is protected with a lock, by considering execution by multiple threads. However, a case is conceivable in which a multithread-compatible library is used by a single-thread program. A case is also possible in which the occurrence of lock contention is substantially zero even at the time of execution by multiple threads. In fact, a report according to an execution record of Java\u00ae (a trademark of Sun Microsystems, Inc.) says that there have been substantially no instances of contention in access to objects in many applications.","Therefore \u201clocking an unlocked object, obtaining access, and unlocking the object\u201d is considered a path executed with increased frequency. This path is executed with markedly high efficiently in the case of a spin lock, but is executed with low efficiency both in terms of time and in terms of space in the case of a queue lock. On the other hand, a CPU resource is wastefully consumed in the case of a spin lock when contention occurs actually, although the frequency of contention is low. There is no such problem with a queue lock.","The basic idea of a composite lock resides in using a suitable combination of a lock using simple processing such as spin lock (referred to as \u201cthin lock\u201d) and a lock using complicated processing such as a queue lock (referred to as \u201cfat lock\u201d) to execute the above-described high-frequency path while maintaining the efficiency at the time of contention. More specifically, locking by a thin lock is first attempted, a transition to locking by a fat lock is made if contention occurs when locking by the thin lock is attempted, and the fat lock is thereafter used.","This composite lock has a field for locking in an object, as does a spin lock. The value of a \u201cthread identifier\u201d or a \u201cfat lock identifier\u201d and a Boolean value indicating which one of the thread identifier value and the fat lock identifier value is stored are stored in the field.","The procedure of locking is as described below.","1) Thin lock acquisition is attempted by an atomic instruction (e.g., compare_and_swap). If success is attained in acquiring the thin lock, access to the object is executed. In the case of failure, it can be found that transition to the fat lock has already been made, or that the thin lock is being maintained by some other thread.","2) If transition to the fat lock has already been made, the fat lock is acquired.","3) In a case where contention occurs in locking by the thin lock, the thin lock is acquired, transition to the fat lock is made and the fat lock is acquired (executed by an inflate function according to a description made below).","The composite lock is implemented in one of two ways according to whether or not yield is effected in \u201cacquisition of thin lock\u201d in the procedure 3, as described below in detail. It is assumed here that the field for locking is one word and, for further simplification, that \u201cthread identifier\u201d or \u201cfat lock identifier\u201d is always an even number other than 0; \u201cthread identifier\u201d is stored if the least significant bit in the locking field is 0; and \u201cfat lock identifier\u201d is stored if the least significant bit in the locking field is 1.","A case of the composite lock in which yield is effected in \u201cacquisition of thin lock\u201d. A locking function can be written in accordance with the above-described procedure, as shown below.",{"@attributes":{"id":"p-0023","num":"0021"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 2"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"10\u2002:void lock(o) {"]},{"entry":[{},"20\u2002: \u2003\u2003if (compare_and_swap(&o->lock, 0, thread_id(\u2009))"]},{"entry":[{},"30\u2002: \u2003\u2003\u2003return;"]},{"entry":[{},"40\u2002: \u2003\u2003while (! (o->lock & FAT_LOCK)) {"]},{"entry":[{},"50\u2002: \u2003\u2003\u2003yield(\u2009);"]},{"entry":[{},"60\u2002: \u2003\u2003\u2003if (compare_and_swap (&o->lock, 0, thread_id(\u2009))){"]},{"entry":[{},"70\u2002: \u2003\u2003\u2003\u2003inflate(o);"]},{"entry":[{},"80\u2002: \u2003\u2003\u2003\u2003return;"]},{"entry":[{},"90\u2002: \u2003\u2003\u2003}"]},{"entry":[{},"100: \u2003\u2003}"]},{"entry":[{},"110: \u2003\u2003\u2003fat_lock(o->lock)"]},{"entry":[{},"120: \u2003\u2003\u2003return;"]},{"entry":[{},"130: }"]},{"entry":[{},"150: void unlock (o){"]},{"entry":[{},"160: \u2003\u2003If (o->lock=\u2009=thread_id(\u2009))"]},{"entry":[{},"170: \u2003\u2003\u2003o->lock=0;"]},{"entry":[{},"180: \u2003\u2003else"]},{"entry":[{},"190: \u2003\u2003\u2003\u2003fat_unlock(o->lock);"]},{"entry":[{},"200: }"]},{"entry":[{},"220: void inflate(o){"]},{"entry":[{},"230; \u2003\u2003o->lock=alloc_fat_lock(\u2009) | FAT_LOCK;"]},{"entry":[{},"240: \u2003\u2003fat_lock(o->lock);"]},{"entry":[{},"250: }"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"In Table 2, pseudo codes at the lines  to  represent a locking function, pseudo codes at the lines  to  represent an unlocking function, and pseudo codes at the lines  to  represent an inflate function used in the locking function. In the locking function, locking by the thin lock is attempted at the line . If the lock is acquired, access to the object is executed. Unlocking with respect to a thread identifier input at the line  to the field for locking of the object is performed by inputting  to the field at the line . Thus, the high-frequency path can be executed at a high speed as in the case of a spin lock. On the other hand, if the lock cannot be acquired at the line , a determination is made at the line  as to whether a condition defined by a while statement, i.e., the result of bit-by-bit AND operation on the FAT_LOCK bit, which is the least significant bit of the locking field, and the bits in the locking field, is zero, that is, whether the FAT_LOCK bit is zero (more specifically, whether locking by the thin lock is designated). If this condition is satisfied, yield is effected until the thin lock is acquired at the line . When the thin lock is acquired, the inflate function from the line  is executed. In the inflate function, a fat lock identifier and the logical value  FAT_LOCK bit are input to the locking field o->lock (line ). The fat lock is then acquired (line ). If the FAT_LOCK bit is already  at the line , the fat lock is immediately acquired (line ). Unlocking of the fat lock is performed at the line . Acquisition and unlocking of the fat lock are not particularly specified in the present invention and, therefore, will not be described.","It is to be noted here that only the thread maintaining the thin lock rewrites the locking field. The same can be said with respect to unlocking. Yield occurs only at the time of contention for the thin lock.","Another example of the composite lock without yield in acquisition of the thin lock will be described. A wait is required in the case of contention in attempting locking by the thin lock. When the thin lock is released, it is necessary to notify the waiting thread of the release of the thin lock. For this wait and notification, a condition variable, a monitor or Semaphore is required. A description will be made below with respect to a case of using a monitor.",{"@attributes":{"id":"p-0027","num":"0025"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 3"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"10\u2002:void lock (o) {"]},{"entry":[{},"20\u2002: \u2003\u2003if (compare_and_swap (&o->lock, 0, thread_id(\u2009))"]},{"entry":[{},"30\u2002: \u2003\u2003\u2003return; 40 : monitor_enter (o);"]},{"entry":[{},"50\u2002: \u2003\u2003\u2003while (! (o->lock, & FAT_LOCK)){"]},{"entry":[{},"60\u2002: \u2003\u2003\u2003\u2003if (compare_and_swap(&o->lock, 0, thread_id(\u2009)){"]},{"entry":[{},"70\u2002: \u2003\u2003\u2003\u2003\u2003inflate(o);"]},{"entry":[{},"80\u2002: \u2003\u2003\u2003\u2003\u2003monitor_exit(o);"]},{"entry":[{},"90\u2002: \u2003\u2003\u2003\u2003\u2003return;"]},{"entry":[{},"100: \u2003\u2003\u2003\u2003} else"]},{"entry":[{},"110: \u2003\u2003\u2003\u2003\u2003\u2003monitor_wait(o);"]},{"entry":[{},"120: \u2003\u2003}"]},{"entry":[{},"130: \u2003\u2003monitor_exit(o);"]},{"entry":[{},"140: \u2003\u2003fat_lock(o->lock);"]},{"entry":[{},"150: \u2003\u2003return;"]},{"entry":[{},"160: }"]},{"entry":[{},"180: void unlock (o) {"]},{"entry":[{},"190: \u2003\u2003if (o->lock =\u2009= thread_id(\u2009)) {"]},{"entry":[{},"200: \u2003\u2003\u2003o->lock=0;"]},{"entry":[{},"210: \u2003\u2003\u2003monitor_enter(o);"]},{"entry":[{},"220: \u2003\u2003\u2003monitor_notify(o);"]},{"entry":[{},"230: \u2003\u2003\u2003monitor_exit(o);"]},{"entry":[{},"240: \u2003\u2003} else"]},{"entry":[{},"250: \u2003\u2003\u2003fat_unlock(o->lock);"]},{"entry":[{},"260: }"]},{"entry":[{},"280: void inflate (o) {"]},{"entry":[{},"290: \u2003\u2003o->lock = alloc_fat_lock(\u2009) | FAT_LOCK"]},{"entry":[{},"300: \u2003\u2003fat_lock(o->lock);"]},{"entry":[{},"310: \u2003\u2003monitor_notify_all(o);"]},{"entry":[{},"320: }"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"The monitor is a sync mechanism devised by Hoare to enable exclusive control of access to an object (enter and exit), a waiting operation of a thread when a predetermined condition is satisfied (wait), an operation for notifying the waiting thread (notify and notify_all) (see Hoare, C. A. R. Monitors: An operating system structuring concept. Communications of ACM 17, 10 (October 1974), 549-557). One thread at most is permitted to enter the monitor. When a thread T is about to enter a monitor m, it is made to wait if some other thread S has already entered. The thread T waits at least before the thread S exits from the monitor m. Exclusive control is thus performed. The thread T having entered the monitor m can wait at the monitor m for a situation in which a certain condition is satisfied. More specifically, the thread T implicitly exits from the monitor m and suspends. It is to be noted here that after the thread T has implicitly exited from the monitor m, another thread can enter the monitor m. On the other hand, the thread S having its entry in the monitor m can give a notice to the monitor m of the entry after satisfying a certain condition. Then, for example, one thread U in threads waiting at the monitor m is waked up. The thread U resumes thereby and attempts to implicitly enter the monitor m. It is to be noted that since the thread A has its entry in the monitor m, the thread U is made to wait at least before the thread S exits from the monitor m. If there is no thread waiting a the monitor m, nothing happens. Instruction \u201cnotify_all\u201d is the same as \u201cnotify\u201d except for waking up all of waiting threads.","Referring to Table 3, the lines  to  represent a locking function, the lines  to  represent an unlocking function, and the lines  to  represent an inflate function. The difference from the composite lock example 1 with respect to the locking function resides in entering the monitor at the line , waiting without effecting yield in the case of contention for the thin lock (line ), and exiting from the monitor when transition to the fat lock is made (line ) and when transition to the fat lock is confirmed. It is to be noted here that an exit from the monitor is made at the line  and the fat lock is acquired at the line .","The difference from the composite lock example 1 with respect to the unlocking function resides in processing for entering the monitor at the lines  to , giving a notice to the monitor, and exiting from the monitor. This is because yield is not effected and waiting at the monitor is performed instead of yield. In the inflate function, notify_all is added. This is also because yield is not effected and waiting at the monitor is performed instead of yield. The line  represents an OR operation on the fat lock identifier obtained by alloc_fat_lock( ) and FAT_LOCK bit set to a logical value 1, and an operation for inputting the result of the OR operation.","Referring to Table 3, while yield is removed, an operation for notification (notify) is provided since there is a possibility of existence of a thread waiting at the time of unlocking, resulting in a reduction in the performance of the high-frequency path. Also, for spatial efficiency, the monitor or an additional function equivalent to the monitor is required. However, the monitor or the additional function become unnecessary after transition to the fat lock. In other words, it is necessary to separately prepare the monitor and the fat lock.","This example of the composite lock, unlike Example 1, does not have the fat lock and the monitor separately provided. In this example, FAT_LOCK bit indicates transition to the fat lock and, after entry in the monitor, processing is performed by assuming that the fat lock has been acquired. See, for example, David F. Bacon, Ravi Konuru, Chet Murthy, and Mauricio Serrano. Thin Locks: Featherweight Synchronization for Java\u00ae. Proceedings of the SIGPLAN '98 Conference on Programming Language Design and Implementation (1998), pp. 258-268. According to this thesis, yield is effected.","The tasuki lock disclosed below is a composite method which does not reduce the high-frequency-path processing speed, which does not use,yield and does not separately prepare a fat lock and a monitor, in which the FAT_LOCK bit indicates transition to the fat lock, and which enables processing after an entry into the monitor by assuming that the fat lock has been acquired. While no consideration is given to transition from the fat lock to the thin lock with respect to the composite locks shown in Tables 2 and 3, the tasuki lock described below enables transition from the fat lock to the thin lock.","In the tasuki lock, a contention bit for prevention of a reduction in the high-frequency-path processing speed is newly introduced. As shown in ,  is stored in each of a locking field and the contention bit in a case where no thread locking an object exists (case ()). Thereafter, when a thread locks the object (by the thin lock), the identifier of the thread is stored in the locking field (case ()). If no other thread attempts to lock the object before the thread designated by this thread identifier unlocks the object, the state () occurs again. If some other thread attempts to lock the object before unlocking, contention for the thin lock occurs and the contention bit is set to record this contention (case ()). Thereafter, when transition to the fat lock is made, the contention bit is cleared (case ()). The bit indicating the thin lock mode or the fat lock mode (FAT_LOCK bit) may be set as the most significant bit in the locking field instead of being set as the least significant bit.","Processing for the tasuki lock using the above-described contention bit and locking field will be described.",{"@attributes":{"id":"p-0036","num":"0034"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 4"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"10\u2002: void lock (Object* o) {"]},{"entry":[{},"20\u2002: \u2003\/* thin lock *\/"]},{"entry":[{},"30\u2002: \u2003if (compare_and_swap (&o->lock, 0, thread_id( )))"]},{"entry":[{},"40\u2002: \u2003\u2003return;"]},{"entry":[{},"50\u2002: \u2003\/* fat lock and mode transition path *\/"]},{"entry":[{},"60\u2002: \u2003MonitorId mon=obtain_monitor(o);"]},{"entry":[{},"70\u2002: \u2003monitor_enter(mon);"]},{"entry":[{},"80\u2002: \u2003\/* mode transition loop *\/"]},{"entry":[{},"90\u2002: \u2003while (o->lock & FAT_LOCK) = =0) {"]},{"entry":[{},"100: \u2003\u2003set_flc_bit(o);"]},{"entry":[{},"110: \u2003\u2003if (compare_and_swap (&o->lock, 0, thread_id( )))"]},{"entry":[{},"120: \u2003\u2003\u2003inflate (o, mon);"]},{"entry":[{},"130: \u2003\u2003else"]},{"entry":[{},"140: \u2003\u2003\u2003monitor_wait (mon);"]},{"entry":[{},"150: \u2003}"]},{"entry":[{},"160:"]},{"entry":[{},"170: }"]},{"entry":[{},"180:"]},{"entry":[{},"190: void unlock (Object* o) {"]},{"entry":[{},"200: \u2003\/* thin lock path *\/"]},{"entry":[{},"210: \u2003if ((o->lock & FAT_LOCK) = =0)"]},{"entry":[{},"220: \u2003\u2003o->lock=0;"]},{"entry":[{},"230: \u2003\u2003\u2003if (test_flc_bit(o)) { \/* overhead of the present"]},{"entry":[{},"invention *\/"]},{"entry":[{},"240: \u2003\u2003\u2003MonitorId mon=obtain_monitor(o);"]},{"entry":[{},"250: \u2003\u2003\u2003monitor_enter(mon);"]},{"entry":[{},"260: \u2003\u2003\u2003if (test_flc_bit(o))"]},{"entry":[{},"270: \u2003\u2003\u2003\u2003monitor_notify(mon);"]},{"entry":[{},"280: \u2003\u2003\u2003monitor_exit(mon);"]},{"entry":[{},"290: \u2003\u2003}"]},{"entry":[{},"300: \u2003\u2003return;"]},{"entry":[{},"310: \u2003}"]},{"entry":[{},"320: \u2003\/* fat lock path *\/"]},{"entry":[{},"330: \u2003x=o->lock"]},{"entry":[{},"340: \u2003\u2003if (there is no thread waiting at the monitor with"]},{"entry":[{},"respect to o)"]},{"entry":[{},"350: \u2003\u2003if (a predetermined condition is satisfied)"]},{"entry":[{},"360: \u2003\u2003\u2003o->lock=0; \/* transition from fat lock to thin lock"]},{"entry":[{},"*\/"]},{"entry":[{},"370: \u2003\u2003monitor_exit ( x & \u02dcFAT_LOCK );"]},{"entry":[{},"380: }"]},{"entry":[{},"390:"]},{"entry":[{},"400:"]},{"entry":[{},"410: void inflate (Object* o, MonitorId mon) {"]},{"entry":[{},"420: \u2003clear_flc_bit;"]},{"entry":[{},"430: \u2003monitor_notify_all (mon);"]},{"entry":[{},"440: \u2003o->lock= (Word) mon | FAT_LOCK;"]},{"entry":[{},"450: }"]},{"entry":[{},"460:"]},{"entry":[{},"470:"]},{"entry":[{},"480: MonitorId obtain_monitor(Object* o) {"]},{"entry":[{},"490: \u2003Word word=o->lock;"]},{"entry":[{},"500: \u2003MonitorId mon;"]},{"entry":[{},"510: \u2003if (word & FAT_LOCK)"]},{"entry":[{},"520: \u2003\u2003mon = word & \u02dcFAT_LOCK;"]},{"entry":[{},"530: \u2003else"]},{"entry":[{},"540: \u2003\u2003mon = lookup_monitor(o);"]},{"entry":[{},"550: \u2003return mon;"]},{"entry":[{},"560: }"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"The contention bit introduced into the tasuki lock is shown as flc_bit in Table 4. The contents of Table 4 will be described in detail. Table 4 is divided into four major sections: a section corresponding to a locking function (lines  to ), a section corresponding to an unlocking function (lines  to ), a section corresponding to an inflate function for transition from the thin lock to the fat lock (lines  to ), and a section corresponding to a function obtain_monitor for obtaining the identifier of the monitor (lines  to ).","(1) Locking Function:","In processing for the locking function starting from the line  with respect to the object o, acquisition of the thin lock is attempted (line ). For this thin lock acquisition, an atomic instruction, e.g., compare_and_swap is used. This instruction is such that if a first argument and a second argument are the same value, a third argument is stored. More specifically, if o->lock which is the locking filed for the object o is equal to 0, the thread identifier is obtained by thread_id( ) and stored in the locking field o->lock, thereby making transition from () to () of FIG. . Then, to perform the necessary processing, a return is made (line ). If the object o locking field o->lock is not equal to 0, thin lock acquisition ends in failure and transition to the line  is made. The processing to this step is the same as that of the codes shown in Table 3.","Next, the value of the obtain_monitor (o) for obtaining the identifier of the monitor is substituted in a variable \u201cmon\u201d (line ) and a thread attempts to make a transition to a state under exclusive control performed by the monitor. That is, the thread attempts to enter the monitor (line ). If the threads succeeds in making transition to a state under exclusive control, processing described below is performed. In the case of failure, the thread waits until it succeeds in making this transition. Subsequently, determination as to a condition defined by a while statement. That is, the result of bit-by-bit AND operation on the locking field o->lock and the FAT_LOCK bit is performed to make a determination as to whether the FAT_LOCK bit is 1 (line ). In this processing, determination is made as to whether transition to the fat lock has been made or the thin lock is on. If the FAT_LOCK bit is not 1 (the thin lock is on), the result of this computation is 0 and processing after the while statement is performed. If the FAT_LOCK bit is 1 (the fat lock is on), the processing from the while statement is not performed and the state under the monitor after entry is maintained. Thus, success in entering the monitor when the FAT_LOCK bit is 1 means that the fat lock has been obtained in the tasuki lock. In this case, the thread performs processing on the object without exiting from the monitor (i.e., exiting from the state under exclusive control).","If it is determined at the line  that the FAT_LOCK bit is not 1, flc_bit is set (line 100, set_flc_bit(o)) since this determination result means occurrence of contention for the thin lock. Transition from (2) to (3) of  is thereby made. Then, determination is again made as to whether the thin clock can be obtained (line ). If the thin lock cannot be obtained, processing is performed for transition from the thin lock to the fat lock by the inflate function (line ). If the thin lock cannot be obtained, transition to a state of waiting at the, monitor is made (line ). Transition to the state of waiting at the monitor comprises exiting from the monitor and suspending, as described above in the description of the monitor. Thus, when contention for the thin lock occurs, the contention bit flc_bit is set and transition to the state of waiting at the monitor is made if the thin lock cannot be obtained. The thread having entered the waiting state receives a notice (notify or notify_all) at the time of processing by the inflate function or unlocking.","(2) Inflate Function:","Processing by the inflate function at the lines  to  will be described. In this processing, the contention bit is cleared (line , clear_flc_bit), and a monitor notification operation (monitor_notify_all) is performed (line ). In this processing, a notification is made such that all of threads in the waiting state are waked up. The result of bit-by-bit OR operation on the variable \u201cmon\u201d in which the monitor identifier is stored and the set FAT_LOCK bit is stored in the locking field o->lock (line , mon|FAT_LOCK). That is, transition from (3) to (4) of  is made. Transition from the thin lock to the fat lock is thereby completed. After the completion of processing at the line , the condition defined by the while statement is again checked. In this case, since the FAT_LOCK bit has already been set to 1, an exit is made from the while statement and the state under the monitor after entry is maintained. That is, processing in the while statement is not executed.","All the threads having received the notification implicitly attempt to enter the monitor at the line , but wait before entering the monitor. This is because the thread that has made notification does not exit from the monitor before unlocking is performed.","() Unlocking Function:","Processing by the unlocking at the lines  to  function will be described. By the unlocking function, unlocking of the thin lock and unlocking of the fat lock are performed. For unlocking of the fat lock, transition from (4) to (1) of  is made.","(3-1) Unlocking of Thin Lock:","To unlock the thin lock, bit-by-bit AND operation on the locking field o->lock and the FAT_LOCK bit is first performed and determination as to whether or not the value obtained by this operation is 0 (line ). This processing is the same as the condition defined by the while statement at the line  and is performed to determine when the thin lock is on. If the thin lock is on, 0 is stored in o->lock (line ). The fact that there is no thread holding the lock is thereby recorded. Determination is then made as to whether or not the contention bit is set (line , test_flc_bit). Even if no contention for the thin lock has occurred, it is necessary to execute at least the line . Thus, the only one overhead for the high-frequency path in the tasuki lock is the line . If the contention bit is not set, unlocking processing is terminated without performing any other processing (line ).","If the contention bit is set, the monitor identifier is stored in the variable \u201cmon\u201d (line ), as at the lines  and , and a thread attempts to enter the monitor identified with the monitor identifier (line ). That is, the thread attempts to enter the state under exclusive control performed by the monitor. If the thread enters the monitor, determination is again made as to whether the contention bit is set (line ). If the contention bit is set, one of the threads in the state of waiting at the monitor is notified of wake-up (line , monitor_notify(mon)). In the case of failure to enter the monitor, the thread attempting to enter the monitor waits until it becomes able to enter. The thread that has made the notification exits from the state under exclusive control performed by the monitor (line , monitor-exit(mon)).","The thread receiving the notification at the line  implicitly enters the monitor at the line . The process then returns to the line  and processing at the line is performed. Ordinarily, the thread receiving the notification at the line  enters the state under exclusive control performed by the monitor after the thread that has made the notice has exited from the state under exclusive control performed by the monitor and obtains the thin lock after setting of the contention bit. Processing by the inflate function is then performed to make transition to the fat lock.","(3-2) Unlocking of Fat Lock:","If it is found at the line  that the FAT_LOCK bit is 1, the process moves to the line . At the line , the contents of the locking field are stored in a variable x, and determination is made as to whether there is any other thread in the state of waiting at the monitor (line ). If no thread in the waiting state exists, determination is made as to whether a predetermined condition is satisfied (line ). If a situation should be considered where it is desirable to avoid exiting from the fat lock, a condition for avoiding exiting from the fat lock in such a situation is set as the predetermined condition. This step, however, may be omitted. If the predetermined condition is satisfied, the locking field o->lock is set to 0 (line ). That is, information indicating that there is no thread holding the lock is stored in the locking field. An exit is then made from the monitor identified with the monitor identifier stored in the portion of the variable x other than the FAT_LOCK bit (line ). In the line , x & \u02dcFAT_LOCK is the bit-by-bit AND of the inverted FAT_LOCK bit and x. The thread waiting to enter the monitor is thereby enabled to enter the monitor.","(4) Function Obtain_Monitor for Obtaining Monitor Identifier:","In this function, the contents of the locking field are stored in a variable \u201cword\u201d (line ). The variable \u201cmon\u201d for storing the monitor identifier is prepared (line ) and determination Is made as to whether the FAT_LOCK bit is  (line , word & FAT_LOCK). If the FAT_LOCK bit is , the portion of the variable \u201cword\u201d other than the FAT_LOCK bit is stored in the variable \u201cmon\u201d (line , word & \u02dcFAT_LOCK). If the FAT_LOCK bit is not 1, a function lookup_monitor(o) is executed (line ). This function is used on the assumption that it has a hash table in which the relationship between objects and monitors is recorded, although the existence of such a table is not indicated in Table 4. Basically, this table is searched with respect to the object o to obtain the identifier of the monitor. If necessary, a monitor is generated, the identifier of the monitior is stored in the hash table, and the monitor identifier is thereafter returned. In either case, the identifier of the monitor stored in the variable \u201cmon\u201d is returned.","The composite lock shown in Table 4 differs largely from that shown in Table 3 in that the contention bit is introduced, that no processing exists between the line  and the line , and that transition from the fat lock to the thin lock at the lines  to  exists. Introduction of the contention bit necessitates checking at the line , but a large penalty is imposed as shown in Table 3 if the contention bit is not introduced. Also, since acquisition of the fat lock is recognized when the FAT_LOCK bit is 1 and when transition to the state under exclusive control performed by the monitor is made, the need for preparing a fat lock mechanism other than the monitor is eliminated and processing for an exit from the state under exclusive control performed by the monitor and acquisition of the fat lock is removed, thereby achieving an increase in processing speed. Also, transition from the fat lock to the thin lock (from () to () of ) is provided to enable return to a state where the high-frequency path (transition between () and () of ) can be executed with a small load.","There is no problem with setting the contention bit at the line  in Table 4 and checking the contention bit at the line , as described below. It should first be noted that \u201cthe contention bit is cleared only by the inflate function\u201d.","With respect to a situation where the thread T waits, the effect of enabling the thread T to be unfailingly notified will be described with respect to following two cases.","(1) A case where the inflate function is thereafter executed. When the inflate function is executed, notify_all is executed at the line . That is, the thread T is notified.","(2) A case where the inflate function is not executed. The thread T waits because of failure to acquire the thin lock at the line . At the point in time corresponding to failure at the line , another thread S is holding the thin lock. That is, the thread S is in a state before execution of the unlocking function at the line . Also, the contention bit set by the thread T before waiting is maintained in the set state due to the condition noted above, since the inflate function is not executed in this case. The thread S thereafter reaches the stage corresponding to the unlocking function at the line  and executes the next check of the contention bit. This check necessarily ends in success. That is, the thread T is notified by the thread S.","Also, transition from () to () of  is introduced. This is safe processing (1) because, while it is necessary for one thread to attain success in compare_and_swap in order to acquire the thin lock, success cannot be attained in compare_and_swap as long as some other thread is holding the fat lock, and the impossibility of acquiring the thin lock when the other thread is holding the fat lock is therefore ensured, and (2) because, while for acquisition of the fat lock by one thread it is necessary that the thread enter the monitor and that the condition defined by the while statement be not satisfied, the condition defined by the while statement is necessarily satisfied as long as some other thread is holding the fat lock and the impossibility of acquiring the thin lock when the other thread is holding the fat lock is therefore ensured, even though entry in the monitor is possible.","The tasuki lock is an improved algorithm, but it has been impossible to efficiently implement the tasuki lock in advanced CPUs. The cause of this impossibility resides in the memory access order required by the tasuki lock. The memory access order to be referred to as a tasuki constraint will be briefly described before the description of the cause. The tasuki lock requires the memory access order shown below to realize a starvation free characteristic. Unlocking of the tasuki lock is performed in the order of clearing the thread ID (TID field: thread identification field) and referring to the flat lock contention bit (flc bit). Also, the waiting operation after failure to secure the tasuki lock is performed in the order of setting the flc bit and referring to the TID field. Once operations are performed out of these store-load memory access orders, some of threads which require memory access will never be waked up.","There is a considerable problem with the tasuki constraint particularly in a multiprocessor environment where a CPU of an advanced architecture is used. An advanced CPU architecture with which a considerable tasuki lock problem exists is, for example, one in which the CPU changes the load-store order in an original program and uses out-of-order execution of a load operation outrunning a store operation. It is very important to conceal the load latency in program execution time, and out-of-order load greatly contributes to concealment of the apparent latency. Therefore almost all CPUs have a mechanism for such out-of-order execution of a load. In such CPUs in actual use, the tasuki constraint cannot be met even if programs are written so as to meet the tasuki constraint.","To meet the tasuki constraint, it is necessary to ensure particularly explicit serialization such that a load operation does not outrun a store operation. Presently existing instructions for explicit serialization are fence and sync (or instructions belonging to them). A fence instruction completes, before fence execution, all preceding memory access instructions preceding it on a program, and starts, after fence execution, all memory access instructions following it on the program. A sync instruction is similar to the fence instruction, but handles all instructions not limited to memory access instructions. For example, in the case of Intel Pentium\u00ae , there are three fence instructions: lfence, sfence, and mfence, and sync instructions include an instruction with a lock prefix, an I\/O instruction, and a CPUID instruction. (Pentium\u00ae II or Pentium\u00ae III also has similar instructions.) Power PC has a sync instruction.","The tasuki constraint in the tasuki lock will be described with reference to FIG. . To execute the tasuki lock, an object header is provided in correspondence with each of objects. The object header is formed of three words (one word being formed of 32 bits). A contention bit, i.e., a flat lock contention (flc) bit, is placed in the first word of the object header, and a thread ID (TID) is placed in the third word of the object header. In a thread A, codes of a store instruction for releasing an object and a load instruction are written by being serialized. These store and load instructions correspond to the line  and the line  in Table 4. That is, the store instruction clears the TID, and the load instruction writes the value of the flc bit to a register. On the other hand, in a thread B, codes of a store instruction for locking an object and a load instruction are written by being serialized. These store and load instructions correspond to the line  and the line  in Table 4. That is, the store instruction clears the flc bit, and the load instruction writes the value of the TID to the register. The contents of the memory stored by each thread must be visible from other threads. Therefore it is necessary to strictly keep serialization of the store instruction and store buffer in each thread. In advanced CPU multiprocessor environments, however, to conceal the load instruction latency, out-of-order execution of instructions is made in such a manner that a load instruction is executed before a store instruction even though the load instruction follows the store instruction in the state of being serialized on the program. For example, in the thread B, the flc bit is set to make a transition from () to () of  with respect to the object o and processing after the transition is started. At this time, in the thread A, the flc bit of the object not set yet is read and unlocking processing to be performed under non-contending condition with respect to the object o is executed by determining that there is no contention, that is, unlocking processing is terminated when it is determined that there is no contention (return at the line  of Table 4), so that the notification (notify at the line  of Table 4) to the thread in the waiting state is not sent and the thread in the waiting state continues waiting endlessly. Therefore it is necessary to strictly keep the order of a certain pair of store and load instructions as the tasuki constraint in memory access serialization.",{"@attributes":{"id":"p-0059","num":"0057"},"figref":"FIG. 3","b":["3","3"],"i":["a","b"]},"The problem with use of the fence instruction is that a considerably large overhead occurs if such an explicit serialization instruction is executed. Therefore, in an implementation of the tasuki lock using an explicit serialization instruction necessary in an advanced CPU, the advantage that only one atomic instruction suffices is lost. Thus, the high-balance tasuki lock algorithm capable of ensuring high-speed locking and efficient lock wait has not been implemented on current CPUs having an out-of-order load execution mechanism by imposing the tasuki restraint without losing its balance.","An object of the present invention is to provide a method, an apparatus, a program and a recording medium for performing memory access serialization and lock management so as to ensure the desired reliability with which store instructions and load instructions are serialized in a program with respect to memory access in spite of the load instruction out-of-order execution function of the CPU without impairing the high-speed performance.","According to the present invention, a mechanism which is implicitly provided in a CPU so as not to change the meaning of a program, and use of which is ordinarily avoided, is positively used. This technique is called store forwarding avoidance (SFA). This technique is used not only for the tasuki lock (the algorithm shown in Table 4) but also to ensure memory access serialization in other fields if conditions described below are satisfied.","In CPUs making out-of-order execution of load, it is important to conceal the load latency. Many of such CPUs has a store forwarding (SF) mechanism for enabling results of store to be used in the CPU by being loaded into the CPU. In such CPUs, for speedup of store execution, store results are temporarily stored in a store buffer and thereafter written to a memory hierarchy. If a load is executed in the same CPU by referring to the store results, the store results can be immediately read from the store buffer by store forwarding. Thus, the latency with respect to reading from the memory hierarchy can be concealed. There are several conditions for enabling SF (considered ordinary conditions for efficient use of resources according to a hardware design). Typically, a memory to be accessed is of the same address and the same size. For example, the result of 4-byte storage at address  is store-forwarded by an instruction for 4-byte load from the address . However, the result of 4-byte storage at address  is not store-forwarded by an instruction for 8-byte load from the address . If store forwarding is not performed, the store result is written from the store buffer to the memory hierarchy, and read from the memory hierarchy is performed for load. That is, when store forwarding is not performed, out-of-order execution of load is not executed by outrunning store. The key point of the present invention resides in positive use of this characteristic.","A computer with which a memory access serialization method of the present invention is executed has a plurality of CPUs and a memory shared by the plurality of CPUs. Each CPU has an out-of-order execution stop mechanism. If address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and subsequent positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from the other CPUs before execution of the load instruction. The computer memory access serialization method includes a detection step of enabling each CPU to detect the pair of the store instruction and the load instruction, which need to be serialized in a before-after relationship with respect to memory access, which are in the preceding and following positions in written order on the program, and which are placed on the program by being set so that their address regions have an overlap therebetween and respectively include address regions for data which needs to be stored and loaded, and an activation step of activating, with respect to the detected pair of instructions, the out-of-order execution stop mechanism of one of the CPUs executing the program relating to the detected pair of instructions.","The memory access serialization method of the present invention is not limited to an application to an object lock management method described below. In the memory access serialization method, with respect to a store instruction and a load instruction in preceding and subsequent positions in written order of a program, memory access operations are serialized in accordance with serialization on the program in spite of the out-of-order execution function of the CPU. The computer with which the memory access serialization method of the present invention is implemented is not limited to the type in which each CPU has a store buffer and is capable of store forwarding (SF) and store forwarding avoidance (SFA). The memory access serialization method of the present invention can also be applied to computers in which each CPU does not have a store buffer and SF and SFA mechanisms. Preferably, the memory access serialization method of the present invention includes a step of extracting essentially necessary data from data loaded by the load instruction in the above-mentioned pair of instructions with an address region increased relative to that for data which essentially needs to be loaded, to enable activation of the out-of-order execution stop mechanism. For compatibility with such an extraction step, the address region of the load instruction in the pair of instructions is set so that data which does not need to be loaded is loaded as well as data which essentially needs to be loaded, while the address region of the store instruction is set so as to load only data which essentially needs to be stored.","According to a preferable memory access serialization method, each CPU has a store buffer for writing data to the memory according to the store instruction of the program. The out-of-order execution stop mechanism has a store forwarding (SF) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and notifies, as data B, of data A written to the store buffer according to the store instruction in the pair of instructions from the store buffer to the program if the address regions on the memory relating to the pair of instructions coincide with each other, and a store forwarding avoidance (SFA) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and performs, instead of SF, storing of data A from the store buffer into a memory hierarchy and notifying of data B from the memory hierarchy to the program on the basis of the load instruction in the pair of instructions if the address regions on the memory relating to the pair of instructions do not coincide with each other but overlap each other. In the activation step, the CPU executing the program relating the detected pair of instructions is made to activate the SFA mechanism in the out-of-order execution stop mechanism with respect to the pair of instructions.","Another preferable memory access serialization method sets the address region of the load instruction so as to load data which does not need to be loaded as well as data which needs to be loaded, while setting the address region of the store instruction so as to store only data which essentially needs to be stored, and includes a load instruction execution step of executing load of data on this load instruction, and an extraction step of extracting the data which needs to be loaded from the data loaded by the load instruction. For example, the program includes first and second program portions relating to first and second processings, the first and second processings including a store processing portion, an observation processing portion for observing data that might have been stored by the other processing after execution of the store processing portion, and a branching processing portion for branching to a corresponding process according to a result of observation by the observation processing portion. The pair of the store instruction and the load instruction are included in the store processing portion and the observation processing portion in the first and, second processings. Preferably, the first and second processings are processing relating to object lock release and processing relating to object acquisition, respectively, in an object management method.","A computer with which a lock management method of the present invention is executed has a plurality of CPUs and a memory shared by the plurality of CPUs. Each CPU has an out-of-order execution stop mechanism. If address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and following positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from other CPUs before execution of the load instruction. According to the lock management method of the present invention, a lock on an object is managed by preparing, in a storage area provided in correspondence with the object, a field for storing a bit indicating the kind of lock and an identifier for a thread acquiring a lock according to the first kind of lock or an identifier relating to the second kind of lock, in a situation where a plurality of threads exist. The lock management method of the present invention includes an object acquisition method of enabling a second thread to obtain a lock on a certain object held by a first thread, and a lock release method of enabling the first thread to release the lock from the certain object. The object acquisition method includes (a1) a step of determining whether or not the bit indicating the kind of lock on the certain object indicates the first kind of lock, and (a2) a step of setting a contention bit when the first kind of lock is indicated. The lock release method includes (b1) a step of determining whether or not the bit indicating the kind of lock indicates the first kind of lock, (b2) a step of storing, in the storage area, information indicating that no thread holding the lock on the certain object existed (b3) a step of determining whether or not the contention bit is set when the bit indicating the kind of lock indicates the first kind of lock, and (b4) a step of terminating processing if it is determined that the contention bit is not set. Address regions on the memory relating to a store instruction S corresponding to storage in the step (b2) and a load instruction L corresponding to read of the bit in the step (b3) are set so that the out-of-order execution stop mechanism is activated with respect to the store instruction S and the load instruction L. The steps (b2) and (b3) are executed on the basis of this setting.","\u201cIdentifier relating the second kind of lock\u201d is the identifier of the monitor related to each object in the embodiment of the present invention. Steps (a1) and (a2) correspond to the lines  and , respectively, of Table 4. Steps (b1), (b2), (b3), and (b4) correspond to the lines , , , and , respectively, of Table 4.","Preferably, the lock release method further includes (b5) a step of enabling the first thread to enter a state under exclusive control performed by a mechanism when it is determined that the contention bit is set, the mechanism enabling exclusive control of access to the object and, if a predetermined condition is satisfied, a waiting operation of the thread and a notification operation to the thread in the waiting state, (b6) a step of executing a notification operation to the thread in the waiting state, and (b7) a step of enabling the first thread to exit from the state under exclusive control. Steps (b5), (b6), and (b7) correspond to the lines , , and , respectively, of Table 4.","The first kind of lock is, for example a lock method in which the state of lock on an object by a thread is managed by storing the identifier of the thread in correspondence with the object. The second kind of object is, for example, a lock method of managing the thread making access to the object by using a queue.","A computer with which another lock management method of the present invention is executed has a plurality of CPUs and a memory shared by the plurality of CPUs. Each CPU has an out-of-order execution stop mechanism. If address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and following positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from other CPUs before execution of the load instruction. According to the lock management method of the present invention, a lock on an object is managed by preparing, in a storage area provided in correspondence with the object, a field for storing a bit indicating the kind of lock and an identifier for a thread acquiring a lock according to the first kind of lock or an identifier relating to the second kind of lock which is a lock method of managing the thread making access to the object by using a queue, in a situation where a plurality of threads exist. The lock management method of the present invention includes (c1) a step of enabling a first thread to enter a state under exclusive control performed by a mechanism enabling exclusive control of access to the object and, if a predetermined condition is satisfied, a waiting operation of the thread and a notification operation to the thread in the waiting state, (c2) a step of determining whether or not the bit indicating the kind of lock on a certain object indicates the first kind of lock, (c3) a step of setting a contention bit when the bit indicating the kind of lock on the certain object indicates the first kind of lock, (c4) a step of determining, after the step (c3), whether or not the first thread can acquire the first kind of lock on the basis of the contents of the storage area provided in correspondence with the certain object; and (c5) a step of storing the bit indicating the second kind of lock and the identifier relating to the second kind of lock in the storage area provided in correspondence with the certain kind of object when the first thread can acquire the first kind of lock. The first thread exits from the state under exclusive control after the completion of necessary processing on the certain object. Address regions on the memory relating to a store instruction S corresponding to the setting of the contention bit in the step (c3) and a load instruction L corresponding to read of the contents of the storage area in the step (c4) are set so that the out-of-order execution stop mechanism is activated with respect to the store instruction S and the load instruction L. The steps (c3) and (c4) are executed on the basis of this setting.","Steps (c1), (c2), (c3), (c4), and (c5) correspond to the lines , , , , and , respectively, of Table 4.","Preferably, the lock management method further includes (c6) a step of enabling the first thread to enter a state of waiting at the mechanism when the first thread cannot acquire the first kind of lock, (c7) a step of performing processing without an exit of the first thread from the state under exclusive control by assuming that the first thread has acquired the second kind of lock when the bit indicating the kind of lock does not indicate the first kind of lock as the lock on the certain object, and (c8) a step of performing processing without an exit of the first thread from the state under exclusive control by assuming that the first thread has acquired the second kind of lock when the bit indicating the kind of lock indicates the second kind of lock as the lock on the certain object in the above-described step (c2). Step (c6) corresponds to the line  of Table 4. Step (c8) corresponds to entry of the first thread into the monitor at the line  of Table 4 and skipping the lines  to , as does step (c7). The condition in step (c7) is \u201cwhen the first kind of lock is not indicated\u201d, while the condition in step (c8) is \u201cwhen the second kind of lock is indicated\u201d. Preferably, the computer with which the lock management method is executed has a plurality of CPUs and a memory shared by the plurality of CPUs. Each CPU has an out-of-order execution stop mechanism. If address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and following positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from other CPUs before execution of the load instruction. According to the lock management method, a lock on an object is managed by preparing, in a storage area provided in correspondence with the object, a field for storing a bit indicating the kind of lock and an identifier for a thread acquiring a lock according to the first kind of lock or an identifier relating to the second kind of lock, in a situation where a plurality of threads exist. The lock management method includes an object acquisition method of enabling a second thread to obtain a lock on a certain object held by a first thread, and a lock release method of enabling the first thread to release the lock from the certain object. The object acquisition method includes (a1) a step of determining whether or not the bit indicating the kind of lock on the certain object indicates the first kind of lock, and (a2) a step of setting a contention bit when the first kind of lock is indicated. The lock release method includes (b1) a step of determining whether or not the bit indicating the kind of lock indicates the first kind of lock, (b2) a step of storing, in the storage area, information indicating that no thread holding the lock on the certain object exists, (b3) a step of determining whether or not the contention bit is set when the bit indicating the kind of lock indicates the first kind of lock, and (b4) a step of terminating lock release processing without performing any processing other than releasing the lock on the certain object if it is determined that the contention bit is not set. Address regions on the memory relating to a store instruction S corresponding to storage in the step (b2) and a load instruction L corresponding to read of the bit in the step (b3) are set so that the out-of-order execution stop mechanism is activated with respect to the store instruction S and the load instruction L. The lock release method further includes (d1) a step of determining whether or not the lock on the certain object acquired by the first thread is the second kind of lock, (d2) a step of determining whether or not any thread exists in a sate of waiting at the mechanism enabling exclusive control of access to the object and, if a predetermined condition is satisfied, a waiting operation of the thread and a notification operation to the thread in the waiting state when the lock on the certain object acquired by the first thread is the second kind of lock, and (d3) a step of storing, in the storage area, information indicating that no thread holding the lock exists if no other thread exists. Steps (d1), (d2), and (d3) correspond to the lines , , and , respectively, of Table 4.","According to a preferable lock management method, each CPU has a store buffer for writing data to the memory according to the store instruction of the program. The out-of-order execution stop mechanism has a store forwarding (SF) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and notifies, as data B, of data A written to the store buffer according to the store instruction in the pair of instructions from the store buffer to the program if the address regions on the memory relating to the pair of instructions coincide with each other, and a store forwarding avoidance (SFA) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and performs, instead of SF, storing of data A from the store buffer into a memory hierarchy and notifying of data B from the memory hierarchy to the program on the basis of the load instruction in the pair of instructions if the address regions on the memory relating to the pair of instructions do not coincide with each other but overlap each other. Also, the address regions on the memory relating to the store instruction S and the load instruction L are set to activate the store forwarding avoidance mechanism, and the steps (b2) and (b3) and the steps (c3) and (c4) are executed on the basis of this setting.","A computer implemented with a memory access serialization apparatus of the present invention has a plurality of CPUs and a memory shared by the plurality of CPUs. Each CPU has an out-of-order execution stop mechanism. If address regions on the memory relating to a part of a store instruction and a load instruction in preceding and subsequent positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from the other CPUs before execution of the load instruction. The computer memory access serialization apparatus includes detection means of enabling each CPU to detect the pair of the store instruction and the load instruction, which need to be serialized in a before-after relationship with respect to memory access, which are in the preceding and following positions in written order on the program, and which are placed on the program by being set so that their address regions have an overlap therebetween and respectively include address regions for data which needs to be stored and loaded, and activation means of activating, with respect to the detected pair of instructions, the out-of-order execution stop mechanism of one of the CPUs executing the program relating to the detected pair of instructions.","Preferably, the computer memory access serialization apparatus has a plurality of CPUs and a memory shared by the plurality of CPUs. Each CPU has a store buffer for writing data to the memory according to the store instruction of the program. The out-of-order execution stop mechanism has a store forwarding (SF) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and notifies, as data B, of data A written to the store buffer according to the store instruction in the pair of instructions from the store buffer to the program if the address regions on the memory relating to the pair of instructions coincide with each other, and a store forwarding avoidance (SFA) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and performs, instead of SF, storing of data A from the store buffer into a memory hierarchy and notifying of data B from the memory hierarchy to the program on the basis of the load instruction in the pair of instructions if the address regions on the memory relating to the pair of instructions do not coincide with each other but overlap each other. The activation means activates, with respect to the detected pair of instructions, the SFA mechanism in the out-of-order execution stop mechanism of one of the CPUs executing the program relating to the detected pair of instructions.","A preferable computer memory access serialization apparatus includes load instruction execution means of executing load of data on the basis of the load instruction in the pair of instructions, the address region of the store instruction being set so as to store only data which essentially needs to be stored, the address region of the load instruction being set so as to load data which does not need to be loaded as well as data which needs to be loaded, and extraction means of extracting the data which needs to be loaded from the data loaded by the load instruction. Preferably, the program includes first and second program portions relating to first and second processings, the first and second processings including a store processing portion, an observation processing portion for observing data that might have been stored by the other processing after execution of the store processing portion, and a branching processing portion for branching to a corresponding process according to a result of observation by the observation processing portion, and the pair of the store instruction and the load instruction are included in the store processing portion and the observation processing portion in the first and second processings. For example, the first and second processings are processing relating to object lock release and processing relating to object acquisition, respectively, in an object management apparatus.","An embodiment of the present invention will be described with reference to the accompanying drawings.",{"@attributes":{"id":"p-0080","num":"0078"},"figref":"FIG. 4","b":["10","10","12","14","20","14","20","14","20","18","14","20","18","20","18","18","14","10"]},{"@attributes":{"id":"p-0081","num":"0079"},"figref":"FIG. 5","b":["3","3"],"i":["a","b"]},{"@attributes":{"id":"p-0082","num":"0080"},"figref":["FIG. 6","FIG. 6"],"b":["32","34","36","32","38","30","34","36","38","32","30","36","10","32","38","32","34","36","32","30","38","38","32","30","30","30","34","30","36","38"]},{"@attributes":{"id":"p-0083","num":"0081"},"figref":["FIG. 7","FIG. 7"],"b":["38","38"]},"(a) A and A\u2032 are not perfectly the same.","(b) A\u2229A\u2032 is not an empty set.","When these two requirements are satisfied, the CPU  does not perform out-of-order execution of load instruction. Instead, the CPU  executes SFA. A\u2282A\u2032 satisfies the requirements (a) and (b). With respect to a load instruction, the CPU  gives higher priority to SF and SFA in comparison with that to out-of-order execution of the load instruction. Thus, data in the address area A is written from the store buffer  to the cache line . Data in the memory  may be temporarily different from data on the cache line  during operation of the CPU . However, coincidence therebetween is ensured. For speedup of data read\/write by the CPU , part of data in the memory  is copied to the cache line . The CPU  performs data read\/write on the cache line  as long as data exists on the cache line . The cache line  and the memory  belong to the memory hierarchy and the contents therein can be observed from any of the CPUs. In the present invention, SFA is positively utilized in order to ensure serialization of memory access in accordance with serialization of store instructions and load instructions on a program and to enable observation of data relating to a store instruction (to make data visible) from the other CPUs. In conventional computers, SFA occurs in cases of absolute necessity when SF cannot be executed, and SFA is of no value in terms of positive use.",{"@attributes":{"id":"p-0087","num":"0085"},"figref":["FIG. 8","FIG. 8","FIG. 8 and a","FIG. 8"],"b":["46","46","46","48","46","50","46","50","2","50","0","220","48","230","48","100","50","110","100","110","220","230"]},{"@attributes":{"id":"p-0088","num":"0086"},"figref":["FIG. 9","FIG. 9"],"b":"8"},{"@attributes":{"id":"p-0089","num":"0087"},"figref":["FIG. 10","FIG. 8","FIG. 10","FIG. 10"],"b":["30","30","32","32","10","30","30","34","34","36","36","36","54","34","36","30","32","36","36","32","36","36","32","36","1","4","30","30","32","30","34","1","36","2","36","30","3","30","36","32","4"],"i":["a ","b ","a ","b","a ","b ","a ","b ","a ","b","a ","a ","a","b ","b ","a ","a ","b ","a","b ","b","a ","b ","a","a ","a ","a ","b ","b ","b ","b ","b "]},{"@attributes":{"id":"p-0090","num":"0088"},"figref":"FIG. 11","b":["60","66","68","220","230","250","210","60","62","60","62","64","68"]},"CPUs such as Pentium\u00ae 4 and Power 4 operating on a higher clock and having a higher degree of out-of-order is supposed to have a higher serialization overhead. (As an experiment for checking this tendency, a microbenchmark test based on repeated execution of the Random-class nextint method, which is a typical synchronized method for Java\u00ae, was executed in an Intel IA-32 multiprocessor environment using an IBM Java\u00ae JIT compiler. The test was made on Pentium\u00ae III operating on a  MHz clock and on Pentium\u00ae 4 operating on a clock of 1.5 GHz 1.6 times higher. In the JITed code, lock cmpxchg instruction (required at the time of locking) +lock and instruction (required at the time of unlocking) are performed with respect to the synchronized method. Even though the nextint method has a suitable amount of computation (64-bit multiplication and shift), the influence of the serialization instruction recognized in the test results is large. According to the test results, Pentium\u00ae 4 is 2.7 times slower than Pentium\u00ae III due to the influence of the serialization instruction. If the clock ratio is considered, Pentium\u00ae 4 is 4.3 times slower than Pentium\u00ae III.) Therefore the access serialization effect based on use of SFA is high. A thin lock will be considered as a basis for comparison. A thin lock is said to be a prototype of the tasuki lock, and tasuki lock=thin lock+tasuki constraint. In the Random.next microbenchmark test on Pentium\u00ae 4, the performance of the tasuki lock is reduced to 65% of that of the thin lock due to the serialization instruction for the tasuki constraint (in the case of a lock prefix instruction, only 71% can be reached even if a mfence instruction, which is a new instruction, is used). The point is that at which level the performance of the thin lock is maintained when the tasuki constraint is introduced.","With respect to implementation with a SSE instruction, the performance of the thin lock has been completely recovered while SFA is applied to memory access serialization. Thus, elimination of spin-wait has been attained in a multiprocessor environment as well as in a single processor environment while the tasuki lock has substantially the same performance as the thin lock. This improvement has great significance with respect to the SPECjvm98 benchmark. The SPECjvm98 benchmark is a benchmark for checking the performance of a plurality of programs. However, only the mtrt program has two-thread parallelism. Therefore the performance of the mtrt program can be simply doubled in the case of execution with two processors. For this reason, many of the SPECjvm98 benchmark test results recently reported have been measured with respect to two processors. In the case of measurement with respect to two processors, however, it is natural that the speed of a program which frequently calls the synchronized method is reduced. Improvements achieved as a result of application of SFA are db 12%, java\u00ae c 7.3%, jack 3.2%, and geometric means 2.4%. These values are the results of the next best implementation by fild\/fistp on the present IBM Java\u00ae, and the best performance has not been attained because of occurrence of useless SFA by the test of fistp and the flc bit. It is to be noted that an implementation in which the TID field and the flc bit are in the same word, and which has been described with respect to , has the potential to further improve the performance.","For summary, configurations of the present invention are shown below.","(1) A method of memory access serialization in a computer having a plurality of CPUs and a memory shared by the plurality of CPUs, each CPU having an out-of-order execution stop mechanism, in which, if address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and subsequent positions, respectively, in written order of a Program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from the other CPUs before execution of the load instruction, the method including:","a detection step of enabling each CPU to detect the pair of the store instruction and the load instruction, which need to be serialized in a before-after relationship with respect to memory access, which are in the preceding and following positions in written order on the program, and which are placed on the program by being set so that their address regions have an overlap therebetween and respectively include address regions for data which needs to be stored and loaded; and","an activation step of activating, with respect to the detected pair of instructions, the out-of-order execution stop mechanism of one of the CPUs executing the program relating to the detected pair of instructions.","(2) The memory access serialization method described in (1), wherein each CPU has a store buffer for writing data to the memory according to the store instruction of the program;","wherein the out-of-order execution stop mechanism has a store forwarding (SF) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and notifies, as data B, of data A written to the store buffer according to the store instruction in the pair of instructions from the store buffer to the program if the address regions on the memory relating to the pair of instructions coincide with each other, and a store forwarding avoidance (SFA) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and performs, instead of SF, storing of data A from the store buffer into a memory hierarchy and notifying of data B from the memory hierarchy to the program on the basis of the load instruction in the pair of instructions if the address regions on the memory relating to the pair of instructions do not coincide with each other but overlap each other; and","wherein, in the activation step, with respect to the detected pair of instructions, the SFA mechanism in the out-of-order execution stop mechanism of one of the CPUs executing the program relating to the detected pair of instructions is activated.","(3) The memory access serialization method described in (1) or (2), further including:","a load instruction execution step of executing load of data on the basis of the load instruction in the pair of instructions, the address region of the store instruction being set so as to store only data which essentially needs to be stored, the address region of the load instruction being set so as to load data which does not need to be loaded as well as data which needs to be loaded; and","an extraction step of extracting the data which needs to be loaded from the data loaded by the load instruction.","(4) The memory access serialization method described in anyone of (1) to (3), wherein the program includes first and second program portions relating to first and second processings, the first and second processings including a store processing portion, an observation processing portion for observing data that might have been stored by the other processing after execution of the store processing portion, and a branching processing portion for branching to a corresponding process according to a result of observation by the observation processing portion; and","wherein the pair of the store instruction and the load instruction are included in the store processing portion and the observation processing portion in the first and second processings","(5) The memory access serialization method described in (4), wherein the first and second processings are processing relating to object lock release and processing relating to object acquisition, respectively, in an object management method.","(6) A method of lock management executed by a computer having a plurality of CPUs and a memory shared by the plurality of CPUs, each CPU having an out-of-order execution stop mechanism, in which, if address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and following positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from other CPUs before execution of the load instruction, the lock management method including:","managing a lock on an object by preparing, in a storage area provided in correspondence with the object, a field for storing a bit indicating the kind of lock and an identifier for a thread acquiring a lock according to the first kind of lock or an identifier relating to the second kind of lock, in a situation where a plurality of threads exist, the lock management method also including:","an object acquisition method of enabling a second thread to obtain a lock on a certain object held by a first thread, and a lock release method of enabling the first thread to release the lock from the certain object, the object acquisition method including:","(a1) a step of determining whether or not the bit indicating the kind of lock on the certain object indicates the first kind","of lock; and","(a2) a step of setting a contention bit when the first kind of lock is indicated, the lock release method including:","(b1) a step of determining whether or not the bit indicating the kind of lock indicates the first kind of lock;","(b2) a step of storing, in the storage area, information indicating that no thread holding the lock on the certain object exists;","(b3) a step of determining whether or not the contention bit is set when the bit indicating the kind of lock indicates the first kind of lock; and","(b4) a step of terminating processing if it is determined that the contention bit is not set,","wherein address regions on the memory relating to a store instruction S corresponding to storage in the step (b2) and a load instruction L corresponding to read of the bit in the step (b3) are set so that the out-of-order execution stop mechanism is activated with respect to the store instruction S and the load instruction L; and","wherein the steps (b2) and (b3) are executed on the basis of the setting of the address regions.","(7) The lock management method described in (6), wherein each CPU has a store buffer for writing data to the memory according to the store instruction of the program;","wherein the out-of-order execution stop mechanism has a store forwarding (SF) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and notifies, as data B, of data A written to the store buffer according to the store instruction in the pair of instructions from the store buffer to the program if the address regions on the memory relating to the pair of instructions coincide with each other, and a store forwarding avoidance (SFA) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and performs, instead of SF, storing of data A from the store buffer into a memory hierarchy and notifying of data B from the memory hierarchy to the program on the basis of the load instruction in the pair of instructions if the address regions on the memory relating to the pair of instructions do not coincide with each other but overlap each other; and","wherein the address regions on the memory relating to the store instruction S and the load instruction L are set to activate the SFA mechanism; and","wherein the steps (b2) and (b3) are executed on the basis of the setting of the address regions.","(8) The lock management method described in (6) or (7), wherein the store instruction S corresponding to the storage in the step (b2) is set with its address region selected as an address region A relating to the storage region in which information indicating that no thread holding the lock on the certain object exists is stored;","wherein the load instruction L corresponding to the read of the bit in the step (b3) is set with its address region selected as an address region A containing the entire address region relating to the bit and at least a portion of the address region A; and","wherein the steps (b2) and (b3) are executed on the basis of this setting.","(9) The lock management method described in any one of (6) to","(8), the lock release method further includes:","(b5) a step of enabling the first thread to enter a state under exclusive control performed by a mechanism when it is determined that the contention bit is set, the mechanism enabling exclusive control of access to the object and, if a predetermined condition is satisfied, a waiting operation of the thread and a notification operation to the thread in the waiting state;","(b6) a step of executing a notification operation to the thread in the waiting state; and","(b7) a step of enabling the first thread to exit from the state under exclusive control.","(10) A method of lock management executed by a computer having a plurality of CPUs and a memory shared by the plurality of CPUs, each CPU having an out-of-order execution stop mechanism, in which, if address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and following positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from other CPUs before execution of the load instruction, the lock management method including:","managing a lock on an object by preparing, in a storage area provided in correspondence with the object, a field for storing a bit indicating the kind of lock and an identifier for a thread acquiring a lock according to the first kind of lock or an identifier relating to the second kind of lock which is a lock method of managing the thread making access to the object by using a queue, in a situation where a plurality of threads exist, the lock management method also including:","(c1) a step of enabling a first thread to enter a state under exclusive control performed by a mechanism enabling exclusive control of access to the object and, if a predetermined condition is satisfied, a waiting operation of the thread and a notification operation to the thread in the waiting state;","(c2) a step of determining whether or not the bit indicating the kind of lock on a certain object indicates the first kind of lock;","(c3) a step of setting a contention bit when the bit indicating the kind of lock on the certain object indicates the first kind of lock;","(c4) a step of determining, after the step (c3), whether or not the first thread can acquire the first kind of lock on the basis of the contents of the storage area provided in correspondence with the certain object; and","(c5) a step of storing the bit indicating the second kind of lock and the identifier relating to the second kind of lock in the storage area provided in correspondence with the certain kind of object when the first thread can acquire the first kind of lock,","wherein the first thread exits from the state under exclusive control after the completion of necessary processing on the certain object;","wherein address regions on the memory relating to a store instruction S corresponding to the setting of the contention bit in the step (c3) and a load instruction L corresponding to read of the contents of the storage area in the step (c4) are set so that the out-of-order execution stop mechanism is activated with respect to the store instruction S and the load instruction L; and","wherein the steps (c3) and (c4) are executed on the basis of this setting.","(11) The lock management method described in (10), wherein each CPU has a store buffer for writing data to the memory according to the store instruction of the program;","wherein the out-of-order execution stop mechanism has a store forwarding (SF) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and notifies, as data B, of data A written to the store buffer according to the store instruction in the pair of instructions from the store buffer to the program if the address regions on the memory relating to the pair of instructions coincide with each other, and a store forwarding avoidance (SFA) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and performs, instead of SF, storing of data A from the store buffer into a memory hierarchy and notifying of data B from the memory hierarchy to the program on the basis of the load instruction in the pair of instructions if the address regions on the memory relating to the pair of instructions do not coincide with each other but overlap each other; and","wherein the address regions on the memory relating to the store instruction S and the load instruction L are set to activate the SFA mechanism; and","wherein the steps (c3) and (c4) are executed on the basis of this setting.","(12) The lock management method described in (10) or (11), wherein the store instruction S corresponding to the setting of the contention bit in the step (c3) is set with its address region selected as an address region A relating to the contention bit;","wherein the load instruction L corresponding to the read of the contents of the storage area in the step (c4) is set with its address region selected as an address region A containing the entire address region of the storage area and at least a portion of the address region A; and","wherein the steps (c3) and (c4) are executed on the basis of this setting.","(13) An apparatus which performs memory access serialization in a computer having a plurality of CPUs and a memory shared by the plurality of CPUs, each CPU having an out-of-order execution stop mechanism, in which, if address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and subsequent positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from the other CPUs before execution of the load instruction, the memory access serialization apparatus including:","detection means of enabling each CPU to detect the pair of the store instruction and the load instruction, which need to be serialized in a before-after relationship with respect to memory access, which are in the preceding and following positions in written order on the program, and which are placed on the program by being set so that their address regions have an overlap therebetween and respectively include address regions for data which needs to be stored and loaded; and","activation means of activating, with respect to the detected pair of instructions, the out-of-order execution stop mechanism of one of the CPUs executing the program relating to the detected pair of instructions.","(14) The memory access serialization apparatus described in (13), wherein a plurality of CPUs and a memory shared by the plurality of CPUs are provided;","wherein each CPU has a store buffer for writing data to the memory according to the store instruction of the program;","wherein the out-of-order execution stop mechanism has a store forwarding (SF) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and notifies, as data B, of data A written to the store buffer according to the store instruction in the pair of instructions from the store buffer to the program if the address regions on the memory relating to the pair of instructions coincide with each other, and a store forwarding avoidance (SFA) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and performs, instead of SF, storing of data A from the store buffer into a memory hierarchy and notifying of data B from the memory hierarchy to the program on the basis of the load instruction in the pair of instructions if the address regions on the memory relating to the pair of instructions do not coincide with each other but overlap each other; and","wherein the activation means activates, with respect to the detected pair of instructions, the SFA mechanism in the out-of-order execution stop mechanism of one of the CPUs executing the program relating to the detected pair of instructions.","(15) The memory access serialization apparatus described in (13) or (14), further including:","load instruction execution means of executing load of data on the basis of the load instruction in the pair of instructions, the address region of the store instruction being set so as to store only data which essentially needs to be stored, the address region of the load instruction being set so as to load data which does not need to be loaded as well as data which needs to be loaded; and","extraction means of extracting the data which needs to be loaded from the data loaded by the load instruction.","(16) The memory access serialization apparatus described in any one of (13) to (15), wherein the program includes first and second program portions relating to first and second processings, the first and second processings including a store processing portion, an observation processing portion for observing data that might have been stored by the other processing after execution of the store processing portion, and a branching processing portion for branching to a corresponding process according to a result of observation by the observation processing portion; and","wherein the pair of the store instruction and the load instruction are included in the store processing portion and the observation processing portion in the first and second processings.","(17) The memory access serialization apparatus described in (16), wherein the first and second processings are processing relating to object lock release and processing relating to object acquisition, respectively, in an object management apparatus.","(18) An apparatus which executes lock management with a computer having a plurality of CPUs and a memory shared by the plurality of CPUs, each CPU having an out-of-order execution stop mechanism, in which, if address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and following positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from other CPUs before execution of the load instruction, the lock management apparatus managing a lock on an object by preparing, in a storage area provided in correspondence with the object, a field for storing a bit indicating the kind of lock and an identifier for a thread acquiring a lock according to the first kind of lock or an identifier relating to the second kind of lock, in a situation where a plurality of threads exist, the lock management apparatus including:","an object acquisition device which enables a second thread to obtain a lock on a certain object held by a first thread, and a lock release device which enables the first thread to release the lock from the certain object, the object acquisition device including:","(a1) means of determining whether or not the bit indicating the kind of lock on the certain object indicates the first kind of lock; and","(a2) means of setting a contention bit when the first kind of lock is indicated, the lock release device including:","(b1) means of determining whether or not the bit indicating the kind of lock indicates the first kind of lock;","(b2) means of storing, in the storage area, information indicating that no thread holding the lock on the certain object exists;","(b3) means of determining whether or not the contention bit is set when the bit indicating the kind of lock indicates the first kind of lock; and","(b4) means of terminating processing if it is determined that the contention bit is not set,","wherein address regions on the memory relating to a store instruction S corresponding to storage performed by the means (b2) and a load instruction L corresponding to read of the bit performed by the means (b3) are set so that the out-of-order execution stop mechanism is activated with respect to the store instruction S and the load instruction L; and","wherein the means (b2) and (b3) perform processing on the basis of this setting.","(19) The lock management apparatus described in (18), wherein each CPU has a store buffer for writing data to the memory according to the store instruction of the program;","wherein the out-of-order execution stop mechanism has a store forwarding (SF) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and notifies, as data B, of data A written to the store buffer according to the store instruction in the pair of instructions from the store buffer to the program if the address regions on the memory relating to the pair of instructions coincide with each other, and a store forwarding avoidance (SFA) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and performs, instead of SF, storing of data A from the store buffer into a memory hierarchy and notifying of, data B from the memory hierarchy to the program on the basis of the load instruction in the pair of instructions if the address regions on the memory relating to the pair of instructions do not coincide with each other but overlap each other; and","wherein the address regions on the memory relating to the store instruction S and the load instruction L are set to activate the SFA mechanism; and","wherein the means (b2) and (b3) perform processing on the basis of this setting.","(20) The lock management apparatus described in (18) or (19), wherein the store instruction S corresponding to the storage performed by the means (b2) is set with its address region selected as an address region A relating to the storage region in which information indicating that no thread holding the lock on the certain object exists is stored;","wherein the load instruction L corresponding to the read of the bit performed by the means (b3) is set with its address region selected as an address region A containing the entire address region relating to the bit and at least a portion of the address region A; and","wherein the means (b2) and (b3) perform processing on the basis of this setting.","(21) The lock management apparatus described in any one of (18) to (20), wherein the lock release device further includes:","(b5) means of enabling the first thread to enter a state under exclusive control performed by a mechanism when it is determined that the contention bit is set, the mechanism enabling exclusive control of access to the object and, if a predetermined condition is satisfied, a waiting operation of the thread and a notification operation to the thread in the waiting state;","(b6) means of executing a notification operation to the thread in the waiting state; and","(b7) means of enabling the first thread to exit from the state under exclusive control.","(22) An apparatus which performs lock management with a computer having a plurality of CPUs and a memory shared by the plurality of CPUs, each CPU having an out-of-order execution stop mechanism, in which, if address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and following positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from other CPUs before execution of the load instruction, the lock management apparatus managing a lock on an object by preparing, in a storage area provided in correspondence with the object, a field for storing a bit indicating the kind of lock and an identifier for a thread acquiring a lock according to the first kind of lock or an identifier relating to the second kind of lock which is a lock method of managing the thread making access to the object by using a queue, in a situation where a plurality of threads exist, the lock management apparatus including:","(c1) means of enabling a first thread to enter a state under exclusive control performed by a mechanism enabling exclusive control of access to the object and, if a predetermined condition is satisfied, a waiting operation of the thread and a notification operation to the thread in the waiting state;","(c2) means of determining whether or not the bit indicating the kind of lock on a certain object indicates the first kind of lock;","(c3) means of setting a contention bit when the bit indicating the kind of lock on the certain object indicates the first kind of lock;","(c4) means of determining, after the operation of the means","(c3), whether or not the first thread can acquire the first kind of lock on the basis of the contents of the storage area provided in correspondence with the certain object; and","(c5) means of storing the bit indicating the second kind of lock and the identifier relating to the second kind of lock in the storage area provided in correspondence with the certain kind of object when the first thread can acquire the first kind of lock,","wherein the first thread exits from the state under exclusive control after the completion of necessary processing on the certain object;","wherein address regions on the memory relating to a store instruction S corresponding to the setting of the contention bit made by the means (c3) and a load instruction L corresponding to read of the contents of the storage area performed by the means (c4) are set so that the out-of-order execution stop mechanism is activated with respect to the store instruction S and the load instruction L; and","wherein the means (c3) and (c4) perform processing on the basis of this setting.","(23) The lock management apparatus described in (22), wherein each CPU has a store buffer for writing data to the memory according to the store instruction of the program;","wherein the out-of-order execution stop mechanism has a store forwarding (SF) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and notifies, as data B, of data A written to the store buffer according to the store instruction in the pair of instructions from the store buffer to the program if the address regions on the memory relating to the pair of instructions coincide with each other, and a store forwarding avoidance (SFA) mechanism which stops out-of-order execution of the load instruction in the pair of instructions and performs, instead of SF, storing of data A from the store buffer into a memory hierarchy and notifying of data B from the memory hierarchy to the program on the basis of the load instruction in the pair of instructions if the address regions on the memory relating to the pair of instructions do not coincide with each other but overlap each other; and","wherein the address regions on the memory relating to the store instruction S and the load instruction L are set to activate the SFA mechanism; and","wherein the means (c3) and (c4) perform processing on the basis of this setting.","(24) The lock management apparatus described in (22) or (23), wherein the store instruction S corresponding to the setting of the contention bit made by the means (c3) is set with its address region selected as an address region A relating to the contention bit;","wherein the load instruction L corresponding to the read of the contents of the storage area performed by the means (c4) is set with its address region selected as an address region A containing the entire address region of the storage area and at least a portion of the address region A; and","wherein the means (c3) and (c4) perform processing on the basis of this setting.","(25) A program for a method of memory access serialization in a computer having a plurality of CPUs and a memory shared by the plurality of CPUs, each CPU having an out-of-order execution stop mechanism, in which, if address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and subsequent positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from the other CPUs before execution of the load instruction, the memory access serialization method including:","a detection step of enabling each CPU to detect the pair of the store instruction and the load instruction, which need to be serialized in a before-after relationship with respect to memory access, which are in the preceding and following positions in written order on the program, and which are placed on the program by being set so that their address regions have an overlap therebetween and respectively include address regions for data which needs to be stored and loaded; and","an activation step of activating, with respect to the detected pair of instructions, the out-of-order execution stop mechanism of one of the CPUs executing the program relating to the detected pair of instructions, the program being used to make the computer perform the steps of the lock management method.","(26) A recording medium on which the program described in (25) is recorded.","(27) A program for a method of lock management executed by a computer having a plurality of CPUs and a memory shared by the plurality of CPUs, each CPU having an out-of-order execution stop mechanism, in which, if address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and following positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from other CPUs before execution of the load instruction, the lock management method including managing a lock on an object by preparing, in a storage area provided in correspondence with the object, a field for storing a bit indicating the kind of lock and an identifier for a thread acquiring a lock according to the first kind of lock or an identifier relating to the second kind of lock, in a situation where a plurality of threads exist, the lock management method also including an object acquisition method of enabling a second thread to obtain a lock on a certain object held by a first thread, and a lock release method of enabling the first thread to release the lock from the certain object, the object acquisition method including:","(a1) a step of determining whether or not the bit indicating the kind of lock on the certain object indicates the first kind of lock; and","(a2) a step of setting a contention bit when the first kind of lock is indicated, the lock release method including:","(b1) a step of determining whether or not the bit indicating the kind of lock indicates the first kind of lock;","(b2) a step of storing, in the storage area, information indicating that no thread holding the lock on the certain object exists;","(b3) a step of determining whether or not the contention bit is set when the bit indicating the kind of lock indicates the first kind of lock; and","(b4) a step of terminating processing if it is determined that the contention bit is not set, address regions on the memory relating to a store instruction S corresponding to storage in the step (b2) and a load instruction L corresponding to read of the bit in the step (b3) being set so that the out-of-order execution stop mechanism is activated with respect to the store instruction S and the load instruction L, the steps (b2) and (b3) being executed on the basis of the setting of the address regions, the program being used to make the computer to execute the steps of the lock management method.","(28) A recording medium on which the program described in (27) is recorded.","(29) A program for a method of lock management executed by a computer having a plurality of CPUs and a memory shared by the plurality of CPUs, each CPU having an out-of-order execution stop mechanism, in which, if address regions on the memory relating to a pair of a store instruction and a load instruction in preceding and following positions, respectively, in written order of a program executed by each of the CPUs have an overlap therebetween, the out-of-order execution stop mechanism stops out-of-order execution of the load instruction and enables data relating to the store instruction to be observed from other CPUs before execution of the load instruction, the lock management method including managing a lock on an object by preparing, in a storage area provided in correspondence with the object, a field for storing a bit indicating the kind of lock and an identifier for a thread acquiring a lock according to the first kind of lock or an identifier relating to the second kind of lock which is a lock method of managing the thread making access to the object by using a queue, in a situation where a plurality of threads exist, the lock management method also including:","(c1) a step of enabling a first thread to enter a state under exclusive control performed by a mechanism enabling exclusive control of access to the object and, if a predetermined condition is satisfied, a waiting operation of the thread and a notification operation to the thread in the waiting state;","(c2) a step of determining whether or not the bit indicating the kind of lock on a certain object indicates the first kind of lock;","(c3) a step of setting a contention bit when the bit indicating the kind of lock on the certain object indicates the first kind of lock;","(c4) a step of determining, after the step (c3), whether or not the first thread can acquire the first kind of lock on the basis of the contents of the storage area provided in correspondence with the certain object; and","(c5) a step of storing the bit indicating the second kind of lock and the identifier relating to the second kind of lock in the storage area provided in correspondence with the certain kind of object when the first thread can acquire the first kind of lock, the first thread exiting from the state under exclusive control after the completion of necessary processing on the certain object, address regions on the memory relating to a store instruction S corresponding to the setting of the contention bit in the step (c3) and a load instruction L corresponding to read of the contents of the storage area in the step (c4) being set so that the out-of-order execution stop mechanism is activated with respect to the store instruction S and the load instruction L, and the steps (c3) and (c4) being executed on the basis of the setting of the address regions, the program being used to make the computer to execute the steps of the lock management method.","(30) A recording medium on which the program described in (29) is recorded.","As described above, serialization of store instructions and load instructions with respect to memory access can be ensured without using an explicit instruction which entails a problem in terms of speed.",{"@attributes":{"id":"p-0229","num":"0227"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"[Description of symbols]"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"10","Computer"]},{"entry":[{},"16","Application program"]},{"entry":[{},"30","Program"]},{"entry":[{},"32","CPU"]},{"entry":[{},"34","Store buffer"]},{"entry":[{},"36","Cache line"]},{"entry":[{},"38","Memory"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"3. BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0218","num":"0216"},"figref":"FIG. 1","b":["1","2","3","4"]},{"@attributes":{"id":"p-0219","num":"0217"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0220","num":"0218"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0221","num":"0219"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0222","num":"0220"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0223","num":"0221"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0224","num":"0222"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0225","num":"0223"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0226","num":"0224"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0227","num":"0225"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0228","num":"0226"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
