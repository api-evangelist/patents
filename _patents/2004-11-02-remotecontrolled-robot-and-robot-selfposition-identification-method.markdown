---
title: Remote-controlled robot and robot self-position identification method
abstract: A remotely controlled robot comprises a unit storing the layout plan of a building, a unit receiving a position remotely designated in the layout plan from a remote location and a unit controlling the travel of the robot to the designated position. A self-position identification method is implemented by a robot with a camera whose shooting direction can be changed. The robot takes in advance a panoramic picture of a room where the robot may travel, generates a reference picture by extracting a plurality of block pictures from the panoramic picture and identifies a room where the robot is located, by applying correlation and DP matching, using both a picture taken in the room where the robot is located and the reference picture.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07120519&OS=07120519&RS=07120519
owner: Fujitsu Limited
number: 07120519
owner_city: Kanagawa
owner_country: JP
publication_date: 20041102
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["This application is a continuation of international PCT application No. PCT\/JP02\/05370 filed on May 31, 2002.","1. Field of the Invention","The present invention relates to a technology for controlling and using a robot. In particular, it relates to a technology for controlling and using a robot, where a robot can be remotely controlled, for example, through the Internet when it is located in a building. It also relates to a robot self-position identification method for recognizing the exact current position and direction of a robot.","2. Description of the Related Art","Conventionally, an Internet camera has been used to remotely monitor a person's home while he\/she is away. However, this Internet camera is fixed in a specific location, and in order to monitor each room of a building, such a camera must be installed in each room. Furthermore, the connection between a plurality of cameras and a host computer becomes complex and the cost increases, which is a problem.","In order to remotely control electrical appliances in a person's home while he\/she is away, digital home appliances that can be connected to LAN have been being developed. However, conventional electrical home appliances that cannot be connected to LAN cannot be remote-controlled, which is another problem.","Furthermore, for example, in order for an autonomous moving robot that can travel in a building to do work as instructed by a user, the own position of the robot must be recognized. Generally, in order for a robot to autonomously travel, a landmark, such as a white line, etc., which is easy for a robot to recognize, is needed.","However, it is impossible to attach a characteristic landmark to an average house. Even if an existing characteristic point can be registered as a landmark, the size of a target on a camera screen varies depending on the position of a robot so the picture cannot easily determine the landmark, which is another problem.","An object of the present invention is to realize a remotely controlled robot whose travel destination in a building can be easily designated from a remote place and through which the state of each room can be monitored from a remote place and through which electrical home appliances located in each room can be remotely operated, at relatively low cost and with a simple configuration, and to provide a robot self-position identification method for a robot exactly fixing its own position and direction, in order to solve the problems described above.",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1","b":["1","2","3","4"]},"The layout storage unit  stores the layout plan of a building, such as a house, and the communication unit  receives a position in the layout plan that is remotely designated from a remote terminal, for example, through a network. The travel control unit  controls the travel of the robot  to the designated position.","In another preferred embodiment of the present invention, the remotely controlled robot can comprise a step getting over unit getting over a step c in a building, based on the result of step detection by an obstacle detecting sensor. The robot can further comprise a self-position identification unit identifying the current position and direction of the robot in a building, and the travel control unit  can control the travel of the robot , based on the result of the identification.","In another preferred embodiment of the present invention, the communication unit  shown in  can also receive the designation of a room in the layout plan of a building from a remote terminal. In this case, the travel control unit  controls the travel of the robot  to, for example, the entrance of the designated room.","In another preferred embodiment of the present invention, the remotely controlled robot can further comprise a picture taking unit taking a picture in a building and a communication unit transmitting a picture taken by the picture taking unit when a robot regularly or irregularly patrols inside the building, to a computer with a memory device that can be accessed from the outside through a network, such as a Web server connected to the internet. Alternatively, a robot can incorporate such a computer, such as a Web server.","In this case, the preferred embodiment can further comprise a revolution unit changing the shooting direction of the picture taking unit, and an infrared emission\/reception unit emitting\/receiving an infrared ray for operating equipment, such as electrical home appliances that are in parallel to the shooting direction of the picture taking unit. Alternatively, it can further comprise the step getting over unit described earlier.","In this case, furthermore, when a ringer signal is transmitted from the outside through the Internet a prescribed number of times, the communication unit can also start the computer described earlier, such as a Web server.","In another preferred embodiment of the present invention, the remotely controlled robot of the present invention comprises a script storage unit storing the script programs of one or more operations of a robot, and a communication unit receiving a command to execute one of the stored programs from the outside.","In another preferred embodiment of the present invention, the remotely controlled robot of the present invention further comprises a command receiving unit receiving an emergency notice\/command which is sent to the outside from a person within a building, such as a resident of a house, and a communication unit issuing an urgent notice to a predetermined external terminal according to the command.","In this preferred embodiment, the robot can further comprise the picture taking unit taking the inside pictures of a building, the revolution unit changing the shooting direction of the picture taking unit and the communication unit transmitting pictures taken by the picture taking unit, to the outside, according to the command from the outside.","The robot self-position identification method of the present invention can be implemented by a robot with a camera whose shooting direction can be changed. The robot takes in advance the panoramic picture of each room where the robot may travel, generates a reference picture by extracting a plurality of block pictures from the panoramic picture and identifies a room where the robot is located, by applying correlation calculation and DP matching in the panoramic picture taken in a position where the robot is located, using a picture of the same size as the block picture and the reference picture.","In this preferred embodiment, the position of a landmark can also be calculated in an picture taken in the position where the robot is located, using a landmark picture taken in advance in the room as a reference template, the distance between the robot and the landmark can also be stereoscopically measured and the self-position and direction of the robot in the identified room can also be identified.","In another preferred embodiment of the present invention, a vertical line in a taken landmark picture can also be extracted and the position and direction of a robot can also be exactly identified by using two angles that are formed by one of the shooting directions of two cameras and the direction of the vertical line.","As described above, according to the present invention, for example, the travel destination or target room of a robot can be remotely designated in the layout plan of a building. By using the panoramic picture of each room to which a robot may travel, a room where the robot is located can be identified.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 2"},"In , the robot comprises a control computer , a travel mechanism , a camera  taking pictures around the robot, a pan\/tilt stand  for adjusting the horizontal revolution angle and elevation\/depression angle of the camera, an infrared transmitter\/receiver  that is, for example, mounted on the same base as that of the camera, transmitting infrared rays in parallel to the shooting direction of the camera and receiving infrared rays to get remote control data, a radio communication unit , an input device , a pointing device , a display device , a variety of switches  and a variety of sensors .","In , the camera  is, for example, a video camera. The infrared transmitter\/receiver  is installed in the vicinity of the camera , and can transmit infrared rays in the same direction as the shooting direction. Its base can be revolved in an arbitrary direction by the pan\/tilt stand  used as a camera revolution mechanism. For example, the transmitter\/receiver  can transmit infrared rays in order to operate a specific electrical home appliance located in that direction while viewing the picture of the camera .","The radio communication unit  conducts communications in order to enable a portable data terminal, such as a cellular phone, a PDA (personal digital assistant) etc., or a personal computer to execute such a remote control.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 3"},"In , the robot control computer  shown in  comprises a Web server , a control execution unit  executing control and an interface , such as CGI (common gateway interface), ISAPI (Internet server application programming interface) or the like, which is located between the Web server  and the control execution unit . The Web server  can be remotely accessed through a Web browser  and the Internet .","In , the Web browser  can be connected to the Internet  by menu selection. In the Web server , the CGI\/ISAPI  is called according to a command from the Web browser . Then, in the CGI\/ISAPI , the command format is converted into a format suited to control the robot. Then, the control execution unit  executes the command.","From the control computer , status and picture data that are returned from the control execution unit  are transmitted to the CGI\/ISAPI , and its data format is converted. Then, the Web server  provides the Web browser  with the status and picture data as an html file through the Internet . Then, the Web browser  displays the menu and picture.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 4","FIG. 2"],"b":["31","32","14","33","19","34","35","36"]},"A travel unit  corresponding to the travel mechanism , a monitor  corresponding to the display device , a near distance sensor  corresponding to the variety of sensors , a microphone, a speaker  and a track pointer  are also provided on the front. On the back, a pan\/tilt unit  corresponding to the pan\/tilt stand  shown in  is provided.",{"@attributes":{"id":"p-0055","num":"0054"},"figref":["FIG. 5","FIG. 5","FIG. 4"],"b":["31","39","38"]},"In this preferred embodiment, for the travel mechanism  of the robot, a mechanism by which the robot can get over clear obstacles and steps using two (left and right) crawlers (wheels) and one or more freely-revolving ball castors (auxiliary wheels) is used. These crawlers can revolve on a plane perpendicular to the center of the revolution axis of each wheel, and when the robot revolves at one point, they operate as if they were two (left and right) wheels rather than crawlers. Since the auxiliary wheel touches on the ground at one point, the grounding point is stable and the one-point revolution center of the entire robot is stable, the robot can get over an obstacle, which is higher than the structural base of the robot. For the steps getting over mechanism, another publicly known technology can also be used.",{"@attributes":{"id":"p-0057","num":"0056"},"figref":["FIG. 6","FIG. 6","FIG. 2","FIG. 3"],"b":["53","51","65","52","10","21","10","53"]},"In , a pointing device , a USB (universal serial bus) port for user extension , a voice codec  with a microphone  and a speaker  connected, an LCD interface  with an LCD  connected, CF (compact flash) memory  connected through a control unit and a communication module  connected through a control unit, are connected to the main CPU .","A CMOS camera , two motors  controlling the rotation of the pan\/tilt stand  shown in , three motors  rotating the crawlers and ball castors that are shown in  as the travel mechanism , a switch sub-substrate  with LEDs and buttons mounted, a distance sensor , a potentiometer for pan (horizontal rotation angle) , a potentiometer for tilt (elevation angle) , an infrared ray transmitter , an infrared ray receiver  and a DC\/DC charging circuit  with an AC adaptor  and a battery  connected, are connected to both the MPU controller  and HUB .",{"@attributes":{"id":"p-0060","num":"0059"},"figref":["FIG. 7","FIG. 7"]},"Firstly, in step S, the robot identifies its own position. This self-position identification is described later. Then, in step S, the robot receives a picture size data size that can be displayed on a mobile terminal, from the remotely located client.","Then, in step S, the size of the layout picture stored in the memory is converted into that of the data received from the client using the data and stores the conversion scale. In step S, the robot transmits the layout picture containing the self-position information identified in step S, to the client. In step S, the robot receives the coordinates of the destination designated from the client.","Then, in step S, the robot calculates the destination coordinates on a real scale from both the conversion scale information stored in step S and the coordinates of the destination designated by the client. In step S, the robot produces a route to the destination. In step S, the robot travels towards the destination. In step S, the robot determines whether it arrives at the destination. The robot repeats the processes in steps  onward until it arrives at the destination. If it determines that it arrives at the destination, the process terminates.",{"@attributes":{"id":"p-0064","num":"0063"},"figref":["FIG. 8","FIG. 7"],"b":"8"},{"@attributes":{"id":"p-0065","num":"0064"},"figref":["FIG. 9","FIGS. 9 and 7"]},"Since after the processes in steps S and S, the client designates the name of a room, etc., instead of a target destination, there is no need to store a conversion scale in step S of . Therefore, omitting the process in step S, in step S, the robot transmits a layout picture containing self-position information, to the client. Then, instead of the processes in steps S and S of , in step S, the robot receives the data of the name or number of a target room from the client. In step S, the robot calculates the coordinates of a travel destination from the name or number of a target room, using a correspondence table storing in advance the coordinates of a target, such as an entrance, for each room. Then, the robot performs the same processes in step S through S as those shown in .",{"@attributes":{"id":"p-0067","num":"0066"},"figref":["FIG. 10","FIG. 9","FIG. 10"]},"Next, the robot's acquisition method of the self-position, that is, the self-position identification method in step S of , is described. In this preferred embodiment, it is assumed that a robot identifies both a room where the robot is located and its exact position by picture taking and registering in advance the panoramic picture of each room in a building and comparing the panoramic picture of each room with a panoramic picture taken by the robot in a room where the robot currently is located.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0070","num":"0069"},"figref":["FIG. 12","FIG. 13","FIG. 12","FIG. 11"],"b":["20","22"]},"Specifically, in step S, the panoramic picture of each room located at an area to which a robot may travel, is taken. In step S, the size of the panoramic picture is reduced and its level is averaged. In step S, a plurality of small block pictures are extracted from the panoramic picture at equal pitches, that is, horizontally at equal intervals, the pictures are enlarged or reduced, and a reference template is generated.","The upper picture of  shows examples of pictures extracted as small blocks in this way. For example, k small block pictures are extracted from the panoramic picture of each room for each of the registered pictures of n rooms.","Processes in steps S and after of  show the identification process of a room where the robot currently is located. Firstly, in step S, the panoramic picture of a room where the robot currently is located is taken. In step S, the size of the panoramic picture is reduced and its level is averaged. In steps S and after, the currently taken picture is compared with the reference template.","The lower picture of  shows examples of the extracted pictures of a room where the robot currently is located. The panoramic picture of a room where the robot currently is located is compared with each of the registered pictures of n rooms, using an extraction start position and xrange small block pictures as a search reference position and a search range, respectively.","In step S of , it is determined whether such a process has been applied to all the registered rooms. If such a process has not been applied to all the registered rooms, in step S, it is determined whether all reference block numbers, specifically, k extracted pictures registered for each of the n rooms shown in  have been searched for.","If all the k extracted pictures registered for each of the n rooms shown in  have not been searched for, in step S, it is determined whether all search range numbers, specifically, the entire search range of xrange pixels from the search reference position in the panoramic picture of a room where the robot currently is located shown in  has been searched for. If the entire search range of xrange pixels from the search reference position in the panoramic picture of a room has not been searched for, in step S it is determined whether all enlargement\/reduction numbers, specifically, the number of pictures compared with the currently taken room picture of n pictures that are obtained by enlarging and reducing the small block pictures extracted in step S, reaches n.","If the number does not reach n, in step S, the correlation calculation between the reference template, specifically, the correlation between the reference template with the process target enlargement\/reduction number of the process target small-blocked picture of the process target room and the panoramic picture of the current room designated by the search range number is calculated. Then, in step S, the enlargement\/reduction number is incremented, and the processes in steps S onward are repeated.","If in step S, it is determined that the enlargement\/reduction number is more than n, that is, n pictures with an enlargement\/reduction number have been all processed, in step S, a picture with an enlargement\/reduction number whose result of the correlation calculation is the smallest of all pictures with a search range number in process is designated as the result of the search in the search position. Then, in step S, the search range number is incremented, and then the processes in steps S onward are repeated. In this case, it is assumed that, for example, distortion equivalent to absolute density difference is calculated for each picture in the correlation calculation. In this case, the smaller the difference is, the larger the matching ratio between pictures becomes.","If in step S it is determined that the search range number is more than xrange, it means that the comparison of a picture with a reference block number in process is completed. Therefore, in step S, the reference block number is incremented and then the processes in steps S onward are repeated.","If in step S it is determined that the reference block number is more than k, it means that the comparison of a room in process is completed. Therefore, in step S, a two-dimensional matrix that is determined by both k small block pictures obtained by conducting the correlation calculation of the room and search range xrange is generated. In step S, cost is calculated, for example, by applying dynamic programming (DP) matching, using the result of the correlation calculation and distance as parameters, and the lowest cost of a room in process is calculated.","Each element of the two-dimensional matrix whose respective number of rows and columns are determined by the k small block pictures and search range xrange becomes the data of a reference template whose correlation calculation value between the current panoramic picture and a picture in each search position is the lowest of the respective n templates obtained by enlarging\/reducing the k small blocks shown in .","Distance in DP matching corresponds to the horizontal distance from the search reference position shown in the lower picture of , that is, xrange. In step S, the lowest cost of a room in process can be calculated by applying general DP matching that calculates cost using the result of correlation calculation and distance as parameters.","Then, in step S, the room number is incremented, and the processes in and after step S are repeated. If it is determined that in step S all the rooms are processed, in step S a room with the lowest cost of the costs calculated for each room in step S is determined to be the room where the robot currently is located, and the process terminates.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":["FIGS. 14 and 15","FIG. 12","FIGS. 14 and 15"]},"In step S of , firstly, prior to the identification of the real position of a robot, a landmark, such as a pillar, is selected in the panoramic picture taken and registered, as described in , and both its position in the picture and its position in the real room are registered. Then, in step S, the picture of the pillar is extracted from the panoramic picture and an enlargement\/reduction template is generated.","Then, in order to identify the rough real position of a robot, in step S correlation calculation is applied using the enlargement\/reduction template of the pillar in a room where the robot currently is located, that is, the same room as identified in the process of , and the position of the pillar in the current panoramic picture is specified. In step S, a distance between the robot and the specified pillar is stereoscopically measured, and the rough position of the robot is identified.",{"@attributes":{"id":"p-0087","num":"0086"},"figref":["FIG. 16","FIG. 16"],"b":"43"},{"@attributes":{"id":"p-0088","num":"0087"},"figref":["FIG. 15","FIG. 14","FIG. 15"],"b":"45"},"Then, in step S, respective angles formed by the extracted vertical line, that is, the edge of the pillar, and each of the shooting directions of two cameras are calculated.","Then, in step S, in order to calculate the exact position and direction of the robot in the room, virtual points are set in a matrix shape in the room, and two angles formed by the vertical line of the pillar corresponding to the position\/posture of the robot and each of the shooting directions of the two cameras are calculated using the direction of the robot at each point as a parameter, and a value corresponding to the difference the angles calculated in steps S and S is calculated as cost. In step S, a position and a direction where the cost is the minimum are calculated as the exact position and direction of the robot. Then, the process terminates.","A triangle in the rectangle shown in  indicates the exact current position and direction of the robot that are identified by the process shown in . The data for the position and direction of a robot that are identified thus is notified to the client, for example, by the radio communication unit  shown in , as requested.","Next, other preferred embodiments of a remotely controlled robot are described.  is a flowchart showing the remote emergency notice process of a remotely controlled robot. As described in , a robot is provided with an emergency button. For example, if the resident of a building wants to notify a remote place of emergency, he\/she can do so by pushing the emergency button.","Specifically, in step S of , the emergency button is monitored, and in step S it is determined whether the emergency button is pushed. If the button is not pushed, the processes in and after step S are repeated. If the button is pushed, in step S emergency is notified to an address registered in advance over electronic mail or telephone. Then, the process terminates.","Next, a method for remotely checking the picture of, for example, a room in a building, that is taken by a robot is described with reference to . In , for example, if a robot  regularly patrols inside the building and transmits the picture of each room, which it takes, to a server computer  provided with a Web server through a wireless LAN, the picture can be remotely referenced by accessing this Web server.","Specifically, the server computer  comprises a socket server  receiving picture data transmitted from the robot , and a Web server . The picture transmitted from the robot  is stored in a folder on the Web server  that can be referenced from the outside. In a remote place, the Web browser  issues a picture obtain command to the Web server  through the Internet , and displays the picture transmitted from the Web server  through the Internet .","In this case, in , the communication module , such as a LAN card, etc., is inserted in a connector.","In , as in , a robot control computer  comprises a Web server , and the Web browser  can refer to the picture by accessing the Web server  through the Internet . In this case, the communication module , such as a PHS card, etc., is inserted in a connector.","Alternatively, when the robot receives a ringer signal a predetermined number of times through the Internet , the Web server can start and allow it to be accessed from the outside.","Lastly, a method for remotely designating a script stored in a robot and making the robot perform an operation that is programmed in advance, is described with reference to . In , in response to a command from a client browser , the command analysis\/execution unit  of a remotely controlled robot  analyzes the command. If the command designates the selection of a script and its execution, a script selection\/execution unit  selects one of a plurality of robot operation scripts through stored in the robot and performs the operation.","As described in detail above, according to the present invention, a remotely controlled robot can be made to travel to a target destination by designating the destination, for example, in a layout plan displayed on a remote terminal.","A remote terminal can also check the inside picture of a building. Alternatively, the remote terminal can make a robot perform an operation that is programmed in advance. Alternatively, the resident of a building can issue an emergency notice to a remote location.","The present invention aims to provide functions to operate electrical home appliances through the Internet and to remotely monitor the state of a client's home while he\/she is away, and the exact self-position identification method of a robot. The present invention can be used in all industries using a remotely controlled robot and in an industry needing to identify an exact self-position of a robot. Specifically, the present invention can be used in a variety of industries, such as electrical home appliance industries, building management industries, etc."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 10","FIG. 9"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 16","FIGS. 14 and 15"]},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 20"}]},"DETDESC":[{},{}]}
