---
title: Information presentation apparatus and mobile terminal
abstract: Information in which a user is interested when viewing a program and a situation and a behavior of the user are to be associated with each other. A keyword dictionary defining program information and a user behavior model are provided, and thereby the scene interesting the user is registered and stored, and information on the interesting scene is presented in a situation optimal to the user.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08478759&OS=08478759&RS=08478759
owner: Hitachi Solutions, Ltd.
number: 08478759
owner_city: Tokyo
owner_country: JP
publication_date: 20101027
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CLAIM OF PRIORITY","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS","DESCRIPTION OF SYMBOLS"],"p":["The present application claims priority from Japanese patent application JP 2009-250274 filed on Oct. 30, 2009, the content of which is hereby incorporated by reference into this application.","1. Field of the Invention","The present invention relates to an apparatus that recommends a program suitable for a user preference to a user.","2. Background Art","In the modern information civilization society, the amount of information provided by various media such as broadcast programs and the Internet is immeasurable. In particular, the influence of television on viewers is great. The ownership rate of televisions is extremely high. Televisions are installed in almost all households. Broadcast content distributed from each broadcasting station is viewed by an unspecified large number of people. In such situations, when a user views a program, the user is interested not only in commercials and program content but also in information related to the program, for example, information on costumes of performers and information on locations.","Recently, development of digital technologies enables a large volume of information related to image content and programs to be stored. Further, HDD (Hard Disk Drive)-based recorders, personal computers having functions of recording and viewing television programs and the like have appeared. Accordingly, techniques that allow a user to register and store information on an interesting scene when viewing a program and then present the information to the user after viewing have actively been researched.","WO2003\/021943 discloses a technique where a user designates an article by voice at a scene in which the article that the user wants to purchase appears when viewing a program and then the user accesses article registration information and receives detailed information on the article, which the user wants to purchase, after viewing the program. JP Patent Publication (Kokai) No. 2006-031441 A discloses a technique that utilizes a broadcast program, such as a program on travels, and information on the Internet corresponding to the broadcast program and registers the program and the information along with location information and thereby generates navigation data suiting interest and preference of a user. JP Patent Publication (Kokai) No. 2007-115220A discloses a technique where an article that a user is required to remember is preliminarily registered on a mobile terminal and then selection of a registered article memo list allows connection to a store terminal, thereby enabling detailed information to be acquired. Further, when the user approaches the store terminal, a notification screen of the article in the store is displayed from the memo list recorded in the mobile terminal.","The method of WO2003\/021943 has a problem that the user forgets that he\/she is interested after viewing the program and does not perform search behavior and the like. Accordingly, a technique is required that presents information having been registered according to the interest of the user in a situation optimal to the user. There is a problem that, if information is presented to the user from the preliminarily created information as with JP Patent Publication (Kokai) No. 2006-031441 A, the presented information is not necessarily information required by the user in the situation. Accordingly, a technique is required that presents an appropriate piece of information from the information having preliminarily interested the user.","The present invention presents information on a scene having interested a user among previously viewed programs in a situation optimal to the user.","Concerning presentation of interesting scene information related to every scene interesting the user when the user has viewed the program in the situation optimal to the user, it is incapable of presenting interesting scene information in the situation optimal to the user without defining a relationship between a keyword defining interesting scene information and a keyword defining the behavior of a user. For example, even if it is determined that the user wants to go to a \u201cdepartment store\u201d according to analysis of behavior of the user, in a case where behavior of \u201cgoing to a department store\u201d is not associated with \u201ccostume\u201d in the interesting scene information, the interesting scene information associated with the \u201ccostume\u201d cannot be presented.","The present invention prepares a keyword dictionary, which defines program information, and a user behavior model, and thereby registers and stores the scene interesting the user and presents information of the scene interesting the user in a situation optimal to the user.","An information presentation apparatus according to the present invention includes: a program information database accumulating program information; a viewing history database accumulating a program viewing history of a user; a dictionary recording correspondence between a keyword and a category; an interesting scene extraction unit extracting a scene of a program that interests the user using the viewing history database and the program information database; an interesting scene registration unit that associates the interesting scene extracted by the interesting scene extraction unit and the keyword in the program information accompanying the interesting scene, and registers the keyword associating the interesting scene in an interesting scene registration information database according to the dictionary on a category-by-category basis; and an interesting scene presentation unit searching the interesting scene registration information database and retrieving and presenting the interesting scene matching with the input category, responsive to an input of information including the category from a mobile terminal.","A mobile terminal according to the present invention is used together with the information presentation apparatus, and includes: a user behavior model storing an input and probabilities for the respective categories corresponding to the input; a behavior analyzer that acquires probabilities for the respective categories corresponding to the latest input from the user behavior model, and transmits the probabilities to the information presentation apparatus; and a display unit displaying the interesting scene transmitted from the information presentation apparatus.","The present invention allows the user to acquire useful information recognized by the user when the user has viewed a program, again in the optimal situation.","Embodiments of the present invention will hereinafter be described on the basis of the drawings.","[Embodiment 1]",{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 1"},"A terminal  includes a program information database , a viewing history database , an interesting scene extraction unit , an interesting scene registration unit , a keyword dictionary , an interesting scene registration information database , an interesting scene presentation unit  and a display style determination unit . These elements can be built into an image content receiver such as, for example, a set-top box and a television. A terminal  includes a user behavior model , a behavior analyzer  and a display unit . These elements can be built into a mobile terminal such as, for example, a mobile phone, and in an information retrieval terminal such as a PC.","For example, an embedded database can be used for the program information database , the viewing history database , the keyword dictionary , the interesting scene registration information database  and the user behavior model . These databases are not necessarily controlled by the terminal. Instead, the databases may be controlled by a server or the like located at a place other than that of the terminal.","Elements configuring this embodiment will hereinafter be described.","The terminal  is a terminal having a function of viewing a program. An image content receiver, such as a set-top box and a television, can be applied thereto.","The program information database  manages program information such as, for example, an EPG (Electronic Program Guide) distributed from an image distribution server.  shows an example of a configuration of the program information database . The program information database  in the example of the figure includes items of a program name, a scene ID, a schedule, a performer, a genre, a content description and a program time length. The performer is stored with the names of a performer. The content description is stored with text describing program content.","The viewing history database  manages starting and finishing times of viewing by a user, and a time of inputting an \u201cINTERESTED\u201d button on a remote controller. The \u201cINTERESTED\u201d button is a button to be pressed by the user at an interesting scene.  shows an example of a configuration of the viewing history database . The viewing history database  includes items of a scene ID, a starting time of viewing, a finishing time of viewing and a button pressing time. In a case of the example of , it is recorded that the user had viewed a scene of a program P whose scene ID is ID_P from the time AA: AA: AA to the time DD: DD: DD and the \u201cINTERESTED\u201d button of the remote controller had not been pressed during the times. It is also recorded that the user had viewed a scene of a program Q whose scene ID is ID_Q from the time BB: BB: BB to the time EE: EE: EE and the \u201cINTERESTED\u201d button of the remote controller had been pressed on the time GG: GG: GG in the times. Not only the time of pressing the \u201cINTERESTED\u201d button of the remote controller but also the time of transmitting email and the time of web search at the mobile terminal may be recorded as times when the user interested in the scenes.","The interesting scene extraction unit  extracts the scene interesting the user from the program information and viewing histories managed by the program information database  and the viewing history database , respectively. More specifically, the interesting scene extraction unit  refers to the viewing history database  and extract the scene ID of a record where the button pressing time is written, and subsequently accesses the program information database  and extracts a keyword included in the items of the performer, the content description and the like of the record with the scene ID concerned.","The interesting scene registration unit  registers the keyword extracted by the interesting scene extraction unit  from the record with the interesting scene ID of the program information database  with respect to each category of the keyword defined by the keyword dictionary , and stores the keyword in the interesting scene registration information database . Words and phrases in a text not listed in the keyword dictionary are not used.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 4","b":["115","115"]},{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 5","FIG. 3"],"b":["116","116","115"]},"Here, the category indicates a meaning, such as a \u201cperson\u201d and a \u201clocation\u201d, to which the keyword belongs, and is for classifying interests and behavioral objects of the user. The category may be defined by a service provider, automatically generated according to a behavior history of the user, or defined by a plurality of users. In Embodiment 1, the categories have already been defined. The case where the categories are automatically generated from the user behavior history will be described in detail in Embodiment 2. The case where the plurality of users define the categories will be described in Embodiment 3.","The interesting scene presentation unit  acquires information that is analyzed by a behavior analyzer , which will be described later, of the terminal  and is wanted by the user, and presents the interesting scene including the information wanted by the user from the interesting scene registration information database  to the display style determination unit .","The display style determination unit  performs a process of converting a format of image compression system and a display style according to the type of the terminal  displaying the interesting scene. It is supposed that the terminal  is a mobile terminal having a GPS function such as a mobile phone in this embodiment.","The user behavior model  is stored with operation content of the terminal , user behavior inferred from the operation content, and a probability to the item category to be sought next.","The user behavior analyzer  determines the category of the information wanted by the user from the operation history of the terminal  by means of the user behavior model , and transmits the category and the sought probability to the interesting scene presentation unit .","The display unit  is a screen, such as a display, for displaying information, and displays the information transmitted from the display style determination unit  of the terminal .",{"@attributes":{"id":"p-0054","num":"0053"},"figref":["FIG. 6","FIG. 7","FIG. 6"]},"In step , an operation via the mobile terminal is input, thereby activating the behavior analyzer . For example, this operation may be according to a press of a button, which is a button such as \u201cINTERESTING SCENE PRESENTATION\u201d button on the mobile terminal. Instead, the operation may be according to an input that is acquisition of location information by the GPS. Further, the operation may be specific behavior, as an input, such as passing through a ticket gate in a train station. Moreover, email transmission and reception, and a web search behavior may be regarded as inputs. It can be preset to the mobile terminal which timing of the operational input the behavior analyzer is activated.","If the input content is related to the location information, the present location information (latitude, longitude, etc.) is acquired in step . If the input content is related to characters such as email transmission and reception and web searches, a characteristic word is obtained in step . In step , connection is made to the user behavior model , and the item category wanted by the user and the probability are acquired. In step , both or any one of the retrieved item category and the location information is transmitted to the interesting scene presentation unit . The interesting scene presentation unit  searches the interesting scene from information database  for the interesting scene including the information. The search result is passed to the display style determination unit .","In step , the display style determination unit  determines a display style and a presentation style of the retrieved interesting scene. For example, the interesting scene information includes moving images and metadata of a text format. If a display apparatus is an apparatus such as a PC having a sufficient processing speed, displaying the entire information causes no problem. On the other hand, if the display apparatus is something like a mobile phone, displaying the entire information causes problems such as slow processing. Accordingly, displaying only text data and a moving image summary is practical. Thus, the display style determination unit  determines an appropriate display style according to the type and the like of the apparatus on which the interesting scene is to be displayed.","In step , the display style determination unit  presents information to the display unit  in a determined display style. For example, in a case of a display unit of a mobile terminal, one or more interesting scenes transmitted from the display style determination unit  are displayed with program names and thumbnails as shown in  and then the user selects one interesting scene from thereamong, thereby displaying detailed information as shown in . The image on the interesting time is displayed as a thumbnail. The detailed information is, for example, information related to the scene, such as \u201cPerformer C_ recommends Item KW_\u201d and the like. This detailed information has already been registered in the program information database.","Next, processes of acquiring an item category from the user behavior model in step  and of searching for an interesting scene in step  will be described.","The user behavior model stores a behavior and a probability of a category wanted by the user at the time as shown in . The user behavior model may be preset by the service provider or automatically generated from the behavior history of the user. More specifically, as shown in the lower part of , the \u201cbehavior\u201d in the user behavior model shown in  is defined according to a combination of the location information extracted by the process in step  and the keyword extracted by the process in step  shown in . For example, a behavior A is defined as a \u201ctravel\u201d according to a combination of location information outside of the range of livelihood and information of passing a ticket gate of a station. A behavior A is defined as \u201chomecoming\u201d according to a combination of information of passing a ticket gate of a station in the range of livelihood and an input of \u201chomecoming\u201d in email text. An input to the mobile terminal determines the behavior of the user, and acquires a category whose probability to be acquired is the highest on the behavior. In the example in , a \u201ccostume\u201d category is acquired as a category with the highest probability for the behavior A. In another example, provided that the location information is acquired in step , the user behavior model in  is referred to in step , the category with the highest probability is acquired from the models having location information (longitude and latitude) acquired in step  or the nearest location as a behavior.","In step , the interesting scene is searched for on the basis of the information acquired in step  or  and the category acquired in step . If the location information is acquired in step , the location name is acquired from the keyword dictionary using the location information (latitude and longitude), and the interesting scene registration information database is searched for the interesting scene whose keyword is stored in the category acquired in step .","Here, in a case where the interesting scene whose keyword is stored in the category with the highest probability has not been registered in the interesting scene registration information database, the search may be performed using the category with the next highest probability. A point of the priority of the interesting scene may be calculated using the probabilities of the entire categories as with an equation (1).",{"@attributes":{"id":"p-0063","num":"0062"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["Q","S"]},"mo":"=","mrow":{"munderover":{"mo":"\u2211","mi":["i","N"]},"mo":"\u2062","mrow":{"msub":[{"mi":["w","i"]},{"mi":["C","i"]}],"mo":"\u2062"}}}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}}},"Here, Qis a priority of an interesting scene S. i is a category. N is the total number of categories. wis the probability of a category i. Since Crepresents whether a keyword of the category i exists in the scene S or not, a binary value, 0 or 1, may be returned.","A several interesting scenes having higher priorities calculated as with the equation (1) may be employed as a search result. The number of items may be set by the service provider. The number of the items may be separately set according to the apparatus displaying the search result. For example, the different numbers of items to be displayed may be set for a case of displaying on the PC and for a case of displaying on the screen of the mobile terminal. In order to consider freshness of the scene, an elapsed time from the registration date may be utilized for calculation of the point of the priority of the scene in equation (1), as with an equation (2).",{"@attributes":{"id":"p-0066","num":"0065"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["Q","S"]},"mo":"=","mrow":{"mrow":{"mfrac":{"mn":"1","mi":"N"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mi":["i","N"]},"mo":"\u2062","mrow":{"msub":[{"mi":["w","i"]},{"mi":["C","i"]}],"mo":"\u2062"}}},"mo":"-","msub":{"mi":["T","S"]}}}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}}},"Tis a point according to the elapsed time from the registration date of the scene to the present time. The later the registration date, the nearer the point approaches to 0.","For example, in a case where the user is traveling to Hiroshima, when the user presses the \u201cINTERESTING SCENE PRESENTATION\u201d button after passing a ticket gate of the Hiroshima station, the \u201cHiroshima station\u201d is acquired as the location name from the location information by means of the GPS, the \u201ctravel\u201d is acquired as the behavior, the priority of the interesting scene is calculated according to the equation (1) using the probabilities of the entire categories related to the travel from the user behavior model, and the interesting scene is presented. Description will be made using . It is provided that the probabilities of the categories wanted by the user in a case of the behavior \u201ctravel\u201d are set as shown in . The priority of the scene in  is such that ID_P is 60, ID_Q is 60 and ID_R is 40. Here, this allows the user to acquire information that is related to Hiroshima and was interesting in the past but is forgotten by the user, for example an okonomiyaki parlor recommended by a favorite celebrity, along with an original purpose of the travel, for example, The Atomic Bomb Museum.","If text, \u201cComing home now.\u201d, is transmitted via email, the behavior analyzer is activated with the email transmission and reception as an input, the probabilities of the entire categories related to \u201chomecoming\u201d are acquired on the basis of the keyword \u201ccoming\u201d and location information in the range of livelihood using the user behavior model, similar calculation is performed, and the interesting scene is presented. Description will be made using . With the behavior \u201chomecoming\u201d, in a case where the priority of each scene in  is calculated using the category probability in  wanted by the user, the priority of ID_Q is 35, the priority of ID_S is 35, the priority of ID_T is 50, the priority of ID_U is 35. Here, even though the user usually stops at a bookstore on the way home, presentation of information on a movie interesting in the past allows the user to stop at a rental shop.","A function of changing the probability of the category stored in the user behavior model using a user review of the presented information may be added. For example, the probability of the category is increased or decreased according to whether an operation of viewing the interesting scene displayed on the terminal of the user is performed or not. As to the calculation method, for example, only the probability of the category registered in the selected scene is multiplied by 1.1, and the probabilities of the other categories are evenly decreased so as to maintain the total sum of the probabilities to be a certain value. In , with the behavior \u201ctravel\u201d, ID_Q is viewed, and the probabilities of the categories, \u201cperson\u201d, \u201clocation\u201d and \u201crestaurant\u201d, which are registered to the ID_Q, are multiplied by 1.1. That is, each of the probabilities of \u201cperson\u201d, \u201clocation\u201d and \u201crestaurant\u201d becomes 22. The probabilities of the entire categories are divided by the sum of the entire probabilities, i.e., 1.06 in this case, so as to maintain the total sum of the entire probabilities to be 100, and the probabilities are acquired to their first decimal places. As a result, \u201cperson\u201d, \u201clocation\u201d and \u201crestaurant\u201d becomes 20.7, and \u201ctourist site\u201d becomes 37.7. Here, since the total sum becomes 99.8, the remaining 0.2 is added to what has the highest probability. In this case, because \u201ctourist site\u201d is the highest, \u201ctourist site\u201d is made to be 37.9. The calculation method of increase and decrease is not limited thereto. The method may be what can perform feedback of a user review.","Instead, the probability of the category may repeatedly be estimated using a predefined probability distribution (Gaussian distribution, mixed Gaussian distribution, etc.).","The presented interesting scene may be presented to users other than the user concerned via a network such as the Internet. This scene may be stored in an external storing medium, such as a USB memory and shared with another user. Here, video data of the interesting scene may be shared. It may be configured such that only the scene ID or a thumbnail of the scene is shared.","In this embodiment, all of the scenes interesting the user are registered. A function of automatically deleting the scenes on which a certain time period has elapsed after registration may be added. In this case, the time period to deleting may be preset or set by the user himself\/herself.","A case where the above embodiment is extended will hereinafter be described.","[Embodiment 2]",{"@attributes":{"id":"p-0075","num":"0074"},"figref":["FIG. 11","FIG. 1"],"b":["1115","1110","1123","1121","1120","1122"]},"As with Embodiment 1, the interesting scene extraction unit  extracts the interesting scene information. The interesting scene registration unit  performs clustering on the keywords included in the interesting scene according to the context, the simultaneous occurrence probability and the like, and performs grouping, as shown in . A degree of similarity defined by the following equation (3) is used for the clustering.",{"@attributes":{"id":"p-0077","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["d","ij"]},"mo":"=","mfrac":{"msub":{"mi":["N","ij"]},"mrow":{"msub":[{"mi":["N","i"]},{"mi":["N","j"]}],"mo":"+"}}}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}}},"dis the degree of similarity between the keywords i and j. Nis the number of scenes where the keywords i and j concurrently appear. Nis the number of scenes where the keyword i appears. Because the information is of the interesting scene, there is high possibility that the concurrently appearing keywords differ in meaning from each other. Accordingly, what has a low dis regarded similar in meaning, and subjected to the clustering. A pair with low dis detected and regarded as a group, and generation thereof is performed. Here, the number of groups may be set. As to the number of groups, the maximum value of the degree of similarity in the group is set as a threshold, and what is less than or equal to the threshold may be regarded as the group.","The thus generated group is registered as the category in the keyword dictionary , as shown in . The interesting scene is registered on the basis of the thus generated keyword dictionary, as shown in .","Next, a process of generating the user behavior model  from the user behavior history  in the behavior\/category combination learning unit  will be described in detailed.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":["FIGS. 15A and 15B","FIG. 15A"],"b":["1121","1","2"],"sub":"12 "},{"@attributes":{"id":"p-0082","num":"0081"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["V","ij"]},"mo":"=","mfrac":{"msub":{"mi":["D","ij"]},"mrow":{"msub":[{"mi":["D","i"]},{"mi":["D","j"]}],"mo":"+"}}}},{"mrow":{"mo":["(",")"],"mn":"4"}}]}}}}},"Vis the probability that an input i and an input j concurrently occur. Dis the number of concurrent inputs of the inputs i and j, and Dis the number of inputs of the input i.","Only combinations where the probabilities are high and the events are easily to occur are extracted from among the concurrent inputs, and registered as the behaviors (action in ). The process may be performed in the background, or accumulated data may periodically be processed.","Next, a method of extracting a behavior from combinations of inputs having concurrently occurred will be described. For example, an input \u201cpassed the ticket gate of the station\u201d and location information \u201cKokubunji station\u201d acquired from the GPS and the like are concurrently held, thereby generating a table of probabilities that the input behaviors in  have concurrently occurred. Provided that an input  is \u201cpassed the ticket gate\u201d and an input  is \u201cKokubunji station\u201d, Vis stored with the probability of concurrent occurrence. Since Vis one and V=V, only Vij (I\u2266j) is stored on the memory. Combinations with high probabilities of concurrent occurrence are set as behaviors (action) using this table. Here, a threshold of the probabilities to be set as the behaviors has been preset. The number of inputs concurrently input is not limited to two. Instead, the number may be three or more, or one. In a case of a single input, the input and the behavior have preliminarily been associated with each other in a one-to-one relationship.  is a table of correspondence between the generated behaviors and inputs. Here, \u201cconcurrently input\u201d indicates inputs within a predetermined time period. For example, the inputs may be a combination of inputs continuous in time, such that the user passes the ticket gate of the station and then performs a behavior of purchase.","As described above, the generated categories and behavior of the scene are stored in the user behavior model .  is an example of a configuration of the user behavior model . The initial values of the probabilities at the start of system operation may be equal probabilities or be randomly set. As with Embodiment 1, the interesting scene presentation is performed, an evaluation value by the user is fed back, and the probability value connecting the behavior and the scene category is learnt ().","A method of feedback of the evaluation value will be described. An initial value of the probability value associating the item category generated as shown in  and the behavior generated as shown in  is provided. As with Embodiment 1, the priority of the interesting scene information is calculated using the probability value for the item category registered in the user behavior model, and the interesting scene information of the highest several items is presented. The probability value on the behavior of the item category included in the selected interesting scene information is increased as with an equation (5), using an input of whether the user has selected the presented information or not. The probability value of the item category included in the information that has not been selected is decreased, as with an equation (6).\n\n\u2003\u2003(5)\n\n\u2003\u2003(6)\n","Here, wis the probability of a category j on a behavior A. w*is an updated probability, C is an increasing rate of the selected category k (1<C<2), and C is a decreasing rate of the category j (0<C<1) having not been selected. Here, it is assumed that the total sum of the probability values is to be maintained at a certain value. Accordingly, a process of maintaining the sum of the probability values at the certain value is performed, as with an equation (7).",{"@attributes":{"id":"p-0089","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msubsup":{"mi":["w","ij"],"mo":"*"},"mo":"=","mfrac":{"msubsup":{"mi":["w","ij"],"mo":"*"},"mrow":{"munderover":{"mo":"\u2211","mi":["j","N"]},"mo":"\u2062","msubsup":{"mi":["w","ij"],"mo":"*"}}}}},{"mrow":{"mo":["(",")"],"mn":"7"}}]}}}}},"Such feedback of the evaluation value is performed, and thereby the probability value suitable for the user is to be registered as shown in .","In the above description, the scene category and the behavior are not changed after having been generated once. However, update to a new scene category and a new behavior may be performed in consideration with insertion of new program information and complication of operation of the terminal by the user. The clustering process as shown in  is to be periodically performed. The user behavior history as shown in  is periodically recalculated. Further, the generation of a behavior as shown in  is to be periodically performed. Also in this case, the behavior\/category combination learning unit  learns the probability value of the item category in the user behavior model, thereby allowing the user to acquire an appropriate interesting scene.","The keyword dictionary and the user behavior model generated as described above are shared with a user other than the user concerned via a network such as the Internet. The interesting scene presentation may be performed using the keyword dictionary and the user behavior model of the other user. Further, those may be shared using an external storing medium such as a USB memory.","[Embodiment 3]",{"@attributes":{"id":"p-0093","num":"0092"},"figref":"FIG. 17","b":["1730","1715","1721"]},"The server  includes a keyword dictionary editor  and a user behavior editor . The keyword dictionary editor  edits the keyword dictionary . An interesting scene registration information database  of a terminal  of each user is generated according to the edited keyword dictionary . Such editing may be performed by a server administrator or by a plurality of users. The user behavior editor  edits the user behavior model . A behavior analyzer  extracts information on a scene category wanted by the user according to the edited user behavior model . Such editing may also be performed by the server administrator or by the plurality of users. The editing here also indicates addition and deletion of a category. The other configuration is substantially identical to the configuration in  of Embodiment 1.","The editing of keyword dictionary and the user behavior in the server  will be described. The user can always connect to the server  via the Internet, and arbitrarily set the user behavior in the user behavior model  and the category of the keyword. In this case, the user behavior is to have been provided as a combination between \u201cpurchase behavior\u201d, \u201cemail operation\u201d or \u201cweb browsing\u201d and location information such as a location name. The entire keywords are to have been extracted from the interesting scene information database.","For example, as shown in , in the user behavior, the concurrent input, \u201cweb browsing\u201d and \u201cKokubunji station\u201d, is set as a behavior \u201ckilling time\u201d. The category of the keyword is regarded as \u201camusement\u201d, and the category probability is arbitrarily set to the keyword (). The user downloads the edited user behavior model from the server via the Internet, and can thereby acquire new interesting scene information on an actual behavior.","What has been edited in a community site by a plurality of users in the Internet may be downloaded. The user behavior model edited by the other users is shared, and thereby a new combination of the behavior and the keyword category can be discovered.","The keyword dictionary edited in the server  may be downloaded to the terminal , and recorded and stored in the external storing apparatus.",{"@attributes":{"id":"p-0099","num":"0098"},"figref":"FIG. 19","b":["1921","1931"]},"The ontology database  is a database where semantic association of categories is registered.  shows an example of a configuration thereof. Semantic superior\/inferior relationship is registered in the keyword and the scene category, and semantic association between the scene category and the behavior is also registered. On the basis thereof, the user behavior definition unit  generates the user behavior model . The other configuration is substantially identical to the configuration of  of Embodiment 1.","The initial values of the probability values of the behaviors of the user behavior model and the categories wanted by user are set such that the total sum of the categories related to the behavior is 100, using the ontology database. For example, provided that categories X and X are defined for a behavior A, the initial value of each category is set to 50. The learning of the probability value as described above is then performed, and user behavior model optimal to the user is learnt.","The invention of the present application may be applied to, for example, home video apparatuses such as DVD recorders and TVs, personal computers with a TV function, information apparatuses such as PDAs and mobile phones, set-top boxes for playing back network-distributed programs and the like.",{"@attributes":{"id":"p-0103","num":"0000"},"ul":{"@attributes":{"id":"ul0001","list-style":"none"},"li":[{"@attributes":{"id":"ul0001-0001","num":"0102"},"b":"110"},{"@attributes":{"id":"ul0001-0002","num":"0103"},"b":"111"},{"@attributes":{"id":"ul0001-0003","num":"0104"},"b":"112"},{"@attributes":{"id":"ul0001-0004","num":"0105"},"b":"113"},{"@attributes":{"id":"ul0001-0005","num":"0106"},"b":"114"},{"@attributes":{"id":"ul0001-0006","num":"0107"},"b":"115"},{"@attributes":{"id":"ul0001-0007","num":"0108"},"b":"116"},{"@attributes":{"id":"ul0001-0008","num":"0109"},"b":"117"},{"@attributes":{"id":"ul0001-0009","num":"0110"},"b":"118"},{"@attributes":{"id":"ul0001-0010","num":"0111"},"b":"120"},{"@attributes":{"id":"ul0001-0011","num":"0112"},"b":"121"},{"@attributes":{"id":"ul0001-0012","num":"0113"},"b":"122"},{"@attributes":{"id":"ul0001-0013","num":"0114"},"b":"123"}]}}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIGS. 8A and 8B"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIGS. 10A and 10B"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 11","FIG. 1"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 14","FIG. 13"]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIGS. 15A and 15B"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIGS. 16A and 16B"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 17","FIG. 1"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIGS. 18A and 18B","FIG. 17"]},{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 19","FIG. 1"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 20"}]},"DETDESC":[{},{}]}
