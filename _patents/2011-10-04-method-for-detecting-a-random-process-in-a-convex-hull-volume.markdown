---
title: Method for detecting a random process in a convex hull volume
abstract: A method is provided for characterizing data sets containing data points. The method can characterize the data sets as random or as non-random. In the method, a convex hull envelope is constructed which contains the data points and passes through at least four non-coplanar data points. The convex hull envelope is partitioned into cells. The method classifies the data set as a sized sample. Based on the classification, a predetermined set of tests is selected for operating on the data set.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08693288&OS=08693288&RS=08693288
owner: The United States of America as represented by the Secretary of the Navy
number: 08693288
owner_city: Washington
owner_country: US
publication_date: 20111004
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["STATEMENT OF GOVERNMENT INTEREST","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION","Example of Analysis Procedures","Example of Testing Procedure"],"p":["The invention described herein may be manufactured and used by or for the Government of the United States of America for governmental purposes without the payment of any royalties thereon or therefore.","1. Field of the Invention","The present invention relates to the field of sonar signal processing and more particularly, to detecting the presence or absence of spatial random processes in physical phenomena.","2. Description of the Prior Art","In some cases, it can be important or critical to know with a high probability whether data received by a sonar system is simply random noise (which may be a false alarm) or is more likely due to the detection of a vessel of interest. In either situation, it is critical to make a determination as quickly as possible.","Naval sonar systems require that signals be categorized according to structure (i.e., periodic, transient, random or chaotic). A variety of large sample data processing methods such as spectral analysis, correlogram plots, and the like are available. However, a number of scenarios may also or only comprise small samples. These small samples include loss, or intermittent contact, transients, equipment failure, own ship maneuver, and the like. The existence of such sparse data sets requires methods that are appropriate for reliable and valid processing.","As such, there is a need for sparse data set methods in which the methods are separate from those methods which evaluate large sample distributions. It is well known in the art that large sample methods often fail when applied to small sample data sets.","The term \u201crandomness\u201d in regard to random noise has different meanings in science and engineering. Random (or randomness) is herein defined in terms of a \u201crandom process\u201d as measured by a probability distribution model\u2014namely a stochastic (Poisson) process. In naval engineering applications, waveform distributions in the time domain may be considered purely random if the distributions conform to a noise structure such as WGN (White Gaussian Noise). This determination is made regardless of the underlying generating mechanism that produced the \u201cnoise.\u201d","Pure randomness may be considered a data distribution for which no mathematical function, relation, or mapping can be constructed that provides an insight into the underlying structure. For example: no prediction model can be generated from the noise\/time waveform in order to derive estimates of a target range, course, speed, depth, etc. Also, one must distinguish the term \u201cstochastic\u201d randomness from \u201cdeterministic\u201d randomness (chaos) as described in U.S. Pat. No. 5,781,460.","The theoretical and practical considerations relevant to the inventive process are contained in the following publications, which are incorporated herein by reference:","Abramowitz, Milton and Irene Stegun. . Washington, D.C. United States Government Printing Office: (1964).","Feller, William. 2nd ed. Vol. I., NY: John Wiley and Sons (1957).","Ruhkin, A. L. \u201c, Vol. 45, No. 1, pp. 111-132 (2000).","Preparata, Franco P. and Michael I. Shamos, , Springer Verlag (1985).","Swed, F. S. and C. Eisenhart. \u201cTables for testing randomness of grouping in a sequence of alternatives.\u201d 14(1), pp. 66-87 (March 1943).","Wald, A. and J. Wolfowitz. \u201cOn a test whether two samples are from the same population.\u201d , Vol. 11, pp 147-162 (1940)","Wilks, S. S. \u201cOrder statistics.\u201d . Volume 54, Number 1, Part 1, pp. 6-50 (1948).","The standard approach for assessing the hypothesis of spatial randomness for large samples is outlined in the known work on probability theory by W. Feller (Ch. 6, \u201cThe Binomial and Poisson Distributions\u201d) [Feller, William. 2nd ed. Vol. I., NY: John Wiley and Sons. 1957].","Typically, from a frequency table derived from counts of spatial data in a partitioned subspace, a Chi-square test for homogeneity of Poisson frequency levels is computed and compared to a level of statistical certainty. The Feller reference (pp. 149-154), demonstrates the utility of this procedure for several large samples of naturalistic data analyzed in finite rectangular and circular space. The noted data sets include radioactive decay measurements, micro-organism distribution on a Petri dish, and others. However, the Feller reference provides little guidance on the matter of subspace partitioning including how many partitions should be used and what should be done about non-whole subset partitions.","Furthermore, most prior art randomness assessment methods are one time tests designed for one-dimensional or two-dimensional space. The methods are primarily applicable for truly random distributions. However, these quantitative techniques sometimes even fail to correctly label truly nonrandom distributions\u2014as pointed out by Ruhkin (A. L. Ruhkin, \u201cTesting Randomness: A Suite of Statistical Procedures\u201d, 2000, Vol. 45, No. 1, pp. 111-132).","The following United States patents significantly improve the above-noted situation.","U.S. Pat. No. 7,277,573 provides a multi-stage method for automatically characterizing data sets containing data points in which are each defined by measurements of three variables as either random or non-random. A three-dimensional Cartesian volume is sized to contain a total number N of data points in the data set which is to be characterized. The Cartesian volume is partitioned into equal-sized cubes, wherein each cube may or may not contain a data point. A predetermined route is defined that goes through every cube one time and scores each cube as a one or a zero; thereby, producing a stream of ones and zeros. The number of runs is counted and utilized to provide a Runs test which predicts if the N data points in any data set are random or non-random. Additional tests are used in conjunction with the Runs test to increase the accuracy of characterization of each data set as random or non-random.","U.S. Pat. No. 7,409,323 provides a method for automatically characterizing data sets containing data points, which may be produced by measurements such as with sonar arrays, as either random or non-random. The data points for each data set are located within a Cartesian space and a polygon envelope is constructed which contains the data points. The polygon is divided into grid cells by constructing a grid over the polygon. A prediction is then made as to how many grid cells would be occupied if the data were merely a random process. The prediction becomes one of two forms depending on the sample size. For small sample sizes, an exact Poisson probability method is utilized. For large sample sizes, an approximation to the exact Poisson probability is utilized. A third test is utilized to test whether the Poisson based model is adequate to assess the data set as either random or non-random.","As evidenced and in summary, the prior art does not disclose a method to provide a faster solution with greater reliability and for widely varying sizes of three-dimensional data sets. The solutions to the above-described and\/or related problems have been long sought without success. Consequently, those skilled in the art will appreciate the present invention that addresses the above-described and other related problems.","It is therefore a general purpose and primary object of the present invention to provide an improved method for characterizing data sets of physical phenomena such as sonar array signals, medical imaging data, and the like, as random noise or as containing a signal.","It is a further object of the present invention to provide a method for characterizing large data sets as well as sparse data sets.","Accordingly, the present invention provides a method for characterizing a plurality of data sets as being random noise or as containing a signal. The method comprises the steps of reading in data points from a first data set of the plurality of data sets and then creating a three-dimensional hull that encloses the data points. The method further comprises a step of ensuring that the hull has a structure that passes through at least four non-coplanar data points from the first data set.","Additional steps comprise partitioning the three-dimensional hull into a plurality of three-dimensional cells and defining the first data set as being a large sample or a small sample based on a selected parameter.","The method further comprises the steps of utilizing a first plurality of tests for characterizing the first data set as comprising random noise or as a signal when the first data set is defined as a large sample and utilizing a second plurality of tests for characterizing the first data set when the first data set is characterized as a small sample.","In one possible embodiment, the method may comprise a step of partitioning the total volume V of data points into the plurality of three-dimensional cells by utilizing at least one of terms",{"@attributes":{"id":"p-0032","num":"0031"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mroot":[{"mfrac":{"mi":["V","k"]},"mn":"3"},{"mfrac":{"msub":{"mi":["V","p"]},"mi":"N"},"mn":"3"}],"mo":[",",",",","],"mrow":{"mi":"or","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mroot":{"mfrac":{"mi":["V","N"]},"mn":"3"}}}}},"br":{}},"Vis the volume of the convex hull;","N is the number of points; and k is a value based at least partially on N.","The method may also comprise the step of ending the testing after any of the first plurality of tests or if the second plurality of tests indicates that the first data set comprises the signal.","In another possible embodiment, the second plurality of tests comprises determining a significance probability value for the small sample for a two-tailed hypothesis for a quasi-symmetric finite discrete Poisson probability distribution.","The first plurality of tests may comprise at least a Runs test, a correlation test, an R ratio and confidence interval analysis and a normal approximations z-test for a Poisson distribution. These tests are completed on a number of non-empty of the plurality of cells wherein the first plurality of tests are performed in a predefined and sequential order.","The second plurality of tests may comprise at least a Runs test, a correlation test, an R ratio and confidence interval analysis and an exact Poisson distribution hypothesis test wherein the second plurality of tests are performed in a predefined and sequential order.","The present invention enhances the likelihood that a correct decision is made in multi-dimensional space for samples of varying sizes. The invention also provides a method to determine whether the three-dimensional data structure conforms to a random process (i.e., predominantly random).","In the preferred embodiment, the present invention creates a compact space by forming a convex hull around time-based measurements. Convex hulls as used herein are discussed by Franco P. Preparata and Michael I. Shamos, Computational Geometry\u2014An Introduction, Springer Verlag, 1985; the discussion incorporated herein by reference.","As used herein, the convex hull of a set of points in space is the surface of a minimum area with a convex (outward) curvature that passes through all the points in the set. In three dimensions, the set must contain at least four distinct, non-coplanar points to make a closed surface with a nonzero enclosed volume.","Typically, a convex hull in the volume will occupy about thirty-five to sixty percent less space than the space needed for containing a rectangular solid\u2014such as proposed in U.S. Pat. No. 7,277,573. Generally, the larger the sample size then the smaller that this difference becomes. As such, a major advantage of the present invention is a more compact region; meaning less processing time. This lessoned processing time is especially noticeable for smaller measurement sets.","A sequenced set of randomness assessment tools tests the randomness hypotheses. The testing is conducted in a sequenced multi-stage paradigm with built-in protocols for detecting aberrant data structures. A flexible mix of known parametric, nonparametric and correlational testing procedures is selectable for similar problems in military and commercial environments.","In one embodiment of the invention, a streamlined decision module functions on an \u201call or nothing\u201d principle. In another embodiment, an operator has the option of ceasing randomness assessment upon one (or more) instance(s) of a non-random testing result. This approach maximizes the likelihood of a correct decision in a shorter period of time and minimizes the chance of an incorrect decision regarding the signal-noise hypothesis. This approach also reduces unnecessary data processing time when searching for a signal classification in the observed noise-dominated data.","Table 1 reflects the structure of the data sets that this invention evaluates in analysis subsystems.",{"@attributes":{"id":"p-0050","num":"0049"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Typical Data Set of a Time-Series in Three-Dimensional "},{"entry":"Cartesian Space For N Measurements"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"91pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Time","Measurement","Measurement"]},{"entry":["(t)","(y)","(z)"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["t","y","z"]},{"entry":["t","y","z"]},{"entry":[".",".","."]},{"entry":["t","y","z"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"It is noted that Time (t) may be replaced by a non-temporal continuous variable X.","These inputted time series (or non-time series) data of unknown structure are first enveloped in a convex hull. The solid polygon shape of the hull is then partitioned into a predetermined number of three-dimensional cubic cells showing a dependent variable x (typically clock time).  depicts a convex hull  enclosing a pseudo-random data set of fifty time-data points (x) [shown as labeled item ] with randomized amplitudes of forty and thirty units (y, z), partitioned into sixty cubic cells. The reduced observation space of approximately fifty percent is notable and is the key to a faster solution. After the waveform is enclosed with a convex hull, then the convex hull is partitioned into three-dimensional partitions (as indicated by partitioning lines ).","Following this method, a noise-free hull-enclosed helix can be determined to have a signal with a high degree of certainty. Other input waveforms which comprise data points, such as a hull-enclosed elliptic parabaloid, are also found to have a signal with a high degree of certainty.","Exemplary partitioning methods are explained as follows:","Method 1: The first method employs an algorithm that accounts for the length of each axis and identifies how many points are used to determine an ideal number of cubes to partition the total volume V. Taking the cube root of the value found (k),",{"@attributes":{"id":"p-0056","num":"0055"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mroot":{"mfrac":{"mi":["V","k"]},"mn":"3"},"mo":","}}},"br":{}},"Method 2: The second method uses the formula",{"@attributes":{"id":"p-0058","num":"0057"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mroot":{"mfrac":{"msub":{"mi":["V","p"]},"mi":"N"},"mn":"3"},"mo":","}}},"br":{},"sub":"p "},"Method 3: The third method uses the formula",{"@attributes":{"id":"p-0060","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mroot":{"mfrac":{"msub":{"mi":["V","p"]},"mi":"N"},"mn":"3"},"mo":"."}}},"br":{},"figref":"FIG. 1"},"Method 4: The fourth and final method uses the same formulae but also eliminates excess space around the hull. This method identifies that at least one point on the face of the convex hull must be tangent to the y-z plane of the containing region x, y, z. Another alternative deletes or minimizes non-whole cubic subspaces. The fourth method is preferred as affording the tightest possible envelope of an input waveform.","Large Sample Testing Procedures","Method A (Wald-Wolfowitz Independent Sample Runs Test Procedure)","An initial statistical test on input distributions is performed to evaluate the time-series structure of individual data sets. The Runs test is a non-parametric combinatorial test that assesses a randomness hypothesis for a two-valued data sequence and is well known to those skilled in the art [Wald, A. and J. Wolfowitz. \u201cOn a test whether two samples are from the same population.\u201d ., Vol. 11, pp 147-162, (1940)].","The Runs test has been previously applied in the art to spatial distributions. The test is attractive because it can be applied for spatial randomness in small or large samples with exact probabilities when assumptions of parametric testing procedures are not met. The novel utility in three dimensions was initially demonstrated for a rectangular and solid envelope in U.S. Pat. No. 7,277,573 (O'Brien).","In the Runs test, the procedural steps for a convex hull that are partitioned into cubic subspaces are as follows:","Step 1. Assign a value of \u201c0\u201d or \u201c1\u201d to respectfully indicate a cell as empty or non-empty. The assignment should be identified separately from the number of points in a cell or cell size. Subsequently, count the number of runs in the observation space of the volume in the same manner specified in U.S. Pat. No. 7,277,573 for a three-dimensional data set. A run (also known as a \u201cclump\u201d) is a countable sequence of at least one consecutive and identical outcome. For the present invention, a run is a sequential and homogeneous stream of assigned 0 or 1 data followed by a different sequential and homogeneous stream of 0 or 1 data.","Arbitrarily label the total number of 1 data identifiers by nand the total number of 0 data identifiers by n. For example and for the following data exhibit: n=eight 1 data identifiers and n=thirteen 0 data identifiers. The total sample size is n=n+n, and six runs:",{"@attributes":{"id":"p-0067","num":"0066"},"chemistry":{"@attributes":{"id":"CHEM-US-00001","num":"00001"},"img":{"@attributes":{"id":"EMI-C00001","he":"17.86mm","wi":"57.40mm","file":"US08693288-20140408-C00001.TIF","alt":"embedded image","img-content":"chem","img-format":"tif"}}}},"Here, the sample shows r=six runs (out of greater than 200,000 combinations) which may be tested for randomness. A sample of ordered binary data (1\/0), corresponding to the behavior of the amplitudes of the time-series may show too few or too many runs to be attributable to mere chance variation. This sample indicates deterministic signal information which may be extracted in detecting or tracking objects in an ocean environment. Alternatively, the number of runs may be in accordance with the laws of probability; thereby, indicating a mere chance fluctuation in the behavior of the time series distribution. This fluctuation is indicative of random noise.","Step 2. In a distribution that is truly random, an expected or average number of total runs E(r) is given by the derived relationship:",{"@attributes":{"id":"p-0070","num":"0069"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"E","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}},{"mfrac":{"mrow":[{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":[{"mi":"n","mn":"1"},{"mi":"n","mn":"2"}]},{"msub":[{"mi":"n","mn":"1"},{"mi":"n","mn":"2"}],"mo":"+"}]},"mo":"+","mn":"1"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}}},"Step 3. The variance or spread in the number of runs of a random sample is computed as:",{"@attributes":{"id":"p-0072","num":"0071"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msubsup":{"mi":["\u03c3","r"],"mn":"2"},"mo":"=","mfrac":{"mrow":[{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":"n","mn":"1"},"mrow":{"msub":{"mi":"n","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":[{"mi":"n","mn":"1"},{"mi":"n","mn":"2"}]},"mo":["-","-"],"msub":[{"mi":"n","mn":"1"},{"mi":"n","mn":"2"}]}}}},{"msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"n","mn":"1"},{"mi":"n","mn":"2"}],"mo":"+"}},"mn":"2"},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"n","mn":"1"},{"mi":"n","mn":"2"}],"mo":["+","-"],"mn":"1"}}}]}}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}}},"Step 4a. For large samples, to statistically assess the relationship of the total sample number of runs r in dimensional space to the distributional moments, E(r), \u03c3; the sample statistic r is submitted to a Gaussian normally distributed test statistic z (with a mean 0 and a variance 1):",{"@attributes":{"id":"p-0074","num":"0073"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"z","mo":"=","mrow":{"mfrac":{"mrow":{"mi":"r","mo":"-","mrow":{"mi":"E","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}},"msqrt":{"msubsup":{"mi":["\u03c3","r"],"mn":"2"}}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":"n","mn":"1"},"mo":",","mrow":{"msub":{"mi":"n","mn":"2"},"mo":">","mn":"10"}}}}}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}}},"Step 4b. Compute the significance probability p of the observed result from the continuous standard Gaussian (normal) distribution:",{"@attributes":{"id":"p-0076","num":"0075"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"p","mo":"=","mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Z","mo":"\u2264","mrow":{"mo":"-","mi":"z"}}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Z","z"],"mo":"\u2265"}}}],"mo":"+"}}}},{"mtd":{"mrow":{"mo":"=","mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Z","z"],"mo":"\u2264"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Z","mo":"\u2264","mrow":{"mo":"-","mi":"z"}}}}],"mo":"-"}}}}}},{"mtd":{"mrow":{"mrow":{"mo":"=","mrow":{"mn":"1","mo":"-","mrow":{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mrow":[{"mo":"-","mrow":{"mo":["\uf603","\uf604"],"mi":"z"}},{"mo":"+","mrow":{"mo":["\uf603","\uf604"],"mi":"z"}}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mi":"x","mn":"2"}}}},{"mo":"\u2146","mi":"x"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}}}},"mo":","}}}]},"mo":["\u2062","-"],"mstyle":{"mtext":{}},"mi":"\u221e"},{"mo":["\uf603","\uf604"],"mi":"z"},{"mo":"+","mi":"\u221e"}],"mo":["<","<"]},{"mn":["0","1"],"mo":["\u2264","\u2264"],"mi":"p"}],"mo":","}},{"mrow":{"mo":["(",")"],"mn":"4"}}]}}}},"br":{},"sub":["1","2"]},"The p value is the probability of detecting noise. Another interpretation is that p represents the impression that the null hypothesis of random noise is true. Small values of p lead to rejection of the null hypothesis of noise.","For example, in the case of pure noise, z=0 in Equation (3) and p=1 by Equation (4). In the case of a pure signal, \u00b1|z|\u2192\u00b1\u221e and p=0 by Equation (4). The calculation of p, well known to those skilled in the art, is performed in a standard finite series expansion.","An estimate of the p value is provided for both the large and small sample testing procedures. This approach streamlines the evaluation process to a simple comparison of p against the a priori false alarm rate \u201c\u03b1\u201d.","Step 4c. If the sample is small (n, n\u226610), save the n, nand r values in memory and proceed to Step 5.","Step 5. Calculate the p value, either for the z statistic by Equation (4) or for small samples. The cumulative probability for computed sample runs r is determined by computing the probability of obtaining a quantity Pr(r\u2266r\u2032)\u2014the likelihood of obtaining that many runs or less in a random sample.","To obtain the two-sided equivalent for non-directional hypotheses, the above probability is doubled to obtain the composite significance probability, p=Pr(r\u2266r\u2032)+Pr(r\u2267r\u2032). The probability of runs, conditional upon r being an even or odd number, is provided by the following combinatorial ratios [see Wilks, S. S. \u201cOrder statistics\u201d . Volume 54, Number 1, Part 1, pp. 6-50, (1948)].","For the case of r EVEN point probability",{"@attributes":{"id":"p-0084","num":"0083"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"r","mo":"=","mrow":{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"k"}}}},{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mfrac":{"mrow":[{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"1"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"2"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}}],"mo":"\u2062"},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":[{"mi":"n","mn":"1"},{"mi":"n","mn":"2"}],"mo":"+"}}},{"mtd":{"msub":{"mi":"n","mn":"1"}}}]}}]}}],"mo":"="},{"mi":"k","mo":"=","mn":"1"}],"mo":[",",",",",","\u2062",",",","],"mn":"2","mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"msub":{"mi":"n","mn":"1"}}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}}},"where k is found from r=2k and",{"@attributes":{"id":"p-0086","num":"0085"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mi":"a"}},{"mtd":{"mi":"b"}}]}},"mo":"=","mfrac":{"mrow":[{"mi":"a","mo":"!"},{"mrow":[{"mi":"b","mo":"!"},{"mrow":{"mo":["(",")"],"mrow":{"mi":["a","b"],"mo":"-"}},"mo":"!"}],"mo":"\u2062"}]}}}},"br":{}},"For the case of r ODD point probability",{"@attributes":{"id":"p-0088","num":"0087"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"r","mo":"=","mrow":{"mrow":{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"k"},"mo":"-","mn":"1"}}}},"mo":"=","mfrac":{"mrow":[{"mrow":[{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"1"},"mo":"-","mn":"1"}}},{"mtd":{"mi":"k"}}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"2"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}}],"mo":"\u2062"},{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"1"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"2"},"mo":"-","mn":"1"}}},{"mtd":{"mi":"k"}}]}}],"mo":"\u2062"}],"mo":"+"},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":[{"mi":"n","mn":"1"},{"mi":"n","mn":"2"}],"mo":"+"}}},{"mtd":{"msub":{"mi":"n","mn":"1"}}}]}}]}},{"mi":"k","mo":"=","mn":"2"},{"msub":{"mi":"n","mn":"2"},"mo":"-","mn":"1"}],"mo":[",","\u2062",",",",","\u2062",",",","],"mstyle":[{"mtext":{}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mn":"3","mi":"\u2026"}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}},"br":{}},{"@attributes":{"id":"p-0089","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"\u2003","mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mi":"a"}},{"mtd":{"mi":"b"}}]}}}}},"br":{}},"The total cumulative probability for a two-sided alternative is p=Pr(r\u2266r\u2032)+Pr(r\u2267r\u2032) and is derived by summing the point probabilities above. The cumulative probability value p is obtained in accordance with the process specified in Swed and Eisenhart F. S. Swed and C. Eisenhart. \u201cTables for testing randomness of grouping in a sequence of alternatives.\u201d 14(1):66-87, (March 1943).","For cumulative probability, r EVEN or ODD:",{"@attributes":{"id":"p-0092","num":"0091"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"r","mo":"\u2264","msup":{"mi":["r","\u2032"]}}}},{"mo":"{","mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mfrac":{"mn":"2","mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mi":"n"}},{"mtd":{"msub":{"mi":"n","mn":"1"}}}]}}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mfrac":{"mi":"r","mn":"2"}},"mo":"\u2062","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"1"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"2"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}}],"mo":"\u2062"}}}},"mo":","}}},{"mtd":{"mrow":{"mrow":[{"mrow":{"msub":[{"mi":"n","mn":"1"},{"mi":"n","mn":"2"}],"mo":"+"},"mo":"=","mi":"n"},{"mi":"r","mo":"=","mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"k","mrow":{"mo":["(",")"],"mrow":{"mi":["r","EVEN"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}}}}],"mo":";"}}},{"mtd":{"mrow":{"mrow":{"mfrac":{"mn":"1","mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mi":"n"}},{"mtd":{"msub":{"mi":"n","mn":"1"}}}]}}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"2"},"mfrac":{"mrow":{"mi":"r","mo":"+","mn":"1"},"mn":"2"}},"mo":"\u2062","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"1"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"2"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"2"}}}]}}],"mo":"\u2062"},{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"1"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"2"}}}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"2"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}}],"mo":"\u2062"}],"mo":"+"}}}},"mo":","}}},{"mtd":{"mrow":{"mrow":[{"mrow":{"msub":[{"mi":"n","mn":"1"},{"mi":"n","mn":"2"}],"mo":"+"},"mo":"=","mi":"n"},{"mi":"r","mo":"=","mrow":{"mrow":[{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"k"},{"mn":"1","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mi":["r","ODD"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}}}],"mo":["\u2062","-"],"mstyle":{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}}}}],"mo":";"}}}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"7"}}]}}}}},"The above cumulative probability values must be doubled to assess the non-directional hypothesis specified below. The cumulative probability value p is the most important datum to employ in the decision rule for this subsystem testing.","The standard statistical practice will be used throughout the present method. The rule specifies:\n\n","In the decision truth table of signal detection theory, this is considered to be the most serious error for this noise processor system. That is, when the call is SIGNAL but NOISE is dominant, then this is a serious error. This results in unnecessary processing time and is an error which must be minimized.","The value of \u03b1 represents the percentage of time that a wrong decision will be made (for example: the error of rejecting a null hypothesis when actually true). Obviously, minimizing this type of significant error is a substantive factor in the present method. Correlatively, minimizing \u03b1 also maximizes 1\u2212\u03b1, defined as Pr(Accept H|H=True), which amounts to calling noise correctly. \u201cTrue\u201d indicates that the distribution is truly random. If \u03b1=five percent, this confidence probability 1\u2212\u03b1 is approximately ninety-five percent.","For a hypothesis text, the non-directional or two-tailed binary hypothesis set is:\n\n","The distribution is labeled NOISE if p\u2267\u03b1, where \u03b1 is the false alarm rate. Otherwise, the presence of a signal is most likely indicated by this system subtest.","For the interpretation of a significant outcome (SIGNAL+NOISE); if r is significantly lower than the expected value E(r), this implies a grouping or clustering of measurements (for example: a periodic function produced by rotating or reciprocating machinery). Other possible forms include parabolic and helical surface functions.","If r is significantly higher than the expected value E(r); this implies a repeated and alternating pattern in the measurements. It should be noted that the null hypothesis of \u201cnoise only\u201d is analogous to the hypothesis of \u201cNO TARGET\u201d in signal detection theory and the opposite is analogous to \u201cTARGET\u201d.","As an example of the calculations for this important module of the subsystem assessment protocol; assume n=8; n=21 (n=29) and r=6 (there are over four million possible runs combinations for this sample). The data may be analyzed by the two-tailed probability method and by the approximate Gaussian distribution method.","Since the number of runs is even, the probability of this many runs or less from Equation (7) is:",{"@attributes":{"id":"p-0103","num":"0106"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"r","mo":"\u2264","mn":"6"}}},{"mrow":[{"mfrac":{"mn":"2","mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mi":"n"}},{"mtd":{"msub":{"mi":"n","mn":"1"}}}]}}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mfrac":{"mi":"r","mn":"2"}},"mo":"\u2062","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"1"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"msub":{"mi":"n","mn":"2"},"mo":"-","mn":"1"}}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}}],"mo":"\u2062"}}}},{"mrow":{"mfrac":{"mn":"2","mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mn":"29"}},{"mtd":{"mn":"8"}}]}}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mn":"3"},"mo":"\u2062","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mn":"7"}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mn":"20"}},{"mtd":{"mrow":{"mi":"k","mo":"-","mn":"1"}}}]}}],"mo":"\u2062"}}}},"mo":"=","mi":".0019"}],"mo":"="}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}}}},"br":{}},"The small sample normal approximation method with continuity correction factor is provided from Equation (3):",{"@attributes":{"id":"p-0105","num":"0108"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"z","mo":"=","mrow":{"mfrac":{"mrow":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"r","mo":"-","mrow":{"mi":"E","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}}},"mo":"-","mfrac":{"mn":["1","2"]}},"msqrt":{"msubsup":{"mi":["\u03c3","r"],"mn":"2"}}},"mo":"=","mn":"2.91"}}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}},"br":{}},{"@attributes":{"id":"p-0106","num":"0109"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"p","mo":"=","mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Z","mo":"\u2264","mn":"2.91"}}},{"mrow":{"mn":"1","mo":"-","mrow":{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mrow":[{"mo":"-","mrow":{"mo":["\uf603","\uf604"],"mn":"2.91"}},{"mo":"+","mrow":{"mo":["\uf603","\uf604"],"mn":"2.91"}}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":"\u2062","msup":{"mi":"x","mn":"2"}}}},{"mo":"\u2146","mi":"x"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}}},"mo":"=","mi":".0036"}],"mo":"="}}},{"mrow":{"mo":["(",")"],"mn":"10"}}]}}}}},"Each method gives almost identical results at a high degree of precision. If the false alarm rate is 0.05 or 0.01, then p<\u03b1Signal+Noise. Also, since r<E(r), the data indicates that mechanism-producing periodic motion is suspected.","It is noted that the Runs test has shown high power (call signal correctly) to detect input signal time waveforms. In one experiment, the Runs test quickly detected a signal for a fifty point hull-enclosed elliptic paraboloid with the detection having a high degree of probability.","The significance probability was p=0.000050834 by Equations (3) and (4), which represents the likelihood that this waveform is actually random noise. Since the number of runs was observed to be far less than expected; this indicated a strong structural grouping or clustering of measurements (for example: a periodic\/parabolic or a helical surface function).","Method B (R Ratio)","A prior art measure useful in the interpretation of outcomes is the R ratio. The R ratio is defined as the observed-to-theoretical expected occupancy rates in partitioned space:",{"@attributes":{"id":"p-0111","num":"0114"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"R","mo":"=","mfrac":{"mi":"m","mrow":{"mi":"k","mo":"*"}}}},{"mrow":{"mo":["(",")"],"mn":"11"}}]}}}}},"where \u201cm\u201d=the observed number of cells occupied (non-empty) in partitioned space; \u201ck\u201d=the number of spatial partitions, and =1\u2212e, a Poisson measure specifying the probability that a partition is non-empty in a sample and the proportion of cells expected to be non-empty in a random distribution. k* is the Poisson mean number of non-empty partitions.","The range of sample values for R indicate: R<1 (clustered distribution); R\u22481 (random distribution); and R>1 (uniform distribution). The minimum R is R=1\/k and the maximum R is R=N\/k, where N is sample size.","The R ratio is graphed as a linear function in a sample for 1\u2266m\u2266N. This measure is used in conjunction with prior art methods in deciding whether to accept or to reject a randomness hypothesis.","An R ratio between 0.90-1.10 is indicative of noise. Outside of that range; a signal waveform should be suspected. For highly skewed distributions (k being much larger than N); a signal structure is suspected when R\u2267R.","The R ratio is a heuristic measure only in that no probability bands of confidence are associated with the computed value. The interpretation of gathered results should merely confirm or deny a random process when read in conjunction with the results derived from previously developed probability and statistical analyses. Latter-described Method D provides a statistical assessment of the R ratio and a method to determine a ninety percent, ninety-five percent or ninety-nine percent confidence band for R. This capability significantly expands prior art methods.","Along with the correlation module measures in Method C, the R ratio test is a second measure for detecting readings. In operational use, the calculation of the R ratio should be embedded in the testing procedure for Method D.","Method C (Correlation Module)","The use of a multiple linear correlation R for 1 criterion\u2014or dependent variable (usually time t and c predictors or independent variables which are measurements coincident with time) of sample size N is one measure employed to correct the paradox mentioned above in respect to randomness assessment test readings that provide false results for deterministic multivariate functions. The range is 0\u2267R\u22661 where values near 0 indicates randomness. This statistical measure will help detect threats to the integrity of the method for a class of linear functions. The likelihood that a correct decision is made will be enhanced and lessens the likelihood that an incorrect decision will be made in regard to \u201csignal\u201d vs. \u201cnoise\u201d.","The squared multiple correlation index for predictors (Y and Z) is derived from the ordinary least squares minimization technique and can be expressed as a weighted sum:",{"@attributes":{"id":"p-0120","num":"0123"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mtable":{"mtr":[{"mtd":{"mrow":{"msubsup":{"mi":"R","mrow":{"mrow":{"mi":["t","y"],"mo":"\u00b7"},"mo":",","mi":"z"},"mn":"2"},"mo":["=","\u2062"],"mi":{},"mfrac":{"mrow":{"mrow":[{"msub":[{"mi":["\u03b2","y"]},{"mi":["r","ty"]},{"mi":["\u03c3","y"]}],"mo":["\u2062","\u2062"]},{"msub":[{"mi":["\u03b2","z"]},{"mi":["r","tz"]},{"mi":["\u03c3","z"]}],"mo":["\u2062","\u2062"]}],"mo":"+"},"msubsup":{"mi":["\u03c3","t"],"mn":"2"}}}}},{"mtd":{"mrow":{"mo":["=","\u2062"],"mi":{},"mfrac":{"mrow":[{"msubsup":[{"mi":["r","ty"],"mn":"2"},{"mi":["t","tz"],"mn":"2"}],"mo":["+","-"],"mrow":{"mn":"2","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":[{"mi":["r","ty"]},{"mi":["r","tz"]},{"mi":["r","yz"]}]}},{"mn":"1","mo":"-","msubsup":{"mi":["r","yz"],"mn":"2"}}]}}}}]},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"mrow":{"mrow":{"mrow":[{"mn":["0","1"],"mo":["\u2264","\u2264"],"msubsup":{"mi":"R","mrow":{"mrow":{"mi":["t","y"],"mo":"\u00b7"},"mo":",","mi":"z"},"mn":"2"}},{"mrow":[{"mo":"-","mn":"1"},{"mo":["[","]"],"mrow":{"msub":[{"mi":["r","ty"]},{"mi":["r","tz"]},{"mi":["r","yz"]}],"mo":[",",","]}},{"mo":"+","mn":"1"}],"mo":["\u2264","\u2264"]}],"mo":";"},"mo":","}}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}},"br":{},"sub":["y ","z ","ty","tz ","yz ","y ","z "],"sup":"2"},"The driving factors in Equation (12) are the zero-order intercorrelations (rrand) of the amplitude measures with time. If the amplitude measures are random, no systematic relationship should exist in the time domain. This leads to an overall composite multiple correlation approaching zero which is a situation that is indicative of noise.","This correlation function is known to those skilled in the art. The multiple R is tested for a difference from 0 (randomness) by the statistical F (variance-ratio) distribution (with c and N-c-1 degrees of freedom) using the following distributional relation:",{"@attributes":{"id":"p-0123","num":"0126"},"maths":{"@attributes":{"id":"MATH-US-00019","num":"00019"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"msubsup":{"mi":"R","mrow":{"mrow":{"mi":["t","y"],"mo":"\u00b7"},"mo":",","mi":"z"},"mn":"2"},"mrow":{"mn":"1","mo":"-","msubsup":{"mi":"R","mrow":{"mrow":{"mi":["t","y"],"mo":"\u00b7"},"mo":",","mi":"z"},"mn":"2"}}},"mo":"\u2062","mrow":{"mfrac":{"mrow":{"mi":["N","c"],"mo":["-","-"],"mn":"1"},"mi":"c"},"mo":"~","mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"c","mo":",","mrow":{"mi":["N","c"],"mo":["-","-"],"mn":"1"}}}}}}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}}}}},"If Ris approximately zero, it can be concluded that the data conforms to a random distribution. The hypothesis set is typically two-tailed.","In the present invention, c is representative of two independent variables (Y, Z). The significance probability p is obtained by direct evaluation of the distribution density F. That is,",{"@attributes":{"id":"p-0126","num":"0129"},"maths":{"@attributes":{"id":"MATH-US-00020","num":"00020"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"p","mo":"=","mrow":{"mrow":[{"mn":"1","mo":"-","mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"F","mrow":{"msub":[{"mi":"v","mn":"1"},{"mi":"v","mn":"2"}],"mo":","}},{"mi":"f","mrow":{"msub":[{"mi":"v","mn":"1"},{"mi":"v","mn":"2"}],"mo":","}}],"mo":"\u2264"}}}},{"mrow":[{"mn":"1","mo":"-","mrow":{"mfrac":{"mrow":[{"mi":"\u0393","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mrow":{"msub":[{"mi":"v","mn":"1"},{"mi":"v","mn":"2"}],"mo":"+"},"mn":"2"}}},{"mrow":[{"mi":"\u0393","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":{"mi":"v","mn":"1"},"mn":"2"}}},{"mi":"\u0393","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":{"mi":"v","mn":"2"},"mn":"2"}}}],"mo":"\u2062"}]},"mo":["\u2062","\u2062"],"msup":{"mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":"v","mn":"1"},{"mi":"v","mn":"2"}]}},"mfrac":{"msub":{"mi":"v","mn":"1"},"mn":"2"}},"mrow":{"msubsup":{"mo":"\u222b","mn":"0","mi":"F"},"mo":"\u2062","mrow":{"msup":{"mrow":[{"msup":{"mi":"y","mrow":{"mfrac":{"msub":{"mi":"v","mn":"1"},"mn":"2"},"mo":"-","mn":"1"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"+","mrow":{"mfrac":{"msub":[{"mi":"v","mn":"1"},{"mi":"v","mn":"2"}]},"mo":"\u2062","mi":"y"}}}},{"mo":"-","mfrac":{"mrow":{"msub":[{"mi":"v","mn":"1"},{"mi":"v","mn":"2"}],"mo":"+"},"mn":"2"}}]},"mo":"\u2062","mrow":{"mo":"\u2146","mi":"y"}}}}},{"mfrac":{"mn":"1","msup":{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"+","mrow":{"mfrac":{"msub":[{"mi":"v","mn":"1"},{"mi":"v","mn":"2"}]},"mo":"\u2062","mi":"F"}}},"mfrac":{"msub":[{"mi":"v","mn":"2"},{"mi":"v","mn":"1"}]}}},"mo":"=","msup":{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msubsup":{"mi":"R","mrow":{"mrow":{"mi":["t","y"],"mo":"\u00b7"},"mo":",","mi":"z"},"mn":"2"}}},"mfrac":{"msub":{"mi":"v","mn":"2"},"mn":"2"}}}],"mo":"="}],"mo":"="}},{"mrow":[{"mn":"0","mo":["\u2264","<"],"mi":["F","\u221e"]},{"mn":["0","1"],"mo":["\u2264","\u2264"],"mi":"p"}],"mo":[",",","]}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"14"}}]}}}},"br":{},"sub":["1","2"]},{"@attributes":{"id":"p-0127","num":"0130"},"maths":{"@attributes":{"id":"MATH-US-00021","num":"00021"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"F","mo":"=","mrow":{"mfrac":[{"msubsup":{"mi":"R","mrow":{"mrow":{"mi":["t","y"],"mo":"\u00b7"},"mo":",","mi":"z"},"mn":"2"},"mrow":{"mn":"1","mo":"-","msubsup":{"mi":"R","mrow":{"mrow":{"mi":["t","y"],"mo":"\u00b7"},"mo":",","mi":"z"},"mn":"2"}}},{"msub":[{"mi":"v","mn":"2"},{"mi":"v","mn":"1"}]}],"mo":"\u2062"}}}},"br":{}},"The value p is interpreted by comparison to the false alarm rate (for example: p\u2267\u03b1Noise; otherwise, p<\u03b1Signal+Noise).","For example, in one typical pseudo-random data set analyzed with fifty measurements, R=0.0424, p\u22480.96 (NOISE) by Equation (14).","In order to recognize the minimum value that the multiple correlation can achieve for the noise hypothesis to be rejected, R is solved",{"@attributes":{"id":"p-0131","num":"0134"},"maths":{"@attributes":{"id":"MATH-US-00022","num":"00022"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":"R","mrow":{"mrow":{"mi":["t","y"],"mo":"\u00b7"},"mo":",","mi":"z"}},"mo":"\u2265","msqrt":{"mrow":{"mn":"1","mo":"-","msup":{"mi":"p","mfrac":{"mn":"2","msub":{"mi":"v","mn":"2"}}}}}}},{"mrow":{"mo":["(",")"],"mn":"15"}}]}}}},"br":{},"sub":"2"},"In addition to the linear multiple correlation, the present method specifies computing a discrete normalized Autocorrelation Function (ACF) indices for one, two and three time-lags or alternatively more (depending on sample size N) if the multiple linear R shows noise.","Autocorrelation is the cross-correlation of a signal with itself. The measure is designed to detect repeating patterns in nonlinear time-series distributions (e.g., periodic, quasi-periodic, parabolic, etc.).","Whereas, the linear measure Rwill detect a linear trend relationship in time; the linear measure will not necessarily detect nonlinear relationships among the amplitude measurements. The autocorrelation function will better detect such nonlinear trends which other testing procedures may mislabel as noise.","As provided below, the method computes autocorrelations for two models (first with Yas a dependent variable and then with Zas a dependent variable). Table 2 illustrates the structure for an autocorrelation analysis of 1, 2, 3-lags, with a Ydependent variable.",{"@attributes":{"id":"p-0136","num":"0139"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Model Illustrating Three-lag Autocorrelations"},{"entry":"(Amplitude Yas a dependent variable)"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},{},{},"(4)","(5)","( 6)"]},{"entry":[{},"(1)","(2)","(3)","Z","Z","Z"]},{"entry":[{},"T","Y","Z","indep","indep","indep"]},{"entry":[{},"Time","depend","indep","Lag-1","Lag-2","Lag-3"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"6","align":"center","rowsep":"1"}}]},{"entry":[{},"t","y","z","z","z","z"]},{"entry":[{},"t","y","z","z","z","z"]},{"entry":[{},".",".",".",".",".","."]},{"entry":[{},"t","y","z","z","z","z"]},{"entry":[{},"t","y","z","z","z",{}]},{"entry":[{},"t","y","z","z",{},{}]},{"entry":[{},"t","y","z"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"6","align":"center","rowsep":"1"}}]}]}}]}}},"This procedure amounts to computing successive multiple linear correlation indices (0\u2266R\u22661) between the dependent variable Yand the time lags of Z, Zand Z, and other lags, analogous to the structure in Equation (12). That is the autocorrelation of lag-1 R(column 2 with column 3 and 4); the autocorrelation of lag-2 R(column 2 with column 3 and 5); and the autocorrelation of lag-3 R(column 2 with column 3 and 6). Additional lags are computed in a similar fashion.","If the data are random, the simple k-lag zero-order intercorrelations of the dependent variable Ywith the amplitude measures, r, will be zero driving the R value towards 0 in the multiple autocorrelation formula for all lag lengths.","The second modeling approach requires treating Zas the dependent variable as shown in Table 3 for an exemplary three-lag analysis.",{"@attributes":{"id":"p-0140","num":"0143"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Model Illustrating Three-lag Autocorrelations"},{"entry":"(Amplitude Zas a dependent variable)"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{},{},{},"(4)","(5)","(6)"]},{"entry":[{},"(1)","(2)","(3)","Y","Y","Y"]},{"entry":[{},"t","Zt","Yt","indep","indep","indep"]},{"entry":[{},"Time","depend","indep","Lag-1","Lag-2","Lag-3"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"6","align":"center","rowsep":"1"}}]},{"entry":[{},"t","z","y","y","y","y"]},{"entry":[{},"t","z","y","y","y","y"]},{"entry":[{},".",".",".",".",".","."]},{"entry":[{},"t","z","y","y","y","y"]},{"entry":[{},"t","z","y","y","y",{}]},{"entry":[{},"t","z","y","y",{},{}]},{"entry":[{},"t","z","y"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"6","align":"center","rowsep":"1"}}]}]}}]}}},"The reverse correlation procedure amounts to computing the multiple linear correlation index between the dependent variable Zand the time lags of Y, Yand Y+3, analogous to the structure in Equation (12). That is for three lags: the autocorrelation of lag-1 R(column 2 with column 3 and 4); the autocorrelation of lag-2 R(column 2 with column 3 and 5); and the autocorrelation of lag-3 R(column 2 with column 3 and 6). Additional lags are computed in a similar fashion. As noted above, randomness occurs when the dependent variable Zdoes not correlate with the simple lag correlations, (For example: r\u22480).","The reason for this more complicated approach for three-dimensional autocorrelation analysis is two-fold. First, in a closed system of data inputs, one cannot specify the dependent variable a priori in a meaningful manner or one cannot know the exact nonlinear mathematical structure of the waveform to be detected (periodic, parabolic, etc.). Second, the linear R and the k-lag autocorrelations will show R\u2248R\u2248R\u22480 for random noise. However for signal waveforms, it is not necessarily true that for a k-lag autocorrelation, R=0 and R=0. At least one model is expected to detect signal structure for nonlinear forms.","This approach will enhance the likelihood that a signal waveform will be detected and not inaccurately be labeled as noise when used in conjunction with the Runs test and other analysis procedures of the present method.","When a three-dimensional data set is not a time series; correlational analysis can be complicated in real-time experiments in which a rapid yes-no classification is required. An example of this circumstance is when a causal model is not present to specify the dependent and independent variables in order to detect and classify the three-dimensional functional form.","Many variable relational techniques are known to those skilled in the art, including multivariate nonlinear curve fitting, partial correlation, canonical correlation analysis, pattern recognition, image processing, feature extraction, and other multivariate data reduction techniques. These are large sample methods requiring significant analyst input to determine the interpretation of outcomes. The present method focuses on time series analyses with potentially sparse data sets in real-time operating systems in which a rapid classification of noise\/signal is required for unknown waveforms.","The hypothesis of no relationship (R\u22480) in time series data will be resolved by comparing the observed autocorrelation R values for N discrete sample points against the approximate standard error on a correlogram (For example: accept the noise hypothesis if the autocorrelation measure lies between the critical values of the white noise band,",{"@attributes":{"id":"p-0147","num":"0150"},"maths":{"@attributes":{"id":"MATH-US-00023","num":"00023"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mn":"0","mo":["\u2264","\u2264"],"mi":"R","mfrac":{"mn":"1.96","msqrt":{"mi":"N"}}},"mo":","}}},"br":{}},"The random wave form in  depicts the following autocorrelation co-efficients: Lag 1: R, . . . z, z=0.152; Lag 2: R\u00b7Z, Z=0.154; Lag 3: R\u00b7Z, Z=0.113. All indicate white noise, since the minimum intensity for deciding \u201csignal\u201d is 0.277 with fifty measurements at a five percent false alarm rate.","As a rationale for this two-step correlational procedure; assume a noise-free parabolic function in two-space f(t)=y=9\u2212t, plotted for t\u00b13 (seven data points). The linear relationship between t and y, r, is zero which indicates noise.","Thus far, the method indicates a random distribution for a simple deterministic function. However, the autocorrelations show an increasing intensity in relationship (For example: r=+0.36; r=\u22120.48; r r=\u22120.84; the fourth lag shows r r=\u22120.96, and the fifth lag shows r r=\u22121.00). The parabolic signal structure is revealed by the successive serial correlations. With each lag, the plot of ywith ybecomes more linear (inversely).","In this case, the first three lags are likely sufficient to indicate a signal structure. Such a change cannot be observed with random noise regardless of sample size or the number of time lags since the correlations will fall within the boundaries of the critical white noise band.","By contrast, in the case of a simple circle function in two-space, x+y=9, \u22123\u2266x\u2266+3 (twelve data points), the method of the Runs procedure quickly detects a signal waveform at a high level of certainty. The autocorrelations increase in intensity only by the fourth and fifth lag. These examples demonstrate that such experiments require a flexible mix of testing procedures in order to arrive at a correct time waveform classification.","The autocorrelation analysis (with Yand Zas separate dependent variables) detects signals in similar three-dimensional algebraic\/geometric and periodic functional forms which might otherwise be mislabeled as noise.","Method D (Normal Approximation z-Test for Poisson Distribution Based on the Number of Non-Empty Partitions)","This testing procedure, derived from the Central Limit Theorem, is used for evaluating the following binary non-directional hypothesis set regarding the number of cells that are non-empty in a partitioned volume as compared to the expected number or mean in a random distribution:\n\n",{"@attributes":{"id":"p-0155","num":"0160"},"maths":{"@attributes":{"id":"MATH-US-00024","num":"00024"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"z","mo":"=","mrow":{"mfrac":{"mrow":{"mi":"m","mo":"-","mrow":{"mi":["k","\u03d1"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"msqrt":{"mrow":{"mi":["k","\u03d1"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},"mo":"~","mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["0","1"],"mo":","}}}}}},{"mrow":{"mo":["(",")"],"mn":"16"}}]}}}},"br":{}},"As discussed in Method B, the quantity \u0398 is the probability that a cell is non-empty in a random distribution population and the quantity k\u0398 is the mean or the average number of non-empty partitions in a stochastic random distribution.","Since the population parameter \u0398 is rarely known, the sample Poisson measure is used, =1\u2212exp(\u2212\u03bbt), where \u03bbt is the average number of points per partition. The quantity, k, is the sample mean or the average number of partitions expected to be non-empty in a spatial random sample. The sample measure m is the actual number of k partitions which are non-empty. These quantities are defined further by using a Poisson frequency analysis notation (as described in the note for Table 4).","As discussed earlier, the operator would compare the value of z against a probability of false alarm \u03b1. The significance probability p of the observed value z is calculated with Equation (4):",{"@attributes":{"id":"p-0159","num":"0164"},"maths":{"@attributes":{"id":"MATH-US-00025","num":"00025"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"p","mo":"=","mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Z","mo":"\u2264","mrow":{"mo":["\uf603","\uf604"],"mi":"z"}}}},{"mn":"1","mo":"-","mrow":{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mrow":[{"mo":"-","mrow":{"mo":["\uf603","\uf604"],"mi":"z"}},{"mo":"+","mrow":{"mo":["\uf603","\uf604"],"mi":"z"}}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":"\u2062","msup":{"mi":"x","mn":"2"}}}},{"mo":"\u2146","mi":"x"}],"mo":"\u2062"}}}}],"mo":"="}},{"mrow":[{"mo":"-","mi":"\u221e"},{"mo":["\uf603","\uf604"],"mi":"z"},{"mo":"+","mi":"\u221e"}],"mo":["<","<"]},{"mn":["0","1"],"mo":["\u2264","\u2264"],"mi":"p"}],"mo":[",","\u2062",","],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"17"}}]}}}},"br":{},"ul":{"@attributes":{"id":"ul0007","list-style":"none"},"li":{"@attributes":{"id":"ul0007-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0008","list-style":"none"},"li":["p\u2267\u03b1Noise","p<\u03b1Signal+Noise\n\nIt is seen that if m\u2248k, or R\u22481, then z\u22480 and p\u22481 (noise).\n"]}}}},"Based on Equation (16), a ninety-five percent or ninety-nine percent confidence interval (CI) can be constructed for the point estimate m when His true (noise); that is, to determine the range of m which is indicative of noise\/signal. A ninety-five percent confidence interval (CI) is obtained by solving for m in Equation (16), written as an algebraic probability statement:\n\n()=1.961.96\n\nor\n\n()=1.96\u2003\u2003(18)\n\nwhere \u00b11.96 is the critical value of the Gaussian distribution when the false alarm rate is five percent for a two-tailed hypothesis.\n","Equation (18) represents the range that m can vary when a distribution is random with a ninety-five percent certainty. A ninety-nine percent CI is derived in a similar manner; the \u00b11.96 is changed to \u00b12.576; for ninety percent use \u00b11.645.","The lower limit can be k\u22121.96\u221a{square root over (k)} on m or mand k+1.96\u221a{square root over (k)} as the upper limit m. This allows a useful measure in terms of the intuitive R ratio, m\/k.","For example, if N=k=25, then k=25 [1\u2212exp(\u22121)]=15.8 cells non-empty on the average in a random distribution. A ninety-five percent CI for m is CI(m)=k\u00b11.96\u221a{square root over (k)}=(8, 24), rounded. Translated into the R ratio in terms of mand m,",{"@attributes":{"id":"p-0164","num":"0171"},"maths":{"@attributes":{"id":"MATH-US-00026","num":"00026"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["R","noise"]},"mo":"=","mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mfrac":[{"msub":{"mi":["m","L"]},"mrow":{"mi":"k","mo":"\u2062"}},{"msub":{"mi":["m","U"]},"mrow":{"mi":"k","mo":"\u2062"}}],"mo":","}},{"mrow":[{"mo":["(",")"],"mrow":{"mfrac":[{"mrow":[{"mrow":[{"mi":"k","mo":"\u2062"},{"mn":"1.96","mo":"\u2062","msqrt":{"mrow":{"mi":"k","mo":"\u2062"}}}],"mo":"-"},{"mi":"k","mo":"\u2062"}]},{"mrow":[{"mrow":[{"mi":"k","mo":"\u2062"},{"mn":"1.96","mo":"\u2062","msqrt":{"mrow":{"mi":"k","mo":"\u2062"}}}],"mo":"+"},{"mi":"k","mo":"\u2062"}]}],"mo":","}},{"mn":"1","mo":"\u00b1","mi":".49"},{"mo":["(",")"],"mrow":{"mn":["0.51","1.49"],"mo":","}}],"mo":["\u2248","\u2248"]}],"mo":"="}},"mo":","}},{"mrow":{"mo":["(",")"],"mrow":{"mn":"19","mo":"\u2062","mi":"A"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0165","num":"0172"},"maths":{"@attributes":{"id":"MATH-US-00027","num":"00027"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["R","noise"]},"mo":"=","mrow":{"mn":"1","mo":"\u00b1","mfrac":{"mn":"1.96","msqrt":{"mrow":{"mi":"k","mo":"\u2062"}}}}}}},"br":{}},"If N\u2266k\u226610, R=1\u00b10.07 which shows that the range narrows as the sample size increases until, in the limit as N\u2192\u221e, R\u21921.0 (pure noise).","One further measure that may be of use: if N\u2248k, a quick result is:",{"@attributes":{"id":"p-0168","num":"0175"},"maths":{"@attributes":{"id":"MATH-US-00028","num":"00028"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["R","noise"]},"mo":["\u2062","\u2248","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mrow":{"mn":"1","mo":["\u2062","\u00b1","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mfrac":{"mn":"2.1","msqrt":{"mi":"k"}}}}}},"br":{}},{"@attributes":{"id":"p-0169","num":"0176"},"maths":{"@attributes":{"id":"MATH-US-00029","num":"00029"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["R","noise"]},"mo":["\u2062","\u2248","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mrow":{"mn":"1","mo":["\u2062","\u00b1","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mfrac":{"mn":"2.5","msqrt":{"mi":"k"}}}}}},"br":{}},{"@attributes":{"id":"p-0170","num":"0177"},"maths":{"@attributes":{"id":"MATH-US-00030","num":"00030"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["R","noise"]},"mo":["\u2062","\u2248","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mrow":{"mn":"1","mo":["\u2062","\u00b1","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mfrac":{"mn":"3.2","msqrt":{"mi":"k"}}}}}},"br":{}},"Note that for highly skewed distributions (k being much larger than N), the value of the maximum R should be obtained (U.S. Pat. No. 7,409,323 demonstrates this methodology). A signal structure is suspected when R\u2267R.","These analyses demonstrate the usefulness of the R ratio,",{"@attributes":{"id":"p-0173","num":"0180"},"maths":{"@attributes":{"id":"MATH-US-00031","num":"00031"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":"R","mo":"=","mfrac":{"mi":"m","mrow":{"mi":["k","\u03d1"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},"mo":","}}},"br":{}},"As mentioned above, the calculation of the R ratio should be embedded within the testing procedure in Method D. The tests are described separately for narrative purposes only.","Method E (Chi-Square Test of Homogeneity\u2014an Alternative)","The Chi-square test is used to decide if the Poisson distribution is adequate to model a random process.",{"@attributes":{"id":"p-0176","num":"0183"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 4"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"POISSON ANALYSIS "},{"entry":"Frequency Table Protocol and Definitions"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"63pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"(1)","(2)","(3)","(4)","(5)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]},{"entry":[{},"k","n","k \u00b7 n","P (k; \u03bbt)","N \u00b7 P (k; \u03bbt)"]},{"entry":[{},"0","n","0","P (0; \u03bbt)","N \u00b7 P (0; \u03bbt)"]},{"entry":[{},"1","n","n","P (1; \u03bbt)","N \u00b7 P(1; \u03bbt)"]},{"entry":[{},".",".",".",".","."]},{"entry":[{},"K","n","K \u00b7 n","P(K; \u03bbt)","N \u00b7 P(K; \u03bbt)"]},{"entry":[{},"TOTAL","N","T","1.00 (approx.)","N (approx.)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]}]}}]}},"br":{},"in-line-formulae":[{},{}],"i":["n","=N\u2212\u03a3","n"],"sub":["0","k=1","k "],"sup":"k=K"},"Vis the computed volume of the convex hull polygon, partitioned into N cubes;","k is an index indicating an empty cell (k=0), cells with one point (k=1), etc.;","K is the number of categories of k;","nis the frequency count associated with k (NOTE: n<5 must be combined with an adjacent cell to ensure n\u22675. The value K is adjusted accordingly);",{"@attributes":{"id":"p-0181","num":"0188"},"maths":{"@attributes":{"id":"MATH-US-00032","num":"00032"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"N","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"0"},"mi":"K"},"mo":"\u2062","msub":{"mi":["n","k"]}}}}},"br":{}},{"@attributes":{"id":"p-0182","num":"0189"},"maths":{"@attributes":{"id":"MATH-US-00033","num":"00033"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"T","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"0"},"mi":"K"},"mo":"\u2062","mrow":{"mi":"k","mo":"\u00b7","msub":{"mi":["n","k"]}}}}}},"br":{}},{"@attributes":{"id":"p-0183","num":"0190"},"maths":{"@attributes":{"id":"MATH-US-00034","num":"00034"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":["\u03bb","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":["\u2248","\u2248"],"mfrac":[{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"0"},"mi":"K"},"mo":"\u2062","mrow":{"mi":"k","mo":"\u00b7","msub":{"mi":["n","k"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"0"},"mi":"K"},"mo":"\u2062","msub":{"mi":["n","k"]}}]},{"mi":["T","N"]}]}}},"br":{}},{"@attributes":{"id":"p-0184","num":"0191"},"maths":{"@attributes":{"id":"MATH-US-00035","num":"00035"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"t","mo":"=","mfrac":{"msub":{"mi":["V","p"]},"mi":"N"}}}},"br":{}},{"@attributes":{"id":"p-0185","num":"0192"},"maths":{"@attributes":{"id":"MATH-US-00036","num":"00036"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"k","mo":";","mrow":{"mi":["\u03bb","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},{"mrow":{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":"\u03bb"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"t"}}},"mo":"\u2062","mfrac":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["\u03bb","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mi":"k"},"mrow":{"mi":"k","mo":"!"}}}],"mo":"="},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0186","num":"0193"},"maths":{"@attributes":{"id":"MATH-US-00037","num":"00037"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"0"},"mi":"K"},"mo":"\u2062","mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"k","mo":";","mrow":{"mi":["\u03bb","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}},{"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"k","mo":"=","mn":"0"},{"mi":["\u03bb","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":";"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"k","mo":">","mn":"0"},{"mi":["\u03bb","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":";"}}}],"mo":"+"},"mo":"\u2248","mn":"1"}],"mo":"="}}},"br":{},"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00029","he":"3.13mm","wi":"1.78mm","file":"US08693288-20140408-P00003.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00030","he":"3.13mm","wi":"1.78mm","file":"US08693288-20140408-P00004.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}]},"n\u2248N\u00b7P(k; \u03bbt) in a random distribution.",{"@attributes":{"id":"p-0188","num":"0195"},"maths":{"@attributes":{"id":"MATH-US-00038","num":"00038"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"0"},"mi":"K"},"mo":"\u2062","mrow":{"mi":"N","mo":"\u00b7","mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"k","mo":";","mrow":{"mi":["\u03bb","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}}},"mo":"\u2248","mi":"N"}}}},{"@attributes":{"id":"p-0189","num":"0196"},"maths":{"@attributes":{"id":"MATH-US-00039","num":"00039"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"m","mo":"=","mrow":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"0"},"mi":"K"},"mo":"\u2062","msub":{"mi":["n","k"]}},"mo":"-","msub":{"mi":"n","mn":"0"}}}}},"br":{}},{"@attributes":{"id":"p-0190","num":"0197"},"maths":{"@attributes":{"id":"MATH-US-00040","num":"00040"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"R","mo":"=","mrow":{"mfrac":{"mi":"m","mrow":{"mi":"N","mo":"\u00b7","mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"k","mo":">","mn":"0"},{"mi":["\u03bb","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":";"}}}}},"mo":"\u2248","mn":"1"}}}},"br":{}},"The R ratio is therefore defined in each notation system as:",{"@attributes":{"id":"p-0192","num":"0199"},"maths":{"@attributes":{"id":"MATH-US-00041","num":"00041"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"R","mo":"=","mrow":{"mfrac":{"mrow":[{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"0"},"mi":"K"},"mo":"\u2062","msub":{"mi":["n","k"]}},"mo":"-","msub":{"mi":"n","mn":"0"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"0"},"mi":"K"},"mo":"\u2062","mrow":{"msub":{"mi":["n","k"]},"mo":"\u2062","mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"k","mo":">","mn":"0"},{"mi":["\u03bb","t"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}],"mo":";"}}}}}]},"mo":"=","mrow":{"mfrac":[{"mi":"m","mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mn":"1","mo":"-","mrow":{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mo":"-","mfrac":{"mi":["T","N"]}}}}}}}},{"mi":"m","mrow":{"mi":"k","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":"="}}}}},"br":{},"img":{"@attributes":{"id":"CUSTOM-CHARACTER-00031","he":"3.13mm","wi":"1.78mm","file":"US08693288-20140408-P00004.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}},"Chi-square statistic for homogeneity test (with K\u22122 degrees of freedom):",{"@attributes":{"id":"p-0194","num":"0201"},"maths":{"@attributes":{"id":"MATH-US-00042","num":"00042"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msup":{"mi":"\u03c7","mn":"2"},"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"0"},"mi":"K"},"mo":"\u2062","mfrac":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["o","k"]},{"mi":["\u2147","k"]}],"mo":"-"}},"mn":"2"},"msub":{"mi":["\u2147","k"]}}}},"mo":","}}},"br":{},"sub":["k","k","k"]},"The Chi-square test for homogeneity is performed on the observed sample frequencies and expected random noise Poisson theoretical frequencies.","Method F (Non-Linear Correlation\u2014an Alternative)","An alternative correlation function is the eta \u03b7 (or nonlinear correlation) coefficient in time-series analyses. This measure is known to provide the maximum correlation possible between the time criterion and any function, linear or nonlinear combinations, of the predictors. The correlation ratio is always at least as large as the linear correlation. For example: \u03b7\u2267R. The range is: 0\u2266\u03b7. Other alternative correlational measures are indicated in correlation Method C for non-time series data sets.","In one exemplary experiment, a sample of fifty pseudo-random data points was assigned to 125 cells of partitioned subspace within a convex hull of total volume",{"@attributes":{"id":"p-0198","num":"0205"},"maths":{"@attributes":{"id":"MATH-US-00043","num":"00043"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["V","p"]},"mo":"=","mrow":{"mn":"516","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mfrac":{"mn":["1","6"]}}}}},"br":{},"sup":"3 "},{"@attributes":{"id":"p-0199","num":"0206"},"maths":{"@attributes":{"id":"MATH-US-00044","num":"00044"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"msub":{"mi":["V","p"]},"mi":"V"},"mo":"=","mi":".517"}}},"br":{}},"The frequency analysis of at least partially of these fifty points is shown below in accordance with the definitions and properties as previously described with Table 4; Poisson Analysis.",{"@attributes":{"id":"p-0201","num":"0208"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 5"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Poisson Frequency Analysis"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"56pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["(1)","(2)","(3)","(4)","(5)"]},{"entry":["k","n","k \u00b7 n","P(k; \u03bbt)","N \u00b7 P(k; \u03bbt)"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"56pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["0","86","0",".6811","85.14"]},{"entry":["1","30","30",".2616","32.69"]},{"entry":["\u22672","9","18",".0502","6.28"]},{"entry":["TOTAL","N = 125","T = 48",".9929","124.11"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"Overall, the frequency data in Table 5 is reasonably dispersed and indicates that the Poisson model is adequate to model the three-dimensional random data enveloped in a partitioned convex hull. The difference between data in Column (2) compared to the data of Column (5) is the primary comparison. The Chi-square homogeneity value for model fit is 1.41 (\u03bd=K\u22122=1 degrees of freedom) with a probability of p=0.49 (noise distribution). The p value was obtained by direct evaluation of the integral for the Chi-square density, f(\u03c7), similar to the approaches used to compute Equations (4) and (14). Thus, the Poisson distribution is adequate to model the data as a random process embedded in a three-dimensional polygon.","Other analyses that can be obtained from Table 5 and the raw data of fifty measurements can show that the number of non-empty cells amounts to m=39 (N\u2212n). The expected average number in a random distribution is",{"@attributes":{"id":"p-0204","num":"0211"},"maths":{"@attributes":{"id":"MATH-US-00045","num":"00045"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mn":"125","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mn":"1","mo":"-","mrow":{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mo":"-","mfrac":{"mn":["48","125"]}}}}}}},"mo":"=","mn":"39.86"}}},"br":{}},{"@attributes":{"id":"p-0205","num":"0212"},"maths":{"@attributes":{"id":"MATH-US-00046","num":"00046"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mfrac":{"mn":["39","39.86"]},"mo":"=","mi":".98"},"mo":","}}},"br":{}},"In the alternative, the actual sample size of fifty points may be used to carry out the computations if the alternative Module E is not used as part of the present method.","The confidence analysis procedure indicates that a ninety-five percent noise band for the data is (0.69, 131) for the R ratio which contains the observed R. Likewise, a ninety-five percent CI for m is (27, 52), rounded. With ninety-five percent certainty, the m and R values are expected to fall within these ranges.","Moreover, from this data, the z test procedure of Method D can be applied which shows a p value of 0.89 (noise). Here the value a k=39.86. The Runs test returned a p value of 0.84 (noise)","Since partitioning is irrelevant to the correlation measure, the multiple linear correlation was obtained in fifty simulation runs with an average correlation of R=0.154 [a p value of 0.57 (noise)]. The noise variance accounts for approximately ninety-eight percent of the total variance. Autocorrelations also indicate random noise.","This is an exemplary technical analysis for the data set in accordance with the present method. Each procedure is similar in result in that the data are noise with a high amount of certainty as compared to a false alarm rate of five percent and less.","The above data analysis results are comparable to the results disclosed in the method for a rectangular solid in previously-referenced U.S. Pat. No. 7,277,573. The difference is a forty-nine percent reduction in observation space with the use of convex hull which translates into a solution obtained in approximately half of the time.","Small Sample Testing Procedures (Measurements\u226625)","Testing Method A, Method B and Method C are also applicable to a small sample case.","The R ratio of Method B should be viewed as descriptive rather than inferential when applied to small samples. The suggested guideline is 0.90\u2266R\u22661.10NOISE; otherwise, SIGNAL R\u2267RSIGNAL [highly skewed distributions\u2014k being much larger than N].","The correlation of Method C presents a statistical problem for small samples. The ability to reject the null hypothesis (noise) depends on the sample size. A high correlation computed on a small sample size may be insufficient to reject the null hypothesis for purely statistical reasons. For this reason, a heuristic procedure in the interpretation of the linear and autocorrelation measure is stated in the following decision rule:\n\n","This testing procedure is the small sample analogue of the normal approximation test in Method D. The procedure provides more accurate estimates of probabilities.","Based on the Poisson point process theory for a measurement set of data in a time interval \u0394t with corresponding measurements of magnitudes \u0394Y and \u0394Z; that data set is considered to be purely random if the number of partitions k is non-empty (containing no observable measurements) to a specified degree. The observed number of non-empty partitions is m, as defined in the Note of Table 4 with follow-on supporting language\u2014to be referred to as Equation (19B) hereinafter for all uses of the Note of Table 4. The mean or expected number of non-empty partitions in a random Poisson distribution is given by:\n\n(1)\u2003\u2003(20)\n\nwhere \u0398 is the probability that any cell is non-empty in a completely random Poisson distribution and \u03bbt is the population parameter of the spatial Poisson process defined in Equation (19B) corresponding to the average number of points observed across all three-dimensional subspace partitions in a random distribution. A spatial Poisson process is assumed to govern the mechanism. The calculation of Equation (20) comes directly from the standard Poisson distribution function given in Equation (19B).\n","In one embodiment of the present method, the spatial mean \u03bbt is calculated from a frequency distribution of Poisson distributed variables in the manner recommended by Feller, Ch. 6. [Feller, William. . Vol I., NY: John Wiley and Sons. (1957)]. This quantity was defined in Equation (19B).","The sample value of \u03bbt corresponds to the average \u201chit rate\u201d or average number of points across all cubic whole and part subspaces of the convex hull in three dimensions and t is the volume of a cubic partition. This situation was defined in Equation (19B).","An alternative to calculate Equation (20) is a standard manner for evaluating a two-tailed hypothesis for finite discrete probability distributions. However, no known way is provided for calculating the significance probability value p for two-tailed hypotheses\u2014as was done for the symmetric infinite Gaussian distribution. If the Poisson mean k>10, the Poisson distribution can be approximated by the Gaussian distribution with the mean and variance of the original Poisson distribution. At this level, the Poisson distribution becomes more symmetric about the mean.","A quantized continuity correction factor of plus or minus 0.5 is applied to the computations since a discrete distribution is approximated by a continuous one. The identifier p can then be calculated fairly accurately. This was the rationale for Equation (16) as derived from the Central Limit Theorem.","For small Poisson means, the distribution is skewed so this Gaussian approximation is not calculable and the p value cannot be provided. This is the situation for which the probability test was designed for the present invention. The need for this probability test (for example: very small samples) will rarely occur.","A derived algorithm of Equation (26) provides an estimate of the significance probability p for evaluating a two-tailed hypothesis for the quasi-symmetric finite discrete Poisson probability distribution. It is validated against the calculated p values for the large sample z test described in Equation (16).","The boundary, above and below the Poisson mean k\u0398, attributable to random variation and controlled by a false alarm rate, is the critical region of the test. In practice, there is no knowledge of the population parameter \u0398 and the functional parameters of that measure. Rather, sample observations  and k are worked with and compared to the frequency structure against a theoretical probability distribution which models random noise.","In essence, this exact probability test determines if the observed number of non-empty cells m is contained within the boundaries of the theoretical Poisson model expectations which is a situation indicative of random noise for the three-dimensional data set. If m falls in the critical region; a signal waveform is suspected.","Lower Boundary Value of Critical Region","The test procedure is described in detail below. An example is provided to clarify each step.","Let ybe the integer quantity forming the lower boundary of the sample mean k given by the Poisson criterion:",{"@attributes":{"id":"p-0227","num":"0236"},"maths":{"@attributes":{"id":"MATH-US-00047","num":"00047"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Y","y"],"mo":"\u2264"}}},"mo":"\u2264","mfrac":{"msub":{"mi":"\u03b1","mn":"0"},"mn":"2"}},{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"mi":"\u03b1","mn":"2"},{"msub":{"mi":"\u03b1","mn":"0"},"mn":"2"}],"mo":"-"}}}],"mo":","}}},"br":{}},{"@attributes":{"id":"p-0228","num":"0237"},"maths":{"@attributes":{"id":"MATH-US-00048","num":"00048"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Y","y"],"mo":"\u2264"}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"y","mo":"=","mn":"0"},"msub":{"mi":"y","mn":"1"}},"mo":"\u2062","mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"y","mo":";","mrow":{"mi":"k","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"21"}}]}}}}},"Pr is probability and P(y; k) is the discrete Poisson probability distribution function given as:",{"@attributes":{"id":"p-0230","num":"0239"},"maths":{"@attributes":{"id":"MATH-US-00049","num":"00049"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"y","mo":";","mrow":{"mi":"k","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},"mo":"=","mfrac":{"msup":{"mrow":{"msup":{"mi":"\u2147","mrow":{"mrow":{"mo":"-","mi":"k"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"k","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},"mi":"y"},"mrow":{"mi":"y","mo":"!"}}},{"mrow":{"mi":"where","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"y","mo":"=","mn":"0"},"mi":"\u221e"},"mo":"\u2062","mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"y","mo":";","mrow":{"mi":"k","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}}},"mo":"=","mn":"1.0"}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"22"}}]}}}}},"The upper limit on the summation is finite in practice; selected such that the summation achieves a predetermined level of convergence (for example: the sum is approximately 0.99999).","The quantity \u03b1is the probability nearest to an exact value of the pre-specified false alarm probability \u03b1 and yis the largest value of y such that",{"@attributes":{"id":"p-0233","num":"0242"},"maths":{"@attributes":{"id":"MATH-US-00050","num":"00050"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Y","y"],"mo":"\u2264"}}},{"mfrac":{"msub":{"mi":"\u03b1","mn":"0"},"mn":"2"},"mo":"."}],"mo":"\u2264"}}},"br":[{},{}],"sub":"0"},"The upper boundary of the Poisson probability test is called yand is determined in a manner similar to that for determining the lower boundary value y.","Let ybe the integer quantity forming the upper random boundary of the mean kgiven by:",{"@attributes":{"id":"p-0236","num":"0245"},"maths":{"@attributes":{"id":"MATH-US-00051","num":"00051"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Y","y"],"mo":"\u2265"}}},"mo":"\u2264","mfrac":{"msub":{"mi":"\u03b1","mn":"0"},"mn":"2"}},{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"mi":"\u03b1","mn":"2"},{"msub":{"mi":"\u03b1","mn":"0"},"mn":"2"}],"mo":"-"}}}],"mo":","}},{"mrow":{"mo":["(",")"],"mn":"23"}}]}}}},"br":{}},{"@attributes":{"id":"p-0237","num":"0246"},"maths":{"@attributes":{"id":"MATH-US-00052","num":"00052"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Y","y"],"mo":"\u2264"}}},{"mn":"1","mo":"-","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"y","mo":"=","mn":"0"},"msub":{"mi":"y","mn":"2"}},"mo":"\u2062","mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"y","mo":";","mrow":{"mi":"k","mo":"\u2062"}}}}}}],"mo":"="}}}},"The value \u03b1is the probability closest to an exact value of the pre-specified false alarm probability \u03b1, and yis the largest value of y such that",{"@attributes":{"id":"p-0239","num":"0248"},"maths":{"@attributes":{"id":"MATH-US-00053","num":"00053"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Y","y"],"mo":"\u2265"}}},{"mfrac":{"msub":{"mi":"\u03b1","mn":"0"},"mn":"2"},"mo":"."}],"mo":"\u2264"}}},"br":{},"sub":"0"},"Hence, the subsystem determines if the frequency structure contains a \u201cy\u201d amount of observed points within the critical region; thereby, warranting a determination of random (otherwise, nonrandom is the call) with the associated PFA a being wrong in the decision when random is the analysis test result (See the discussion for Table A).","The overall protection against a Type I error\u2014\u03b1\u2014is the sum Pr (Y\u2266y)+Pr (Y\u2267y) which is often higher (as previous research has indicated). This value is also known as the actual level of significance.","Hypothesis","In the hypothesis, the subsystem assesses and evaluates the random process binary hypothesis for small samples by means of the sample proportion of non-empty partitions:\n\n","where y=m (the number if non-empty cells are in a sample).","The false alarm rate is set at \u03b1=0.05 for very small samples. For (N\u226616); \u03b1 a may be set to 0.10.","As mentioned, the quantity \u0398 is the unknown population parameter representing the probability that a cell is non-empty in a completely random Poisson distribution and  is the sample value indicated above =1\u2212e.","Note that the actual Poisson hypothesis test uses the calculated mean k (referred to as the Poisson mean \u03bc or \u03bb in probability distribution tables) to carry out the calculations for assessing the hypothesis set. This practice is done for convenience since the probability  is a small quantity (0\u2267<1) in finite samples which gives a restricted range of the Poisson probability distribution integer count parameter y in the Poisson probability function P(y; k).","In practice, one does not possess a priori knowledge of the population parameters; therefore, sample spatial data is compared against a known probability function which characterizes the structure of a random distribution. The Poisson distribution is known to model a random process for distributions on the line interval and in the partitioned plane.","Because the principle of the exact Poisson probability test is the same regardless of the sample size, the testing procedure is illustrated for the data previously analyzed (see Table 4). The following summary data (=0.319; k==39.86; m=39) are required to carry out the computations and to arrive at a reasonable decision for the signal-noise hypothesis.","As previously defined, \u201cm\u201d is the observed number of non-empty partitions; =0.319 is the probability that a cell is non-empty, and k is the mean or expected number of non-empty partitions in a random distribution.","From this data, the two-tailed hypothesis set is:\n\n","This input generates the discrete Poisson distribution P(y; k) given in",{"@attributes":{"id":"p-0252","num":"0265"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 6"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Poisson Probability Distribution for k9 39.86"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"98pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["y","Prob","Cum %"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"98pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["16 ","0.001%","0.002%"]},{"entry":["17 ","0.002%","0.004%"]},{"entry":["18 ","0.005%","0.009%"]},{"entry":["19 ","0.010%","0.019%"]},{"entry":["20 ","0.021%","0.040%"]},{"entry":["21 ","0.039%","0.079%"]},{"entry":["22","0.071%","0.150%"]},{"entry":["23","0.123%","0.272%"]},{"entry":["24","0.204%","0.476%"]},{"entry":["25","0.325%","0.801%"]},{"entry":["26","0.498%","1.300%"]},{"entry":["27","0.736%","2.036%"]},{"entry":["28","1.047%","3.083%"]},{"entry":["29","1.440%","4.523%"]},{"entry":["30","1.913%","6.435%"]},{"entry":["31","2.459%","8.894%"]},{"entry":["32","3.063%","11.958%"]},{"entry":["33","3.700%","15.657%"]},{"entry":["34","4.337%","19.995%"]},{"entry":["35","4.939%","24.934%"]},{"entry":["36","5.469%","30.403%"]},{"entry":["37","5.891%","36.294%"]},{"entry":["38","6.179%","42.473%"]},{"entry":["39","6.315%","48.789%"]},{"entry":["40","6.293%","55.082%"]},{"entry":["41","6.118%","61.200%"]},{"entry":["42","5.896%","67.006%"]},{"entry":["43","5.382%","72.388%"]},{"entry":["44","4.875%","77.263%"]},{"entry":["45","4.318%","81.581%"]},{"entry":["46","3.742%","85.323%"]},{"entry":["47","3.173%","88.496%"]},{"entry":["48","2.635%","91.131%"]},{"entry":["49","2.143%","93.275%"]},{"entry":["50","1.709%","94.983%"]},{"entry":["51","1.335%","96.319%"]},{"entry":["52","1.024%","97.342%"]},{"entry":["53","0.770%","98.112%"]},{"entry":["54","0.568%","98.680%"]},{"entry":["55","0.412%","99.092%"]},{"entry":["56","0.293%","99.385%"]},{"entry":["57","0.205%","99.590%"]},{"entry":["58","0.141%","99.731%"]},{"entry":["59","0.095%","99.826%"]},{"entry":["60","0.063%","99.889%"]},{"entry":["61","0.041%","99.930%"]},{"entry":["62","0.027%","99.957%"]},{"entry":["63","0.017%","99.974%"]},{"entry":["64","0.010%","99.984%"]},{"entry":["65","0.006%","99.991%"]},{"entry":["66","0.004%","99.995%"]},{"entry":["67","0.002%","99.997%"]},{"entry":["68","0.001%","99.998%"]},{"entry":["69","0.001%","99.999%"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"Based on the PFA of 0.05; the critical boundaries are computed to be y=27 and y=53. These values are virtually the same as found for the ninety-five percent CI for the large sample approximate z test (27, 52) in Method D. These values also provide evidence that the computations are consistent as well as evidence that the Gaussian z test is adequate. Since m=39 and y<39<y; then the null hypothesis of noise only is accepted. The number of non-empty cells in the one hundred and twenty-five partitioned space is consistent with a Poisson random distribution.","The protection against a Type I error is found by calculating the sum of Pr (Y\u2266y)+Pr (Y\u2267y)=0.02036+0.01888=0.039 which is approximately twenty-five percent higher than the a priori value of \u03b1=0.05. This significance level represents the actual probability of incorrectly labeling this waveform signal. The difference 1\u2212[Pr(Y\u2266y)+Pr(Y\u2267y)]=0.961 is the confidence that the operator has when deciding that noise is the correct decision. For example: Pr(Noise|Noise). Considering the data from the exact Poisson hypothesis test, the noise-only decision is reasonable. The results are consistent with the large-sample method of Method D but provide a higher degree of confidence.","Alternative Testing Procedure for the Signal-Noise Hypothesis","(Estimate of p)","In the case of the continuous Gaussian distribution, the p value from the large-sample z test in Equation (16) is relatively easy to compute because of the mirror symmetry of the distribution about the mean. Expressing the derivation of the Gaussian p measure in conceptual terms of areas where z is the assumed calculated value in Equation (4):","By definition,",{"@attributes":{"id":"p-0256","num":"0269"},"maths":{"@attributes":{"id":"MATH-US-00054","num":"00054"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"p","mo":"=","mrow":{"mrow":[{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mrow":[{"mo":"-","mi":"\u221e"},{"mo":"-","mi":"z"}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":"\u2062","msup":{"mi":"x","mn":"2"}}}},{"mo":"\u2146","mi":"x"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}},{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mi":["z","\u221e"]},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":"\u2062","msup":{"mi":"x","mn":"2"}}}},{"mrow":{"mo":"\u2146","mi":"x"},"mo":"."}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}}],"mo":"+"}}}},"br":{}},{"@attributes":{"id":"p-0257","num":"0270"},"maths":{"@attributes":{"id":"MATH-US-00055","num":"00055"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"p","mo":"=","mrow":{"mrow":{"mn":"1","mo":"-","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mrow":{"mo":"-","mi":"z"},"mn":"0"},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":"\u2062","msup":{"mi":"x","mn":"2"}}}},{"mo":"\u2146","mi":"x"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}},{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mn":"0","mi":"z"},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":"\u2062","msup":{"mi":"x","mn":"2"}}}},{"mo":"\u2146","mi":"x"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}}],"mo":"+"}}},"mo":"="}}}},{"mtd":{"mrow":{"mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":".5000","mo":"-","mrow":{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mrow":[{"mo":"-","mi":"\u221e"},{"mo":"-","mi":"z"}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":"\u2062","msup":{"mi":"x","mn":"2"}}}},{"mo":"\u2146","mi":"x"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}}}},{"mo":["(",")"],"mrow":{"mrow":{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mrow":[{"mo":"-","mi":"\u221e"},{"mo":"-","mi":"z"}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":"\u2062","msup":{"mi":"x","mn":"2"}}}},{"mo":"\u2146","mi":"x"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}},"mo":"-","mi":".5000"}}],"mo":"+"}}},"mo":"="}}},{"mtd":{"mrow":{"mrow":[{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mrow":{"mo":"-","mi":"\u221e"},"mi":"z"},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":"\u2062","msup":{"mi":"x","mn":"2"}}}},{"mo":"\u2146","mi":"x"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}},{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}},"mo":"\u2062","mrow":{"msubsup":{"mo":"\u222b","mrow":[{"mo":"-","mi":"\u221e"},{"mo":"-","mi":"z"}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":"-","mi":".5"},"mo":"\u2062","msup":{"mi":"x","mn":"2"}}}},{"mo":"\u2146","mi":"x"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}}],"mo":"-"}}},{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Z","z"],"mo":"\u2264"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["Z","z"],"mo":"\u2264"}}}],"mo":"-"}}}],"mo":"="}}}]}},{"mrow":{"mo":["(",")"],"mn":"24"}}]}}}},"br":{}},"In a similar fashion, an estimate for p was derived for the discrete Poisson distribution. The algorithm of Equation (27) is used for estimating p in the small sample Poisson distribution test when the mean k>10 (approximating a symmetric Gaussian distribution).","The procedural steps are to first, consider any observed y value in Table 6 (which is assumed less than or equal to the mean k) to be a lower limit called L. Second, assume that the mean k has a theoretical cumulative probability, Pr(Y\u2266k)=0.50000 (or the area up to the mean is one-half of the total area of the probability mass) as in the Gaussian case. This is a basic but untestable assumption. However, by linear interpolation, on the interval about the mean [39, 40] by cumulative percent:",{"@attributes":{"id":"p-0260","num":"0273"},"maths":{"@attributes":{"id":"MATH-US-00056","num":"00056"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"y","mo":"=","mrow":{"mrow":{"mn":"39","mo":"+","mrow":{"mfrac":{"mrow":[{"mi":[".50000",".48789"],"mo":"-"},{"mi":[".55082",".48789"],"mo":"-"}]},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mn":["40","39"],"mo":"-"}}}},"mo":"=","mn":"39.192"}}},{"mrow":{"mo":["(",")"],"mn":"25"}}]}}}},"br":{}},"This calculation differs from the actual Poisson mean k=39.86 by only 1.7 percent. Alternate estimation procedures such as geometric mean averaging leads to no more than a 1.8 percent difference. Thus, the assumption appears to be reasonable for large k values and is used in the estimation procedure.","Third, a value is found that is equidistant above the mean yto represent the upper and approximate equi-probable outcome of the experiment for a two-sided signal and noise hypothesis. The difference in the cumulative probabilities of yand ywith respect to the mean k=39.86 will be the estimate of p\u2014analogous to Equation (24). The values yand yroughly symmetric with respect to the mean. The input value determined as yor yby comparison to k.","The lower\/upper y values and p are determined in the following manner for the case of y either above or at\/below the mean k:",{"@attributes":{"id":"p-0264","num":"0277"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["UPPER BOUND DETERMINATION","LOWER BOUND DETERMINATION"]},{"entry":["y","y"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["y \u2266 k ","y > k  "]},{"entry":["\u03bc = int (k )","\u03bc = int (k )"]},{"entry":["y = y","y = y"]},{"entry":["y= \u03bc + |\u03bc \u2212 y|","y= \u03bc \u2212 |y\u2212 \u03bc|"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"right"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"(26)"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{"maths":[{"@attributes":{"id":"MATH-US-00057","num":"00057"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"p","mo":"=","mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mfrac":[{"mn":["1","2"]},{"mn":["1","2"]}],"mo":["-","+","-"],"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","msub":{"mi":["y","L"]}}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","msub":{"mi":["y","u"]}}}}]}}}}}},{"@attributes":{"id":"MATH-US-00057-2","num":"00057.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"p","mo":"=","mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","msub":{"mi":["y","u"]}}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","msub":{"mi":["y","L"]}}}}],"mo":"-"}}}}}}]},{"maths":[{"@attributes":{"id":"MATH-US-00058","num":"00058"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"p","mo":"=","mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mfrac":[{"mn":["1","2"]},{"mn":["1","2"]}],"mo":["-","+","-"],"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","msub":{"mi":["y","L"]}}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","msub":{"mi":["y","u"]}}}}]}}}}}},{"@attributes":{"id":"MATH-US-00058-2","num":"00058.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"p","mo":"=","mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","msub":{"mi":["y","u"]}}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","msub":{"mi":["y","L"]}}}}],"mo":"-"}}}}}}]}]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{},"img":{"@attributes":{"id":"CUSTOM-CHARACTER-00070","he":"3.13mm","wi":"1.78mm","file":"US08693288-20140408-P00002.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},"sub":["L ","u"]},"Applying the algorithm of Equation (26) to the case for the experimental observed value y=m=39; non-empty partitions in Table 4 provide an estimate of p in order to test the null hypothesis of noise only:",{"@attributes":{"id":"p-0266","num":"0279"},"maths":{"@attributes":{"id":"MATH-US-00059","num":"00059"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"y","mo":"=","mrow":{"mi":"m","mo":"=","mrow":{"msub":{"mi":["y","L"]},"mo":"=","mn":"39"}}},{"mi":"\u03bc","mo":"=","mn":"39"},{"msub":{"mi":["y","u"]},"mo":"=","mrow":{"mn":"39","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"since","mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"\u03bc","mo":"-","msub":{"mi":["y","L"]}}}},"mo":"=","mn":"0"}}}}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mtext":{}},{"mtext":{}},{"mtext":{}}],"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"p","mo":"=","mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mi":[".5000",".5000"],"mo":["-","+","-"],"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"39"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"39"}}}]}}}}}},{"mtd":{"mrow":{"mo":"=","mrow":{"mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"39"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"39"}}}],"mo":"-"}}},"mo":"=","mn":"1.00"}}}}]}}},{"mrow":{"mo":["(",")"],"mn":"27"}}]}}}}},"The probability that y=m=39 indicates noise is 1.00. Using the nominal level of significance \u03b1=0.05 then since 1.00\u2267\u03b1NOISE; the operator can conclude that this time waveform contains virtually no signal information. To validate this value against the Gaussian calculation, use Equation (16) with m set to y but apply a quantized value of +0.5 to the numerator. For example:",{"@attributes":{"id":"p-0268","num":"0281"},"maths":{"@attributes":{"id":"MATH-US-00060","num":"00060"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"z","mo":"=","mrow":{"mfrac":{"mrow":{"mn":"39","mo":["-","+"],"mrow":{"mi":"k","mo":"\u2062"},"mi":".5"},"msqrt":{"mrow":{"mi":"k","mo":"\u2062"}}},"mo":"=","mrow":{"mo":"-","mrow":{"mn":"0.06","mo":"."}}}}},{"mrow":{"mo":["(",")"],"mn":"28"}}]}}}}},"Then, compute the p value from Equation (4) for the observed z-test value. This value is found to be p=0.95. If z were 0; p would be 1.00 by Equation (4).","The rule of the present method for applying the quantized continuity correction factor is: if y\u2212k\u22660, add +0.5\u2014and if y\u2212k>0, add \u22120.5. The algorithm appears acceptable if applied to selected values of y in Table 6 and compared to the Gaussian distribution.","For example: the likelihood that y was observed to be twenty is,",{"@attributes":{"id":"p-0272","num":"0285"},"maths":{"@attributes":{"id":"MATH-US-00061","num":"00061"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"y","mo":"=","mrow":{"msub":{"mi":["y","L"]},"mo":"=","mn":"20"}}},{"mrow":{"mo":["(",")"],"mn":"29"}}]},{"mtd":[{"mrow":{"mi":"\u03bc","mo":"=","mn":"39"}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"msub":{"mi":["y","u"]},"mo":"=","mrow":{"mrow":{"mn":"39","mo":"+","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mn":["39","20"],"mo":"-"}}},"mo":"=","mn":"58"}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"mi":"p","mo":"=","mrow":{"mrow":[{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mi":[".5000",".5000"],"mo":["-","+","-"],"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"39"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"58"}}}]}}},{"mrow":[{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"58"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"20"}}}],"mo":"-"}}},{"mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mi":[".99731",".00040"],"mo":"-"}}},"mo":"=","mi":".003"}],"mo":"="}],"mo":"="}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}]}}}},"The probability is only 0.003 that the number of non-empty partitions is twenty (20). This appears reasonable since twenty (20) is an extreme value compared to the mean 39.86, indicative of noise. The Gaussian p calculation with the continuity correction factor of +0.5 for y=20 is the same (p=0.003).","Another example: if y=27, the likelihood of that value can estimated by the algorithm:",{"@attributes":{"id":"p-0275","num":"0288"},"maths":{"@attributes":{"id":"MATH-US-00062","num":"00062"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"y","mo":"=","mrow":{"msub":{"mi":["y","L"]},"mo":"=","mn":"27"}}},{"mrow":{"mo":["(",")"],"mn":"30"}}]},{"mtd":[{"mrow":{"mi":"\u03bc","mo":"=","mn":"39"}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"msub":{"mi":["y","u"]},"mo":"=","mrow":{"mrow":{"mn":"39","mo":"+","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mn":["39","27"],"mo":"-"}}},"mo":"=","mn":"51"}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"mi":"p","mo":"=","mrow":{"mrow":[{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mi":[".5000",".5000"],"mo":["-","+","-"],"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"27"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"51"}}}]}}},{"mrow":[{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"51"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"27"}}}],"mo":"-"}}},{"mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mi":[".96319",".02036"],"mo":"-"}}},"mo":"=","mi":".057"}],"mo":"="}],"mo":"="}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}]}}}},"Compared to the Gaussian calculation with the continuity correction factor of +0.5 for y=27, p=0.05.","Lastly, if y=53; the Poisson p can be estimated by the algorithm:",{"@attributes":{"id":"p-0278","num":"0291"},"maths":{"@attributes":{"id":"MATH-US-00063","num":"00063"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"y","mo":"=","mrow":{"msub":{"mi":["y","U"]},"mo":"=","mn":"53"}}},{"mrow":{"mo":["(",")"],"mn":"31"}}]},{"mtd":[{"mrow":{"mi":"\u03bc","mo":"=","mn":"39"}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"msub":{"mi":["y","L"]},"mo":"=","mrow":{"mrow":{"mn":"39","mo":"-","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mn":["53","39"],"mo":"-"}}},"mo":"=","mn":"25"}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"mi":"p","mo":"=","mrow":{"mrow":[{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mi":[".5000",".5000"],"mo":["-","+","-"],"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"25"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"53"}}}]}}},{"mrow":{"mn":"1","mo":"-","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"53"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Y","mo":"\u2264","mn":"25"}}}],"mo":"-"}}},"mo":"=","mi":".027"}],"mo":"="}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}]}}}},"The p for the Gaussian is 0.046 with the continuity correction factor of \u22120.5.","The algorithm for estimating p to test the two-tailed signal-noise hypothesis is workable as validated against the Gaussian distribution. Overall, the differences of the p values (Poisson and Gaussian) are small.","To further validate the derived process, the algorithm in Equation (26) is applied to other Poisson distributions with means as low as 10-15. The means of those distributions differ from the interpolated means by no more than 4.4 percent. This percentile is an adequate tolerance level with which to compute p values to test the signal-noise hypothesis. When the mean is approximately one hundred (100) then only a 0.96 percent difference exists. At a mean of five hundred (500), the difference is down to 0.20 percent and continues to decrease with higher values of the Poisson mean.","Consequently, the algorithm is incorporated into the present method when the sample mean k>10 regardless of the sample size. When the mean does not meet the criteria of k>10, the p value cannot be estimated by Equation (26) due to the high asymmetry of such distributions. The two-tailed signal-noise hypothesis must be evaluated in the standard manner using the DECISION RULE, under HYPOTHESIS.","Employing the algorithm of Equation (2%) indicates that an alternate way to assess the signal and noise hypothesis involves comparing the estimated p to the approximate PFA by the rule adopted: p\u2267\u03b1NOISE; p<\u03b1SIGNAL+NOISE. That procedure would result in a faster solution.","Note that in the foregoing, the data derived from the Poisson frequency distribution (Table 4) of Method E has been used to illustrate the testing procedures for Method D. Those computations provided forty-eight (48) as the sample size based on the approximate procedure modeled on the formalism provided by the Feller reference (Chapter 6). In the alternative, if Method E is not implemented; the operator may use the actual sample size of fifty points (50) to carry out the computations for testing the signal-noise hypothesis. This has the effect of using the mean:",{"@attributes":{"id":"p-0285","num":"0298"},"maths":{"@attributes":{"id":"MATH-US-00064","num":"00064"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"k","mo":"\u2062"},{"mrow":{"mn":"125","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mn":"1","mo":"-","mrow":{"mi":"exp","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mo":"-","mfrac":{"mn":["50","125"]}}}}}}},"mo":"=","mn":"41.21"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"32"}}]}}}},"br":{},"img":{"@attributes":{"id":"CUSTOM-CHARACTER-00078","he":"3.13mm","wi":"1.78mm","file":"US08693288-20140408-P00002.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}},"That is, Table 6 would be based on 41.21 instead of 39.86. All numerical results would change slightly, but the conclusions will not differ in regard to determining that the input time waveform is noise.","In conclusion, the fifty point pseudo-random distribution in Table 4 has been analyzed with the testing procedures of the present invention. Each test has given the same result which is random noise.",{"@attributes":{"id":"p-0288","num":"0301"},"figref":["FIG. 2","FIG. 3A-3C"],"b":["50","100"]},"In , in support of the data characterization method , step  provides a measurement input of data based on a plurality of measurements of physical phenomena, such as sonar, medical imaging, or the like.","For example: step  comprises reading input data vectors {t, y, z} where t is clock time and x, y are amplitude measures in the time domain. This step may also comprise performing pre-processing conditioning, filtering, formatting, and selecting a discrete sample size N.","Step  comprises forming a three-dimensional convex hull over the data. The data is then partitioned into volumes based on a partitioning algorithm\u2014as previously described (See Method 1-4). The convex hull can average approximately fifty-two percent of the containing region formed by the t, y, z volume; thereby, providing a significant increase in processing speed as compared to the prior art.","In step , a determination is made as to whether the sample size is large or small. While presently preferred embodiments for this value (N>25) have been given hereinbefore, it will be understood that parameters can be selected which may vary. Thus, if the number of data elements is greater than a selected parameter, range of parameters, formulae based on parameters; then the sample size is considered large. If not, then the sample size is considered small.","Based on the determination made in step , a set of tests are utilized for a small sample size as indicated at data analysis module  or a large sample as indicated at data analysis module . Decision module  states that tests are conducted and followed by an \u201call or nothing\u201d decision rule. If all accepted tests indicate random noise, then that is the determination. Otherwise, the determination is to be a signal plus noise.","For LARGE SAMPLE TEST MODULE: N>25 as indicated at step , then the following tests comprise one possible presently preferred embodiment of: a Runs Test; a R Ratio; a Correlation Module; a Normal Approximate z-Test\/Confidence Interval (CI) Analysis; a Chi-square Test (alternative); a Nonlinear correlation and other correlation techniques (alternative).","For SMALL SAMPLE TEST MODULE: N  as indicated at step , then the following tests comprise one possible embodiment: a Runs Test; a R Ratio; a Correlation Module; and a Poisson Probability Test. One possible and presently preferred order of the testing protocol is:",{"@attributes":{"id":"p-0296","num":"0309"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Large Sample"},{"entry":"(Data Analysis Module 60)"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"77pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["TEST ORDER","TESTING PROCEDURE"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["First","Wald-Wolfowitz Runs test for independent"]},{"entry":[{},"samples"]},{"entry":[{},"Normal approximation"]},{"entry":[{},"Exact probability computation"]},{"entry":["Second","Correlation Method"]},{"entry":[{},"Linear R"]},{"entry":[{},"Serial Correlation (Autocorrelation)"]},{"entry":[{},"Correlogram"]},{"entry":["Third","R Ratio and Confidence Interval (CI)"]},{"entry":[{},"Analysis"]},{"entry":["Fourth","Normal Approximations z - Test for Poisson"]},{"entry":[{},"distribution on the number of non-empty"]},{"entry":[{},"partitions"]},{"entry":[{},"Exact Poisson Distribution Hypothesis"]},{"entry":[{},"Test (alternative)"]},{"entry":["alternative","Chi-square Test of Homogeneity"]},{"entry":["alternative","Nonlinear and other correlational"]},{"entry":[{},"techniques"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},{"@attributes":{"id":"p-0297","num":"0310"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Small Sample"},{"entry":"(Data Analysis Module 58)"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"77pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["TEST ORDER","TESTING PROCEDURE"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["First","Wald-Wolfowitz Runs test for Independent"]},{"entry":[{},"Samples (Exact test)"]},{"entry":["Second","Correlation Method"]},{"entry":[{},"Linear R"]},{"entry":[{},"Serial Correlation (Autocorrelation)"]},{"entry":[{},"Correlogram"]},{"entry":["Third","R Ratio and Confidence Interval Analysis"]},{"entry":["Fourth","Exact Poisson Distribution Hypothesis Test"]},{"entry":[{},"Standard Approach"]},{"entry":[{},"Significance probability"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"As indicated at step  of the decision module; if all test results indicate noise then the data is considered to be random. If any test indicates nonrandom; then the data contains signal information.","As indicated at step , reports may comprise outputs of analysis results in summary form, archiving (graphics and text) and the next window of data to be processed.","In regard to , steps , , , , , , and  of data characterization method  correspond to the previously discussed steps , , , , , , and  of . However, the characterization method  provides that testing continues while noise is the present conclusion.","Referring to , logic tests  are provided after each test; whereby, if any test determines that a signal is present (for example: the data is not random noise). At that time, the testing is terminated with a determination of a signal by the decision module .","Alternatively, if all tests characterize the data set as noise, then the method produces a characterization of the data set as noise as indicated at  shown in  shown in . As discussed hereinbefore with the data characterization method ; testing is conditional upon the size of the sample. The sample dictates the testing procedures used to evaluate the signal and noise hypotheses.","One utility of the present method is in the field of signal processing and other data processing fields in which it is of interest to know whether the measurement structure is random in the presence of potentially highly sparse data sets contained in a compact volume. The method provides a faster solution for randomness determination than prior art methods.","A significant new feature is an explicit method to handle very small samples by means of a polygon envelope; thereby, creating a more concentrated region for analysis. The calculation of the significance probability (as discussed hereinbefore for small samples) constitutes another novel, useful and non-obvious feature. The present inventive method can most likely be adopted for two-dimensional data sets in order to identify and filter Poisson noise. Finally, a four-dimensional time series analysis can be performed if measures {x, y, z} are captured at discrete time intervals t.","Various alternatives to the above-discussed methods are possible. Another example, during partitioning, another step may comprise establishing a criterion for eliminating or reducing the amount of non-whole cubic subspaces from the analysis. For example: eliminate subspace segments that are less than one-half to three-quarters of the size of the volume t. The sample size is reduced with this criterion. For small samples, this may lower the power of the testing procedures although the probability assumptions will be less violated.","During analysis, a Chi-square test for homogeneity (large samples) and the nonlinear correlation may be utilized. In addition, the small sample Poisson probability test can be used in place of the large sample approximate test since exact probabilities will be provided regarding the signal-noise hypothesis. The autocorrelation functions (ACF) may be computed for as many lags as possible.","For non-time series data, many variable-relational techniques are known to those skilled in the art, including multivariate nonlinear curve fitting, partial correlation, canonical correlation analysis, pattern recognition, image processing, feature extraction, and other multivariate data reduction techniques. However, these are large sample methods that require significant analyst input in the interpretation of outcomes. In the decision module, testing may contain as many procedures as needed to provide confidence to the operator that the data are a noise or a signal.","The improved methodology over the prior art of this field can be applied to the two-dimensional case for noise identification and filtering. Moreover, the inventive method can be applied to four-dimensional structures with time t concomitant with measures {x, y, z}.","Many additional changes in the details, components, steps, and organization of the system, herein described and illustrated to explain the nature of the invention, may be made by those skilled in the art within the principle and scope of the invention. It is therefore understood that within the scope of the appended claims, the invention may be practiced otherwise than as specifically described."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["A more complete understanding of the invention and many of the attendant advantages thereto will be readily appreciated as the same becomes better understood by reference to the following detailed description when considered in conjunction with the accompanying drawings, wherein like reference numerals refer to like parts and wherein:",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 3A-3C"}]},"DETDESC":[{},{}]}
