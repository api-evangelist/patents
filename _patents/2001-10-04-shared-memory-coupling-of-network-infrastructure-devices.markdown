---
title: Shared memory coupling of network infrastructure devices
abstract: Described herein are systems and methods of coupling network infrastructure devices through a shared memory facility, rather than through conventional network I/O (input/output) adapters. All communications through the resulting network infrastructure service system are conducted using shared memory as the physical transport medium. In this way, the congestion and processing overhead caused by the duplication and storage of multiple copies of data packets to be transferred between network infrastructure devices may be avoided. This feature of the invention significantly increases the speed at which packets may be transmitted between network infrastructure devices.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06999998&OS=06999998&RS=06999998
owner: Hewlett-Packard Development Company, L.P.
number: 06999998
owner_city: Houston
owner_country: US
publication_date: 20011004
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This invention relates, in general, to network infrastructure (or edge) devices and, in particular, to systems and methods of coupling network infrastructure devices through a shared memory facility.","In modern computer systems, computers may communicate with each other and with other computing equipment over various types of data networks. Routable data networks are configured to route data packets (or frames) from a source network node to one or more destination network nodes. As used herein, the term \u201croutable protocol\u201d refers to a communications protocol that contains a network address as well as a device address, allowing data to be routed from one network to another. Examples of routable protocols are SNA, OSI, TCP\/IP, XNS, IPX, AppleTalk, and DECnet. A \u201croutable network\u201d is a network in which communications are conducted in accordance with a routable protocol. One example of a routable network is the Internet, in which data packets are routed in accordance with the Internet Protocol (IP). In a routable data network, when a network routing device (or router) receives a data packet, the device examines the data packet in order to determine how the data packet should be forwarded, if at all. Similar forwarding decisions are made as necessary at one or more intermediate routing devices until the data packet reaches a desired destination node.","Network infrastructure services have been developed for monitoring, managing and manipulating traffic through a network. In general, network infrastructure services may be classified as security services (e.g., firewall, proxy and intrusion detection services), quality of service services (e.g., load balancing), or network management services (e.g., application level management and active network management services). These services conventionally are implemented as one or more software modules executing on general-purpose computers, in hardware, firmware or software operating in single-function (or dedicated) devices, or in software or firmware operating on switches and routers. A general-purpose computer typically provides a complete operating environment for network infrastructure applications, including all of the services provided by the operating system and application program interfaces for communicating with the operating system. New network infrastructure applications may be loaded and, generally, existing network infrastructure applications may be updated on a general-purpose computer simply by loading the new application or application update. However, the performance (e.g., bandwidth, latency, interrupt response time, and processing speed) of general-purpose computers typically is not optimized for running network infrastructure applications. In contrast, the performance of a dedicated device typically is optimized for providing a particular network infrastructure service. Although the operating characteristics of a dedicated device generally may be changed simply by loading a new configuration file into a dedicated device, the service functionality of a dedicated device typically cannot be changed. Thus, a new dedicated device usually is needed for each new network infrastructure service that is to be implemented in the network.","In sum, in terms of network infrastructure service management, general-purpose computers provide the greatest flexibility and the lowest performance, whereas dedicated devices typically provide the highest performance and the least flexibility. The flexibility and performance characteristics of routers and switches generally fall somewhere between the corresponding characteristics of general-purpose computers and dedicated devices.","To address some of these issues, U.S. Pat. No. 6,157,955 has proposed a general-purpose programmable packet-processing platform for accelerating network infrastructure applications that have been structured to separate the stages of classification and action. According to the Abstract of this patent:\n\n","The invention features systems and methods of coupling network infrastructure devices through a shared memory facility rather than through conventional I\/O (input\/output) adapters. All communications through the resulting network infrastructure service system are conducted using shared memory as the physical transport medium. In this way, the congestion and processing overhead caused by the duplication and storage of multiple copies of data packets to be transferred between network infrastructure devices may be avoided. This feature of the invention significantly increases the speed at which packets may be transmitted between network infrastructure devices. In addition, the invention provides an interface that makes the shared memory facility appear to application programs as a regular network. Thus, application programs may use the shared memory facility without having to be re-coded.","In one aspect, the invention features a system providing network infrastructure services. The system comprises a shared memory facility interconnecting a plurality of network devices each configured to perform a dedicated network infrastructure function.","Embodiments of the invention may include one or more of the following features.","In some embodiments, the dedicated network infrastructure function is selected from the group consisting of: a network security function, a quality of service function, and a network management function. In these embodiments, the dedicated network infrastructure function may be a proxy function, a load balancing function, a memory caching function, an encryption function, a compression function, a re-routing function, an application level network management function, or an active network management function.","The shared memory facility may be a global shared memory facility, a distributed shared memory facility, or a logically shared memory facility.","In some embodiments, each network device is operable to perform only a single network infrastructure function.","In other embodiments, each network device is configurable and comprises a local processor and a local memory. In these embodiments, each network device preferably includes in local memory an application module that is operable to control the functionality of the network device, and a configuration file containing parameters controlling operating characteristics of the network device. Each network device also may include a kernel that is operable to provide basic services to the network device. The dedicated network infrastructure function that is performed by a network device may be dynamically configurable. The dedicated network infrastructure function that is performed by a network device may be selected based upon a network management policy.","In some embodiments, each network device includes a local communications protocol stack, and a shared memory interface system. The shared memory interface system is operable to provide a local shared memory network between the network devices, and a global shared memory network between the network devices and one or more remote nodes by capturing packets from the local communications protocol stacks and routing the captured packets over the shared memory facility. The shared memory interface system on each local node may comprise a local shared memory virtual adapter and a global shared memory virtual adapter. The local shared memory virtual adapters are operable to capture locally addressed packets from the local communications protocol stacks and to route the captured packets for physical transport over the shared memory facility. The global shared memory virtual adapters are operable to capture globally addressed packets from the local communications protocol stacks and to route the captured packets for physical transport over the shared memory facility. The local shared memory virtual adapters preferably appear to the local communications protocol stacks as device drivers for physical network adapters that are connected to the local shared memory network. The global shared memory virtual adapters preferably appear to the local communications protocol stacks as device drivers for physical network adapters that are connected to the global shared memory network.","The global shared memory network allows all of the local nodes to be addressed by a single network address. In this way, packets may be diverted from one node to another in a manner that is transparent to remote client nodes (e.g., a remote client node does not have to explicitly make a connection to a local node that is actually servicing the remote client node). The local shared memory network enables local network device nodes to communicate over shared memory using conventional network software. In addition, the local shared memory network enables each local device to be addressed uniquely through a local shared memory network address.","In another aspect, the invention features a method of providing network infrastructure services that comprises interconnecting through a shared memory facility a plurality of network devices each configured to perform a dedicated network infrastructure function.","In another aspect of the invention, a computer program residing on a computer-readable medium comprises computer-readable instructions for causing a computer system to interconnect through a shared memory facility a plurality of network devices each configured to perform a dedicated network infrastructure function.","Other features and advantages of the invention will become apparent from the following description, including the drawings and the claims.","In the following description, like reference numbers are used to identify like elements. Furthermore, the drawings are intended to illustrate major features of exemplary embodiments in a diagrammatic manner. The drawings are not intended to depict every feature of actual embodiments nor relative dimensions of the depicted elements, and are not drawn to scale.","Referring to , in one embodiment, a network infrastructure service system  includes a plurality of device nodes , , ,  that are interconnected by a shared memory facility  on which a local shared memory network and a global shared memory are constructed. Each device node \u2013 includes a network infrastructure (or edge) device whose functionality and operating characteristics may be reconfigured. A remote client node  and a network management node  may connect to network infrastructure service system  over a respective external network , . Remote client node  and network management node  each may be implemented as a single computer system or a multi-computer system having nodes that are interconnected to form a network. In multi-computer system embodiments, the component systems of remote client node  and network management node  may be implemented in one or more whole computer systems. Remote client node  and network management node  each includes conventional network interfaces (not shown) that provide electronic and communication interfaces to external networks , . External networks ,  each may be implemented as a LAN or a WAN. External networks ,  may be connected to remote client nodes  and network management node  by conventional network routers (not shown). External networks ,  may be of the same or different types. For example, external network  may be an ATM (Asynchronous Transfer Mode) network and external network  may be an Ethernet network. In addition, external networks ,  may have different performance characteristics from one another. For example, external networks ,  may have different load conditions, transmission characteristics, and maximum transmission unit (MTU) sizes (i.e., the largest packet sizes that can be transmitted over the networks).","Communications with network infrastructure service system  are conducted in accordance with a routable communications protocol (e.g., TCP\/IP, SNA, OSI, XNS, IPX, AppleTalk, and DECnet). In the illustrated embodiment, network communications with network infrastructure service system  are described in accordance with the TCP\/IP protocol. Accordingly, network infrastructure service system , remote client node , network management node , and external networks ,  each are assigned a unique IP address. Any additional network nodes (e.g., routers) that are distributed along the routes between remote client node , network management node , and network infrastructure service system  also are assigned a respective IP address.","As explained in detail below, network management node  may access device nodes \u2013 individually or they may access network infrastructure service system  as a single, unified computing resource in accordance with a standard routable network communication protocol. In addition, each of the device nodes \u2013 may access another device node \u2013 or network management node  in accordance with the same standard routable network communication protocol; even device nodes that are not physically connected to external networks ,  may access remote client node  and network management node  over one of the shared memory networks. All communications through network infrastructure service system  may be conducted using shared memory as the physical transport medium. In this way, the congestion and processing overhead caused by the duplication and storage of multiple copies of data packets in non-shared-memory communications networks may be avoided.","As explained in detail below, network management node  includes a service management module  that is configured to deploy network infrastructure services across network infrastructure service system  by causing each network device \u2013 to receive a network infrastructure service module  that may be stored at a storage node . Each network infrastructure service module  may be loaded by a respective network device \u2013 to implement a particular network infrastructure service function. For example, in one illustrative network infrastructure service deployment, device nodes ,  may be configured to perform load balancing functions, and device nodes ,  may be configured to perform firewall functions. Other network infrastructure service deployments are possible. The resources of each network device \u2013 are allocated to perform a single network infrastructure service function at any given time. In addition, each network device \u2013 may be reconfigured to perform a different network infrastructure function simply by loading a different network infrastructure service module . In this way, network infrastructure services may be deployed rapidly and flexibly in accordance with a selected network management policy, while substantially maintaining the performance advantages provided by dedicated-function network devices. In addition, because the network infrastructure services are deployed from a centralized source, the distributed network devices \u2013 may be synchronized and reconfigured in a coherent and efficient way.","Referring to , in one embodiment, service management module  may manage a plurality of network infrastructure services that are provided by network infrastructure service system  as follows. Service management module  interrogates network devices \u2013 to determine the status of the network devices \u2013 and to obtain statistics about network traffic flowing through the network devices \u2013 (step ). Communication between service management module  and network devices \u2013 may be in accordance with a simple network management protocol (SNMP), a common open policy service (COPS) protocol, or some other agreed-upon protocol. Based upon this information, service management module  determines whether a network device initialization is required (e.g., because there is a new device, or a device has transmitted an initialization request, or a device has failed) (step ). If a network device initialization is required (step ), service management module  causes a selected network infrastructure service module  to be received by the network devices to be initialized (step ). The network infrastructure service modules  may be disseminated to the network devices \u2013 in accordance with a push-type or a pull-type transmission model. The network infrastructure service modules  may be selected based upon a network management policy (e.g., a user priority policy, a type of service policy, a congestion control policy, a service level policy, or an allocation of resources policy). In addition, service management module  determines whether resources should be reallocated in order to optimize the performance of the network under current network conditions (step ). If a resource reallocation is required (step ), service management module  causes a replacement network infrastructure service module  to be received by one or more of the network devices \u2013 to change their functionality or their operating characteristics, or both (step ). Service management module  also determines whether the network infrastructure service modules  loaded onto one or more of the network devices \u2013 should be updated (step ). If a device update is required (step ), service management module  causes updated network infrastructure service modules  to be received by the network devices \u2013 to be updated (step ). Service management module  periodically interrogates the next network devices \u2013 (step ), and repeats the above-described service management process (steps \u2013).","General Operating Environment of the Shared Memory Networks","Referring to , in one embodiment, although each network device \u2013 may have a different overall architecture, these devices share a common core component structure that includes one or more processors  with associated caches , a memory controller , and an input\/output (I\/O) controller . The memory controller  is connected to a memory bridge  and a local memory . The input\/output (I\/O) controller  may be connected to one or more network interface cards (NICs) , which provide physical connections to external networks , . The processors  communicate with memory controller  and I\/O controller  over a memory (or system) bus , which may be compatible with any of a variety of bus protocols, including PCI, VESA, Microchannel, ISA, and EISA. Memory bridge  provides a coherent physical layer interconnecting the memory busses of device nodes \u2013 to form a virtual computer system. Memory controller  controls the flow of data between processors  and the local memory  and remote memory (i.e., memory residing on another device node). In this architecture, if a processor  requests data that is not in cache  or in local memory , memory controller  retrieves the data from a remote memory through memory bridge . Memory controller  may include bus-snooping protocols and other intelligence to maintain cache coherence. For example, memory controller  may communicate with the memory controllers of other device nodes in accordance with a standard cache coherence protocol (e.g., the ANSI\/IEEE Scalable Coherent Interface protocol (SCI)) that provides shared memory across device nodes \u2013.","As shown in , a number of program modules may be stored in the local memory  of each device node \u2013, including an operating system  (e.g., the Windows NT\u00ae operating system available from Microsoft Corporation of Redmond, Wash. U.S.A.) and a network service application program . Program data, such as a connection table , a registry (or configuration database) , and a configuration database  also may be stored in local memory . Operating system  includes a kernel  that provides the base operating system services (e.g., memory management, process and thread management, security, input\/output, and interprocess communication) for creating a run-time execution environment on a device node \u2013. The registry  contains the following information: parameters needed to boot and configure the system; system-wide software settings that control the operation of operating system ; a security database; and per-user profile settings. A native operating system (OS) application programming interface (API)  exposes the base operating system services of the executive to network service application program  and to one or more shared memory services (or services modules) . As used herein, the term \u201cservice\u201d (or \u201cservice module\u201d) refers to a component of an operating system that provides a set of one or more functions. The shared memory service modules  are device drivers that may be configured to start automatically at system boot time without requiring an interactive logon; they also may be controlled dynamically during run-time. The shared memory service modules  call certain base operating system services (or functions) to interact with a service controller; such functions may include registering a successful startup, responding to status requests, and pausing or shutting down the service. The service controller starts, manages and directs operations within the service modules . The shared memory service modules , on the other hand, create the environment in which one or more processes may operate and control the start-up, maintenance and termination of such processes. The shared memory service modules are designed to configure the shared memory facility to look like a conventional transport medium and make it available to networking applications. In this way, networking applications do not have to be re-coded before using a shared memory connection.","Typically, the run-time execution environment is installed on a device node \u2013, and network infrastructure service application program  may access the functionality provided by the shared memory service modules  through a shared memory API . The shared memory modules, however, allow the application programs  to access the functionality provided by the shared memory service modules  without being recorded to a shared memory API. Instead, application programs simply may use existing networking APIs. Before a shared memory service module  may operate in the run-time execution environment, it must be installed on a device node \u2013. A shared memory service module  typically is installed by storing the shared memory service module  in a data storage area that is accessible by a device node \u2013, and registering the attributes of the service module  in the registry . Further details about the Windows NT\u00ae operating system may be obtained from \u201cInside Windows NT,\u201d Second Edition, David A. Solomon, Microsoft Press (1998), which is incorporated herein by reference.","The kernel , the network infrastructure service application , and the configuration database  may be encapsulated into a network infrastructure service module  that may be obtained from storage node . Configuration database  may contain parameters needed to boot and configure the network devices \u2013, and system-wide software settings that control the operation of operating system . Network infrastructure service application  provides the specific network infrastructure function to be performed by the network devices \u2013. The function may be, for example, a proxy function, a load balancing function, a memory caching function, an encryption function, a compression function, a re-routing function, an application level network management function, or an active network management function. Each of these functions may be implemented as one or more conventional network infrastructure service software programs.","Each network device \u2013 may perform additional network functions, such as monitoring and collecting information relating to network traffic flowing through the network devices \u2013. This information may be stored in memory local memory  for retrieval by service management module . This additional functionality may be enabled by loading one or more corresponding service modules into the network devices.","Network infrastructure service module  may be loaded by a network device \u2013 at boot-up or dynamically. At boot-up, the network devices \u2013 may obtain service module  by transmitting an initialization request to service management module . In response to the initialization request, service management module  may reply by returning either a selected network infrastructure service module  or an identifier with which the network device \u2013 may retrieve the selected network infrastructure service module  from storage node . Depending upon the particular implementation and the particular network infrastructure management task to be performed, some or all of the components of network infrastructure service module  may be transmitted to a network device \u2013. For example, all of the components of the network infrastructure service module  may be transmitted to a network device \u2013 to initialize or change the functionality of the network device \u2013. Alternatively, only the configuration database  may be transmitted to a network device \u2013 to update the operating parameters of the network device \u2013.","A shown in , the execution environment stored in local memory  also includes a set of network transport protocols . In the illustrated embodiment, communications over the local and global shared memory networks are conducted in accordance with the Transmission Control Protocol\/Internet Protocol (TCP\/IP). The TCP portion of the protocol provides the transport function by breaking a message into smaller packets, reassembling the packets at the other end of the communication network, and re-sending any packets that get lost along the way. The IP portion of the protocol provides the routing function by assigning to the data packets addresses for the destination network and the target node at the destination network. Each data packet that is communicated using the TCP\/IP protocol includes a header portion that contains the TCP and IP information. The IP protocol provides no guarantee of packet delivery to the upper layers of the communications stack. The TCP protocol, on the other hand, provides a connection-oriented, end-to-end transport service with guaranteed, in-sequence packet delivery. In this way, the TCP protocol provides a reliable, transport layer connection. In other embodiments, communications over the local and global shared memory networks may be conducted in accordance with the User Datagram Protocol\/Internet Protocol (UDP\/IP). UDP may be used in place of TCP in conditions when a reliable delivery is not required. For example, UDP\/IP is often used for real-time audio and video traffic where lost data packets are simply ignored, because there is no time to retransmit. Gateways may be used to convert into a TCP\/IP (or UDP\/IP) format data packets that are received from external networks using different protocols. The execution environment also includes hardware link level and access protocols, which may correspond to the Data link and Physical layers of the Open System Interconnection (OSI) reference model.","At system start up, each device node \u2013 must determine an IP address for each of its network interfaces before it may communicate using TCP\/IP. For example, a device node \u2013 may need to contact a server to dynamically obtain an IP address for one or more of its network interfaces. The device node \u2013 may use a Dynamic Host Configuration Protocol (DHCP) to issue a request for an IP address to a DHCP server. For example, a DHCP module broadcasts a DHCP request packet at system start up requesting allocation of an IP address for an indicated network interface. Upon receiving the DHCP request packet, the DHCP server allocates an IP address to the requesting device node \u2013 for use with the indicated network interface. The requesting device node \u2013 then stores the IP address in the response from the server as the IP address to associate with that network interface when communicating using TCP\/IP.","General Architecture of the Shared Memory Networks","As mentioned above, two shared memory networks are created: (1) a local shared memory network supporting traditional node specific addresses; and (2) a global shared memory network supporting global node addresses. In this way, device nodes \u2013 may communicate through standard network interfaces while using shared memory as the physical transport medium. Over the local shared memory network, network infrastructure service system  may be addressed externally and internally as individual nodes. This feature enables applications to have particular node affinities (such as hardware affinities), and enables distributed processing within the network infrastructure service system partition. Over the global shared memory network, network infrastructure service system  may be addressed externally and internally as a single node. This feature enables the system to be used as a single, unified computing resource and reduces system administration and client application development overhead.","In general, the local shared memory network and the global shared memory network have the following characteristics:\n\n","Referring to , in one embodiment, for each of the local and global shared memory networks a number of shared memory rings are created. In particular, for each shared memory network, the following structures are allocated in global shared memory: (1) one broadcast ring  per system partition; (2) a configurable number of multicast rings ; and (3) a pair of transmit\/receive rings  between each pair of device nodes \u2013 (i.e., for a four-node network infrastructure service system , twelve transmit\/receive rings are created). In some embodiments, each of the shared memory rings corresponds to a respective pool of a fixed number of scribble buffers (or slots) in global shared memory. In other embodiments, the buffer pools may have variable lengths, and a linked list reconstruction algorithm may be used to reconstruct the pools in the event of failure. Each pool slot is a data buffer having a size of approximately one MTU. In the illustrated embodiment, the MTU may range in size from 1,490 bytes to 65,536 bytes. The MTU size is a configurable parameter for each of the local and global shared memory networks. By making the MTU flexible and configurable network administrators may match the MTU to the physical media connecting the system to the outside world. In some embodiments, multiple shared memory networks may be created with different MTUs. In this way, traffic may be partitioned to take the most efficient path. For example, traffic between the devices utilizing shared memory may travel a link with the largest possible MTU (e.g., 65,536 bytes). Traffic destined to an outside Ethernet, on the other hand, may be directed onto a shared memory network link with a 1,500 byte MTU. Packets on this link may be shaped to this MTU without having to be fragmented when they reach the node that must put the packets on the physical Ethernet.","As shown in , in one embodiment, a write pointer (W(Cast)) , which indicates the next slot to which to write, and a slot sequence number (SN(Cast))  are associated with broadcast\/multicast buffer pool . Each multicast pool also has an associated memory area that labels the multicast address of the pool. In operation, broadcast ring  receives all broadcast packets from all of the device nodes \u2013, and each multicast ring  receives all multicast packets that are addressed to its respective multicast address. Each of the broadcast ring  and the multicast rings  has a configurable fixed depth, which translates into a fixed number of packet slots. Each of the broadcast ring  and the multicast rings  is allocated at a respective known global address by the first device node that tries to place a packet in the broadcast ring or one of the multicast rings. Each of the broadcast ring  and the multicast rings  is synchronized in accordance with a ticker tape mutual exclusion locking algorithm in which writes are serialized by locks in global shared memory, reads are not serialized, and writers are not blocked for readers but are forced into the \u201cstale\u201d slot.","As shown in , in one embodiment, a write pointer (W(transmitting node a: receiving node b)) ,  and a read pointer (R(transmitting node a: receiving node b)) ,  are associated with each of the transmit\/receive buffer pools ,  that are allocated between each pair of device nodes \u2013. Each of the transmit\/receive rings  is configured for unidirectional transfer of data between a pair of device nodes \u2013. The write and read pointers \u2013 are located in global shared memory. In some embodiments, the write pointers ,  are completely under the control of the transmitting nodes, and the read pointers are completely under the control of the receiving nodes. In these embodiments, local memory locks protect the read and write pointers \u2013. In other embodiments, a global lock may be used to serialize access to the transmit\/receive buffer pools , . In operation, when a writer transmits a packet, a pool slot is filled, the write pointer ,  is incremented, and the receiving node is notified by the generation of an interrupt at the receiving node. At the receiving node, a pool slot is emptied and the read pointer ,  is incremented. There is no \u201cjoin\u201d processing on the local shared memory network or the global shared memory network. Instead, nodes are discovered when they place a packet in the broadcast pool. When this occurs, each active node connects the pre-allocated receive ring on the discovered node from transmit. These rings are guaranteed to be allocated before processing is initiated on a node. When a node on the local shared memory network fails, the transmit rings into the failed node are marked down and, in the general case, all access to the failed node's shared memory ceases. If the failed node allocated the broadcast pool or any multicast pools, these pools are reallocated on another device node.","Referring to , in one embodiment, each packet message that is placed on the local shared memory network or the global shared memory network is encapsulated as a LAN packet  that is prefixed by a shared memory MAC header . In another embodiment, each message packet may not be encapsulated in a LAN packet with IP and TCP\/UDP headers. Instead, these message packets may be presented directly to other local devices, and protocol (e.g., IP\/TCP\/UDP) processing is performed only once on the receiving node. The LAN packet  includes an Internet packet  that is sandwiched between a LAN header  and a LAN trailer . IP packet  includes an IP header , a UDP header , and a data area . As shown in , the shared memory MAC header  includes a source identifier , a destination identifier , and a packet type identifier . Source identifier  has a size of six bytes, and for non-cast packets, the last two bytes correspond to the source node ID, which may be used by the virtual network adapters (described below) for routing packets to the appropriate shared memory buffer pools. Destination identifier  has a size of six bytes, and for non-cast packets, the last two bytes correspond to the destination node ID, which may be used by the virtual network adapters (described below) for routing packets to the appropriate shared memory buffer pools. Packet type identifier  has a size of two bytes and corresponds to the packet type identifiers used for IEEE standard 802.3 CSMA\/CD local area networks. The packet type identifier  may be used for multi-protocol packet multiplexing.","As mentioned above, in one embodiment, the local shared memory network and the global shared memory network are implemented in software by shared memory virtual adapters that are configured to appear to user application programs as standard hardware network interfaces. Data transmissions over the local and global shared memory networks are passed through the shared memory virtual adapters, which control the routing of packets through the shared memory facility . Each network adapter registers with the network layer in the TCP\/IP (or UDP\/IP) stack that it is able to reach IP addresses of interfaces within the local shared memory network or the global shared memory network. In this way, packets received by the TCP\/IP (or UDP\/IP) stack that are addressed for delivery over the local shared memory network or the global shared memory network will be passed by the TCP\/IP (or UDP\/IP) stack to the appropriate shared memory virtual adapters. The shared memory virtual adapters, in turn, encapsulate the data packets in suitably addressed data frames and pass the data frames back to the TCP\/IP (or UDP\/IP) stack to be sent to the correct physical address through the shared memory facility  or through a physical network adapter .","Referring to , network infrastructure service application  may transmit data  to be sent over the local shared memory network or the global shared memory network, as follows. Initially, network infrastructure service application  transmits data  through the operating system API . The operating system API  converts the received data  into data packets  in accordance with the TCP\/IP (or UDP\/IP) protocol by adding the LAN header  and the LAN trailer , the IP header , and the UDP header . The operating system API  transmits the data packets  to the TCP (or UDP) layer of the TCP\/IP (or UDP\/IP) protocol stack . The TCP (or UDP) layer passes the data packets  to the IP layer, which refers to a routing table  to determine which network interface should be used to reach the destination IP address. The IP layer determines from the routing table  that the destination IP address corresponds to a local shared memory network node or a global shared memory network node and, therefore, passes the data packets to an appropriate shared memory virtual adapter . The shared memory virtual adapter  encapsulates the received data packets into appropriately addressed data frames, each prefixed with a shared memory MAC header , and passes the data frames back to the TCP\/IP (or UDP\/IP) protocol stack . The TCP layer forms a TCP layer packet  for each data frame, with the data frame as its data. The IP layer consults the routing table  and, based upon the routing table entries, routes the TCP layer packets  to global shared memory through memory bridge  or to external network  through physical network adapter .","Referring to , data packets that are addressed for the local shared memory network or the global shared memory network and received through memory bridge  or physical network adapter  may be transmitted to network infrastructure service application , as follows. Initially, data arrives over a physical network and is received by either memory bridge  or physical network adapter  and passed to a physical network driver. The physical network driver passes the data through the IP layer of the TCP\/IP (or UDP\/IP) protocol stack , which in turn passes the data to shared memory virtual adapter  based upon an entry in routing table . Shared memory virtual adapter  strips off the MAC header  and passes the data back to the IP layer of the TCP\/IP (or UDP\/IP) protocol stack . The data is then passed through the TCP\/IP (or UDP\/IP) protocol stack  and the operating system API  to the user application .","Referring to , in one embodiment, the shared memory virtual adapters are implemented as Network Device Interface Specification (NDIS) MAC intermediate drivers  for use in the Microsoft Windows NT\u00ae operating environment. In this embodiment, the shared memory virtual adapters appear to the TCP\/IP (or UDP\/IP) protocol stack as an Ethernet physical adapter. In this embodiment, network service application  passes data to a WinSock layer  that interfaces with the TCP (or UDP) layer  of the TCP\/IP (or UDP\/IP) protocol stack. The network service application  also passes a destination IP address that is associated with a node on the local shared memory network or the global shared memory network and is accessible through a shared memory virtual adapter . The TCP (or UDP) layer  passes the data to the IP layer , which in turn passes the data to an NDIS MAC interface layer . The shared memory virtual device driver  previously has registered with the IP layer  that it is able to reach a node associated with the destination IP address for the user application data. Accordingly, the IP layer uses the NDIS MAC layer interface  to invoke the driver interface to the shared memory virtual device driver . The shared memory virtual device driver  encapsulates the received data into a data frame prefixed with a shared memory MAC header  indicating the IP address of a node on the local shared memory network or the global shared memory network. The shared memory virtual device driver  passes the data frame to WinSock layer , which passes the data frame through TCP layer , IP layer , and NDIS MAC interface layer  to a physical layer . The physical layer  transmits data frames to memory bridge  or physical network adapter .","In the embodiment of , all normal Windows NT\u00ae server networking tools, such as the network monitor and the NCP, recognize the shared memory networks and function normally because all driver functions are supported and a MAC header is created. In addition, because a MAC header is constructed, Netbios and Netware should function normally over the local shared memory network. All normal Windows NT\u00ae server networking commands, such as ipconfig, route, and netstat, recognize the shared memory networks and function normally. User applications deal with the local and global shared memory networks in the same way that they would deal with other IP interfaces and addresses. Multiple shared memory virtual adapters may be installed on each of the device nodes \u2013. Each of the virtual adapters may be configured with its own unique IP address. The local shared memory network and the global shared memory network may be multihomed with unique MTU settings.","In other embodiments, the shared memory virtual adapters may be implemented in a UNIX-based execution environment. For example, the shared memory virtual adapters may be provided by a STREAMS mechanism, which is a feature of a UNIX-based system that provides a standard way of dynamically building and passing messages up and down a communications protocol stack.","Packet Routing Over the Local Shared Memory Network","In the above-described embodiments, each device node \u2013 may be addressed over the local shared memory network by a unique IP address. The local shared memory virtual adapters  use shared memory MAC header , which includes the node identifier that is embedded in the physical address, to avoid demultiplexing output packets. In particular, the shared memory MAC header  includes a special bit that is set to signal internal shared memory virtual device driver commands.","Normal Address Resolution Protocol (ARP) processing may be used to route packets over the local shared memory network. In particular, an ARP process may be used to map IP layer addresses (referred to herein as \u201cIP addresses\u201d) to addresses that are used by the hardware link level and access protocols (referred to herein as \u201cphysical addresses\u201d or \u201cMAC addresses\u201d). The ARP protocol layer in each device node \u2013 typically contains a table of mappings between IP addresses and physical addresses (referred to as the \u201cARP cache\u201d). When a mapping between an IP address and the corresponding physical address is not known, the ARP protocol issues a broadcast packet (an \u201cARP request\u201d packet) on the local shared memory network. The ARP request indicates an IP address for which a physical address is being requested. The ARP protocols in each device node \u2013 examine the ARP request, and if a device node recognizes the IP address indicated by the ARP request, it issues a response (an \u201cARP response\u201d or \u201cARP reply\u201d packet) to the requesting device node indicating the responder's physical address. The requesting ARP protocol reports the received physical address to the local IP layer, which then uses the received physical address to send datagrams directly to the responding device node.","Packet Routing Over the Global Shared Memory Network","In one embodiment, the global shared memory virtual adapters on each of the device nodes \u2013 are configured for an identical global IP address, which is read from the registry . In this way, network applications executing outside of network infrastructure service system  may address a set of the device nodes \u2013 using a single global IP address. Multiple global IP addresses may be assigned to one or more sets of the device nodes \u2013. Global IP addresses are visible to applications running on device nodes \u2013 and appear as normal network interfaces. Global IP addresses are not linked to any physical adapters. In TCP-based embodiments, the TCP registry entries for the global shared memory virtual adapters are modified to include an additional attribute of GLOBAL. In addition, the TCP\/IP layer is modified so that any packet destined to a GLOBAL interface and not received from a GLOBAL interface is handed to a global shared memory virtual adapter for processing. Packets destined to a GLOBAL interface and received from a GLOBAL interface are passed up to the local TCP\/IP protocol stack for processing. In UNIX-based embodiments, the ifconfig command may be used to set to GLOBAL flag on the interface.","Referring to , the global shared memory virtual adapters may route packets over the global shared memory network, as follows. Initially, a globally addressed packet is cracked to determine its targeted 5-tuple (i.e., <protocol, local address, local port, foreign address, foreign port>), which fully specifies its TCP connections and UDP associations (step ). Next, the transmitting global shared memory virtual adapter queries a local connection table to identify an exact match for the 5-tuple (step ). The connection table contains a list of active (or pending) connections to the global shared memory network. In Windows NT\u00ae-based embodiments, the Windows NT\u00ae TCP\/IP protocol stack may be queried to export the location of the open TCP and UDP ports. At initialization and periodically thereafter, the global shared memory virtual adapters walk the port connections to create and update the connection table entries. Garbage collection for the connection tables is triggered by a periodic timer. If an exact match for the 5-tuple is found (step ), the globally addressed packet is forwarded to the matching node identified in the local connection table (step ). Otherwise, the transmitting global shared memory virtual adapter queries the global shared memory virtual adapters on other nodes for an exact match (step ). If another driver responds (step ), the transmitting global shared memory virtual adapter updates the local connection table with the identifier <node, 5-tuple > (step ) and forwards the globally addressed packet to the responding node (step ).","If no exact match is found for the 5-tuple (step ), the transmitting global shared memory virtual adapter replaces the local address of the 5-tuple with a wild card value (step ) and queries the local connection table or the other global shared memory virtual adapters for a match (step ). If a match is found (step ) this would indicate a server waiting for a connection request on any connected network from a particular foreign address and port. If only one match is found (step ), the transmitting global shared memory virtual adapter updates the local connection table (step ) and forwards the globally address packet to the matching node (step ). If multiple matches are found (step ), this would indicate that the server has multiple instances executing within the system partition. In this case, the transmitting global shared memory virtual adapter invokes a load-balancing algorithm (e.g., a round robin load-balancing algorithm) to select a destination node (step ). The transmitting global shared memory virtual adapter updates the local connection table to reflect this selection (step ) and forwards the globally addressed packet to the selected node (step ).","If no match is found at this point (step ), the transmitting global shared memory virtual adapter drops the foreign portion of the 5-tuple entirely (step ) and queries the local connection table or the other the global shared memory virtual adapters for a match (step ). If a match is found (step ), this would indicate a server waiting for a connection request on any connected network from any foreign address or port. If only one match is found (step ), the transmitting global shared memory virtual adapter updates the local connection table (step ) and forwards the globally address packet to the matching node (step ). If multiple matches are found (step ), this would indicate that the server has multiple instances executing within the system partition. In this case, the transmitting global shared memory virtual adapter invokes a load-balancing algorithm (e.g., a round robin load-balancing algorithm) to select a destination node (step ). The transmitting global shared memory virtual adapter updates the local connection table to reflect this selection (step ) and forwards the globally addressed packet to the selected node (step ).","If no match is found for the globally addressed packet, the packet is dropped (step ).","In one embodiment, the network infrastructure service system  is configured as an OSPF (Open Shortest Path First) area. In this embodiment, device nodes that have physical network adapters (referred to herein as \u201cphysically connected nodes\u201d) are configured as OSPF area border routers. OSPF cross area routing algorithms route first to the optimal area border router into or out of the targeted area. In particular, packets destined to remote nodes (referred to herein as \u201coutbound packets\u201d) are routed first to device nodes that have physical network adapters. In one implementation, OSPF cost metrics are set so that the optimal route to the area border router is always over the local shared memory network. OSPF supports duplicate routes to the same area through alternate area border routers. To improve the availability of the global shared memory network, different nodes are installed with physical adapters and defined as area border routers into the system partition of the network infrastructure service system . In addition, alternate routes from remote global clients are established to each area border router. OSPF detects whenever a node fails, a physical network adapter fails, or a physical network interface changes state, and recovers by invoking an alternate route. OSPF also handles updating of the routing tables.","Systems and methods have been described herein in connection with a particular network infrastructure service system environment. These systems and methods, however, are not limited to any particular hardware or software configuration, but rather they may be implemented in any shared memory network infrastructure service computing or processing environment, including a global shared memory environment, a distributed shared memory environment, or a logically shared memory environment. In general, the component systems of the shared memory virtual adapters may be implemented, in part, in a computer process product tangibly embodied in a machine-readable storage device for execution by a computer processor. In some embodiments, these systems preferably are implemented in a high level procedural or object oriented processing language; however, the algorithms may be implemented in assembly or machine language, if desired. In any case, the processing language may be a compiled or interpreted language. The methods described herein may be performed by a computer processor executing instructions organized, for example, into process modules to carry out these methods by operating on input data and generating output. Suitable processors include, for example, both general and special purpose microprocessors. Generally, a processor receives instructions and data from a read-only memory and\/or a random access memory. Storage devices suitable for tangibly embodying computer process instructions include all forms of non-volatile memory, including, for example, semiconductor memory devices, such as EPROM, EEPROM, and flash memory devices; magnetic disks such as internal hard disks and removable disks; magneto-optical disks; and CD-ROM. Any of the foregoing technologies may be supplemented by or incorporated in specially designed ASICs (application-specific integrated circuits).","Other embodiments are within the scope of the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF DRAWINGS","p":[{"@attributes":{"id":"p-0019","num":"0019"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0020","num":"0020"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0021","num":"0021"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0022","num":"0022"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0023","num":"0023"},"figref":["FIG. 5","FIG. 1"]},{"@attributes":{"id":"p-0024","num":"0024"},"figref":["FIG. 6A","FIG. 1"]},{"@attributes":{"id":"p-0025","num":"0025"},"figref":["FIG. 6B","FIG. 1"]},{"@attributes":{"id":"p-0026","num":"0026"},"figref":["FIG. 7","FIG. 1"]},{"@attributes":{"id":"p-0027","num":"0027"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0028","num":"0028"},"figref":"FIG. 8B"},{"@attributes":{"id":"p-0029","num":"0029"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0030","num":"0030"},"figref":["FIGS. 10A and 10B","FIG. 1"]}]},"DETDESC":[{},{}]}
