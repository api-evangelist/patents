---
title: System and method for determining overload state for service requests
abstract: A computer system that provides services to clients may be configured to determine whether it is operating in an overloaded state based on the percentage of client-specified quality of service (QoS) expectations that are not met. For example, if the percentage of service requests in a group of recently serviced requests for which client-specified expectations of a maximum response time were not met is greater than a pre-determined overload threshold, the system may be considered to be in an overloaded state. The overload threshold may be configurable. The overload state may be determined periodically by determining the percentage of service requests in a moving window of time for which client-specified QoS expectations were not met. In response to determining that the system is operating in an overloaded state, it may be configured to throttle at least a portion of incoming service requests in an attempt to exit the overloaded state.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08392558&OS=08392558&RS=08392558
owner: Amazon Technologies, Inc.
number: 08392558
owner_city: Reno
owner_country: US
publication_date: 20110322
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","DETAILED DESCRIPTION OF EMBODIMENTS","Introduction"],"p":["Every system that provides services to clients needs to protect itself from a crushing load of service requests that could potentially overload the system. In general, for a Web service or remote procedure call (RPC) service, a system is considered to be in an \u201coverloaded\u201d state if it is not able to provide the expected quality of service for some portion of client requests it receives. Common solutions applied by overloaded systems include denying service to clients or throttling a certain number of incoming requests until the systems get out of an overloaded state.","For example, a na\u00efve solution may throttle incoming requests if the system is overloaded and may stop throttling once the system gets out of overloaded state. This implementation, however, can lead to an oscillatory behavior in which the system is able to exit an overloaded state by throttling incoming requests, but gets right back into the overloaded state once it removes the throttle.","Many current systems avoid an overload scenario by comparing the request rate and\/or the quality of service perceived by the system itself with a fixed or varying global threshold and selectively refusing service to clients once this threshold has been crossed. However this approach does not take into account differences in the expectations of different clients regarding quality of service. In addition, it is difficult, if not impossible, to define a single global threshold that is meaningful (much less that provides acceptable performance) in a system that receives different types of requests at varying, unpredictable rates.","While the technology described herein is susceptible to various modifications and alternative forms, specific embodiments thereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the disclosure to the particular form disclosed, but on the contrary, the intention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the present disclosure as defined by the appended claims.","The computer systems described herein for providing services to clients may in some embodiments be configured to adaptively throttle incoming service requests in response to changing conditions. The systems may modify one or more throttle parameters in order to aggressively increase throttling in response to detecting that the system is in an overloaded state. For example, a throttle multiplier value may be increased by a large amount in an attempt to quickly exit the overloaded state. The throttle multiplier value may be increased multiple times before the system exits the overloaded state. In some embodiments, the percentage of incoming requests that are throttled and\/or the particular requests that are throttled may be dependent on the throttle multiplier value and\/or on the client-specific priority rank of each request.","In some embodiments, in response to the system returning to a non-overloaded state (e.g., as a result of aggressive throttling), it may gradually reduce throttling by iteratively decreasing the throttle multiplier value until it is zero (or until the system returns to the overloaded state). The amounts by which the throttle multiplier may be increased and\/or decreased in order to aggressively throttle service requests or gradually reduce throttling may be configurable. Gradually reducing throttling may in some embodiments allow the system to damp or avoid oscillations between an overloaded state and a non-overloaded state when modifying the throttle multiplier or other throttle parameters.","In some embodiments, the systems described herein may be configured to adaptively throttle incoming service requests in order to reach and then maintain operation at an ideal request rate. In some embodiments, an ideal request rate may be defined as the maximum rate at which incoming service requests can be accepted and serviced such that client-specified quality of service (QoS) expectations are met for all (or a targeted high percentage of) incoming service requests that are accepted and serviced. In other embodiments, an ideal request rate may be defined as any request rate within a pre-defined range of request rates that includes the maximum rate at which incoming service requests can be accepted and serviced such that client-specified quality of service (QoS) expectations are met for all (or a targeted high percentage of) incoming service requests that are accepted and serviced. For example, an ideal request rate range may in some embodiments be centered about the maximum request rate at which expectations are met for all (or a targeted high percentage) of requests. Note that the width of the range of request rates that are considered acceptable for inclusion in an ideal request rate range may be defined by a default system parameter value or by a client-specified default parameter value, and\/or it may be configurable at initiation or during runtime, in various embodiments. In some embodiments, an ideal request rate range may have as its upper or lower bound the maximum request rate at which expectations are met for all (or a targeted high percentage) of requests. Note that the maximum request rate at which QoS expectations are met for all (or a targeted high percentage) of requests may sometimes be referred to herein as the \u201cabsolute ideal request rate\u201d.","Determining whether the system is operating at an ideal request rate may include determining the minimum difference between the expected QoS and the actual QoS for a group of recently serviced requests. The system may gradually modify a throttle multiplier value (and\/or another throttle parameter) in order to reach or maintain an ideal request rate. Maintaining operation at an ideal request rate may allow the system to avoid entering an overloaded state, and\/or to avoid oscillating between an overloaded state and a non-overloaded state. Note that in some embodiments, maintaining operation at an ideal request rate may include continuously and\/or periodically evaluating the minimum difference between the expected and actual QoS for serviced requests and, as appropriate, adjusting a throttle multiplier or other throttle parameter in an ongoing attempt to reach the absolute ideal request rate, whether it is physically possible to achieve this exact request rate or not. However, such potentially constant adjustment may not be practical, in some embodiments. Therefore, in some embodiments, maintaining operation at an ideal request rate may include adjusting a throttle multiplier or other throttle parameter only as needed to maintain operation within an acceptable ideal request rate range, as described herein.","In some embodiments, the systems described herein may be configured to determine whether they are operating in an overloaded state based on the percentage of client-specified QoS expectations that are not met, rather than on a single global performance threshold. For example, if the percentage of service requests in a group of recently serviced requests for which client-specified expectations of a maximum response time were not met is greater than a pre-determined overload threshold, a system may be considered to be in an overloaded state. The overload threshold may be configurable, in some embodiments.","In some embodiments, the overload state of a system may be determined periodically by determining the percentage of service requests in a moving window of time for which client-specified QoS expectations were not met. As noted above, in response to determining that the system is operating in an overloaded state, it may be configured to throttle at least a portion of incoming service requests in an attempt to exit the overloaded state.","Various techniques described herein may be employed in local or remote systems, including systems that provide services to users (e.g., subscribers) over the Internet or over other public or private networks, such as virtual private networks and connections to services in a virtual private cloud (VPC) environment.  illustrates a block diagram of a system that provides various Web-based services to clients, according to one embodiment. In this example, system  includes one or more clients . In this example, the clients  may be configured to interact with a Web server  via a communication network .","As illustrated in this example, the Web server  may be configured to process requests from clients  for various services, such as Web service A (), Web service B (), and Web service C (), and to return results to the clients . As described in more detail herein, in various embodiments, a component of Web server  may be configured to determine whether computing system, such as computing system  in , is operating in an overloaded state with respect to the number and\/or rate of requests for service that are directed to the system, and\/or to apply one or more of the techniques described herein to respond to such a determination, to move the system out of an overloaded state, to throttle or increase the number of requests that are accepted or serviced, to avoid oscillating between an overloaded state and a non-overloaded state, to prevent a subsequent return to an overloaded state, or to service requests at an ideal request rate. For example, in some embodiments, an admission control subsystem, such as admission control subsystem  in , may be configured to monitor the performance of computing system  with respect to the servicing client requests, and may control which and how many service requests are accepted and\/or serviced by the system in order to maintain an acceptable level of availability and\/or consistency in the system. Computing system  and admission control subsystem  in  are described in more detail below.","In the example illustrated in , the clients  may encompass any type of clients configured to submit service requests to Web server  via network  on behalf of a user or a requesting application. For example, a given client  may include a suitable version of a Web browser, or a plug-in module or other type of code module configured to execute as an extension to or within an execution environment provided by a Web browser. Alternatively, a client  may encompass an application such as a database application, media application, office application, or any other application that may make use of the services provided by Web server . In some embodiments, such an application may include sufficient protocol support (e.g., for a suitable version of Hypertext Transfer Protocol (HTTP)) for generating and processing Web service requests without necessarily implementing full browser support for all types of Web-based data. That is, client  may be an application configured to interact directly with Web server . In various embodiments, client  may be configured to generate requests for Web services according to a Representational State Transfer (REST)-style Web services architecture, a document or message-based Web services architecture, or another suitable Web services architecture. In some embodiments, client  may be configured to provide access to Web-based service to other applications in a manner that is transparent to those applications. For example, a client  may be configured to integrate with an operating system to provide services in accordance with a suitable variant of the service model described herein. However, the operating system may present a different service request interface to applications than that described herein.","In various embodiments, the communication network  may encompass any suitable combination of networking hardware and protocols necessary to establish Web-based communications between clients  and Web server . For example, the communication network  may generally encompass the various telecommunications networks and service providers that collectively implement the Internet. The communication network  may also include private networks such as local area networks (LANs) or wide area networks (WANs) as well as public or private wireless networks. For example, both a given client  and the Web server  may be respectively provisioned within enterprises having their own internal networks. In such an embodiment, the communication network  may include the hardware (e.g., modems, routers, switches, load balancers, proxy servers, etc.) and software (e.g., protocol stacks, accounting software, firewall\/security software, etc.) necessary to establish a networking link between the given client  and the Internet as well as between the Internet and Web server . Note that in some embodiments, clients  may communicate with Web server  using a private network rather than the public Internet. For example, in some embodiments clients  may be provisioned within the same enterprise as the resources that provide various services to those clients. In such a case, clients  may communicate with a server  entirely through a private communication network (not shown).",{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 2","FIG. 1"],"b":["200","200","130","200","200","200","205","210","230"]},"In this example, Web services interface  may be configured to receive requests for services from various clients and to communicate with admission control subsystem  to facilitate the performance of those services on behalf of the clients. For example, in some embodiments, admission control subsystem  may be configured to determine which and\/or how many service requests to accept from various clients, and may communicate with a service request subsystem  to accept and\/or service one or more received service requests. Service request subsystem  may in turn be configured to allocate (or initiate allocation of) one or more resources needed to perform the requested services to those requests, and to return results to the client via Web services interface . In some embodiments, admission control system  may make decisions about admission control based on feedback received from request subsystem . In various embodiments, this feedback may be in-band\/implicit feedback (e.g., in terms of actual response times of serviced requests, or other QoS levels achieved) or may be out-of-band\/explicit feedback. In some embodiments, Web service interface  may utilize predefined instructions or communications, such as via defined application protocol interfaces (APIs), to communicate with admission control subsystem  and\/or other components of computing system  on behalf of a client.","In some embodiments, admission control subsystem  may be configured to determine whether computing system  is operating in overloaded state with respect to the number and\/or rate of requests for service that are directed to the system, and\/or to apply one or more of the techniques described herein to respond to such a determination, to move the system out of an overloaded state, to throttle or increase the number of requests that are accepted or serviced, to avoid oscillating between an overloaded state and a non-overloaded state, to prevent a subsequent return to an overloaded state, or to service requests at an ideal request rate. For example, in some embodiments, admission control subsystem  may be configured to monitor the performance of computing system  with respect to the servicing of client requests, and may control which and how many service requests are accepted and\/or serviced by the system in order to maintain an acceptable level of availability and\/or consistency in the system.","Note that in various embodiments, the components illustrated in  may be implemented directly within computer hardware, as instructions directly or indirectly executable by computer hardware (e.g., a microprocessor or computer system), or as a combination of these techniques. For example, the components of the computing system  may be implemented by a distributed system including any number of computing nodes (or simply, nodes). In various embodiments, the functionality of a given component may be implemented by a particular node or distributed across several nodes. In some embodiments, a given node may implement the functionality of more than one of the component illustrated in  and\/or .","Various techniques that may be implemented by a Web server (or an admission control subsystem or other component thereof) are described in more detail below, according to different embodiments. In general, any or all of the techniques described herein for managing the processing of service requests on behalf of clients may be performed by and\/or implemented in an admission control module that is a component of a Web server. While several examples described herein are directed to systems that provide services over the Internet, in other embodiments, these techniques may be performed by and\/or implemented in an admission control module or a similar component of another type of system that provides services to clients, and that is configured to receive, accept, and\/or service requests on behalf of those clients.","As noted above, a common solution applied by overloaded systems is to deny service to or throttle a certain number of incoming requests until the systems exits the overloaded state. In contrast to this na\u00efve throttling solution, in which a system merely throttles incoming requests if the system is overloaded and stops throttling incoming requests once the system exits the overloaded state, the techniques described herein may allow a system to avoid an oscillatory behavior in which the system is able to exit an overloaded state by throttling incoming requests, but goes right back into the overloaded state once it removes the throttle. The adaptive throttling techniques described herein may instead attempt to damp oscillations by aggressive throttling and slow release. In other words, the systems describe herein may employ adaptive techniques for request throttling that may damp oscillations between an overloaded state and a non-overloaded state. These adaptive throttling techniques may modify one or more throttle parameters to apply aggressive throttling to quickly exit an overloaded state (once it is detected), and then may slowly reduce the amount of throttling in the system to avoid oscillating between overload and non-overloaded states.","For example, in some embodiments, the system may be configured to detect that the system is overloaded with respect to incoming service requests, and, in response, to aggressively throttle incoming requests in an attempt to exit the overloaded state as quickly as possible (e.g., before a crushing load causes a system failure). In such embodiments, once the system is no longer operating in an overloaded state, it may be configured to gradually reduce the amount of throttling to avoid oscillating between overloaded and non-overloaded states. In some embodiments, the system may adjust one or more parameters that control the amount and\/or type of throttling in the system to aggressively throttle requests in response to detecting an overload condition, and then to further modify them in order to incrementally reduce throttling once the system is no longer in an overloaded state. For example, in some embodiments, the system may employ a throttle multiplier that may be aggressively or coarsely incremented, and then gradually or finely tuned in order to damp overload state oscillations.","In some embodiments, when an overloaded state is detected, a throttle multiplier may be incremented, which may cause the system to increase the percentage of incoming service requests that are throttled. For example, the value of the throttle multiplier may be increased by a large amount in response to detecting that the system is operating in an overloaded state in order to more aggressively throttle incoming requests.","In some embodiments, the value of the throttle multiplier may be increased to a value that is likely to increase throttling by an amount that is aggressive enough to cause the system to return to a non-overloaded state. In some embodiments, a throttle multiplier may need to be incremented multiple times if a first attempt to increase throttling enough to exit the overloaded state is unsuccessful.","In some embodiments, once the system returns to a non-overloaded state (e.g., as a result of aggressive throttling), the system may be configured to gradually reduce the amount of throttling until the throttle multiplier value is zero, in which case all subsequent incoming requests may be accepted and serviced, or until the system returns to an overloaded state. In some embodiments, the system may be configured to wait until a pre-determined amount of time has passed following the return of the system to a non-overloaded state before it begins to reduce throttling. In other embodiments, the system may perform a pre-determined number of evaluations of the overload state (e.g., by periodically polling the performance of the system) before it begins to reduce throttling.","One embodiment of a method for damping oscillations between an overloaded state and a non-overloaded state in a system that receives and services client requests is illustrated by the flow diagram in . As illustrated at  in this example, the method may include the system detecting that it is operating in overloaded state. In different embodiments, the system may employ any of various methods and\/or criteria for determining that it is an overloaded state, including comparing a request rate or quality of service measurement with a fixed target, or using one or more of the techniques described herein for determining that the system is operating in overloaded state dependent on client-specified or client-specific expectations of quality of service (QoS). In response to detecting that the system is operating in overloaded state, the method may include the system modifying one or more throttle parameters in an aggressive attempt to exit the overloaded state, as in . This may cause the system to throttle at least a portion of subsequent service requests, as in . In various embodiments, throttling service requests may include rejecting (i.e. failing to accept or acknowledge) service requests directed to the system, or failing to service requests received by the system. In some embodiments, throttling may include sending an indication to one or more clients that the system is in an overloaded state and\/or that they should reduce the number and\/or rate of service requests that they direct to the system. Other types of request throttling may be employed in other embodiments.","In some embodiments, after aggressively throttling service requests in an attempt to exit the overloaded state, the system may be configured to determine whether the system is still in an overloaded state, as in . For example, in some embodiments, the system may be configured to sample the performance of the system with respect to servicing client requests, or to periodically poll the system to determine whether it is still in an overloaded state. The system may then adjust one or more throttling parameters accordingly, as in . For example, the system may be configured to increase or decrease a throttle multiplier, depending on whether or not the system is still in an overloaded state, and to do so in a way that avoids oscillating between overloaded and non-overloaded states. Such adjustments are described in more detail below.","As noted above, in some embodiments, determining the percentage of incoming requests that should be throttled may be dependent on the value of a throttle multiplier. In some such embodiments, the throttle multiplier may be initialized (e.g., at bootstrap) to a value of zero, which may cause the system to service every request that it receives. In the event that an overload is detected, the system may increment the throttle multiplier by a pre-determined value, and begin aggressively throttling a percentage of incoming service requests. For example, in one embodiment, if the value of the throttle multiplier was initialized to zero and then increased by a pre-determined value, T, the system may begin to throttle T % of all incoming requests. The system may poll its state periodically (e.g., evaluating its performance in servicing incoming requests at fixed time intervals) to determine its overloaded state. If the system is still overloaded after the initial increment of the throttle multiplier, the system may be configured to further increase the throttle multiplier value (e.g., again by T) and to begin throttling 2T % of all incoming requests. In some embodiments, the system may be configured to continue increasing the throttle multiplier (e.g., by T) after every poll interval until the system exits the overloaded state.","In some embodiments, the amount of throttling may be dependent on a priority rank associated with each request (e.g., a client-specified or type-specific priority rank), in addition to being dependent on a throttle multiplier. In such embodiments, when the system increases the throttle multiplier from zero to T, it may being throttling (T\u00d7P) % of all incoming requests, where P is the request priority rank, and high priority requests have a low priority rank. In such embodiments, the system may be configured to throttle high priority requests at a lower rate than the rate at which it throttles low priority requests. As in the previous example, the system may poll its state periodically (e.g., evaluating its performance in servicing incoming requests at fixed time intervals) to determine its overloaded state. For example, in some embodiments, only the requests that have been received within the most recent time interval are considered when evaluating the performance of the system in servicing incoming requests. In other embodiments, such an evaluation may be performed at fixed time intervals, but each evaluation instance may consider requests that were received within multiple time intervals (e.g., to evaluate and\/or detect changes in the cumulative performance of the system over multiple time intervals). If the system is still overloaded after the initial increment of the throttle multiplier, the system may be configured to further increase the throttle multiplier value (e.g., again by T) and to begin throttling (2T\u00d7P) % of all incoming requests. Again, the system may be configured to continue increasing the throttle multiplier (e.g., by T) after every poll interval until the system exits the overloaded state.","Once the system has been in a non-overloaded state for a pre-determined number of consecutive poll intervals, the system may begin releasing the throttle. For example, the system may reduce the throttle multiplier by a different pre-determined amount than the amount by which the throttle multiplier was incrementally increased in order to exit the overloaded state (e.g., a value R, where R<<T) in every consecutive non-overloaded interval. In this way, the system may avoid going back to the overloaded state, while accepting that this may come at the expense of reduced system throughput. As noted above, the system may continue to reduce the throttle rate until the throttle multiplier value is zero, or until the system returns to the overloaded state, in which case the throttle multiplier may again be increased by T.","Note that in some embodiments, the throttle multiplier may be initialized to a value other than zero (e.g., to a default or client-specified value that is deemed likely to result in acceptable performance based on historical workloads and\/or performance measurements). In such embodiments, if the system enters an overloaded state, it may employ the adaptive throttling techniques described herein (e.g., aggressively increasing the value of the throttle multiplier until the system exits the overloaded state, and then gradually reducing it) in order to avoid oscillating between an overloaded state and a non-overloaded state. In some such embodiments, the throttle multiplier may be reduced until it reaches its initial value, rather than a value of zero.","One embodiment of a method for adjusting a throttle parameter to avoid oscillating between overloaded and non-overloaded states is illustrated by the flow diagram in . As illustrated in this example, the method may include a computing system that provides various services to clients (i.e. that receives and services client requests) detecting that it is operating in an overloaded state, as in . In different embodiments, the system may employ any of various methods and\/or criteria for determining that it is an overloaded state, including comparing a request rate or quality of service measurement with a fixed target, or using one or more of the techniques described herein for determining that the system is in an overloaded state dependent on client-specified or client-specific expectations of QoS.","As illustrated in this example, the method may include, in response to detecting that the system is in an overloaded state, the system increasing a throttle multiplier (e.g., from a default, initial, or zero value) by a pre-determined (and possibly large) amount, as in . For example, the throttle multiplier may be increased by an amount that, based on current and\/or historical loads and system performance, may be likely to cause the system to exit the overloaded state. Increasing the throttle multiplier may cause the system to throttle at least a portion of subsequent service requests, as in . In various embodiments, throttling service requests may include rejecting (i.e. deliberately failing to accept or acknowledge) service requests directed to the system, or deliberately failing to service requests received by the system. In some embodiments, throttling may include sending an indication to one or more clients that the system is in an overloaded state and\/or that they should reduce the number and\/or rate of service requests that they direct to the system. Other types of throttling may be employed in other embodiments. Note that in various embodiments, victim selection (i.e. the determination of which requests are rejected and which requests are accepted and\/or serviced) may be dependent on a request priority rank and\/or on an expected QoS value (either of which may be specified in the requests themselves), as described herein, or may be dependent on other criteria.","As illustrated at , in this example, the method may include the system monitoring service requests and response thereto to determine whether the system is still in an overloaded state following the increase in the throttle multiplier. For example, the system may perform periodic sampling, polling, or other types of monitoring operations to determine the value of various performance measures related to the servicing of client request, such as how often an expected QoS value is (or is not) being met. For example, in some embodiments, only the requests that have been received within a most recent time window are considered when evaluating the performance of the system in meeting QoS expectations. In other embodiments, such an evaluation may be performed at fixed time intervals, but each evaluation instance may consider requests that were received within multiple time windows (e.g., to evaluate and\/or detect changes in the cumulative performance of the system over multiple time windows). If the system is determined to be in an overloaded state, shown as the positive exit from , the method may include the system increasing the throttle multiplier, as in . For example the throttle multiplier may be increased by the same amount as the initial amount by which it was increased in an aggressive attempt to exit the overloaded state, or some another, less aggressive, incremental amount, in different embodiments. If it is determined that the system is not in an overloaded state, shown as the negative exit from , the method may include the system decreasing the throttle multiplier, as in . For example, the throttle multiplier may be decreased by an incremental amount (e.g. by an amount that is less than the current throttle multiplier value or the amount by which is was previously increased).","As previously noted, by aggressively throttling requests when a system is operating in an overloaded state, and then slowly or incrementally reducing throttling once the system is no longer in an overloaded state, the system may avoid oscillating between overloaded and non-overloaded states, effectively damping the response of the system to changes in the load and corresponding changes in the amount of throttling applied to service requests. One embodiment of a method for adjusting a throttle multiplier to implement such a damping technique is illustrated by the flow diagram in . As illustrated in this example, the method may include a computing system that provides various services to clients (i.e. that receives and services client requests) initializing a throttle multiplier to zero, as in . In this example, setting the throttle multiplier to zero may result in all service requests being accepted and serviced until or unless the throttle multiplier is subsequently changed or the system fails.","In this example, in response to the system detecting an overloaded state, as in , the method may include the system increasing the throttle multiplier by a pre-determined amount (e.g., a large amount selected in an attempt to aggressively throttle service requests and exit the overloaded state), as in . For example, in different embodiments, the system may employ any of various methods and\/or criteria for determining that it is an overloaded state, including comparing a request rate or quality of service measurement with a fixed target, or using one or more of the techniques described herein for determining that the system is in an overloaded state dependent on client-specified or client-specific expectations of QoS.","As illustrated in this example, the method may include the system monitoring service requests and response thereto to determine whether the system is still in an overloaded state following the increase in the throttle multiplier, as in . For example, the system may perform periodic sampling, polling, or other types of monitoring operations to determine the value of various performance measures related to the servicing of client request, such as how often an expected QoS value is (or is not) being met. For example, in some embodiments, only the requests that have been received within a most recent time window are considered when evaluating the performance of the system in meeting QoS expectations. In other embodiments, such an evaluation may be performed at fixed time intervals, but each evaluation instance may consider requests that were received within multiple time windows (e.g., to evaluate and\/or detect changes in the cumulative performance of the system over multiple time windows). If the system is determined to be in an overloaded state, shown as the positive exit from , the method may include the system increasing the throttle multiplier, as in . For example the throttle multiplier may be increased by the same amount as the initial amount by which it was increased in an aggressive attempt to exit the overloaded state, or some another, less aggressive, incremental amount, in different embodiments. After increasing the throttle multiplier, the method may include continuing to monitor service requests and response thereto to determine whether the system is still in an overloaded state following the additional increase in the throttle multiplier. This is illustrated in  as the feedback from  to . If the system is still in an overloaded state following the additional increase in the throttle multiplier, the operations illustrated in  as  to  may be repeated, as applicable.","If it is determined that the system is not in an overloaded state, shown as the negative exit from , and if the system has been in a non-overloaded state for a given time period, shown as the positive exit from , the method may include the system decreasing the throttle multiplier, as in . For example, the throttle multiplier may be decreased by an incremental amount (e.g. by an amount that is less than the current throttle multiplier value or the amount by which it was previously increased). Otherwise, shown as the negative exit from  and the negative exit from , the method may include the system decreasing the throttle multiplier, as in . In other words, in some embodiments, after increasing the throttle multiplier to aggressively throttle service requests and then determining that the system is no longer in an overloaded state, the system may not begin to back off of its aggressive throttling until the system has been in non-overloaded state for a given time period (e.g., for a given number of samples, or time periods over which overloaded state is determined, according to various embodiments).","As illustrated in , if the value of the throttle multiplier is not zero following the decrease, shown as the negative exit from , the operations illustrated as - may be repeated until the throttle multiplier is zero (shown as the positive exit from ) or until the system returns to an overloaded state (shown as the positive exit from ). However, by slowly and\/or incrementally reducing the amount of throttling in the system, such state oscillations may be avoided or their frequency reduced. Note that if the throttle multiplier is reduced to zero, shown as the positive exit from , the system may accept and service all incoming client requests until and unless the system detects that the system has returned to an overloaded state, at which point the operations illustrated as  to  may be repeated, as applicable. This is illustrated in  by the dashed feedback line from  to .","As noted above, a common solution applied by overloaded systems is to deny service to or throttle a certain number of incoming requests until the systems exits the overloaded state. In some embodiments, the systems described herein may make use of the concept of an \u201cideal request rate\u201d to ensure that the system does not go into an overloaded state (or at least avoids going into an overloaded state) while still achieving close to optimum throughput. In such embodiments, the system may attempt to avoid entering an overloaded state in the first place by only accepting requests that it can satisfy (which may come at the cost of reduced throughput). As used herein the term \u201cideal request rate\u201d may refer to the maximum rate at which incoming service requests can be accepted and serviced such that client-specified quality of service expectations are met for all (or a targeted large percentage) of incoming service requests that are accepted and serviced (i.e. the absolute ideal request rate), or any request rate within a pre-determined range of request rates that includes such an absolute ideal request rate, in different embodiments. In some embodiments, an ideal request rate range may have as its upper or lower bound the maximum rate at which incoming service requests can be accepted and serviced such that client-specified quality of service expectations are met for all (or a targeted large percentage) of incoming service requests. In general, an ideal request rate may be thought of as a rate of incoming requests to a service at which every request (or a targeted large percentage thereof) is satisfied with its expected quality of service, and the difference between the expected and actual quality of service is close to zero. For example, in some embodiments this difference may be maintained as close as is possible (or practical) to a pre-determined threshold near zero without being significantly above or below that threshold.","In some embodiments, once a system enters an overloaded state, it may aggressively begin throttling incoming requests until it exits the overloaded state. Once the system is out of the overloaded state, it may start easing back on the throttle, making sure that it continues to satisfy every request it accepts with the expected quality of service. Specifically, the system may keep track of the minimum difference between the expected and actual quality of service (e.g., for requests received within a moving window in time) and may keep reducing the throttle until the minimum difference becomes equal to a pre-determined ideal request rate threshold (e.g., a default or client-specified threshold value that is close to zero). When the system is operating at an ideal request rate, it may achieve (or be operating close to) the maximum throughput possible while barely meeting QoS expectations for all (or a targeted high percentage) of incoming requests. Once the system reaches an ideal request rate, it may try to maintain operation at an ideal request rate according to the ideal request rate threshold, e.g., by increasing throttling if the minimum difference between the expected and actual quality of service decreases or becomes negative, and decreasing throttling if the minimum difference between the expected and actual quality of service increases.","One embodiment of a method for using an ideal request rate to avoid oscillating between an overloaded state and a non-overloaded state in a system that receives and services client requests is illustrated by the flow diagram in . As illustrated at  in this example, the method may include the system detecting that it is operating in an overloaded state. In different embodiments, the system may employ any of various methods and\/or criteria for determining that it is an overloaded state, including comparing a request rate or quality of service measurement with a fixed target, or using one or more of the techniques described herein for determining that the system is in an overloaded state dependent on client-specified or client-specific expectations of QoS. In response to detecting that the system is in an overloaded state, the method may include the system modifying one or more throttle parameters in an aggressive attempt to exit the overloaded state, as in . For example, the system may increase the value of a throttle multiplier, which may cause the system to throttle at least a portion of subsequent service requests, as in . In various embodiments, throttling service requests may include rejecting (i.e. failing to accept or acknowledge) service requests directed to the system, or failing to service requests received by the system. In some embodiments, throttling may include sending an indication to one or more clients that the system is in an overloaded state and\/or that they should reduce the number and\/or rate of service requests that they direct to the system. Other types of request throttling may be employed in other embodiments.","In some embodiments, after aggressively throttling service requests in an attempt to exit the overloaded state, the system may be configured to determine whether the system is still in an overloaded state. For example, in some embodiments, the system may be configured to sample the performance of the system with respect to servicing client requests, or to periodically poll the system to determine if it is still in an overloaded state. For example, in some embodiments, only the requests that have been received within a most recent time window are considered when evaluating the overload state of the system. In response to determining that the system is in a non-overloaded state, as in , the method may include the system adjusting one or more throttle parameters until an ideal request rate is reached as in . For example, the system may be configured to decrease a throttle multiplier, and to do so in a way that avoids oscillating between overloaded and non-overloaded states (as described in more detail below). Again, in some embodiments, only the requests that have been received within a most recent time window are considered when evaluating the performance of the system, while in other embodiments, such an evaluation may be performed at fixed time intervals, but each evaluation instance may consider requests that were received within multiple time windows.","One embodiment of a method for reaching and maintaining an ideal request rate for servicing client requests is illustrated by the flow diagram in . As illustrated in this example, the method may include a computing system that provides various services to clients (i.e. that receives and services client requests) initializing a throttle multiplier to zero, as in . In this example, setting the throttle multiplier to zero may result in all incoming service requests being accepted and serviced (i.e. none of the incoming requests being throttled) until or unless the throttle multiplier is subsequently changed or the system fails.","In this example, the system may be configured to monitor the performance of request servicing (e.g., to determine the performance of the system in servicing all, or a sample of, the client requests received, accepted, and\/or serviced in a moving time window using any suitable performance criteria, including those described herein), as in . In other embodiments, such an evaluation may be performed at fixed time intervals, but each evaluation instance may consider requests that were received within multiple time windows. Note that the length of the window may be a default length for the system and\/or it may be configurable at initialization and\/or during operation. If the system is determined to be in an overloaded state, shown as the positive exit from , the method may include the system increasing the throttle multiplier by a pre-determined amount (e.g., a large amount selected in an attempt to aggressively throttle service requests and exit the overloaded state), as in . For example, in different embodiments, the system may employ any of various methods and\/or criteria for determining that it is an overloaded state, including comparing a request rate or quality of service measurement with a fixed target, or using one or more of the techniques described herein for determining that the system is operating in an overloaded state dependent on client-specified or client-specific expectations of QoS.","As illustrated in this example, if the system is determined to be in a non-overloaded state, shown as the negative exit from , and the system is operating at a rate that is above the ideal request rate (meaning, for example, that the system is accepting and servicing client requests at a rate that is higher than an absolute ideal request rate or the request rates defined in an ideal request rate range, but not at a request rate high enough to cause the system to enter an overloaded state), as shown by the positive exit from , the method may include the system increasing the throttle multiplier in an attempt to incrementally increase throttling and, thus, to reduce the rate at which requests are accepted and\/or serviced, as in . For example, the throttle multiplier may be increased by a less aggressive, incremental amount than the initial amount by which it was increased in an aggressive attempt to exit the overloaded state, in some embodiments. One embodiment of a method for determining whether the system is operating at an ideal request rate is illustrated in  and described in detail below. After increasing the throttle multiplier (as in  or ), the method may include continuing to monitor service requests and response thereto as long as the system continues to operate. This is illustrated in  as the feedback from  to , and the feedback from  to . While the system continues to operate, any or all of the operations illustrated in  as  to  may be repeated, as applicable.","If the system is determined to be in a non-overloaded state, shown as the negative exit from , and the system is operating and the system is operating at a rate that is below the ideal request rate (meaning, for example, that the system is accepting and servicing client requests at a rate that is lower than an absolute ideal request rate or the request rates defined in an ideal request rate range), shown as the positive exit from , the method may include decreasing the throttle multiplier in an attempt to incrementally decrease throttling and, thus, to increase the rate at which requests are accepted and\/or serviced, as in . For example, the throttle multiplier may be decreased by an incremental amount (e.g. by an amount that is less than the current throttle multiplier value) in an attempt to reach an ideal request rate. Otherwise, shown as the negative exits from , , and , the system may be operating at an ideal request rate. In this case, the system may not adjust the throttle multiplier at this point (i.e. based on the most recently collected or calculated performance data), but may continue monitoring system performance and adjusting the throttle multiplier in an attempt to maintain the ideal request rate. This is shown in  as the feedback from the negative exit of  to .","Note that, as in previous examples, in some embodiments, after increasing the throttle multiplier to aggressively throttle service requests and then determining that the system is no longer in an overloaded state, the system may not begin to back off of its aggressive throttling until the system has been in non-overloaded state for a given time period (e.g., for a given number of samples, or time periods over which the overloaded state is determined, according to various embodiments).","As illustrated in , the system may adjust the throttle multiplier in an attempt to reach and then maintain an ideal request rate by repeating any or all of the operations illustrated as - (as applicable) while the system is operating. For example, any or all of these operations may be repeated one or more times for groups of requests serviced in one or more subsequent time windows as long as the system is operating correctly. Again, in some embodiments, only the requests that have been received within a single time window are considered when evaluating the performance of the system, while in other embodiments, such an evaluation may be performed at fixed time intervals, but each evaluation instance may consider requests that were received within multiple time windows. Note that by slowly and\/or incrementally increasing or reducing the amount of throttling in the system in an attempt to reach and maintain an ideal request rate, overloaded state oscillations may be avoided or their frequency reduced.","Note that in some embodiments, the throttle multiplier may be initialized to a value other than zero (e.g., to a default or client-specified value that is deemed likely to result in acceptable performance based on historical workloads and\/or performance measurements). In such embodiments, if the system enters an overloaded state, it may employ the adaptive throttling techniques described herein (e.g., aggressively increasing the value of the throttle multiplier until the system exits the overloaded state, and then gradually reducing it) until the system reaches an ideal request rate.","One embodiment of a method for reaching and maintaining an ideal request rate for service requests using a client-specified or client-specific expectation of QoS is illustrated by the flow diagram in . As illustrated at  in this example, the method may include a computing system that provides various services to clients (i.e. that receives and services client requests) beginning to track whether (and\/or how often) client-specified (or client-specific) QoS expectations are (or are not) being met. In various embodiments, these QoS expectations may be request-specific (e.g., an indication of a QoS expectation may be included in each service request), client- or client-specific, and\/or specific to particular types of service requests. In some embodiments, an indication of a QoS expectation included in a service request may override a system-wide default QoS expectation or a default QoS expectation for a customer, client, and\/or service request type. In this example, the QoS expectations tracked and evaluated for compliance by the system may include the maximum expected response time for service requests (e.g., the maximum time that a client is willing to wait for a response to a submitted service request). In other embodiments, other QoS expectations may be tracked and evaluated instead of, or in addition to, expected response time.","As illustrated in , the method may include the system receiving (e.g., from a client) one or more service requests, as in . In this example, each request may include an indication of the expected response time. In some embodiments, each request may also include an indication of a priority rank. In other embodiments, various QoS expectations that are customer- or client-specific, and\/or specific to particular types of service requests may be stored in the system and accessed when requests are received in order to evaluate whether they are being met. As illustrated at  in , the method may include calculating the difference between the expected and actual response times for each request. The system may also calculate the minimum difference between the expected and actual response times for a group of recent requests, as in . For example, the system may be configured to calculate the minimum difference between the expected and actual response times for a group of requests that were recently received and\/or serviced within a moving window of a time having a pre-determined length. Note that, as in other examples, the length of the window may be a default length for the system and\/or it may be configurable at initialization and\/or during operation. Within each such time period, all received requests may be considered, or a sampling of requests may be considered, in different embodiments. Note also that in other embodiments, such a calculation may be performed at fixed time intervals, but each evaluation instance may consider requests that were received within multiple time intervals.","In this example, if the calculated minimum difference between the expected and actual response times for the group of requests is within an acceptable range above a pre-determined ideal request rate threshold, shown as the positive exit from , the system may be operating at an ideal request rate. In other words, the positive exit from  may indicate a situation in which the rate at which requests are being accepted and serviced is slightly lower than the request rate defined by the ideal request rate threshold, but is within an acceptable ideal request rate range. In this example, the ideal request rate range may be defined as a range of request rates whose upper bound is the maximum rate at which incoming service requests can be accepted and serviced such that client-specified quality of service expectations are met for all (or a targeted percentage) of incoming service requests, as defined by the threshold for the calculated minimum difference between expected and actual response times. In some embodiments, defining an ideal request rate range as having such an upper bound may provide an acceptable and\/or relatively conservative buffer between the ideal request rate range and higher request rates that could potentially cause the system to become overloaded. In other embodiments, e.g., in a less conservative implementation, the ideal request rate range may be defined as a pre-determined and\/or relatively narrow range of request rates that is centered about the maximum rate at which incoming service requests can be accepted and serviced such that client-specified quality of service expectations are met for all (or a targeted percentage) of incoming service requests, or pre-determined and\/or relatively narrow range of request rates whose lower bound is such an absolute ideal request rate. As illustrated in , if the system is operating at an ideal request rate, no adjustments to the throttle parameters may be made (at this point). In this example, if the calculated minimum difference between the expected and actual response times for the group of requests is significantly above a pre-determined threshold, shown as the positive exit from , the system may be operating at a request rate that is lower than an absolute ideal request rate or the request rates defined in an ideal request rate range, and may be able to service requests at a higher rate, while still meeting QoS expectations for a targeted percentage of income requests (e.g., for all requests or for a pre-determined high percentage of requests). In this case, the method may include the system adjusting one or more throttle parameters to reduce throttling, as in . For example, the system may decrease a throttle multiplier by an incremental amount (e.g. by an amount that is less than the current throttle multiplier value), which may result in a higher percentage of requests being accepted and\/or serviced.","If the calculated minimum difference between the expected and actual response times for the group of requests is not above a pre-determined threshold, shown as the negative exit from , it must be below the pre-determined threshold, i.e. the system must be operating at a request rate that is higher than an absolute ideal request rate or the request rates defined in an ideal request rate range. In this case, the method may include the system adjusting one or more throttle parameters to increase throttling, as in . For example, the system may increase a throttle multiplier by an incremental amount (e.g. by an amount that is less than the current throttle multiplier value), which may result in a smaller percentage of requests being accepted and\/or serviced. Note that, as in other examples, the threshold value may be a default value for the system and\/or it may be configurable at initialization and\/or during operation. Note also that in this and other embodiments, the incremental amount by which a throttle multiplier is increased (e.g., in  or ) and the incremental amount by which the throttle multiplier is decreased (e.g., in  or ) may have the same value or may have different values. In some embodiments, theses values may be default values for the system and\/or may be configurable at initialization and\/or during operation.","After adjusting one or more throttle parameters, or if no adjustments are necessary because the system is operating at an ideal request rate, the method may include continuing to monitor service requests and response thereto, and to adjust one or more throttle parameters (when necessary) to attempt to reach and\/or maintain an ideal request rate, as long as the system continues to operate. This is illustrated in  by the feedback paths from the positive exit of  to , from  to , and from  to . While the system continues to operate, any or all of the operations illustrated in  as  to  may be repeated, as applicable. For example, any or all of these operations may be repeated one or more times for groups of requests serviced in one or more subsequent time windows as long as the system is operating correctly.","In general, techniques that leverage the concept of an ideal request rate may be employed in a wide variety of systems that receive, accept, and\/or service requests on behalf of clients to achieve the maximum throughput possible while still meeting QoS expectations for all (or a targeted high percentage) of incoming requests. Note that while several of the examples herein describe iteratively adjusting throttling to reach (and then maintain) an ideal request rate following an exit from an overloaded state, in other embodiments, these techniques may be employed in an attempt to avoid overload conditions entirely by only accepting the requests that can be serviced successfully.","As described herein, systems that provide services to clients (e.g., systems that receive, accept, and\/or service requests on behalf of clients) may employ a variety of approaches to determine whether they are operating in an overloaded state. As previously noted, typical systems avoid an overload scenario by comparing the request rate and\/or the quality of service perceived by the system itself with a fixed or varying global threshold and selectively refusing service to clients once this threshold has been crossed.","By contrast, the systems described herein may in some embodiments use the client's perception of the performance of the system to determine whether the system is overloaded. For example, in some embodiments, clients may explicitly specify an expectation of quality of service (e.g., a maximum response time) with every request they send to the system. In other embodiments, various QoS expectations that are customer- or client-specific, and\/or specific to particular types of service requests may be stored in the system and accessed when requests are received in order to evaluate whether they are being met. In some embodiments, beginning at initialization (e.g., at bootstrap), the system may be configured to satisfy every request it receives, while keeping track of the number of requests (in a fixed time interval) that it was not able to satisfy with the expected quality of service. As long as the system is able to satisfy all (or a high percentage) of requests with their respective client-specified expected quality of service, it may continue to service every request it receives, irrespective of its performance characteristics. However, if the system fails to satisfy a pre-determined percentage of client requests with their respective client-specified expected quality of service (e.g., from among requests received within a fixed time interval), the system may be considered to be in an overload mode.","In some embodiments, when a system is operating in an overload mode, the system may begin dropping or throttling client requests at a rate proportional to their priority rank and\/or a throttle multiplier, as described above. As previously noted, in some embodiments, high priority requests may have a low priority rank. Therefore, the system may throttle high priority requests at a rate that is lower that a rate at which low priority requests are throttled. The system may continue to keep track of the quality of service achieved when servicing the requests it chooses to accept, and may compare it with client-specified QoS expectations associated with those requests. In various embodiments, and based on the severity of the overload scenario, the system may adjust its throttle multiplier in an attempt to exit an overloaded state, e.g., using any of the techniques described herein.","One embodiment of a method for determining whether a computing system that provides various services to clients (i.e. that receives and services client requests) is operating in an overloaded state is illustrated by the flow diagram in . As illustrated in this example, the method may include the system receiving a service request from a client that includes an indication of expected QoS. In various embodiments, the QoS expectation may be request-specific (e.g., a QoS expectation may be explicitly included in each service request), customer- or client-specific, and\/or specific to particular types of service requests. In some embodiments, an indicator that is usable to determine a QoS expectation for the service request may be included in the request. For example, in some embodiments, various QoS expectations that are customer- or client-specific, and\/or specific to particular types of service requests may be stored in the system and accessed when requests are received in order to evaluate whether they are being met. In some such embodiments, a customer may be able to specify the values of one or more of the configurable parameters described herein (e.g., a time window length, an ideal request rate threshold, an overload indicator, or various throttle parameters) as default values to be applied when servicing requests submitted on their behalf (e.g., when they register as a subscriber to the service). In some embodiments, the stored information may include two or more values for a given configurable parameter (e.g., for use with different request types, requests having different priority ranks, etc.). In embodiments in which such parameter values are store, each service request may include an indication of the customer, client, and\/or type service request, which may be used to determine the stored QoS expectations that are applicable to the request. In some embodiments, a QoS expectation (or indication thereof) that is included in a service request may override a system-wide default QoS expectation or a default QoS expectation for a customer, client, and\/or service request type. In some embodiments, each request may include an indication of a priority rank.","As illustrated in , the method may include the system determining the actual QoS achieved in servicing the request, as in , and comparing the actual QoS to the expected QoS. In some embodiments, the system may calculate the percentage of recent requests for which the expected QoS was not met, as in . For example, the system may be configured to calculate the percentage of requests for which QoS expectations were not met for a group of requests received within a moving window of a time having a pre-determined length. Note that, as in other examples, the length of the window may be a default length for the system and\/or it may be configurable at initialization and\/or during operation. Within such a time period, all received requests may be considered, or a sampling of requests may be considered, in different embodiments. As described above, the method may include the system determining whether it is in an overloaded state dependent on the calculated percentage of requests for which QoS expectations were not met for this group of requests. For example, if the calculated percentage of requests for which QoS expectations were not met is higher than a pre-determined overload indicator value, the system may be considered to be in an overloaded state. Note that in various embodiments, this overload indicator value may be request-specific, customer- or client-specific, and\/or specific to particular types of service requests. In some embodiments, it may be a default value for the system and\/or it may be configurable at initialization and\/or during operation.","In some embodiments, in response to determining that the system is in an overloaded state, as in , the system may reject (i.e. may deliberately fail to accept or acknowledge) at least a portion of the service requests that are subsequently directed to the system, or may deliberately fail to service at least a portion of the service requests that are received by the system, as in . For example, in some embodiments, in response to determining that the system is in an overloaded state, the system may throttle at least a portion of at least a portion of the service requests that are subsequently directed to the system using any suitable technique for throttling requests, including, but not limited to, those described herein. In some embodiments, throttling may include sending an indication to one or more clients that the system is in an overloaded state and\/or that they should reduce the number and\/or rate of service requests that they direct to the system. The percentage of requests that are throttled, accepted, and\/or serviced may in some embodiments be dependent on the calculated percentage of requests for which QoS expectations were not met during a recent time period. As previously noted, in some embodiments, the system may drop or throttle client requests at a rate that is proportional to their priority rank and a throttle multiplier.","In some embodiments, the systems described herein may request characteristics (e.g., expected QOS and priority rank) provided by clients (as defaults or with each service request) to determine the overload state of the system (e.g., to determine whether the system is in an overloaded state or a non-overloaded state), and to help in victim selection during an overloaded state. Therefore, unlike in typical systems in which \u201csystem overload\u201d status is based on global performance thresholds, in such embodiments the overload state of the system may be determined based on the performance of the system as perceived by its clients.","One embodiment of a method for determining whether a computing system that provides various services to clients (i.e. that receives and services client requests) is operating in an overloaded state based on an expected response time is illustrated by the flow diagram in . As illustrated at  in this example, the method may include the system beginning to track whether expected response times are (or are not) being met for service requests. The method may include the system receiving a service request from a client that includes an indication of an expected response time (e.g., the maximum time that a client is willing to wait for a response), as in . In various embodiments, the expected response time may be request-specific (e.g., an expected response time may be explicitly included in each service request), customer- or client-specific, and\/or specific to particular types of service requests. In some embodiments, an indicator that is usable to determine an expected response time for the service request may be included in the request. For example, in some embodiments, various QoS expectations that are customer- or client-specific, and\/or specific to particular types of service requests (including expected response times) may be stored in the system and accessed when requests are received in order to evaluate whether they are being met. In such embodiments, the request may include an indication of the customer, client, and\/or type service request, which may be used to determine the stored expected response time that is applicable to the request. In some embodiments, an expected response time (or indication thereof) that is included in a service request may override a system-wide default for the expected response time or a default response time expectation for a customer, client, and\/or service request type. In some embodiments, each request may include an indication of a priority rank in addition to an expected response time.","As illustrated in , the method may include the system determining whether the expected response time was met, as in . In some embodiments, the system may calculate the percentage of recent requests for which the expected response time was not met, as in . For example, the system may be configured to calculate the percentage of requests for which expected response times were not met for a group of requests received within a moving window of a time having a pre-determined length. Note that, as in other examples, the length of the window may be a default length for the system and\/or it may be configurable at initialization and\/or during operation. Within such a time period, all received requests may be considered, or a sampling of requests may be considered, in different embodiments.","As described above, the method may include the system determining whether it is in an overloaded state dependent on the calculated percentage of requests for which expected response times were not met for this group of requests. For example, if the calculated percentage of requests for which expected response times were not met is higher than a pre-determined overload threshold, i.e. an overload indicator value, the system may be considered to be in an overloaded state. This is illustrated in  as the positive exit from  and element . On the other hand, if the calculated percentage of requests for which expected response times were not met is not higher than the pre-determined overload threshold (or overload indicator value), shown as the negative exit from , the system may be considered to be in a non-overloaded state, as in . Note that in various embodiments, the overload indicator value may be request-specific, customer- or client-specific, and\/or specific to particular types of service requests. In some embodiments, it may be a default value for the system and\/or it may be configurable at initialization and\/or during operation. As illustrated by the feedback paths from  to  and from  to  in , the system may be configured to continue to track whether expected response times are (or are not) being met, and to determine whether (and when) the system is in an overloaded state, as long as the system continues to operate.","In some embodiments, the system may be configured to drop and\/or throttle at least a portion of the service requests that are subsequently directed to the system while the system is in an overloaded state (e.g., in an attempt to exit the overloaded state), and to accept and service all service requests while in a non-overloaded state. In other embodiments, the system may be configured to adaptively throttle service requests in order to exit an overloaded state, to avoid oscillating between overloaded and non-overloaded states, and\/or to reach or maintain an ideal request rate, as described herein.","One embodiment of a method for determining whether a computing system that provides various services to clients (i.e. that receives and services client requests) is operating in an overloaded state and attempting to exit the overloaded state is illustrated by the flow diagram in . As illustrated at  in this example, the method may include the system beginning to track the percentage of service requests for which one or more client-specified or client-specific QoS expectations are not being met. The method may include the system determining that it is an overloaded state, and beginning to drop and\/or throttle at least a portion of incoming client requests, as in . In some embodiments, in response to determining that the system is in an overloaded state, the system may be configured to adaptively throttle service requests in an attempt to exit an overloaded state, to avoid oscillating between overloaded and non-overloaded states, and\/or to reach or maintain an ideal request rate, as described herein. In some embodiments, the number or percentage of requests that are dropped or throttled may be dependent on the percentage of requests for which client-specified or client-specific QoS expectations are (or are not) being met and\/or on a throttle multiplier, as described herein. The victims of this exercise (i.e. the specific requests that are dropped or throttled) may in some embodiments be selected dependent on a priority rank. For example, the system may drop or throttle high priority requests at a lower rate than the rate at which low priority requests are dropped or throttled.","As illustrated in this example, the method may include the system accepting and servicing one or more service request (e.g., from one or more clients), as in . As in previous examples, these requests may include one or more QoS expectations, and\/or the system may determine applicable QoS expectations dependent on information included in the requests, as described herein. Although not all requests directed to the system while in an overloaded state are accepted and\/or serviced, the system may continue to calculate the percentage of recently serviced requests for which QoS expectations are (or are not) met, as in . For example, the system may be configured to calculate the percentage of requests for which QoS expectations were not met for a group of requests received within a moving window of a time having a pre-determined length. Note that, as in other examples, the length of the window may be a default length for the system and\/or it may be configurable at initialization and\/or during operation. Within such a time period, all received requests may be considered, or a sampling of requests may be considered, in different embodiments.","As described above, the method may include the system determining whether it is in an overloaded state dependent on the calculated percentage of requests for which QoS expectations were not met for this group of requests. For example, if the calculated percentage of requests for which QoS expectations were not met is higher than a pre-determined overload threshold, i.e. an overload indicator value, the system may be considered to be in an overloaded state. Note that in various embodiments, the overload indicator value may be request-specific, customer- or client-specific, and\/or specific to particular types of service requests. In some embodiments, it may be a default value for the system and\/or it may be configurable at initialization and\/or during operation. In some embodiments, if the calculated percentage of recently serviced requests for which QoS expectations were not met indicates that the system is in an overloaded state, shown as the positive exit from , the method may include the system adjusting one or more throttle parameters and\/or performing a victim selection for dropping or throttling incoming requests in an attempt to exit the overloaded state, as in .","As illustrated in this example, in some embodiments, the operations illustrated as - in  may be repeated one or more times (e.g., for requests serviced in one or more subsequent time windows) until the calculated percentage of recently serviced requests for which QoS expectations were not met no longer indicates that the system is in an overloaded state. This is shown in  as the feedback path from  to . Once the calculated percentage does not indicate that the system is in an overloaded state, shown as the negative exit from , the system may be considered to be no longer in an overloaded state. In this case, the method may include the system exiting the overloaded state, as in . In various embodiments, exiting the overloaded state may include reducing or eliminating the dropping or throttling of incoming service requests. For example, in some embodiments, in response to exiting the overloaded state, the system may be configured to accept and service all incoming service requests until or unless another overload condition is detected. In other embodiments, in response to exiting the overloaded state, the system may be configured to adaptively throttle service requests in order to exit an overloaded state, to avoid oscillating between overloaded and non-overloaded states, and\/or to reach or maintain an ideal request rate, as described herein.","Note that each of the techniques described herein may be employed independently and\/or in various combinations, in different embodiments. For example, systems that provide services to clients and that receive, accept, and\/or service requests on behalf of those clients may implement any or all of the techniques described herein for determining the overload state of a system, dropping or throttling requests, damping oscillations between an overloaded state and a non-overloaded state, and\/or reaching and maintaining an ideal request rate, in any combinations.","The techniques described herein for determining the overload state of a system (e.g., to determine whether the system is operating in an overloaded state or a non-overloaded state), damping oscillations between an overloaded state and a non-overloaded state and\/or reaching and maintaining an ideal request rate may be applied in a wide variety of systems that provide various services to clients (i.e. that receive and service client requests). For example, any or all of these techniques may be applied in a distributed storage system that provides access to a subscriber's data through one or more Web servers.  is a block diagram illustrating a portion of such a distributed storage system, according to one embodiment. In this example, a distributed storage system  may include one or more load balancers , a plurality of Web servers  (illustrated in  as -), and a plurality keymap control components  (illustrated in  as -).","In this example, load balancer(s)  may be configured to distribute each incoming request from subscribers  (e.g., subscribers -) for access to subscriber data to one of the plurality of Web servers , using any suitable load balancing technique and\/or distribution criteria. Web servers  may be configured to receive requests for access to data stored in the storage system (e.g., requests to put, get, or modify data) from load balancer(s)  on behalf of subscribers . In this example, keymap control components  may be configured to map requests to access data to a respective node in the distributed system on which the data is stored (e.g., dependent on a user key associated with the data and included in the request).","In response to receiving a request from a subscriber , load balancer(s) may route the request to a particular Web server , which may be configured to determine a particular one of the keymap control components  to which the request should be directed (e.g., because the particular keymap control component  stores, or otherwise has access to, a mapping between the data targeted by the request and a storage node on which it can be accessed).","As illustrated in , if multiple requests  (shown as requests -) are received from one or more subscribers  to access data having the same key (e.g., if multiple \u201cget\u201d requests are received that target data associated with the key \u201cfoo\u201d), these requests may initially be distributed (e.g., by load balancer(s) ) to multiple Web servers  as requests -. However, each of the Web servers  to which these requests are initially distributed may subsequently route them to the same keymap control component  (e.g., keymap control component , in this example), if that keymap control component  stores, or otherwise has access to, a mapping between the data targeted by the request (i.e. data associated with the key \u201cfoo\u201d) and a storage node on which it can be accessed (not shown). If the number of such requests is large enough and\/or the rate at which they are received by the system is high enough, the system may enter an overloaded state, as described herein.","In the system illustrated in , the techniques described herein may be employed to determine the overload state of a system based on client-specific QoS expectations (such as expected response times), to drop or throttle requests when the system is operating in an overloaded state, to damp oscillations between an overloaded state and a non-overloaded state (e.g., through adaptive throttling), and\/or to reach and maintain an ideal request rate in order to better serve subscribers  while avoiding a system shutdown or failure caused by a crushing overload. In one specific example, if each individual keymap control component  is capable of handling requests at a rate of 3000 transactions per second (Tps), but more than 3000 requests per second are directed to a single keymap control component  (e.g., keymap control component ), its performance (and thus the performance of the system) may degrade, and the level of degradation may be proportional to the amount by which the actual Tps rate exceeds the capacity of the keymap control component (i.e. the rate at which the requests exceed 3000 Tps). In this example, the techniques described herein may be employed in the system to determine the overload state of the system, to drop or throttle requests, to damp oscillations between an overloaded state and a non-overloaded state, and\/or to reach and maintain an ideal request rate may prevent keymap control component from failing, due to its inability to handle a crushing load.","Note that the number of subscribers , requests  and , Web servers , and keymap control components  illustrated in  (designated as \u201cn\u201d for each of these component types) may not be the same. In other words, the values of \u201cn\u201d for each of these component types may be independent of each other, in this example.","In some embodiments, the system and methods described herein for determining whether a system is operating in an overloaded state, dropping or throttling requests, damping oscillations between an overloaded state and a non-overloaded state, and\/or reaching and maintaining an ideal request rate may be employed in a system through which various services are provided to subscribers as part of a virtualized computing service. In various embodiments, such virtualized computing may be offered as an on-demand, paid service to clients. For example, an enterprise may assemble and maintain the various hardware and software components used to implement virtualized computing, and may offer clients access to these resources according to various pricing models (e.g., usage-based pricing, subscription pricing, etc.). Thus, clients may have access to a range of virtual computing resources without having to incur the costs of provisioning and maintaining the infrastructure needed to implement those resources.","Example Computer System Embodiment","It is contemplated that in some embodiments, any of the methods, techniques or components described herein may be implemented as instructions and data capable of being stored or conveyed via a computer-accessible medium. Such methods or techniques may include, for example and without limitation, various methods for determining the overload state of a system, dropping or throttling requests, damping oscillations between an overloaded state and a non-overloaded state, and\/or reaching and maintaining an ideal request rate, as described herein. Such instructions may be executed to perform specific computational functions tailored to specific purposes (e.g., processing requests received via a Web services interface, or returning feedback and\/or results of servicing various requests) as well as higher-order functions such as operating system functionality, virtualization functionality, network communications functionality, application functionality, storage system functionality, and\/or any other suitable functions.","One example embodiment of a computer system that includes computer-accessible media and that provides mechanisms for determining the overloaded state of a system, dropping or throttling requests, damping oscillations between an overloaded state and a non-overloaded state, and\/or reaching and maintaining an ideal request rate is illustrated in . In various embodiments, the functionality of any of the various modules or methods described herein may be implemented by one or several instances of computer system . In particular, it is noted that different elements of the system described herein may be implemented by different computer systems . For example, a computer system that supports the functionality described herein for determining the overload state, dropping or throttling requests, damping oscillations between an overloaded state and a non-overloaded state, and\/or reaching and maintaining an ideal request rate may be implemented on the same computer system  on which a client (through which a customer\/subscriber may access the system) executes, or on another computer system , in different embodiments. In another example, different subsystems (e.g., a Web service interface, an admission control subsystem, and a service request subsystem; or one or more load balancers, Web servers, and\/or keymap control components) may be implemented on or across multiple ones of the computing nodes, and each of the computing nodes may be similar to computer system .","In the illustrated embodiment, computer system  includes one or more processors  coupled to a system memory  via an input\/output (I\/O) interface . Computer system  further includes a network interface  coupled to I\/O interface . In various embodiments, computer system  may be a uniprocessor system including one processor , or a multiprocessor system including several processors  (e.g., two, four, eight, or another suitable number). Processors  may be any suitable processor capable of executing instructions. For example, in various embodiments processors  may be a general-purpose or embedded processor implementing any of a variety of instruction set architectures (ISAs), such as the x86, PowerPC\u2122, SPARC\u2122, or MIPS\u2122 ISAs, or any other suitable ISA. In multiprocessor systems, each of processors  may commonly, but not necessarily, implement the same ISA.","System memory  may be configured to store instructions (e.g., code ) and data (e.g., in data store ) accessible by processor . In various embodiments, system memory  may be implemented using any suitable memory technology, such as static random access memory (SRAM), synchronous dynamic RAM (SDRAM), nonvolatile\/Flash-type memory, or any other type of memory. In the illustrated embodiment, instructions and data implementing desired functions, methods or techniques (such as functionality for supporting determining an overload state, dropping or throttling requests, damping oscillations between an overloaded state and a non-overloaded state, and\/or reaching and maintaining an ideal request rate according to various mechanisms described herein), are shown stored within system memory  as code . It is noted that in some embodiments, code  may include instructions and data implementing desired functions that are not directly executable by processor  but are represented or encoded in an abstract form that is translatable to instructions that are directly executable by processor . For example, code  may include instructions specified in an ISA that may be emulated by processor , or by other code  executable on processor . Alternatively, code  may include instructions, procedures or statements implemented in an abstract programming language that may be compiled or interpreted in the course of execution. As non-limiting examples, code  may include code specified in a procedural or object-oriented programming language such as C or C++, a scripting language such as perl, a markup language such as HTML or XML, or any other suitable language.","In some embodiments, data store  within system memory  may store values of default, client-specific, or type-specific configurable parameters; actual QoS information; calculated percentages of requests for which QoS expectations were not met; calculated differences between expected and actual QoS, and\/or other data in various data structures suitable for implementing the techniques described herein.","In one embodiment, I\/O interface  may be configured to coordinate I\/O traffic between processor , system memory , and any peripheral devices in the device, including network interface  or other peripheral interfaces. In some embodiments, I\/O interface  may perform any necessary protocol, timing or other data transformations to convert data signals from one component (e.g., system memory ) into a format suitable for use by another component (e.g., processor ). In some embodiments, I\/O interface  may include support for devices attached through various types of peripheral buses, such as a variant of the Peripheral Component Interconnect (PCI) bus standard or the Universal Serial Bus (USB) standard, for example. In some embodiments, the function of I\/O interface  may be split into two or more separate components, such as a north bridge and a south bridge, for example. Also, in some embodiments some or all of the functionality of I\/O interface , such as an interface to system memory , may be incorporated directly into processor .","Network interface  may be configured to allow data to be exchanged between computer system  and other devices attached to a network, such as other computer systems, for example. In various embodiments, network interface  may support communication via wired or wireless general data networks, such as any suitable type of Ethernet network, for example; via telecommunications\/telephony networks such as analog voice networks or digital fiber communications networks; via storage area networks such as Fibre Channel SANs, or via any other suitable type of network and\/or protocol.","In some embodiments, system memory  may include a non-transitory, computer-readable storage medium configured to store instructions and data as described above. However, in other embodiments, instructions and\/or data may be received, sent or stored upon different types of computer-accessible storage media. Generally speaking, a computer-accessible storage medium may include storage media or memory media such as magnetic or optical media, e.g., disk or CD\/DVD-ROM coupled to computer system  via I\/O interface . A computer-accessible storage medium may also include any volatile or non-volatile storage media such as RAM (e.g. SDRAM, DDR SDRAM, RDRAM, SRAM, etc.), ROM, etc, that may be included in some embodiments of computer system  as system memory  or another type of memory. A computer-accessible storage medium may generally be accessible via transmission media or signals such as electrical, electromagnetic, or digital signals, conveyed via a communication medium such as a network and\/or a wireless link, such as may be implemented via network interface .","Although the embodiments above have been described in considerable detail, numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims be interpreted to embrace all such variations and modifications."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
