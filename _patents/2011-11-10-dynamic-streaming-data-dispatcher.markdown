---
title: Dynamic streaming data dispatcher
abstract: A method includes receiving, by a computing device, a plurality of data streams from plurality of sources, distributing the data streams to a plurality of sinks on multiple hosts, receiving load information indicating a load on at least one of the plurality of sinks and adjusting the distribution of the data stream accordingly and instructing the plurality of sinks to write the data streams to a distributed data store.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09367501&OS=09367501&RS=09367501
owner: INTERNATIONAL BUSINESS MACHINES CORPORATION
number: 09367501
owner_city: Armonk
owner_country: US
publication_date: 20111110
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["STATEMENT OF GOVERNMENT INTEREST","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This invention was made with Government support under Contract Number H98230-07-C-0383. The U.S. Government has certain rights to this invention as provided for by the terms of the contract.","The present disclosure relates to dispatching data streams, and more specifically, to adaptable methods for dispatching incoming data streams to multiple hosts.","With the increased instrumentation and interconnectedness of the world, businesses are experiencing an exponential increase in the volume, variety and rate of data that requires processing. However, the ability to analyze and extract useful insight from this data poses a huge computational challenge, both in the systems and analytics spaces. As a result, large-scale, distributed data-analytics platforms for computing on streaming data and static data have been proposed to address these challenges.","Currently separate systems are used for analyzing streaming data and for processing large volumes of historic data stored on distributed storage systems. Increasingly, applications are requiring the integration of both systems in order to extract real-time insights from streaming data and apply these insights to make predictions from models formulate from historical data.","According to one embodiment of the present disclosure, a method for distributing incoming data includes receiving a data stream from a source, distributing the data stream to a plurality of sinks on multiple hosts, receiving load information indicating a load on at least one of the plurality of sinks and adjusting the distribution of the data stream accordingly and instructing the plurality of sinks to write the data stream to a distributed data store.","According to another embodiment of the present disclosure, a method for distributing incoming data includes receiving a plurality of data streams from a plurality of data sources distributing the plurality data stream to a plurality of sinks on multiple hosts, receiving load information indicating a load on at least one of the plurality of sinks and adjusting the distribution of the data stream accordingly and instructing the plurality of sinks to write the plurality of data streams to a distributed data store.","According to another embodiment of the present disclosure, a computer program product for distributing incoming data streams, the computer program product includes a non-transitory computer readable storage medium having computer readable program code embodied therewith, the computer readable program code including computer readable program code configured to receive a plurality of data streams from a plurality of data sources, distribute the plurality data stream to a plurality of sinks on multiple hosts, receive load information indicating a load on at least one of the plurality of sinks and adjust the distribution of the data stream accordingly and instruct the plurality of sinks to write the plurality of data streams to a distributed data store.","According to yet another embodiment of the present disclosure, a system for distributing incoming data streams includes splitter for receiving a data stream from a data source, a plurality of sinks in operable communication with the splitter, a distributed data storage device in operable communication with the plurality of sinks and a load manager in operable communication with the plurality of sinks and the splitter, wherein the load manager instructs the splitter on distribution of the data stream to the plurality of sinks and received feedback from each of the sinks when they have written the data to the store.","Additional features and advantages are realized through the techniques of the present disclosure. Other embodiments and aspects of the disclosure are described in detail herein and are considered a part of the claimed disclosure. For a better understanding of the disclosure with the advantages and the features, refer to the description and to the drawings.","Referring to , there is shown an embodiment of a processing system  for implementing the teachings herein. In this embodiment, the system  has one or more central processing units (processors) , , , etc. (collectively or generically referred to as processor(s) ). In one embodiment, each processor  may include a reduced instruction set computer (RISC) microprocessor. Processors  are coupled to system memory  and various other components via a system bus . Read only memory (ROM)  is coupled to the system bus  and may include a basic input\/output system (BIOS), which controls certain basic functions of system .",{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1","b":["107","106","113","107","103","105","107","103","105","104","106","113","116","100","115","113","112","107","106","112","113","113","108","112","109","110","111","113","108"]},"Thus, as configured in , the system  includes processing capability in the form of processors , storage capability including system memory  and mass storage , input means such as keyboard  and mouse , and output capability including speaker  and display . In one embodiment, a portion of system memory  and mass storage  collectively store an operating system such as the AIX\u00ae operating system from IBM Corporation to coordinate the functions of the various components shown in .","It will be appreciated that the system  can be any suitable computer or computing platform, and may include a terminal, wireless device, information appliance, device, workstation, mini-computer, mainframe computer, personal digital assistant (PDA) or other computing device.","Examples of operating systems that may be supported by the system  include Windows 95, Windows 98, Windows NT 4.0, Windows XP, Windows 2000, Windows CE, Windows Vista, Macintosh, Java, LINUX, and UNIX, or any other suitable operating system. The system  also includes a network interface  for communicating over a network. The network can be a local-area network (LAN), a metro-area network (MAN), or wide-area network (WAN), such as the Internet or World Wide Web. Users of the system  can connect to the network through any suitable network interface  connection, such as standard telephone lines, digital subscriber line, LAN or WAN links (e.g., T, T), broadband connections (Frame Relay, ATM), and wireless connections (e.g., 802.11(a), 802.11(b), 802.11(g)).","As disclosed herein, the system  includes machine readable instructions stored on machine readable media (for example, the hard disk ) for capture and interactive display of information shown on the screen  of a user. As discussed herein, the instructions are referred to as \u201csoftware\u201d . The software  may be produced using software development tools as are known in the art. Also discussed herein, the software  may also referred to as a \u201ccommand line testing tool\u201d , an \u201ca testing interface\u201d  or by other similar terms. The software  may include various tools and features for providing user interaction capabilities as are known in the art.","Referring now to , a block diagram of a system  for dispatching incoming data streams  from multiple sources  is illustrated. The system  includes a plurality of sinks , each located on one or more hosts , for buffering and writing to a distributed data store . The distributed data store  includes one or more data stores  which may also be located of different hosts. The system  also includes one or more splitters  which receive the incoming data streams  and redirects the data to one of plurality of sinks . The splitter  reads data streams  from a streaming data source  and forwards it to the sinks  based upon factors such as data type, size, rate etc. The splitter  determines the amount of data to be transferred to each sink  and is also tracks the progress of the write operations to the distributed data store .",{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 3","b":["204","204","212","214","204","214","208","206","204","206","212","210","228","226","226","204","214","208","204","216","218","216","218"]},"The sink  is responsible for buffering streaming data and writing it to a data store . In exemplary embodiments multiple sinks  can be deployed on a single or on multiple hosts . For example, in a distributed network there may be one sink  per host  in the network. In an exemplary embodiment, the write operations to the data store  are handled asynchronously and do not affect the buffering process. The sink  can be configured to write one or more buffers  concurrently to the data store . The maximum number of buffers , maximum size of each buffer  and the number of concurrent writers can be configured at application deployment time based on the available memory and CPU capacity of the hosts  in the network. In exemplary embodiments, the sink  can be designed to operate in one of two modes. In the first mode, the sink  buffers incoming data up to a pre-configured maximum size and then enqueues the buffer  for writing to the data store . In the second mode, the sink  will buffer data until signaled by the splitter  to cease writing to the buffer . Once the sink  receives instructions from the splitter , it will cease adding to the current buffer , enqueue the buffer  for writing to the data store  and continue to accumulate incoming data into a separate buffer .","Turning now to , a block diagram illustrating the operation of a load manager  is illustrated. In exemplary embodiments, the load manager  monitors the load on each host  by checking the load of all the writers on that host . The load manager  may also determine the load on the hosts  by receiving load metrics  from the sink . Based upon the load of each host , the load manger  determines the least busy hosts to send data to and sends appropriate host assignments  to the splitter . In addition, the load manager  may receive host requests  from the splitter  requesting a new host. The load manager  can occasionally choose to not allocate any host based on load information. In exemplary embodiments, the load manager  is used as a load balancing mechanism to ensure proper distribution of work based on the current load. The load manager  may include a configurable dispatch policy that is used to ensure that input data streams  are properly distributed by the splitter . In one embodiment, the load manager  instructs the splitter  to distribute the data streams  to the plurality of sinks  in a balanced manner, i.e., the load manager  attempts to maintain similar loads on each of the plurality of sinks . The load manager  may instruct the splitter to distribute the data streams  to the plurality of sinks  based upon the load on each of the plurality of sinks  and the total size of data being sent to each sink .","Continuing now with reference to , the splitter  receives incoming data streams  and sends the data tuples  to one of the plurality of sinks . The splitter  receives host assignments  from the load manager  and result tuples  from the sinks . Based upon the information received from the sink  and the load manger , the splitter  decides which data tuples  of the incoming data stream  to send to each sink . In exemplary embodiments, the splitter  is configured to direct the data tuples  based on the type of data that is being written. For example, the splitter  could determine which sink  to send the data tuples  to based upon the size of the data, the time the data will be sent, or on other information contained in the data. In exemplary embodiments, the splitter  also receives result tuples  from the sink , which indicate if the write operations were successful or not. Since the splitter  controls when the data is written to the distributed data store , it can adjust to changes in incoming data rates and send \u201cwrite\u201d requests to the sink  with different data sizes.","In exemplary embodiments, after the splitter  determines that the sink  has enough data to be written to a data store , the splitter  sends the sink  a control tuple  that includes a \u201cwrite\u201d request. Once the sink  receives the \u201cwrite\u201d request from the splitter , the sink  will cease buffering to the current active buffer and enqueue the buffer  for writing to the distributed data store . In addition, the control tuples  can be used to send other messages from the splitter  to the sink . Such messages can include, for example, a \u201cdiscard\u201d request instructing the sink  to discard a buffer . The control tuples  can be used for replication and fault-tolerance. The sink  generates result tuples  which are used to inform the splitter  if requests received, in the form of control tuples , from the splitter  have been completed or have failed. The result tuples  can be received by and acted on by the splitter  and any other external entity. In exemplary embodiments, the splitter  can be configured to send the same data tuple  to multiple sinks  and if a particular sink  fails to write to the distributed data store , another sink  can be asked to write the data to the distributed data store . In addition, the additional sinks  can be asked to discard data if the write was successful. The degree to which the system uses replication can be configured by a user.","In an exemplary embodiment, the data tuple  includes a group identification number, a sequence number and a payload. The group identification number may be a unique number for every group of tuples being written together. The sequence number may be a tuple counter for current group and the payload includes the actual data to be written.","In an exemplary embodiment, the control tuple  includes request identification number, a maximum sequence number and a type variable. The request identification number is a unique identification number for the current request. The maximum sequence number is a sequence number of the last tuple in group. The type variable indicate that type of action that the control tuple  is instruction the sink  to perform such as write, discard, etc. In addition, the control tuple  can also be designed to contain additional application specific data.","In an exemplary embodiment, the result tuple  includes a request identification number and a type variable. The request identification number is a unique identification number of the request which included the write instruction. The type variable indicates the result being reported by the result tuple  such as a write success or failure. In addition, the result tuple  can also be designed to contain additional application specific data.","In an exemplary embodiment, the host request  includes a request identification number, a splitter identification number, a number of hosts variable, and a current host identification number. The request identification number is a random number assigned to the request. The splitter identification number is a unique identification number of the splitter that the request is being sent from. The number of hosts variable is the number of hosts requested by the splitter and the current host identification number is the identification number of the hosts currently being used by the splitter. In addition, the host request  can also be designed to contain additional application specific data. In exemplary embodiment, the host request  can be sent at any time by the splitter and it is typically sent before the splitter sends a write request to the sink.","In an exemplary embodiment, the host assignment  includes a request identification number, a splitter identification number, a type variable, and a host identification number. The request identification number is the number assigned to the request  that the host assignment  is in response to. The splitter identification number is the number assigned to the splitter for which the host assignment  is requested. The type variable indicates whether the requested host is available or un-available and the host identification number is the identification number of the currently assigned hosts. In addition, the host assignment  can be designed to contain additional application specific data.","Referring now to , a block diagram illustrating the operation of a system for dispatching incoming data streams from a single source is shown is shown. The system includes a splitter  that receives and distributes an incoming data stream and a plurality of hosts  that each include a sink  which receive data from the splitter . The splitter  sends both data tuples  and control tuples  to the sinks . The sinks  write data to the distributed data store  and send load metrics  to the load manager  and result tuples  to the splitter . The splitter  receives hosts assignment tuples  from the load manager  and sends the load manager  host requests .","Referring now to , a block diagram illustrating the operation of a system for dispatching incoming data streams from multiple sources is shown. The system includes multiple splitters  that receive data from multiples sources . The splitters  distribute the incoming data streams to a plurality of hosts  that each include a plurality of sinks  which receive distributed data from the splitter . The splitters  send both data tuples  and control tuples  to the sinks . The sinks  write data to the distributed data store  and send load metrics  to the load manager  and result tuples to the splitter . The splitter  receives hosts assignment tuples  from the load manager  and sends the load manager  host requests .","In the system shown in , each streaming data source  can potentially have a different and variable data rate. Since the data will be written to the same repository, there needs to be coordination between the writers so that the load across all the writers is distributed evenly. Accordingly, in exemplary embodiments each data source  is coupled with a unique splitter . This ensures that the splitter  can adapt to the data rate of the source  without affecting other data sources . To balance the load across the hosts  in the network, the load manager  will be shared across the data sources. The load manager  accepts load information from all the sinks  in the system and uses this information to determine the overall load on each host  and can intelligently decide on how the load should be distributed to enhance performance.","In an exemplary embodiment, the system for distributing incoming data streams is advantageous in that it eliminates the need for intermediate data storage mechanisms because the streaming data need not be stored into files which are then uploaded to the data storage facility. In addition, the system is advantageous because it is designed to adjust to multiple streams with varying data rates. Since the splitter controls when the data is written to the data store, the splitter can adjust to incoming rates and send \u201cwrite\u201d requests to sink with different data sizes. Another advantage of the system is that it can be designed to have a configurable degree of fault-tolerance.","The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting of the disclosure. As used herein, the singular forms \u201ca\u201d, \u201can\u201d and \u201cthe\u201d are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms \u201ccomprises\u201d and\/or \u201ccomprising,\u201d when used in this specification, specify the presence of stated features, integers, steps, operations, elements, and\/or components, but do not preclude the presence or addition of one more other features, integers, steps, operations, element components, and\/or groups thereof.","The flow diagrams depicted herein are just one example. There may be many variations to this diagram or the steps (or operations) described therein without departing from the spirit of the disclosure. For instance, the steps may be performed in a differing order or steps may be added, deleted or modified. All of these variations are considered a part of the claimed disclosure.","The corresponding structures, materials, acts, and equivalents of all means or step plus function elements in the claims below are intended to include any structure, material, or act for performing the function in combination with other claimed elements as specifically claimed. The description of the present disclosure has been presented for purposes of illustration and description, but is not intended to be exhaustive or limited to the disclosure in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art without departing from the scope and spirit of the disclosure. The embodiment was chosen and described in order to best explain the principles of the disclosure and the practical application, and to enable others of ordinary skill in the art to understand the disclosure for various embodiments with various modifications as are suited to the particular use contemplated","While the preferred embodiment to the disclosure had been described, it will be understood that those skilled in the art, both now and in the future, may make various improvements and enhancements which fall within the scope of the claims which follow. These claims should be construed to maintain the proper protection for the disclosure first described."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS","p":["The subject matter which is regarded as the disclosure is particularly pointed out and distinctly claimed in the claims at the conclusion of the specification. The forgoing and other features, and advantages of the disclosure are apparent from the following detailed description taken in conjunction with the accompanying drawings in which:",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
