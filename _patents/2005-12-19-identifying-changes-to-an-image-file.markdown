---
title: Identifying changes to an image file
abstract: Editing an image is disclosed. Editing may include receiving a marking on the image, activating a command interface in response to the marking, receiving a command via the command interface, and applying the command to a portion of the image, where the portion is determined based at least in part on the marking.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07986298&OS=07986298&RS=07986298
owner: Adobe Systems Incorporated
number: 07986298
owner_city: San Jose
owner_country: US
publication_date: 20051219
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","DETAILED DESCRIPTION"],"p":["Digital photographs may be edited using an image editing application. For example, a photograph may be edited in order to fix perceived problems with the photograph, such as red eye, portions being too light or dark, or a color cast on the photo. Typically, a user knows which problems the user would like to fix in a photo. However, the user does not necessarily know which tools or interfaces to use in order to fix these problems. Most image editing applications provide numerous features that a typical user does not use because the user does not understand what the feature does or how to use the feature. For example, a user might not understand the terminology used by the application. A user may have a hard time selecting the exact area to which a change should be applied, or may not know this is necessary before proceeding. An improved method of editing an image file would be useful.","The invention can be implemented in numerous ways, including as a process, an apparatus, a system, a composition of matter, a computer readable medium such as a computer readable storage medium or a computer network wherein program instructions are sent over optical or electronic communication links. In this specification, these implementations, or any other form that the invention may take, may be referred to as techniques. A component such as a processor or a memory described as being configured to perform a task includes both a general component that is temporarily configured to perform the task at a given time or a specific component that is manufactured to perform the task. In general, the order of the steps of disclosed processes may be altered within the scope of the invention.","A detailed description of one or more embodiments of the invention is provided below along with accompanying figures that illustrate the principles of the invention. The invention is described in connection with such embodiments, but the invention is not limited to any embodiment. The scope of the invention is limited only by the claims and the invention encompasses numerous alternatives, modifications and equivalents. Numerous specific details are set forth in the following description in order to provide a thorough understanding of the invention. These details are provided for the purpose of example and the invention may be practiced according to the claims without some or all of these specific details. For the purpose of clarity, technical material that is known in the technical fields related to the invention has not been described in detail so that the invention is not unnecessarily obscured.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1A","b":"802"},"A gesture, as used herein, refers to a mouse (or other pointing device) movement associated with a meaning. A gesture may include a marking that is associated with a change. For example, if an \u201cX\u201d is associated with the change \u201cdelete,\u201d a user could draw an \u201cX\u201d over an object in a photo to indicate that removal of the object is desired. Alternatively, the user could move a mouse in the shape of an \u201cX\u201d without marking the photo. In another example, moving the mouse in the shape of a \u201cP\u201d may mean print.","At , a change is determined based on the marking. A change includes an edit to the image. Various markings may be associated with the same change. For example,  illustrate examples of various markings. In , markup is a circle around a pair of eyes. Text says \u201cRemove red eye.\u201d A line connects markup to text . The line may be drawn by a user, or automatically drawn. For example, a user may first draw markup . In response, a dialog box or other command interface may open. Alternatively, the user could trigger the dialog box, for example, by double clicking on markup . The dialog box could include a place for entering a command, such as text . When the dialog box is closed, the markings would appear as shown. In , text  says \u201cRemove red eye from Bob.\u201d Text  is located adjacent to the image. The user may have previously tagged a face in the picture with \u201cBob,\u201d for example. In , gesture  is an \u201cX\u201d over a pair of eyes. In some embodiments, the same change determined for the markings shown in  is the same, and that is to remove the red eye of the face on the left.","The command interface can be either displayed to the user for entry or not displayed and a command entry made based on an interpretation of the marking. For example, if the marking is a gesture, then a command associated with that gesture may be entered. A command interface may include an application programming interface (API). A command may include a change provided by a user (in the user's own words or selected from machine provided choices) or a change that is generated based on a marking.","Returning to , the change is applied at . For example, in the case of , a red eye removal technique may be applied to the face on the left. In some embodiments, the change is applied as a preview before the change is applied. At , it is determined whether a user adjustment is received. For example, the user may view the change and decide to adjust a marking or a parameter associated with the change. For example, if the change was to lighten a portion of a photo, the user may enlarge the portion of the photo (e.g., by making a circle bigger) that is lightened and\/or change the percentage by which the photo is lightened. If an adjustment is received, the process returns to , in which a change is determined. In this case, the change is based on the user adjustment. As such, the user can continuously adjust a photo until the user is satisfied with the results. If an adjustment is not received at , the process ends at .","In some embodiments, a plurality of markings are received at . A plurality of changes may be determined at . The changes may all be applied at . Each change may be individually previewed at  before applying the change. An adjustment that affects any of the changes may be received at .",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2","b":["900","901","902","904","906","908"]},"In this example, a user is in the process of creating markings . Markings  include a circle around the spot on the floor. For example, the user may have drawn the circle (or other shape) around the spot on the floor, and command interface (window)  may have opened in response. Window  may include a place (e.g., a text entry field) for the user to enter text or select from a menu of changes to apply to the circled portion of the photo. The menu choices may include default menu choices and\/or choices that are generated based on the marking, as more fully described below. The machine's best guess may be pre-filled in a text field. For example, the area within the circle may be analyzed and it may be automatically determined that there is an undesirable spot on the floor. As a result, \u201cRemove spot\u201d or \u201cRemove\u201d (as shown) may be provided as a menu option. Alternatively, the user could enter the text \u201cRemove.\u201d Such a window may include other ways to receive user input, such as a slider bar, as shown. The slider bar allows the user to indicate using a slider whether to increase or decrease the region the change would affect. For example, the spot may be desirable by the user, in which case, the user may want to resize the spot. Any parameter related to the change may be shown in window . After closing window , markings  may include text describing the command (e.g., \u201cRemove\u201d) in place of window .","Markings  include an arrow from the text \u201cRemove tan lines\u201d to a circle around the tan lines. For example, a user may have drawn the circle. The text \u201cRemove tan lines\u201d may have been selected or entered by the user in an interface such as window .","Markings  include arrows from the text \u201cDress is too dark, gray\u201d to two bullets. In some embodiments, markings  is a grouping of two markings. For example, a user may have drawn one of the bullets, and entered the text \u201cDress is too dark.\u201d The user may then have drawn the other bullet, and entered the text \u201ctoo gray.\u201d The two markings may have been grouped or consolidated to combine the text into \u201cDress is too dark, gray\u201d and the arrows may have been adjusted, resulting in markings .","Marking  includes text only and is not located on image . In some embodiments, text that refers to changes that apply to the entire image are displayed outside of the image.","Interface  allows a user to more naturally describe what the user would like adjusted and where. For example, the user may describe what the user does not like about the photo, what needs to be fixed, and\/or how it should be fixed using markup, gestures, and\/or their own text descriptions on the photo. The user may also specify non-exact regions for these descriptions by circling the general area, pointing to an object, etc. The user may use natural language commands, such as \u201cthis photo looks too blue,\u201d \u201cthis area is too dark,\u201d \u201cI want to remove this blemish,\u201d or \u201cJust the green in this general area should be brighter.\u201d Natural language processing may be used to understand standard words that a user might use and translate them into changes, which can be mapped to algorithms, to apply to an image.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 3A","b":"1002"},"Marking  may be used to indicate a selection of a portion of an image by roughly circling the portion, such as an object. Marking  may be circular, rectangular, or any predefined or freeform shape. For example, a user could draw a freeform shape that roughly outlines an object in an image. Marking  is a line, and may be interpreted in various ways. For example, marking  could indicate an area which the line points to, or an area near the line, depending on what is near the line in the image.","Markings , , and  may be referred to as sloppy selection. Various techniques can be used to handle sloppy selection (e.g., convert a sloppy selection into a precise pixel selection). For example, techniques based on Graph Cut, GrabCut may be used. In some embodiments, the selection is based at least in part on other markings, such as text. For example, if the user has entered the text \u201clighten\u201d next to a circle around an already white object in the image, then a portion of the image other than the white object will be selected, such as the background.","Marking  may be a gesture that is used to indicate the removal of an object. Marking  may be a gesture that is used to indicate that a portion of the photo should be pinched. Marking  may be a gesture that is used to indicate that the portions of the image the two sides of marking  should be blended or healed.",{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 3B","b":["1002","1012","1002","1010","1008","1004","1004","1012","1012","1006","1006","1004","1012","1006"],"i":["a ","a ","a ","a","a","a "]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 4","b":["1116","1116","1102","1104","1106","1106","1106"]},"Markings  are provided to an interpreter . Interpreter  interprets or translates markings  to determine changes  to apply to the image. Interpreter  may interpret markings  by performing natural language processing. For example, natural language detection techniques may be used to map a user's words to commands that an application supports. For example, if the application is Adobe Photoshop\u00ae Elements, the user words \u201ctoo dark\u201d can be mapped to \u201cchange Shadow\/Highlights\u201d with no change to highlights and a \u201clighter\u201d change to the shadows. This can be done using natural language techniques and\/or a library of typical terms used in describing problems with photos.","Interpreter  may use gesture recognition to understand that the user is drawing or has drawn a symbol (e.g., an \u201cX\u201d, a circle, a rectangle, etc.) and map the gesture to the definition of a region and\/or command(s).","Some gestures can be directly translated to a change. This is done by having a library of typical gestures used in describing problems with photos (X=remove, arrows in=pinch, etc) and matching gestures not in the library to a defined gesture that is similar. The gesture may be mapped to a change, similar to how text may be mapped to a change.","In the case where interpreter  cannot translate markings  to a degree of certainty, the interpreter may ask the user for more information and\/or offer a short list of \u201cbest guesses\u201d to choose from. More information may be received via user input .","Over time, or by direct request of the user, the interpreter can learn a particular user's language and gestures for more efficient translation. For example, the user may decide to start using \u201cr.e.\u201d instead of typing \u201cred eye.\u201d","In some embodiments, interpreter  generates a set of changes and the user may modify the changes directly or by going back and changing one or more of markings . For example, if markup  includes an \u201cX\u201d over a pair of eyes, a change generated may be to remove red eye. An interface may be provided for the user to accept (or verify), modify, or reject the change.","In some embodiments, interpreter  may be used to assist a user with creating markings. For example, a user may draw a circle around a pair of eyes. In response, a command interface, such as a dialog box or other window, may open. The window may include generated and\/or pre-defined changes for the user to select. \u201cRemove red eye\u201d may be a generated change because the machine may have detected that the circle contains red eyes. The change generated may not be a change the user desires. For example, the user wants to remove red eye, but the generated changes are \u201cbrighten\u201d and \u201csharpen.\u201d If a change is not generated or the only generated choices are not what the user wants, the user may enter the text \u201cremove red eye.\u201d","Interpreter  determines changes  based on markup , gesture , and user input . For example, interpreter  may determine changes  based on a selected area, which may be determined based on markup , gesture , and\/or user input . For example, if a pair of eyes is circled, changes  may include remove red eye. In another example, if \u201cX\u201d is drawn over a pair of eyes, changes  may include remove red eye.","The changes are provided to technique selector . A technique includes an algorithm or command(s). Technique selector  selects technique  to apply to implement a change. For example, to remove red eye on a selected face, a technique for removing red eye may be applied to the selected face. To lighten a portion of an image, a lightening technique can be applied.","In this example, markings  and technique  are provided as input to image portion selector . Image portion selector  selects portion  of an image to which to apply one or more changes. Portion  may include, for example, an object in the image. Portion  may be selected based on markings  and\/or technique . For example, if markings  include a circle around a person and technique  includes a red eye removal algorithm, then image portion selector  may select the person's eyes. In another example, if user input  includes the text \u201cRemove red eye from Bob,\u201d then image portion selector  selects the person's eyes if the person has been previously tagged Bob.","In some embodiments, for regions, standard shapes and closed paths are recognized. If the path is closed, the region is taken as the area inside that path. If the path is not closed, more interpretation is needed based on properties of the region alone or in conjunction with the text. For example, a line pointing to a very dark area may be interpreted as \u201call dark spots touching where this line points to,\u201d whereas a line pointing to a gray area cannot be interpreted alone. If the text states, \u201ctoo gray, should be white,\u201d the region would be interpreted as all grayish colors touching this spot.","In some embodiments, image portion selector  selects a portion based on change  rather than technique . In some embodiments, both change  and technique  are used to select a portion.","Portion selector  may select a general region or a more exact region. Once the technique is determined and the portion for the technique is determined, an exact area and parameters associated with the technique may be determined. For example, consider a region defined by a circle. In some cases, some algorithms should not be run on the entire encircled area.","For example, to blend out a cut on a person's hand, it may be that the \u201cheal\u201d command should only be applied on the cut and very little of the surrounding skin. Because the command is \u201cheal,\u201d an encircled area may be further refined. An object close to the size of the circle but within it would be determined.","A \u201cLighten Shadows\u201d command may run on the dark spots within a given area, but not on the light spots. It may be applied in different percentages to different spots, depending on how light they already are. The command may also be applied in the surrounding area, perhaps with lower intensity, in order to create a realistic, blended effect. Therefore, the selected area may be further broken down into various degrees of dark and light spots. Different levels of lightening may be applied to the different levels of dark spots. In addition, the area outside the selected area may be affected, with diminishing amounts of lightening applied moving further from the selected area, enabling a blending effect.","A \u201cRemove Red Eye\u201d command removes red from a circular area of a pupil. A circle around two eyes may be further broken down in order to avoid removing other red spots like red eyeglasses. In some embodiments, the textual description of the circle maps to the \u201cremove red eye\u201d command, and red circular areas within the general region are found, and the fix only applied to those areas.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 5","b":["1202","1204","1110","1206","1112"]},"At , a portion of the image is selected based on the selected techniques and the markings. For example, image portion selector  may be used to select the portion of the image. At , the selected techniques are applied to the selected portion.","For example, the user may have pointed to a background area in the photo and typed \u201ctoo dark.\u201d This may be interpreted as needing to use the \u201clighten shadows\u201d function that it has on that background area. Lighten Shadows is run and the area becomes less dark. Similarly, the user may have typed \u201clighten this,\u201d \u201cLighten the shadows a little,\u201d \u201cmake brighter,\u201d or \u201cless black,\u201d which may all be translated to using the \u201clighten shadows\u201d function or technique.","The user may have drawn an \u201cX\u201d over a cut on the hand of someone in the photo. This may be interpreted as needing to use a \u201chealing\u201d function on that area of the hand. The healing function is run and the cut disappears. Similarly, the user may have drawn a naught symbol, put lines through the cut, or circled the cut and typed \u201cremove,\u201d and this may be translated in the same way.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 6","b":"1302"},"At , an input is received in response to the markup. For example, an input window opens in response to the user creating a marking. The window provides an interface for the user to provide input relating to the marking. For example, a user draws a circle or an \u201cX\u201d on a portion of an image, and an input window opens.  is optional. At , a correction is specified. For example, the user can use the input window to input the correction. In some embodiments, the user may specify the correction using natural language. In some embodiments, the user may select the correction from a list of predefined and\/or machine selected corrections. Alternatively, the correction may be implicit in the marking. For example, an \u201cX\u201d may both identify (i.e., select) an area and indicate that an object in that area should be removed. At , the markings are applied. For example, the user selects a \u201cGo\u201d or \u201cApply All\u201d button to apply the marking. In some embodiments, each marking is applied as soon as they are drawn. In other words, the markings are applied real time. At , the changes are verified. For example, a list of the changes that were made may be provided, and the user can go down the list to check the changes. If the user is dissatisfied with a change, the user can manually fix it.","In some embodiments, each marking can be previewed and applied. For example, the right mouse button might include \u201cpreview,\u201d \u201capply,\u201d and \u201cundo\u201d options. In another example, such options might be available from an input window. The input window may open in response to drawing a marking or may open when the user double clicks on the marking or performs another action. In some embodiments, markings may be toggled on or off For example, when the preview is on, the markings are in an \u201con\u201d state, the markings are shown on the photo. When the markings are in an \u201coff\u201d state, the markings are not shown and a preview of the markings as applied is shown.",{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 7","b":["1400","1401","1402","1401","1402","1404","1406","1408","1402","1404","1406","1408","1402","1402","1402","1402","1402"]},"Using sidebar , a user can insert, modify, accept, or reject a change associated with a marking. For example, marking  having identifier  is displayed at the top of sidebar . As shown, marking  is associated with a red eye fix. In sidebar , the user may have selected the text \u201cred eye\u201d from a menu or entered the text \u201cred eye\u201d in free form. As shown, markings , , and  are associated with the changes \u201cpatch,\u201d \u201cshadow\/highlight,\u201d and \u201cremove,\u201d respectively. In sidebar , various interfaces may be used for each change, including menus, slider bars, freeform text entry, etc. In some embodiments, sidebar  includes a preview and apply button. In some embodiments, each change in sidebar  includes a preview and apply button.","Although the foregoing embodiments have been described in some detail for purposes of clarity of understanding, the invention is not limited to the details provided. There are many alternative ways of implementing the invention. The disclosed embodiments are illustrative and not restrictive."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Various embodiments of the invention are disclosed in the following detailed description and the accompanying drawings.",{"@attributes":{"id":"p-0004","num":"0003"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0005","num":"0004"},"figref":"FIGS. 1B-1D"},{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 3B","b":["1002","1012"]},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
