---
title: Transforming a submitted image of a person based on a condition of the person
abstract: Apparatuses, computer media, and methods for altering a submitted image of a person. The submitted image is transformed in accordance with associated data regarding the person's condition. Global data may be processed by a statistical process to obtain cluster information, and the transformation parameter is then determined from cluster information. The transformation parameter is then applied to a portion of the submitted image to render a transformed image. A transformation parameter may include a texture alteration parameter, a hair descriptive parameter, or a reshaping parameter. An error measure may be determined that gauges a discrepancy between a transformed image and an actual image. A transformation model is subsequently reconfigured with a modified model in order to reduce the error measure. Also, the transformation model may be trained to reduce an error measure for the transformed image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07792379&OS=07792379&RS=07792379
owner: Accenture Global Services GmbH
number: 07792379
owner_city: Schaffhausen
owner_country: CH
publication_date: 20070206
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This invention relates to altering a submitted image of a person. More particularly, the invention provides a platform for transforming the image in accordance with a submitted image and associated data regarding the person's condition.","Excessive body weight is a major cause of many medical illnesses. With today's life style, people are typically exercising less and eating more. Needless to say, this life style is not conducive to good health. For example, it is acknowledged that type-2 diabetes is trending to epidemic proportions. Obesity appears to be a major contributor to this trend.","On the other hand, a smaller proportion of the population experiences from being underweight. However, the effects of being underweight may be even more divesting to the person than to another person being overweight. In numerous related cases, people eat too little as a result of a self-perception problem. Anorexia is one affliction that is often associated with being grossly underweight.","While being overweight or underweight may have organic causes, often such afflictions are the result of psychological issues. If one can objectively view the effect of being underweight or underweight, one may be motivated to change one's life style, e.g., eating in a healthier fashion or exercising more. Viewing a predicted image of one's body if one continues one's current life style may motivate the person to live in a healthier manner.","The above discussion underscores a market need to provide a computing platform for transforming a submitted image in order to project the image in accordance with a specified condition of a person.","Embodiments of invention provide apparatuses, computer media, and methods for altering a submitted image of a person. The submitted image is transformed in accordance with associated data regarding the person's condition.","With an aspect of the invention, a submitted image and associated data of a person's condition is obtained. A transformation parameter is determined and applied to a portion of the submitted image to render a transformed image.","With another aspect of the invention, an error measure is determined that gauges a discrepancy between a transformed image and an actual image. A transformation model is reconfigured with a modified model in order to reduce the error measure.","With another aspect of the invention, a transformation parameter includes a deformation vector. A mesh with a plurality of vertices is formed that overlays a portion of a submitted image. The deformation vector is applied to a vertex to obtain a transformed vertex to transform the mesh. A transformed image is rendered from the transformed mesh.","With another aspect of the invention, a transformation model is trained to reduce an error measure for the transformed image.","With another aspect of the invention, global data is processed by a statistical process to obtain cluster information. A transformation parameter is then determined from cluster information.","With another aspect of the invention, a transformation parameter includes a texture alteration parameter, a hair descriptive parameter, or a reshaping parameter. The transformation parameter is determined and subsequently applied to a portion of the submitted image.","With another aspect of the invention, a client-server configuration enables a requester to provide a submitted image with associated data about a person. The server returns a transformed image to the requester.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 1","FIGS. 10 and 11"],"b":["100","101","103","101"]},"With embodiments of the invention, system  may transform (e.g., reshape) a submitted image of a person for different objectives. For example, as will be discussed in greater detail, system  may thin or fatten the face of the person to show the effects of one's diet. Also, system  may provide guidance to patients in determining the benefits of cosmetic surgery or may project the effects of aging on a person (e.g., in support of a missing person's investigation. Embodiments of the invention also support other forecasting-health scenarios. Other scenarios include the evolution of face appearance while smoking and the evolution of stains on the face resulting from sun exposure. Embodiments of the invention can also forecast the effect of a drug taken for some illness. While photographic images can be used, other types of images (e.g., medical imaging including MRI, x-ray, ultrasound, and 3D) may be analyzed for different affected body organs (e.g., heart, lungs, kidney, and liver).","With an embodiment of the invention, system  transforms a portion of the submitted image in accordance with the associated data provided from interface . The portion may be specified as the head, torso, or entire body of a person.","With an embodiment of the invention, system  may be trained through training module  to configure a transformation model as will be discussed. After training, a picture (corresponding to a submitted image) and associated data is provided to database . Database  accesses a search model and model parameters that best match the submitted image. For example, a search model may include a mesh having points (vertices) as selected points of the face (e.g., shown in ). The mesh may vary based on the associated data, e.g., the ethnic group or the sex of the person.","Search module  obtains the image and the search model from database  and places the vertices on the portion of the image to form a mesh. As shown in , an exemplary mesh is formed for the face of the person. The vertices may be placed differently on the image based on the search model, which may depend on the ethnic group and the sex of the person. Search module  provides the image and the associated mesh to image transformation module .","In order for image transformation module  to transform the portion of the submitted image, transformation control module  determines vertex vectors (deformation vectors) for transforming the vertices of the mesh to form a transformed mesh. (As will be discussed with , the mesh is associated with corresponding texture from the picture where the alteration is taking place. When the mesh has been transformed, computer graphics software includes the associated texture to render the transformed image. Also, as will be discussed,  shows vertices that are transformed in accordance with determined deformation vectors.) The transformed image may be provided to a user through interface , printer , or communications channel .","Transformation control module  determines the deformation vectors from entry data (as may be contained in the associated data provided by a doctor) in accordance with an embodiment of the invention. (Embodiments of the invention may also include changes in texture, pattern, color and any other image characteristic.) For example, entry data may include specific information about a patient, e.g., the patient's weight loss during a period of time, the caloric input of the patient, and other dietary information. Also, as shown in , transformation control module  may be provided model parameters by training modules . In addition, the patient may be associated to a cluster by statistical analysis module . Module  may determine the associated cluster from the associated data from doctor that may include the age, weight, height, and ethnic group of the patient. A plurality of clusters may be formed based on the values of different attributes such age, weight, and ethnic group. A population may be assigned to the plurality of clusters based on selected attributes.","With an embodiment of the invention, system  is adaptive so that the transformation parameters for the transformation model may be modified in order to reduce an error measure between the transformed image and an actual image. For example, system  may provide a transformed image that predicts (projects) the image of a person's face after one year using the associated data from a doctor. The transformed image may be compared with the actual image (if one is available) after one year to determine an error measure, and a model parameter may be subsequently modified in order to reduce the error for images that are submitted to system . (As will be discussed,  provides an approach for determining an error measure.) For example, the deformation factor w (as discussed with EQs. 4A-4D) may be modified. The above error analysis may be implemented within one of the modules as shown in  (e.g., module ) or may be implemented with a separate module (e.g., an error analysis module not shown in ).","Embodiments of the invention also support training module  that configures transformation models and search models in order to obtain a transformed images that have an acceptable error with respect to actual data (e.g., an actual image). For example, a submitted image, associated data, and corresponding actual image are provided to training module . The submitted image is transformed and compared to the actual image. Model parameters for the transformation model are then adjusted to minimize an error measure. In order to train system , the process can be repeated a number of times until an acceptable error is obtained.","With embodiments of the invention, search module  may use a search model in which a search function of an Active Appearance Model (AAM) determines the vertices of the mesh (as will be discussed). A transformation model may be represented as a set of equations (e.g., EQs. 1-5B.) The set of equations may be specified by the model parameters (e.g., the constants contained in EQs. 1-5B.) Transformation control module  uses the transformation model to determine a deformation vector (that transforms a corresponding vertex of the mesh). The deformation vector comprises a weight value A, a scale factor s, a deformation factor w, and a direction vector \u016b as expressed in EQs. 1-5B and as will be later discussed.","With system  one can introduce images (photos or medical-specific images) in order to automatically forecast an evolution of a person's condition. Moreover, the results provided by system  can be improved by introducing feedback from experts (e.g., doctors nutritionist, surgeons) if improvement is desired.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 2","FIG. 9"],"b":["105","205","201","203","207","209","205","211"]},{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 3","FIG. 2"],"b":["300","100","300","100","105"]},"With embodiments of the invention, the execution of process  may be distributed over a plurality of modules as shown in . In step , a submitted image and associated data is entered and stored in database . In step , database  provides the appropriate search model and the submitted image to search module  to obtain the associated mesh.","In step , transformation control module  determines transformation parameters (e.g., deformation vectors) from cluster data and specific data about the person in accordance with the selected transformation model as identified by database . Image transformation module  subsequently processes the transformation parameters, submitted parameter, and mesh in step .","Even though system  may have been previously trained with training module , system  can subsequently update model parameters through error analysis process . Image transformation module  transforms the submitted image to obtain a transformed image as discussed above. If an actual image of the person is available at a time corresponding to the projected time of the transformed image, error analysis process  can compare the actual image with the transformed image. (Typically, the transformed image is stored in database  and later retrieved when the actual image is available. As an example, the results of every Nsubmitted image may be evaluated with respect to the actual image that is available after the projected time.) Error analysis process  then adjusts the model parameters in order to reduce an error measure (e.g., the error measure illustrated with ).",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 4","FIG. 1"],"b":["400","100","401","403","405","407","409","403","405","403","107","111","117","401","403","405","409"]},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 5","b":["536","545"]},"This mesh is associated to its corresponding texture from the picture where the alteration is taking place. The corners and four points along each side of the picture (as shown in  are also considered as part of the mesh. Computer graphics software API (Application Programming Interface) is used to render the altered image (e.g., as shown in ). OpenGL API is an example of computer graphics software that may be used to render the altered image.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 6","FIG. 6","FIG. 6"],"b":["600","606","618","631","600","606","618","631","600","606","618","631"]},{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 6","FIGS. 5-7"]},{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 7","FIG. 6","FIG. 6"],"b":["706","731","706","718","731","606","618","631","706","731","706","731"]},"In the following discussion that describes the determination of the deformation vectors for reshaping the face image, index i=6 to index i=31 correspond to points  to points , respectively. The determined deformation vectors are added to points  to points  to re-position the point, forming a transformed mesh. A reshaped image is consequently rendered using the transformed mesh.","In accordance with embodiments of the invention, deformation vector correspond to a product of four elements (factors):\n\n\u2003\u2003(EQ. 1)\n\nwhere A is the weight value factor, s is the scale factor, w is the deformation factor, and {right arrow over (u)} is the direction vector. In accordance with an embodiment of the invention:\n\n",{"@attributes":{"id":"p-0053","num":"0054"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"s","mo":"=","mfrac":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":"x","mn":"31"},{"mi":"x","mn":"6"}],"mo":"-"}},"mi":"B"}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"3"}}}]}}}},"ul":{"@attributes":{"id":"ul0003","list-style":"none"},"li":{"@attributes":{"id":"ul0003-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0004","list-style":"none"},"li":"Deformation factor [w]. It is calculated differently for different parts of cheeks and chin. One uses a different equation depending on which part of the face one is processing:"}}}},{"@attributes":{"id":"p-0054","num":"0056"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"i","mo":"\u2208","mrow":{"mo":["[","]"],"mrow":{"mn":["6","13"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mo":"\u2062","mrow":{"msub":{"mi":["w","i"]},"mo":"=","mrow":{"mrow":{"mfrac":[{"mn":["2","3"]},{"mn":"1","mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":"x","mn":"6"},{"mi":"x","mn":"13"}],"mo":"-"}}}],"mo":["\u2062","\u2062"],"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mrow":{"mi":"C","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}],"mo":"-"}}},"mo":"+","mfrac":{"mn":["1","3"]}}}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mstyle":[{"mtext":"EQ"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mo":[".","\u2062"],"mn":"4"},"mo":"\u2062","mstyle":{"mtext":"A"}}}}]},{"mtd":[{"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"i","mo":"\u2208","mrow":{"mo":["[","]"],"mrow":{"mn":["14","18"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mrow":{"msub":{"mi":["w","i"]},"mo":"=","mrow":{"mrow":{"mrow":{"mo":"-","mfrac":{"mn":"1","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":"x","mn":"13"},{"mi":"x","mn":"18"}],"mo":"-"}},"mn":"2"}}},"mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mrow":{"mi":"C","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}],"mo":"-"}},"mn":"2"}},"mo":"+","mn":"1"}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"4"},"mo":"\u2062","mi":"B"}}}]},{"mtd":[{"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"i","mo":"\u2208","mrow":{"mo":["[","]"],"mrow":{"mn":["19","23"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mrow":{"msub":{"mi":["w","i"]},"mo":"=","mrow":{"mrow":{"mrow":{"mo":"-","mfrac":{"mn":"1","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":"x","mn":"18"},{"mi":"x","mn":"24"}],"mo":"-"}},"mn":"2"}}},"mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mrow":{"mi":"C","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}],"mo":"-"}},"mn":"2"}},"mo":"+","mn":"1"}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"4"},"mo":"\u2062","mi":"C"}}}]},{"mtd":[{"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"i","mo":"\u2208","mrow":{"mo":["[","]"],"mrow":{"mn":["24","31"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mrow":{"msub":{"mi":["w","i"]},"mo":"=","mrow":{"mrow":{"mfrac":[{"mn":["2","3"]},{"mn":"1","mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":"x","mn":"24"},{"mi":"x","mn":"31"}],"mo":"-"}}}],"mo":["\u2062","\u2062"],"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mrow":{"mi":"C","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"}}],"mo":"-"}}},"mo":"+","mfrac":{"mn":["1","3"]}}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mstyle":[{"mtext":"EQ"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mo":[".","\u2062"],"mn":"4"},"mo":"\u2062","mstyle":{"mtext":"D"}}}}]}]}}},"ul":{"@attributes":{"id":"ul0005","list-style":"none"},"li":{"@attributes":{"id":"ul0005-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0006","list-style":"none"},"li":"Direction vector [{right arrow over (u)}]: It indicates the sense of the deformation. One calculates the direction vector it the ratio between: the difference (for each coordinate) between the center and our point, and the absolute distance between this center and our point. One uses two different centers in this process: center C (point  as shown in ) for the points belonging to the jaw and center C (point  as shown in ) for the points belonging to the cheeks."}}}},{"@attributes":{"id":"p-0055","num":"0058"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":{"mi":"i","mo":"\u2208","mrow":{"mo":["[","]"],"mrow":{"mn":["6","13"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}},"mo":"&"},{"mn":["24","31"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}],"mo":["\u2062","[","]"],"mstyle":{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mrow":{"msub":{"mover":{"mi":"u","mo":"->"},"mi":"i"},"mo":"=","mfrac":{"mrow":[{"msub":[{"mi":["x","i"]},{"mi":"x","mrow":{"mi":"C","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}],"mo":"-"},{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mrow":{"mi":"C","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}}],"mo":"-"}}]}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"5"},"mo":"\u2062","mi":"A"}}}]},{"mtd":[{"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"i","mo":"\u2208","mrow":{"mo":["[","]"],"mrow":{"mn":["14","23"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mo":"\u2062","mrow":{"msub":{"mover":{"mi":"u","mo":"->"},"mi":"i"},"mo":"=","mfrac":{"mrow":[{"msub":[{"mi":["x","i"]},{"mi":"x","mrow":{"mi":"C","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"}}],"mo":"-"},{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mrow":{"mi":"C","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"}}],"mo":"-"}}]}}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"5"},"mo":"\u2062","mi":"B"}}}]}]}}}},"Neck point-coordinates xare based on the lower part of the face, where",{"@attributes":{"id":"p-0057","num":"0060"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"i","mo":"\u2208","mrow":{"mo":["[","]"],"mrow":{"mn":["36","45"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mrow":{"mi":"j","mo":"\u2208","mrow":{"mo":["[","]"],"mrow":{"mn":["14","23"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mrow":{"msub":{"mi":["x","i"]},"mo":"=","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","j"]},"mo":",","mrow":{"msub":{"mi":["y","j"]},"mo":"+","mi":"neck_height"}}}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"6"}}}]},{"mtd":[{"mrow":{"mi":"neck_height","mo":"=","mfrac":{"mrow":{"msub":[{"mi":"y","mn":"18"},{"mi":"y","mn":"0"}],"mo":"-"},"mn":"6"}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"7"}}}]}]}}},"br":{},"sub":["18 ","0 "],"b":["618","600","536","545","714","723","536","545","536","545","714","723","714","723"],"figref":["FIG. 6","FIG. 5","FIG. 3"]},"The deformation vector ({right arrow over (v)}) applied at points  to  has two components:",{"@attributes":{"id":"p-0059","num":"0062"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"msub":{"mover":{"mi":"v","mo":"->"},"mrow":{"mi":["d","_","neck"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]}},"mo":"=","mrow":{"mo":["(",")"],"mrow":{"mn":"0","mo":",","msub":{"mi":"y","mrow":{"mi":["d","_","neck"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"8"}}}]},{"mtd":[{"mi":"when"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mtable":{"mtr":{"mtd":[{"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mn":"41"}],"mo":"<"}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mrow":{"msub":{"mi":"y","mrow":{"mi":["d","_"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"msub":{"mi":["neck","i"]}}},"mo":"=","mrow":{"mo":"-","mfrac":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mn":"18"}],"mo":"-"}},"mn":"2"},"mrow":{"mn":"10","mo":"\u00b7","mrow":{"mo":["(",")"],"mfrac":{"mrow":{"msub":[{"mi":"x","mn":"24"},{"mi":"x","mn":"13"}],"mo":"-"},"mn":"2"}}}}}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"9"},"mo":"\u2062","mi":"A"}}}]},{"mtd":[{"mi":"when"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mtable":{"mtr":{"mtd":[{"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mn":"41"}],"mo":"\u2265"}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mrow":{"msub":{"mi":"y","mrow":{"mi":["d","_","neck"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]}},"mo":"=","mfrac":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["x","i"]},{"mi":"x","mn":"18"}],"mo":"-"}},"mn":"2"},"mrow":{"mn":"10","mo":"\u00b7","msup":{"mrow":{"mo":["(",")"],"mfrac":{"mrow":{"msub":[{"mi":"x","mn":"24"},{"mi":"x","mn":"13"}],"mo":"-"},"mn":"2"}},"mn":"2"}}}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"9"},"mo":"\u2062","mi":"B"}}}]}]}}}},{"@attributes":{"id":"p-0060","num":"0063"},"figref":["FIG. 8","FIG. 7"],"b":["716","720","856","860","117","816","820","716","720","856","860"]},{"@attributes":{"id":"p-0061","num":"0064"},"figref":["FIG. 9","FIG. 8"],"b":["816","820","916","920","115","956","960"],"sub":"i"},{"@attributes":{"id":"p-0062","num":"0065"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"square_error","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","msup":{"mrow":{"msub":{"mi":["a","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["actual_vertex","transformed_vertex"],"mo":"-"}}},"mn":"2"}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"10"}}}]}}}}},"Each weight ais adjusted to reflect the relative importance of the vertex pair. (If a vertex pair is not included when determining the square error, the corresponding weight is set to zero. Thus, some or all of the vertices shown in  may be included in the error analysis.) The least square error may be determined by error analysis module  (as shown in ) by adjusting model parameters (e.g., constants in EQs. 1-5B) that corresponds to reduce the square error to a minimum.",{"@attributes":{"id":"p-0064","num":"0067"},"figref":"FIG. 10","b":["1001","1005"]},"With an embodiment of the invention, A=+100 corresponds to a maximum degree of fattening and A=\u2212100 corresponds to a maximum degree of thinning. The value of A is selected to provide the desired degree of fattening or thinning. For example, if a patient were afflicted anorexia, the value of A would have a negative value that would depend on the degree of affliction and on the medical history and body type of the patient. As another example, a patient may be over-eating or may have an unhealthy diet with many empty calories. In such a case, A would have a positive value. A medical practitioner may be able to gauge the value of A based on experience. However, embodiments of invention may support an automated implementation for determining the value of A. For example, an expert system may incorporate knowledge based on information provided by experienced medical practitioners.",{"@attributes":{"id":"p-0066","num":"0069"},"figref":"FIG. 11","b":["1101","1105","1101","1103"]},"With embodiments of the invention, medical imaging may be processed in order to determine effects of treatment on an organ. For example, a patient is being treated for pancreatitis (inflammation of pancreas). The doctor is prescribing the patient a drug and wants to compare the evolution of the patient's condition with expected results. The doctor uses ultrasound (or MRI) images to view the pancreas. A mesh is also utilized to track the contour of the pancreas to determine how the pancreas evolves. Feedback from the doctor and the evolution of the patient's condition are utilized to improve future predictions. Moreover, this approach may be extended so that pharmacologists can evaluate the tests of a new drug with the help of experts.",{"@attributes":{"id":"p-0068","num":"0071"},"figref":"FIG. 12","b":["1200","1201","1203"]},"In step  deformation vectors are determined and applied to points (e.g. points - as shown in ) on the face. For example, as discussed above, EQs. 1-5. are used to determine the relocated points. In step  deformation vectors are determined (e.g., using EQs. 6-9) and applied to points (e.g., points - as shown in ) on the neck. A transformed mesh is generated from which a reshaped image is rendered using computer graphics software in step .","While  illustrate embodiments of the invention for fattening and thinning a person's face, embodiments of the invention support other types of transformations. For example, not only may vertices of a mesh be transformed to reshape the face, texture components (e.g., wrinkling of the skin associated with aging) may also be transformed. Also, hair attributes (e.g., graying and balding) may be included when forming a transformed image by adding artificial synthetic elements. Other image transformations that may be considered are: texture, pattern and color. Moreover, slight perspective changes may be applied to some of the objects in the images (e.g., face) to rectify the point of view in which the picture has been taken and the point of view in which the transformation model was trained. More than one image may be evaluated at a time if those images give different views from the same face, organ or object (e.g., one can evaluate the evolution of a face from a frontal and a side perspective).",{"@attributes":{"id":"p-0071","num":"0074"},"figref":"FIG. 13","b":["1","1","1","10","12","14","12","10","14","12"]},"Computer  may also include a variety of interface units and drives for reading and writing data. In particular, computer  includes a hard disk interface  and a removable memory interface  respectively coupling a hard disk drive  and a removable memory drive  to system bus . Examples of removable memory drives include magnetic disk drives and optical disk drives. The drives and their associated computer-readable media, such as a floppy disk  provide nonvolatile storage of computer readable instructions, data structures, program modules and other data for computer . A single hard disk drive  and a single removable memory drive  are shown for illustration purposes only and with the understanding that computer  may include several of such drives. Furthermore, computer  may include drives for interfacing with other types of computer readable media.","A user can interact with computer  with a variety of input devices.  shows a serial port interface  coupling a keyboard  and a pointing device  to system bus . Pointing device  may be implemented with a mouse, track ball, pen device, or similar device. Of course one or more other input devices (not shown) such as a joystick, game pad, satellite dish, scanner, touch sensitive screen or the like may be connected to computer .","Computer  may include additional interfaces for connecting devices to system bus .  shows a universal serial bus (USB) interface  coupling a video or digital camera  to system bus . An IEEE 1394 interface  may be used to couple additional devices to computer . Furthermore, interface  may configured to operate with particular manufacture interfaces such as FireWire developed by Apple Computer and i.Link developed by Sony. Input devices may also be coupled to system bus  through a parallel port, a game port, a PCI board or any other interface used to couple and input device to a computer.","Computer  also includes a video adapter  coupling a display device  to system bus . Display device  may include a cathode ray tube (CRT), liquid crystal display (LCD), field emission display (FED), plasma display or any other device that produces an image that is viewable by the user. Additional output devices, such as a printing device (not shown), may be connected to computer .","Sound can be recorded and reproduced with a microphone  and a speaker . A sound card  may be used to couple microphone  and speaker  to system bus . One skilled in the art will appreciate that the device connections shown in  are for illustration purposes only and that several of the peripheral devices could be coupled to system bus  via alternative interfaces. For example, video camera  could be connected to IEEE 1394 interface  and pointing device  could be connected to USB interface .","Computer  can operate in a networked environment using logical connections to one or more remote computers or other devices, such as a server, a router, a network personal computer, a peer device or other common network node, a wireless telephone or wireless personal digital assistant. Computer  includes a network interface  that couples system bus  to a local area network (LAN) . Networking environments are commonplace in offices, enterprise-wide computer networks and home computer systems.","A wide area network (WAN) , such as the Internet, can also be accessed by computer .  shows a modem unit  connected to serial port interface  and to WAN . Modem unit  may be located within or external to computer  and may be any type of conventional modem such as a cable modem or a satellite modem. LAN  may also be used to connect to WAN .  shows a router  that may connect LAN  to WAN  in a conventional manner.","It will be appreciated that the network connections shown are exemplary and other ways of establishing a communications link between the computers can be used. The existence of any of various well-known protocols, such as TCP\/IP, Frame Relay, Ethernet, FTP, HTTP and the like, is presumed, and computer  can be operated in a client-server configuration to permit a user to retrieve web pages from a web-based server. Furthermore, any of various conventional web browsers can be used to display and manipulate data on web pages.","The operation of computer  can be controlled by a variety of different program modules. Examples of program modules are routines, programs, objects, components, and data structures that perform particular tasks or implement particular abstract data types. The present invention may also be practiced with other computer system configurations, including hand-held devices, multiprocessor systems, microprocessor-based or programmable consumer electronics, network PCS, minicomputers, mainframe computers, personal digital assistants and the like. Furthermore, the invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote memory storage devices.","In an embodiment of the invention, central processor unit  obtains a face image from digital camera . A user may view the face image on display device  and enter points (e.g., points - as shown in ) to form a mesh that is subsequently altered by central processor  as discussed above. The user may identify the points with a pointer device (e.g. mouse ) that is displayed on display device , which overlays the mesh over the face image. With embodiments of the invention, a face image may be stored and retrieved from hard disk drive  or removable memory drive  or obtained from an external server (not shown) through LAN  or WAN .","As can be appreciated by one skilled in the art, a computer system (e.g., computer  as shown in ) with an associated computer-readable medium containing instructions for controlling the computer system may be utilized to implement the exemplary embodiments that are disclosed herein. The computer system may include at least one computer such as a microprocessor, a cluster of microprocessors, a mainframe, and networked workstations.","While the invention has been described with respect to specific examples including presently preferred modes of carrying out the invention, those skilled in the art will appreciate that there are numerous variations and permutations of the above described systems and techniques that fall within the spirit and scope of the invention as set forth in the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example and not limited in the accompanying figures in which like reference numerals indicate similar elements and in which:",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
