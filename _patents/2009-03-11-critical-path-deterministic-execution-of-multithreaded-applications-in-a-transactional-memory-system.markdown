---
title: Critical path deterministic execution of multithreaded applications in a transactional memory system
abstract: A hardware and/or software facility for controlling the order of operations performed by threads of a multithreaded application on a multiprocessing system is provided. The facility may serialize or selectively-serialize execution of the multithreaded application such that, given the same input to the multithreaded application, the multiprocessing system deterministically interleaves operations, thereby producing the same output each time the multithreaded application is executed. The facility divides the execution of the multithreaded application code into two or more quantum specifying a deterministic number of operations, and the facility specifies a deterministic order in which the threads execute the two or more quantum. The deterministic number of operations may be adapted to follow the critical path of the multithreaded application. Specified memory operations may be executed regardless of the deterministic order, such as those accessing provably local data. The facility may provide dynamic bug avoidance and sharing of identified bug information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08739163&OS=08739163&RS=08739163
owner: University of Washington
number: 08739163
owner_city: Seattle
owner_country: US
publication_date: 20090311
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED APPLICATIONS","BACKGROUND","DETAILED DESCRIPTION"],"p":["This application claims priority to U.S. Provisional Patent Application No. 61\/035,490 entitled \u201cA METHOD FOR EFFICIENT DETERMINISTIC MULTITHREADING,\u201d filed on Mar. 11, 2008, which is hereby incorporated by reference. This application is related to U.S. patent application Ser. No. 12\/334,336 entitled \u201cDETERMINISTIC MULTIPROCESSING,\u201d filed on Dec. 12, 2008, which claims priority to U.S. Provisional Patent Application No. 61\/013,019 entitled \u201cDETERMINISTIC MULTIPROCESSING,\u201d filed on Dec. 12, 2007, which are hereby incorporated by reference.","Multiprocessing is a mode of operation in which two or more processing units each carry out one or more processes (programs or sets of instructions) in tandem. The objective of a multiprocessing system is to increase processing speed. Typically, this is accomplished by each processing unit operating on a different set of instructions or on different threads of the same process. A process may execute one or more threads. Each thread has it own processor context, including its own program context. Traditionally, for an application to take advantage of the benefits of multiprocessing, a software developer must write the application to be multithreaded. As used herein, a multithreaded application refers to a program capable of running two or more threads simultaneously.","On a multiprocessor or multi-core system (collectively referred to herein as a \u201cmultiprocessing system\u201d), two or more of the threads of a multithreaded application may be able to execute at the same time, with each processor or core running a particular thread. It is common for threads of a multithreaded application to share resources during concurrent execution, such as, for example, memory. As used herein, concurrent execution refers to the simultaneous execution of two or more threads of a multithreaded application. A consequence of concurrent execution is that two or more threads of a multithreaded application may read and\/or update the same shared resource. For example, one thread may modify a value of a shared memory location while another thread executes a sequence of operations that depend on the value stored in the shared memory location.","Under the traditional software development model, software developers spend a substantial amount of time identifying and attempting to correctly synchronize parallel threads within their multithreaded applications. For example, a developer may explicitly use locks, semaphores, barriers, or other synchronization mechanisms to control access to a shared resource. When a thread accesses the shared resource, the synchronization mechanism prevents other threads from accessing the resource by suspending those threads until the resource becomes available. Software developers who explicitly implement synchronization mechanisms also typically spend a substantial amount of time debugging their synchronization code. However, software defects (referred to as \u201cbugs\u201d) resulting from synchronization errors typically manifest themselves transiently (i.e., a bug may appear only on a particular sequence or sequences of interleaved thread operations). As a result, defective software might execute correctly hundreds of times before a subtle synchronization bug appears.","It is difficult to develop software for multiprocessing systems because of the nondeterministic behavior created by the various interleaving of threads on such systems. An interleaving refers to an order of thread operations that may include interaction between threads. The number of possible interleavings between threads significantly increases as the number of threads increase. Consequently, multithreaded applications present additional challenges in terms of error detection and modeling program behavior. For example, given the same input to a multithreaded application, a multiprocessing system will interleave thread operations nondeterministically, thereby producing different output each time the multithreaded application is executed.  is a high-level diagram showing an example of two possible thread interleavings in a multithreaded application executed on a multiprocessing system. As illustrated, the application includes at least two threads: thread  and thread . When the application is invoked, at some point in time, thread  executes an operation settings the value of variable A to one (A=1) followed by an operation settings the value of variable B to the value of variable A (B=A), and thread  executes an operation settings the value of variable B to zero (B=0) followed by an operation settings the value of variable A to the value of variable B (A=B). As illustrated, the operations of thread  and thread  are interleaved nondeterministically, thereby producing different output each time the application is invoked. That is, during the first illustrated invocation, the interleaving of operations resulted in variables A and B each being set to zero, while during the second illustrated invocation, the interleaving of operations resulted in variables A and B each being set to one.","Non-determinism in multithreaded execution may arise from small changes in the execution environment, such as, for example, other processes executing simultaneously, differences in the operating system resource allocation, the state of caches, translation lookaside buffers (\u201cTLBs\u201d), buses, interrupts, and other microarchitectural structures. As a result, developing a multithreaded application is significantly more difficult than developing a single-threaded application.","Conventionally, efforts in addressing this problem have focused on deterministically replaying multithreaded execution based on a previously generated log file. However, deterministic replay systems suffer substantial performance degradation as a result of the overhead associated with maintaining the replay log file. Moreover, with deterministic replay, a software developer does not have control over how the interleaving of threads is performed. As a result, synchronization bugs resulting from particular interleavings of operations may not be identified (and, more importantly, corrected) before the software is deployed to a customer. Non-determinism further complicates the software development process in that non-determinism makes it hard to assess test coverage. Good coverage requires both a wide range of program inputs and a wide range of possible thread interleavings.","Conventional systems, such as deterministic replay systems, do not adequately resolve the problems associated with the nondeterministic behavior in the development of multithreaded applications. Additionally, no existing systems reduce or attempt to resolve the problems associated with nondeterministic behavior in the deployment of multithreaded applications. Accordingly, a hardware and\/or software facility for deterministic multiprocessing of multithreaded applications (\u201cthe facility\u201d) has been developed. As used herein, the term deterministic multiprocessing refers to a technique by which given the same input to a multithreaded application, the same output is produced by the multithreaded application. The facility simplifies the process of developing multithreaded applications, for example, by freeing developers from the burden of synchronizing thread accesses to shared resources. Additionally, the facility improves the reliability of such multithreaded applications when they are deployed, for example, by enabling developers to reproduce bugs and rigorously test various thread interleavings.","In some embodiments, the facility divides execution of a multithreaded application into sets of a finite, deterministic number of operations (each set is referred to herein as a \u201cquantum\u201d). When identifying quanta, the facility may distinguish between operations that can be performed concurrently, such as communication-free thread operations, and operations that are to be performed in a deterministic order, such as inter-thread communications, system calls, and so on. Each quantum identified by the facility is then performed in a deterministic order. By controlling the order in which quanta are executed by threads of a multithreaded application, the facility enables the multithreaded application to behave deterministically. That is, given the same input, threads of the multithreaded application interleave their operations deterministically, thereby providing the same output. In some embodiments, the quanta size (i.e., the predefined number of operations) varies between threads, while in other embodiments, the quanta size is uniform.","In some embodiments, the facility serializes execution of a multithreaded application. That is, the facility may control the global interleaving of all thread operations. For example, this may be accomplished by establishing a memory access token that is passed in a deterministic order between threads when a quantum boundary is reached. A thread may be referred to as \u201cholding\u201d the token when the value of the token matches the identifier of that thread. When the value of the token does not match the identifier of a thread, its execution is suspended until the value of the token matches the identifier of the thread. When the value of the token matches the identifier of a thread, the thread performs a finite, deterministic number of operations (i.e., a quantum) before the token is passed to the next thread. The token may be passed to the next thread, for example, by advancing the value of the token to correspond to the identifier of the next thread in the deterministic order.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 2","b":["200","200","205","215","205","210","205","210","215","215","205","200"]},"Those skilled in the art will appreciate that the steps shown in  and in each of the following flow diagrams may be altered in a variety of ways. For example, the order of certain steps may be rearranged; certain sub-steps may be performed in parallel; certain shown steps may be omitted; or other steps may be included; etc.","In some embodiments, the facility selectively serializes execution of a multithreaded application. That is, the facility may control the interleaving of certain thread operations (referred to herein as \u201ccontrolled operations\u201d), while other thread operations are performed concurrently. For example, the facility may control the interleaving of operations that involve communication between two or more threads. Inter-thread communication occurs when a thread reads data that is privately held by another thread or when a thread writes to shared data thereby privatizing it. In some embodiments, when a thread attempts to read data that is regarded as privately held by another thread, the thread suspends its execution until the value of the token matches its identifier and all other threads reach a deterministic point in their execution (e.g., complete execution of a quantum, are blocked, etc.). Similarly, in some embodiments, when a thread attempts to write to data that is shared or regarded as privately held by another thread, it suspends its execution until the value of the token matches its identifier and all other threads reach a deterministic point in their execution. As a result, the facility ensures that all threads observe the change in state of the data (from shared to privately held by the thread) at a deterministic point in their execution.","In some embodiments, to detect inter-thread communication, the facility maintains a shared-memory data structure that includes sharing information for each memory location in the address space of the multithreaded application. For example, such information may indicate that a memory location is shared, private, etc. It is noted that sharing may occur at different levels, such as the operation-level, instruction-level, page-level, and so on. In some embodiments, a thread may access its own privately held data or read shared data without holding the token. However, to write to shared data or to read data that is held as private by another thread, the thread waits until it holds the token and all other threads reach a deterministic point in their execution. When a thread reads a memory location that is regarded as private by another thread, the shared-memory data structure is updated to indicate that the read memory location is to be regarded as shared. When a thread writes to a memory location, the shared-memory data structure is updated to indicate that the memory location is to be regarded as privately held by that thread. Similarly, when a thread reads a memory location that has not been previously accessed by another thread, the shared-memory data structure is updated to indicate that the memory location is to be regarded as privately held by that thread.","In some embodiments, the facility implements a shared-memory data structure as a sharing table.  is a high level block diagram showing a sharing table  in some embodiments. Sharing table  maintains sharing information for each memory location  in the address space of a multithreaded application. It is noted that sharing may occur at different levels, such as the operation-level, instruction-level, page-level, and so on. Sharing table  includes a shared data field  that, for each memory location , identifies two or more threads that have accessed the data stored at that location. For example, in the illustrated embodiment, shared data field  indicates that the data stored at memory location B has been accessed by thread , thread , and thread . Sharing table  includes a private data field  that, for each memory location , identifies the thread for which the data stored at that location is regarded as private. For example, in the illustrated embodiment, private data field  indicates that memory locations A and C store data that is regarded as private to thread .","Those skilled in the art will appreciate that the facility may implement a shared-memory data structure in a variety of forms. For example, in some embodiments, the shared-memory data structure is implemented as a bit mask that, for each memory location, identifies all threads that have accessed that memory location.  is a high level block diagram showing thread masks  for each memory location  in the address space of a multithreaded application in one or more embodiments. A memory location  is regarded as private when its corresponding thread mask  identifies a single thread . For example, memory location A and memory location C are regarded as private to thread  because their corresponding masks and identify only thread . A memory location  is regarded as shared when its corresponding thread mask  identifies two or more thread . For example, memory location B is regarded as shared because its corresponding thread mask identifies thread , thread , and thread. It is noted that the number of threads  may vary between applications and\/or the states of an application. As such, the example of eight threads, as shown in the illustrated embodiment, should not be taken as restrictive.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 3","b":["300","300","305","325","310","310","315","355","315","320","325","320","325","355","325","330","325","330","335","330","335","355","340","340","345","350","345","355","350","355","355"]},"In some embodiments, the facility operates together with a transactional memory system to serialize or selectively serialize execution of a multithreaded application. For example, the facility may use the transactional memory system to detect inter-thread communication that would violate the deterministic ordering of memory operations. That is, the transactional memory system may be used instead of, or in addition to, the shared-memory data structure. It is noted that the transactional memory system may be a hardware transactional memory (HTM) system, a software transactional memory (STM) system, or a hybrid hardware-software transactional memory system (HS-TM). When operating together with a transactional memory system, the facility encapsulates each quantum executed by a thread within a transaction. By encapsulating each quantum within a transaction, the threads appear to execute atomically and in isolation. As a result, transactions may be executed concurrently, and then committed according to a deterministic order. That is, the TM system commits a transaction when a thread holds the token and, after the transaction is committed, the token is passed to the next thread in the deterministic order. It is noted that, in some embodiments, the facility supports multiple tokens, thereby allowing multiple deterministic processes to execute at the same time, each process specifying a token that is passed between threads within each process. A transaction is typically not committed if the transaction includes an inter-thread communication that would violate the deterministic ordering (referred to herein as a \u201cconflict\u201d). When a conflict exists, the transaction may be aborted and restarted.","In some embodiments, the facility includes a quantum builder component and a deterministic multiprocessing (\u201cDMP\u201d) component. For example,  are high-level block diagrams showing various functional elements of a deterministic multiprocessing system  in some embodiments.  illustrates a DMP system that includes a quantum builder component  and a DMP component . The quantum builder component  is used to divide execution of a multithreaded application into quanta (i.e., sets of a finite, deterministic number of operations). In some embodiments, the quantum builder  component distinguishes between operations that may be performed concurrently, such as communication-free thread operations, and operations that are to be performed in a deterministic order (e.g., controlled operations), such as inter-thread communications, system calls, and so on. The DMP component  ensures that each quantum is performed according to a deterministic order. For example, to serialize execution of a multithreaded application, the DMP component  may implement a token that is passed between threads in a deterministic order when a quantum boundary is reached. As another example, to selectively serialize execution of a multithreaded application, the DMP component  may implement a shared-memory data structure that is used to determine whether a thread is permitted to execute an operation without holding the token.  illustrates a DMP system that includes a shared memory data structure . As yet another example, a transactional memory system may be used instead of, or in addition to, the shared-memory data structure .  illustrates a DMP system that includes a transactional memory system , which may operate together with the quantum builder component  and the DMP component  to serialize or selectively serialize execution of a multithreaded application. The transactional memory system  may be a hardware transactional memory (HTM) system, a software transactional memory (STM) system, or a hybrid hardware-software transactional memory system (HS-TM).","In some embodiments, when the token is advanced to a thread that is blocked (e.g. waiting for a lock held by another thread), the facility passes the token to the next thread, thereby avoiding livelock resulting from blocking synchronization primitives that a developer included within the multithreaded code. For example, if thread  holds a lock that thread  requires to proceed at the time that the token is passed to thread , then the token is passed to the next thread (e.g., thread ), and so on. Because the token is passed in a deterministic order, and because each thread executes a quantum (or passes the token), the quanta are interleaved deterministically, thereby preventing livelock and producing the same output each time the code is executed with the same input.","The quantum builder component  and DMP component  may be implemented in hardware, software, or a combination of hardware and software. For example, the quantum builder component  may be implemented by counting instructions as they retire and placing a quantum boundary when the predetermined quantum size is reached. To serialize execution, the DMP component  may be implemented as a token that is passed between processors at a quantum boundary in a deterministic order. As another example, to selectively serialize execution, the quantum builder component  may monitor memory accesses to determine whether an access involves inter-thread communication (e.g., access to shared data, etc.). In one embodiment, the DMP component  uses a cache line state maintained by a MESI (\u201cModify, Exclusive Share, Invalidate\u201d) cache coherence protocol to implement a shared-memory data structure . A cache line in an exclusive or modified state is regarded as privately held by a processor, and can be freely read or written by its owner thread without holding the token. Similarly, a cache line in a shared state may be freely read by its owner thread without holding the token. The processor may write to a cache line in a shared state when all threads are at a deterministic point in their execution (e.g., when all processors are blocked or reach a quantum boundary) and when the processor acquires the deterministic token. In such embodiments, each processor broadcasts when it is blocked and\/or when it is unblocked. It is noted that the state of entries in the shared-memory data structure  corresponding to lines that are not cached by any processor may be kept in memory and managed by a memory controller, and that the state of such entries may be transferred when cache misses are serviced.","In some embodiments, the facility may be implemented using a compiler or a binary rewriting infrastructure. For example, the quantum builder component  may use a compiler to build quanta by inserting synchronization code within multithreaded application code to track operations in the control-flow-graph (\u201cCFG\u201d) generated by the complier. It is noted that quanta need not be of uniform size as long as the size is deterministic. Such synchronization code may be inserted, for example, at the beginning and end of function calls, and at the tail end of CFG back edges. The inserted code tracks quantum size and when the target size has been reached, it calls back to the DMP component . In some embodiments, the facility augments source code, an intermediate representation of source code, or an executable. In some embodiments, the inserted code includes one or more deterministic multiprocessing (\u201cDMP\u201d) functions and\/or data structures. The inserted DMP functions may call back to a runtime system, which may be provided by a DMP component , which maintains one or more data structures (e.g., a shared-memory data structure ). When the augmented code is executed by a multiprocessing system, the inserted DMP functions and data structures are then used to control the order in which operations are performed, such as memory and I\/O operations, system calls, and so on. By controlling the order in which threads perform such operations, the facility enables the multithreaded application to behave deterministically. That is, given the same input, threads of a multithreaded application may interleave some or all of their operations deterministically, thereby providing the same output. Those skilled in the art will appreciate that the facility may be extended to control other thread operations.","In some embodiments, after the code is augmented, a compiler re-optimizes the code, such as, for example, inlining all calls to the DMP library. Those skilled in the art will appreciate that the compiler may perform other optimizations to the augmented code not specifically described herein.","In some embodiments, a multithreaded application is divided into quanta by counting instructions and establishing a quantum boundary when a predetermined number of operations is reached. In some embodiments, an adaptive quanta building technique is employed to account for the fact that threads typically do not progress at the same rate and to thereby improve the threads' progress on the critical path of execution of a multithreaded application. That is, each thread may have a different, yet deterministic, quantum boundary.  is a flow diagram showing an adaptive quanta process  performed by the facility in one or more embodiments. In some embodiments, the process  is performed by the facility while a thread holding the token executes a quantum having a finite, predefined number of memory operations. In steps -, the facility loops through each memory operation of the quantum to determine whether to adapt the quantum boundary and thereby improve performance of the critical path of execution of a multithreaded application. In step , the facility selects a memory operation of the quantum.","In step , the facility evaluates application-level synchronization information relating to the critical path of the multithreaded application. In some embodiments, the facility evaluates application-level synchronization information to determine whether another thread is likely the critical path thread. For example, such information may include an indication of whether the selected memory operation results in the thread holding the token releasing an application-level lock. The rationale is that, when the thread holding the token releases an application-level lock, other threads might be spinning waiting for that lock. As another example, such information may include an indication of whether another thread has started to spin on an application-level lock. The facility evaluates the application-level synchronization information to determine whether the token should be advanced forward as early as possible to allow a waiting thread to make progress. In some embodiments, a compiler or binary rewriting tool is used to insert a call back to the DMP component to notify the facility when a thread releases, or starts to spin on, an application-level lock. In some embodiments, hardware is used to monitor for changes in application-level synchronization information. For example, typically special instructions are used to implement locks (e.g., lock prefix instructions, load linked\/store conditional, test\/test&set instructions, etc.). As another example, the hardware may offer special instructions that software uses to indicate when locks are being released\/acquired.","In step , the facility evaluates shared memory information. In some embodiments, the facility evaluates shared memory information to determine whether the thread holding the token has potentially completed work on shared data such that the token may be advanced to the next thread. For example, such information may include an indication of whether a predetermined threshold has elapsed (e.g., time period, number of instructions, etc.) in which the thread holding the token has not issued a memory operation to shared memory. The rationale is that, when the thread holding the token is working on shared data, it is expected that other threads will access that data soon. By ending a quantum early and passing the token, another thread will potentially consume the data earlier than if the quantum is completed. In some embodiments, the predetermined threshold is measured as a finite number of operations, such as, for example, 30 memory operations. In some embodiments, the facility uses a shared-memory data structure to track the number of accesses made to shared memory by the thread holding the token and then compares that number to one or more predefined thresholds. In some embodiments, the facility implements a shared memory monitor that notifies the facility when a predefined threshold elapses.","In step , if the facility determines that another thread is likely the critical path thread based on the information evaluated in steps -, then the facility continues to step , else the facility continues to step . In step , if additional memory operations within the quantum remain, then the facility loops back to step , else the process  completes.","In step , the facility ends the quantum without reaching the original quantum boundary. It is noted that under some circumstances, the facility's determination to end a quantum boundary may actually coincide with the last operation of the quantum (i.e., the original quantum boundary). That is, if in step  the facility determines that another thread is likely the critical thread and no memory operations remain within the quantum, then the facility may in fact end the quantum in step  at the original quantum boundary.","In step , the facility advances the token to the next thread according to the deterministic order, and then the process  completes. In some embodiments, prior to ending the quantum, the facility issues a barrier instruction that causes the thread holding the token to perform a memory fence at the edge of the new quantum boundary, where inter-thread communication occurs. A memory fence is an instruction that causes a processor to enforce an ordering constraint on memory operations issued before and after the barrier instruction. By issuing a barrier instruction, the facility guarantees that all memory operations executed by the thread holding the token are completed before the token is advanced to the next thread. As a result, changes to memory caused by the thread holding the token to memory become visible to all of the threads of the multithreaded application. It is noted that, even if the facility ends a quantum as a result of information that a particular thread began to spin on an application-level lock, the facility does not advance the token to that thread unless it corresponds to the next thread in the deterministic order.","Those skilled in the art will appreciate that the information evaluated by the facility to determine whether to end a quantum may include other types of information relating to the thread holding the token, the selected memory operation, DMP and\/or application-level synchronization information, shared memory information, and so on. For example, in some embodiments, when the selected memory operation is a system call that does not include inter-thread communication via shared memory, the facility ends the quantum and advances the token to the next thread prior to the system call. The rationale is that system calls typically take a longer amount of time to complete and may not require the token. As a result, by ending the quantum and advancing the token to the next thread before the system call is invoked, the facility provides another thread with the opportunity to make progress earlier than if the quantum completed.","In some embodiments, the facility recovers parallelism and reduces the overhead associated with accessing a shared-memory data structure by identifying memory operations that access locations that are provably local to a single thread and\/or memory locations within a single quantum that must alias.  is a flow diagram of a process  performed by the facility to reduce the overhead associated with accessing a shared memory data structure in one or more embodiments. In step , the facility obtains the code of a multithreaded application, then continues to step . For example, this may include reading the binary form of the multithreaded application code from the source file. As another example, this may include a compiler or a binary rewriting tool translating a binary form of the multithreaded application into an intermediate form, such as a control flow graph. Control flow graphs are representations of program execution that specify operations as nodes of a graph.","In step , the facility identifies memory operations of the multithreaded application that are guaranteed to be local to a single thread of the multithreaded application (i.e., \u201cprovably local\u201d during code generation), then the facility continues to step . In some embodiments, the facility uses escape analysis to identify memory operations that access provably local data. When data is allocated in a function and the function returns a pointer to that data, the data is said to \u201cescape\u201d to other threads of execution or to the calling function. Data can also escape if it is stored in a global variable or other data structure that, in turn, escapes the current function or thread of execution.","In steps -, the facility loops through each quantum of the multithreaded application code. In step , the facility selects a quantum, then continues to step . In step , if the facility determines that two or more memory operations within the selected quantum point to the same memory location (i.e., that the memory operations \u201cmust alias\u201d), then the facility continues to step , else continues to step . For example, memory operations must alias if both the base addresses and the offsets are the same. In steps -, the facility loops through each group of memory operations that must alias within the selected quantum. In step , the facility selects a group of memory operations that must alias within the selected quantum, then continues to step . In step , the facility identifies each memory operation that is subsequent to the first memory within the selected quantum that must alias the first memory operation, then the facility continues to step . In step , if additional groups remain, then the facility loops back to step , else the facility continues to step . In step , if additional quantum remain, then the facility loops back to step , else the facility continues to step . In step , the facility inserts code to track memory operations other than the memory operations identified in steps  (i.e., memory operations accessing data that is provably local) and\/or  (i.e., memory operations within a quantum that must alias to an earlier memory operation within the same quantum), then the process  ends. By accessing the shared-memory data structure once per data item per quantum and by not requiring a thread to hold the token to access its provably local data, the facility recovers parallelism and reduces the overhead associated with checking the shared-memory data structure.","In some embodiments, the facility includes a binary rewriting tool to profile a multithreaded application as it executes to identify memory operations that are local to a single thread. For example, the binary rewriting tool may profile a multithreaded application by instrumenting the application executable to monitor the state of a shared-memory data structure. Memory locations accessed by a single thread during execution of the multithreaded application may be identified as local. When the profiling information is stable across multiple executions, the identified memory operations may be performed without requiring a thread to hold the token. However, it is noted that this technique may not provide full determinism, since the profiling pass reflects a particular execution of the multithreaded application.","In some embodiments, the facility includes a DMP data structure, referred to herein as a \u201cthread data structure,\u201d the details of which are discussed below in connection with . However, it is noted that any number of DMP data structures may be included. It is further noted that the thread data structure may represent multiple DMP data structures. In some embodiments, the thread data structure stores a thread identifier (\u201cID\u201d) corresponding to each thread that is created by the multithreaded application during execution. For example, the thread data structure may include an array, linked list, a queue or other data structure of thread IDs (referred to herein as a \u201cthread container\u201d).","In some embodiments, the thread data structure includes a token that may be used to control the order of quantum execution. For example, in some embodiments, prior to executing a quantum, a thread determines whether the current value of the token matches the ID of the thread. When the ID of a thread matches current value of the token, the thread may execute the quantum. Otherwise, the thread waits to execute the quantum until the current value of the token matches its identifier.","In some embodiments, the order in which threads are created corresponds to the order in which the threads are deterministically executed. For example, as each thread is created, the thread's corresponding thread ID may be sequentially stored in the thread container (e.g., a thread ID of 1 for the first-created thread; a thread ID of 2 for the second-created thread; etc.). As operations are executed, the threads may invoke certain DMP functions that operate to advance the value of the token by sequentially looping through the thread IDs stored in the thread container based on the sequence in which the thread IDs were stored (beginning with the first thread ID). It is noted that, when a thread exits, the thread's corresponding ID is typically removed from the thread container.","In some embodiments, the thread data structure stores a value corresponding to a finite, deterministic number (i.e., quantum) of controlled operations or blocks that may be executed by a thread whose thread ID matches the current value of the token before the token is advanced. This number of controlled operations or blocks is referred to herein as the \u201ccommit block size.\u201d The commit block size may range from one to N controlled operations or blocks. Those skilled in the art will appreciate that there are performance tradeoffs associated both large and small commit block sizes. For example, when the commit block size is too small, the performance of the multithreaded application will suffer as a result of the overhead associated with context switches between threads. As another example, when the commit block size is too large, the performance of the multithreaded application will suffer because many or all threads may be forced to wait for the thread whose thread ID matches the token (and every thread whose thread ID precedes its thread ID) to exit actually execute the number of controlled operations specified by commit block size. In at least one embodiment, the commit block size is equal to one thousand (10,000).","In some embodiment, the commit block size is configurable. For example, the commit block size may be configured by a software developer to programmatically manipulate and test the various thread interleavings of a multithreaded application. As another example, the commit block size may be automatically configured based on the maximum number of threads that may be created by the multithreaded application and\/or the number of processor or cores of the multiprocessing system on which the multithreaded application executes. Those skilled in the art will appreciate that a variety of techniques may be used to count the number of controlled operations performed by a thread. For example, in some embodiments, the thread data structure includes a value corresponding to the number of controlled operations that have been performed by a thread whose thread ID matches the current token ID. Each time the thread performs a controlled operation, the number of controlled operations in incremented, and the compared to the commit block size. If the number of controlled operation equals the commit block size, then the token is advanced to the next thread ID, and the number of controlled operations is reset to zero.","By augmenting a multithreaded application to control the ordering of certain thread operations (such as, e.g., controlled thread operations), the development process is substantially simplified. For example, the facility can be used by a software developer to directly manipulate thread interleavings of a multithreaded application, thereby allowing for substantially better test coverage of the multithreaded application. A developer may manipulate the interleavings of controlled thread operations, for example, by modifying the commit block size. As another example, a developer may manipulate the interleavings of controlled thread operations by modifying the deterministic order in which the threads execute. In some embodiments, the facility enables a software developer to mark code as being inserted for augmentation purposes, such that the inserted code will not affect quantum building.","In some embodiments, the facility provides a bug finder web service to which software developers may submit their applications for testing.  is a high-level data flow diagram showing a bug finder web service  in some embodiments. In the illustrated embodiment, the bug finder web service  receives a request from a software developer using a computer  via a network , such as the Internet or a local area network. In some embodiments, the request includes a copy of a multithreaded application  to be tested. For example, the request may include a multithreaded application binary. As another example, the request may include source code of a multithreaded application. In some embodiments, the request includes an indication of a location at which a copy of the multithreaded application  may be retrieved. In some embodiments, the request includes a test suite  with which the application is to be tested.","In some embodiments, in response to receiving a request to test a multithreaded application , the bug finder web service  dispatches the request to a multiprocessing system . The multiprocessing system  includes a deterministic multiprocessing (DMP) system , such as DMP system , that is used to deterministically control execution of the multithreaded application under test (MUT)  and to programmatically test the various thread interleavings of a MUT . In some embodiments, the multiprocessing system  includes a test suite  that is used to test the MUT . For example, the test suite  may include one or more inputs and the expected corresponding output. As another example, the test suite  may include one or more automated scripts that simulate user interaction with the MUT . In some embodiments, the MUT  is executed directly on the multiprocessing system . In some embodiments, the MUT  is executed within a virtual machine executing on the multiprocessing system.","In some embodiments, the multiprocessing system  include a bug logging component . The bug logging component  may observe when a MUT  produces an incorrect output for a specified input and\/or when a MUT  crashes. When a MUT  produces an incorrect output or crashes, the bug logging component  determines the source of the bug that produced the incorrect output or crash (e.g., one or more shared memory accesses for a particular deterministic thread order). The bug logging component  then stores the determined source of the bug in a bug log. In some embodiments, the bug log is stored in a data store . The data store  may include a copy of the MUT  or an indication of a location at which a copy of the MUT  may be located (e.g., the multiprocessing system  on which the MUT  was tested). The data store  may include a test suite  or an indication of a location at which the test suit  may be located. The data store  may include other information, such as account information associated with the software developer or vendor of the MUT .","In some embodiments, the bug finder web service  is provided as a free service. That is, the bug finder web service  tests a multithreaded application  without charging the software developer. In some embodiments, the bug finder web service  tests a multithreaded application  based upon a paid time-based subscription, or in exchange for a per-testing cycle charge.","In some embodiments, the bug finder web service  operates in accordance with the following business model. It sends a message to the software developer indicating the test results. When no bugs are identified in the MUT , the bug finder web service  sends a message to the software developer indicating that no bugs were identified in the MUT . When bugs are identified, the bug finder web service  send a message to the software developer indicating that bugs were identified. In some embodiments, the message includes an offer to sell the identification of the bugs to the software developer for a fee. For example, the fee may be based on the number of bugs identified, a flat fee, etc. If the software developer accepts the offer, the bug finder web service reveals each of the identified bugs to the software developer. For example, the identified bug results may be displayed in a web page to the software developer. As another example, the identified bug results may be sent in a message to the software developer. In some embodiments, for each identified bug, the results include: an indication of the input, an indication of the incorrect output or that the MUT  crashed, the one or more shared memory accesses that produced the identified bug, the thread order that produced the identified bug, the quanta size, and so on. In some embodiments, the message includes a mechanism to replay the identified bugs on the computer  of the software developer. For example, the message may include the binary application instrumented to control the order in which threads execute and the parameters used to identify the bug (e.g., the quanta size and\/or thread order). In some embodiments, the message includes an option to report one or more of the identified bugs to a centralized bug library, such that the reported bugs may be avoided by customers that have deployed multithreaded application . Bug avoidance is discussed further herein in connection with .","While various embodiments are described in terms of the environment described above, those skilled in the art will appreciate that the bug finder web service  may be implemented in a variety of other environments including a single, monolithic computer system, as well as various other combinations of computer systems or similar devices connected in various ways.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 24","b":["2400","2400","2405","2410","2415","2425","2420","2420","2400","2425","2430","2435","2430","2435","2400","2410"]},"In some embodiments, a multithreaded application is deployed in its augmented form. By deploying a multithreaded application in its augmented form, the reliability of the application is substantially increased because, for example, the execution of the multithreaded application \u201cin the field\u201d (i.e., by a customer) will more closely resemble in-house testing of the application. Additionally, if the multithreaded application were to crash or experience a synchronization bug, a software developer may quickly resolve the defect by collecting meaningful crash information from the customer. That is, when deployed in its augmented form, the actions performed by the customer that preceded the crash are meaningful because they allow the software developer to easily reproduce the crash. As a result, the software developer can resolve the defect substantially faster than if the crash or synchronization bug were associated with an unknown interleaving of threads. Accordingly, the facility improves both the development and deployment of multithreaded applications.","In some embodiments, the facility is implemented on a multiprocessing system that includes a virtual machine monitor (VMM). A VMM is a software layer that virtualizes the resources of a physical computing system, such as a multiprocessing system, to provide a virtual machine in which an operating system and\/or any number of applications may be executed. As used herein, a virtual machine (VM) is a logical instance of a multiprocessing system that is implemented through a VMM.  is a high-level block diagram showing a VMM that executes together with a deterministic multiprocessing (DMP) system to deterministically control the execution of threads of a multithreaded application within a virtual machine in one or more embodiments. Certain well-known structures and functions have not been shown or described in detail to avoid obscuring the description. In some embodiments, a virtual machine monitor (VMM)  is implemented on a multiprocessing system, such as computing system  described in connection with . The VMM  provides a virtual machine (VM)  with access to a virtualized set of resources, including virtual processors -, virtual memory , virtual drivers , etc., that each represent virtual instances of the physical resources on which the VMM  executes. The VM  may also include one or more applications, such as multithreaded application . It is noted that the VMM  may include any number of virtual machines. In some embodiments, VMM  is a \u201chosted\u201d VMM, meaning that it is treated much like another application on the multiprocessing system and shares use of a system resources with other applications. While in other embodiments, VMM  is a \u201cnon-hosted\u201d VMM, meaning that the VMM accesses the system resources directly without operating system support.","In some embodiments, the VMM  includes a deterministic multiprocessing (DMP) system  that divides the multithreaded application  into quanta that are performed in a deterministic order. By controlling the order in which quanta are executed by threads of the multithreaded application , the DMP system  enables the multithreaded application to behave deterministically. In some embodiments, the DMP system  enables the operating system (not shown) to behave deterministically. Note, however, that the DMP system  does not have to be implemented by the VMM . For example, in some embodiments, the DMP system  is implemented outside of the VMM , or by a separate computing system, to which the multithreaded application  is provided as input.","In some embodiments, the VMM  includes a bug reporting component  that observes an application crash, determines a buggy sequence (e.g., one or more shared memory accesses for a particular deterministic thread order that preceded a memory access that ultimately caused the application to crash), and stores the determined buggy sequence in the bug library .","In some embodiments, the VMM  includes a thread communication monitor  that monitors inter-thread communications to detect and avoid known buggy sequences. The thread communication monitor  may detect a buggy sequence by observing the order in which threads access shared memory and reconciling that order with sequences known to be buggy (i.e., ultimately cause the application to crash). A \u201cbuggy sequence\u201d may include one or more interleaving patterns (e.g., shared memory accesses for a particular deterministic order) that precede an interleaving that ultimately causes the application to crash. The thread communication monitor  may avoid known buggy sequences that causes the application to crash by selecting a valid interleaving when a buggy sequence is detected. This may be accomplished, for example, by triggering a change to the quanta size or the deterministic order in which the threads are executed.",{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 19","b":["1900","1900","1900","1835","1905","1915","1905"]},"In step , if the facility determines that the observed accesses matches a buggy sequence, then the facility continues to step , else the facility loops back to step . In step , at the next quantum boundary, the facility changes the thread interleaving, then the facility loops back to step . For example, the facility may change the deterministic order in which the threads are executed. As another example, the facility may change the quanta size. In some embodiments, the facility changes the thread interleaving when it is determined that the observed accessed match a buggy sequence. That is, in some embodiments, the facility does not wait for the next quantum boundary to be reached. When a multithreaded application is deployed within a VM-based multiprocessing system that provides dynamic avoidance of concurrency bugs, such as , the reliability of the multithreaded application is substantially increased because the user is shielded for the time it takes the vendor of the application to fix the concurrency bugs.","In some embodiments, the bug reporting component  updates the bug library  when an application crashes. In some embodiments, the bug reporting component  updates the bug library  by receiving or fetching bug updates from a bug aggregator service.",{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 20","b":["2000","2000","2000"]},"In , a bug aggregator service  sends buggy sequences associated with multithreaded applications  to, and receives buggy sequences from, a number of multiprocessing systems . . . via a network , such as the Internet or a local area network. In the illustrated embodiment, each multiprocessing systems  includes a DMP system  to enable multithreaded applications  to behave deterministically and a thread communication monitor  to detect and avoid buggy sequences. Buggy sequences accessed by the thread communication monitor  may be stored locally in a bug library  at the multiprocessing system  and\/or remotely in a centralized bug library  maintained by the bug aggregator service . In the illustrated embodiments, each multiprocessing system  further includes a bug reporting component  to observe when a multithreaded application  crashes; determine the buggy sequence that produced the crash (e.g., one or more shared memory accesses for a particular deterministic thread order that preceded a shared memory access that ultimately caused the multithreaded application  to crash); and store the determined buggy sequence. The bug reporting component  may store updates to the bug library  of the multiprocessing system  on which it operates, the bug library  of another multiprocessing device, and\/or the centralized bug library . Updates to the centralized bug library  may be sent to the bug aggregator service  and\/or sent directly to the centralized bug library  via the network . Updates to either the centralized bug library  or a bug library  of a multiprocessing system  may be made on a sporadic basis, on a periodic basis, during periods of low activity, etc. In some embodiments, the updates to a bug library  of a multiprocessing device  are limited to the bugs associated with the multithreaded applications  executed by the multiprocessing system . While in other embodiments, a user interface is provided to select the multithreaded applications  for which updates are to be sent and\/or received.","While various embodiments are described in terms of the environment described above, those skilled in the art will appreciate that the collection and\/or distribution of bug information may be implemented in a variety of other environments including a single, monolithic computer system, as well as various other combinations of computer systems or similar devices connected in various ways. For example, in various embodiments, a multiprocessing system  implements a virtual machine monitor (not shown) together with a DMP system, thread communication monitor, and bug reporting component to collect and\/or share bug information.","In some embodiments, the computing system on which a multithreaded application is developed, and\/or on which the multithreaded application is deployed, includes a transactional memory (\u201cTM\u201d) system for controlling access to shared memory. The transactional memory system may be a hardware transactional memory (\u201cHTM\u201d), a software transactional memory (\u201cSTM\u201d) system, or a hybrid hardware-software (HS-TM) system. Both TM systems are known in the art. A STM system provides a programming abstraction through which a thread atomically performs a sequence of operations, some of which may involve one or more shared resources (e.g., memory), without locking or waiting for a shared resource to be freed.","Conventional TM systems are \u201coptimistic\u201d in the sense that a thread completes modifications to shared memory without regard for what other threads might be doing. This is accomplished, for example, by maintaining a log for each thread of a multithreaded application and, for each transaction, each thread sequentially record its operations in its corresponding log. For example, a log may include a number and type of memory locations and values that a thread reads and\/or writes during a transaction. At the end of the transaction, if no other thread has concurrently accessed the same shared memory locations, the thread actually performs the sequence of operations (this is commonly referred to as a \u201ccommit\u201d). However, if another thread has concurrently accessed one or more of the same memory locations, then the transaction is aborted and restarted. That is, in conventional TM systems, transactions execute concurrently so long as a shared resource is not accessed by more than one thread during the same transaction.","There are a number of disadvantages associated with conventional TM systems. For example, although conventional TM systems somewhat simplify development by allowing developers to declare certain operations or certain sequences of operations as atomic, conventional TM systems do not provide deterministic multiprocessing of multithreaded applications. Additionally, conventional TM systems do not allow software developers to specify or manipulate the interleavings of threads in a multithreaded application. As a result, conventional TM systems also suffer from latent synchronization bugs. Also, compared with HTM systems, STM systems suffer a performance hit as a result of the overhead associated with maintaining a log and the time spent committing transactions.","In some embodiments, the facility controls the order of execution of certain thread operations of a multithreaded application that uses a transactional memory system to control access to shared resources, such as a HTM, STM, or HS-TM system. That is, the facility may control the order in which threads begin and\/or commit transactions in a transactional memory system. In some embodiments, the facility augments an application programming interface (\u201cAPI\u201d) provided by a STM system. As one example, the facility may augment the functions of the STM API provided in Table 1 below. It will be appreciated by those skilled in the art that, although some embodiments of the facility are described with reference to the STM API provided in Table 1, the facility may operate on various transactional memory systems.",{"@attributes":{"id":"p-0090","num":"0089"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"105pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"void STMBeginTransaction( ):","begins a new transaction performed by a"]},{"entry":[{},{},"thread"]},{"entry":[{},"value STMRead(*addr):","records information in a log about the"]},{"entry":[{},{},"operation type, address, and\/or current value"]},{"entry":[{},{},"of the shared memory location"]},{"entry":[{},"void STMWrite(*addr, value):","records information in a log about the"]},{"entry":[{},{},"operation type, address, and\/or current value"]},{"entry":[{},{},"of the shared memory location as a result of"]},{"entry":[{},{},"the operation"]},{"entry":[{},"bool STMValidTransaction ( ):","determines, based on a thread's log, whether"]},{"entry":[{},{},"another thread has concurrently accessed one"]},{"entry":[{},{},"or more of the same shared resources"]},{"entry":[{},"void STMAbortTransaction( ):","aborts a transaction performed by a thread"]},{"entry":[{},"bool STMCommitTransaction( ):","commits a transaction performed by a thread"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"In some embodiments, a software developer manually specifies atomic blocks within a multithreaded application. For example, a software developer may include the following atomic block:",{"@attributes":{"id":"p-0092","num":"0091"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"atomic {"]},{"entry":[{},"\u2003\u2003a = b + c;"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Following compilation, the above example atomic block would be replaced by the following pseudo code:",{"@attributes":{"id":"p-0094","num":"0093"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"STM_Begin_Transaction( );"]},{"entry":[{},"try {"]},{"entry":[{},"\u2003\u2003var_1 = STMRead(*b);"]},{"entry":[{},"\u2003\u2003var_2 = STMRead(*c);"]},{"entry":[{},"\u2003\u2003STMWrite(*a, var_1 + var_2);"]},{"entry":[{},"\u2003\u2003bool transaction_valid = STMValidTransaction( );"]},{"entry":[{},"\u2003\u2003if (!STMValidTransaction( )) {"]},{"entry":[{},"\u2003\u2003\u2003\u2003STMAbortTransaction( );"]},{"entry":[{},"\u2003\u2003}"]},{"entry":[{},"\u2003\u2003else if (STMValidTransaction( )) {"]},{"entry":[{},"\u2003\u2003\u2003\u2003bool transaction_commited = STMCommitTransaction( );"]},{"entry":[{},"\u2003\u2003\u2003\u2003if (!transaction_commited) {"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003throw transaction_failed_to_commit;"]},{"entry":[{},"\u2003\u2003\u2003\u2003}"]},{"entry":[{},"\u2003\u2003}"]},{"entry":[{},"\u2003}"]},{"entry":[{},"\u2003catch (transaction_failed_to_commit)"]},{"entry":[{},"\u2003{"]},{"entry":[{},"\u2003\u2003..."]},{"entry":[{},"\u2003}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"In some embodiments, one or more of the transactions (i.e., atomic blocks) are not visible to the software developer. For example, they may be inserted by the compiler, runtime, TM system, or some combination of thereof. In some embodiments, atomic blocks are augmented irrespective of whether the blocks were specified by a software developer or inserted by the compiler, runtime, or TM system. In some embodiments, when a thread calls an augmented function of the STM API, the function transfers control to a DMP function that checks the corresponding thread ID to the current value of a token, which is used to start and\/or commit transactions deterministically. One skilled in the art will appreciate that many different techniques may be used to intercept transactions. For example, some STM APIs provide a callback mechanism through which hooks may be registered to transfer control to a DMP function before and\/or after an API function is performed.","Transactions of an augmented transactional memory system are deterministic in size. That is, each thread executes a specific number of operations on blocks (referred to herein as the \u201ccommit block size\u201d), and then the threads deterministically attempt to commit, starting with the thread whose ID matches the current value of the token. If a transaction is valid and the thread ID matches the token, then the thread calls STM_Commit_Transaction( ). After a transaction is committed, the token is advanced to the next thread ID. However, if the transaction is invalid (for example, because the thread read from a location written by another thread during that transaction), then the thread calls STM_Abort_Transaction( ). It is noted that the token is typically not advanced until the thread whose thread ID matches the token successfully commits its corresponding transaction.","In some embodiments, certain types of operations will cause a transaction to immediately abort if the current value of the token does not match the thread ID of the thread executing the transaction. For example, when a transaction includes an operation that cannot be undone, such as an I\/O operation, the thread executing the transaction determines whether its thread ID matches the token. If its thread ID matches the token, then the transaction may proceed. Otherwise, the transaction may be automatically aborted.","In some embodiments, all threads having thread IDs subsequent to an aborted thread are aborted, while in other embodiments only those threads whose concurrent transactions accessed the same shared resource are aborted and restarted. The token is typically not advanced until the thread whose thread ID matches the token successfully commits its corresponding transaction. As a result, any threads having thread IDs subsequent to an aborted thread, which did not abort their transactions, will wait for the token to match their thread IDs before calling STM_Commit_Transaction( ).","It is noted that when a multithreaded application is executed on a computing system having HTM in its augmented form, the multithreaded application can be executed deterministically with no substantial performance penalty. As a result, software developers and\/or manufacturers can deploy their multithreaded applications knowing that they have thoroughly tested for likely thread interleaving. Thus, even if synchronization bugs remain in the multithreaded code, they will not appear to the customer.","Before describing the facility in greater detail, it is useful to consider an environment in which the facility can be implemented.  is a high-level block diagram showing an example architecture of a computing system  on which the facility executes in one or more embodiments. Certain well-known structures and functions have not been shown or described in detail to avoid obscuring the description. The computing system  includes one or more processors  and memory  coupled to an interconnect system . The processors  are the central processing units (\u201cCPUs\u201d) of the computing system  and, thus, control its overall operation. In some embodiments, the processors  accomplish this by executing software stored in memory . In some embodiments, the computing system  includes a processor  having two or more independent cores in a package composed of a single integrated circuit (referred to as a \u201cdie\u201d), one or more dies packaged together, multiple packages, and so on. In some embodiments, the computing system  includes a hyper-threaded processor  that, despite having only a single core, is capable of performing as a multi-core processor. A processor  may be, or may include, one or more programmable general-purpose or special-purpose microprocessors, digital signal processors (\u201cDSPs\u201d) programmable controllers, application specific integrated circuits (\u201cASICs\u201d), programmable logic devices (\u201cPLDs\u201d), or the like, or a combination of such devices.","The interconnect system  shown in  is an abstraction that represents any one or more separate physical buses and\/or point-to-point connections, connected by appropriate bridges, adapters and\/or controllers. The interconnect system  may include, for example, a system bus, a form of Peripheral Component Interconnect (PCI) bus, a HyperTransport or industry standard architecture (ISA) bus, a small computer system interface (SCSI) bus, a universal serial bus (USB), an Institute of Electrical and Electronics Engineers (IEEE) standard 1394 bus (sometimes referred to as \u201cFirewire\u201d), and so on.","System memory  includes a memory  for storing programs and data while they are being used; a persistent storage device , such as a hard drive, for persistently storing programs and data; and a computer-readable media drive , such as a CD-ROM or DVD-ROM drive, for reading programs and data stored on a computer-readable medium. As used herein, system memory  includes any form of volatile, nonvolatile, removable, and non-removable media, or any combination of such media devices that are capable of storing information such as computer-readable instructions, data structures, program modules, and other data of the computing system .","Also connected to the processors  through the interconnect system  is a network adapter  and one or more input devices and output devices (\u201cI\/O devices\u201d) . The network adapter  provides the computing system  with the ability to communicate with other computing systems over a network and may be, for example, an Ethernet adapter. The I\/O devices  provide a user of the computing system  with the ability to access programs and data stored in system memory . For example, I\/O devices  may include input devices such as a keyboard, pointing device, microphone, etc., and output devices such as a display device, speakers, a printer, and so on. While computing systems configured as described above are typically used to support the operation of the facility, those skilled in the art will appreciate that the facility may be implemented using devices of various types and configurations, and having various components.",{"@attributes":{"id":"p-0104","num":"0103"},"figref":"FIG. 5","b":["500","500","400","500","500"]},"In some embodiments, the deterministic multiprocessing system  includes a quantum builder component  and a deterministic multiprocessing (\u201cDMP\u201d) component . The quantum builder component  may be implemented, for example, as a compiler module that augments code of a multithreaded application  using one or more of the functions - provided by the DMP component . Those skilled in the art will appreciate that the functions provided by the DMP component  may be altered in a variety of ways. For example, certain functions may be merged together or divided; certain functions may be omitted; certain functions may be added; and so on. In some embodiments, the quantum builder component  is implemented as a compiler pass within a compiler infrastructure, such as, for example, within the low level virtual machine (\u201cLLVM\u201d) compiler infrastructure. While in other embodiments, the quantum builder component  is implemented by a separate system to which the multithreaded application code  is provided as input.","In the illustrated embodiment, the deterministic multiprocessing system  receives and\/or accesses the multithreaded application code . It is noted that multithreaded application code  may represent one or more code files. The code  may be the source code of a multithreaded application, an intermediate representation (\u201cIR\u201d) of the source code of a multithreaded application, the executable of a multithreaded application, and so on. In some embodiments, the quantum builder component  may use a compiler to build quanta by inserting synchronization code within the multithreaded application code  to track operations in the control-flow-graph (\u201cCFG\u201d) generated by the complier. The inserted code tracks quantum size and, when the quantum size has been reached, it calls one or more functions provided by the DMP component  to control the forward progress of threads within the application. The DMP component  may provide a runtime system and\/or one or more of the DMP functions - may be inserted into the code . In some embodiments, the deterministic processing system  operates together with a transactional memory system and\/or implements a sharing table.","In the illustrated embodiment, the DMP library includes a DMP start function (\u201cDMP_Function_Start( ) function \u201d), a DMP initialization function (\u201cDMP_Init( ) function \u201d), a DMP store function (\u201cDMP_Store( ) function \u201d), a DMP load function (\u201cDMP_Load( ) function \u201d), a DMP commit function (\u201cDMP_Commit( ) function \u201d), and a DMP end function (\u201cDMP_Function_End( ) function \u201d). The DMP start function  and end function  may be used to demarcate when an application function starts and ends. The DMP load function  may be used to convey to the deterministic multiprocessing system  that a load operation will be, or has been, executed. Similarly, the DMP store function  may be used to convey to the deterministic multiprocessing system  that a store operation will be, or has been, executed. The DMP store and load functions  and  are used to control the order of memory operations and thereby enforce deterministic execution of such operations. The DMP initialization function  and the DMP commit function  may be used to demarcate a block of code that is used to control the order of memory operations or to start or end a transaction. Those skilled in the art will appreciate that the functions provided by the DMP component  may be altered in a variety of ways. For example, certain functions may be merged together or divided; certain functions may be omitted; certain functions may be added; and so on.","In some embodiments, the quantum builder component  inserts the function - of the DMP component  as listed in table 2 below:",{"@attributes":{"id":"p-0109","num":"0108"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 2"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DMP_Function_Start( ) -","inserted at the start of each function included"]},{"entry":[{},{},"in code 545"]},{"entry":[{},"DMP_Function_End( ) -","inserted at the end of each function included in"]},{"entry":[{},{},"code 545"]},{"entry":[{},"DMP_Load( ) -","inserted prior to each load block"]},{"entry":[{},"DMP_Store( ) -","inserted prior to each store block"]},{"entry":[{},"DMP_Commit( ) -","inserted prior to any jump block; inserted prior"]},{"entry":[{},{},"to any function call; inserted prior to any OS"]},{"entry":[{},{},"call; inserted prior to a return block"]},{"entry":[{},"DMP_Init( ) -","inserted at each jump-to block from another"]},{"entry":[{},{},"block containing a DMP_Commit( ); inserted"]},{"entry":[{},{},"after each function call; inserted after each OS"]},{"entry":[{},{},"call; inserted after DMP_Function_Start( );"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"In some embodiments, the quantum builder component  creates an intermediate representation of the augmented code, which may be represented, for example, as a control flow graph (\u201cCFG\u201d).  illustrates an example of a control flow graph of a function of multithreaded application code  augmented according Table 2. In some embodiments, after the multithreaded application code  is augmented, a compiler re-optimizes the augmented code, for example, by inlining calls to the DMP function -. Those skilled in the art will appreciate that the compiler may perform other optimizations to the augmented code not specifically described herein.","In some embodiments, the multithreaded application code  uses a transactional memory system, such as an STM, HTM, or HS-TM, to control access by threads to shared resources. In such embodiments, the deterministic multiprocessing system  may be used to control the order in which transactions are committed by threads of the multithreaded application. For example, the quantum builder  may wrap each quantum in a transaction by inserting a call to a DMP initialization function  and a DMP commit function . As another example, when the multithreaded application code  includes one or more application-level transactional memory blocks, the quantum builder component  may augment the multithreaded application code  by inserting a call to a DMP initialization function  prior to each atomic block declared by a software developer, and by inserting a call to a DMP commit function  prior to any call to the TM system to commit an instruction. As yet another example, the deterministic multiprocessing system  may augment an interface provided by the TM system by wrapping calls to functions of the TM interface with calls to one or more functions - of the DMP component . As a result, when the deterministic multiprocessing system  operates together with a TM system, transactions may be started and\/or committed deterministically. It is noted that when the transactional memory system is a HTM system, the DMP load function  and DMP store function  do not need to be included, as long as the HTM performs such tracking.","In some embodiments, the multithreaded application code  is compiled into an executable augmented application . While in other embodiments, the augmented application  is a machine independent, intermediate language code, which is converted into executable instructions at runtime. Following augmentation, the augmented application  may be deterministically executed on a multiprocessing system. That is, given the same input to the augmented application , a multiprocessing system will interleave thread quantum deterministically, thereby producing the same output each time the augmented application  is executed. Those skilled in the art will appreciate that the components shown in  may be altered in a variety of ways. For example, certain components may be merged or divided; certain components may be omitted; certain components may be added, such as, for example, a compiler; and so on.","In some embodiments, the functions - provided by the DMP component  are responsible for passing or advancing a token deterministically between the threads of the multithreaded application, thereby deterministically controlling the forward progress of each thread. In some embodiments, this is accomplished by using a thread data structure .  is a high-level block diagram showing a thread data structure  used by the facility to make multiprocessor code deterministic in one or more embodiments. In some embodiments, the thread data structure  includes a thread container . The thread container stores a thread ID for each thread that is created by the multithreaded application during execution. The thread container  may be implemented as an array, a linked list, a queue or other data structure of thread IDs.","In some embodiments, the thread data structure  includes a token  that is used to control the ordering of execution of transaction or controlled operations by threads of the multithreaded application during execution. For example, in some embodiments, prior to executing a controlled operation or committing a transaction, a thread determines whether its thread ID matches the current value of the token . When the current value of the token  matches a thread's ID, a corresponding thread may execute the controlled operation or attempt to commit the transaction. Otherwise, the corresponding thread waits until the current value of the token  matches its thread ID.","In some embodiments, the order in which threads are created corresponds to the order in which the threads are deterministically executed. For example, as each thread is created, the thread's corresponding thread ID may be sequentially stored in the thread container . As transactions or controlled operations are executed, the executing thread invokes certain DMP functions, such as DMP_Commit( ) , which operate to advance the value of the token  by sequentially looping through the thread IDs stored in the thread container  based on the sequence in which the thread IDs were stored (beginning with the first thread ID). It is noted that, when a thread exits, the thread's corresponding ID is removed from the thread container .","In some embodiments, the thread data structure stores a commit block size . The commit block size  represents a predetermined number of transactions or controlled operations that may be executed by a thread whose thread ID matches the current value of the token  before the token is advanced. The commit block size  may range from 1 transaction or controlled operation to N transactions or controlled operations. In at least one embodiment, the commit block size  is equal to one thousand (1,000). In some embodiment, the commit block size  is configurable. For example, the commit block size  may be configured by a software developer to programmatically manipulate and test the various thread interleaving of a multithreaded application. As another example, the commit block size  may be automatically configured based on the maximum number of threads that may be created by the multithreaded application and\/or the number of processor or cores of the multiprocessing system on which the multithreaded application executes.","Those skilled in the art will appreciate that a variety of techniques may be used to count the number of controlled operations executed by a thread. In some embodiments, the thread data structure  includes a thread commit block . The thread commit block  may represent the number of controlled operations that have been executed by a thread whose thread ID matches the current token ID . Each time the thread performs a controlled operation, the value of the thread commit block  is incremented, and the compared to the commit block size . If the value of the thread commit block  equals the commit block size , then the token  is advanced to the next thread ID, and the value of the thread commit block  is reset to zero. As an alternative example, the thread commit block  may represent the number of blocks that remain before a thread attempts to commit its corresponding transaction. In such embodiments, the thread commit block  may include a number of remaining blocks for each thread having a thread ID stored in the thread container . Then, each time a thread performs a block, the thread decrements its corresponding thread commit block and, when the number of remaining blocks equals zero, the thread attempts to commit its transaction.","In some embodiments, the thread data structure includes a threads-in-use block , which represents the number of threads executing in a multithreaded application. In some embodiments, the threads-in-use block  is incremented each time a thread is created. Similarly, the threads-in-use block  is decremented each time a thread exits. While in other embodiments, the threads-in-use block  is determined based on the size of the thread container . Those skilled in the art will appreciate that the thread data structure  shown in  may be altered in a variety of ways. For example, certain parts may be merged or divided; certain parts may be omitted; certain parts may be added; and so on.",{"@attributes":{"id":"p-0119","num":"0118"},"figref":"FIG. 7","b":["600","610"]},"In the illustrated example, the first-created thread (\u201cthread \u201d) represents the main application thread of the multithreaded application. To facilitate description, the thread ID of each thread is equal to the order in which the thread was created. That is, the thread ID of the first-created thread is 1; the thread ID of the second-created thread is 2; the thread ID of the third-created thread is 3; and so on. Between time Tand T, thread  executes and thread  is created. In the illustrated example, a thread's execution is represented by a specified number of controlled operations (e.g., a quantum specified by commit block size ). Thus, the time increments illustrated in  are not necessarily equal. It is also noted that the number of uncontrolled operations executed by each thread may be different, and may differ for each thread during each of its execution periods.","Returning to , because thread  was created at some point before thread  completed its quantum execution, the number of thread-in-use  between time Tand Tis two. As a result, when thread  completed, the token  was advanced to the next thread ID stored in the thread container  (i.e., thread ).","Between time Tand T, thread  executes, and then the token  is advanced back to thread . Between time Tand T, thread  executes, and then the token  is advanced to thread . Between time Tand T, thread  executes, and then the token  is advanced back to thread .","Between time Tand T, thread  executes and thread  is created. Although thread  was created between time Tand T, thread  executes between time Tand T. This is because the order in which threads were created corresponds to the order in which the threads are executed. As a result, thread  executes between time Tand T, and then the token  is advanced to thread . Thread  then executes between time Tand T, and then the token  is advanced back to thread .",{"@attributes":{"id":"p-0124","num":"0123"},"figref":"FIG. 8","b":["600","605","1","2","3","610","610","1","615"]},"As illustrated, at time T, threads - begin a transaction. After a thread completes its corresponding transaction, the thread attempts to deterministically commit its transaction. In some embodiments, each thread determines whether its transaction resulted in a conflict that would prevent the thread from committing its transaction. While in other embodiment, this determination is made by a thread when its thread ID matches the current value of the token . For example, this may be accomplished by calling STMValidTransaction( ).","At time T, the current value of token  matches the ID of thread . Thus, in the illustrated example, thread  determines whether its transaction resulted in a conflict that would prevent it from committing the transaction. Because transactions are committed according to a specified deterministic order, the facility is able to use memory renaming to avoid aborting transactions as a result of write-after-write and write-after-read conflicts. That is, because operations within a transaction are buffered before the transaction is committed, the facility is able to determine whether a write-after-write or a write-after-read operations actually conflict, rather than aborting both transactions. In the illustrated example, although thread  and thread  accessed the same shared memory location (i.e., address A), which would result in a write-after-read conflict in a conventional transaction memory system, the transaction of thread  is valid. This is because thread  stored a value at address A and the token  matched its thread ID. That is, the store of A (performed by thread ) is not affected by the load of A (performed by thread ). As a result, thread  commits its transaction (e.g., by calling STMCommitTransaction( )), and then the token  is advanced to the next thread ID. However, if the token  had matched the thread ID of thread , then thread  would abort its transaction. This is because thread  may have loaded A after thread  stored A. Assuming that the token  matched the ID of thread , then both thread  and thread  would abort their transactions. In which case, thread  would begin and commit the aborted transaction prior to restarting the aborted transaction of thread .","As illustrated, at time T, thread  commits it transaction, and then the token  is advanced to thread . However, thread  cannot commit its transaction because thread  loaded a value that was stored by thread  during the same transaction. That is, thread  may have loaded A prior to thread  storing A. As a result, thread  must abort its transaction and restart. In the illustrated example, all threads having thread IDs subsequent to an aborted thread are aborted. While in other embodiments only those threads having subsequent IDs whose concurrent transactions accessed the same shared resource are aborted and restarted. Thus, in the illustrated example, the transaction of thread  is aborted and restarted. However, in other embodiments, the transaction of thread  would not be aborted because its transaction did not access a shared resource that was accessed by thread  or thread  during the concurrent transaction. Instead, thread  would simply wait for the token  to match its thread ID. It is noted that the token  is not advanced until the thread whose thread ID matches the token successfully commits its corresponding transaction.","As illustrated, at time T, threads - restart their aborted transactions. At time T, the current value of token  matches the ID of thread , so thread  determines whether its restarted transaction resulted in a conflict that would prevent it from committing the transaction. In the illustrated example, the restarted transactions of threads  and  do not access any shared memory locations. As a result, at time T, thread  successfully commits it transaction, and then the token  is advanced to thread . At time T, thread  successfully commits its transaction, and then the token  is advanced back to thread .","Next, at time T, threads - begin a transaction, and the process continues as described above. It is noted that, at time T, the concurrent transactions of threads  and  will result in thread  aborting and restarting its transaction. However, threads  and  will deterministically commit, and the token  will be advanced to thread , as described above.","In some embodiments, uncommitted (\u201cspeculative\u201d) data is forwarded between threads, thereby reducing the number of aborted transactions and recovering more parallelism within a multithreaded application. For example,  is a high-level diagram showing an example of transactional memory (TM) forwarding in one or more embodiments. To facilitate description, the contents of a portion of the thread data structure  are shown over time. Also, to facilitate description, it is assumed that the thread IDs are ordered in the thread container  as follows: thread , thread , thread . As illustrated by the token value  over time, the order in which threads commit transactions is deterministic. To facilitate description, the first value of the token  corresponds to the thread ID of thread .","When TM forwarding is enabled and a thread (referred to as an \u201cupdater\u201d thread) issues a memory operation to write to a memory location regarded as shared or private to another thread, the updater thread broadcasts a message indicating that the data stored at the memory location has been updated. In response to the broadcast, each thread with an outdated copy of the data removes the outdated data from its cache. In some embodiment, if another thread (referred to as a \u201ccalling\u201d thread) subsequently issues a memory operation to read the shared memory location, an updated copy of the data is forwarded to the calling thread instead of aborting the transaction, provided that the updater thread precedes the calling thread in the deterministic order. For example, in the illustrated embodiment, at time T, threads - begin a transaction. Thread  issues a memory operation to write to memory location A and broadcasts a message indicating that the data stored at memory location A has been updated. To facilitate description, it is assumed that thread  previously cached the data stored at memory location A. When thread  receives the broadcast from thread , thread  removes the outdated copy of the data from its cache. Thread  subsequently issues a memory operation to read memory location A. Because the data is no longer cached, thread  determines whether the memory location A has been updated and, if so, whether it was updated by a thread preceding it in the deterministic order. In this example, because thread  precedes thread  in the deterministic order, an updated copy of the data to be stored at memory location A by thread  is forwarded to thread . The data forwarded to thread  is speculative because thread  has not committed its transaction at the time the data is received by thread . In some embodiments, if speculative data is forwarded from a uncommitted transaction that is ultimately aborted, then all threads that consumed the speculative data are also aborted. That is, if thread  aborts its transaction, thread  will abort its transaction as well because it consumed speculative data from thread .","After threads - complete their corresponding transaction, each thread attempts to commit its transaction. At time T, the current value of the token  matches the ID of thread  and no conflict exists that would prevent thread  from committing its transaction. Thus, thread  commits its transaction at time T, and then the token  is advanced to the next thread ID in the deterministic order (i.e., thread ). At time T, the current value of the token  matches the ID of thread  and no conflict exists that would prevent thread  from committing its transaction. That is, because thread  successfully committed the transaction from which speculative data was previously forwarded to thread , no conflict exists to prevent thread  from committing its transaction. Thus, at time T, thread  commits its transaction and the token  is advanced to the next thread ID in the deterministic order (i.e., thread ). At time T, the current value of the token  matches the ID of thread  and no conflict exists that would prevent thread  from committing its transaction. As a result, thread  commits its transaction at time Tand the token  is advanced to the next thread ID in the deterministic order (i.e., thread ). Next, at time T, threads - begin a transaction, and the process continues as described above.",{"@attributes":{"id":"p-0133","num":"0132"},"figref":"FIG. 22","b":["2200","2205","2260","2205","2210","2215","2225"]},"In step , the facility updates the cache of the calling thread to reflect the store operation. In step , the facility sends a broadcast message indicating that the data stored at the memory location specified by the store operation has been updated, and then continues to step . In step , if additional operations within the transaction remain, then the facility continues to step , else the process  returns. In some embodiments, when such broadcast message is received, the facility determines for each thread whether the thread has accessed the updated memory location during the current transaction. If a thread has not accessed the memory location during the current transaction, then the message is disregarded for the thread. Otherwise, if a thread has accessed the memory location during the current transaction, then facility determines whether the thread precedes the updater thread in the deterministic order. If a thread precedes the updater thread in the deterministic order, then the message is disregarded for the thread. Otherwise, if a thread does not precede the updater thread in the deterministic order, the facility aborts the transaction executed by that thread.","In step , if the operation is a load operation, then the facility continues to step , else the facility continues to step . In step , if the memory location specified by the load operation is cached by the calling thread, then the facility continues to step , else the facility continues to step . In step , the facility loads the data from the cache of the calling thread, then continues to step . In step , if the memory location has been updated during the transaction by another thread (referred to as the \u201cupdater thread\u201d), then the facility continues to step , else the facility continues to step .","In step , if the updater thread precedes the calling thread in the deterministic order, then the facility continues to step , else the facility continues to step . In step , the facility forwards the data stored at the memory location specified by the load operation to the calling thread from the cache of the updater thread, then the facility continues to step . In step , the facility loads the data stored at the memory location specified by the load operation from memory, then continues to step . In step , if additional operations within the transaction remain, then the facility continues to step , else the process  returns.",{"@attributes":{"id":"p-0137","num":"0136"},"figref":"FIG. 9","b":["900","905","940","545","905","910","910","515","915","915","520","920","920","930","920","925","925","1000","930","930","920","935","935","540","940","940","905"]},{"@attributes":{"id":"p-0138","num":"0137"},"figref":"FIG. 10","b":["1000","1005","1010","1015","1010","530","1015","1020","1025","1020","525","1025","1030","1035","1030","535","520","1035","1040","1045","1040","535","520","1045","1040","1050","1050","1055","1055","535"]},{"@attributes":{"id":"p-0139","num":"0138"},"figref":"FIG. 11","b":["1100","1105","1130","1100","1110","520","1105","1130","1115","1125","1120","1125","1110","1115","1120","1125"]},{"@attributes":{"id":"p-0140","num":"0139"},"figref":"FIG. 12","b":["1200","1200"]},"In step , if the facility determines that the value of a thread's initiation variable (\u201cinitSite\u201d) is equal to zero, then the facility continues to step , else the facility returns. A thread's initialization variable may be assigned to zero, for example, after a thread successfully commits a transaction. In step , if the facility determines that the current value of the token matches the thread's ID, then the facility continues to step , else the facility loops back to step . That is, the facility suspends the thread execution in step  until the thread's ID matches the value of the token. In step , the facility assigns the initSite variable to the memory address at which the thread begins a transaction, then the facility returns. The initSite variable may then be used as an explicit jump address if the transaction cannot be committed.",{"@attributes":{"id":"p-0142","num":"0141"},"figref":"FIG. 13","b":["1300","1300","1305","1310","1310","1315","1315","1320","1325","1320","1325","1330","1330","1335","1335","1340","1340"]},"Thus, a facility for deterministic multiprocessing of multithreaded applications has been described. Although the facility has been described with reference to specific embodiments, it will be recognized that the facility is not limited to the embodiments described, but can be practiced with modification and alteration within the spirit and scope of the appended claims. Accordingly, the specification and drawings are to be regarded in an illustrative sense rather than a restrictive sense."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["One or more embodiments of the facility are illustrated by way of example and not limitation in the figures of the accompanying drawings, in which like references indicate similar elements and in which:",{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIGS. 25A-25C"}]},"DETDESC":[{},{}]}
