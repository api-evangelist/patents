---
title: Determining a relevance score of an item in a hierarchy of sub collections of items
abstract: A hierarchical collection of items including one or more sub collections of items ordered in a hierarchy is received. A statistical measure of frequency of an item in a sub collection of items is determined. Further, statistical measures of weightages of the item are determined defining a number of sub collections in the hierarchical collection of items in which the item appears and a number of sub collections in which the item appears. A statistical measure of variability defining a number of occurrences of the item in the hierarchical collection of items across different sub collections is calculated. Furthermore, a relevance score of the item is determined based on the statistical measure of frequency, the one or more statistical measures of weightages of the item and the statistical measure of variability. Based on the relevance score, the item is presented on a computer generated graphical user interface.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08538965&OS=08538965&RS=08538965
owner: SAP AG
number: 08538965
owner_city: Walldorf
owner_country: DE
publication_date: 20120522
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD","BACKGROUND","DETAILED DESCRIPTION"],"p":["Embodiments generally relate to data mining and ranking items based on relevancy and more particularly to methods and systems to determine a relevance score of an item in a hierarchy of sub collections of items.","The amount of content or data or items available on the Internet (e.g., time sensitive documents such as blogs, forum posts and the like) continues to increase exponentially. Users with limited information and limited time have difficulty in finding items that satisfy their interests. Thus, several recommendation systems (e.g., text mining systems and information retrieval systems (IR)) are used widely in the art to recommend appropriate items to users based on their inclinations and preferences. A typical way for presenting output of the IR system is by means of listing the documents and sometimes their scores of relevancy. Another popular way to present the output of text mining systems is through tag clouds. Tag clouds are used to present the relevance of items (e.g., text items) in a collection of documents, where relevant text items appear in a dedicated area where relevance is emphasized usually by size and color.","Currently, the text mining systems determine importance or significance of text items using standard Term Frequency-Inverse Document Frequency (tf-idf) techniques and the like. However, one of the challenges in implementing the standard tf-idf technique is that the idf part at a particular small sub collection (e.g., documents pertaining to a week in a yearly corpus of documents) is almost constant as the idf part uses logarithmic function which is very aggressive for small collections. Thus, achieving accurate relevance for the text item through tf-idf technique corresponding to the small sub collection of documents may not be possible. Further, there is no notion of hierarchy in the standard tf-idf technique, other than the simple corpus document hierarchy.","In many cases relevant text items are supervised (e.g., manually selected set of tags). Many tag cloud implementations are based on these supervised tags. However in many practical scenarios, such as in emails, no supervised tags exist. Moreover, even when supervised tags exist, they are not always complete and may not cover all the topics in the document. Therefore, the existing methods of determining relevance score of the text item and generating tag cloud to present relevant text item may not facilitate finding significant, interesting and relevant text item in a document or a collection of documents.","Embodiments of techniques to determine relevance score of an item in a hierarchy of sub collections of items are described herein. Further, the item is presented graphically on a graphical user interface based on the relevance score of the item using techniques such as tag clouds and the like. According to various embodiments, the tag cloud is a visual representation of items (e.g., text items), where relevant text items appear in a dedicated area, emphasized usually by font, relative to their significance based on various factors. The tag cloud may include a plurality of text items (e.g., topics in a document). The items may be, but are not limited to a word, phrase, paragraph and section, and the items may include, but are not limited to text, special characters, numerals and any combination thereof. Further, tag cloud may be used to present items of a corpus or any sub collection within it. The corpus is a hierarchical collection of documents (e.g., collection of time sensitive documents such as emails, blogs, forum posts and the like) and each document includes a plurality of items. In other words, the hierarchical collection of documents includes one or more sub collection of items ordered in a hierarchy.","According to one embodiment, the relevance score of the item is determined to identify significant items in the hierarchical collection of items corresponding to the sub collection of items (e.g., items corresponding to a time frame). For example, in a corpus (e.g., hierarchical collection of items) corresponding to one year of documents, important or relevant text items in a sub collection of text items corresponding to a time frame (e.g., a week, a month and the like) are presented to a user through the tag cloud. Further, the tag cloud is generated based on a relevance score of the text item. Higher the relevance score, higher the relevancy and vice versa.","In one embodiment, the relevance score is determined based on a statistical measure of frequency of the item, weightages of the item and a statistical measure of variability of the item. Therefore, the important or significant items in the sub collection of items corresponding to the time frame are emphasized whereas the less significant items are suppressed. Thus, higher accuracy in emphasizing significant items in the sub collection of items can be achieved and since the relevance score of the item is determined for the sub collection of items (e.g., time frame such as a week, a month and the like). The method of determining the relevance score of the item in a sub collection of items is described taking an example of email corpus corresponding to a time frame in the below description. However, the method may be implemented in determining a significant item in a set of any collection and sub collection of items (e.g., in a set of books and the like).","In the following description, numerous specific details are set forth to provide a thorough understanding of the embodiments. One skilled in the relevant art will recognize, however, that the embodiments can be practiced without one or more of the specific details, or with other methods, components, materials, etc. In other instances, well-known structures, materials, or operations are not shown or described in detail.","Reference throughout this specification to \u201cone embodiment\u201d, \u201cthis embodiment\u201d and similar phrases, means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one of the one or more embodiments. Thus, the appearances of these phrases in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures, or characteristics may be combined in any suitable manner in one or more embodiments.",{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1","b":["100","110"]},"What items are significant can be configured based on a number of factors. For instance, at step , a statistical measure of frequency of an item in a sub collection of items is determined. In one exemplary embodiment, the item is a text item that is analyzed in context of surrounding text items to consider synonyms and inflected forms of the text item (e.g., using a lemmatizer). The lemmatizer is described in greater detail in . The sub collection of documents of the corpus includes one or more documents of the corpus associated with a time frame, for instance. For example, in a corpus including 200,000 emails corresponding to two years' time period, the emails corresponding to a week (e.g., 25 emails corresponding to the first week of September 2011) are concatenated to sub collection of documents. In the sub collection of documents, the normalized number of times the text item, for example the word \u2018computer\u2019 appears, is determined using equation (1).\n\ntf(item)=(Number of times the item appears in the week)\/(Total number of items in the document corresponding to the week)\u2003\u2003(1)\n","In tf(item), \u2018tf\u2019 stands for the term or item frequency. The tf(item) defines the normalized number of times the text item appears in the concatenated document and implies that the more times the item appears in the sub collection of documents, the more significant the item is in the sub collection of documents. For example, assuming the text item, the word \u2018computer\u2019 appears 30 times in the sub collection of documents and the sub collection of documents includes a total of 2000 text items corresponding to the first week of September 2011. The item frequency, tf(computer) is 0.015 as in equation (2).\n\ntf(computer)=(Number of times the text item, the word \u2018computer\u2019, appears in the first week of September 2011)\/(Total number of items in the sub collection of documents corresponding to the first week of September 2011)=30\/2000=0.015\u2003\u2003(2)\n","At step , one or more statistical measures of weightages of the item defining a number of sub collections in the hierarchical collection of times in which the item appears and a number of sub collections in which the item appears are determined. In one exemplary embodiment, the weightages of the text item defining the number of documents in the corpus in which the item appears is determined using equation (3). For example, the number of documents in the 200,000 emails in which the text item, the word \u2018computer\u2019, appears is determined.\n\nidf(item)=log [(Total number of documents in the corpus)\/(Number of documents in the corpus where the item appears)]\u2003\u2003(3)\n","In idf(item), \u2018idf\u2019 stands for inverse document frequency. The idf(item) defines the number of documents in which the item appears in the corpus and implies that less number of times the item appears, the more significant is the item. For example, assuming the text item, the word \u2018computer\u2019, appears in 45 documents of total of 200,000 documents, the weightages of the text item, the word \u2018computer\u2019, with respect to total number of documents of 200,000 emails, idf(computer) is 8.4 as in equation (4).\n\nidf(computer)=log(200,000\/45)=8.4\u2003\u2003(4)\n","In one embodiment, the weightages of the item defining the number of time frames in which the item appears is determined using equation (5). For example, the number of time frames in the two year time period in which the text item, the word \u2018computer\u2019, appears is determined.\n\nidf(item)=log [(Total number of time frames associated with the corpus)\/(Number of time frames in which the item appears)]\u2003\u2003(5)\n","The idf(item) defines the number of time frames in which the item appears. For example, assuming the item \u2018computer\u2019 appears in two weeks' time frames of total of 108 weeks (e.g., 108 weeks in two years), the idf(computer) is 3.99 as in equation (6).\n\nidf(computer)=log(108\/2)=3.99\u2003\u2003(6)\n","Further, idf(item) is almost constant for each week as the idf(item) uses logarithmic function (as logarithmic function is more aggressive for small numbers). Therefore, a mathematical function which is less aggressive compared to the logarithmic function may be used for achieving the accuracy in determining the significant items. For example, a less aggressive mathematical function such as a square root function may be used. Hence, the weightage of the sub collection of items, in this case the number of time frames (e.g., number of weeks) in which the text item, the word \u2018computer\u2019 appears, is determined using less aggressive mathematical function as shown in equation (7).\n\nidf*(item)=sqrt[(Total number of time frames associated with the corpus)\/(Number of time frames in which the item appears)]\u2003\u2003(7)\n","The idf*(item) defines the number of time frames in which the item appears. For example, assuming the text item, the word \u2018computer\u2019 appears in two weeks' time frames of total of 108 weeks (e.g., 108 weeks in two years), the idf*(computer) is 7.35 as in equation (8).\n\nidf*(computer)=sqrt(108\/2)=7.35\u2003\u2003(8)\n","In one embodiment, the mathematical function is selected by a configuration unit based on the sub collection of items corresponding to the time frame for which the relevance score of the item is determined. The mathematical function may be a logarithmic function, a square root function, a division function (e.g., divide by a constant greater than 1), an exponential function (e.g., 1-efor a\u22670), a generalization of square root function (e.g., xfor a<1), and the like based on the sub collection of items corresponding to the time frame for which the relevance score of the item is determined. For example, to determine significant items in a time frame of a week, square root function is selected and used in the idf technique. As the configuration unit intelligently selects the mathematical function, domain experts may not be required for performing the method of generation of the tag cloud. The configuration unit is described in greater detail in .","At step , a statistical measure of variability defining a number of occurrences of the item in the hierarchical collection of items across different sub collections is calculated. In other words, to further emphasize in determining significant items across sub collections (e.g., weeks), an additional factor, standard deviation (std(item)) is calculated. For example, the standard deviation (std(computer)) of the item \u2018computer\u2019 is computed as 3.72 using standard equations used to calculate standard deviation.","At step , a relevance score of the item is determined based on the statistical measure of frequency, the one or more statistical weightages of the item and the statistical measure of variability. In one exemplary embodiment, the statistical measure of frequency (e.g., as shown in equation 2), the weightages of the item (e.g., as shown in equations 4, 6 and 8) and the statistical measure of variability are multiplied to determine the relevance score of the text item, the word \u2018computer\u2019 as shown in equation (9).\n\nRelevance score of the text item, the word \u2018computer\u2019=tf(computer)\u00d7idf(computer)\u00d7idf(computer)\u00d7idf*(computer)\u00d7std(computer)\u2003\u2003(9)\n","Therefore, relevance score of the text item, the word \u2018computer\u2019 in the first week of September 2011=0.015\u00d78.4\u00d73.99\u00d77.35\u00d73.72=13.75","Similarly, relevance of other items in the sub collection of items is determined.","At step , the item is presented on a computer generated graphical user interface, using a technique such as a tag cloud and the like, based on the relevance score of the item in the sub collection of items as determined in step . For example, the text item, the word \u2018computer\u2019 is displayed in the tag cloud based on the relevance score 13.75. If other items are having lower relevance score compared to the text item, the word \u2018computer\u2019, the text item, the word \u2018computer\u2019 is emphasized or vice versa. The tag cloud is described with an example in .",{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 2","FIG. 1"],"b":["200","200","205","210","205","205","235","205","215","205","205"]},"In one embodiment, the computer system  includes a processor  to execute software instructions or code stored on a memory  to perform the method as described in . The computer system  is described in greater detail in . In one exemplary embodiment, the memory  includes a relevance score evaluator . The relevance score evaluator  determines a relevance score of an item for a sub collection of items. The relevance score of the item is determined based on a statistical measure of frequency of the item (e.g., as described in step  of ), one or more weightages of the item (e.g., as described in step  of ) and the statistical measure of variability (as described in step  of ). The relevance score evaluator  includes a plurality of components to perform the steps described above. The plurality of components in the relevance score evaluator  is described in greater detail in .",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 3","b":["300","300","300","300","305","310","305","300","300","300","300"]},"In one embodiment, the relevance score evaluator  includes a lemmatizer , a statistics calculator , a weightage calculator , a configuration unit , a relevance score calculator , and a tag cloud generator , which are communicatively coupled as shown in . The lemmatizer  groups together the different inflected forms of an item or synonyms, so they can be analyzed as a single item. For example, the item \u2018better\u2019 has \u2018good\u2019 as its lemma and thereby both the items \u2018better\u2019 and \u2018good\u2019 can be considered as single item to determine the relevance score. In another example, the item \u2018meeting\u2019 may be either the base form of a noun or a form of a verb (i.e., \u2018to meet\u2019) depending on the context (e.g., \u2018in our last meeting\u2019 or \u2018We are meeting again tomorrow\u2019). Further, in the context \u2018Mr. Said asked for tee\u2019, a classic stemmer will interpret the item \u2018said\u2019 as past from of the verb \u2018say\u2019, as the classic stemmer determines the inflected items to their stem, base or root form. However, the lemmatizer  understands context and the part of speech of the item in the sentence to determine the synonyms of the item. In one exemplary embodiment, lemmatizer  uses Natural Language Processing (NLP) techniques to analyze the items. Thus, the higher accuracy in determining the relevance score of the item may be achieved.","In one embodiment, the statistics calculator  calculates a statistical measure of variability defining a number of occurrences of the item in a hierarchical collection of items across one or more sub collections of items. For example, the statistics calculator  calculates standard deviation of the number of occurrences of the item (computer') across different time frames (e.g., in weeks' time frame) as described in step  of . In other items, statistics calculator  is a component responsible for calculation of statistics over the items in the corpus.","In one embodiment, the weightage calculator  determines a statistical measure of frequency of the item (tf(item)) as described in step  of . Further, one or more statistical measures of weightages of the item defining a number of sub collections in the hierarchical collection of items in which the item appears idf(computer) and a number of sub collections (e.g., time frames) in which the item appears (idf(computer) and idf*(computer)) are determined as described in step  of .","In one embodiment, the configuration unit  determines the mathematical function (e.g., a logarithmic function, a square root function, a division function (e.g., divide by a constant greater than 1), an exponential function (e.g., 1-efor a\u22670), a generalization of square root function (e.g., xfor a<1) and the like) to be used in determining the weightage of the item based on the sub collection of items (e.g., time frame duration) for which the tag cloud is generated. The mathematical functions other than the logarithmic function and the square root function may be automatically chosen depending on the sub collection of items corresponding to the time frame duration by the configuration unit. Further, the configuration unit  may control the other components of the relevance score evaluator . For example, the configuration unit  controls the lemmatizer  and the statistics calculator  by selecting an algorithm for lemmatization and statistics calculations depending on the time frame for which the tag cloud is generated.","In one embodiment, the relevance score calculator  determines the relevance score of the item based on input from the statistics calculator  and the weightage calculator . In other items, the relevance score calculator  combines the input from the statistics calculator  and the weightage calculator  to determine the relevance score of the item. In one exemplary embodiment, machine learning methods may be used to optimize the relevance score combination. Further, the configuration unit  determines the way in which the two inputs are combined. For example, as in equation (9), the inputs are multiplied to determine the relevance score of the text item, the word \u2018computer\u2019. However, sophisticated combination other than multiplication may also be used depending on the time frame for which the tag cloud is generated.","In one embodiment, the tag cloud generator  receives the relevance score determined by the relevance score calculator  and generates the tag cloud accordingly. The tag cloud generator  prepares graphic presentation of the items by emphasizing on items with higher relevance scores. Further, the generated tag cloud is presented on a graphical user interface through the output device . It is advantageous that technique other than tag cloud may be used to present the item based on the relevance score of the item. In one exemplary embodiment, the configuration unit  controls the tag cloud generator  regarding the graphical representation of items.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 4","b":["400","400","405","410","405","400","400","410"]},"In one embodiment, the relevance score evaluator  includes a topic partitioner  along with the other components as described in  such as a lemmatizer, a statistics calculator, a weightage calculator, a configuration unit, a relevance score calculator and a tag cloud generator. The topic partitioner  segregates content of the documents corresponding to one or more topic clusters. The topic clusters includes segregation of content of the document based on topics. Further, when a user is interested in a particular topic, the documents of the time frame (e.g., documents corresponding to a week are concatenated to form a sub collection of item) may first be clustered according to topics and the tag cloud may be constructed per individual topic. Furthermore, the user can extract the relevant tag cloud using a search query to extract the search results in an information retrieval (IR) query based search. In one exemplary embodiment, the configuration unit  as described in  controls the topic partitioner  by switching on or off the topic partitioner  based on user's interest.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 5","FIGS. 1 and 3"],"b":["500","500"]},{"@attributes":{"id":"p-0045","num":"0044"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}},{"entry":[{},"tf","idf","idf*",{},{},"Relevance"]},{"entry":["Items","(item)","(item)","(item)","std(item)","idf(item)","score"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"7"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Computer","0.015","3.99","7.35","3.72","8.4","13.75 "]},{"entry":["Weather","0.012","0.076","1.039","4.8","10.3","0.047"]},{"entry":["Flood","0.017","2.5","6.5","3.99","9.6","10.58"]},{"entry":{"@attributes":{"namest":"1","nameend":"7","align":"center","rowsep":"1"}}}]}}]}}},"The tag cloud for the time frame of first week of September 2011 is depicted in . As per Table 1, the text item, the word \u2018computer\u2019 has a higher relevance score (e.g., 13.75) compared to other two text items \u2018weather\u2019 (e.g., 0.047) and \u2018flood\u2019 (e.g., 10.58). Therefore, the text item \u2018computer\u2019  is displayed with a larger font size compared to the text items \u2018weather\u2019  and \u2018flood\u2019 . Further, the text item \u2018flood\u2019  has the next higher relevance score and thereby the text item \u2018flood\u2019  is displayed with larger font size compared to the text item \u2018weather\u2019 . The text item \u2018weather\u2019  is displayed with a font size less than the font size of the text item \u2018flood\u2019 . In one exemplary embodiment, the items can be emphasized with different colors, highlighting and the like depending on the relevance score of the item.","It is advantageous that the method described above to determine a relevance score of the item and to generate a tag cloud based on the relevance score of the item for a time frame eliminates manual supply of tags and automatically extracts the significant items, using NLP techniques to use as tags for the tag cloud. This avoids human intervention in the process of generation of the tag cloud. Further, the method may be advantageous to an enterprise, which maintains a collection of text messages, e.g. emails, blog posts or recordings of chats that customers have with service representatives. Each day new messages are added to the collection. Using the method described above, the enterprise can identifying key topics for a time frame (e.g., on a weekly basis, on a monthly basis and the like). Thus the new developing topics can be emphasized. Further, an additional functionality to identify sub-topics in documents and generation of the tag cloud per sub-topic can be achieved to focus on the significant topics using a topic partitioner of the relevance score evaluator.","Some embodiments may include the above-described methods being written as one or more software components. These components, and the functionality associated with each, may be used by client, server, distributed, or peer computer systems. These components may be written in a computer language corresponding to one or more programming languages such as, functional, declarative, procedural, object-oriented, lower level languages and the like. They may be linked to other components via various application programming interfaces and then compiled into one complete application for a server or a client. Alternatively, the components maybe implemented in server and client applications. Further, these components may be linked together via various distributed programming protocols. Some example embodiments may include remote procedure calls being used to implement one or more of these components across a distributed programming environment. For example, a logic level may reside on a first computer system that is remotely located from a second computer system containing an interface level (e.g., a graphical user interface). These first and second computer systems can be configured in a server-client, peer-to-peer, or some other configuration. The clients can vary in complexity from mobile and handheld devices, to thin clients and on to thick clients or even other servers.","The above-illustrated software components are tangibly stored on a computer readable storage medium as instructions. The term \u201ccomputer readable storage medium\u201d should be taken to include a single medium or multiple media that stores one or more sets of instructions. The term \u201ccomputer readable storage medium\u201d should be taken to include any physical article that is capable of undergoing a set of physical changes to physically store, encode, or otherwise carry a set of instructions for execution by a computer system which causes the computer system to perform any of the methods or process steps described, represented, or illustrated herein. Examples of computer readable storage media include, but are not limited to: magnetic media, such as hard disks, floppy disks, and magnetic tape; optical media such as CD-ROMs, DVDs and holographic devices; magneto-optical media; and hardware devices that are specially configured to store and execute, such as application-specific integrated circuits (\u201cASICs\u201d), programmable logic devices (\u201cPLDs\u201d) and ROM and RAM devices. Examples of computer readable instructions include machine code, such as produced by a compiler, and files containing higher-level code that are executed by a computer using an interpreter. For example, an embodiment may be implemented using Java, C++, or other object-oriented programming language and development tools. Another embodiment may be implemented in hard-wired circuitry in place of, or in combination with machine readable software instructions.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 6","b":["600","600","605","655","600","640","655","610","615","610","615","605","615","600","625","630","600","625","630","600","635","600","650","650","600","645","600","620","660","660","660","650","660"]},"A data source is an information resource. Data sources include sources of data that enable data storage and retrieval. Data sources may include databases, such as, relational, transactional, hierarchical, multi-dimensional (e.g., OLAP), object oriented databases, and the like. Further data sources include tabular data (e.g., spreadsheets, delimited text files), data tagged with a markup language (e.g., XML data), transactional data, unstructured data (e.g., text files, screen scrapings), hierarchical data (e.g., data in a file system, XML data), files, a plurality of reports, and any other data source accessible through an established protocol, such as, Open DataBase Connectivity (ODBC), produced by an underlying software system (e.g., ERP system), and the like. Data sources may also include a data source where the data is not tangibly stored or otherwise ephemeral such as data streams, broadcast data, and the like. These data sources can include associated data foundations, semantic layers, management systems, security systems and so on.","In the above description, numerous specific details are set forth to provide a thorough understanding of embodiments. One skilled in the relevant art will recognize, however that the embodiments can be practiced without one or more of the specific details or with other methods, components, techniques, etc. In other instances, well-known operations or structures are not shown or described in detail.","Although the processes illustrated and described herein include series of steps, it will be appreciated that the different embodiments are not limited by the illustrated ordering of steps, as some steps may occur in different orders, some concurrently with other steps apart from that shown and described herein. In addition, not all illustrated steps may be required to implement a methodology in accordance with the one or more embodiments. Moreover, it will be appreciated that the processes may be implemented in association with the apparatus and systems illustrated and described herein as well as in association with other systems not illustrated.","The above descriptions and illustrations of embodiments, including what is described in the Abstract, is not intended to be exhaustive or to limit the one or more embodiments to the precise forms disclosed. While specific embodiments of, and examples for, are described herein for illustrative purposes, various equivalent modifications are possible within the scope of the one or more embodiments, as those skilled in the relevant art will recognize These modifications can be made in light of the above detailed description. Rather, the scope is to be determined by the following claims, which are to be interpreted in accordance with established doctrines of claim construction."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The claims set forth the embodiments with particularity. The embodiments are illustrated by way of example and not by way of limitation in the figures of the accompanying drawings in which like references indicate similar elements. The embodiments, together with its advantages, may be best understood from the following detailed description taken in conjunction with the accompanying drawings.",{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
