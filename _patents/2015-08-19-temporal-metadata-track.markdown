---
title: Temporal metadata track
abstract: Methods, data processing systems and machine readable non-transitory storage media are described that can provide, in one embodiment, a non-time based description of types of metadata in a time based metadata track that can be associated with, in time, a time based media track. The description can include a set of keys, or other identifiers, that specify the types of metadata in the metadata track, and the description can also include values describing the structure of each key and values describing how to interpret each key.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09507777&OS=09507777&RS=09507777
owner: Apple Inc.
number: 09507777
owner_city: Cupertino
owner_country: US
publication_date: 20150819
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DESCRIPTION"],"p":["The present invention relates to, in one embodiment, methods and systems for using a temporal metadata track. Many electronic devices have the ability to capture media such as still images, video, audio, or a combination thereof. For example, an electronic device can include a lens that is used to capture light from a user's environment and use the captured light to generate the still image or video. When the electronic device captures images substantially continuously (e.g. at a rate of 30 frames per second) the electronic device can store the images as video and play them back to provide a movie. To assist the user in managing the stored media, the electronic device can mark the media file with different types of information, such as metadata. For example, the electronic device can provide a date and time indicating when the video was recorded. As another example, an electronic device can specify attributes of the lens and other camera data such as shutter speed, F\/stop, and other information related to the camera. Some electronic devices can also mark a recorded video with location information specifying a location where the recording started and another location where the recording stopped. The metadata can be stored in a time independent manner or can be stored in a time dependent manner such as the manner described in part 12 of ISO\/IEC 14496-12:2008: The ISO Base Media File Format, available from the International Organization for Standardization. One or more metadata tracks can, when possible and appropriate, be linked to one or more tracks of the video or audio file that they described. The metadata tracks can include metadata values, such as GPS coordinates, camera data, etc.","Methods, data processing systems and machine readable, non-transitory storage media are described that can provide, in one embodiment, a non-time based description of metadata in a time based metadata track that can be associated with, in time, a time based media track. The description can include a set of keys, or other identifiers, that specify the types of metadata in the metadata track, and the description can also include values describing the structure of each key and values describing how to interpret each key or metadata identified by each key. In one embodiment, the non-time based description of metadata can provide an index and other information about the metadata in the time based metadata track. A playback device or other system can use the index to determine whether certain metadata exists in the time based metadata track without having to examine or search through the time based metadata track. In one embodiment, each key in the description uniquely specifies a type of metadata relative to all other types of metadata in the time based metadata track. Further, in one embodiment, a unique key can be reserved as a null value to specify the absence of metadata, for any type of metadata, in the time based metadata track. In one embodiment, the time based metadata track and the associated media tracks, such as audio or video tracks, can be stored in a container, such as a container used in the QuickTime movie file format.","In one embodiment, a machine readable non-transitory storage medium can include, in one file, a time based metadata track and a time based media track which is associated in time with the time based metadata track, and also can include a non-time based description of types of metadata in the time based metadata track.","In another aspect of the invention, a method, implemented through an application program interface (API) can include calling, through the API, to cause a definition of metadata in a time based metadata track that is associated with a time based media track. The call can specify a unique key for a particular type of metadata, and the call can cause the key and other data to be stored in a non-time based description of types of metadata in the metadata track.","Some embodiments include one or more application programming interfaces (APIs) in an environment with calling program code interacting with other program code being called through the one or more interfaces. Various function calls, messages or other types of invocations, which further may include various kinds of parameters, can be transferred via the APIs between the calling program and the code being called. In addition, an API may provide the calling program code the ability to use data types or classes defined in the API and implemented in the called program code.","At least certain embodiments include an environment with a calling software component interacting with a called software component through an API. A method for operating through an API in this environment includes transferring one or more function calls, messages, other types of invocations or parameters via the API.","Various embodiments and aspects of the inventions will be described with reference to details discussed below, and the accompanying drawings will illustrate the various embodiments. The following description and drawings are illustrative of the invention and are not to be construed as limiting the invention. Numerous specific details are described to provide a thorough understanding of various embodiments of the present invention. However, in certain instances, well-known or conventional details are not described in order to provide a concise discussion of embodiments of the present inventions.","Reference in the specification to \u201cone embodiment\u201d or \u201can embodiment\u201d means that a particular feature, structure, or characteristic described in conjunction with the embodiment can be included in at least one embodiment of the invention. The appearances of the phrase \u201cin one embodiment\u201d in various places in the specification do not necessarily all refer to the same embodiment. The processes depicted in the figures that follow are performed by processing logic that comprises hardware (e.g. circuitry, dedicated logic, etc.), software, or a combination of both. Although the processes are described below in terms of some sequential operations, it should be appreciated that some of the operations described may be performed in a different order. Moreover, some operations may be performed in parallel rather than sequentially.","In at least certain embodiments of the invention, a time based metadata track can be described by a non-time based description that can be referred to as a sample description. The time based metadata track can be a concatenated series of metadata contained within samples, or other distinct, retrievable objects, and each of these objects or samples can be associated with a playback time, such as a time stamp for a particular playback time, such that the metadata can be presented or retrieved along with audio or video when the audio or video (or both) is presented (e.g. displayed) even without presenting the media track. In other words, the time based metadata track has content, such as data for one or more types of metadata, that is synchronized in time with media content that is dependent upon time such as audio or video or both audio and video. In the case of the ISO (International Organization for Standardization) Standard ISO\/IEC 14496-12:2008: The ISO Base Media File Format, a track is a time sequence of related samples in an ISO base media file; for a media track implemented according to this international standard, a sample is an individual frame of video, a series of video frames in a decoding order or a compressed section of audio in decoding order, and a sample is all data associated with a single time stamp. In one implementation of this international standard, no two samples within a track can share the same time stamp and the time stamps can progress in time from a starting time to an ending time. The sample description, on the other hand, is not time based although it can include references to time for those embodiments in which the sample description provides an index to the location of metadata within the time based metadata track. The sample description provides a way to search or examine the time based metadata track without having to scan through or search the metadata track. This is useful because the metadata can sometimes be missing in the metadata track.","For example, runs of metadata within a time based metadata track can be interspersed with runs of no metadata. For example, GPS data may not be available when a recording system, such as a video camera which includes a GPS receiver, is used within a building, but the GPS signals and hence GPS data will generally be available when the recording device is used outside of the building. If a video is recorded both indoors and outdoors and the GPS receiver operates during the entire recording session, GPS data may be available while the device is outside of the building but often will not be available when the recording device is within the building. Hence, a metadata track containing GPS data may have time periods in the metadata track which include GPS data and other time periods where there is no GPS metadata in the metadata track, and thus this metadata track includes GPS metadata interspersed with no GPS metadata associated with the movie that was recorded. In some cases, the movie could be recorded and there is no GPS metadata because the entire movie was recorded within a building which prevented the GPS receiver from receiving GPS signals.","The various embodiments of the invention can provide a set of files (e.g. one or more files) or a file format that includes the time based media track(s) and a time based metadata track(s) and also includes the non-time based sample description. The set of files can be stored on a machine readable non-transitory storage medium, such as a flash memory or other semiconductor memory, magnetic memory, optical memory, etc. Other embodiments can include methods of creating the files, methods of transmitting or otherwise distributing the set of files, methods of using the set of files, such as playback or examination of the sample description that describes the metadata track, and methods of revising a sample description to correct for the absence of metadata that was expected or declared in the sample description. These methods can be performed by one or more data processing systems and can be performed by executing instructions from a machine readable non-transitory storage medium.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 1","FIG. 1"],"b":["101","105","103","103","103","109","111","113","113","107","103","110","107","109","111","113"]},"Sample description  can include a variety of information about each of the tracks , , and  and can be one or more sample descriptions even though only one sample description is shown in . In one embodiment, each track has at least one sample description. For example, sample description  can include height and width data  specifying the height and width of the video in the video tracks , and sample description  can include codec data  which specifies the codecs that can be used to decode one or both of the audio content or video content contained within audio track  and video track , respectively. In addition, sample description  can include data describing the metadata in the metadata track . In one implementation, this data describing the metadata in a metadata track can be an index specifying what metadata exists within a metadata track, and further the index can optionally specify the location of each type of metadata within the metadata track in at least certain embodiments.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 2","FIG. 3"],"b":["201","101","205","203","207","1","209","2","209","211","213","213","213","213","213","213","213","213","213","213","213","213","213","213"]},"Sample description  can include some of the same type of information as the sample description  such as codec data  and height and width data . Sample description  can also include a description of the metadata within the time based metadata track , and this sample description can provide information specifying the location of each group of samples, in time, within the metadata track . This sample description of the metadata is not dependent upon time and is not time based. Metadata information A provides information about the sample group within metadata track  which includes metadata of the types A and C. The sample description includes those identifiers A and C and includes an indication of the location of that group of samples containing metadata of the types A and C, where the location is shown, in this case, as spanning a period of time measured in, for example, seconds and milliseconds or other time measurements. Metadata information B can provide information about the metadata of metadata type B and can provide the location of the two sample groups of that metadata type (access units C and G) within the metadata track . Metadata information C can provide information in the sample description for the types of metadata B and C designated as such by the identifiers within the sample description and can also provide the location of the sample group containing these two types of metadata. Metadata information D can provide information about the metadata of three different types of metadata, designated with the identifiers A, B, and C which are specified within the sample description along with the location of that sample group (access unit F) in the metadata track . Finally, metadata information E can provide information about the metadata C and the location of that metadata within the metadata track .",{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIGS. 3 and 4","FIG. 3","FIGS. 9A and 9B"],"b":["303","301","307","1","6","319","309","5","309","309","311","311","1","313","3","313","313","301","315","2","315","315","317","4","317","319","307","309","311","313","315","317"]},"Sample description  can be similar to the sample description  or sample description . For example, it can include codec data  and height and width data  and other information commonly stored in a sample description, such as the sample descriptions for movies stored in a QuickTime movie format. In addition, sample description  includes information about the metadata stored within metadata tracks , , , , and  of . This information includes, for each type of metadata, the identifier for the type of metadata, a key name space for the identifier, data type information specifying how to interpret the metadata, and potentially other information such as, for example, the location within the metadata track of the metadata of that type. The sample description  can also include the null identifier \u201cnull ID\u201d  which will match and be identical to the null ID contained within the time based metadata tracks, such as the null ID contained within metadata track  or metadata track  or metadata track . Metadata information  provides information for the clip name metadata type and includes the identifier or key for that type of metadata (ID) as well as a key name space information for that identifier and a data type information specifying how to interpret the clip name (e.g. the clip name is provided in ASCII format, etc.). Metadata information  includes the identifier or key for GPS-type metadata as well as information with respect to the key name space for that identifier and data type information indicating how to interpret the GPS data coordinates (e.g. as latitude and longitude or other types of position information). Further, metadata information  can include other types of metadata information relating to that type of metadata. Metadata information  can include the identifier (ID) for copyright metadata and can include a key name space information describing a structure of that identifier for the copyright metadata and can also include data type information indicating how to interpret the metadata of this type. Metadata information  can include the identifier (ID) for camera data metadata and can include a key name space describing a data structure for the identifier ID and can also include data type information specifying how to interpret metadata of the camera data type such as whether the film speed is in ASA or ISO, etc. Metadata information  can include the identifier (ID) for face detection metadata and information about the key name space for that identifier ID and data type information specifying how to interpret the face detection metadata and potentially other types of information with respect to this type of metadata. While the examples shown in  includes five different types of metadata, it will be appreciated that a variety of different types of metadata can be included such as any one of the types shown in  and other types of metadata such as spatial orientation information (e.g. obtained from accelerometers), picture quality metadata, user added metadata, other types of position information metadata such as position information derived from a cellular telephone communication system or other types of satellite positioning systems other than the GPS system or location information derived from data networks, such as WiFi hotspot location information or other information derived from a data network. It will also be understood that the sample description  may include other types of information with respect to the metadata tracks, and that the metadata tracks can also include information about the metadata track such as the height and width (both being zero in a typical implementation) and a track volume (of zero) for the metadata track. Further, the metadata track can be associated with a time based media track (e.g. video and\/or audio tracks) by a reference that the time based metadata track describes the time based media track.","In certain embodiments, a system can allow additional metadata to be added after the creation or recording of a movie; for example, post-processing of the movie can be performed to add face detection metadata or to add metadata of picture quality so that this metadata can be used in further editing of the movie to, for example, improve picture quality by identifying areas of the movie that have poor picture quality and by performing image enhancements on those portions of the movie. The use of the key name space for an identifier allows certain formats to receive data from other formats without having to transcode the key or identifier from one format into another format. The data type information allows any system, receiving the file containing the sample description and the time based metadata track, to interpret the metadata in the metadata track.","A method for creating a sample description will now be provided with reference to . It will be appreciated that the operations shown in  can be performed in an order which is different than that shown in . In operation , a movie can be created by recording audio and video or by creating the audio and video to be stored in a time based media track. In operation , metadata is recorded into one or more metadata tracks which are associated in time with the time based media content, such as a movie. The metadata may be location metadata or copyright metadata or face detection metadata or other types of metadata known in the art. The metadata is captured and recorded into the one or more metadata tracks which are time based tracks such as the metadata track  shown in . In operation , the sample description which describes the metadata in the metadata track can be created. Operation  could occur before operation  in some embodiments. In operation , the time based media content and the time based metadata content with the sample description which is not time based can be stored as a single file or optionally as multiple files. For example, the time based media content and the time based metadata track and the sample description could be stored as a single file in the QuickTime movie file format that is known in the art.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 6","b":["401","205","601","605","607"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIGS. 7 and 8","FIG. 8"],"b":["701","701","802","703","705","705","803","707","701","707","705","707","707"]},"The metadata may not exist in some embodiments during recording because of power constraints. For example, in some embodiments a low power mode to conserve battery life may cause a restriction on the amount or even the presence of metadata in a time based metadata track. For example, GPS receivers can consume a lot of power and hence reduce battery life. It may be desirable in some embodiments to turn off the GPS receiver during a portion of recording a movie or during the entire movie in order to conserve battery power. Hence, as a result, certain types of metadata which are expected to be available may not, in fact, be available due to power conservation. Moreover, the frequency of the metadata within a metadata track may vary depending upon the power mode of the system. If the system has enough battery power the metadata may be recorded with a first frequency which is greater than a second frequency used when the system is operating under a low battery power mode.","After determining in operation  that certain expected types of metadata do not exist in the time based metadata track, then in operation , the sample description is revised to reflect what metadata actually exists within the metadata track. In one embodiment, a null value may be inserted into the sample description created in operation , and this null value is selected so that the size of the sample description does not change as a result of inserting the null value. Moreover, the insertion of a null value into the sample description can be an insertion and replacement in place such that the size of the sample description does not change and no other re-writing of the sample description is required. Table  shows an example of the revised sample description which includes a null value  which has been inserted in place of the face detection data . This creates the revised sample description  in which the null value  replaces the face detection data  in the sample description . In an alternative embodiment, the sample description can be rewritten to remove identifiers of metadata that do not actually exist within the metadata track, and the rewritten sample description can, as a result of this removal, change in size, and the containers or boxes that contain the sample description can also be rewritten to change their sizes as a result of this removal.","Some clients using timed metadata tracks may prefer to create metadata tracks samples that have the same size. Two exemplary approaches are described here. In one approach, the access values written might contain a fixed set of fixed-sized metadata values (see MetaDataAUBox above). If one or more values are not used, boxes corresponding to unused values can have their local_key_id set to an unreferenced value (e.g., 0). This can be done without resizing the AU. In the second approach, the size of individual metadata values may vary. It is possible to create constant-sized AUs by determining a maximum size and using unreferenced boxes to pad to this size. The approach is:\n\n",{"@attributes":{"id":"p-0040","num":"0043"},"figref":["FIGS. 9A and 9B","FIG. 9B"],"b":["915","901","902","905","907","911","1","2","3","4","2","3","1","2","2","3","915","913","911"],"sub":["0","1","2","3","4"]},"The following description provides an example of a specific embodiment of the invention. Metadata tracks use a null media header (\u2018nmhd\u2019), as defined in subclause 8.4.5.5 of ISO\/IEC 14496-12. As a metadata track is neither visual nor aural, the following track properties should have these values:\n\n","Sample Entry (or Sample Description) Format","Per ISO\/IEC 14496-12, the sample entry (or SampleDescription in QuickTime) is a MetaDataSampleEntry and is defined as:","and BitRateBox is defined as:",{"@attributes":{"id":"p-0045","num":"0052"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"aligned(8) class MetaDataSampleEntry(codingname) extends SampleEntry"},{"entry":"(codingname) {"},{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"and BitRateBox is defined as:",{"@attributes":{"id":"p-0047","num":"0054"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"aligned(8) class BitRateBox extends Box(\u2018btrt\u2019){"]},{"entry":[{},"unsigned int(32) bufferSizeDB;"]},{"entry":[{},"unsigned int(32) maxBitrate;"]},{"entry":[{},"unsigned int(32) avgBitrate;"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"The optional BitRateBox exists to indicate bitrates of the corresponding timed metadata streams. A sample entry format is described in which access units (such as media samples in QuickTime) contain values that are boxed. In a \u201cboxed\u201d access unit, metadata values are each surrounded by a ISO\/IEC 1449642 Box( ) structure. Access units may also include other boxes not holding metadata values. In this boxed design, zero, one or more values may be carried in an access unit for a particular time (actually a time range).","Sample Entry for Boxed AUs","The sample entry for boxed AUs is the BoxedMetaDataSampleEntry:",{"@attributes":{"id":"p-0051","num":"0058"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"aligned(8) class BoxedMetaDataSampleEntry extends"]},{"entry":[{},"MetaDataSampleEntry (\u2018mebx\u2019) {"]},{"entry":[{},"MetaDataKeyTableBox( );"]},{"entry":[{},"BitRateBox ( ); \/\/ optional"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Semantics\n\n","MetaDataKeyTableBox","The MetaDataKeyTableBox contains a table of keys and mappings to payload data in the corresponding access units. It is defined as:",{"@attributes":{"id":"p-0055","num":"0065"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"aligned(8) class MetaDataKeyTableBox extends Box(\u2018keys\u2019) {"]},{"entry":[{},"MetaDataKeyBox[ ];"]},{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"If the MetaDataKeyTableBox does not contain a key for which a client is searching, no access units associated with this sample entry contain values with that key. If the MetaDataKeyTableBox does contain a particular key, this does not however guarantee that any access units containing a value for the key were written. So clients finding a key in the MetaDataKeyTableBox may still need to look through the track's access units for values to determine if the track has the particular metadata. This rule allows a sample entry to be populated with keys that might be discovered (say during a capture process) and then access units to be written with a binding only for the keys found. If never used, there is no requirement that the sample entry be rewritten to exclude the key that was not needed. This makes writing using movie fragments easier as the sample entries in the initial movie never need to be rewritten. It is possible to remove unused sample entries efficiently and rewrite the sample entry, and this can be done using a method described relative to .","MetaDataKeyBox","MetaDataKeyBox is defined as:",{"@attributes":{"id":"p-0059","num":"0069"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"aligned(8) class MetaDataKeyBox extends Box(local_key_id) {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"MetaDataKeyDeclarationBox( );","\/\/ optional"]},{"entry":[{},"MetaDataDatatypeBox( );","\/\/ optional"]},{"entry":[{},"MetaDataLocalBox( );","\/\/ optional"]},{"entry":[{},"MetaDataSetupBox( );","\/\/ optional"]},{"entry":[{},"MetaDataExtensionsBox( );","\/\/ optional"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The box type for each MetaDataKeyBox is here referred to as \u2018local_key_id\u2019 and serves (1) as a unique identifier among all MetaDataKeyBoxes and (2) as the identifier for the metadata value boxes within access units that have that key.","The box type for the contained MetaDataKeyBox is \u2018local\u2019 to the containing track and corresponds to the box types (32-bit integers or four CCs) for boxes within metadata access units that hold that particular metadata value. For example, if the MetaDataKeyBox has the box type of \u2018stuf\u2019, any boxes of type \u2018stuf\u2019 in access units sharing this sample entry hold the value for this key. Any value fitting in a 32-bit big endian integer can be used (e.g., \u2018stuf\u2019, the integer 72) but it is recommended that it be mnemonic if possible.","There is one reserved box type for boxes of type MetaDataKeyBox. A local_key_id of 0 indicates that the MetaDataKeyBox is unused and should not be interpreted. This allows the key to be marked as unused in the sample entry without requiring the sample entry and parent atoms to be rewritten\/resized. All other box types are available for use. Because the children boxes within MetaDataKeyTableBox can take on any box type, there should be no special interpretation of the box type for contained boxes other than the special value 0. Therefore, including a \u2018free\u2019 box does not have the conventional meaning in the MetaDataKeyBox. Even so, it is recommended (but not required) to avoid overly confusing use of existing four CCs.","Each MetaDataKeyBox contains a variable number of boxes that define the key structure, optionally the datatype for values, optionally the locale for the values, and optional setup information needed to interpret the value.","MetaDataKeyDeclarationBox","The MetaDataKeyDeclarationBox holds the key namespace and key value of that namespace for the given values:",{"@attributes":{"id":"p-0066","num":"0076"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"aligned(8) class MetaDataKeyDeclarationBox extends Box(\u2018keyd\u2019) {"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"unsigned int(32) key_namespace;"]},{"entry":[{},"unsigned int(8) key_value[ ];"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"};"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Semantics\n\n","Examples of a few possible key namespaces (or \u201ckeyspaces\u201d) could be:\n\n","MetaDataDatatypeDefinitionBox","To specify the data type of the value, it is possible to include an optional MetaDataDatatypeDefinitionBox as defined here:",{"@attributes":{"id":"p-0071","num":"0088"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"aligned(8) class MetaDataDatatypeDefinitionBox extends Box (\u2018dtyp\u2019) {"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"unsigned int(32) datatype_namespace;"]},{"entry":[{},"unsigned int(8) datatype[ ];"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Semantics\n\n","MetaDataLocaleBox","A metadata value may optionally be tagged with its locale so that it may be chosen based upon the user's language, country, etc. This makes it possible to include several keys of the same key type (e.g., copyright or scene description) but with differing locales for users of different languages or locations.","This is accomplished by including a MetaDataLocaleBox within the MetaDataKeyBox. The definition of MetaDataLocaleBox is:",{"@attributes":{"id":"p-0076","num":"0095"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"aligned(8) class MetaDataLocaleBox extends Box(\u2018loca\u2019) {"]},{"entry":[{},"string locale_string;"]},{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Semantics\n\n","MetaDataSetupBox","Some metadata values benefit from having setup information to describe their interpretation. This setup data is private to the metadata datatype. The data can take the form of leaf data bytes or children boxes.",{"@attributes":{"id":"p-0080","num":"0102"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"aligned(8) class MetaDataSetupBox extends Box(\u2018setu\u2019) {\/\/ \u2018init\u2019"]},{"entry":[{},"instead?"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"An example might be information used to interpret the coordinate system of rectangles used in face detection metadata. As mentioned, the contents of MetaDataSetupBox can be boxes or raw data, the structure being dependent upon the data type. Another kind of setup might be a media type (e.g., \u2018vide\u2019) and a sample description. This would allow the metadata to reference a still image compliant with H.264 because the setup for the \u2018acv1\u2019 decoder is available.","MetaDataExtensionsBox","Some metadata values may benefit from having publicly defined and interpretable state associated with them. This is in contrast to the type-specific private state held in MetaDataSetupBox( ). By analogy, VisualSampleEntries may have PixelAspectRatioBox (\u2018pasp\u2019) or CleanApertureBox (\u2018clapC\u2019) extensions.\n\n","Semantics\n\n","Sample Data Format","An access unit (e.g. a media sample) is structured as a concatenation of one or more Boxes. Typically each box will contain a metadata value corresponding to a key signaled in the sample entry.","If no value for a particular key is present in the access unit at the given time, the interpretation should be that there is no metadata of that type at the time. Metadata values for that key for other times (e.g., from a previous access unit) should not be interpreted as applying to the target time.","If no values for any key are present for a time range, one approach is to include a \u201cNULL\u201d access unit (or AU) for the time range. In one embodiment, a zero-byte sized AU should not be used, in one embodiment, as all sample sizes must be one or more bytes in size. Also, an empty track edit list entry could be used to indicate there is no metadata for a range of movie time.","In one embodiment, however, it is preferable to include a NULL AU instead of using a track edit with an empty edit to indicate the absence of metadata.","Boxed Metadata AU","A boxed access unit (e.g. a media sample in QuickTime) is defined as:",{"@attributes":{"id":"p-0092","num":"0116"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"aligned(8) class MetaDataAccessUnit {"]},{"entry":[{},"Box boxes[ ];"]},{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"It consists of some number of concatenated boxes derived from a type referred to as MetaDataAUBox:",{"@attributes":{"id":"p-0094","num":"0118"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"aligned(8) class MetaDataAUBox extends Box(local_key_id) {"]},{"entry":[{},"};"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Semantics\n\n","So, by way of an example, if one were to carry VANC data in an access unit, it might be carried in a derived MetaDataAUEntry something like this:",{"@attributes":{"id":"p-0097","num":"0122"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"aligned(8) class VANCMetaDataAUEntry extends"]},{"entry":[{},"metaDataAUEntry(local_key_id) {"]},{"entry":[{},"unsigned int(8) vanc_data[...];"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Here, the structure of the value is specific to how such VANC data is thought useful to carry. There is no VANCMetaDataAUEntry described herein; it is simply an example. As described before, local_key_id values of 0 are reserved.","A MetaDataAccessUnit may contain boxes with types (the local_key_id) other than those advertised in the MetaDataKeyTableBox although this is discouraged. Any instances of such boxes may be interpreted according to their conventional meaning (e.g., \u2018free\u2019) or in a private way so long as they are not advertised as keys.","Using Sample Groups to Optimize Key Searches","This section describes an optional mechanism to optimize searches for metadata track access units containing particular key\/value pairs.","Sample Group Overview","A metadata track conforming to this specification may optionally make use of the SampleGroupDescriptionBox and SampleToGroupBox constructs to optimize searching for access units containing particular keys. This can be characterized as having a \u2018key search sample group.\u2019","The SampleGroupDescriptionBox and SampleToGroupBox are defined in ISO\/IEC 14496-12. A sample group consists of two parts: a SampleGroupDescriptionBox containing a collection of differing \u201cdescriptions\u201d serving to describe properties of samples and a SampleToGroupBox mapping samples to a description. Each of SampleGroupDescriptionBox and SampleToGroupBox making up the sample group are tagged with the same grouping type field to indicate the type of grouping and to distinguish this sample group from other sample groups. At most (in one embodiment) one sample group within a track may have the same grouping type.","An example sample group is the pre-roll sample group used with audio pre-roll. The pre-roll group uses the grouping type \u2018roll\u2019.","Optimizing Search with a New Sample Group","In a metadata track containing one or more sample entries in one embodiment, the MetaDataKeyTableBox( ) in the BoxedMetaDataSampleEntry can be used to determine possible keys present in the track's AUs. If a key is not present in the MetaDataKeyTableBox( ), it is known that the key doesn't exist in any AUs. It doesn't however indicate which samples have particular keys (and associated values). Therefore, to determine which metadata keys are present in the track requires an exhaustive search of AUs (associated with that sample entry) in the metadata track in one embodiment.","While it would be possible to create a track with sample entries for each combination of keys present in the track and only associate the samples with that combination with the particular sample entry, having many sample entries may not be ideal or easily done. An alternative (described here) is to define a new kind of sample group that indicates the keys present in an AU.","The new sample group consists of a SampleGroupDescriptionBox holding a new group description for each new combination of keys present in AUs. If all AUs consist of the same four keys, for example, there would be one group description with these four keys. If the set of keys varied, there need only be as many descriptions as there are different sets of keys present in AUs.","A client looking for AUs with a particular key (or keys) would first consult the sample entry (or sample entries if there are more than one) and determine if the key is present in the set of possible keys (via MetaDataKeyTableBox( )). If this succeeds, the client would check if the optional sample group exists, and finding this to be the case, the client would walk through the SampleToGroupBox checking if the corresponding sample group description contains the key. As these operations require only information present in the MovieBox( ), direct reading and processing of AUs is unnecessary. While \u201ckey\u201d is used here as being present in the sample group description, an equivalent, more compact identifier can be used.","Definition of the Key Search Sample Group","For this section, an optional sample group known as a \u201ckey search sample group\u201d can be defined. It consists of SampleGroupDescriptionBox and SampleToGroupBox having the grouping type \u2018keyp\u2019.","The SampleGroupDescriptionBox can contain variable-sized SampleGroupDescriptionEntries, each of type MetaDataKeySearchGroupEntry. MetaDataKeySearchGroupEntry is defined in one embodiment as:",{"@attributes":{"id":"p-0114","num":"0139"},"tables":{"@attributes":{"id":"TABLE-US-00013","num":"00013"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class MetaDataKey SearchGroupEntry( ) extends"]},{"entry":[{},"SampleGroupDescriptionEntry(\u2018keyp\u2019) {"]},{"entry":[{},"unsigned int(32) entry_count;"]},{"entry":[{},"unsigned int(32) local_key_ids_array[entry_count];"]},{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Semantics\n\n","Each sample group description entry signals the presence of one or more keys from the key table found in the sample entry associated with the sample(s). Access units associated with this sample group description shall have corresponding metadata values with these same keys.","Each key in use can be signaled by using the 32-bit integer value of the local_key_id field associated with the MetaDataKeyTableBox entry. This local key id is also used in access units as the type of Box holding the corresponding value.","If two samples differ in the keys present, they cannot, in one embodiment, share the same sample group description. A sample group description for each combination should be created. While not strictly required, it is recommended that the order of local_key_ids be the same as the order of local key ids in the MetaDataKeyTableBox of the sample entry. This prevents group descriptions with the same set of keys but differing only in key order from creating multiple, trivially different sample group descriptions.","As the number of local key ids present in MetaDataKeySearchGroupEntry will typically vary, the containing SampleGroupDescriptionBox should be a version 1 SampleGroupDescriptionBox with a default length set to 0. This indicates there is a 32-bit size before each group description entry holding the size in bytes of the following entry. A version 0 SampleGroupDescriptionBox should not be used.","Finally, if a sample group spans multiple sample entries with different sets of keys, the local key ids present in the sample entries spanned should be compatible in one embodiment (i.e., the local_key_id must be present in each MetaDataKeyTableBox and the corresponding key table entry must be the same).","The use of sample group descriptions can allow for rapid search of a run of access units that contain the same set of metadata types. A sample group description, in one embodiment, can be limited to a specific consecutive (in time) set of access units that contain the same set of metadata types, and each of the access units in this set can include an identifier that maps to or points to the corresponding sample group description.","One or more Application Programming Interfaces (APIs) may be used in some embodiments. An API is an interface implemented by a program code component or hardware component (hereinafter \u201cAPI-implementing component\u201d) that allows a different program code component or hardware component (hereinafter \u201cAPI-calling component\u201d) to access and use one or more functions, methods, procedures, data structures, classes, and\/or other services provided by the API-implementing component. An API can define one or more parameters that are passed between the API-calling component and the API-implementing component.","An API allows a developer of an API-calling component (which may be a third party developer) to leverage specified features provided by an API-implementing component. There may be one API-calling component or there may be more than one such component. An API can be a source code interface that a computer system or program library provides in order to support requests for services from an application. An operating system (OS) can have multiple APIs to allow applications running on the OS to call one or more of those APIs, and a service (such as a program library) can have multiple APIs to allow an application that uses the service to call one or more of those APIs. An API can be specified in terms of a programming language that can be interpreted or compiled when an application is built.","In some embodiments the API-implementing component may provide more than one API, each providing a different view of or with different aspects that access different aspects of the functionality implemented by the API-implementing component. For example, one API of an API-implementing component can provide a first set of functions and can be exposed to third party developers, and another API of the API-implementing component can be hidden (not exposed) and provide a subset of the first set of functions and also provide another set of functions, such as testing or debugging functions which are not in the first set of functions. In other embodiments the API-implementing component may itself call one or more other components via an underlying API and thus be both an API-calling component and an API-implementing component.","An API defines the language and parameters that API-calling components use when accessing and using specified features of the API-implementing component. For example, an API-calling component accesses the specified features of the API-implementing component through one or more API calls or invocations (embodied for example by function or method calls) exposed by the API and passes data and control information using parameters via the API calls or invocations. The API-implementing component may return a value through the API in response to an API call from an API-calling component. While the API defines the syntax and result of an API call (e.g., how to invoke the API call and what the API call does), the API may not reveal how the API call accomplishes the function specified by the API call. Various API calls are transferred via the one or more application programming interfaces between the calling (API-calling component) and an API-implementing component. Transferring the API calls may include issuing, initiating, invoking, calling, receiving, returning, or responding to the function calls or messages; in other words, transferring can describe actions by either of the API-calling component or the API-implementing component. The function calls or other invocations of the API may send or receive one or more parameters through a parameter list or other structure. A parameter can be a constant, key, data structure, object, object class, variable, data type, pointer, array, list or a pointer to a function or method or another way to reference a data or other item to be passed via the API.","Furthermore, data types or classes may be provided by the API and implemented by the API-implementing component. Thus, the API-calling component may declare variables, use pointers to, use or instantiate constant values of such types or classes by using definitions provided in the API.","Generally, an API can be used to access a service or data provided by the API-implementing component or to initiate performance of an operation or computation provided by the API-implementing component. By way of example, the API-implementing component and the API-calling component may each be any one of an operating system, a library, a device driver, an API, an application program, or other module (it should be understood that the API-implementing component and the API-calling component may be the same or different type of module from each other). API-implementing components may in some cases be embodied at least in part in firmware, microcode, or other hardware logic. In some embodiments, an API may allow a client program to use the services provided by a Software Development Kit (SDK) library. In other embodiments an application or other client program may use an API provided by an Application Framework. In these embodiments the application or client program may incorporate calls to functions or methods provided by the SDK and provided by the API or use data types or objects defined in the SDK and provided by the API. An Application Framework may in these embodiments provide a main event loop for a program that responds to various events defined by the Framework. The API allows the application to specify the events and the responses to the events using the Application Framework. In some implementations, an API call can report to an application the capabilities or state of a hardware device, including those related to aspects such as input capabilities and state, output capabilities and state, processing capability, power state, storage capacity and state, communications capability, etc., and the API may be implemented in part by firmware, microcode, or other low level logic that executes in part on the hardware component.","The API-calling component may be a local component (i.e., on the same data processing system as the API-implementing component) or a remote component (i.e., on a different data processing system from the API-implementing component) that communicates with the API-implementing component through the API over a network. It should be understood that an API-implementing component may also act as an API-calling component (i.e., it may make API calls to an API exposed by a different API-implementing component) and an API-calling component may also act as an API-implementing component by implementing an API that is exposed to a different API-calling component.","The API may allow multiple API-calling components written in different programming languages to communicate with the API-implementing component (thus the API may include features for translating calls and returns between the API-implementing component and the API-calling component); however the API may be implemented in terms of a specific programming language. An API-calling component can, in one embodiment, call APIs from different providers such as a set of APIs from an OS provider and another set of APIs from a plug-in provider and another set of APIs from another provider (e.g. the provider of a software library) or creator of the another set of APIs.",{"@attributes":{"id":"p-0130","num":"0157"},"figref":["FIG. 10","FIG. 10"],"b":["1000","1010","1020","1020","1030","1020","1030","1020","1010","1020","1010","1020","1030"]},"It will be appreciated that the API-implementing component  may include additional functions, methods, classes, data structures, and\/or other features that are not specified through the API  and are not available to the API-calling component . It should be understood that the API-calling component  may be on the same system as the API-implementing component  or may be located remotely and accesses the API-implementing component  using the API  over a network. While  illustrates a single API-calling component  interacting with the API , it should be understood that other API-calling components, which may be written in different languages (or the same language) than the API-calling component , may use the API .","The API-implementing component , the API , and the API-calling component  may be stored in a machine-readable medium, which includes any mechanism for storing information in a form readable by a machine (e.g., a computer or other data processing system). For example, a machine-readable medium includes magnetic disks, optical disks, random access memory; read only memory, flash memory devices, etc.","In  (\u201cSoftware Stack\u201d), an exemplary embodiment, applications can make calls to Services A or B using several Service APIs and to Operating System (OS) using several OS APIs. Services A and B can make calls to OS using several OS APIs.","Note that the Service  has two APIs, one of which (Service  API ) receives calls from and returns values to Application  and the other (Service  API ) receives calls from and returns values to Application . Service  (which can be, for example, a software library) makes calls to and receives returned values from OS API , and Service  (which can be, for example, a software library) makes calls to and receives returned values from both OS API  and OS API . Application  makes calls to and receives returned values from OS API .",{"@attributes":{"id":"p-0135","num":"0162"},"figref":["FIG. 12","FIG. 12"],"b":["1200","1200"]},"As shown in , the computer system , which is a form of a data processing system, includes a bus  which is coupled to a microprocessor(s)  and a ROM (Read Only Memory)  and volatile RAM  and a non-volatile memory . The microprocessor  may retrieve the instructions from the memories , ,  and execute the instructions to perform operations described above. Memories , , and  are examples of machine readable non-transitory storage media that can store computer program instructions for execution. The bus  interconnects these various components together and also interconnects these components , , , and  to a display controller and display device  and to peripheral devices such as input\/output (I\/O) devices which may be mice, keyboards, modems, network interfaces, printers and other devices which are well known in the art. Typically, the input\/output devices  are coupled to the system through input\/output controllers . The volatile RAM (Random Access Memory)  is typically implemented as dynamic RAM (DRAM) which requires power continually in order to refresh or maintain the data in the memory.","The mass storage  is typically a magnetic hard drive or a magnetic optical drive or an optical drive or a DVD RAM or a flash memory or other types of memory systems which maintain data (e.g. large amounts of data) even after power is removed from the system. Typically, the mass storage  will also be a random access memory although this is not required. While  shows that the mass storage  is a local device coupled directly to the rest of the components in the data processing system, it will be appreciated that the present invention may utilize a non-volatile memory which is remote from the system, such as a network storage device which is coupled to the data processing system through a network interface such as a modem, an Ethernet interface or a wireless network. The bus  may include one or more buses connected to each other through various bridges, controllers and\/or adapters as is well known in the art. Computer system  can optionally include a metadata and media acquisition device . While one such metadata and media acquisition device is shown, it will be appreciated that the computer system can include a plurality of such metadata and media acquisition devices. In one embodiment, the metadata and media acquisition device is an electronic device tethered to the computer system . In another embodiment, the metadata and media acquisition device  is a device integrated into the computer system  and can capture media and metadata such as location, orientation, and motion information, etc. Furthermore, this device  can associate the location, orientation, or motion information or other metadata with the captured media as described herein. In another embodiment, system  can include one or more devices for capturing media (e.g. a camera and a microphone for capturing a movie) and one or more other, separate devices (e.g. a GPS receiver) for capturing metadata (e.g. GPS coordinates).",{"@attributes":{"id":"p-0138","num":"0165"},"figref":["FIG. 13","FIG. 13"],"b":["1300","1300","1300","1311","1301","1300","1305"]},"A display controller and display device  can provide a visual user interface for the user; this interface may include a graphical user interface which is similar to that shown on a Macintosh computer when running OS X operating system software or on an iPhone. The system  also includes one or more wireless transceivers  to communicate with another data processing system. A wireless transceiver may be a WLAN transceiver (e.g. WiFi), an infrared transceiver, a Bluetooth transceiver, and\/or a wireless cellular telephony transceiver. It will be appreciated that additional components, not shown, may also be part of the system  in certain embodiments, and in certain embodiments fewer components than shown in  may also be used in a data processing system. The system  further includes one or more communications ports  to communicate with another data processing system. The communications port may be a USB port, Firewire port, Bluetooth interface, a docking port, etc.","The data processing system  also includes one or more input devices  which are provided to allow a user to provide input to the system. These input devices may be a keypad or a keyboard or a touch panel or a multi-touch panel which is overlaid and integrated with a display device. The data processing system  also includes an optional input\/output device  which may be a connector for a dock. It will be appreciated that one or more buses, not shown, may be used to interconnect the various components as is well known in the art. The data processing system shown in  may be a handheld computer or a personal digital assistant (PDA), or a cellular telephone with PDA-like functionality, or a handheld computer which includes a cellular telephone, or a media player, such as an iPod, or a game or entertainment device, or devices which combine aspects or functions of these devices, such as a media player combined with a PDA and a cellular telephone in one device or an embedded device or other consumer electronic devices. In other embodiments, the data processing system  may be a network computer or an embedded processing device within another device, or other types of data processing systems which have fewer components or perhaps more components than that shown in .","Data processing system  can optionally include one or more metadata and media acquisition devices, such as device . In one embodiment, the metadata and media acquisition device is an electronic device tethered to the data processing system . In another embodiment, metadata and media acquisition device  is a device integrated into the computer system  and can capture media and metadata information. In another embodiment, system  can include one or more devices for capturing media (e.g., a camera and a microphone for capturing a movie) and one or more other separate devices (e.g. a GPS receiver) for capturing metadata. Furthermore, this device  can associate the metadata information with the captured media as described herein.","At least certain embodiments of the inventions may be part of a digital media player, such as a portable music and\/or video media player, which may include a media processing system to present the media, a storage device to store the media and may further include a radio frequency (RF) transceiver (e.g., an RF transceiver for a cellular telephone) coupled with an antenna system and the media processing system. In certain embodiments, media stored on a remote storage device may be transmitted to the media player through the RF transceiver. The media may be, for example, one or more of music or other audio, still pictures, or motion pictures.","The portable media player may include a media selection device, such as a click wheel input device on an iPod\u00ae or iPod Nano\u00ae media player from Apple Inc. of Cupertino, Calif., a touch screen input device, pushbutton device, movable pointing input device or other input device. The media selection device may be used to select the media stored on the storage device and\/or the remote storage device. The portable media player may, in at least certain embodiments, include a display device which is coupled to the media processing system to display titles or other indicators of media being selected through the input device and being presented, either through a speaker or earphone(s), or on the display device, or on both display device and a speaker or earphone(s). Examples of a portable media player are described in published U.S. Pat. No. 7,345,671 and U.S. published patent application number 2004\/0224638, both of which are incorporated herein by reference.","In the foregoing specification, the invention has been described with reference to specific exemplary embodiments thereof. It will be evident that various modifications may be made thereto without departing from the broader spirit and scope of the invention as set forth in the following claims. The specification and drawings are, accordingly, to be regarded in an illustrative sense rather than a restrictive sense."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings in which like references indicate similar elements.",{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIGS. 9A and 9B"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
