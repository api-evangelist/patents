---
title: Printable representations for time-based media
abstract: The system of the present invention allows a user to generate a representation of time-based media. The system of the present invention includes a feature extraction module for extracting features from media content. For example, the feature extraction module can detect solos in a musical performance, or can detect music, applause, speech, and the like. A formatting module formats a media representation generated by the system. The formatting module also applies feature extraction information to the representation, and formats the representation according to a representation specification. In addition, the system can include an augmented output device that generates a media representation based on the feature extraction information and the representation specification. The methods of the present invention include extracting features from media content, and formatting a media representation being generated using the extracted features and based on a specification or data structure specifying the representation format. The methods can also include generating a media representation based on the results of the formatting.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07747655&OS=07747655&RS=07747655
owner: Ricoh Co. Ltd.
number: 07747655
owner_city: Tokyo
owner_country: JP
publication_date: 20040330
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCES TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["This application claims the benefit of the following provisional patent applications, each of which is incorporated by reference in its entirety: U.S. Provisional patent application entitled \u201cPrinter Including One or More Specialized Hardware Devices\u201d filed on Sep. 25, 2003, having Ser. No. 60\/506,303; U.S. Provisional patent application entitled \u201cPrinter For Non-Paper and Multiple Media Types\u201d filed on Sep. 25, 2003, having Ser. No. 60\/506,411; and U.S. Provisional patent application entitled \u201cSystems and Methods for Printing Audio or Video Paper\u201d filed on Sep. 25, 2003, having Ser. No. 60\/506,263.","This application is a related to the following co-pending U.S. patent applications (hereinafter referred to as the \u201cVideo Paper Applications\u201d), each of which is hereby incorporated by reference in its entirety: U.S. patent application Ser. No. 10\/001,895, \u201cPaper-based Interface for Multimedia Information,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,849, \u201cTechniques for Annotating Multimedia Information,\u201d filed Nov. 19, 2001; application Ser. No. 10\/001,893, \u201cTechniques for Generating a Coversheet for a paper-based Interface for Multimedia Information,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,894, \u201cTechniques for Retrieving Multimedia Information Using a Paper-Based Interface,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/001,891, \u201cPaper-based Interface for Multimedia Information Stored by Multiple Multimedia Documents,\u201d filed Nov. 19, 2001; U.S. patent application Ser. No. 10\/175,540, \u201cDevice for Generating a Multimedia Paper Document,\u201d filed Jun. 18, 2002; and U.S. patent application Ser. No. 10\/645,821, \u201cPaper-Based Interface for Specifying Ranges,\u201d filed Aug. 20, 2003.","This application is also related to the following co-pending patent applications, each of which is hereby incorporated by reference in its entirety: U.S. patent application entitled, \u201cPrinter Having Embedded Functionality for Printing Time-Based Media,\u201d to Hart et al., filed Mar. 30, 2004; U.S. patent application entitled, \u201cPrinter With Hardware and Software Interfaces for Peripheral Devices,\u201d to Hart et al., filed Mar. 30, 2004; U.S. patent application entitled, \u201cPrinter User Interface,\u201d to Hart et al., filed Mar. 30, 2004; and U.S. patent application entitled \u201cNetworked Printing System Having Embedded Functionality for Printing Time-Based Media,\u201d to Hart, et al., filed Mar. 30, 2004.","1. Field of the Invention","The present invention relates to systems and methods for generating printable representations for time-based media.","2. Description of the Background Art","Conventional printers are currently used to generate documents of various different formats and based upon different types of content. However, while conventional printers can produce images of text and\/or pictures, conventional printers are limited in their ability to effectively generate representations of multimedia content. Conventional printers print onto a fixed medium, such as paper, and thus they are unable to effectively capture the elements of time-based media.","Yet, the capability to easily review time-based media content is commonly needed today. To search for desired features within time-based media content currently, one must actually review the content itself, skimming to find the desired information. For example, a user may have to manually skim an audio recording of a radio talk show to find content on a particular topic or to find discussions by a particular speaker. Due to these limitations in conventional printers, there is currently no easy way for users to search through a lengthy media segment to identify and extract particular features of interest from the media content. Additionally, there is no way for users to create an easily readable representation of media that provides useful information about the media.","Moreover, media content is commonly only available in digital form. However, for many users, a digital format is not the optimal format in which to view information. While viewing media information in digital form is adequate for some users, many users find it easier to comprehend and assimilate information when the information is printed on a paper medium. Nonetheless, there is not currently available a mechanism for generating a paper-based representation of time-based media through which the user can review or even access media content.","Therefore, what is needed is a system and methods for generating a representation of time-based media that can be paper-based and can provide users with the ability to extract defined features in the multimedia content.","The present invention overcomes the deficiencies and limitations of the prior art with a system and method for generating a representation of time-based media. The system of the present invention includes a feature extraction module for extracting features from media content. For example, the feature extraction module can detect solos in a musical performance, or can detect music, applause, speech, and the like. A formatting module formats a media representation generated by the system. The formatting module also applies feature extraction information to the representation, and formats the representation according to a representation specification. In addition, the system can include an augmented output device that generates a media representation based on the feature extraction information and the representation specification. The representation can be generated in a paper-based format, in digital format, or in any other representation formats. The representation generated can include user-selectable identifiers that enable random access to points along a media content timeline.","The methods of the present invention include extracting features from media content, and formatting a media representation using the extracted features and based on a specification or data structure specifying the representation format. The methods can also include generating a media representation based on the results of the formatting.","A system and method for generating a representation of time-based media is described. According to an embodiment of the present invention, a printer generates a representation of time-based media that can incorporate feature extraction information and can be formatted according to a representation specification. More specifically, the printer incorporates a format specification, feature extraction, and a formatting algorithm to produce documents that provide a visual representation for multimedia information (e.g., an audio recording), and provide an index that enables random access to points in a multimedia recording.","For the purposes of this invention, the terms \u201cmedia,\u201d \u201cmultimedia,\u201d \u201cmultimedia content,\u201d \u201cmultimedia data,\u201d or \u201cmultimedia information\u201d refer to any one of or a combination of text information, graphics information, animation information, sound (audio) information, video information, slides information, whiteboard images information, and other types of information. For example, a video recording of a television broadcast may comprise video information and audio information. In certain instances the video recording may also comprise close-captioned (CC) text information, which comprises material related to the video information, and in many cases, is an exact representation of the speech contained in the audio portions of the video recording. Multimedia information is also used to refer to information comprising one or more objects wherein the objects include information of different types. For example, multimedia objects included in multimedia information may comprise text information, graphics information, animation information, sound (audio) information, video information, slides information, whiteboard images information, and other types of information.","For the purposes of this invention, the terms \u201cprint\u201d or \u201cprinting,\u201d when referring to printing onto some type of medium, are intended to include printing, writing, drawing, imprinting, embossing, generating in digital format, and other types of generation of a data representation. Also for purposes of this invention, the output generated by the system will be referred to as a \u201cmedia representation,\u201d a \u201cmultimedia document,\u201d a \u201cmultimedia representation,\u201d a \u201cdocument,\u201d a \u201cpaper document,\u201d or either \u201cvideo paper\u201d or \u201caudio paper.\u201d While the words \u201cdocument\u201d and \u201cpaper\u201d are referred to in these terms, output of the system in the present invention is not limited to such a physical medium, like a paper medium. Instead, the above terms can refer to any output that is fixed in a tangible medium. In some embodiments, the output of the system of the present invention can be a representation of multimedia content printed on a physical paper document. In paper format, the multimedia document takes advantage of the high resolution and portability of paper and provides a readable representation of the multimedia information. According to the teachings of the present invention, a multimedia document may also be used to select, retrieve, and access the multimedia information. In other embodiments, the output of the system can exist in digital format or some other tangible medium. In addition, the output of the present invention can refer to any storage unit (e.g., a file) that stores multimedia information in digital format. Various different formats may be used to store the multimedia information. These formats include various MPEG formats (e.g., MPEG , MPEG , MPEG , MPEG , etc.), MP3 format, SMIL format, HTML+TIME format, WMF (Windows Media Format), RM (Real Media) format, Quicktime format, Shockwave format, various streaming media formats, formats being developed by the engineering community, proprietary and customary formats, and others.","Reference in the specification to \u201cone embodiment\u201d or \u201can embodiment\u201d means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the invention. The appearances of the phrase \u201cin one embodiment\u201d in various places in the specification are not necessarily all referring to the same embodiment.","In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the invention. It will be apparent, however, to one skilled in the art that the invention can be practiced without these specific details. In other instances, structures and devices are shown in block diagram form in order to avoid obscuring the invention. For example, the present invention is described primarily with reference to audio content, and the representation generated by the printer is often referred to as audio paper. However, the features of the present invention apply to any type of media content and refer to media representations in formats other than paper-based formats, even if the description discusses the features only in reference to audio content and audio paper.","Referring now to , an exemplary system  for generating a representation of time-based media is shown. In this embodiment, there is shown an augmented output device or a printer  for generating multimedia representations. The printer  comprises a number of components, including the following: a conventional printer , an audio paper production system (APPS) , and processing logic  for a printer console and for a printer driver interface.","The printer  receives multimedia data, such as audio data, and this content may be stored in a multimedia document that is accessible to system . The multimedia content may be stored directly on system , or it may be information stored on an external storage device or a server (not shown) that can be accessed by system . In other embodiments, instead of accessing a multimedia document, the system  may receive a stream of multimedia information (e.g., a streaming media signal, a cable signal, etc.) from a multimedia information source. Examples of sources that can provide multimedia information to system  include a television, a television broadcast receiver, a cable receiver, a video recorder, a digital video recorder, a personal digital assistant (PDA), or the like. For example, the source of multimedia information may be embodied as a radio that is configured to receive multimedia broadcast signals and to transmit the signals to system . In this example, the information source may be a radio antenna providing live radio broadcast feed information to system . The information source may also be a device such as a video recorder\/player, a digital video disc (DVD) player, a compact disc (CD) player, etc. providing recorded video and\/or audio stream to system . In alternative embodiments, the source of information may be a presentation or meeting recorder device that is capable of providing a stream of the captured presentation or meeting information to system . Additionally, the source of multimedia information may be a receiver (e.g., a satellite dish or a cable receiver) that is configured to capture or receive (e.g., via a wireless link) multimedia information from an external source and then provide the captured multimedia information to system  for further processing.","Multimedia content can originate from some type proprietary or customized multimedia player, such as RealPlayer\u2122, Microsoft Windows Media Player, and the like. In alternative embodiments, system  may be configured to intercept multimedia information signals received by a multimedia information source. System  may receive the multimedia information directly from a multimedia information source or may alternatively receive the information via a communication network (not shown).","Referring again to the components of printer , there is shown in  a conventional printer  component of printer . The conventional printer  component of the printer  can include all or some of the capabilities of a standard or conventional printing device, such as an inkjet printer, a laser printer, or other printing device. Thus, conventional printer  has the functionality to print paper documents, and may also have the capabilities of a fax machine, a copy machine, and other devices for generating physical documents. More information about printing systems is provided in the U.S. patent application entitled \u201cNetworked Printing System Having Embedded Functionality for Printing Time-Based Media,\u201d to Hart, et al., filed Mar. 30, 2004, which is hereby incorporated by reference in its entirety.","In , there is also shown an audio paper production system (APPS)  in this embodiment of the present invention. This system is referred to as an audio paper production system, but it could alternatively be a video paper production system in other embodiments, or any other type of multimedia production system. Additionally, though the APPS  refers to the word \u201cpaper\u201d in its title, the APPS  can also be used to generate multimedia representations in digital format and other types of formats.","The APPS  is shown in  as being part of the printer . However, in other embodiments, the APPS  is located remotely, on a personal computer (PC) (not shown) for example, which can be connected to the printer . The APPS  includes a feature extraction capabilities and formatting capabilities. An audio file enters the APPS  as input and feature extraction techniques are applied to generate a representation  of the multimedia content (i.e., a representation of audio content in waveform). The representation or document  can include markers for particular features recognized within the multimedia content during feature extraction. For example, the representation  could include markers for each time, along an audio timeline, that applause occurs or for each time there is a saxophone solo within a music track. The feature extraction techniques applied may be user defined, or may alternatively be set by a default printer  setting. The formatting functionality of the APPS  uses the feature extraction results and applies the formatting according to a document format specification (DFS) .","In some embodiments, the user can set formatting preferences with regard to the document  produced by entering information into fields provided in the DFS . In some embodiments, the user can set preferences as to document format and layout, font type and size, information displayed in each line, information displayed in a header, size and location of schedule columns, font colors, line spacing, number of words per line, bolding and capitalization techniques, language in which the document is printed, paper size, paper type, and the like. For example, the user might choose to have a multimedia document that includes a header in large, bold font showing the name of the multimedia content being displayed (e.g., CNN News segment), and the user can choose the arrangement of the graphical representation of multimedia content displayed per page.","The DFS  determines the feature extraction that is applied to the audio data and the format guidelines used to product the output document . The DFS  is a data structure that can be supplied by an external application, such as a print driver dialog interface on a PC (not shown), or it can be determined internally by interacting with the APPS  on the printer's console (not shown). The DFS  represents the transformation(s) of the multimedia data. The DFS  is used to populate a user interface that is displayed to the user, giving the user formatting options. The DFS  determines the feature extraction options presented to the user, which can be applied to the multimedia data. The DFS  also determines the format guidelines used to produce the output document.","The DFS  can include meta data information about an audio file, such as information about the title of the audio content, the composer of the audio content, and the like. The DFS  can also include other information, such as beginning and ending times of a segment (e.g., beginning and ending times of an audio recording), and a specification for a graphical representation of the multimedia data that can be displayed along a time line (e.g., a waveform showing the amplitude of an audio signal over time). The DFS  can further include a specification for time stamp markers and meta-data for each time stamp (i.e., a barcode, an RFID tag, a URL, or some other indication for the location where the multimedia data can be retrieved from) that could be displayed along the timeline, and layout parameters that determine the appearance of the physical multimedia document .","In the embodiment shown in , the printer  additionally comprises processing logic  for a printer console and for a print driver interface. The processing logic  interacts with the user through a print driver dialog interface (not shown). For example, the processing logic  manages the display of a user interface that allows the user to control certain printer actions, such as the processing of the multimedia content or the format in which the multimedia content will be displayed in a multimedia representation . Alternatively, the functionality of the user interface can be provided by a web interface, allowing the user to manage printer actions, such as formatting issues, through this web interface. Additionally, the processing logic  can return a paper or electronic format for the audio paper. For example, in some embodiments, the user can choose the format in which the representation will be printed. In other embodiments, the printer  automatically applies a default setting regarding the format of the representation.","The multimedia document  generated by the printer  can comprise various formats. For example, the multimedia document  can be a paper document, such as an audio paper document  of the form shown in . The multimedia document  produced by the printer  can be also stored on digital media. The digital media writing hardware can include, for example, a network interface card, a DVD writer, a secure digital (SD) writer, a CD writer, and the like. The multimedia content can be stored on digital media, such as flash media, a DVD, a CD, and the like.","The multimedia document  can have a number of different types of layouts and can display various types of information.  provides an example of an audio paper document  displaying audio content, though in other embodiments the document may be a video paper document displaying video content. More information about generation of video paper documents is provided in the Video Paper Applications, each of which is hereby incorporated by reference in its entirety.","In the  example, the audio paper document  includes an audio waveform  display of audio information. The layout and format information may specify the length of audio content to be extracted from an audio recording, the arrangement of the audio waveform  on the medium, and other like information. For audio information, the printer  can extract segments that capture salient features of the audio (or frames that are informative) for a particular segment of the multimedia information. Additionally, as discussed previously, the printer  may include feature extraction capabilities (e.g., audio event detection, and the like), allowing the user to search within an audio segment for items of interest, such as for certain speakers, for music, for laughing or yelling, etc. The document  produced can display one audio waveform  or can divide audio content to be displayed over more than one audio waveform . The audio waveform  in  is displayed vertically, but in other embodiments the audio waveform  can be displayed in other arrangements.","Additionally, the audio waveform  of  includes time stamp markers  marking the beginning and the end of the audio content displayed over the audio waveform . As an alternative, the audio waveform  can include numerous time stamp markers  along the length (i.e., possibly user-defined locations of markers), or the document  can include no time stamp markers  at all.","In the  embodiment of the audio paper , the document  can contain a header . The header  provides general information about the audio content included in the document . For example, the header  may include information about the type of audio content displayed on the document  (e.g., \u201cMeeting\u201d), the date of recording of the audio content (e.g., \u201cNov. 21, 2003\u201d), and the location at which the audio content was recorded (e.g., \u201cRII Conference Room\u201d).","In another embodiment of the present invention, user-selectable identifiers  (e.g., a barcode or textual tag) are associated the audio waveform . In the  example, the user selectable identifiers  are displayed on the right side of the audio waveform  at user-defined locations, but these can alternatively be displayed anywhere on the page. These identifiers  act as index markers, allowing a user to access the associated audio content. For example, in a document  printed on paper, the user can physically scan a barcode identifier  on the page, and this identifier will point to an audio segment within the audio content displayed on the audio waveform . A user selects the user-selectable identifier  by scanning the appropriate barcode on the paper document  using any type of device (not shown) that has a barcode scanner incorporated into it, such as a cell phone or a personal digital assistant (PDA).","The audio file can be played on a device that allows the random access technique (e.g., barcode scanning) assumed when the document was generated. For example, a document that contains barcodes can be played on a cell phone with a barcode reader and software that can convert barcodes to commands that play an audio file starting at a given point. Thus, the user-selectable identifiers  act as an interface to permit users to access or retrieve the multimedia content displayed on the multimedia document .","As one example, by scanning the barcode of , the user can cause the audio segment to begin playing from the marked location on a display device (e.g., a television, a PC monitor, a cell phone screen, a PDA, and the like) and the user can listen to the content. The multimedia document  can even provide tactile feedback, by causing a PDA to hum, for example, during parts of a recording that is being played. As another example, the paper multimedia document  can also or alternatively include numerical identifiers included instead of or in addition to barcode markers, and the user can type these numerals into a keypad or touchpad (not shown) on the printer  or on an external device to direct the system  to play an audio segment on a printer display or on the display device. Alternatively, if the audio paper document  shown in  were in digital format, the system  could be configured so that a user could select an audio segment to be played directly from the digital document (i.e., by clicking on the location in the audio waveform  with a mouse or other selection device or by selecting a play button).","The printer  is capable of retrieving multimedia information corresponding to the user-selectable identifiers . The signal communicated to the printer  from the selection device (i.e., device with barcode scanner or keypad for entering in numerical identifiers) may identify the audio segment selected by the user, the location of the audio content to be played, the multimedia paper documents from which the segments are to be selected, information related to preferences and\/or one or more multimedia display devices (e.g., a cell phone) selected by the user, and other like information to facilitate retrieval of the requested multimedia information. For example, the system  can access an audio file stored on a PC (not shown), and the system can play this audio content on the user's command.","The example of  further shows text information  next to marked locations along the audio waveform  in the document . In this example, the text information  includes portions of a transcript of a conversation that correspond to the marked location along the audio waveform . Thus, by selecting the user-selectable identifier , the user can cause the audio content to begin playing at the start of the text information  that corresponds to the user-selectable identifier . Various other types of text information  can be also or alternatively displayed along the audio waveform  timeline in the document , such as summaries of conversations, speaker names, and the like.","The multimedia document  produced by system  can be used in a number of different ways. For example, the document  provides the user with a convenient way to visually review audio data by searching for particular audio content of interest, providing markers and even text regarding this selected content, and even providing an interface through which the user can access and play audio content. There can also be numerous variations on this type of multimedia document . For example, the user can print double-sided video or audio paper. In this example, the user prints a multimedia document  on a printer that can apply ink to both sides of a document. The original audio or video paper format can be printed on the front side of the document. The reverse side can show a two-dimensional barcode representation for the data represented on the front. This format provides a stand-alone paper-based representation that could be stored in a filing cabinet, for example, and subsequent retrieval of the multimedia content would not require reference to an off-paper representation. In the case of double-sided video paper, the video would need to be super-compressed because of the limited capacity of a typical two-dimensional barcode. A combination technology could be used that would extract a rough approximation of the digital data (e.g., the low frequency components of the FFT) from the images printed on the front of the document and supplement that with the higher frequency components, as encoded in the two-dimensional barcode.","As another example, a user can create a perforated multimedia document , such as perforated video or audio paper. For example, the user can print a video file that has been segmented into scenes that are each printed on a different perforated strip of paper. Each strip can contain at least one video frame from the video content, and at least one barcode that refers to an online repository of the video data. The strips could be pasted into a notebook or tacked onto a bulletin board, for example. In the case of perforated audio paper, the user can print an audio file that has been segmented by speaker, sound localization, audio event detection, and the like, and each of these segmentation types can be printed on a different perforated strip of paper. For example, one strip could contain barcodes that point to the instances when people were arguing during a meeting. Each strip can contain at least one barcode that refers to an online repository of the audio data. However, because the amount of multimedia data can be limited, a two-dimensional barcode could be used to provide a complete stand-alone representation for the multimedia. These strips could be cut out and easily moved around by someone who needs to edit the audio recording or by someone who needs to remember only small pieces of the recording. As stated above, the strips could also be pasted into a notebook or tacked onto a bulletin board.","As another example, the user can create a DVD or CD cover sheet using a multimedia document . In this example, the user can print a DVD or CD using this printing technology. Additionally, the printer  can be programmed to automatically produce a cover sheet that shows video frames from the scenes segmented from the video file and barcodes that refer to those scenes. This cover sheet can be printed on small paper stock that could be inserted into a special tray in the printer , for example. Alternatively, the cover sheet can be printed on normal paper stock and provided with fold-marks that indicate how the paper should be folded so that it fits in the typical DVD holder. A similar cover sheet can be printed for a music CD displaying an audio waveform  timeline showing markers for user-selected content and barcodes that refer to the marked portions of the audio content. More information about generating printable representations of multimedia information is provided in the Video Paper Applications, referenced above.","Referring now to , there is shown the architecture of an embodiment of the present invention. In this embodiment, the system  includes an APPS  that can process audio files that are input into the system . The APPS  can be located on printer  or it can be located on a data processing system (not shown), which could include a PC, a portable computer, a workstation, a computer terminal, a network computer, a mainframe, a kiosk, a standard remote control, a PDA, a game controller, a communication device such as a cell phone, an application server, or any other data system. Alternatively, the APPS  might be located on a printer  that is coupled to a data processing system.","In the example of , the APPS  comprises the following components: a feature extraction module  and a formatting module . As described previously, the system  accesses or receives multimedia information, such as an audio file. The file can be stored on the system  or stored on a data processing system (not shown), which is coupled to the printer. In the  embodiment, the user can listen to an audio file using any one of various standard multimedia playing tools that allow the user to play back, store, index, edit, or manipulate multimedia information. Examples include proprietary or customized multimedia players (e.g., RealPlayer\u2122 provided by RealNetworks, Microsoft Windows Media Player provided by Microsoft Corporation, QuickTime\u2122 Player provided by Apple Corporation, Shockwave multimedia player, and others), video players, televisions, PDAs, or the like.","An audio file can enter the APPS  through a data port . This port can include any type of data port, such as an Ethernet connection, over which data can enter printer . Additionally, the DFS  is input into APPS  over connection , which couples the APPS  to the storage location (not shown) of the DFS . Both the feature extraction module  and the formatting module  can use the DFS  information. The DFS  defines the feature extraction techniques to be applied to the multimedia content by the feature extraction module , and the DFS  defines the document formatting information to be used by the formatting module ","The DFS  includes various different types of information. The DFS  includes meta data about an audio file for which a representation is being generated. For example, the DFS  can include information such as the title of the audio recording, the artist, the publisher, and the like. The DFS  can include beginning and ending times relative to the recording. The DFS  can also include a specification for a graphical representation of the audio data that can be displayed along a timeline. For example, the graphical representation can be an audio waveform, as discussed in . The waveform can show the amplitude of the audio signal over time, and the user can zoom into and out of the audio waveform when necessary. Another example would be a JPEG for a waveform. The DFS  can also include a specification for time stamp markers and meta data for each time stamp or user-selectable identifiers (i.e., textual tags or barcodes), that could be displayed along the timeline.","Layout parameters can also be defined in the DFS , in which the parameters determine the appearance of the physical document  created. The layout parameters can include, for example, a specification for the portion of the timeline that will be displayed on each page of document . The generation of the layout can be determined by a default behavior specification, stored in the printer default settings (e.g., Printer Properties). This can include the autonomous productions of a paper document  or an interactive process using a user interface on a printer's console, a web page, etc.","The feature extraction module  produces the graphical representation, and the user-selectable identifiers  and time stamps specified in the DFS . Examples of a graphical representation include a curve that shows the amplitude of an audio file over time. Examples of other features that could be used to produce user-selectable identifiers  include the detection of solos in a musical performance, speech recognition, applause detection, detection of music, and the like.","The formatting module  is coupled to the feature extraction module by connection . Feature extraction data is sent over connection  to the formatting module  for use in formatting the document . The formatting module  converts the audio features and the DFS  into a document representation that can be rendered on paper or as an electronic file, such as a PDF document. The DFS  contains detailed information about the fonts to be used and other information that is typically provided by a document-formatting package (e.g., Microsoft Word). This layout information will be included in the \u201clayout\u201d field of the DFS , discussed below.","The system  of  can also include a processor (not shown), in printer , which processes data signals. The processor (not shown) may comprise various computing architectures including a complex instruction set computer (CISC) architecture, a reduced instruction set computer (RISC) architecture, or an architecture implementing a combination of instruction sets. The system  can include a single processor or multiple processors. Main memory (not shown) may store instructions and\/or data that may be executed by processor , including the software and other components of system . The instructions and\/or data may comprise code for performing any and\/or all of the techniques described herein. Main memory (not shown) may be a dynamic random access memory (DRAM) device, a static random access memory (SRAM) device, or some other memory device known in the art.","When printer  receives a print request, the request and the associated multimedia data is transferred to a processor (not shown), in some embodiments. The processor interprets the input and activates the appropriate module. In some embodiments, the processor is coupled to and controls the feature extraction module  for transforming multimedia content. Additionally, the processor is coupled to the formatting module  for controlling formatting of document , in some embodiments. The APPS  generates the appropriate document-based representation and can interact with the user through a print driver dialog interface (not shown) to modify the parameters of the document  generation and to preview the results. The results and parameters of the multimedia transformation are represented in the DFS . The processor (not shown) can also manage generation of a document , by communicating with and sending print job information to a conventional printer (not shown), and the conventional printer (not shown) generates a paper output. As previously described, the document  can also include user-selectable identifiers, such as barcodes, and other links to multimedia data stored by the printer  or stored in a specified online database (not shown).","In operation, the system  provides methods for printing multimedia content, and in the specific examples given in the Figures, the system  provides methods for printing audio content. Referring now to , there is shown a flowchart that describes processing steps in an audio paper production system . The APPS  is coupled to a control program that runs the subroutine process, as described below. In this embodiment, the processing steps of the APPS  include inputting  an audio file into the system and inputting  the DFS  into the system. Based on the user's instructions, the APPS  determines whether or not a graphical representation has been requested. If not, the APPS  moves on to determining if feature extraction is required. If so, the APPS  then calls  the feature extraction module  of the system  to produce the graphical representation using the audio file information and the information provided in the DFS . The APPS  updates the DFS  by adding  a symbolic form or representation of the feature extraction results as one of the document specification fields listed in the DFS .","As a next step in the process, the APPS  determines if feature extraction is required. If not, the APPS  moves onto calling  the formatting module  to produce the document type specified in the DFS  output format listed in the \u201clayout\u201d field of the DFS . If so, the APPS  calls  the feature extraction module  to produce the markers requested in the DFS  using the audio file information and the information included in the DFS . The APPS  then adds  marker data to the DFS . Once this step is completed, the APPS  calls  the formatting module  to produce the document type specified in the DFS  output format listed in the \u201clayout\u201d field of the DFS .","Referring now to , there is shown a flowchart describing the operations of the formatting module . The formatting module  is coupled to a control program that runs the subroutine process, as described below. In this embodiment, the processing steps of the formatting module  include inputting  the results of feature extraction conducted by the feature extraction module . For each page listed in the \u201clayout page\u201d field of the DFS , the formatting module  determines if the formatting of the page is finished. If it is, the formatting module  sends a return message to the control program. If it is not finished, the formatting module  formats  meta-data in the formatting module  as specified in the \u201clayout\u201d field of the DFS  regarding \u201cmeta-data placement.\u201d The formatting module  then formats  the graphical representation created by the feature extraction module , as specified in the \u201clayout type\u201d field of the DFS , based on the result of the feature extraction. The formatting module  generates  barcodes, according to the \u201cmarker type\u201d field of the DFS , the \u201cmarker frequency\u201d field of the DFS , and the \u201cmarker n\u201d field of the DFS . The markers are then formatted  as specified in the formatting module  given the barcodes. The system then renders  the page given the formatted meta-data, graphical representation, and markers. Once this process is finished for a page, the formatting module  then runs through this process for the next page in the \u201clayout pages\u201d field of the DFS , and for all other pages, until all pages in the \u201clayout pages\u201d field have been formatted.","Referring now to , there is shown a flowchart describing generation of barcodes for multimedia documents . The APPS  is coupled to a control program that runs the subroutine process, as described below. In this embodiment, the processing steps include inputting  information, including barcode type (e.g., interleaved 2 of 5), number of identifier digits in barcode, number of time stamp digits in a barcode, and time stamp value. The system then reads  the identifier field from the formatting module , and then converts  the identifier into a right-justified decimal string. The system then determines if the length of the right-justified identifier is greater than the number of identifier digits allowed in the barcode. If so, then the system returns an error code to the control program. If not, then the system converts  the time stamp value into a right-justified decimal string. The system then determines if the length of the right-justified time stamp is greater than the number of time stamp digits allowed in the barcode. If so, then the system returns an error code. If not, then the system appends  the right-justified time stamp, which is padded on the left with zeros, to the right-justified identifier. The system then renders  a barcode image of the specified type, containing identifier information plus time stamp information. The system sends a return message to the control program signaling the end of the operation.","Though the above-described flowcharts are discussed in reference to audio content, these methods can also apply to video or other media content. The figures that follow show examples of the results of applying different combinations of format specification, feature extraction, and parameters for the audio paper generation algorithm. As stated previously, the format specifications, feature extraction and parameters can also be used to generate a document displaying another type of media content.",{"@attributes":{"id":"p-0076","num":"0075"},"figref":["FIG. 6","FIG. 6"],"b":["116","104","602","104","120","104","604","120","608","116","610","612","104","614","104","616","618","620","622","624","120"],"i":"a"},"The DFS  also includes information about user-selectable identifiers , or markers, to be included in the document , along with the layout specifics of the document . There is shown a \u201cmarker type\u201d field  and a \u201cmarker frequency\u201d field , which specify the type of marker to be included in the document  (e.g., a barcode), and the frequency at which the marker should appear in along the graphical representation (e.g., at 30 second intervals). Additionally, the layout fields give information about the layout of the document . In , there is shown a \u201clayout type\u201d field  that specifies the arrangement of the contents of the audio paper. For example, the layout type can include one horizontal timeline to be displayed on the document , or it could instead include two vertical timelines. The \u201clayout pages\u201d field  specifies the number of pages of the document . The \u201clayout marker placement\u201d field  specifies the location at which user-selectable identifiers  or markers should be displayed (e.g., above the graphical representation). Additionally, the \u201clayout meta-data placement\u201d field  lists information about the placement of meta-data on the document . The meta-data can include a header  or other meta-data.","The DFS  of displays just one example of a set of information about the media representation being generated. In other embodiments, the DFS  can include a number of other fields including, but not limited to, a field for picture information, for hypertext links, for biographies of artists, for birth\/death dates of artists, for address information of artists, for information on where to purchase the displayed media content (i.e., link to website for purchasing the album), and the like. Some other examples of DFS  fields are also discussed below. This is a non-exhaustive list of variations, and numerous other types of information could be incorporated.","Also shown in is the audio feature extraction specification . The feature field  defines the feature extraction applied to the audio content. In this example, the audio feature extraction  is an audio amplitude extraction and graphical approximation. Thus, the document  shows an audio waveform . In this example, an SVG file is output.","In , there is shown a graphical representation of an audio paper document , according to one embodiment of the present invention. In this document , there is shown a header , with header information according to the specifications in the DFS . The header  is also positioned as specified in the DFS  (i.e., in this case, it is centered at the top of the page). The document  displays an audio waveform  or amplitude curve along a timeline. In other embodiments of the present invention, the timeline can be represented by a single straight line, or other variations of a graphical representation. The timeline runs from \u201c00:00:00\u201d to \u201c00:07:14,\u201d which corresponds to the length of the audio recording. Time stamps  are shown at three places along the audio waveform , marking the beginning time and ending time of the recording, along with a time stamp  marking a location in the middle of the section. The document  can show more than three time stamps  or no time stamps  at all, according to the user's preferences.","In addition, the document  displays user-selectable identifiers  (e.g., barcodes), which provide an interface by which the user can access the audio content at locations along the timeline. In some embodiments, the user can specify particular locations for each user-selectable identifier . In this example, the user has specified that the document  should include barcode markers at every 30 seconds along the timeline. These user-selectable identifiers  are displayed in a \u201cstair-step\u201d fashion, rather than in one long line, to allow for easier selection of each individual identifier . However, the arrangement of user-selectable identifiers  can vary greatly, and can be specified in the DFS . As described previously, the user can select any user-selectable identifier  in the printed document to play the associated audio content. For example, the user could scan a barcode, using a cell phone with a barcode scanner, at any location along the timeline to play the recording starting from that point on the cell phone screen or other display device.","Referring now to , there is shown a graphical representation of a document  with user-selectable identifiers  for each musical solo in the recording, and the associated DFS  with audio feature extraction specification  for creating the audio paper . The DFS  shown in is similar to that shown in FIG. , but the example of includes a few variations. The example of a DFS  includes a \u201cfeature extraction\u201d field  that lists the feature extraction to be applied to the audio content. In this case, the feature extraction includes marking of musical solos within the audio content, in which the output shows the instrument name and the time when the solo began. In the example of , there is shown a \u201cmarker type \u201d field  and a \u201cmarker type \u201d field , and these fields specify two types of user-selectable identifiers  to be displayed in the document . For example, the document  will include a marker type  that displays an instrument name that is shown above a barcode that is shown above a time stamp . In the example, a marker type  will be a barcode (i.e., a second barcode displayed at defined locations under the graphical representation). The DFS  also includes a \u201clayout marker  placement\u201d field  and a \u201clayout marker  placement\u201d field . These fields specify where each marker will be shown on the document , such as under the timeline or above the timeline.",{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 7","i":"a ","b":["602","606","602","602"]},{"@attributes":{"id":"p-0084","num":"0083"},"figref":["FIG. 7","FIG. 7"],"i":["b ","a"],"b":["120","104","602","120","110","112","114","112","116","114","120","112","714","116","114"]},"Referring now to , there is shown a graphical representation of a document  showing a timeline for a radio program, and the associated DFS  with audio feature extraction specification  for creating the audio paper . The DFS  shown in is similar to that shown in , but the example of includes a few variations. The example of shows the DFS  for a radio program, and the DFS  includes an \u201cannotation\u201d field  that adds an extra annotation to the document  regarding the radio program. In this example, the annotation shows that the guest on the program is \u201cBill O'Reilly.\u201d Thus, a summary of available meta information about a radio talk show, such as the time it occurred, the name of the host, and its duration can printed on paper together with barcodes for each portion of the conversation and indications of when commercial breaks occurred. The names of the participants could be included if they are known. The barcodes could point to audio data recorded separately by the user of the system, or they could point to audio data on a web site provided by the talk show. This could be coupled to software that post-processes the recording, producing the document and the streamable media file as well as a web page. Further utility would be provided by actively linking the production process to annotation performed online while the talk show occurs. This annotation can be performed at the radio station while the show is happening since the producers would have access to information not available to a listener, such as the phone numbers of people calling the program.",{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 8","i":"b ","b":["120","104","602","120","110","112","114","116"]},"Referring now to , there is shown a graphical representation of a document  showing a timeline for a radio program with markers for keywords, and the associated DFS  with audio feature extraction specification  for creating the audio paper . The DFS  shown in is similar to that shown in , but the example of a includes variations on the marker information. The \u201cmarker type\u201d field  of shows a marker type that includes keywords, barcodes, and timestamps. The \u201cmarker frequency\u201d field  shows that the frequency is \u201cuser-defined.\u201d Thus, in this example, the user has selected each marker to be displayed along the timeline. In the \u201cmarker\u201d fields , the user has made selections for markers  through . For marker , for example, the user has defined the marker to include a barcode, a timestamp, and text describing the marker (e.g., \u201cWTC\u201d), and likely describing the audio content that is being marked. The user has also defined the vertical position of each marker, as \u201cvert. pos. ,\u201d \u201cvert. pos. ,\u201d or \u201cvert. pos. ,\u201d along the timeline. These positioning specifications determine where the marker will be positioned vertically, chosen from a number of stair-step positions above the timeline. The audio feature extraction  is again an audio amplitude extraction with graphical approximation.",{"@attributes":{"id":"p-0088","num":"0087"},"figref":["FIG. 9","FIG. 9"],"i":["b ","a"],"b":["120","104","602","120","110","112","114","112","714","116","114"]},"Referring now to , there is shown a graphical representation of a document  showing a timeline for a radio program with audio feature extraction for search terms. The DFS  of shows, in the \u201cfeature extraction\u201d field  that speech recognition and keyword match techniques were applied to the audio content. In this example, the user searched for \u201cNew York Times\u201d or \u201cfair and balanced\u201d as search terms. shows the \u201cmarker type\u201d field  that includes a matching search term, barcodes, and timestamps. The \u201cmarker frequency\u201d field  shows that the frequency is \u201cuser-defined.\u201d Thus, in this example, the user has selected each marker to be displayed along the timeline. In the \u201cmarker\u201d fields , the user has made selections for markers  through . For marker , for example, the user has defined the marker to include a barcode, a timestamp, and text describing the marker (e.g., \u201cfair and balanced\u201d), and the vertical position of each marker.","The audio feature extraction specification  again includes an audio amplitude extraction with graphical approximation. The audio feature extraction specification  also includes speech recognition, along with term matching to a given list of keywords. Thus, the user searched for locations within a radio program in which the speakers use particular terms, and these locations are marked along the timeline, possibly along with a transcript of a portion of or all of the speech. As an alternative, the user could apply speech recognition alone, recognizing any point in the audio content in which speech occurred. Since the speech. recognition output may be noisy, some representation for the confidence of the recognition can also be included, so the user can see which words or phrases are more likely to be correct. For example, the document  could include colors or variations in font size to represent recognition confidence. The highest confidence decisions could be shown in red, 12-point font, while the lowest confidence decisions could be in blue, 8-point font. User-selectable identifiers  can be included for each decision or for only the ones with the highest confidence.","Other examples of audio feature extractions that could be applied to audio content include speaker detection and speaker recognition. The speaker detection extraction can recognize a group of equivalent speakers in a recording and determine when the same person was speaking. This can be represented along a timeline by segments annotated with a limited palette of colors, showing a different color for each speaker, and the same color for the same speaker. This might be used for scanning through a long recording looking for only the comments of a specific person. Speaker recognition extraction identifies the actual people who spoke during an audio recording. The symbolic identity of the people can be computed and added next to segments of the timeline together with barcodes that when swiped would play the audio from the beginning of that segment. This would allow one to scan the printout and see who participated in a meeting. An alternative version could print a list of names and could place bar codes next to those names. A user could swipe those barcodes and listen to the parts of the recording when that person spoke. A further example would retrieve face images for those people and print them next to the names and barcodes. The audio data could also be embedded in a two-dimensional bar code, thus providing a completely stand-alone representation for the audio file.",{"@attributes":{"id":"p-0092","num":"0091"},"figref":["FIG. 10","FIG. 10"],"i":["b ","a"],"b":["120","104","602","120","110","112","114","112","714","714","116","114","116"]},"In , there is shown a graphical representation of a document  showing a timeline for a radio program with audio feature extraction for applause events. The DFS  of shows, in the \u201cfeature extraction\u201d field  that applause detection was applied to the audio content. The audio feature extraction specification  includes applause detection timestamps. Thus, the user searched for locations within a radio program that applause events occurred, and these locations are marked along the timeline.",{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 11","FIG. 11"],"i":["b ","a"],"b":["120","104","602","120","110","112","114","112","116","114","116"]},"Sound localization techniques could also be applied to audio content. In this example, a timeline representation can include directional indicators that point to places in a room where the recording was done. This allows users to quickly scan the timeline and determine when, for example, the person in the southeast corner of the room or the person across the table from them, was speaking. This can be applied, for example, with fixed installations that have multiple-microphone setups that can be calibrated to perform sound localization. It can also be used with appropriately equipped portable recorders, such as those used by professionals who record interviews.","In , there is shown a graphical representation of a document  showing a timeline for a radio program with audio feature extraction for music events. The DFS  of shows, in the \u201cfeature extraction\u201d field  that music detection was applied to the audio content. The audio feature extraction specification  includes music detection timestamps. Thus, the user searched for locations within a radio program that music events occurred, and these locations are marked along the timeline. Additionally, the \u201clayout type\u201d field  shows the layout type to include two vertical timelines that are split in half.",{"@attributes":{"id":"p-0097","num":"0096"},"figref":["FIG. 12","FIG. 12"],"i":["b ","a"],"b":["120","104","602","120","110","112","114","112","116","114","116","104"]},"Multimedia paper can also be used for generating representations of voice mail messages. A user can generate a summary of the available meta information about a collection of voice mail messages, such as the phone number of the calling party, the result of looking up that phone number in an internet search engine (which can often show the name of the caller, their address, and a map showing their location), as well as the date, time, and duration of messages. Each block of meta information could be printed next to a barcode that would retrieve the audio information from a remote network location or it could be represented in a two-dimensional barcode that could be played directly from the paper, thus obviating the need for any off-device access. The paper document provides value to users by providing extra information that can be retrieved and added to the paper document (e.g., internet search engine information). Also, the paper document itself would provide users with the ability to write notes about the voice mail messages on the document.","Multimedia paper can also be used in generating representations of public safety radio transmissions. A summary of the available meta information about the recording of one or more public safety (e.g., police, fire, etc.) radio transmissions, including the date, time, duration, car number, officer name (if available), can be printed on paper together with barcodes that reference an off-line representation for those recordings. Two-dimensional bar codes can also be used that directly encode audio data. This provides a stand-alone representation that can be used independently of a network connection. The meta information can be computed by signal processing algorithms applied to the recorded audio, or it could be computed from digital side channel information provided in the radio transmissions (e.g., Motorola digital radio information). Alternatively, it could be provided digitally at the radio dispatcher's console. This system could assist managers who need to selectively inspect the radio logs, or it could assist members of the public who want to observe public safety procedures.","Multimedia paper can also be used in generating representations of aviation radio transmissions. A summary of the available meta information about the recording of one or more aviation radio transmissions, including the date, time, duration, flight name, origin, destination, current position, of a flight when a particular transmission occurred, can be printed on paper together with barcodes that point to an online form of the audio recording. The meta information can be extracted directly from the mode S transponder returns, assuming suitable equipment is available. Additional meta information could be retrieved from various online services that track flight progress in real-time. Speech recognition applied to the audio recording could provide symbolic information that could be used to compute links to the online data. This would obviate the need for a direct link to the mode S data and would make this system usable by people without access to FAA equipment.","While the present invention has been described with reference to certain preferred embodiments, those skilled in the art will recognize that various modifications may be provided. Variations upon and modifications to the preferred embodiments are provided for by the present invention, which is limited only by the following claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The invention is illustrated by way of example, and not by way of limitation in the figures of the accompanying drawings in which like reference numerals refer to similar elements.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6","i":"a "},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 6","FIG. 6"],"i":["b ","a. "]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7","i":"a "},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 7","FIG. 7"],"i":["b ","a. "]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 8","i":"a "},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 8","FIG. 8"],"i":["b ","a. "]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9","i":"a "},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 9","FIG. 9"],"i":["b ","a. "]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 10","i":"a "},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 10","FIG. 10"],"i":["b ","a. "]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 11","i":"a "},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 11","FIG. 11"],"i":["b ","a. "]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 12","i":"a "},{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 12","FIG. 12"],"i":["b ","a. "]}]},"DETDESC":[{},{}]}
