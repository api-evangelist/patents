---
title: Depth bounds testing
abstract: Lights can be conservatively bounded within a depth range. When image pixels are outside of a light's depth range, an associated volume fragment does not have to be rendered. Depth bounds registers can be used to store minimum and maximum depth values for a light. As graphics hardware processes volume fragments overlapping the image, the image's depth values are compared with the values in the depth bounds register. If the image's depth is outside of the depth range for the light, stencil buffer and illumination operations for this volume fragment are bypassed. This optimization can be performed on a per-pixel basis, or simultaneously on a group of adjacent pixels. The depth bounds are calculated from the light, or from the intersection of the volume with one or more other features. A rendering application uses API functions to set the depth bounds for each light and to activate depth bounds checking.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07145565&OS=07145565&RS=07145565
owner: NVIDIA Corporation
number: 07145565
owner_city: Santa Clara
owner_country: US
publication_date: 20030523
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCES TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This application claims priority to U.S. Provisional Patent Application No. 60\/451,311, filed Feb. 27, 2003, which is incorporated herein by reference for all purposes.","The present invention relates to the field of computer graphics. Many computer graphic images are created by mathematically modeling the interaction of light with a three dimensional scene from a given viewpoint. This process, called rendering, generates a two-dimensional image of the scene from the given viewpoint, and is analogous to taking a photograph of a real-world scene.","Realistic and dynamic shadows are crucial for rendering high-quality computer graphics. Shadow volume rendering is one technique for generating shadows. A shadow volume defines a region of space that is in the shadow of a particular object (referred to as an occluder) with respect to a particular light source. Using shadow volumes turns the problem of rendering shadows from a lighting problem to a geometry problem. A shadow test determines whether all or a portion of an object is inside the shadow volume defined by an occluder and a light source. If all or a portion of an object is inside the shadow volume, then these portions are shadowed with respect to the particular light source. Conversely, if all or a portion of an object is outside the shadow volume of the occluder, as well all other occluder shadow volumes, then these portions are illuminated by the light source. The shadow test is repeated for each object and for every light source (and corresponding shadow volume) in a scene. The shadow test can be performed on a per-pixel basis or on a group of pixels in parallel.","As the demand for computer graphics, and in particular for real-time computer graphics, has increased, specialized hardware for accelerating the rendering process has become widespread. Hardware stencil buffers can be used to improve the performance of shadow volume algorithms. Stencil buffers can mask off portions of the rendered image in shadow from a particular light source. The unmasked portions of the rendered image are then re-rendered to add the illumination from the light source.","Due to the limitations of memory speed and bandwidth, pixel fill rate, which is the number of pixels that the graphics hardware can update in a given time period, is a critical bottleneck in graphics hardware performance. Because the computation of the mask in the stencil buffer requires rasterizing numerous shadow volume primitives and extensive reading and writing to the stencil buffer, rendering shadow volumes consumes tremendous amounts of pixel fill rate. This makes rendering dynamic shadows time-consuming and real-time rendering difficult for complex scenes.","It is desirable for computer graphics hardware to reduce the number of stencil buffer updates needed to render shadow volumes, thereby decreasing the pixel fill rate requirements and improving performance. It is further desirable that any optimization of shadow volume rendering requires little modification of the rendering application and results in correct images without artifacts or errors. Additionally, it is desirable for computer graphics hardware to reduce the number of stencil buffer updates needed to render other types of volumes, such as fog, smoke, constructive solid geometry, or collision detection.","The performance of stenciled shadow volume algorithms can be improved by avoiding the rendering of unnecessary portions of shadow volumes into the stencil buffer. This reduces the amount of time spent rendering shadow volumes and decreases the memory bandwidth consumed by writing to the stencil buffer. Many light sources can be conservatively bounded within an effective depth range. For example, many light sources attenuate within a relatively small range. This range can be defined as a conservative depth bounds for the light source in a scene. During the rendering of shadow volumes into the stencil buffer, image fragments or pixels outside of a given light source's depth range are discarded and do not have to be rendered into the stencil buffer. This reduces the time and pixel fill rate spent on shadow volume rendering.","This improvement can be implemented in computer graphics hardware. Depth bounds registers can be used to store minimum and maximum depth values for a given light source. As the graphics hardware processes the pixels overlapping the shadow volume, the depth value associated with each pixel can be compared with the values in the depth bounds register. If the depth of the pixel is outside of the depth range for the light source, the stencil buffer operations for this portion of the shadow volume can be safely bypassed.","In an embodiment, an improved method for rendering a volume, such as a shadow volume or alternatively a constructive solid geometry object, includes rendering the scene to fill a depth buffer with depth values, setting a depth bounds associated with the volume, and defining a fragment associated with the volume, which has a volume depth and covers at least a portion of the pixels of the scene. A portion of the fragment covering the portion of the pixels is discarded when the depth value of the covered pixels is outside of the depth bounds associated with the volume. Conversely, further processing of the fragment continues when the depth value of the covered pixels is inside the depth bounds. This further fragment processing may (or may not if the fragment is discarded by subsequent fragment processing tests) result in the updating of the stencil, depth, color, or other values associated with the pixels not discarded by the depth bounds test.","In one embodiment, the depth value of the covered pixels is the depth value of a single pixel. Alternatively, the depth value of the covered pixels is the minimum and maximum depth values of a group of adjacent pixels. In this embodiment, a portion of the fragment covering the group of adjacent pixels is discarded when either the minimum depth value of the pixels in the group is greater than the maximum depth bounds value or the maximum depth value of the pixels in the group is less than the minimum depth bounds value.","In another embodiment, the depth bounds includes a minimum depth bounds value and a maximum depth bounds value outside of which the light source cannot potentially illuminate an object in the scene. An embodiment determines at least one of the depth bounds values by an attenuation of the light source. Another embodiment determines at least one of the depth bounds values by a view frustum. A third embodiment determines at least one of the depth bounds values by an object in the scene.","In another embodiment, the depth bounds associated with the volume is received from a rendering application via a function in an application programming interface (API).","Although , , A\u2013C, and  show two dimensional scenes for simplicity, it is understood that the present invention is intended for use in rendering three-dimensional scenes.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1","b":["100","100","105","110","105","115","120","100","125","100","100","105","110","115","120","125","160"]},"A graphics subsystem  is further connected with data bus  and the components of the computer system . The graphics subsystem  includes a graphics processing unit (GPU)  and graphics memory. Graphics memory includes a display memory  (e.g., a frame buffer) used for storing pixel data for each pixel of an output image. Pixel data can be provided to display memory  directly from the CPU . Alternatively, CPU  provides the GPU  with data and\/or instructions defining the desired output images, from which the GPU  generates the pixel data of one or more output images. The data and\/or instructions defining the desired output images is stored in additional memory . In an embodiment, the GPU  generates pixel data for output images from instructions and data defining the geometry, lighting, shading, texturing, motion, and\/or camera parameters for a scene.","Pixel data for each pixel in an output image may be divided among several different memory buffers. A color buffer stores color data for each pixel. Color data can be represented by three 8-bit color component values (for example red, green, and blue). An 8-bit alpha value may also be stored in the color buffer for each pixel for blending and transparency operations. A depth buffer stores a depth value for each pixel in an output image. The depth value of each pixel is used to determine the visibility of objects as they are rendered into the scene. In an embodiment, the depth value is a 24-bit number. A stencil buffer stores stencil values for each pixel in an output image. Stencil values are used to mask portions of the output image during rendering, and are used to render a variety of different effects, such as mirrors and shadows. The GPU  can read and write stencil values in the stencil buffer, and also perform increment, decrement, and reset operations on these values. In an embodiment, the stencil value is an 8-bit number.","In an embodiment of system , display memory  and\/or additional memory  are part of memory  and is shared with the CPU . Alternatively, display memory  and\/or additional memory  is one or more separate memories provided for the exclusive use of the graphics subsystem . The graphics subsystem  periodically outputs pixel data for an image from display memory  and displayed on display device . Display device  is any device capable of displaying visual information in response to a signal from the computer system.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 2","b":["205","210","205","210","205","215","220","210","205","210","210","205","205","220","210"]},"The possible silhouette edge set  determines the \u201ctop\u201d of the shadow volume . The sides of the shadow volume  are formed by projecting the possible silhouette edges  and  away the light source  to the edges of the silhouette . Projected possible silhouette edges  and  and possible silhouette edge set \u201ctop\u201d  define the boundary representation of shadow volume . Shadow volume  may be an open volume, or alternately closed off with the addition of a surface (not shown) at a finite or infinite distance from the light source . This may be done to simplify rendering of shadow volumes when the viewer is within a shadow volume.","In , object  is partially within shadow volume . Object portions  and  are outside of the shadow volume  and illuminated by light source . Object portion  is inside shadow volume  and is unilluminated by light source . By determining the intersection of objects with shadow volumes created by a light source, realistic and dynamic shadows can be rendered. Hardware stencil buffers can be used to determine the intersection of objects with the shadow volumes from a light source on a per-pixel basis. This technique for using a stencil buffer to render scenes with shadow volumes is referred to as stenciled shadow volumes.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 3","b":["300","305","305","305","310"]},"Step  creates shadow volumes for a light source in a scene. Shadow volumes can be formed by finding occluders in the scene, computing the possible silhouette edge set of each occluder, and projecting these edges away from the light source. In complex scenes, a single light source may interact with several occluders to create a large number of shadow volumes.","Step  renders the front-facing shadow volume surfaces. \u201cFront-facing\u201d surfaces are the surfaces facing the viewer that define the boundaries of a shadow volume. One method of determining whether the surface faces the viewer is to compute the sign of the signed area of the shadow volume primitive in pixel coordinates. Step  renders the front-facing shadow volume surfaces in the scene, but does not draw the shadow volume surfaces into the color buffer, nor does it update the depth buffer. Instead, for each pixel of a shadow volume surface, step  compares the depth value associated with the pixel of the shadow volume surface with the corresponding pixel depth value stored for the output image in the depth buffer. If the shadow volume surface depth is less than the corresponding pixel depth value in the output image (i.e., the shadow volume surface pixel is in front of the pixel in the output image), step  increments the stencil value for this pixel. Conversely, if the shadow volume surface depth is greater than the corresponding pixel depth value, step  leaves the stencil buffer unchanged. Step  repeats this operation for all of the pixels of all of the front-facing shadow volume surfaces created by the light source, including front-facing shadow volume surfaces created from different occluders in the scene.","Step  renders the back-facing shadow volume surfaces. \u201cBack-facing\u201d surfaces are the shadow volume surfaces facing away from the viewer. As in step , step  does not does not draw the shadow volume surfaces into the color buffer. Step  compares the depth value associated with each pixel of a back-facing shadow volume surface with the corresponding pixel depth value stored for the output image in the depth buffer. If the shadow volume surface depth is less than the corresponding pixel depth value in the output image (i.e., the shadow volume surface pixel is in front of the pixel in the output image), step  decrements the stencil value for this pixel. Conversely, if the shadow volume surface depth is greater than the corresponding pixel depth value, step  leaves the stencil buffer unchanged. Step  repeats this operation for all of the pixels of all of the back-facing shadow volume surfaces created by the light source, including the back-facing shadow volume surfaces created from different occluders in the scene. Other approaches to updating the stencil buffer with equivalent outcomes are possible. For example, incrementing the stencil buffer for back-facing shadow volumes when the depth test fails, and decrementing the stencil buffer for front-facing shadow volumes when the depth tests fails has the same outcome though extra primitives to cap the shadow volume is required. This second approach is useful to avoid the shadow volume being clipped by the near clip plane.","Following the completion of steps  and , step  renders the scene with the light source. Step  fills the color buffer with the color values contributed by the illumination from the light source. During the rendering of the scene with the light source, step  reads the stencil value associated with each pixel in the output image. If a pixel's stencil value is zero and the depth value of the fragment matches the depth value of the pixel, step  adds the color values contributed by the illumination from the light source to the pixel in the color buffer. If there are color values previously stored in the color buffer, step  adds the illumination from the light source to the previously stored color values. Conversely, if the stencil value associated with a pixel in the output image is not zero, step  leaves the color values for this pixel unchanged. Essentially, the non-zero stencil buffer values \u201cmask\u201d pixels inside one or more shadow volumes from being illuminated by the light source, creating a realistic shadow.","Step  determines if there are any other light sources to be rendered in the scene. If there are other light sources, steps , , , and  are repeated for each light source, so that each light source contributes its illumination to the unmasked portions of the output image.","For scenes with complicated occluders, a single light source can generate a large number of shadow volumes. For example, a scene with a picket fence will have a separate shadow volume for each plank in the fence. In this example, there may be over 100 different shadow volumes. When rendering the front-facing and back facing shadow volume surfaces in this example, there may be over 200 stencil operations (increments or decrements) for each pixel in the scene. The tremendous amount of pixel fill rate required for such an extensive number of stencil operations limits the use of stenciled shadow volumes to relatively simple scenes, especially for real-time rendering applications.","Many light sources can be conservatively bounded within a specific range. For example, the intensity of a light source may attenuate to zero or a negligible value over a relatively short range. In this example, the illumination contribution from the light source to an object outside the range of the light source can be ignored regardless of whether the object is within a shadow volume created by the light source. Other features, such as scene geometry, the view frustum, or a clipping plane, can also be used to determine the range of a light source.","An embodiment of the present invention uses the range of a light source to avoid rendering unnecessary shadow volumes into the stencil buffer. In this embodiment, a depth range defining the minimum and maximum depth values is computed for a light source. The depth range represents the maximum range from the light source projected into the z or depth direction (relative to the viewer). Portions of the scene outside of a light source's depth range are unaffected by the light source. During the rendering of shadow volume surfaces into the stencil buffer, shadow volume surface fragments or pixels outside of a light source's depth range do not have to be rendered into the stencil buffer and are discarded. Similarly, during the rendering of a scene with a light source, image fragments or pixels outside of a light source's depth range do not have to be rendered into the color buffer and are discarded. This reduces the time and pixel fill rate spent rendering shadow volume surfaces and computing illumination values for pixels. Because the image fragments or pixels outside of a light source's depth range are, by definition of the depth range, unaffected by the light source, the appearance of the resulting output image is unchanged from an output image rendered using prior shadow volume rendering methods.","An embodiment of the invention can be implemented in computer graphics hardware.  illustrates a block diagram of an improved rasterization pipeline  for rendering stenciled shadow volumes according to an embodiment of the invention. Rasterization pipeline  converts all or a portion of a geometric primitive, often a triangle or other convex polygon, into a corresponding set of pixel values in the color buffer , depth buffer , and\/or stencil buffer . This conversion is referred to as rasterization. Rasterization pipeline can operate on a single pixel, or alternatively, a set of pixels simultaneously.","A fragment and associated data  representing all or a portion of a geometric primitive is first tested by pixel ownership unit  to determine whether the fragment is within the window or screen display area. Associated data includes color, lighting, texture, normal vector, and shader data defining the appearance of pixels within the fragment. Pixel ownership unit  discards portions of the fragment  outside of the window or screen display area.","If the fragment  is not completely discarded by pixel ownership unit , scissor test unit  tests the remaining portion of fragment  within an x and\/or y range on the screen. A fragment or a portion thereof outside of the on-screen x and\/or y range is discarded by scissor test unit . The on-screen x and\/or y range is used by the scissor test unit  to define screen region where a scene is rendered.","If the fragment  is not completely discarded by scissor test unit , depth bounds testing unit  processes all of or the remaining portion of fragment . Depth bounds test unit  retrieves one or more depth values previously stored in the portion of the depth buffer corresponding to the portion of the screen covered by the fragment . Depth bounds test unit  then compares the retrieved depth value or values with depth bounds values stored in depth bound minimum and depth bound maximum registers. In an embodiment, the depth bounds values stored in the depth bound minimum and depth bound maximum registers are the minimum and maximum depth values associated with the maximum range from the light source projected into the z or depth direction (relative to the viewer).","If the retrieved depth value or values are outside the depth bounds (i.e. each retrieved depth value is either less than the value in the depth bound minimum register or greater than the value in the depth bound maximum register), then the pixel or pixels in the fragment do not need to be rendered and can be discarded. If all of the pixels in a fragment  are outside of the depth range, then the remaining units of the rasterization pipeline  can be skipped for the fragment .","In an embodiment, depth bounds test unit  retrieves a pair of depth values, referred to as z-cull values, associated with a group of adjacent pixels. The z-cull values represent the minimum and maximum depth values associated with the group of adjacent pixels. For example, a pair of z-cull values can represent the minimum and maximum depth values for a 4 by 4 group of adjacent pixels. Z-cull values are typically used to optimize depth testing, such as that performed by a depth test unit  discussed below. In this embodiment, the z-cull values are further used by depth bounds test unit  to quickly determine whether a group of adjacent pixels can be discarded by depth bounds test unit .","In this embodiment, if the minimum z-cull value for a group of pixels overlapping the fragment  is greater than the value in the depth bound maximum register, then all of the pixels in the group are behind the maximum depth bound and the portion of the fragment overlapping the group of pixels can be discarded. Similarly, if the maximum z-cull value for a group of pixels overlapping the fragment is less than the value in the depth bound minimum register, then all of the pixels in the group are in front of minimum depth bound and the portion of the fragment overlapping the group of pixels can be discarded. If the group of pixels is neither entirely behind nor entirely in front of the depth bounds stored in the depth bounds registers, in a further embodiment, the depth value for each pixel in the group is individually compared with the depth bounds values. Fragment pixels overlapping pixels in the depth buffer that are outside the depth bounds can be discarded, and if all of the pixels in a fragment  are discarded, then the remaining units of the rasterization pipeline  can be skipped for the fragment .","In an embodiment, the depth bounds values are determined by a rendering application. As discussed below, a rendering application can set depth bounds values according to a light source's attenuation properties, scene geometry, the view frustum, and\/or a clipping plane. The rendering application sets the values of the depth bounds registers in depth bounds test unit  using an API, such as DirectX\u2122 or OpenGL\u2122. OpenGL\u2122 is a cross-platform standard API for 3D rendering and 3D hardware acceleration. Microsoft DirectX\u2122 is a Microsoft Windows-based API for running and displaying applications using multimedia elements such as full-color graphics, video, 3-D animation, and surround sound. Additionally, the rendering application enables or disables the depth bounds testing unit  using an API. In an embodiment, the rendering application communicates with the depth bounds testing unit  through one or more vendor-provided API extension functions, such as NV_depth_bounds_test. An alternative embodiment could, instead of allowing the application to enable or disable the depth bounds test operation, always perform depth bounds testing and rely on the application to set the minimum and maximum depth bounds to the minimum and maximum possible depth values when the intent is to have no fragments discarded by the depth bounds test.","The depth bounds testing unit  allows the rasterization pipeline  to skip fragment rendering when the depth values previously stored in the depth buffer are outside of the depth bounds values set in the depth bounds test unit . For scenes with light sources and shadow volumes that can be bounded to a limited depth range, the depth bounds test unit  allows a large number of stencil operations to be bypassed. Additionally, when rendering the scene with a light source, the depth bounds test unit  allows illumination computations for image fragments or pixels outside of a light source's depth range to be bypassed. The result is a reduction in the time and pixel fill rate required to render shadow volume surfaces and compute illumination values.","Additionally, an embodiment of the depth bound test unit  does not require any additional computational overhead or pixel fill rate to operate. In this embodiment, depth bounds test unit  reads depth values from the depth buffer  via read-only connection . Because these depth values are normally retrieved for the depth test unit , discussed below, the depth bounds test unit does not require any additional depth buffer reads. Further, because the depth bounds test unit  never modifies the depth values in the depth buffer , there is no increase in the number of writes to the depth buffer.","Following processing by depth bounds test unit , the remaining portion of fragment , if any, is processed by alpha test unit . Alpha test unit  determines if all or a portion of the fragment is visible due to alpha values associated with the fragment. Alpha is commonly used to model transparency of pixels; however, it can be used for other purposes.","The portion of the fragment  remaining after processing by alpha test unit  is processed by stencil test unit . Stencil test unit  masks all or a portion of the fragment from rendering according to a stencil value stored in the stencil buffer . Additionally, stencil test unit  can modify the stencil values stored in the stencil buffer .","Following processing by stencil test unit , the remaining portion of fragment , if any, is processed by depth test unit . Depth test unit , not to be confused with depth bounds test unit , determines the visibility of the remaining fragment or pixels with respect to previously stored values in the depth buffer . A fragment or pixel having a depth value greater than the depth value from a corresponding portion of the depth buffer  are not visible in the scene and does not need to be rendered. Conversely, a fragment or pixel having a depth value less than the depth value from a corresponding portion of the depth buffer  is visible and needs to be rendered. Furthermore, the depth value associated with each visible fragment or pixel is stored in the corresponding portion of the depth buffer , overwriting the previously stored depth value. This ensures that future visibility determinations for additional fragments or pixels will be performed on the correct depth values.","Additionally, depth test unit  can optionally perform stencil operations on pixels, such as increments or decrements of the pixel's corresponding stencil value, in response to the visibility determination of the fragment or pixel. This feature can be used, for example, when rendering front-facing or back-facing shadow volume surfaces, as discussed in method .","The portion of the fragment  remaining after processing by depth test unit  is then drawn into the color buffer  by blending unit , dithering unit , and logic op unit . The blending unit  blends the pixel's or fragment's color values with the color values previously stored in the color buffer . The dithering unit  and the logic op unit  determine the color value associated with the pixel or fragment to be drawn, and store the final color value in the color buffer .","The rasterization pipeline  illustrates the implementation of the invention in example rasterization hardware. Other embodiments of the invention may use different rasterization hardware that includes alternative or additional functions than shown in example rasterization pipeline . Furthermore, the functional units of the rasterization pipeline can be performed in various orders. However, it is preferable from a performance standpoint that functional units that potentially discard large numbers of pixels or entire fragments, such as the pixel ownership test unit , the scissor test unit , and the depth bounds test unit , be performed earlier in the pipeline to avoid unnecessary computations for pixels or fragments.","In an further embodiment, the depth bounds test  can be combined with conventional scissor testing to further limit the rasterization and fragment processing overhead required for rendering with shadow volumes. The scissor test  discards fragments outside of rectangle specified with pixel positions. The depth bounds test and scissor are similar in that they reject fragments outside ranges. The scissor test operates on the X and Y pixel positions of fragments while the depth bounds test operates on the Z pixel position (depth) of fragments.","An embodiment of the invention can be used to optimize the rendering of scenes with stenciled shadow volumes. In this embodiment, a depth bounds is associated with each light source used to cast a shadow in a scene.  illustrates a block diagram of a method  for optimizing the rendering a shadow volume according to this embodiment of the invention. Rendering the scene with stenciled shadow volumes is performed generally in a manner similar to method , with method  defining the improvements to method  according to this embodiment of the invention.","Step  sets a depth bounds for a light source. The depth bounds for a light source are set prior to rendering the front-facing shadow volume surfaces, the back-facing shadow volume surfaces, and the scene with illumination from the light source. If there are multiple light sources, step  is repeated for each light source prior to rendering its associated shadow volume surfaces and illumination contribution to the scene. In an embodiment, step  loads depth bounds values for the light source into the depth bounds test unit  as described above. In another embodiment, the depth bounds values are determined by a rendering application. Examples of different depth bounds determinations are discussed in detail below.","Steps  to  optimize the processing of fragments when rendering stenciled shadow volumes. In an embodiment, steps  to  are repeated for each of rendering steps , , and  in method . Step  creates fragments to be processed. When step  is performed for steps  or , fragments are created from the geometry of shadow volume surfaces. Step  creates fragments from the scene geometry when step  is performed for step . Step  may create numerous fragments depending upon the amount of screen space occupied by the geometry.","Step  retrieves the previously-stored depth value from portion of the depth buffer covered by the fragment. As discussed above, depth values for the scene are stored in the depth buffer in step , where the scene is rendered with disabled light sources. Step  retrieves a depth value corresponding to each pixel in the fragment. In a further embodiment, step  retrieves z-cull values for one or more groups of adjacent pixels from the portion of the depth buffer covered by the fragment.","Step  compares the retrieved depth values with the depth bounds set for the light source in step . If the retrieved depth values are outside of the depth bounds, (i.e. the depth value is greater than the maximum depth bound or less than the minimum depth bound), step  discards the fragment from the rasterization pipeline. If only a portion of the fragment is outside the depth bounds, then step  discards only this portion of the fragment. The remaining portion of the fragment is processed according to step , discussed below.","In a further embodiment, step  first compares the z-cull values for one or more groups of adjacent pixels in the fragment. If the minimum z-cull value for a group of pixels in a fragment is greater than the maximum depth bound, or if the maximum z-cull value for a group of pixels in a fragment is less than the minimum depth bound, then all of the pixels in the group are outside the depth bounds and the corresponding portion of the fragment can be discarded in step . If the group of pixels is not either entirely behind or in front of the depth bounds, step  compares the individual pixel depth values with the depth bounds.","For a fragment either wholly or partially within the depth bounds, step  processes the portion of the fragment within the depth bounds. In an embodiment, fragment processing includes some or all of the functions described by fragment processing pipeline . As step  processes a fragment created from front-facing shadow volume surfaces, such as when step  is performed for step , step  increments the stencil values corresponding to the area of the screen covered by the fragment. Similarly, as step  processes a fragment created from a back-facing shadow volume surface, such as when step  is performed for step , step  decrements the stencil values corresponding to the fragment. As step  processes a fragment created from scene geometry, such as when step  is performed for step , step  computes a color value for each pixel in the fragment with a stencil value of zero based upon the illumination of the scene geometry by the light source and then stores the color values in the color buffer.","After either processing all or a portion of a fragment in step  or discarding all or a portion of a fragment in step , step  determines if there are any additional fragments remaining to be processed. Steps  to  are repeated for any remaining fragments.","Method  illustrates that the present invention can be easily integrated into rendering applications using prior stenciled shadowed rendering techniques. In many cases, rendering applications previously using a prior stenciled shadow volume technique can be easily modified to employ the present invention. For example, a rendering application used in conjunction with rasterization pipeline  only needs the addition of steps to set the depth bounds for each light source and to enable the depth bounds test unit  in order to employ the present invention.",{"@attributes":{"id":"p-0065","num":"0064"},"figref":["FIGS. 6A","FIG. 6A"],"b":["6","6","605","610","615","635","615","635","640","620","610"]},"The shadow volume  intersects the view frustrum  at two places. These intersections form a front depth bounds plane  and a rear depth bounds plane . Portions of the scene  outside of the depth bounds planes  and  are outside of the shadow volume  (or inside the shadow volume  but outside of the view frustum , and therefore not visible to the viewer). Because any scene geometry outside of the depth bounds planes, such as geometry  and , cannot be shadowed, there is no need to compute any illumination or shadowing on this geometry from light source . In this example, the surfaces of the shadow volume  overlapping geometry  do not have to be rendered into the stencil buffer and can be discarded.","Scene  in  includes a viewer , a light source , and an occluder . Light source  attenuates over a relatively short radius. This defines the effective range  of the light source . The light source  cannot illuminate (or cast a shadow) on scene geometry outside of the effective range . The interaction between the light source  and the occluder  define a shadow volume .","In this example, the depth bounds are set to the minimum depth  and the maximum depth  of the effective range  of the light source . Scene geometry outside of this depth bounds, such as geometry  or , cannot be lit or shadowed by the light source , regardless of whether the geometry is inside or outside shadow volume . Therefore, the portions of the shadow volume  overlapping scene geometry outside of the depth bounds, such as geometry  and , do not need to be rendered into the stencil buffer and can be discarded. Similarly, geometry  and  are not illuminated by light source . Therefore, rendering the illumination from light source  can be bypassed for scene geometry outside of the depth bounds, such as  and .","Scene  in  includes a viewer , a light source , and an occluder . The interaction between the light source  and the occluder  define a shadow volume . Shadow volume  intersects scene geometry , which can be a wall, floor, or other geometric feature in the scene. In this example, the intersection of the shadow volume  with scene geometry  defines a minimum depth bound  and a maximum depth bound . In this example, geometry  cannot be shadowed by this shadow volume. Therefore, the shadow volume surfaces for shadow volume  that overlap geometry  do not need to be rendered into the stencil buffer and can be discarded. In contrast, prior stenciled shadow volume rendering methods would require both the front-facing and back-facing shadow volume surfaces that overlap geometry  to be rendered into the stencil buffer.","In other embodiments, the example depth bounds computations shown in , B, and C can be combined to compute the depth bounds for a light source. For example, a minimum depth bounds may be set according to the effective range of a light source, while a maximum depth bounds may be set according to the scene geometry. In computing the depth bounds for a light source, a rendering application may compute several potential depth bounds values using alternative methods and select the optimum values for the minimum and maximum depth bounds values. Additionally, if the light source interacts with two or more occluders, then the rendering application may compute the depth bounds separately for each shadow volume associated with the light source. The rendering application can then select the depth bounds values that define the minimum and maximum depth values for the entire set of shadow volumes associated with the light source.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 7","b":["700","705","710","700","710","715","735","740","710"]},"Geometry  is has a first portion  located within the depth bounds of light . A second portion  of object  is outside of the depth bounds of light . When rendering the front-facing and back-facing surfaces of any shadow volumes, the portions of the shadow volume overlapping scene geometry outside of the depth bounds, such as the shaded portion  of geometry , do not need to be rendered into the stencil buffer and can be discarded. Illumination calculations for geometry outside the shadow volume can similarly be skipped, as discussed above.","As can be seen by comparing the relative sizes of portions  and  of geometry , the addition of depth bounds testing eliminates a large amount of the stencil operations and illumination calculations needed to render stenciled shadow volumes. The performance improvements in shadow volume rendering resulting from the present invention will vary depending on many factors, including the complexity of the scene and the number of light sources. In rendering applications with complex occluders, numerous shadow volumes, and multiple light sources, performance can be improved anywhere from 5% to 25% using depth bounds testing. Other implementations of the present invention will result in different performance gains.","In a further embodiment, the depth bounds test unit can compute a depth bounds value based on a plane equation. In this embodiment, the rendering application specifies the parameters of a plane equation, for example, the values of A, B, C, and D in the standard plane equation Ax+By+Cz=D. Using a plane equation, rather than a constant depth bounds value, allows shadow volumes to be conservatively bounded with planes that are not parallel to the image plane. This allows shadow volumes to be more \u201ctightly\u201d bounded and increases the performance of the depth bounds test.","Although the invention has been discussed with respect to specific embodiments thereof, these embodiments are merely illustrative, and not restrictive, of the invention. Depth bounds testing can be used in any application that requires testing for the intersection of two or more volumes. For example, although the invention is discussed with reference to shadow volumes, it can be used to optimize the rendering of constructive solid geometry (CSG) rendering or to perform collision detection. Thus, the scope of the invention is to be determined solely by the claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention will be described with reference to the drawings, in which:",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIGS. 6A","b":["6","6"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
