---
title: Just-in-time transcoding of application content
abstract: The techniques discussed herein contemplate improved methods and systems for transcoding application content to minimize latency in just-in-time conversion of application formats. In embodiments, a target client device requests application content of a particular format from a content provider. If the content provider does not have a local copy of the requested format, the content is split to multiple segments and a first high-priority segment is identified. This first segment is converted using a dedicated high-performance computing unit and transmitted with minimal latency to the target client device for immediate rendering. Concurrently, remaining segments of the content are converted in multiple lower performance computing units and fed into the target client device. By ensuring that at least a first segment of the application is available for immediate rendering while other segments are converted, the transcoding application minimizes latency delay in rendering of the application in the target device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08549167&OS=08549167&RS=08549167
owner: Net Power and Light, Inc.
number: 08549167
owner_city: San Francisco
owner_country: US
publication_date: 20110621
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION OF THE INVENTION"],"p":["The present teaching relates to network communications and more specifically to improved methods and systems for transcoding application content \u201cjust-in-time.\u201d","With the ever-increasing integration of electronic devices in people's lives, users often use multiple types of electronic gadgets for use in everyday activities. For example, it is not uncommon for users to have a personal computer (e.g., a laptop) for work purposes, a smart phone (e.g., an iPhone\u00ae) for mobile connectivity, a set-top box connected to a digital television for home-entertainment purposes, etc. It is also not uncommon for such gadgets to render similar applications (e.g., streaming an online video clip). In typical instances, the user may have a number of these gadgets connected via a common network (e.g., a home wireless network). In such instances, the user may wish to switch rendering of an application from one mobile device to another for a variety of reasons.","Consider an illustrative scenario. A user, while walking from his car to his office is watching a video clip on his smart phone to prepare for a meeting. The video clip is streamed into his smart phone via the Internet from a remote server. As soon as the user enters his office, he may want to switch the video from the smart phone to his office computer to be able to view the video on a larger display screen. Typically, the format (e.g., the type of encoding) of the video streamed from the server to the device would depend on the type of device. For example, a video clip rendered to an iPhone device may need to be encoded according to H.264 standards. However, when the video rendering is switched from an iPhone to a laptop, the server may instead need to supply the video clip that is formatted according to, for example, Windows Media Video standards.","In typical scenarios, the server may not readily have a copy of the video file in the requested (i.e., the second) format. Accordingly, the server would have to encode or otherwise reformat the video data prior to streaming the video clip to the second client device, introducing substantial latency in the rendering of the video. Such data processing latency problems are only exacerbated when the application (e.g., the video clip) is converted on a remote server and streamed to the client device. In such cases, network latency and data processing latency both contribute to the inability of the client to deliver seamless rendering of the application.","Some prior art systems attempt to resolve this issue by retaining at least popularly requested content in several formats. This results in content providers having to increase their storage footprint to be able to handle storage of all the application content, increasing the cost of maintaining and delivering the content. Also, without knowing what type of application format will be required, the content providers would need to maintain a separate copy for every potential format of the application, further increasing the cost of storage. It would be preferable to deliver the content just-in-time, that is, when the data is requested by a client device. However, present systems suffer from the latency issues illustrated above when attempting to perform just-in-time transcoding.","The techniques discussed herein contemplate a variety of improved methods and systems for transcoding application content to minimize latency of on-the-spur or just-in-time conversion of application formats. In embodiments, when a client device requests application content in a specified format, a content server delivering the application content determines whether the application content is available in a format suitable for the target client device. If not, the content server splits the application content to multiple segments and identifies a first segment for immediate (or high-priority) conversion to the target format. This first segment is transmitted to a high-performance computing unit that is dedicated for such initial high-priority segments. This segment is converted and transmitted with minimal latency to the target client device for immediate rendering. Concurrently, the remaining segments are converted in multiple lower performance computing units and fed into the target client device. In embodiments, a length of the first segment is chosen in a manner that ensures that there is sufficient content to be rendered in the target client device before the remaining segments trickle their way in from the remaining computing units. By ensuring that at least a first segment of the application is available for rendering while other segments are converted, the transcoding application avoids an initial latency delay of rendering of the application. This allows for seamless or near-seamless delivery of the application content and improved user experiences in situations where on-the-spur format conversion is necessary.","By using these techniques in preventing network or data processing latency from affecting seamless delivery of the application content, content providers are able to perform just-in-time transcoding, content providers may retain fewer or even just one copy (format) of application content, and convert the other content as necessary. Also, content providers may assess popularity of video content and have multiple copies (formats) of application content having a high demand, and retain minimal copies of application content found to have relatively lower demand. In embodiments, a combination of just-in-time transcoding and selective retention of multiple copies enables content providers to advantageously balance storage cost and latency in delivering application content in a networked environment.","In an illustrative embodiment, the just-in-time transcoding comes into play when a user utilizes an experience platform to switch rendering of the application content from one device type to another. In some instances, the user may cause such switching or transfer to happen using, for example, a physical or audio gesture that is captured and translated by the experience platform. In embodiments, when the switching occurs to a target client device.","Various examples of the invention will now be described. The following description provides specific details for a thorough understanding and enabling description of these examples. One skilled in the relevant art will understand, however, that the invention may be practiced without many of these details. Likewise, one skilled in the relevant art will also understand that the invention can include many other obvious features not described in detail herein. Additionally, some well-known structures or functions may not be shown or described in detail below, so as to avoid unnecessarily obscuring the relevant description.","The terminology used below is to be interpreted in its broadest reasonable manner, even though it is being used in conjunction with a detailed description of certain specific examples of the invention. Indeed, certain terms may even be emphasized below; however, any terminology intended to be interpreted in any restricted manner will be overtly and specifically defined as such in this Detailed Description section.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1","b":["10","10","10"]},"In general, services are defined at an API layer of the experience platform. The services are categorized into \u201cdimensions.\u201d The dimension(s) can be recombined into \u201clayers.\u201d The layers form to make features in the experience.","By way of example, the following are some of the dimensions that can be supported on the experience platform.","Video\u2014is the near or substantially real-time streaming of the video portion of a video or film with near real-time display and interaction.","Audio\u2014is the near or substantially real-time streaming of the audio portion of a video, film, karaoke track, song, with near real-time sound and interaction.","Live\u2014is the live display and\/or access to a live video, film, or audio stream in near real-time that can be controlled by another experience dimension. A live display is not limited to single data stream.","Encore\u2014is the replaying of a live video, film or audio content. This replaying can be the raw version as it was originally experienced, or some type of augmented version that has been edited, remixed, etc.","Graphics\u2014is a display that contains graphic elements such as text, illustration, photos, freehand geometry and the attributes (size, color, location) associated with these elements. Graphics can be created and controlled using the experience input\/output command dimension(s) (see below).","Input\/Output Command(s)\u2014are the ability to control the video, audio, picture, display, sound or interactions with human or device-based controls. Some examples of input\/output commands include physical gestures or movements, voice\/sound recognition, and keyboard or smart-phone device input(s).","Interaction\u2014is how devices and participants interchange and respond with each other and with the content (user experience, video, graphics, audio, images, etc.) displayed in an experience. Interaction can include the defined behavior of an artifact or system and the responses provided to the user and\/or player.","Game Mechanics\u2014are rule-based system(s) that facilitate and encourage players to explore the properties of an experience space and other participants through the use of feedback mechanisms. Some services on the experience Platform that could support the game mechanics dimensions include leader boards, polling, like\/dislike, featured players, star-ratings, bidding, rewarding, role-playing, problem-solving, etc.","Ensemble\u2014is the interaction of several separate but often related parts of video, song, picture, story line, players, etc. that when woven together create a more engaging and immersive experience than if experienced in isolation.","Auto Tune\u2014is the near real-time correction of pitch in vocal and\/or instrumental performances. Auto Tune is used to disguise off-key inaccuracies and mistakes, and allows singer\/players to hear back perfectly tuned vocal tracks without the need of singing in tune.","Auto Filter\u2014is the near real-time augmentation of vocal and\/or instrumental performances. Types of augmentation could include speeding up or slowing down the playback, increasing\/decreasing the volume or pitch, or applying a celebrity-style filter to an audio track (like a Lady Gaga or Heavy-Metal filter).","Remix\u2014is the near real-time creation of an alternative version of a song, track, video, image, etc. made from an original version or multiple original versions of songs, tracks, videos, images, etc.","Viewing 360\u00b0\/Panning\u2014is the near real-time viewing of the 360\u00b0 horizontal movement of a streaming video feed on a fixed axis. Also the ability to for the player(s) to control and\/or display alternative video or camera feeds from any point designated on this fixed axis.","Turning back to , the experience platform  includes a plurality of devices  and a data center . The devices  may include devices such as an iPhone , an android , a set top box , a desktop computer , a netbook , or other such computing devices. At least some of the devices  may be located in proximity with each other and coupled via a wireless network. In certain embodiments, a participant utilizes multiple devices  to enjoy a heterogeneous experience, such as using the iPhone  to control operation of the other devices. Participants may, for example, view a video feed in one device (e.g., an iPhone) and switch the feed to another device (e.g., a netbook) to switch the feed to a larger display device. In other examples, multiple participants may also share devices at one location, or the devices may be distributed across various locations for different participants.","Each device  has an experience agent . The experience agent  includes a sentio codec and an API. The sentio codec and the API enable the experience agent  to communicate with and request services of the components of the data center . The experience agent  facilitates direct interaction between other local devices. Because of the multi-dimensional aspect of the experience, the sentio codec and API are required to fully enable the desired experience. However, the functionality of the experience agent  is typically tailored to the needs and capabilities of the specific device  on which the experience agent  is instantiated. In some embodiments, services implementing experience dimensions are implemented in a distributed manner across the devices  and the data center . In other embodiments, the devices  have a very thin experience agent  with little functionality beyond a minimum API and sentio codec, and the bulk of the services and thus composition and direction of the experience are implemented within the data center .","Data center  includes an experience server , a plurality of content servers , and a service platform . As will be appreciated, data center  can be hosted in a distributed manner in the \u201ccloud,\u201d and typically the elements of the data center  are coupled via a low latency network. The experience server , servers , and service platform  can be implemented on a single computer system, or more likely distributed across a variety of computer systems, and at various locations.","The experience server  includes at least one experience agent , an experience composition engine , and an operating system . In one embodiment, the experience composition engine  is defined and controlled by the experience provider to compose and direct the experience for one or more participants utilizing devices . Direction and composition is accomplished, in part, by merging various content layers and other elements into dimensions generated from a variety of sources such as the service provider , the devices , the content servers , and\/or the service platform .","The content servers  may include a video server , an ad server , and a generic content server . Any content suitable for encoding by an experience agent can be included as an experience layer. These include well know forms such as video, audio, graphics, and text. As described in more detail earlier and below, other forms of content such as gestures, emotions, temperature, proximity, etc., are contemplated for encoding and inclusion in the experience via a sentio codec, and are suitable for creating dimensions and features of the experience.","The service platform  includes at least one experience agent , a plurality of service engines , third party service engines , and a monetization engine . In some embodiments, each service engine  or  has a unique, corresponding experience agent. In other embodiments, a single experience  can support multiple service engines  or . The service engines and the monetization engines  can be instantiated on one server, or can be distributed across multiple servers. The service engines  correspond to engines generated by the service provider and can provide services such as audio remixing, gesture recognition, and other services referred to in the context of dimensions above, etc. Third party service engines  are services included in the service platform  by other parties. The service platform  may have the third-party service engines instantiated directly therein, or within the service platform  these may correspond to proxies which in turn make calls to servers under control of the third-parties.","Monetization of the service platform  can be accomplished in a variety of manners. For example, the monetization engine  may determine how and when to charge the experience provider for use of the services, as well as tracking for payment to third-parties for use of services from the third-party service engines .",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 2","b":["100","100","102","104","102"]},"The sentio codec  is a combination of hardware and\/or software which enables encoding of many types of data streams for operations such as transmission and storage, and decoding for operations such as playback and editing. These data streams can include standard data such as video and audio. Additionally, the data can include graphics, sensor data, gesture data, and emotion data. (\u201cSentio\u201d is Latin roughly corresponding to perception or to perceive with one's senses, hence the nomenclature \u201csensio codec.\u201d)",{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 3","b":["200","200","202","204","206","208","210","200","212","214","212","214"]},"The sentio codec  can be designed to take all aspects of the experience platform into consideration when executing the transfer protocol. The parameters and aspects include available network bandwidth, transmission device characteristics and receiving device characteristics. Additionally, the sentio codec  can be implemented to be responsive to commands from an experience composition engine or other outside entity to determine how to prioritize data for transmission. In many applications, because of human response, audio is the most important component of an experience data stream. However, a specific application may desire to emphasize video or gesture commands.","The sentio codec provides the capability of encoding data streams corresponding with many different senses or dimensions of an experience. For example, a device  may include a video camera capturing video images and audio from a participant. The user image and audio data may be encoded and transmitted directly or, perhaps after some intermediate processing, via the experience composition engine , to the service platform  where one or a combination of the service engines can analyze the data stream to make a determination about an emotion of the participant. This emotion can then be encoded by the sentio codec and transmitted to the experience composition engine , which in turn can incorporate this into a dimension of the experience. Similarly a participant gesture can be captured as a data stream, e.g. by a motion sensor or a camera on device , and then transmitted to the service platform , where the gesture can be interpreted, and transmitted to the experience composition engine  or directly back to one or more devices  for incorporation into a dimension of the experience.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIGS. 4-5","b":"4"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIGS. 6-7","FIGS. 4-5"]},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIGS. 8-9"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIGS. 10-16","FIGS. 10-11","FIGS. 12-14"],"b":["15","16"]},"The description above illustrated in some detail how a specific application, an \u201cexperience,\u201d can operate and how such an application can be generated as a composite of layers. , explained below in detail, now illustrate a transcoding service that is utilized when content endemic to an application or an experience (e.g., a video layer) is switched from a first client device to a second client device. In embodiments, the transcoding application comes into play when the first client device and second client device render the same content in two different formats, and consequently, the data center (or any other content provider) needs to provide content in a different format when the experience is switched to the second client device. Implementation of the transcoding service can be built over a virtual cloud, for example, on top of Amazon Web Services. In particular, the virtual cloud illustrates distributing the transcoding service over a plurality of virtual machines instantiated by the third-party service.","Consider an illustrative scenario where the experience relates to playback of video content (i.e., application content) on a user's iPhone\u00ae device. A content server provides the video content, for example, as streaming media. The content server, having a cached copy of the requested video content, provides the content (in a format compatible with the iPhone\u00ae device) from, for example, a local cache. However, as part of the user experience paradigm contemplated by the techniques discussed herein, the user may wish to switch playback of the video content from the iPhone device to a laptop or another computing device, to perhaps be able to watch the video content on a larger screen. The user may initiate such a transfer using a physical or audio gesture, as may be contemplated by the user experiences discussed herein. For example, in embodiments, the user may transfer the video content from the iPhone to the laptop by a simple sway of the iPhone in a direction pointing to the laptop. This would enable the video to, for example, simply cease (or just pause) playing on the iPhone and start playing on the laptop from the point at which the video stopped playing on the iPhone. Of course, it is contemplated that the two client devices have corresponding experience agents (similar to the ones discussed with respect to ) to be able to capture and react to such gestures.","It is understood that the transcoding services discussed herein may also be practiced independent of the above experience paradigms. For example, the transcoding techniques explained below may be implemented when a content server receives a request for content in a format different from a locally cached format of the content (without any involvement of user experiences). Also, while the following description illustrates the transcoding service with respect to video content, it is understood that the general transcoding principles may similarly be applied to any application content that is, for example, supported on the experience platform.  now discuss these transcoding techniques in detail.",{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 17","b":["1022","1022","1024","1022","1026","1022","1026","1022","1022","1024","1026","1024","1024"]},"As contemplated here, the content server first verifies whether the requested format (e.g., the second format of the video clip) is locally available, for example, in cache . If the second format is available, the content server simply continues to stream the content out in the second content. However, if the second content is not available in cache, the content server needs to convert (or initiate conversion using third party services) the video clip from the first format to the second format. In embodiments, the content server may initiate conversion of the video clip only from the point at which the video was transferred to device  or may simply initiate conversion for the entire video clip.","In embodiments, as discussed above, the content server initiates a conversion process in a distributed processing setup over a cloud (e.g., using third party or proprietary cloud services). As illustrated in , block  indicates this distributed processing. A splitter  receives the video clip (either the entire clip, or a remaining portion of the clip that needs to be converted) and splits the clip into several segments. The number of segments may be defined based on a performance capability of the high performance  and lower performance computing units  indicated in block . For example, if the high performance computing unit  can handle 30 seconds worth of video feed for near-instant conversion to the second format, then the video clip is split to generate a first segment of 30 seconds and then converts the remaining video clip into segments for being fed into the lower performance computing units . In embodiments, the number of segments for the lower performance computing units may be determined by the number of freely available lower performance computing unit available for conversion of the remaining video clip. In embodiments, the high performance computing unit  and\/or the lower performance computing units  are dedicated for the sole purpose of conversion of content to a specified format. Accordingly, they are maintained free (i.e., not utilized for any other computing operation), such that they are immediately available for the transcoding process when a request is received at the content server .","Furthermore, even when multiple conversion requests may be imposed on the distributed block  (i.e., multiple requests are simultaneously received from several different client devices for a variety of video clips in different formats), it can be appreciated that the high performance computing unit  is kept free for receiving requests and working on them instantly (or near instantly) by ensuring that only a small load is applied to it for immediate conversion. In embodiments, it can be contemplated that the distributed block includes multiple high performance computing units commensurate with the number of conversion requests likely to be received. Also, in the multiple request scenario, the splitter  implements algorithms to split (and distribute) the various video clips optimally to ensure that at least a certain number of segments of each video clip is available for being streamed into device , with minimal or no latency.","As defined herein, a high performance computing unit  is, for example, a processor architecture or cloud computing architecture with high processing capability. By virtue of such computing units being prohibitively expensive, the transcoding principles described herein make use of one or a small set of such higher performance computing units to get an initial spurt of video content converted to the second format (i.e., format compatible with device ). This way, at least an initial video feed, corresponding to the content converted using the higher performance computing unit(s) is available for minimal-latency playback at device  while the rest of the clip is converted using a distributed architecture. In embodiments, while the initial segment is being converted and sent for playback to device , the remaining segments are converted using the lower performance computing units that are more affordable (relative to the high performance computing unit). The assembler  combines the converted segments received from the various computing units. Further, in embodiments, the assembler  organizes the converted segments in timeline order and transmits segments as appropriate for playback to device . In embodiments, assembler  may receive all converted segments and assemble them in a timeline prior to transmitting to device . In other embodiments, the assembler may simply transmit the segments to the client device as and when the segments are received. In examples, the assembled content may also be fed back to cache  to ensure that the content server  has a cached copy of the video content in the new format for subsequent requests.","It is understood that the splitter  and assembler  operations indicated in block  may be performed in the content server  itself or in another such computing device (instead of such blocks being part of a cloud). Similarly, the computing units illustrated as cloud computing units in block  may instead be substituted with an array of processors or other such distributed computing resources directly within (or in conjunction with) the content server . It is further understood that the content server  may simply be the data center as described in  or can also be computing devices that control transmission of online video content to client devices.","In embodiments, application content providers may utilize a combination of maintaining cached versions of popular formats and just-in-time transcoding techniques to optimize the cost of transcoding. For example, application providers may retain popular application content (e.g., video clips from a popular movie heavily demanded for instant viewing) in several formats, while retaining the less popular application content in just one format. In examples, application providers may retain content in multiple popularly requested formats, but not retain any copies of the less-frequently requested formats. In examples, content providers may utilize combinations of such techniques to perform the transcoding techniques, effectively reducing storage cost while improving latency in delivery of content.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 18","FIG. 17","FIG. 17"],"b":["1800","1800","1700","1810","1811","1812","1800","1800","1820","1800","1814","1816","1818","1820"]},{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0065","num":"0064"},"figref":["FIG. 20","FIG. 1","FIG. 17","FIG. 20"],"b":["600","40","1026","600","605","610","625","625","625"]},"The processor(s)  may include central processing units (CPUs) to control the overall operation of, for example, the host computer. In certain embodiments, the processor(s)  accomplish this by executing software or firmware stored in memory . The processor(s)  may be, or may include, one or more programmable general-purpose or special-purpose microprocessors, digital signal processors (DSPs), programmable controllers, application specific integrated circuits (ASICs), programmable logic devices (PLDs), or the like, or a combination of such devices.","The memory  is or includes the main memory of the computer system . The memory  represents any form of random access memory (RAM), read-only memory (ROM), flash memory (as discussed above), or the like, or a combination of such devices. In use, the memory  may contain, among other things, a set of machine instructions which, when executed by processor , causes the processor  to perform operations to implement embodiments of the present invention.","Also connected to the processor(s)  through the interconnect  is a network adapter . The network adapter  provides the computer system  with the ability to communicate with remote devices, such as the storage clients, and\/or other storage servers, and may be, for example, an Ethernet adapter or Fiber Channel adapter.","Unless the context clearly requires otherwise, throughout the description and the claims, the words \u201ccomprise,\u201d \u201ccomprising,\u201d and the like are to be construed in an inclusive sense (i.e., to say, in the sense of \u201cincluding, but not limited to\u201d), as opposed to an exclusive or exhaustive sense. As used herein, the terms \u201cconnected,\u201d \u201ccoupled,\u201d or any variant thereof means any connection or coupling, either direct or indirect, between two or more elements. Such a coupling or connection between the elements can be physical, logical, or a combination thereof. Additionally, the words \u201cherein,\u201d \u201cabove,\u201d \u201cbelow,\u201d and words of similar import, when used in this application, refer to this application as a whole and not to any particular portions of this application. Where the context permits, words in the above Detailed Description using the singular or plural number may also include the plural or singular number respectively. The word \u201cor,\u201d in reference to a list of two or more items, covers all of the following interpretations of the word: any of the items in the list, all of the items in the list, and any combination of the items in the list.","The above Detailed Description of examples of the invention is not intended to be exhaustive or to limit the invention to the precise form disclosed above. While specific examples for the invention are described above for illustrative purposes, various equivalent modifications are possible within the scope of the invention, as those skilled in the relevant art will recognize. While processes or blocks are presented in a given order in this application, alternative implementations may perform routines having steps performed in a different order, or employ systems having blocks in a different order. Some processes or blocks may be deleted, moved, added, subdivided, combined, and\/or modified to provide alternative or sub-combinations. Also, while processes or blocks are at times shown as being performed in series, these processes or blocks may instead be performed or implemented in parallel, or may be performed at different times. Further any specific numbers noted herein are only examples. It is understood that alternative implementations may employ differing values or ranges.","The various illustrations and teachings provided herein can also be applied to systems other than the system described above. The elements and acts of the various examples described above can be combined to provide further implementations of the invention.","Any patents and applications and other references noted above, including any that may be listed in accompanying filing papers, are incorporated herein by reference. Aspects of the invention can be modified, if necessary, to employ the systems, functions, and concepts included in such references to provide further implementations of the invention.","These and other changes can be made to the invention in light of the above Detailed Description. While the above description describes certain examples of the invention, and describes the best mode contemplated, no matter how detailed the above appears in text, the invention can be practiced in many ways. Details of the system may vary considerably in its specific implementation, while still being encompassed by the invention disclosed herein. As noted above, particular terminology used when describing certain features or aspects of the invention should not be taken to imply that the terminology is being redefined herein to be restricted to any specific characteristics, features, or aspects of the invention with which that terminology is associated. In general, the terms used in the following claims should not be construed to limit the invention to the specific examples disclosed in the specification, unless the above Detailed Description section explicitly defines such terms. Accordingly, the actual scope of the invention encompasses not only the disclosed examples, but also all equivalent ways of practicing or implementing the invention under the claims.","While certain aspects of the invention are presented below in certain claim forms, the applicant contemplates the various aspects of the invention in any number of claim forms. For example, while only one aspect of the invention is recited as a means-plus-function claim under 35 U.S.C. \u00a7112, sixth paragraph, other aspects may likewise be embodied as a means-plus-function claim, or in other forms, such as being embodied in a computer-readable medium. (Any claims intended to be treated under 35 U.S.C. \u00a7112, \u00b66 will begin with the words \u201cmeans for.\u201d) Accordingly, the applicant reserves the right to add additional claims after filing the application to pursue such additional claim forms for other aspects of the invention","In addition to the above mentioned examples, various other modifications and alterations of the invention may be made without departing from the invention. Accordingly, the above disclosure is not to be considered as limiting and the appended claims are to be interpreted as encompassing the true spirit and the entire scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF DRAWINGS","p":["These and other objects, features and characteristics of the present invention will become more apparent to those skilled in the art from a study of the following detailed description in conjunction with the appended claims and drawings, all of which form a part of this specification. In the drawings:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIGS. 4-16"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 20"}]},"DETDESC":[{},{}]}
