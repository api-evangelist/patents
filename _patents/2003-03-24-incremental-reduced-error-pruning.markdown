---
title: Incremental reduced error pruning
abstract: Described are techniques used automatic generation of classification rules used in machine learning. A single rule is formed of one or more logical expressions and an associated target. Using a set of training data, rules are formed one logical expression at a time using special data structures that require each feature to be sorted only once per rule formation. The FOIL gain metric is used in determining optimal splits for categorical features. Rule formation ceases with the production of five bad rules in which a bad rule is one in which there are more negative than positive examples in the training data set.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07305373&OS=07305373&RS=07305373
owner: Massachusetts Institute of Technology
number: 07305373
owner_city: Cambridge
owner_country: US
publication_date: 20030324
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","STATEMENT OF GOVERNMENT INTEREST","BACKGROUND","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF EMBODIMENT(S)"],"p":["This application claims priority to U.S. Provisional Patent Application No. 60\/432,050, filed on Dec. 10, 2002, which is incorporated by reference herein.","The invention was made with Government support under contract No. F19628-00-C-0002 by the Department of the Air Force. The Government has certain rights in the invention.","1. Technical Field","This application generally relates to machine learning techniques, and more particularly to techniques for producing classification rules.","2. Description of Related Art","Techniques may be used to perform classification of data such as, for example, related to objects and the occurrence of events, in an automated manner. Data to be classified may be represented as a set of data items. In one representation, each data item includes one or more attribute values for a number of attributes. One classification technique uses a set of rules to classify the data items in accordance with attribute values placing each data item into a class. For example, a program may be executed in a computer system which applies a set of rules to unclassified input data. The program may produce as output a classification of each of the data items included in the input data.","Different techniques may be used in connection with producing a set of rules. The rules may be manually produced. However, manual techniques may become too expensive in terms of time, for example, as the complexity of the input data set and the associated classification increases. Additionally, the manual rule production requires a user to have knowledge about the data items and the classifications.","An alternative class of techniques automate the production of the set of rules. For example, a rule generation program may be executed in a computer system to automate rule production. It may be desirable to have the automated technique be efficient in terms of computer resources. If the rule generation is performed interactively, it may be particularly desirable to utilize a technique that seeks to minimize execution time.","Unclassified input data may include categorical and numeric, or non-categorical, data. \u201cCategorical data\u201d may be characterized as data that cannot naturally be ordered by a metric such as, for example, names of automobile producers, products offered by one or more manufacturers, and the like. It may be desirable to have an efficient automated technique for rule generation that may be used with categorical and non-categorical features. It may also be desirable that the rule generation technique produce rules that properly classify the given input data, and more generally, any input data set to a particular degree of correctness. In other words, it may be desirable that the generated rules are not overly specific to any particular input set, but rather achieve a high uniform degree of correct classification in accordance with all possible input data sets.","In accordance with one aspect of the invention is a method for generating a classification rule. Feature vectors of values of a training data set are determined. Values of each of the feature vectors are sorted in accordance with a ranking of values included in each of the feature vectors producing sorted feature vectors. A first condition of the classification rule is determined using a training data set. Values are removed from the sorted feature vectors that are associated with examples included in the training data set that are uncovered with respect to the first condition while maintaining the sorted feature vectors in sorted order. At least one additional subsequent condition of the classification rule using the sorted feature vectors is determined.","In accordance with another aspect of the invention is a method of forming a classification rule for classifying input data by determining a single condition of the classification rule at a time. When forming a first condition, each of a plurality of feature vectors including feature values associated with examples in the input data is sorted in accordance with feature values of each feature vector producing sorted feature vectors. The sorted feature vectors are used when adding each next condition to the classification rule such that the feature vectors are sorted only when determining the first condition of the classification rule.","In accordance with another aspect of the invention a computer program product that generates a classification rule comprising: machine executable code that determines feature vectors of values of a training data set; machine executable code that sorts values of each of said feature vectors in accordance with a ranking of values included in each of said feature vectors producing sorted feature vectors; machine executable code that determines a first condition of the classification rule using a training data set; machine executable code that removes values from said sorted feature vectors that are associated with examples included in said training data set that are uncovered with respect to said first condition while maintaining said sorted feature vectors in sorted order; and machine executable code that determines at least one additional subsequent condition of the classification rule using said sorted feature vectors.","In accordance with yet another aspect of the invention is a computer program product that forms a classification rule for classifying input data comprising machine executable code that determines a single condition of said classification rule at a time, wherein, when forming a first condition, each of a plurality of feature vectors including feature values associated with examples in said input data is sorted in accordance with feature values of said each feature vector producing sorted feature vectors, and said sorted feature vectors are used when adding each next condition to the classification rule such that said feature vectors are sorted only when determining said first condition of the classification rule.","Referring now to , shown is an example of an embodiment of a computer system according to the present invention. The computer system  includes a data storage system  connected to host systems -through communication medium . In this embodiment of the computer system , the N hosts -may access the data storage system , for example, in performing input\/output (I\/O) operations or data requests. The communication medium  may be any one of a variety of networks or other type of communication connections as known to those skilled in the art. The communication medium  may be a network connection, bus, and\/or other type of data link, such as a hardwire, wireless, or other connection known in the art. For example, the communication medium  may be the Internet, an intranet, network or other connection(s) by which the host systems -may access and communicate with the data storage system , and may also communicate with others included in the computer system .","Each of the host systems -and the data storage system  included in the computer system  may be connected to the communication medium  by any one of a variety of connections as may be provided and supported in accordance with the type of communication medium . Each of the processors included in the host computer systems -may be any one of a variety of commercially available single or multi-processor system, such as an Intel-based processor, IBM mainframe or other type of commercially available processor able to support incoming traffic in accordance with each particular embodiment and application.","It should be noted that the particulars of the hardware and software included in each of the host systems -, as well as those components that may be included in the data storage system , are described herein in more detail, and may vary with each particular embodiment. Each of the host computers -may all be located at the same physical site, or, alternatively, may also be located in different physical locations. Examples of the communication medium that may be used to provide the different types of connections between the host computer systems and the data storage system of the computer system  may use a variety of different communication protocols such as SCSI, ESCON, Fibre Channel, or GIGE (Gigabit Ethernet), and the like. Some or all of the connections by which the hosts and data storage system  may be connected to the communication medium  may pass through other communication devices, such as a Connectrix or other switching equipment that may exist such as a phone line, a repeater, a multiplexer or even a satellite.","Each of the host computer systems may perform different types of data operations in accordance with different types of tasks. In the embodiment of , any one of the host computers -may issue a data request to the data storage system  to perform a data operation, such as a read or a write operation.","Referring now to , shown is an example of an embodiment of a data storage system  that may be included in the computer system  of . The data storage system  in this example may include a plurality of data storage devices through . The data storage devices through may communicate with components external to the data storage system  using communication medium . Each of the data storage devices may be accessible to the hosts through using an interface connection between the communication medium  previously described in connection with the computer system  and the communication medium . It should be noted that a communication medium  may be any one of a variety of different types of connections and interfaces used to facilitate communication between communication medium  and each of the data storage devices through ","The data storage system  may include any number and type of data storage devices. For example, the data storage system may include a single device, such as a disk drive, as well as a plurality of devices in a more complex configuration, such as with a storage area network and the like. Data may be stored, for example, on magnetic, optical, or silicon-based media. The particular arrangement and configuration of a data storage system may vary in accordance with the parameters and requirements associated with each embodiment.","Each of the data storage devices through may be characterized as a resource included in an embodiment of the computer system  to provide storage services for the host computer systems through . The devices through may be accessed using any one of a variety of different techniques. In one embodiment, the host systems may access the data storage devices through using logical device names or logical volumes. The logical volumes may or may not correspond to the actual data storage devices. For example, one or more logical volumes may reside on a single physical data storage device such as . Data in a single data storage device may be accessed by one or more hosts allowing the hosts to share data residing therein.","Referring now to , shown is an example of an embodiment of a host or user system . It should be noted that although a particular configuration of a host system is described herein, other host systems -may also be similarly configured. Additionally, it should be noted that each host system -may have any one of a variety of different configurations including different hardware and\/or software components. Included in this embodiment of the host system is a processor , a memory, , one or more I\/O devices  and one or more data storage devices  that may be accessed locally within the particular host system. Each of the foregoing may communicate using a bus or other communication medium . Each of the foregoing components may be any one of more of a variety of different types in accordance with the particular host system ","Computer instructions may be executed by the processor  to perform a variety of different operations. As known in the art, executable code may be produced, for example, using a loader, a linker, a language processor, and other tools that may vary in accordance with each embodiment. Computer instructions and data may also be stored on a data storage device , ROM, or other form of media or storage. The instructions may be loaded into memory  and executed by processor  to perform a particular task.","Referring now to , shown is an example of an embodiment of components that may be included in a rule generation and classifier system . The components of the rule generation and classifier system  may reside and be executed on one or more of the host computer systems included in the computer system  of . The rule generation and classifier system  in this particular embodiment includes unclassified data , the classifier program , classified output data , classification rules , a rule generation program , and an input data set or training and validation data . The classifier program  may be executed which reads the unclassified data  as input. Classifier program  may also read as input classification rules . The classifier program  then classifies the unclassified data  in accordance with classification rules  to produce the output classified data . The classification rules  may be produced using the rule generation program . The rule generation program  uses input training and validation data  to produce the classification rules  as an output in an automated fashion.","It should be noted that components included in , such as the input and output data sets, may also be stored in the data storage system.","The rule generation program  and the classifier program  may be executed on any one of a variety of different computer processor or processors of a host system, for example, as described elsewhere herein in more detail. Each of the rule generation program  and the classifier program  may also be produced using any one of a variety of different techniques or a combination thereof. For example, in one embodiment, the rule generation program may be generated using the C++ programming language and a compiler, or other translator. The data and the components included in the rule generation and classifier system  are described in more detail in following paragraphs and in connection with other figures.","Referring now to , shown is an example of a representation of classification rules  in a table format. The representation of the classification rules  includes one or more rules represented by corresponding ones of rows through . Each rule may include one or more logical expressions on the left hand side of the rule and an associated class specifier on the right hand side of the rule. In this particular embodiment, a rule generation program  outputs classification rules  in a format that is human readable. Other embodiments may output classification rules in any one of a variety of other different forms and formats.","Referring now to , shown is a more detailed example  of a rule and a rule that may be included in the classification rules . The rule in this example includes one or more logical expressions in which each logical expression is represented by the triple of an attribute, an operator, and a value. The attribute corresponds to a particular attribute of the input data items comprising the unclassified data . The operator in this example represents a logical operator such as equal to, less than, greater than and the like. The value of the triple represents a value that is compared to the value of the attribute of a particular data item. The right hand side of the rule includes a classification target value or a target. Rule representation in this example includes an attribute and set of values pair mapped to a classification target value.","A rule including a categorical feature may take the form described in in which a particular attribute is compared against one or more literal values represented as a set of values. A single rule may include only categorical features, only non-categorical features, or a mix of categorical and non-categorical features.","The classifier program  may apply the rules  in a predefined order until one rule is found for which all of the logical expressions on the left hand side of the arrow evaluate to true. When this occurs, the particular associated class specifier or target is assigned to the particular data item as its class.","Referring now to , shown is an example of an input data set  that may represent the combined training and validation set  input to the rule generation program The input data set may be represented as table  where each row  represents a data point (\u201ctraining pattern\u201d) and each column -represents a feature (variable). In this embodiment, a boolean target is used such that one of the features or variables is designated the target and contains one of two unique values which may be encoded as the values 0 and 1 corresponding, respectively, to Boolean values of false and true. However, the target values may be any value that is representative of the target concept for the domain of interest. In one embodiment, the target takes on values \u201cJOIN\u201d and \u201cNOT JOIN\u201d. The other features represent values of an observation of an attribute.","Techniques described in following paragraphs attempt to derive a set of conditions and rules that predict the value of the target variable from the values of the other features. These derived conditions can be used to accurately predict the target value for a data point whose feature values are known, but whose target value is not known. In the example described in following paragraphs, a method begins with a default rule: all data points should be classified as target value 0. The method then derives conditions (literals) which may be logically ANDed together to produce a rule which predict exceptions to the default. Each of these conditions corresponds to a logical expression as described in connection with the rules  in which each condition may be represented by a triple (attribute, operator, value) or a pair (attribute, set of values) . Several conditions may be logically ANDed together (a \u201cconjunction of literals\u201d) to form a single rule. The system may learn many rules. In this embodiment, any input data point whose feature values satisfy the conditions of any of the rules are predicted to have target value 1 instead of the default value of 0.","It should be noted that the unclassified data  and the training and validation data  may be similarly represented in an embodiment as shown in the representation  of . The training and validation data  may be characterized as a particular instance of data items to produce a more general set of rules that should also be capable of classifying other data items, such as unclassified data .","Referring now to , shown is a flowchart  of steps of one embodiment for rule generation. The steps included in the flowchart  may be executed by the Rule Generation Program  described elsewhere herein. The flowchart  sets forth method steps that may be referred to as an Incremental Reduced Error Pruning (IREP++) technique which, in this embodiment, is used with a rules-based system with boolean targets. It should be noted that the techniques described herein are not limited to this specific example system and have general applicability.","At step , features of importance are determined and the input data set of feature vectors is generated. The input data set may be as represented in the form  of . Any one of a variety of different techniques may be used to select particular features of importance. Features selected are highly correlated with, or are predictive of, each of the target values. Any one of a variety of different techniques may be used in feature selection. For example, an embodiment may manually perform feature selection, or use other techniques, such as the forward and backward feature selection technique. For example, the LNKnet data mining tool provides routines that perform feature selection as available at the web address:","www.II.mit.edu\/IST\/Inknet\/index.html","Additionally, the text book entitled \u201cFeature Extraction Construction and Selection: A Data Mining Perspective\u201d, Editors Huan Liu and Hiroshi Motoda, published by Kluwer International, 1998, ISBN:0-7923-8196-3 is a collection of articles on feature selection techniques that may be used in an embodiment.","It should be noted that step  may be performed at any point prior to performing the remainder of the steps included in the flowchart . An embodiment may perform feature selection, for example, immediately before performing other processing steps. An embodiment may also choose to perform feature selection, for example, several days or weeks prior to performing other processing steps.","Once features have been selected and the input data set is formed, control proceeds to step  where the data set is input by the rule generation program . The input data set  may be sorted on input such that rows of data having common target values, such as JOIN and NO JOIN, are grouped together within the table representation.","Control proceeds to  where a determination is made as to whether there are any positive examples in the input data set. If not, processing stops. Otherwise, if there are positive examples in the input data set, control proceeds to step  where the input data set may be randomly partitioned into two portions, a training data set and a validation set. In this example, a random number function may be used in determining which elements of the input data set are in each of the two portions. An embodiment may also preserve the distribution of JOIN\/NO JOIN examples within each of the two portions. For example, if the input data set includes 20% NO JOIN targets and 80% JOIN targets, the input data set may be partitioned into the two portions so that this distribution is preserved, or approximately so. One technique known in the art for preserving the distribution is described in \u201cThe Art of Computer Programming\u201d, Volume 2, Second Edition, Section 3.4.2, P. 136, by Donald Knuth. It should be noted that an embodiment may preserve the distribution such that a system learns and validates in accordance with conditions of the recorded data to produce a more accurate model assuming the distribution of the recorded data accurately represents the distribution of a more general population.","As part of step  processing, the training data set may be mapped from the representation to the representation in accordance with feature tables -and Keep tables  of  for use when performing other processing steps of the IREP++ technique of flowchart . The tables -and Keep table  include a representation of only the training data set subsequent to executing step . The validation set does not need to be placed in feature vectors with an associated Keep table. Table is a portion of the input data set  corresponding to the training data set in this example.","Each of the feature tables -of the representation  includes data from one of the columns of the training data table . Each entry of the tables includes a Row ID# associate with each Value. The Row ID# identifies the corresponding row from the original table within which the Value occurs. Table includes the values of feature  for each row of table data, and table includes the values of feature n for each row of table data. Keep table  is a table of boolean values where there is one boolean value corresponding to each row of data included in the data set . A value of KEEP in the Keep table  indicates that a corresponding row of data (Row ID#) is included in the training set. A value of NO KEEP indicates otherwise. At this point, the values in the Keep table  are all initially KEEP. The tables  and -are updated at various points in subsequent processing steps","It should be noted that an embodiment may not store the Row ID explicitly as represented in the table . For example, in one embodiment, the Keep table  may be implemented as an array in which the Row ID is used as an index into this array. Other embodiments may use other data structures to implement those items represented in  and described herein.","Once tables -are populated, each of the tables -may be sorted in subsequent processing steps in accordance with feature values included therein. The use of the Keep table  is described in connection with later processing steps of the flowchart  elsewhere herein.","Control proceeds to step , where a first feature corresponding to one of the feature vectors represented as one of -is selected. At step , a determination is made as to whether all features in the tables -have been processed. If not, control proceeds to step  where the training set is sorted based on the current feature. Using the representation tables , the current feature vector may be sorted independently of the other feature vectors. In other words, only the current feature vector values are sorted in connection with step  processing.","At step , the best training data split is determined for the sorted training data. In one embodiment, the sorted training data is repeatedly split at various points. For each split, a corresponding metric value is determined using the FOIL gain metric described, for example, in Chapter 10 of the text book entitled \u201cMachine Learning\u201d, published 1997 by McGraw-Hill, ISBN 0-07-042807-7. The FOIL metric is determined at each split point in the sorted feature vector using the following:",{"@attributes":{"id":"p-0059","num":"0058"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":{"mi":"log","mn":"2"},"mo":"\u2062","mfrac":{"mi":"p","mrow":{"mi":["p","n"],"mo":"+"}}},{"msub":{"mi":"log","mn":"2"},"mo":"\u2062","mfrac":{"msub":{"mi":"p","mn":"0"},"mrow":{"msub":[{"mi":"p","mn":"0"},{"mi":"n","mn":"0"}],"mo":"+"}}}],"mo":"-"}}}}},"br":{}},"p=the number of positive or JOIN examples below the split point,","n=number of negative or NOJOIN examples below the split point,","p=number of positive examples in the entire data set, and","n=number of negative examples in the entire data set.","Step  processing involves determining the foregoing FOIL gain metric of the training data that is sorted in increasing order of the current feature vector values in which the split point is 1, then 2, and so on. The split point corresponds to a row in the current feature vector. The split point selected as the \u201cbest\u201d as a result of step  processing is the split point with the largest associate FOIL gain metric value. Other embodiments may utilize other metrics to determine the split of the training data set sorted in accordance with values of data items for the current feature. Control proceeds to step  where the next feature is selected and the processing of steps , ,  and  is repeated until a \u201cbest\u201d split point has been determined for the training data in accordance with a sorted order based on each feature vector.","When all features vectors have been processed as determined at decision point , control proceeds to step  where the best data split of all the features is selected using the metric, such as the FOIL gain metric. The logical expression associated with the condition represented by the best split selected is added to the left side of the current rule being formed. Control proceeds to step  where examples uncovered with respect to the current rule are removed from the training data set. A row of data may be characterized as covered by a rule if the associated example meets the conditions in the rule, and may otherwise be characterized as uncovered. A row of data may be similarly, characterized as covered by a single condition (literal) if the condition is true for the features in the row.","More detailed processing of steps  and  are described in following paragraphs with reference made to the particular embodiment using the feature tables -and the Keep table . The Keep table may be used with tables -to indicate which examples or rows of training data are currently being utilized by the IREP++ processing steps of flowchart  in a particular iteration for growing a rule. Processing step , for example, updates the current training data set to remove those examples or rows of data which are not covered by the new condition selected as a result of processing step .","Referring now to , shown are representations  and  of the tables representing the training data set at two different processing points. The representation  may correspond to the tables subsequent to step  processing and the representation  may correspond to the tables subsequent to processing step . Consider, for example, an instance in which, after processing step , the best selected condition is \u201cfeature <2.5.\u201d This split is represented by the line  in table . At step , the uncovered examples are removed. In this instance, all rows of data set having \u201cfeature  greater than or equal to 2.5\u201d are considered uncovered and are removed. This removal may be accomplished using the Keep table  and tables -. A row of data that remains in the training data set may be indicated by an entry VALUE of KEEP in the Keep table . Otherwise, the entry has a value of NO KEEP. Line  of Feature  table illustrates the logical division of sorted feature  values in accordance with the condition \u201cfeature <2.5\u201d. The values above the line  meet the condition, and have the corresponding Row ID # entry in the Keep table  with a value of KEEP. All other rows of data have a corresponding entry in the Keep table  with a value of NO KEEP.","Using the IREP++ technique of flowchart  with the foregoing data structures, the Keep table is updated once for each condition or literal added to a rule. Each feature vector -may then be compressed using the Keep table such that each feature vector includes only those examples indicated as KEEP. Referring again to , the tables  show revised versions of the tables -after such compression. An embodiment may use any one of a variety of different techniques to copy the KEEP data and overwrite as needed data in the tables that is to be deleted.","It should be noted that an embodiment may not compress the Keep table  as shown in the representation  of  because of the implementation of the underlying structure as an array in which the row number or ID is an index into the table. Other embodiments may choose to compress the Keep table  such that it includes only those elements with values of KEEP prior to the next condition being selected and use other techniques to keep track of which Row ID corresponds to which entry in the Keep table .","The Keep table may be used to preserve the sorted input data in accordance with the JOIN and NOT JOIN apportionments. An index value into the Keep table  may be used to indicate a dividing line as to where the JOIN values end and the NO JOIN values start. This may be represented, for example, by the line  included in table  of .","As described herein, use of the Keep table  provides for maintaining a sorted order of the features for the training data set such that as examples are removed, all feature vectors or tables need only be sorted once per rule formation when selecting the first condition or literal. For subsequent conditions selected for the same rule, the Keep table  may be used to preserve the sort order of tables -when adding conditions or literals for the same rule. When forming a new rule, the training set includes only those examples covered by the literals or conditions included in the rule so far.","Control proceeds to step  where a determination is made as to whether there is a classification error with the current rule and training data set. In other words, the currently formed rule is applied to the training data set reduced as a result of step  processing to determine if the currently formed rule properly classifies each example in the training data set. If there is a classification error, it means additional conditions (logical expressions) need to be added to the rule so control proceeds to step  where the current feature (Curr_feature) is assigned to first feature and control proceeds to step  where the next best split of all features is determined. This processing to add conditions continues to grow the current rule until, at step , it is determined that there is no classification error causing control to proceed to step .","It should be noted that using the techniques and data structures described herein, when determining subsequent conditions or literals to add to a rule, there is no need to execute step  processing to sort the feature vectors. The feature vectors are sorted only the first time each first condition or feature is added. Subsequently, the feature vectors are updated and maintained in sorted order, for example, when removing uncovered examples in step  processing. The next time the feature vectors are once again sorted is when there are new values included therein as a result of forming a new rule when the data sets are recombined, as in step  processing described elsewhere herein.","Subsequently, the currently formed rule may be overspecific with respect to the training data set due to the fact, for example, that there may be too many conditions on the left hand side of the rule. Accordingly, the currently formed rule is pruned using the validation set. Pruning may result in reducing the number of conditions. In this embodiment, the FOIL gain metric is used to evaluate which pruned rule is best. As described in more detail in following paragraphs, the technique used in this embodiment determines the FOIL gain metric for the original rule and then determines the FOIL gain metric for each of one or more pruned rules. A FOIL gain metric is determined for each pruned rule formed by successively removing single conditions in a last-in-first out (LIFO) fashion from the final rule. The pruned rule with the maximum FOIL gain metric is selected as the final rule.","Pruning may be performed in an embodiment as follows. The number of data points in the validation set covered by the unpruned rule whose target value is true (JOIN) is determined. This may be referred to as p. The number of examples in the validation covered by the unpruned rule whose target value is false (NOT JOIN) is then determined. This may be referred to as n. It should be noted that while literals or conditions are added to the rule until the currently formed rule covered no training patterns with target value false on the training set, the rule may cover some patterns with target value false in the validation set; hence n may be nonzero. The last literal from the unpruned rule is then removed. It is then determined how many examples from the validation set with target value true are covered by this new rule. This value is designated p. The number of patterns in the validation set covered by the new rule with target value false is designated n. Using the values calculated for p, n, p, and n, the FOIL gain of the new rule is calculated using the FOIL gain metric formula described elsewhere herein. The result is negated by being multiplied by \u22121. The last two literals are then removed from the original, unpruned rule and pand nare recalculated as before. The negative of the FOIL gain is again calculated. This process is repeated until all literals have been removed from the rule and all associated FOIL gains determined. The pruned rule which maximizes the negated FOIL gain metric is kept as the \u201cfinal\u201d pruned rule. The pruning provides for compensating the possibility of overtraining using the training data set. Removing conditions provides for a more generalized rule.","Using the foregoing FOIL metric in evaluating pruned rules, p and n are associated with the original rule formed before any pruning begins. nand pare associated with the currently formed pruned rule that varies with the removal of each condition or literal.","It should be noted that an embodiment may use other techniques for performing rule pruning in combination with other processing steps described herein.","When pruning a rule, as each condition or literal is removed, the rule becomes more general. Accordingly, if an example is covered by pruned rule at iteration \u201cx\u201d, the same examples will also be covered by the pruned rule formed at iteration \u201cx+1\u201d. In determining the error rate of each newly formed pruned rule by successively removing conditions, all examples do not need to be tested for each newly formed pruned rule. On a pruning iteration \u201cx+1\u201d, the validation set used may be formed by eliminating from the validation set those examples covered by the pruned rule at iteration \u201cx\u201d. It should be noted that this removal of examples from the validation set applies only for pruning this rule.","It should be noted that an embodiment may continually reduce the validation set for each pruning iteration of the current rule, as described above. Alternatively, one embodiment reduces the validation set only after the first pruning iteration. An embodiment may also reduce the validation set for any predetermined number of pruning iterations. One consideration as to the number of pruning iterations for which a validation set is reduced may include the overhead associated with keeping track of which elements or examples of the validation set are eliminated. This may vary in accordance with the data structures included in an embodiment.","Referring now to , shown is an example of a rule  that may be formed and exist prior to pruning at step . Each of the logical expressions or conditions -has been added to the rule subsequent to an iteration of step . The pruning process described above determines a FOIL gain metric by examining a first pruned rule formed by removing the condition . A second FOIL gain metric is determined by examining a second pruned rule formed by removing conditions and . A third FOIL gain metric is determined by examining a third pruned rule formed by removing conditions , and . A FOIL gain metric is determined for the original unpruned rule as well. The form of the rule with the highest FOIL gain metric is selected as the final rule that is used in step  processing. It should be noted that conditions and includes a categorical feature using set notation.","After the current rule is pruned, control proceeds to step  where it is determined if the current rule is a \u201cbad rule\u201d. If the current rule is a bad rule, control proceeds to step  where the rule is discarded, and the total number of bad rules is increased by 1. Control proceeds to step  where a determination is made as to whether a predetermined stopping criteria is met. In this embodiment, the stopping criteria for rule formation in the IREP++ technique described herein with flowchart  processing is the formation of 5 \u201cbad\u201d rules. A rule may be classified as \u201cbad\u201d when there are more negative than positive training examples covered by the rule in the validation set. If the bad rule count or other stopping criteria has been met as determined by step , processing of the steps of flowchart  stops. Otherwise, control proceeds to step . If at step  it is determined that the final new rule is not a bad rule, the rule is added to the current set of rules generated at step , and control proceeds to step  where the examples included in the training and the validation set that are covered by the newly formed rule just considered by the pruning process are removed. Control proceeds to step .","The current training and validation data sets are recombined at step . The newly formed combined set is then used as a new input data set to continue processing on subsequent iterations beginning at step . Successive new rules are similarly formed until predetermined stopping criteria is met.","It should be noted that the input data set may include categorical data in addition to numerical data. Numerical data may be much more readily compared and sorted, as opposed to categorical feature data. What will now be described are techniques that may be used with categorical data processing in connection with the IREP++ processing steps of flowchart , for example, such as in step  where a subset of feature values that maximize the FOIL gain metric is determined.","Consider the following example. Suppose there is a feature . An example including feature  may have a value that is one of w possible alphanumeric strings. Each of the w possible feature values may be associated with a number of positive examples pp and a number of negative examples nn. A subset of feature values may be determined for each feature that maximizes the FOIL gain metric. For each feature, the technique described in following paragraphs performs a sorting of the categorical data in accordance with decreasing pp\/nn ratios. Any sorting technique may be used. A linear search may then be performed on subsets of the feature values using the FOIL gain metric to determine an optimal subset of values. Below is a pseudo-code representation of the technique for use with categorical data selection for a particular feature:","Determine pp\/nn ratio for each feature value 1..w","Sort feature values 1..w in accordance with decreasing pp\/nn ratio order","num=1","while num < w+1\n\n","end_while","best_split= feature value combination having the MAX(all FOIL gain metrics)","This may be used, for example, to determine the best split in the table of a feature as a result of processing step . The foregoing technique allows an embodiment to compare categorical and non-categorical data using the same metric, the FOIL gain metric to select a condition or literal to be added to a rule currently being formed by the IREP++ processing. Using the foregoing technique, a subset of the features can be determined which is guaranteed to maximize the FOIL gain entry. In the foregoing, only w combinations of contiguous feature values sorted by associated pp\/nn ratios are evaluated. The selected subset is guaranteed to be optimal and have the highest FOIL gain by examining only w subsets of a possible 2total number of subsets.","It should be noted that the techniques described herein for sorting and evaluating categorical data may generally be used in connection with other applications using categorical data.","The foregoing provides a machine learning technique that may be used to generate classification rules in an efficient and automated fashion. The foregoing handles processing of categorical and non-categorical (numeric) features and describes efficient techniques using the FOIL gain metric for producing the optimal split on categorical features in linear time. The foregoing uses particular data structures to reduce the amount of sorting time by describing a method in which each feature is sorted once per rule formed. Referring to , each feature vector is only sorted in step  the first time the loop formed by steps ,   and  is executed if the data structures described herein are utilized. The foregoing also includes simple stopping criteria.","The embodiment including the rule generation techniques described herein uses boolean targets. However, the techniques described herein may also be used in connection with handling non-boolean targets. For example, the rule generation techniques may handle categorical targets taking on one of several unique non-numeric values. The input data may be sorted by target classification value in accordance with decreasing order of prevalence of each class in the training data set portion. In other words, the training data is classified by each target classification value. The target classification value that appears most in the training data is the most prevalent and may be characterized as the first class. The next most prevalent target classification value is determined and characterized as the second class, and so on for each target classification value. The input data set is then sorted in decreasing prevalence in accordance with each of these classes. The foregoing IREP++ technique described herein, such as discussed in connection with flowchart  of , may be executed iteratively using the sorted input data. For example, on a first iteration, rules are generated to separate the first class from all other classes. On the second iteration, rules are generated to separate the second class from all others, and so on. The processing steps of the IREP++ technique may be embodied in a subroutine that is iteratively invoked in which each call or invocation may be characterized as a classification problem with boolean targets. For example, the first iteration generates rules to determine whether an input item belongs to a first class C1 or not. The second iteration generates rules to determine whether an input item belongs to a second class C2 or not, and so on for each iteration. It should be noted that an embodiment may use the techniques described herein in connection with IREP++ in other ways and this is one example of how the foregoing techniques may be included in an embodiment to handle non-boolean target values.","While the invention has been disclosed in connection with preferred embodiments shown and described in detail, their modifications and improvements thereon will become readily apparent to those skilled in the art. Accordingly, the spirit and scope of the present invention should be limited only by the following claims."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Features and advantages of the present invention will become more apparent from the following detailed description of exemplary embodiments thereof taken in conjunction with the accompanying drawings in which:",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 6","FIG. 4"]},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 9","FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
