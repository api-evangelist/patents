---
title: System and method for automatic data mapping
abstract: A system and method for automatic data mapping of a source object to a target object. Field maps can be automatically determined from the source and target objects, database platform, ETL maps, user-defined and data conversion rules, default values, or other pre-defined parameters. Where a change occurs in the source or target data structure, the present invention ensures proper mapping between the source and target data structures occurs, thus reducing the burden of exception handling on the user and preventing oversight in correcting improper mapping. The present invention can also be used by a compiler to generate SQL steps during compile-time processes to design field maps that can be stored as an application class.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07596573&OS=07596573&RS=07596573
owner: Oracle International Corporation
number: 07596573
owner_city: Redwood Shores
owner_country: US
publication_date: 20030611
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["1. Field of the Invention","The present invention relates generally to the field of software and more particularly to a system and method for automatic data mapping.","2. Background of the Invention","Computer programs or software can be used to accomplish various project requirements and organizational needs. Large enterprise software applications often require the use of large amounts of data and information, generally stored in and requested from databases or repositories. Used in conjunction with enterprise applications are database and database management systems which manage, maintain, and operate on varying quantities of data. Enterprise applications operating or managing large amounts of data stored in databases, storage systems, or other repositories can be used for a variety of functions, often supporting activities such as accounting, operations, finance, marketing, and numerous other activities. However, large amounts of data often increase the complexity of operation for enterprise applications.","Providers of enterprise applications, which are often distributed throughout an organization, must meet increasing data requirements for operation, which includes the creation, maintenance, management, and use of data maps. Data maps, which direct various software applications to necessary and relevant portions of other software applications, are used in the execution or operation of other, often more complex, software applications. The setup and maintenance of large numbers of maps also represents an enormous operational burden on enterprise software applications, particularly in terms of expense and money.","A data or field map is used to identify relationships between multiple data fields in order to enable an application to execute at run-time or compile program code. Field maps may often be used to map data contained in tables, records, files, fields, or other structures where data can be stored. In a typical field map, a data source can be mapped to a data target. One example of a data source is a source table, where data is mapped to fields contained in a target table, generating a particular field map. In other words, a target table identifies the data destination for a source table. Tables containing fields may house varying quantities of data, which may be used to different extents by software and enterprise applications. Each field in each table of each map must be accounted for at many levels for use in various types of software applications. Conventional data mapping techniques and means require manual design and construction, where an individual developer must design individual maps for each data field correlation. Conventional data mapping techniques are labor and time-intensive, requiring developers to design, develop, and implement maps on an often ad-hoc basis. Once determined, data maps must be loaded in order to enable application at run-time to operate and draw upon required data. Again, this process in the conventional art is time and labor intensive.","If a source or target table, as described above, containing multiple data fields, changes, a map designer must review and change a corresponding table map. Changes to a corresponding data map may also be required. After the changes are made, then a data loader map must be rebuilt and each field must be individually and explicitly handled. The developer or user probably has no advance knowledge of changes and will only be aware of problems when an application stops running as a result of an improper data map.","Therefore, there is a need to reduce the time and labor-intensity of conventional data mapping techniques and methods.","The present invention provides for a method for generating a data map including defining a source object and a target object, applying a rule for defining the source object and the target object, assigning a default value to the target object, and saving the data map to a library. Embodiments of the present invention provide for further defining the source object and the target object based on using a default value to define the target object. In accordance with an embodiment of the present invention, additional definition of the source object and the target object can be accomplished by using a rule to define the target object. Alternatively, defining the source object and the target object may also be accomplished by using the source object to define the target object.","With regard to the use of default values to define the target object, using a record level default value may be implemented as a type of default value. Additionally, a system level default value can be used to define the target object.","In generating the data or field map, background information can be processed to further define the target object. Processing background information can include information based on database platform types and data types. This information is used to determine the resulting field map by enabling the automatic mapping process to generate field maps based on pre-determined or specified criteria such as the type of data base in use or the type of data being called.","In accordance with another embodiment of the present invention, an automatic mapping system is provided, including a data repository, an application engine exchanging data with the data repository, and an automatic mapping engine for generating a field map using data from the data repository. The automatic mapping system can also include a management system, and an interface for exchanging data and information with the application engine and the automatic mapping engine. Further, the data repository of the automatic mapping system also includes a presentation layer a data layer and an engine layer.","In accordance with an embodiment of the present invention which includes the above-referenced automatic mapping system, the presentation layer can include a data source for providing a source field, a map designer for designing a field map, and a scheduler for integrating the field map. In the data layer, the automatic mapping system can also include an extract, transform, and load (ETL) engine, a data transformation module exchanging data with the automatic mapping engine, and a query module for structured calling of data from the data repository based on the field map using a querying language such as SQL, although the present invention is not limited to the use of this programming language.","The automatic mapping engine can include an initialization module for initializing field map generation, a rules module for administering a map rule for the automatic mapping engine, default module for specifying a default field value, a map definition module for integrating the map rule and the default field value to define a target field, a field conversion module for converting the target field using the map definition module, and a field map generator for generating a field map.","Provided in another embodiment of the present invention is an apparatus for generating a data map including a means for defining a source object and a target object, a means for applying a rule for defining the source object and the target object, a means for assigning a default value to the target object, and a means for saving the data map to a library.","Still further, another embodiment of the present invention provides for a computer data signal embodied in a carrier wave comprising code for defining a source object and a target object, code for applying a rule for defining the source object and the target object, code for assigning a default value to the target object, and code for saving the data map to a library. A further embodiment of the present invention provides for a computer readable medium storing instructions for generating a field map comprising defining a source object and a target object, applying a rule for defining the source object and the target object, assigning a default value to the target object; and saving the data map to a library. A further understanding of the nature and advantages of the inventions herein may be realized by referring to the remaining portions of the specification and the attached drawings.","As shown in the exemplary drawings wherein like reference numerals indicate like or corresponding elements among the figures, exemplary embodiments of an automatic data mapping system and method according to the present invention will now be described in detail. The following description sets forth an example of an automatic mapping engine designed to simplify the source to target mapping effort by automating a significant amount of data mapping at run time. Embodiments according to the present invention provide for automatically mapping a source data field to a target data field, particularly where large amounts of data may require correspondingly large numbers of maps within the execution or run time of software such as enterprise applications.","Automatic data mapping provides for the definition and generation of data maps or \u201cfield maps\u201d between a source data object and a target data object. Data can be stored within database and database platform management systems such as SQL Server, OS390, Sybase, Oracle, DB\/2, Unix and other platforms known by those of ordinary skill in the art. Data held within data structures such as a record, table or field require maps, which can be automatically generated and adjusted (for data changes, errors, deletions, modifications, etc.) by the present invention. The following embodiments describe automatic data mapping systems, methods, and processes to enable one of ordinary skill in the art to implement the present invention. The following descriptions include exemplary embodiments, including an automatic data mapping engine operating within an application server environment and application engine.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 1","b":["100","102","104","106","108","104","106","108","104"]},"Within application server , a web server  is shown. Web server  houses various sub-applications or servlets, which operate as software modules for the presentation of content in a web-based format. In , web server  houses presentation relay servlet , an integration relay servlet , and a portal servlet . Presentation relay servlet  communicates with integration relay servlet  to send and display content via portal servlet . Data is exchanged between web server , application manager , SQL interface , and application services -. Application manager  manages data communication between the web server  and the application services -. SQL interface  manages data access and communication with database management system .","Application services - can be implemented as a series of software modules within application server . Although the illustrative embodiment is represented as having those software modules shown, application services - can be implemented using one or more software modules and is not limited to the embodiment shown. In , application services - include an application messaging processor , a business interlink processor , a component processor , a user interface generator , a query processor , a process scheduler , an application engine , a portal processor , and a security manager . Application engine  will be described in further detail in connection with  below. The illustrative embodiment shown is directed towards the implementation of a business-function enterprise application such as accounting, inventory or supply management, operations, finance, etc. Application messages are managed in terms of publishing, subscribing, and delivery by application messaging processor . Third-party software systems are managed by business interlink processor . Other enterprise application modules or components are managed by component processor . User interfaces are generated by UI generator . In conventional enterprise applications, application engine  provides the necessary functionality to enable manual creation and management of data mapping.",{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 2","b":["136","136","136","136"]},"A warehouse module  is shown housed within application engine . Also shown are data acquisition module , data warehouse administration module , and operational systems . Within warehouse module  are an Extract, Transform, and Load Engine (ETL)  and an automatic data mapping engine , in accordance with an exemplary embodiment of the present invention. The automatic data mapping engine  provides for automatic data mapping capabilities and features, including exception handling, in accordance with an embodiment of the present invention.","Modules for data loader  and data mart builder  are also shown. Operational systems  exchange data with ETL engine  which receives data maps generated automatically by automatic data mapping engine . An ETL repository  exchanges data with data acquisition module . Data exchange between operational systems , ETL engine , ETL repository , and data acquisition module  can be implemented in several ways. For example, an application programming interface (API) may be used to integrate data and information from operational systems  for a variety of formats, languages, and protocols (e.g., HTML, XML, XHTML, HTTP, etc.). Elements of an operational data store (ODS) are shown in communication with data loader . An ODS staging module  stages mapping metadata and other data from ETL engine , which is loaded and implemented for overall application use by data loader . Using data warehouse administration module , a user can direct the deposit of metadata to metadata module . After exchanging data with data mart builder , metadata, which is used to assist in creating field maps, is stored and managed for access within data mart . An additional data storage facility is provided by data warehouse , which receives stored data from data mart builder  and metadata module . Data which is loaded and stored in either data mart  or data warehouse  may be reported to users via ODS reporting module  which provides generated reports for review via either operational systems  or the data warehouse administration module . Alternatively, one of ordinary skill in the art may envision implementations whereby ODS reporting module  may exchange data directly with operational systems  and data warehouse administration module  using fewer or more intermediary modules such as data loader , ODS staging module  or ETL engine .",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 3","FIG. 2","FIG. 6"],"b":["300","212","304","306","304","208","104","304","212"]},"The scheduler  provides the ability to schedule data maps for implementation and use. Within automatic data mapping engine , an initialization module , a rules module , a target field default module , a map definition module , a field conversion module  and a field map generator  are shown. Rules governing the automatic data mapping process can be entered by a user and integrated with the mapping process using rules module . For example, a rule specifying that only those fields entitled \u201ccolor\u201d should be selected for automatic mapping between available source and target fields can be entered into rules module  using an interface. A typical interface may include an API or other programming interface intended to permit user input. A user can also specify rules such as these or others as one of ordinary skill in the art may envision.","Regardless of whether automatic mapping rules are entered, the automatic data mapping engine  automatically generates data maps, also incorporating default values for selected fields using target field default module  and map definition module . Map definition module  defines field maps using various inputs from rules module  and target field default module . Using either pre-specified rules or default values for target fields, map definition module  creates the map definition, from which field map generator  will generate the resulting field map. Continuing the above example, if \u201ccolor\u201d is a field to be selected for automatic data mapping, then a user can assign a default value of \u201cblue\u201d to this field, if it were to appear, overriding any other existing rules governing the mapping process. The user also provides for exception handling, where there may be exceptions that the user either desires or must address during the automatic data mapping process.","Once a map has been automatically generated using both rules and default values from rules module  and target field default module , respectively, the target field is converted using field conversion module . Finally, the resulting map is generated by field map generator . The modules within automatic data mapping engine  exchange data and communicate to enable the generation of the data maps or field maps. One of ordinary skill in the art may envision fewer or additional modules, but the embodiment described herein is not intended to be limiting upon the overall nature of the automatic data mapping process and system claimed by the Applicants. Further, the automatic data mapping process and the associated rules are described in greater detail with regard to .",{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 4","b":["400","402","404","406","402"]},"The database layer  represents the layer of the schema where data is extracted, transformed, and loaded from data repositories in order for the presentation layer  to present content, information, or data to a user . At the engine or application layer , data is aggregated in batch  for compilation and execution during run-time. As indicated to the right of , the presentation layer  is wholly represented as part of design-time processes during the operation of the automatic data mapping system and methods described herein. However, as presentation of content, information, and data may occur before, during, or after either the design or run-time phases (i.e., the user runs a report to view the generated field maps), the presentation layer described herein is not intended to be limited to only design-time phase activities, in accordance with an alternative embodiment of the present invention. The database layer  represents processes in both design-time and run-time in the operation of the automatic data mapping systems and methods described herein. Finally, the engine layer provides operations which exist wholly in run-time.","Throughout the presentation layer , a data sourcing module , a designer , and a scheduler  provide rules and operating parameters by which the automatic mapping process operates. At the database layer , four (4) stored data modules are shown, including extraction rules governing the selection of data and data objects from databases, repositories, warehouses, data marts, or other storage media and facilities, which are incorporated by extraction rules module . One of ordinary skill in the art may envision the use of fewer or more stored data modules than those shown in . The embodiment described herein is not intended to be limiting in any fashion other than to provide enabling guidance on the development and integration of the various modules and rules for automatic data mapping. The data transformation module  contains the automatic data mapping rules and any user override or exception handling rules that may be entered by a user. Communicating with the designer  and the scheduler , the data transformation module  provides the automatic mapping input to the engine layer , whose operation will be described below.","Referring back to the database layer , the data transformation module  passes data to the scheduler , providing input for the creation, management, and scheduling of field maps. Loading rules module  governs the implementation of the field maps for eventual use by the end application or application services that require the data maps. An SQL module  provides for the interface and exchange of data for querying, retrieving, and storing data in various data repositories. Although SQL is described in the preferred embodiment, one of ordinary skill in the art may envision other query languages which may be used for the purpose of exchanging data with various data structures and repositories, e.g., MySQL, etc. Finally, the engine layer  compiles, executes, and generates the field maps resulting from the automatic mapping process for integration into an end application such as operational systems  () which may be an enterprise application, software program, etc.","A compiler  compiles the necessary software or program code defining the field maps, which in turn generates the field maps which govern the exchange of data to and from any data structures or repositories, using SQL module . The executor  provides run-time execution of the field maps, exchanging data with SQL module  in the data base layer for version control of the various field maps. The SQL module  is a library which stores the SQL steps generated by the run-time compiling of the requests or \u201ccalls\u201d compiler  for field-maps which are generated by compiling code for the ETL engine  (). The resulting field maps are generated and executed by executor . Also, SQL module  maintains version control over field maps, to ensure that the most recent and updated field maps are used by executor .",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIGS. 5A-5C","b":["212","102","136","136","136"]},{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIGS. 5A-5C","FIG. 1","FIG. 1"],"b":["136","212","212","136","502","136","136","132","128","126"]},"Examples of SQL statements which are used in embodiments of the present invention include \u201cdo\u201d statements. \u201cDo\u201d statements represent control loops similar to those found in second and third-level programming languages such as C, C++, SQL, MySQL, etc.  use several SQL statements such as \u201cdo while,\u201d \u201cdo when,\u201d \u201cdo until,\u201d and \u201cdo select.\u201d The \u201cdo\u201d control loops represent logic loops which are performed until a particular condition or parameter is met. For example, in a \u201cdo while\u201d SQL statement, a particular set of instructions are executed by the application engine  until a condition or parameter is met.","Referring to , if, within the current section of data, there are more steps or entities (e.g., fields, tables, etc.) which require processing, then the application engine  proceeds to step . If not, then the application engine  () moves to the next or calling section of data. In step , the application engine  determines whether the current section of data is to be processed. If the current section of data is to be processed, then the application engine  proceeds to the logic flow path described in . If not, then a mass change SQL statement is generated in COBOL in step , the changes are recorded in a library within SQL module  (), and the application engine returns to step  to determine whether more steps or entities require processing within the current section of data.","In  the application engine  performs a series of evaluations to identify and process specific data fields. The goal of the application engine  logic is to determine a rowset from a data table is delivered in response to several logic control loops which are performed by the application engine . The application engine  filters data from a database and a database management system in response to SQL statements, conditions, and values sought by a particular user's query. In step , the application engine  determines whether a series of SQL statements should be applied during the application engine program flow. SQL statements are numeric expressions which evaluate one value against another value, range, or alternative in order to determine a specific data field, table, rowset, etc. The specific data field, table, rowset or record is returned based upon the resulting evaluation of the SQL statement. Examples of \u201cdo when,\u201d \u201cdo while,\u201d \u201cdo select,\u201d and \u201cdo until\u201d are shown in , but the present invention is not limited to those statements illustrated herein.","Application engine  determines in step  whether a \u201cdo when\u201d SQL statement exists. If yes, then the application engine  evaluates the called section of data using the \u201cdo when\u201d SQL statement in step , which ultimately returns or \u201cselects\u201d a data result based upon the evaluation. In step , the application engine  determines whether a rowset has been returned as a result of the application engine  evaluating the \u201cdo when\u201d statement. If no rowset is returned, then the application engine returns to step  in . If a rowset is returned or if no \u201cdo when\u201d SQL statement is present, then the application engine  continues to step  to determine whether a \u201cdo while\u201d statement exists. Again, if a \u201cdo while\u201d statement does not exist, then the application engine  will continue to determine whether a \u201cdo select\u201d or a \u201cdo until\u201d SQL statement exists, as described below.","In step , the application engine  performs a similar evaluation to determine a specific result using a \u201cdo while\u201d SQL statement. In step , if a \u201cdo while\u201d SQL statement is present, then the application engine  evaluates the \u201cdo while\u201d SQL statement in step  to determine a specific rowset, which is returned in step . If a \u201cdo while\u201d SQL statement is not present, then the application engine  will determine whether a \u201cdo select\u201d SQL statement exists in step .","Referring back to step , if no rowset is returned as a result of the evaluation of the \u201cdo while\u201d SQL statement, then the application engine  returns to step  in . However, if a row is returned, then the application engine  determines whether the resulting rowset is returned for the first time in step . Referring back to step , if a \u201cdo select\u201d SQL statement exists, then the application engine then determines whether \u201cstep\u201d and \u201cfetch\u201d SQL statements are present in step . If \u201cstep\u201d and \u201cfetch\u201d SQL statements are not present, then the application engine  applies the \u201cdo select\u201d SQL statement to the current section of data. If a \u201cstep\u201d and \u201cfetch\u201d SQL statement are not present, then the application engine  determines whether the rowset returned from step  has been returned a first time. If a rowset is returned from the \u201cdo while\u201d SQL statement but is not returned for the first time (step ), then the application engine  proceeds to step  to perform a fetch SQL statement based upon one or more default values and rules. If a rowset is returned for the first time from the \u201cdo while\u201d SQL statement, then the application engine  proceeds to step  issues an \u201copen cursor\u201d statement which generates the returned rowset from a database. Subsequently, the next returned rowset is also generated when the application engine  issues a \u201cfetch row\u201d statement in step . After executing the \u201cfetch row\u201d statement, the application engine  determines again whether a row is returned. If a row is returned, then the application engine  proceeds to  to evaluate a further sequence of SQL statements. If a row is returned, then the application engine  returns to step  () to evaluate the next called section of data.",{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIG. 5C","FIG. 1"],"b":["136","136","538","136","540","136","136","542","136","540","136","544"]},"In step , the application engine  performs the process of selecting a rowset. In step , the application engine  determines whether a row is returned from the process of step . If a rowset is returned, then the application engine returns to step  () to evaluate the next called section of data. If no rowset is returned, then the application engine returns to step  () to determine whether a \u201cdo while\u201d SQL statement exists. The application engine  and its logic flow procedure represent the environment within which embodiments of the present invention operate. In other words, the automatic data mapping system and method operates within the context of the overall logic of the application engine . However,  represents a generic context for illustrating the logic flow of the application engine . The automatic mapping logic flow is integrated with the application engine logic flow in order to generate the necessary field maps, as described in further detail with regard to .",{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 6","b":"600"},"There are five general steps in automatic data mapping, in accordance with an embodiment of the present invention:","1. Apply map rules. The map rule definition captures required transformations, defaults, translation sets, field map hints and applies these rules based on target field;","2. Match the source and target fieldname from an ETL control field list;","3. Apply default data values from Set Target Defaults;","4. Map the remaining target fields without any source input field from the target with specified field constant default values which are contained within specific data tables, fields, records, etc. (e.g., an example of a specific field where a default data value SQL statement may be: PSRECFIELD.DEFFIELDNAME. (SELECT DEFFIELDNAME FROM PSRECFIELD WHERE DEFRECNAME =\u2033 AND B.DEFFIELDNAME <>\u2032)); and","5. In the background, the automatic data mapping engine  will resolve any record structure, changes, data type conversions, truncate row data where the source field length is greater than the target field length, and default any remaining target fields without source input null values with the following null alias:","a. Character\u2033 (space) for character field","b. Numeral 0 for numeric field","c. Literal Null for date field","In the process shown, the automatic data mapping engine  initializes a field map in step , referencing any pre-determined fields needed for processing. Examples of pre-determined fields needed for processing include indications for rows in error, duplicates, etc. At step , the automatic data mapping engine determines whether the automatic data mapping process  has been previously run. If the automatic data mapping process  has been previously run, then the automatic data mapping engine  performs a run-time adjust in step . During this step, the automatic data mapping engine  determines whether any source and\/or target data objects have been changed since the last field map was generated. For example, if a target table has had a field added, then the automatic data mapping engine  will provide a value for the added field, based on required or optional rules, previous field maps, or required or optional defaults.","If the automatic data mapping process  has not been previously run or after performing a run-time adjust, the automatic data mapping engine  then applies required map rules (step ), required defaults (step ), and map definition (step ). Examples of required rules include source-to-target mapping (e.g., map Field A to Field B), transformations (e.g., concatenate Fields A and B; truncate Field A), or translations (e.g., if Field A is observed, assign Field C to the target data object or field) which are defined previously, but applied during the design-time generation of field maps.","An example of a required map rule is where Field A is observed, the automatic data mapping engine  maps Field A to Field B, thus overriding all other rules and default values.","An example of a required default is where Field A is observed by the automatic data mapping engine , then a default value of \u201c10\u201d is inserted in every unassigned Field A. A specific example may be an accounting application which uses a set of default values, specified by a user, to describe accounting-related data, e.g., transaction type, transaction amount, transaction date. However, required default values do not override required rules, but do override optional rules and optional default values.","In step , applying the map definition refers to the assignment of a source data object to a target data object, thus defining a field map. Pre-existing field maps, if any, are also applied during this step. In step , the automatic data mapping engine  determines whether all target data objects have been assigned a value from a source data object. If all target objects are assigned, then the automatic data mapping engine  proceeds to step  to apply any background processing. If instead all target data objects still do not have a source data object assigned, then the automatic data mapping engine  will apply optional rules (step ) and optional default values (step ), if any. Examples of optional rules and default values are similar to those described above for required rules and defaults. However, optional rules and default values do not override required rules and values. Further, if there are not optional rules or default values, then the automatic data mapping engine  will simply apply background processing in step .","As described above, in general, background processing provides for instances where target data objects remain unassigned or without values. Where neither required nor optional rules and default values provide assigned values to target data objects, the automatic data mapping engine  will assign a null, void, or blank value. These null values may include \u201c0\u201d, \u201c-,\u201d a blank space, or any other value which a person of ordinary skill in the art may envision.","After completing the application of background processing, the automatic data mapping engine  will perform field conversion, thus defining one or more field maps in step . Following the field map definition in step , a user may intervene to stop the automatic data mapping engine  in step , thus ending the process (in step ). However, if the user does not intervene to stop the run-time execution of the automatic data mapping engine , this process will continue by returning to step  from step . Ultimately, the automatic data mapping process repeats until a \u201cdo\u201d control loop in the application engine  environment is fulfilled which stops the process, a user intervention occurs.","An exemplary processing scenario using the automatic data mapping engine  may be described as follows. A new date\/time field is to be added to each record in a particular section of data within a database. Under the conventional techniques and methods available, a map developer or user would be required to manually input the new date\/time field. In accordance with an embodiment of the present invention, a new required rule can be entered to direct the addition of the new field. Specifically, the new required rule can specify a transformation rule whereby a new field \u201cdate\/time\u201d is added which represents the concatenation of the individual fields \u201cdate\u201d and \u201ctime.\u201d At run-time, the automatic data mapping engine  initializes looking for changes to the existing source and target data objects. As a change has occurred, the automatic data mapping engine  performs a run-time adjust to search for the changes. Once the change (a new required rule for a new \u201cdate\/time\u201d field), the automatic data mapping engine applies any required rules and\/or any required defaults, performs an intermediate determination as to whether all target data objects or fields have been assigned and, if so, conducts background processing prior to defining and generating field maps. If all target data objects have not been assigned a source data object, then the automatic data mapping engine  applies any optional rules and\/or defaults. If unassigned target data objects remains, the automatic data mapping engine  assigns null values to the unassigned target data objects. A person of ordinary skill in the art may direct the assignment of any type of null value as she may envision.","The automatic data mapping engine  and automatic mapping process described herein eliminates the labor, time and expense-intensive nature of setting up and maintaining map and map metadata. Maintenance requirements for field maps are greatly reduced by embodiments of the present invention as the automatic nature of run-time adjustments provides for any changes that occur in the source or target data objects after a field map\/field conversion process is run. Conventionally, users must manually correct for changes, errors, duplications, modifications, etc. in order to generate and load data or field maps. Due to the manual efforts involved, a user will only discover a faulty map after it has been loaded, compiled, and run. In an embodiment of the present invention, an incorrect or obsolete field map is corrected during the run-time execution of the application engine .","The automatic data mapping engine  can generate ETL\/data transformer maps based on the source and target object definition along with pre-defined rules to streamline exception handling. In one embodiment of the present invention, the automatic data mapping engine  may be integrated with the ETL engine run-time compiler  (), which can generate required SQL steps and save them to a library. The automatic data mapping engine  provides the user with the ability to automatically map a target field based on an identified source field, default value, and pre-specified rule. The name of the source and target fields or objects is the minimum amount of information required to run the automatic data mapping engine  as the names identify which target fields are to be matched to particular source fields. However, an exemplary data table showing examples of fields that can be evaluated by an embodiment of the present invention is show in .",{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 7","b":["702","708"]},"The automatic data mapping engine  also provides for the automatic generation of field maps as well as the ETL functions to implement the field maps for immediate use. In an embodiment of the present invention, field maps can be defined and generated based on the contents of the source and target objects, the database platform, an ETL map, user-defined rules and data conversion, and basic default values. However, in accordance with an embodiment of the present invention, field maps generated by automatic data mapping engine  can be overridden by ETL map definition. Working in conjunction with the automatic data mapping engine , the application engine  () will resolve any record structure, changes, data type conversions, truncate row data where the source field length is greater than the target field length, and default any remaining target fields without source input null values with the following null alias:","a. Character\u2033 (space) for character field","b. Numeral 0 for numeric field","c. Literal Null for date field","Alternatively, in some embodiments, each field on a target field or object is handled using the following four steps:\n\n","The above four steps define, in sum, the four basic types of rules and default values which can be applied in either a \u201crequired\u201d or \u201coptional\u201d state. In steps 3 and 4 of the alternative logic flow embodiment above, defaults can be defined as either record level or system level defaults. These default values guide the logic flow process to ultimately enable automatic data mapping.","The novel and inherent improvements over the elimination of onerous conventional techniques for establishing data maps is overcome by embodiments of the present invention, as described herein and further imagined by one of ordinary skill in the art, given the above-description.","The above description is illustrative and not restrictive. Many variations of the invention will become apparent to those of skill in the art upon review of this disclosure. For examples, the steps described in the above flow charts may be performed in a different order or not all steps may be performed. The scope of the invention should, therefore, be determined not with reference to the above description, but instead should be determined with reference to the appended claims along with their full scope of equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 5C"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
