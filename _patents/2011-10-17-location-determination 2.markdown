---
title: Location determination
abstract: Techniques for determining a location of a device include estimating a mobility trace of the device, mapping the mobility trace to a map, and determining the location of the device based on the mapped mobility trace. The mobility trace may be estimated based on a reading obtained from the device, which may be a reading from an accelerometer and/or magnetometer sensor. The determined location of the device may correspond to a location on the mapped mobility trace.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09568323&OS=09568323&RS=09568323
owner: Microsoft Technology Licensing, LLC
number: 09568323
owner_city: Redmond
owner_country: US
publication_date: 20111017
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION","CONCLUSION"],"p":["Many localization services determine a geographic location of a mobile device by utilizing a global positioning system (GPS), cellular-based localization techniques, and\/or wireless access point-based localization techniques. When utilizing GPS, the mobile device receives information from one or more satellites and determines the location based on the received information. When utilizing cellular-based or wireless access point-based techniques, the mobile device receives identification information from one or more communication points (e.g., a cellular base station, Wi-Fi\u00ae access point, or Bluetooth\u00ae access point), and queries an online service with the identification information to resolve the location.","These approaches suffer from low energy efficiency, long startups delays, low location accuracy, and\/or coverage dependency, which adversely affect the localization services and mobile device. For example, GPS suffers from long startup delays, due to a time required to connect with satellites, and consumes a significant amount of energy, which may lead to untimely location information and inefficient use of battery life of the mobile device. GPS also suffers from providing inaccurate location information when the mobile device is in proximity to buildings, commonly referred to as \u201cthe canyon effect.\u201d","Meanwhile, cellular-based and wireless access point-based localization techniques are coverage dependent and provide low location accuracy, which may lead to unreliable and inaccurate location information. In addition, cellular-based and wireless access point-based localization techniques consume a significant amount of energy to communicate with an online service to resolve the location. These techniques may also provide delayed location information when a network (e.g., cellular network, wireless network, etc.) exhibits poor communication conditions.","There is an increasing opportunity to determine a location of a mobile device in an energy efficient, accurate, and timely manner.","This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.","This disclosure is related, in part, to estimating a mobility trace of a device based on a reading obtained from a sensor of the device. The sensor may be, for example, an accelerometer and\/or magnetometer sensor. The estimating may include estimating the mobility trace based on a determined motion state of the device. The motion state may be a driving, cycling, walking, or running state, for example, and may be determined through motion state detection.","This disclosure is also related, in part, to mapping a mobility trace to a map. The mapping may include selecting a map based on a determined motion state, and fixing the mobility trace to the selected map based on cell tower data and\/or wireless access point data. The cell tower data and\/or wireless access point data may be obtained by the device at a location on the mobility trace. The fixing may include utilizing Viterbi decoding based on a Hidden Markov Model to determine a sequence of segments that the device traveled. The sequence of segments may include segments from the selected map.","This disclosure is also related, in part, to determining a location of a device based on a mapped mobility trace. The determining may include performing interpolation or extrapolation to determine the location of the device. The performing interpolation or extrapolation may be based on a plurality of segments of the mapped mobility trace and a speed of the device on at least one of the plurality of segments. Interpolation may be performed when a time included in a location query is determined to be within a time duration of a closed-ended segment. The closed-ended segment may be a segment from the plurality of segments of the mapped mobility trace. Extrapolation may be performed when the time included in the location query is determined to be within a time duration of an open-ended segment. The open-ended segment may be a segment from the plurality of segments of the mapped mobility trace.","As discussed above, many localization services determine a location of a mobile device through GPS, cellular-based localization techniques, and\/or wireless access point-based localization techniques, which suffer from various disadvantages providing adverse effects to the localization services and mobile device.","This disclosure describes techniques that, among other things, determine a location of a device (e.g., a mobile device) in an energy efficient, location accurate, and timely manner.","Aspects of this disclosure are directed to estimating a mobility trace of a device based on a reading obtained from a sensor of the device. The reading may be obtained from an accelerometer and\/or magnetometer sensor of the device and may indicate an acceleration and\/or direction of the device. In one example, the reading from the sensor may be obtained without obtaining data from GPS, cellular-based localization techniques, and\/or wireless access point-based localization techniques. The estimating may be based on a motion state of the device determined through motion state detection. In one embodiment, the motion state may be a driving, cycling, walking, or running state. In other embodiments, the motion state may include these and\/or other motion states (e.g., skipping, strolling, riding a scooter or segway, etc.).","Aspects of this disclosure are also directed to mapping the mobility trace to a map. The mapping may include selecting a map based on a determined motion state, and fixing the mobility trace to the selected map based on cell tower data and\/or wireless access point data. The cell tower data and\/or wireless access point data may be obtained by the device, at a location on the mobility trace, from a communication point (e.g., a cell tower or wireless access point). Meanwhile, the fixing may include utilizing Viterbi decoding based on a Hidden Markov Model to determine a sequence of segments that the device traveled (e.g., a sequence of road segments).","Aspects of this disclosure are also directed to determining a location of a device based on the mapped mobility trace. The determining may include performing interpolation or extrapolation to determine the location of the device. The performing interpolation or extrapolation may be based on a plurality of segments of the mapped mobility trace and a speed of the device on at least one of the plurality of segments. The interpolation and\/or extrapolation may be performed after receiving a location query. The location query may be a query requesting the device to determine the location of the device at a particular time (e.g., a current or past time).","In one example, interpolation is performed when the time included in the location query is determined to be within a time duration of a closed-ended segment. The closed-ended segment may be a segment from the plurality of segments of the mapped mobility trace. The time duration of the closed-ended segment may indicate a traveling duration of the device on the closed-ended segment. Meanwhile, extrapolation may be performed when the time included in the location query is determined to be within a time duration of an open-ended segment. The open-ended segment may be a segment from the plurality of segments of the mapped mobility trace.","The techniques described below may allow a location of a device to be determined in an energy efficient, location accurate, and timely manner. For example, by utilizing readings from energy efficient sensors (e.g., an accelerometer and\/or magnetometer), the device may consume less energy than GPS, cellular, or wireless access point based localization techniques. In addition, by utilizing readings from sensors (e.g., accelerometer and\/or magnetometer) which are located on the device, the device consumes less energy than localization techniques that require significant amounts of communication power, such as GPS, cellular, and wireless access point based localization techniques. Furthermore, by utilizing sensors located on the device and information which may be previously stored on the device (e.g., a map and cell tower coverage information), the device may determine a location of the device even when a GPS, cellular, or wireless signal becomes weak or non-existent. Moreover, by utilizing cell tower data and\/or wireless access point data, which may be utilized periodically, a mobility trace may be accurately mapped to a map in an energy efficient manner.","The sections below are examples provided for the reader's convenience and are not intended to limit the scope of the claims, nor the proceeding sections. Furthermore, the techniques described in detail below may be implemented in a number of ways and in a number of contexts. One example implementation and context is provided with reference to the following figures, as described below in more detail. However, the following implementation and context is but one of many.","Illustrative Architecture",{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 1","b":["100","102","104","106","108","102","104","102"]},"In architecture , device  may include any combination of hardware and\/or software resources configured to process data. Device  may be implemented as any number of devices, including, for example, a personal computer, a laptop computer, a cell phone, a tablet device, a personal digital assistant (PDA), etc. Device  may be equipped with a processor(s)  and memory . Device  may also be equipped with a sensor(s)  and a global positioning system, such as GPS . Sensor  may include an accelerometer, a magnetometer, and\/or another motion-based or magnetic-based sensor.","Memory  may include an application programming interface, such as API . Memory may be configured to store applications and data. An application, such as localization module , running on device  performs operations for determining a location of a device. Localization module  may include a mobility trace estimation module , a motion state detection module , and a mapping module . Modules -, running on device , perform operations for mobility trace estimation, motion state detection, and mapping described herein.","Device  may also include other software, hardware, or combinations thereof, to perform GPS, cellular, and\/or wireless access point based localization operation(s) to determine a location of device . These operation(s) may provide the location in a geo-location form (i.e., longitude and latitude), address form, or any other suitable location format, and may include time and date information. These operation(s) may also include reporting the location of device  to a location service, such as location service .","Although memory  is depicted in  as a single unit, memory  may include one or a combination of computer readable media. Computer readable media may include computer storage media and\/or communication media. Computer storage media includes volatile and non-volatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules, or other data. Computer storage media includes, but is not limited to, phase change memory (PRAM), static random-access memory (SRAM), dynamic random-access memory (DRAM), other types of random-access memory (RAM), read-only memory (ROM), electrically erasable programmable read-only memory (EEPROM), flash memory or other memory technology, compact disk read-only memory (CD-ROM), digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other non-transmission medium that can be used to store information for access by a computing device.","In contrast, communication media may embody computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave, or other transmission mechanism. As defined herein, computer storage media does not include communication media.","Architecture  also includes communication point(s) , such as a cell tower(s) (i.e., cell base station), a wireless access point(s), or similar communication point configured to communicate with a device. Communication point(s)  may be implemented as appropriate in hardware and include software components. While techniques described herein are illustrated with reference to cell towers and wireless access points, these techniques may additionally or alternatively apply to any other type of communication point enabling communication with a device (e.g., any type of RF-based communication point).","Meanwhile, architecture  also includes network(s)  and location service(s) . Network(s)  may include any one or combination of multiple different types of networks, such as cellular networks, wireless networks, local area networks, and the Internet. Location service(s)  may include any combination of hardware and software configured to process data. Location service(s)  may be implemented on one or more computing devices including, for example, a server, a personal computer, or a laptop computer. In one example, location service(s)  is hosted on one or more servers in a data center or cloud computing environment.","The one or more computing devices implementing location services(s)  may be equipped with a processor(s) , memory , and a network interface(s) . Memory  may include one or a combination of computer readable media. Memory  may be configured to store applications and data. An application, such as a location service module , running on the one or more computing devices, performs operations for a location service.","As an overview, location service(s)  may monitor a location of a device(s) and perform operations based on the monitored location. Location service(s)  may include, for example, navigation, tracking, tracing, location-based gaming, proximity reminder services, or any other location-based service utilizing location information of a device. During implementation, location service(s)  may receive a location(s) of one or more devices, store the location(s), and send location-based information to the one or more devices.","Illustrative Motion State Detection","The following section describes techniques directed to performing motion state detection to determine a motion state of a device.","In one aspect of this disclosure, a device performs motion state detection to determine a motion state of the device. Here, the device may determine that the motion state is a still or moving state. In addition, or alternatively, the motion state may be a subset of the still or moving state, such as a moving state of driving, cycling, walking, or running. The motion state may also be defined based on a location of the device on a user, such as a location of device  on user . For example, the location may be an upper body (u), hip pocket (h), or pant pocket (p) location.","In one implementation, the device determines the motion state of the device based on features extracted from a magnitude of acceleration. The magnitude of acceleration may be obtained from an accelerometer of the device. Here, the device may determine the motion state by utilizing a decision tree (DT) with thresholds previously defined. Some of the extracted features may include, for example, standard deviation of magnitude, spectrum shape index, sprout frequency, trough imbalance degree, and sprout and trough asymmetry to be described in further detail below.","The standard deviation of magnitude may be utilized to classify a motion state of the device, for example, into one of three states, such as S1: {absolute still}, S2: {quasi-still, driving, cycling(u, h)}, and S3: {walking(u, h, p), cycling(p)}. Here, the device may utilize two thresholds \u03c3and \u03c3. \u03c3may be set to a conservative small value to allow a high confidence when determining a state as absolute still. \u03c3may be set to a larger value to allow a high confidence when determining a state such as those in S3. In one example, state S1 is determined when the standard deviation of magnitude is less than \u03c3, state S2 is determined when the standard deviation of magnitude is greater than \u03c3and less than \u03c3, and state S3 is determined when the standard deviation of magnitude is greater than \u03c3. In one implementation, \u03c3and \u03c3are set to 0.2 and 2.0, respectively.","The spectrum shape index may be utilized to further classify the motion state of S2, for example, into one of two states, such as S21: {cycling(u, h)} and S22: {driving, quasi-still}. The spectrum shape index may be defined as a ratio of maximal FFT coefficient value to an average value. The spectrum shape index may be utilized to separate a signal with more periodicity from a signal with less periodicity. In one example, in a signal with more periodicity, an energy distribution is more concentrated as compared to a signal with less periodicity. The FFT may be applied on a horizontal component of the acceleration.","The sprout frequency may be utilized to further classify the state of \u201cquasi-still\u201d in S22, for example, into one of two states, such as casual-still and driving-waiting. Casual-still may refer to a state where the device is still with infrequent casual motion, such as sitting or standing still. Driving-waiting may refer to a state where the device is driving and not moving, such as when the device is stopped at a traffic light.","The sprout frequency may be defined as a number of sprouts in a detection window. The sprout frequency is a temporal domain feature which may be calculated by counting the occurrences of sprouts. In one implementation, an acceleration signal is first mean removed. Thereafter, a magnitude of acceleration that exceeds a sprout threshold, such as \u03b4, may be marked as a sprout candidate. Consecutive sprout candidates may then be merged and counted as one sprout. A threshold \u03c3may then be utilized to differentiate casual-still from driving. For example, when a number of sprouts, or merged sprouts, in a detection window does not exceed the threshold \u03c3, the device may be determined to be in a casual-still state. Alternatively, when the number of sprouts, or merged sprouts, in the detection window exceeds threshold \u03c3, the device may be determined to be in a driving state. This approach may consider an observation that causal movement of a device may cause only occasional sprouts, while typical road conditions may cause frequent sprouts.","Thereafter, a threshold \u03c3may be utilized to determine whether the classified driving state is a driving-moving or driving-waiting state. For example, when a magnitude of a sprout, or a merged sprout, is greater than \u03c3, the device may be determined to be in a driving-moving state. Alternatively, when the magnitude of the sprout, or merged sprout, is less than \u03c3, the device may be determined to be in a driving-waiting state. Threshold \u03c3may consider an observation that in a driving-waiting state, the vehicle engine may be the only vibration source, which may be significantly attenuated.","Meanwhile, in one example, the magnitude of acceleration is utilized to further classify the motion states of S3, which may account for changes in an orientation of the device.  illustrate differences between magnitudes of acceleration for walking and cycling and will be described in further detail hereafter.","In one implementation, the trough imbalance degree is utilized to further classify motion state S3, for example, into one of two states, such as S31: {walking (h, p)} and S32: {walking(u), cycling(p)}. The trough imbalance may be defined as a ratio between two neighboring trough depths. Meanwhile, a trough depth may be defined as a difference between an average and a minimum magnitude of acceleration in a trough, and a trough may be defined as an area under an average magnitude of acceleration line. In one example, when the trough imbalance degree is smaller than one, the reciprocal is taken.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIGS. 2A-2B","FIGS. 2A-2B","FIG. 2A","FIG. 2B","FIGS. 2A-2B"],"sup":"2 "},"In one example, when the trough imbalance degree is greater than a threshold, the device may determine that the motion state is S31, and when the trough imbalance degree is not greater than the threshold, the device may determine that the motion state is S32. Here, the trough imbalance degree may indicate a location of the device. For example, when the device is located in a pant or hip pocket, the trough imbalance may be greater than when the device is located in another location. When the device is located in another location the trough imbalance may be close to one.",{"@attributes":{"id":"p-0051","num":"0050"},"figref":["FIGS. 3A-3B","FIG. 3A","FIG. 3B","FIG. 3A"],"b":["1","2"]},"Meanwhile, the device may utilize the sprout and trough asymmetry to classify the motion state S32 into walking(u) or cycling(p). The sprout and trough asymmetry may be defined as a ratio between a trough depth and a sprout height. In one implementation, when the sprout and trough asymmetry is greater than a threshold, the device may determine that the motion state is the cycling(p) state, and when the sprout and trough asymmetry is not greater than the threshold, the device may determine that that motion state is the walking(u) state.","As illustrated in , for cycling(p), the device has large magnitude of acceleration changes when the thigh moves around the hip, and small magnitude of acceleration changes when the lower leg moves around the knee (i.e., in the lower half of a pedaling circle). Accordingly, the magnitude of acceleration may be asymmetric during cycling.","In one implementation, the device may sample an accelerometer of the device at 25 Hz, and all samples may be preprocessed by taking an average over four nearby samples. In this implementation, state detection may be performed every second over a four-second running detection window. After a rough classification is obtained utilizing the classifier and a decision tree, a second pass may be applied to remove misclassifications. In the second pass, the device may consider 1) the motion state's continuity (e.g., high unlikelihood of entering a still state during a fast driving state), 2) the motion state's transition possibility (e.g., high unlikelihood of changing to a cycling state immediately after a driving state), and 3) penalty of an incorrect detection (e.g., higher penalty for detecting a still state as a driving state than for detecting a driving state as a still state). In one implementation, when there are sporadic different states among a sequence of detected states, those sporadic different states are corrected in view of the first consideration, such that a sporadic different state is changed to the same state as a detected state immediately before or after the sporadic different state. Meanwhile, if those different states are not sporadic, but continuous for a short period, then the different states are determined to be incorrect detected states if the transition possibility between the two states is low. Here, the incorrect detected states may be removed in view of the second consideration.","Although this section describes various motion state detection techniques, in some embodiments conventional motion state techniques may also be utilized to determine a motion state of a device. These techniques may generally include obtaining one or more readings from a motion sensor of the device, such as an accelerometer and\/or magnetometer, and determining the motion state based on the one or more readings.","Meanwhile, the device may perform motion state detection until a condition is satisfied. For example, the device may perform motion state detection until a moving state is determined. When the moving state is determined the device may estimate a mobility trace of the device utilizing the techniques described hereafter.","Alternatively, or in addition, the device may periodically obtain sensor readings from a sensor of the device (e.g., an accelerometer and\/or magnetometer) based on a first period of time. Here, the device may also perform motion state detection and\/or estimate a mobility trace of the device periodically based on a second period of time, where the second period of time is longer than the first period of time.","Illustrative Mobility Trace Estimation","The following section describes techniques directed to estimating a mobility trace of a device. The mobility trace may be estimated after it is determined that the motion state of the device is a moving state.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIG. 4","FIG. 4"],"b":"1"},"In one aspect of this disclosure, the mobility trace is estimated based on one or more readings obtained from a sensor of the device, such as an accelerometer and\/or magnetometer. The one or more readings may generally indicate an acceleration of the device and\/or a direction the device is traveling.","Meanwhile, a determined motion state of a device may determine the techniques utilized to estimate a mobility trace. For example, when the device is determined to be in a driving state the device may estimate the mobility trace through driving techniques, and when the device is determined to be in a cycling state, the device may estimate the mobility trace through cycling techniques.","(A) Illustrative Mobility Trace Estimation in a Driving State","Aspects of this disclosure are directed to estimating a mobility trace based on a heading vector and\/or orientation vector. The heading vector may be based on one or more readings from an accelerometer of the device, and the orientation vector may be based on one or more readings from a magnetometer of the device. The heading vector and\/or orientation vector may be utilized when the device is determined to be in a driving motion state.","In one implementation, a mobility trace of a device is estimated in a 3-D Global Cartesian coordinate system (G) with acceleration readings obtained from a 3-D Cartesian coordinate system (M). This approach may allow a device to estimate a mobility trace of the device with respect to a vehicle where the device is located. Here, the device is in the coordinate system M, whereas the vehicle is in the coordinate system G. Meanwhile, an acceleration reading obtained from a sensor of the device (e.g., an accelerometer) is also in the coordinate system M, because the sensor is located on the device. Accordingly, in order to obtain a mobility trace in G from acceleration readings in M in this implementation, the mobility trace is estimated by utilizing a heading vector.","The heading vector may refer to an actual acceleration of the vehicle that occurs in G. For example, as the vehicle is traveling along a road segment the vehicle may experience an acceleration which may be represented as the heading vector along the road segment.","Thereafter, the heading vector may be utilized to estimate a speed, distance, and direction associated with the mobility trace. For example, the device may estimate the speed of the device at a location on the mobility trace through integration of an acceleration along the heading vector, and may estimate the distance of a segment of the mobility trace through double integration of the acceleration along the heading vector. Meanwhile, the direction of the device at a location on the mobility trace may be estimated based on an angle between the heading vector and an orientation vector to be described hereafter.","In one example, the heading vector is obtained as {right arrow over (h)}={right arrow over (a)}\u2032\u2212{right arrow over (a)}, where {right arrow over (h)} represents the heading vector and {right arrow over (a)}\u2032 and {right arrow over (a)} represent two acceleration readings. These two accelerations may be two readings obtained from an accelerometer of the device, where there is no orientation change of the device between the two readings. In one example, the two readings may be obtained when the device is positioned in any orientation, as long as the orientation remains constant between obtaining the two readings. Detection of the orientation of the device will be discussed hereafter.","In one implementation, processing is performed on an acceleration reading before it is utilized to estimate a heading vector. For example, a two step process may be performed on the acceleration reading, which may be a noisy raw signal. In a first step, the device may apply median filtering to accelerometer readings sampled at 25 Hz, which may remove accidental spikes in the accelerometer readings. The filtered accelerometer readings may be utilized in obtaining the heading vector. In a second step, the device may calculate a mean acceleration from acceleration readings obtained over a two-second running window, and utilize the mean acceleration for obtaining the heading vector. In one example, the two-second running window represents a window set based on empirical data from experimental driving experiences.","Meanwhile, the device may obtain a heading vector at a time when a strong acceleration or deceleration is determined. For example, the device may determine the strong acceleration or deceleration when one or more acceleration readings are greater than a threshold, and obtain the heading vector in response to the determination. The device may alternatively, or in addition, determine a strong acceleration or deceleration based on average acceleration readings. For example, the device may utilize average acceleration readings in a previous period (e.g., a previous 60 seconds) as rough gravity and obtain a rough horizontal plane based on the rough gravity. The average acceleration readings may exclude portions of large variance in magnitude of acceleration. Thereafter, the device may project an acceleration reading onto the rough horizontal plane and identify a strong acceleration or deceleration as a large acceleration change on the rough horizontal plane. These techniques may allow the device to obtain a reliable heading vector.","The device may also obtain a more reliable heading vector based on a bi-direction search of an extended window around strong acceleration or deceleration points. Here, the device may extend the window to a longer period than the window was previously set, and perform a bi-direction search to identify the most stable acceleration reading(s) within the extended window. The average acceleration within the extended window is then obtained. This operation may be applied both before and after the strong acceleration or deceleration. The heading vector may then be obtained from the resulting more stable acceleration readings.","In one implementation, the heading vector includes one or more properties that may be useful to calibrate the heading vector. For example, the heading vector may always be orthogonal to a gravity in M for an arbitrary motion in a horizontal plane, as long as there is no orientation change between two accelerometer readings. This property may indicate that if a device is moving horizontally, then the heading vector may always be orthogonal to the gravity (also expressed in M). Here, when the device identifies chances of reliable gravity estimation, the device may fine tune a possible imperfect heading vector so as to remove the impact of gravity on the heading vector.","In another property, the heading vector may always be orthogonal to a centripetal acceleration in M when turning on a horizontal plane, as long as there is no orientation change between two accelerometer readings. This property may indicate that when a device is moving along a straight road segment (which may be identified via stable magnetometer readings), the centripetal component may be around zero, and when the device is moving along a road segment having a turn, there may be a transient surge in the centripetal acceleration, with positive and negative surges corresponding to right and left turns, respectively.","Aspects of this disclosure are also directed to estimating a distance and speed of a device based on a heading vector. Here, given a heading vector {right arrow over (h)} and for any acceleration {right arrow over (a)}, the device may calculate the acceleration component along the heading vector {right arrow over (a)}as:\n\n\n\nwhere {right arrow over (h)}is the normalization of {right arrow over (h)}. Here, {right arrow over (a)}contributes to a movement of a vehicle along a road. With {right arrow over (a)}, the speed and distance of the device may be estimated through integration and double integration of {right arrow over (a)}, respectively.\n","In one example, the device may utilize acceleration error mitigation techniques to address any exaggerated inaccurate acceleration readings. This may allow the device to account for double integration which may exaggerate the effect of an inaccurate acceleration reading, such as drift or initial error, especially when integrating over a long time interval.","In one implementation, the acceleration error mitigation techniques may include utilizing mean removal which may remove mean acceleration noise from all accelerometer readings of an entire integration interval. This approach considers that when a device starts from a still state, a speed obtained via integration of acceleration may be zero when the device comes to a next still state. In other words, any non-zero final speed must be caused by noises in acceleration.","Alternatively, or in addition, the acceleration error mitigation techniques may include utilizing the following process. First, when the device observes strong acceleration changes, the device may repeatedly obtain a heading vector. This may be performed even when an orientation change of the device is detected. Second, when long stable motion segments (e.g., still state of a device at a traffic light or constant speed at cruising) are identified, the device may utilize average accelerometer readings as gravity (still in M) and re-calibrate a previous heading vector through orthogonality. This may prevent gradual or slight orientation changes during movement of the device, especially after turning.","Third, the device may utilize a weighted moving average to account for a heading vector that may vary slightly around a real heading vector that the device desires to find. Here, the weighted moving average may balance an impact of previous heading vectors and a current detection. The weighted moving average may be defined by:\n\n+(1)\u00b7\u2032\n\nwhere {right arrow over (h)}\u2032 is a determined heading vector, {right arrow over (h)}is a newly detected heading vector, and w is a weight. Fourth, when a calculated velocity is negative while the vehicle is still in a driving state, the device may slightly adjust the heading vector such that the calculated velocity is positive. Similarly, the device may adjust the heading vector when a velocity above a threshold is detected (e.g., a high calculated velocity).\n","Meanwhile, the device may also estimate a direction of travel of the device. The device may estimate the direction based on an angle between the heading vector and an orientation vector ({right arrow over (d)}) obtained from a magnetometer of the device. For example, the device may calculate the angle in two steps: 1) project {right arrow over (d)} to a horizontal plane and obtain a horizontal component {right arrow over (d)}from:\n\n\n\nwhere {right arrow over (a)}is a normalized vertical acceleration of {right arrow over (a)}obtained via {right arrow over (a)}={right arrow over (a)}\u2212{right arrow over (a)}; and 2) calculate the angle \u03b8 from:\n\n\u03b8=arccos().\n\nThis angle \u03b8 may correspond to the direction of travel of the device at a location on the mobility trace. Here, the orientation vector {right arrow over (d)} may be filtered through a median filtering to remove transient large orientation changes.\n","This two step approach for calculating the angle may account for an alignment of a coordinate system with respect to the magnetometer and a coordinate system with respect to the accelerometer (i.e., M). For example, because the magnetometer and accelerometer are fixed to the same device, the Cartesian coordinate system with respect to the magnetometer and the Cartesian coordinate system with respect to the accelerometer may have a fixed geometry mapping (e.g., through a Euler transform matrix W). The Wmay be obtained via a calibration process, which may only need to be performed once. In one example, the two coordinate systems are aligned, i.e., W=I.","With an estimated direction, the device may determine a strong accelerometry change to be an acceleration or deceleration. In one example, the device may determine the strong accelerometry change when the change is greater than a threshold. In this example, the device may assume motion continuity of a vehicle where the device is located, i.e., the vehicle does not make abrupt 180-degree turns. The motion continuity may indicate a continuity of direction of the device and vehicle. Here, the device may determine an acceleration when the angle \u03b8 is small (i.e., close to or at zero degrees), and the device may determine a deceleration when the angle \u03b8 is large (i.e., close to or at 180 degrees).","Meanwhile, the device may detect a turn of the device based on one or more estimated directions of travel of the device. In one example, the device compares changes in the one or more directions against a threshold \u0398. Here, with an instantaneous direction of travel \u03b8, the device may first obtain a stationary direction at time t as a mean of \u03b8s observed since a last direction change at t, i.e., {right arrow over (\u03b8)}=(\u03a3\u03b8)\/(t\u2212t). Thereafter, the device may compute the direction change at t as \u0394\u03b8=\u03b8\u2212{right arrow over (\u03b8)}. If |\u0394\u03b8|\u2267\u0398, then the starting point of a turning phase is spotted at t. In one implementation, threshold \u0398 is set to 25 degrees. Here, an end point of a turn is detected when an instantaneous direction becomes stable again (i.e., minimal direction changes compared to a threshold), which is evaluated over a four-second running window at t. The overall turning angle may be a difference between the stationary directions at tand t. A final check may be performed to ensure a real turn. Here, the device may determine the real turn when an angle difference is larger than the threshold \u0398 and the time difference between tand t is more than four seconds.","Aspects of this disclosure are also directed to detecting an orientation change of a device. In one example, the orientation change is detected when a significant change of a vertical acceleration of the device is detected and a significant change of a direction of the device is detected. Here, the device may monitor a vertical acceleration component (i.e., {right arrow over (a)}), and detect the significant change in the vertical acceleration when the vertical acceleration component is greater than a threshold. This threshold may be set to 0.1 g, which corresponds to a 25-degree inclination. Meanwhile, the device may monitor an angle \u03b8 between a heading vector and a magnetometer's north direction, and detect the significant change of direction of the device when the change of direction occurs within a predetermined time duration (e.g., within one second). This may allow the device to distinguish an orientation change from a turn, which may also be associated with a change of direction.","The device may also filter out suspicious orientation changes by utilizing a mark and trace back approach. A suspicious orientation change may refer to a possible incorrect orientation change which is not caused by a vehicle. In one implementation, every orientation change is initially treated as a suspicious orientation change until a new heading vector is detected. Here, the device may mark a time and put the device into an undetermined state when a suspicious orientation change is detected. Thereafter, the device may re-estimate a heading vector when a strong acceleration change is detected, and trace back to the moment of a last suspicious orientation change. If multiple suspicious orientation changes exist, then the device may discard the suspicious changes. The device may assume that a motion state (both speed and heading direction) between the first and the last suspicious orientation change is a mean over a previous and subsequent steady motion state.","The detected orientation change may be utilized in various techniques of this disclosure. For example, as discussed above, the device may obtain a heading vector based on two acceleration readings where there is no orientation change of the device between the two readings. In this example, the device may determine whether there is an orientation change between two readings, by comparing times associated with the two readings and the detected orientation change. When a time of the detected orientation change is between a time of the first reading and a time of the second reading, the device may determine an orientation change between the two readings. When the orientation change is detected between two readings, the heading vector may be re-estimated from acceleration changes which are subsequent to the orientation change.","(B) Illustrative Mobility Trace Estimation in a Cycling, Walking, or Running State","Aspects of this disclosure are directed to estimating a mobility trace of a device based on a pedaling frequency, number of steps, and\/or magnetometer reading corresponding to a minimum magnitude of acceleration. The pedaling frequency, number of steps, and\/or magnetometer reading may be utilized when the device is determined to be in a cycling, walking, or running motion state.","In one example, when the device is determined to be in the cycling motion state, the device may estimate a speed and distance associated with the mobility trace based on a periodicity of cycling. Here, the speed of the device at a location on the mobility trace may be estimated as a linear function of a pedaling frequency. For example, the speed may be proportional to the pedaling frequency. In one implementation, the device estimates that the speed to be a first speed when the pedaling frequency is a first frequency, and estimates the speed to be a second speed when the pedaling frequency is a second frequency, where the first speed is less than the second speed and the first frequency is less than the second frequency. The pedaling frequency may be determined while the device is obtaining readings from an accelerometer during motion state detection.",{"@attributes":{"id":"p-0088","num":"0087"},"figref":["FIG. 5","FIG. 5"]},"Meanwhile, the device may estimate the distance based on the speed and a duration of time associated with the speed. The duration of time may indicate a time duration during which the device was traveling at the speed. Here, the device may estimate the distance as corresponding to the speed multiplied to the duration of time.","Meanwhile, when the device is determined to be in a walking or running motion state, the device may estimate a speed and distance of the device based on a periodicity of walking or running. For example, the device may calculate a number of steps a user with the device has traveled, and estimate the speed and distance based on this number. A step of the user may be determined with the readings from the accelerometer of the device. Here, the distance may be estimated by multiplying the number of steps to an average stride length, which may be previously set and\/or stored in the device. The speed may be estimated as the distance over a traveling time of the device for the distance.","The device may also estimate a direction of the device based on readings from an accelerometer and magnetometer of the device. In one example, the estimated direction of the device corresponds to a direction obtained from a magnetometer when the magnitude of acceleration reaches a minimum value. Here, the estimated direction of the device may correspond to a median of directions obtained from the magnetometer when the magnitude of acceleration reaches minimum values. The obtained readings may be obtained in a previous number of cycles (e.g., in a last three cycles), where a cycle is determined by a readings from the accelerometer and\/or magnetometer.","Meanwhile, a minimum value of the magnitude of acceleration may be determined by sampling a plurality of readings from the accelerometer, each indicating a magnitude of acceleration, and identifying a reading from the plurality of readings which has a lowest magnitude of acceleration. In one implementation, the device may utilize these techniques to estimate the direction of the device when the device is located anywhere on a user, including, for example, an upper body, hip pocket, and pant pocket location. The techniques for estimating the direction of the device may be applied, among other cases, in a case where the device is in a cycling, walking, or running motion state.",{"@attributes":{"id":"p-0093","num":"0092"},"figref":"FIG. 6"},"Illustrative Mobility Trace Mapping","The following section describes techniques directed to mapping an estimated mobility trace of a device to a map. The estimated mobility trace of the device may be obtained from one or more of the techniques described above. The mapping may include selecting the map based on a determined motion state of the device. For example, when the device is determined to be in a driving motion state, the device may select a map corresponding to driving, such as a road map. The mapping may also include fixing the estimated mobility trace to the selected map. The fixing may be based on cell tower data and\/or wireless access point data obtained by the device at a location on the mobility trace.","Cell tower data may refer to identification information of one or more cells or cell towers of a cellular network. Cell tower data may include a CellID, cell tower ID, or similar identification information. Meanwhile, wireless access point data may include identification information identifying one or more wireless access points (e.g., a Wi-fi\u00ae or Bluetooth\u00ae access point). The cell tower data and\/or wireless access point data may be obtained by a device and indicate that the device is within a coverage area of the cell tower or wireless access point identified in the cell tower data or wireless access point data.","Meanwhile, a map may be previously stored on the device or obtained as the device travels. The map may be obtained from a database including a plurality of maps. The map may be any type of map identifying a road, segment, path, location, and\/or other information generally understood as being included on a map.","As discussed above,  illustrates an exemplary mobility trace and cell tower (e.g., Tower 1) associated with a location L. Here, the device obtains cell tower data from the cell tower when the device is at location L on the mobility trace. The cell tower data identifies the cell tower and indicates that the device is within a coverage area of the cell tower, as illustrated by the circle surrounding the cell tower.","Meanwhile, a mobility trace may be mapped to a selected map by utilizing a Hidden Markov Model (HMM) and applying Viterbi decoding. For example, the mapping may include fixing the estimated mobility trace to the selected map by utilizing Viterbi decoding based on the HMM. Here, the HMM may include hidden states and the Viterbi decoding may determine a sequence of the hidden states which corresponds to a sequence of segments that the device traveled. The sequence of segments may include segments of a selected map (e.g., road segments for a selected road map). The HMM may include parameters, such as hidden states, observations, emission probabilities, and\/or transition probabilities, to be described in detail below.","A hidden state of the HMM may refer to a span of one or more road segments. The span of one or more road segments may be defined as one or more continuous road segments between one intersection and another intersection. Here, if a road has N intersections with other roads, then there may be N possible hidden states, which may be dependent on where a starting point of the mobility trace is.","An observation may include, for example, an angle of a turn(s), a distance between two consecutive turns, and\/or cell tower data and\/or wireless access point data. The cell tower data and\/or wireless access point data may be obtained at one or more locations on a mobility trace. The cell tower data and\/or wireless access point data may identify a rough location of the device. The rough location may be obtained from a cell tower or wireless access point database including location information for cell towers and\/or wireless access points.","An observation may also include, for example, location data obtained through GPS, cellular-based localization techniques, and\/or wireless access point-based localization techniques. This location data may be sporadically obtained as the device travels on a mobility trace, which may allow the device to conserve energy.","In one embodiment, cell tower data and\/or wireless access point data is utilized as an observation instead of location data obtained through GPS, cellular-based localization techniques, and\/or wireless access point-based localization techniques. This may allow the device to device to conserve energy.","Meanwhile, an emission probability may describe a probability of an observation given a specific hidden state. In one example, a joint probability density is utilized as an emission probability. The joint probability density may be defined as \u03a0N(dist(l,c)), where N(\u00b7) is a zero mean Gaussian function (due to a noisy cell tower location) with variance R (a rough estimation of an average radius of the cell tower coverage), lis a uniformly interpolated position at sampling time t along the specific hidden state, cis a location of the cell tower observed at t, and dist(l,c) is an Euclidian distance between land c. R may be a system parameter. This approach may consider that a cell tower ID, and the associated location information, may provide a rough estimation of a position of the device when the cell tower ID was sampled. In addition, this approach may consider that there may be multiple cell tower ID samplings along a span of one or more road segments (due to a mobility of the device), because a cellular module of the device may update on a predetermined period (e.g., every second).","A transition may refer to a transition between hidden states, and be signaled when a turn is detected. Meanwhile, a transition probability may be calculated from all observations at the turn. In one example, several constraints are imposed to limit a number of candidate hidden states, including, for example, bound-limiting on estimated angles of turns, error distribution of estimated distances, and cell tower coverage. At an nturn and hidden state j, which was transitioned from state i at (n\u22121)turn, the transition probability to a new state k may be computed as:",{"@attributes":{"id":"p-0105","num":"0104"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["j","d"],"mo":"|"}}},{"mfrac":{"mrow":[{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["d","j"],"mo":"|"}}},{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"j"}}],"mo":"\u2062"},{"mo":"\u2211","mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"j"}},{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["d","j"],"mo":"|"}}}],"mo":"\u2062"}}]},"mo":"."}],"mo":"="}}}},"The priori probability P(j) may be calculated as follows:\n\n()=1\n\nwhere N is a total number of candidate states. At a start state (e.g., t=1), the candidates include all intersections lying within the coverage of the cell tower observed at the turn except those with no outgoing states that lie within the direction range (\u03b3\u00b1\u03b5). If t>1, the candidate states may be identified with the following three conditions: 1) egresses from state i, i.e., whose first segment joins the last segment of state i; 2) the angle of turn is within the direction range \u03b3\u00b1\u03b5; and 3) the end point is within the coverage of the cell tower observed at the turn.\n","Meanwhile, the conditional probability P(d|j) may be calculated as follows:",{"@attributes":{"id":"p-0108","num":"0107"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["d","j"],"mo":"|"}}},{"mfrac":{"mn":"1","mrow":{"msub":{"mi":["\u03c3","j"]},"mo":"\u2062","msqrt":{"mrow":{"mn":"2","mo":"\u2062","mi":"\u03c0"}}}},"mo":"\u2062","msup":{"mi":"\u2147","mfrac":{"mrow":[{"mo":"-","msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":"d","mo":"-","msub":{"mi":["d","j"]}}},"mn":"2"}},{"mn":"2","mo":"\u2062","msubsup":{"mi":["\u03c3","j"],"mn":"2"}}]}}}],"mo":"="}}},"br":{},"sub":["j ","j ","j"]},"In one implementation, if multiple cell tower readings are available (e.g., when a device can hear multiple cell towers), the scope of candidate states may be further narrowed for the calculation of both the emission and transition probabilities. Alternatively, or in addition, when the cell tower location is not available, no cell tower constraint may be applied.","As noted above, a HMM may utilize cell tower data and\/or wireless access point data obtained at one or more locations on a mobility trace. This data may be utilized to identify an area of a map to search. For example, when a device obtains cell tower data and\/or wireless access point data identifying a cell tower and\/or wireless access point, this indicates that the device is located within a coverage area of the cell tower and\/or wireless access point. This data may provide a rough location of the device which may be utilized to identify an area of a map to search in order to map a mobility trace to the map.",{"@attributes":{"id":"p-0111","num":"0110"},"figref":["FIG. 7","FIG. 4"],"b":["1","1"]},"Meanwhile, the Viterbi algorithm may determine the most likely sequence of hidden states corresponding to the mobility trace. The resulting sequence of hidden states may represent the fix of the mobility trace to segments of the map. Here, the fixed mobility trace may include a sequence of segments which may represent the actual segments of the map that the device traveled. In one example, the sequence of segments is a sequence of road segments.",{"@attributes":{"id":"p-0113","num":"0112"},"figref":["FIG. 8","FIG. 9","FIG. 8","FIG. 9"]},"Illustrative Location Determination","The following section describes techniques directed to determining a location of a device at a given time based on a mapped (e.g., fixed) mobility trace. As discussed above, the mapped mobility trace may include a sequence of segments (e.g., road segments) of a map that the device traveled. A segment may be defined by one or more turns located at ends of the segment. Here, the device may determine the location by utilizing interpolation or extrapolation based on the sequence of segments and a speed of the device.","In one implementation, the sequence of segments (e.g., road segments) are ordered based on times that the device traveled the segments. For example, a first segment may be ordered before a second segment where the device traveled the first segment before the second segment. In the sequence of segments, a first and last segment of the sequence may be opened-ended, and the other segments closed-ended. An opened-ended segment may be a segment with one or more undetermined ends (e.g., turns), and a closed-ended segment may be a segment with two determined ends (e.g., two consecutive turns).","Meanwhile, a location of a device may determined in response to a location query. The location query may be sent from a location-based service or application and may request the device to determine the location of the device at a particular time (e.g., a current or past time). In one example, when the particular time included in the location query is determined to be within a time duration during which the device traveled a closed-ended segment, the location is determined by performing interpolation. The interpolation may be implemented by the following equation:",{"@attributes":{"id":"p-0117","num":"0116"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"L","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mrow":[{"mi":"L","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"t","mn":"0"}}},{"mfrac":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","msub":{"mi":"t","mn":"0"}},"mi":"t"},"mo":"\u2062","mrow":{"mi":"v","mo":"\u2061","mrow":{"mo":["[","]"],"mi":"i"}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","msub":{"mi":"t","mn":"0"}},"msub":{"mi":"t","mn":"1"}},"mo":"\u2062","mrow":{"mi":"v","mo":"\u2061","mrow":{"mo":["[","]"],"mi":"i"}}}]},"mo":"\u00b7","mrow":{"mi":"dist","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"t","mn":"0"},{"mi":"t","mn":"1"}],"mo":","}}}}],"mo":"+"}],"mo":"="}}},"br":{},"sub":["0","0","1 ","0","1","0","1","i=t",{"sub2":"0"},"0","1"],"sup":["t",{"sub2":"1"}]},"Meanwhile, when the particular time included in the location query is determined to be within a time duration during which the device traveled an open-ended segment, the location is determined by performing extrapolation. Extrapolation may be utilized when the location query requests a current location of the device at a current time. The extrapolation be implemented by the following equation:",{"@attributes":{"id":"p-0119","num":"0118"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"L","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mrow":[{"mi":"L","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"t","mn":"0"}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","msub":{"mi":"t","mn":"0"}},"mi":"t"},"mo":"\u2062","mrow":{"mrow":{"mrow":{"mi":"v","mo":"\u2061","mrow":{"mo":["[","]"],"mi":"i"}},"mo":"\u00b7","mi":"\u0394"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"T"}}],"mo":"+"}],"mo":"="}}},"br":{},"sub":["0","0"]},"In one example, the device may perform Viterbi decoding in the background of the device (i.e., without notice to a user of the device) until a location query is received. Here, the device may continuously fix the mobility trace of the device to segments of the map, and then determine a location of the device in response to receiving the location query. When the location query is received, the device may also determine all intermediary locations through time-and-speed-based interpolation. The intermediary locations may correspond to locations of the mobility trace between a time when a previous location query was received and a time when a current location query was received.","Furthermore, after the device determines the location of the device, the device may provide the determined location to a service or application, such as a location-based service or application. The service or application may be a service or application running on the device or running remotely. In addition, the device may provide an estimated or mapped mobility trace of the device to the service or application. The determined location and mobility trace may be provided to the service or application via a set of service APIs.","Illustrative Process","The following section describes, in reference to , an exemplary process of location determination. Process  (as well as each process described herein) is illustrated as a logical flow graph, each operation of which represents a sequence of operations that can be implemented in hardware, software, or a combination thereof. In the context of software, the operations represent computer-executable instructions stored on one or more computer-readable storage media that, when executed by one or more processors, perform the recited operations. Generally, computer-executable instructions include routines, programs, objects, components, data structures, and the like that perform particular functions or implement particular abstract data types. The order in which the operations are described is not intended to be construed as a limitation, and any number of the described operations can be combined in any order and\/or in parallel to implement the process.","For ease of illustration, process  is described as being performed in the environment  of . For example, process  may be performed by localization module  of device . However, process  may be performed in other environments. Moreover, the environment of  may be used to perform other processes.","Process  includes an operation  for obtaining a sensor reading(s) from a sensor a device, such as sensor(s)  of device . The sensor reading(s) may include a reading from an accelerometer and\/or magnetometer of the device. The device may obtain the sensor reading(s) periodically based on a predetermined period of time.","Thereafter, process  may proceed to an operation  for performing motion state detection to determine a motion state of the device. The motion state may be based on the sensor reading(s) obtained in operation . Operation  may be performed by motion state detection module  of device , and may include many of the techniques discussed above in the section entitled \u201cIllustrative Motion State Detection.\u201d","Process  may also include an operation  for determining whether a determined motion state is a moving state. When the determined motion state from operation  is not a moving state (e.g., a still state), the process  may return to operation . Alternatively, when the determined motion state is the moving state, the process  may proceed to an operation .","Operation  may include estimating a mobility trace of a device based on previously obtained sensor readings(s), such as the sensor reading(s) obtained in operation . The mobility trace may include a plurality of segments and turns. The estimating may be performed periodically based on a predetermined period of time. The predetermined period of time may be a longer period of time than the predetermined period of time for obtaining sensor reading(s). Moreover, the mobility trace may be estimated based on techniques that are specific to the motion state determined in operation . Operation  may be performed by mobility trace estimation module  of device , and may include many of the techniques discussed above in the section entitled \u201cIllustrative Mobility Trace Estimation.\u201d","Process  may also include an operation  for mapping a mobility trace of a device to a map. The mapping may include selecting a map and fixing the mobility trace to the selected map. The selecting may be based on a determined motion state, such as the motion state determined in operation . The fixing may be based on cell tower data and\/or wireless access point data, which may be obtained from an operation . Moreover, the mapping may be performed in response to detecting a turn of the device on the mobility trace. Operation  may be performed by mapping module  of device , and may include many of the techniques discussed above in the section entitled \u201cIllustrative Mobility Trace Mapping.\u201d","Operation  may include obtaining cell tower data and\/or wireless access point data as the device travels on the mobility trace. The cell tower data and\/or wireless access point data may indicate that the device was located within a coverage area of a communication point(s) identified in the cell tower data and\/or wireless access point data.","Process  may also include an operation  for determining a location of a device based on a mapped mobility trace. The location of the device may determined in response to receiving a location query, for example, in an operation . The mapped mobility trace may be the mapped mobility trace from operation , and may include a plurality of segments. Operation  may include performing interpolation or extrapolation based on the plurality of segments and a speed of the device on one of the plurality of segments.","Operation  may include receiving a location query including a time of a requested location of the device. The location query may be received from a location-based service or application. The location query may request that the device determine a location of the device at the time included in the location query.","Illustrative Implementation","The following section describes an exemplary implementation for many of the techniques discussed above. In this implementation, these techniques are implemented as a service or application which is continuously running in the background of a device (e.g., a mobile device). In one example, the service or application performs motion state detection, distance estimation, and turn detection periodically based on a first period of time (e.g., four seconds) to maintain a small memory footprint. Meanwhile, the service or application may perform mapping in response to detecting a turn. The device may perform the mapping even if a location query has not been received. This approach may allow the service or application to provide a location of the device in a timely manner.","In one example, the service or application runs in the background in a wake-lock mode by calling a WakeLock API with a parameter PARTIAL_WAKE_LOCK. In this mode, the service or application may remain running in the background after a user presses a power button to put the device into a sleep mode. An AlarmManager API may also be used to wake a CPU of the device from the sleep mode.","In a further implementation, the service or application may utilize a determined still motion state of the device to place the system into a sleep mode. For example, when the device is determined to be in an absolute still motion state (e.g., a still motion state for more than five minutes), the sampling process may begin duty cycling to sample a sensor reading only four seconds per minute. In this case, the service or application may set the device to a sleep mode between samplings by utilizing an AlarmManager API to put the CPU of the device into the sleep mode.","Although embodiments have been described in language specific to structural features and\/or methodological acts, it is to be understood that the disclosure is not necessarily limited to the specific features or acts described. Rather, the specific features and acts are disclosed herein as illustrative forms of implementing the embodiments."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The detailed description refers to the accompanying figures. In the figures, the left-most digit(s) of a reference number identifies the figure in which the reference number first appears. The use of the same reference numbers in different figures indicates similar or identical items.",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIGS. 2A-2B"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIGS. 3A-3B"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 9","FIG. 8"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
