---
title: Method and apparatus for providing and receiving user interface
abstract: In a method of providing/receiving a user interface between a user interface client and a user interface server, when the user interface server encodes information on a plurality of user interface scenes in a multimedia data format and transmits the encoded information to the user interface client. The user interface client receives and reproduces the multimedia data so that a user interface may be displayed to which a variety of effect are applied considering individual characteristics of the user interface client such as performance of the user interface client and user preference.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09084020&OS=09084020&RS=09084020
owner: SAMSUNG ELECTRONICS CO., LTD.
number: 09084020
owner_city: Suwon-Si
owner_country: KR
publication_date: 20090415
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND","SUMMARY","DETAILED DESCRIPTION OF EMBODIMENTS"],"p":["This application claims the benefit of Korean Patent Application No. 10-2008-0079033, filed on Aug. 12, 2008, and Korean Patent Application No. 10-2008-0094897, filed on Sep. 26, 2008, in the Korean Intellectual Property Office, and U.S. Provisional Patent Application No. 61\/045,787, filed on Apr. 17, 2008, in the U.S. Patent and Trademark Office, and the disclosure of which is incorporated herein in their entirety by reference.","1. Field","One or more embodiments relate to a method and apparatus providing and receiving a user interface (UI).","2. Description of the Related Art","Various types of multimedia devices have been developed and a convergence of the multimedia devices has been accelerating. Among multimedia deices, it has become common to exchange multimedia data or to control each other by forming a network of different types of multimedia devices.","Remote control between devices that are physically located far apart from each other is performed via a remote user interface (RUI). A UI server provides a UI to a UI client to control the UI server. The UI client controls the UI server using the UI provided to the UI client by the UI server. For example, the UI server provides a web page to the UI client so that the UI client can remotely control the UI server. The UI client displays the web page to a user through a web browser. The user selects a control operation using the displayed UI, that is, the web page, to control the UI server.","In CEA-2014 that is a related art for the remote control of consumer electronics (CE) devices, the UI server generates a web page and provides the web page to the UI client. The UI client displays the received web page through a web browser.","Additional aspects and\/or advantages will be set forth in part in the description which follows and, in part, will be apparent from the description, or may be learned by practice of the invention.","One or more embodiments include a method and apparatus providing and receiving a user interface.","One or more embodiments correspondingly include a computer readable recording medium recording a program executing the above method.","Additional aspects will be set forth in part in the description which follows and, in part, will be apparent from the description, or may be learned by practice of the invention.","To achieve the above and\/or other aspects, one or more embodiments may include a method of providing a user interface to a user interface client from a user interface server, the method comprising encoding information on a plurality of user interface scenes in a multimedia data format, and transmitting the multimedia data to the user interface client.","The information on the plurality of user interface scenes is to display a user interface at a plurality of different user interface clients.","The information on the plurality of user interface scenes comprises presentation information to present objects included in the user interface scene in a scene, event information on events generated by the objects, and function information on functions called to process the events.","To achieve the above and\/or other aspects, one or more embodiments may include a method of receiving a user interface from a user interface server in a user interface client, the method comprising receiving multimedia data including information on a plurality of user interface scenes and decoding the multimedia data, and displaying the plurality of user interface scenes by reproducing the decoded multimedia data.","To achieve the above and\/or other aspects, one or more embodiments may include a user interface server providing a user interface to a user interface client, the user interface server comprising an encoding unit encoding information on a plurality of user interface scene in a multimedia data format, and a transmission unit transmitting the multimedia data to the user interface client.","To achieve the above and\/or other aspects, one or more embodiments may include a user interface client receiving a user interface from a user interface server, the user interface client comprising a decoding unit receiving multimedia data including information on a plurality of user interface scenes and decoding the multimedia data, and a reproduction unit displaying the plurality of user interface scenes by reproducing the decoded multimedia data.","To achieve the above and\/or other aspects, one or more embodiments may include a computer readable recording medium recording a program executing any one of the above methods.","To achieve the above and\/or other aspects, one or more embodiments may include a method of providing a user interface to a user interface client from a user interface server, the method comprising encoding the user interface in a multimedia data format, and transmitting the multimedia data to the user interface client, wherein the multimedia data includes information on a protocol of a control message transmitted to the user interface server when the user interface client performs a control operation according to the user interface.","To achieve the above and\/or other aspects, one or more embodiments may include a method of receiving a user interface from a user interface server in a user interface client, the method comprising receiving a multimedia data including a first user interface and decoding the multimedia data, receiving information on a content provided to a user via the user interface, and generating a second user interface by coupling the first user interface and the information on the content.","To achieve the above and\/or other aspects, one or more embodiments may include a user interface server providing a user interface to a user interface client, the user interface server comprising a user interface generation unit generating the user interface, a user interface encoding unit encoding the user interface in a multimedia data format, and a user interface providing unit transmitting the multimedia data to the user interface client, wherein the multimedia data includes information on a protocol of a control message transmitted to the user interface server when the user interface client performs a control operation according to the user interface.","To achieve the above and\/or other aspects, one or more embodiments may include a user interface client receiving a user interface from a user interface server, the user interface client comprising a user interface decoding unit receiving a multimedia data including a first user interface and decoding the multimedia data, and a user interface coupling unit generating a second user interface by coupling the first user interface and information on a content provided to a user via the user interface.","To achieve the above and\/or other aspects, one or more embodiments may include a computer readable recording medium recording a program for executing any of the above-described methods of providing or receiving a user interface.","Reference will now be made in detail to embodiments, examples of which are illustrated in the accompanying drawings, wherein like reference numerals refer to the like elements throughout. In this regard, the present embodiments may have different forms and should not be construed as being limited to the descriptions set forth herein. Accordingly, the embodiments are merely described below, by referring to the figures, to explain aspects of the present description. The embodiments are described below to explain the present invention by referring to the figures.  is a flowchart of a method of providing and receiving a user interface (UI) according to an embodiment. In the following embodiments, a user interface (UI) includes a user interface, such as a widget or a gadget, displayed on a part of a screen.","Referring to , in operation , a UI server  according to an embodiment encodes information on a plurality of UI scenes in multimedia data format. Operations , , , , , and  of  are described in detail with reference to subsequent figures.","Operation  is described in detail with reference to .",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 2","FIG. 2"],"b":["200","200","1","2","3","210","230"]},"In an example shown in , each of the UI elements #, #, and # - includes information related to at least one UI scene. The UI scene represents a scene including at least one UI object. The UI scenes may be classified by the included UI object. A change in at least one of the UI objects forming the UI scene indicates a change of the UI scene. The UI scene may include one or more UI objects. That is, the UI scene may include only one UI object or may include a plurality of UI objects. The UI object represents the minimum unit of the UI capable of generating a predetermined event and calling a predetermined function based on the generated event.","A UI for a predetermined control operation may include a plurality of UI scenes. For example, information on the plurality of UI scenes, that is, the UI package , may include information on UI scenes continuously displayed at a UI client  as a user selects a predetermined object at a UI scene.","An initial UI scene in which information on movies to be selected by a user is displayed in the form of a thumb-nail may be stored in the UI element # . When the user selects one of the movies from the initial UI scene, the next scene displaying a scene controlling reproduction of the movie with detailed information on the movie may be stored in the UI element # . The initial UI element and the UI elements of the next scene may exchange information with each other.","The information on the UI scenes may be information for displaying a UI of the UI server  at a plurality of different UI clients . When there are multiple UI clients  receiving the UI from the UI server  via a network, different UI clients  may often have different capabilities. The UI clients  may be different in terms of supporting resolution of a display device and the capacity of an installed memory or CPU. Accordingly, the UI package  may include the information on the UI scenes that may be displayed at each of the different UI clients .","For example, when the UI server  is an IP-settop box connected to a digital TV, a computer, or a portable media player (PMP) via a network, the resolutions of display devices of and hardware performance of the digital TV, the computer, and the PMP are different from one another. Accordingly, the UI element #  includes information on the UI scene that the digital TV may display. The UI element #  includes information on the UI scene that the computer may display. The UI element #  includes information on the UI scene that the PMP may display. Next, the UI package  is provided to all sorts of the UI clients  so that each of the UI clients  may select and display one of the provided UI scenes.","In the above description, the performance of the UI client  is discussed as an example, a network environment or the preference of a UI client  may be a standard for selecting a UI scene from the UI package . Also, a bandwidth of a network that the UI client  connects or a personal profile of a user of the UI client  may be a standard for selecting the UI scene. The personal profile may include the age, the nationality, and the language(s) of a user, or combinations or sub-combinations thereof. The information on the user preference may include structured information generated according to a standard such as MPEG-21 usage environment description (UED) or W3C composite capabilities\/preference profile (CC\/PP), for example.","Also, the information on the UI scenes may be information for sequentially displaying the UI scenes. For example, the UI element #  may include a portion of an object of the UI scene while the UI element #  may include the other portion of the object of the UI scene, which will be described in detail with reference to .","Referring back to , in operation , the information on the UI scenes is encoded by the UI server  in multimedia data format. When the UI is generated in the form of a web page and transmitted to the UI client  as in the related art, there may be a limit in the presentation of a UI. Also, the UI client  may additionally include a software or hardware module to present a UI. However, the above structure is not suitable for a device having a limited usable hardware resource as in the case in which the UI client  is a mobile device.","Thus, in operation , the UI server  encodes the UI by forming a UI package based on MPEG data, for example. That is, the UI server  encodes the information on the UI scenes in multimedia data format that is reproducible by various devices. The UI scenes are encoded in a multimedia data format including multimedia, that is, video, audio, and\/or text. Since the UI scenes may be encoded in the multimedia data format including various media, various and eye-catching effects may be applied to the UI scenes. Since most devices including a mobile device are capable of reproducing multimedia including a moving picture and voice, the UI is encoded in the multimedia data format.","For example, the UI may be encoded based on an MPEG (Moving Picture Experts Group) standard. The MPEG standard is an international standard for a method of compressing and encoding a moving picture and audio and includes a variety of standard versions such as MPEG-1, MPEG-2, MPEG-4, and MPEG-7. The UI server  generates a UI scene using the MPEG standard. For example, by encoding a UI in a moving picture format to be reproduced by the UI client , the above-described compatibility problem may be solved.","In particular, the UI scene may be encoded using an object-based multimedia encoding method such as MPEG-4 binary format for scene (BIFS) and lightweight applications scene representation (LASeR) for a mobile device, for example. By regarding objects included in the UI scene as objects encoded based on BIFS or LASeR, the space-time arrangement of objects at the UI scene may be encoded using a scene description method according to BIFS or LASeR.","BIFS or LASeR include information on the scene description method to present the space-time arrangement of the objects included in an image. Accordingly, the space-time arrangement of UI objects such as a button or a menu may be presented using BIFS or LASeR.","Multimedia data including an image of the UI, for example, AV stream, is generated by encoding the UI using an image codec such as BIFS or LASeR, for example. When the UI client  reproduces a received AV stream, the UI is displayed. Since the UI is displayed by simply reproducing the AV stream, devices capable of reproducing the AV stream may display the UI provided by the UI server . Thus, the UI scene including the UI object is encoded by using the object-based multimedia encoding method according to the present invention. All devices capable of reproducing multimedia data encoded according to BIFS or LASeR may reproduce a UI having a variety of multimedia effects.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 3","FIG. 3"],"b":["300","300","310","320","330"]},"Since the information on the presentation, the event, and the function are structurally classified and included in the UI elements #, #, and # , , and , a dynamic expansion of the UI is possible, which is described later with reference to .","The presentation information  indicates that how the objects included in the UI scene are arranged in a scene and which media is used for presentation. A scene description  is information to describe the structure of a UI scene and may include information to describe a layout, a form, a theme, and a template of a scene, or combinations or sub-combinations thereof. Also, the scene description  may include information on a method of presenting the UI scene. When the overall UI scene is presented using a special effect such as fade out or fade in, the scene description  may include information on the special effect.","An object description  is information on the method of presenting the objects included in the scene and includes information indicating which one of media including an image, video, and audio is used to present each of the UI objects. Also, the object description  may include information on the presentation time and method of the objects. For example, when the objects included in the UI scene are presented in the scene on different times, information on a time for timing adjustment may be included in the object description . Also, the object description  may include information on the presentation method when the objects are presented in the scene using the special effects such as fade out or fade in. Furthermore, when an animation effect in which the sizes or shapes of the objects are not fixed and continuously moved is used, the object description  may include information on the presentation method.","An adaptation utility  includes information for the dynamic configuration of a UI scene. For example, the adaptation utility  includes information on the dynamic configuration of a scene when a UI scene includes UI objects A, B, C, and D and the UI client  uses only the UI objects A and B, considering the performance of itself, in the presentation of the UI scene.","The adaptation utility  includes information on the performance of the UI client  and a standard for dynamically configuring a scene according to the performance of the UI client . For example, the adaptation utility  includes information on a standard for the dynamic configuration by which a UI client having a display performance of a standard definition (SD) level presents only the objects A and B in the UI scene while a UI client having a display performance of a high definition (HD) level represents all objects A, B, C, and D in the UI scene. All respective characteristics of the UI client  including the performance of the UI client  and a network environment or the preference of the UI client  may be the dynamic configuration standard.","Also, the adaptation utility  may include information on a standard for the selection of a UI element. As described above, the UI package  includes information on a plurality of UI scenes to display a UI at a plurality of different UI clients .","Thus, when the different UI clients  select and display one of the UI elements , , and  from the UI package , information that may be referred to for selection is needed. The adaptation utility  may include information that may be a standard for the selection.","For example, if the information on the minimum performance to display each of the UI elements , , and  is included in the adaptation utility , the UI client  refers to the information and selects one of the UI elements , , and  from the UI package  that may be displayed by the UI client .","A resource  includes sources to present an UI scene and may include multimedia data such as an image, moving picture, and audio. The presentation information  to present objects included in the UI scene in a scene may include information for forming a UI scene including an iconized UI, for example, the UI scene including an UI iconized in the scene description , the object description , or the adaptation utility .","An iconized UI according to an embodiment is now explained with reference to .",{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIG. 11","FIG. 11","FIG. 11"],"b":["1100","1110","1120","1100","1132","1134","1130","1100","1110","1120","1132","1134","1130","1132","1134","11300","1110","1130","1110","310","1130","1100"]},"The icons A and B  and  displayed on the dock  and the widgets A and B  and  may be interlinked. As described above, when the widget A  is a widget indicating weather information, the icon A  and the widget A  may be interlinked so that the shape of the icon A  may be changed according to the change of weather. For example, when the weather is sunny, an icon having a shape of the sun is displayed on the dock . When the weather is overcast or precipitating, an icon having a shape of a cloud is displayed on the dock .","Referring again to , the event information  includes information on events generated by the objects included in the UI scene. Also, the event information  includes information on events generated by a result of interaction between the UI object and a user, such as, the selection of an object by the user.","An event description  includes information on events generated by the objects and describes the type of user interactions that may be performed by the UI object such as click, touch, and rotation, or combinations or sub-combinations thereof.","An event handle  includes information on a method of processing the generated events. For example, when an event \u201cclick\u201d is defined in the even description , the event handle  includes information on how to process the event \u201cclick\u201d. If a clicked UI object is an object to control volume, the event handle  includes information for processing the event \u201cclick\u201d by analyzing the event \u201cclick\u201d as volume up or volume down.","A binding interface  includes information on mapping between the defined events and a device application programming interface (API) called to process the events. The binding interface  includes information on mapping between the events and a device API called to process the events to correlate the events generated by the UI objects and functions called by the events.","The function information  includes detailed information on device APIs called to perform functions. A function description  includes information on detailed operations of the device APIs called by the events, that is, detailed functions that a user may use via the device APIs. For example, when a device API for a vibration function is called, the function description  includes information on a detailed function such as control of vibration strength or control of vibration time that may be embodied by the device API.","A function call  includes information on a detailed parameter of a function called by a UI object. For example, when the device API for a vibration function is described in the function description  as being able to control the vibration strength and vibration time at five levels of 1-5, the function call  includes detailed parameters indicating at which level of the five levels of the vibration strength and vibration time the function is called. For example, when a UI object A calls a vibration function with a vibration strength of level 3 and a vibration time of level 1 of the five levels of the vibration strength and vibration time described in the function description , detailed parameters for the above function call may be included in the function call .","As shown in , since information related to the presentation, event and function is classified and included in the UI elements , , and , the UI scene may be dynamically configured, which will be described in detail with reference to .",{"@attributes":{"id":"p-0078","num":"0077"},"figref":["FIG. 4","FIG. 4"],"b":["310","320","330"]},"For example, for the UI client  to dynamically configure the UI scene, the scene description , the object description , the adaptation utility , and the resource  of the UI client , that is, \u201cLocal\u201d, are used as the presentation information  to present the UI object A. The event description , the event handle , the binding interface , the function description , and the function call  of the UI server , that is, \u201cRemote\u201d, are used as the event information  and the function information . While performing the event and function of the UI provided by the UI server , the UI client  may freely configure the presentation of the UI scene.","Referring back to , in operation , the UI server  transmits information on a plurality of UI scenes that is encoded in a multimedia data format, to the UI client . That is, by transmitting the multimedia data by streaming to the UI client , the UI client  may reproduce the UI scene. Also, the UI may be provided by downloading to the UI client , rather than by streaming.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":["FIG. 5","FIG. 5"],"b":["110","200","112","210","220","230"]},"The UI server  first transmits the UI element #  including a portion of the UI object to the UI client . Then, when the UI displays a UI scene including a portion of the UI object according to the UI element # , the UI element #  including the other UI object is transmitted to the UI client . For example, the UI client  receiving the UI package  may first display a UI scene including a portion of the object according to the UI element #  and then a complete UI scene including the other UI objects after receiving the UI element # . The UI client  may determine whether to display the complete UI scene using the UI element #  according to the performance of the UI client , network environment, and user preference, or a combination or sub-combination thereof.","Referring back to , in operation , the UI client  decodes the received multimedia data. The decoded multimedia data is reproduced to display a UI scene.","In operation , the UI client  selects a predetermined control operation using the UI scene displayed in operation . The predetermined control operation may be selected as a user generates an event in a UI object of the UI scene.",{"@attributes":{"id":"p-0085","num":"0084"},"figref":["FIG. 6","FIG. 6","FIG. 6"],"b":["124","126","602","112","200"]},"In operation , the presentation information  to present objects included in the UI scene in a scene is interpreted. In operation , the UI client  interprets the event information  on the events generated by the objects included in the UI element  and the function information  on the function called to process the events.","In operation , the UI client  determines whether the UI scene needs to be dynamically reconfigured, considering the performance of the UI client , network environment, and user preference. The necessity of the reconfiguration is determined referring to the information included in the adaptation utility .","If the reconfiguration is determined to be needed in operation , in operation , the UI client  reconfigures the UI scene and object. Accordingly, a portion of the objects included in the UI scene is displayed or the UI scene is reconfigured by adjusting the arrangement of the objects.","In operation , the UI client  displays the UI scene by reproducing the decoded multimedia data, that is, the UI package . In operation , the UI client  receives a predetermined input from a user. When there is a user input, a predetermined event is generated according to the user input. When there is no user input, the program goes back to operation  to repeat the reproduction of the UI scene.","In operation , the UI client  determines whether a function for the predetermined control operation is called according to the event generated in Operation . Determination is made as to whether the function is called according to the generated event because there is a case in which, even if an event is generated, only a UI scene is updated without calling a function for a control operation.","In operation , the UI client  calls a predetermined control function according to the generated event. In operation , the UI client  updates the UI scene. In operation , the UI client  determines whether to terminate the reproduction of the UI scene. When it is determined that the reproduction is not terminated, the method of  returns to operation  and continues to reproduce the UI scene.","Referring back to , in operation , the UI client  transmits a predetermined control signal to the UI server  based on the control operation selected in operation . When a device controlled using the UI is not the UI server , the control signal may be transmitted to another device, not the UI server .","In operation , the UI server  performs a control operation according to the control signal received from the UI client . For example, a content such as movie, drama, or MP3 songs are transmitted to the UI client  or a control operation such as reproduction, stop, fast forwarding, or fast rewinding of the content is performed. When the control signal is transmitted to other device not the UI server  in operation , the other device performs the control operation.",{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 7","FIG. 7"],"b":["110","710","720","730"]},"The encoding unit  encodes information on a plurality of UI scenes in a multimedia data format. As described above, the UI scenes may be encoded using an object-based multimedia encoding method such as an MPEG standard, for example, MPEG-4 binary format for scene (BIFS) and lightweight applications scene representation (LASeR) for a mobile device, for example.","The transmission unit  transmits multimedia data generated as a result of the encoding in the encoding unit  to the UI client . That is, the transmission unit  transmits the UI package  including the information on the UI scenes to the UI client . As described with reference to , the respective UI elements , , and  included in the UI package  may be sequentially transmitted at a time interval.","The control performing unit  receives a control signal from the UI client  and performs a predetermined control operation. That is, the control performing unit  performs a predetermined control operation by receiving the control signal transmitted by the UI client  based on the UI scenes provided by the transmission unit .",{"@attributes":{"id":"p-0098","num":"0097"},"figref":["FIG. 8","FIG. 8"],"b":["112","112","810","820","830","810","110"]},"The reproduction unit  displays the decoded multimedia data using a predetermined display device. The UI scene may be displayed using a method of reproducing a general moving picture by reproducing the multimedia data according to an MPEG standard, for example.","The control performing unit  generates a predetermined control signal based on user input according to the UI scene displayed by the reproduction unit . Then, a generated control signal is transmitted to the UI server . The user input may be transmitted to the control performing unit  through a variety of UI devices such as a keyboard, a mouse, or a touch screen, for example.",{"@attributes":{"id":"p-0101","num":"0100"},"figref":["FIG. 9","FIG. 9","FIG. 9"],"b":["918","910","910","920","922","1","912","2","914","910","918","910"]},"When one of the UI server #  and the UI server #  includes a complete UI for controlling the device A , the UI server transmits the complete UI to the UI client . However, if neither the UI server #  nor the UI server #  includes a complete UI for controlling the device A , the UI client  receives a portion of the UI from the UI server #  and the other portion from the UI server #  and combines the received UIs.","For example, when receiving a UI for reproducing MP3 of the device A , the UI client  may receive a UI related to \u201cPlay\u201d and \u201cPause\u201d of the MP3 from the UI server #  and a UI related to \u201cFast forward\u201d and \u201cRewind\u201d from the UI server # . In operations  and , the UI received from the UI server #  and the UI server #  may be a widget.","In operation , the UI client  generates a new UI for control of the device A  by combining the received UIs in Operations  and . For example, when the UI is a widget, a new widget C may be generated by combining a widget A received from the UI server #  and a widget B received from the UI server # .","A new UI may be generated in consideration of the performance of the UI client , the network environment, and the user preference, or combinations or sub-combinations thereof. For example, when the language that a user uses is English, UI objects may be display in English. When a color that a user prefers is blue, a UI using a blue theme may be generated.","In operation , the UI client  selects a predetermined control operation based on the UI generated in operation . The UI generated in operation  is displayed and a predetermined control operation is selected according to the user input based on the displayed UI.","In operation , the UI client  transmits a predetermined control signal to the device A  according to the selection in operation . In operation , the device A  performed a predetermined control operation according to the control signal received in operation .",{"@attributes":{"id":"p-0108","num":"0107"},"figref":["FIG. 10","FIG. 10"],"b":["1000","1000","1010","1010"]},"When a new UI is generated by combining two or more UIs, a UI may be dynamically generated in consideration of the performance of the UI client , the network environment, and the user preference stored in the characteristic information storage unit , for example.","The control performing unit  controls the device A using the UI generated by the UI management unit . The UI generated by the UI management unit  is displayed to a user. The user input according to the displayed UI is received and a control signal to control the device A is generated and transmitted to the device A.",{"@attributes":{"id":"p-0111","num":"0110"},"figref":["FIG. 11","FIG. 10","FIG. 12"]},{"@attributes":{"id":"p-0112","num":"0111"},"figref":["FIG. 12","FIG. 12","FIG. 12","FIG. 12"],"b":["1210","1220"]},"The UI server  includes a widget generation unit , a widget encoding unit , and a widget providing unit . The widget generation unit  and the widget encoding unit  may be independent devices unlike those shown in . The widget generation unit  generates a widget provided to the UI client . That is, the widget generation unit  authors a widget including various media such as video, audio, and text.","The widget encoding unit  encodes a widget generated by the widget generation unit , that is, encodes the widget in a predetermined multimedia data format in relation to . Here, a scene technology using an object-based multimedia encoding method such as MPEG-4 BIFS and LASeR, for example, may be used.","Information on a protocol related to a control message transceived when a control operation is performed based on the widget is encoded together. When the UI client  generates a predetermined event based on the widget, the UI server  performs a predetermined control operation related to the event. That is, the UI client  transmits a predetermined control message to the UI server . The widget encoding unit  encodes together the information on the protocol used for generating a control message and transmits an encoded information to the UI client . The widget encoding unit  may encode a widget by including information on the protocol in a function field of the UI element .","The widget providing unit  transmits multimedia data generated as a result of the encoding by the widget encoding unit  to the UI client . That is, the widget providing unit  may transmit a UI package generated as a result of the encoding to the UI client .","However, when the UI client  is not able to generate the widget again based on the multimedia data generated by the widget encoding unit , the widget providing unit  may generate and transmit the widget again based on the multimedia data. For example, the UI client  may be a device that is not capable of encoding the multimedia data encoded in a UI package format. In this case, the widget providing unit  performs the function of the widget coupling unit  of the UI client . That is, the widget providing unit  generates the widget based on the multimedia data and transmits the generated widget to the UI client . By accessing a content information unit  that will be described later, a widget coupled with information on a content may be generated, which will be described in detail later.","The UI server  includes a widget decoding unit, a widget coupling unit , and the content information unit . The widget decoding unit  may be an independent device different from that shown in . In particular, the content information unit  may be an external server providing the UI client  with content information provided to a user via a widget. When the widget is information to display weather information as in the example shown in , the content information unit  may be a weather server providing the weather information to the UI client .","The widget decoding unit  decodes the multimedia data provided by the widget providing unit . The widget decoding unit  decodes the multimedia data generated by being encoded using a scene description method of MPEG. A first widget is generated as a result of the decoding. The generated first widget may be a widget that does not include information on the content provided to a user. For example, a widget may include only a frame such as layout, form, theme, or template, not the content information provided to a user via the widget.","The widget coupling unit  generates a second widget based on the first widget generated as a result of the decoding by the widget decoding unit  and information on the content received by the content information unit . If the first widget does not include the content information as described above in relation to the widget decoding unit  and the first widget already includes predetermined content information, then the second widget may be generated by replacing the already included information with the content information received from the content information unit . For example, when the first widget is a widget providing information on weather and may include information on the weather of Seoul, the information may be replaced by information on weather of other domestic or foreign cities such as Busan or New York. The widget coupling unit  will be described in detail with reference to .","The content information unit  is a module providing information on a content, that is, meta data, provided to a user via a widget. The content information unit  may be a DB in the UI client  or a separate server existing outside the UI client .","When the widget is a UI providing weather information to a user as described above, the weather information is provided to the widget coupling unit  so that the widget coupling unit  may generate a widget by containing the first widget and the weather information. In another example, when the widget is a UI providing information on released movies, the content information unit  may provide meta data about at least one movie content to the widget coupling unit .","An example of a widget coupling unit  of  is described with reference to widget coupling unit  of .",{"@attributes":{"id":"p-0124","num":"0123"},"figref":["FIG. 13","FIG. 13","FIG. 12","FIG. 13"],"b":["1300","1300","1310","1320","1330","1340","1350","1360","1370"]},"The UI list management unit  analyzes a plurality of UI packages and creates and manages a UI list. The plurality of UI packages may be UI packages received from different UI servers. The list includes the first widget received from the UI server  shown in . A list indicating which UI server provides which UI is managed.","The UI parser unit  generates widgets by decoding the UI packages. The first widget received from the UI server  is generated by the UI parser unit . The generated first widget may be a widget that does not include information on a content, as described above.","The widget management unit  manages widgets generated by the UI parser unit . The widget may be generated by coupling information on a predetermined content to the first widget generated by the UI parser unit . Information on a content may be coupled to the first widget that does not include information on a content. When the first widget includes information on a predetermined content, the information on existing content may be replaced by information on a new content received by the information management unit .","When the life cycle of the second widget is already determined, the termination of the widget may be managed based on the life cycle. For example, when a user is allowed to use the second widget for only a month, the second widget may no longer be used after a month.","The information management unit  provides the widget management unit  with information on a content provided to a user so that the widget management unit  may generate the second widget. The information on a content may be received from a server outside the UI client, as described above. The information on a content may be transmitted to an external server.","The resource management unit  controls the widget management unit  to manage a resource of the UI client. The generation of a widget by the widget management unit  may be controlled considering the security of the UI client. Download of a particular widget may be limited considering security or hardware resource.","The presentation engine unit  is an engine for presentation of a widget. The widget according to the present embodiment is encoded to a multimedia data using the scene description method of MPEG, for example. The presentation engine unit  includes an engine for presenting the multimedia data. For example, a moving picture decoding engine such as an MPEG decoder, for example, may be included in the presentation engine unit .","The widget library unit  includes a library for dynamic generation of a widget and is a module storing the widgets that the UI client already possesses or the widgets that have been downloaded in the past. The stored widgets are provided to the widget management unit  at the request of the widget management unit  so that the widget management unit  may dynamically generate a widget.",{"@attributes":{"id":"p-0133","num":"0132"},"figref":["FIG. 14","FIG. 14","FIGS. 2 and 3"],"b":["1410","1420"]},{"@attributes":{"id":"p-0134","num":"0133"},"figref":["FIG. 15","FIG. 15"],"b":"1510"},"In operation , the UI client decodes the multimedia data received in operation . The first UI is generated by parsing and analyzing the UI package. In operation , the UI client receives the content information provided to a user via a UI from an external server. In operation , the UI client generates a second UI by coupling the first UI generated as a result of the decoding in operation  and the content information received in operation .","As described above, according to the one or more of the above embodiments, a basic component and an extended component of a component scene constituting a reproduction scene may be presented through the classification of data forming a UI and the respective constituent elements may exchange information each other through the objects thereof.","In addition, other embodiments can also be implemented through computer readable code\/instructions in\/on a medium, e.g., a computer readable medium, to control at least one processing element to implement any above described embodiment. The medium can correspond to any medium\/media permitting the storing and\/or transmission of the computer readable code.","The computer readable code can be recorded on a medium in a variety of ways, with examples of the medium including recording media, such as magnetic storage media (e.g., ROM, floppy disks, hard disks, etc.) and optical recording media (e.g., CD-ROMs, or DVDs). Thus, the medium may be such a defined and measurable structure including or carrying a signal or information, such as a device carrying a bit stream, for example, according to one or more embodiments. The media may also be a distributed network, so that the computer readable code is stored and executed in a distributed fashion. Still further, as only an example, the processing element could include a processor or a computer processor, and processing elements may be distributed and\/or included in a single device.","It should be understood that the exemplary embodiments describing therein should be considered in a descriptive sense only and not for purposes of limitation. Descriptions of features or aspects within each embodiment should typically be considered as available for other similar features or aspects in other embodiments.","Although a few embodiments have been shown and described, it would be appreciated by those skilled in the art that changes may be made in these embodiments without departing from the principles and spirit of the invention, the scope of which is defined in the claims and their equivalents."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["These and\/or other aspects will become apparent and more readily appreciated from the following description of the embodiments, taken in conjunction with the accompanying drawings of which:",{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 15"}]},"DETDESC":[{},{}]}
