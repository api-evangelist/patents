---
title: Highlighting in response to determining device transfer
abstract: A computationally implemented method includes, but is not limited to: determining that a computing device that was presenting an item has been transferred from a first user to a second user; and presenting, via the computing device, one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining. In addition to the foregoing, other method aspects are described in the claims, drawings, and text forming a part of the present disclosure.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08726367&OS=08726367&RS=08726367
owner: Elwha LLC
number: 08726367
owner_city: Bellevue
owner_country: US
publication_date: 20111222
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","SUMMARY","DETAILED DESCRIPTION"],"p":["The present application is related to and claims the benefit of the earliest available effective filing date(s) from the following listed application(s) (the \u201cRelated Applications\u201d) (e.g., claims earliest available priority dates for other than provisional patent applications or claims benefits under 35 USC \u00a7119(e) for provisional patent applications, for any and all parent, grandparent, great-grandparent, etc. applications of the Related Application(s)). All subject matter of the Related Applications and of any and all parent, grandparent, great-grandparent, etc. applications of the Related Applications, including any priority claims, is incorporated herein by reference to the extent such subject matter is not inconsistent herewith.\n\n","The United States Patent Office (USPTO) has published a notice to the effect that the USPTO's computer programs require that patent applicants reference both a serial number and indicate whether an application is a continuation, continuation-in-part, or divisional of a parent application. Stephen G. Kunin, -, USPTO Official Gazette Mar. 18, 2003. The present Applicant Entity (hereinafter \u201cApplicant\u201d) has provided above a specific reference to the application(s) from which priority is being claimed as recited by statute. Applicant understands that the statute is unambiguous in its specific reference language and does not require either a serial number or any characterization, such as \u201ccontinuation\u201d or \u201ccontinuation-in-part,\u201d for claiming priority to U.S. patent applications. Notwithstanding the foregoing, Applicant understands that the USPTO's computer programs have certain data entry requirements, and hence Applicant has provided designation(s) of a relationship between the present application and its parent application(s) as set forth above, but expressly points out that such designation(s) are not to be construed in any way as any type of commentary and\/or admission as to whether or not the present application contains any new matter in addition to the matter of its parent application(s).","A computationally implemented method includes, but is not limited to determining that a computing device that was presenting an item has been transferred from a first user to a second user, and presenting, via the computing device, one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining. In addition to the foregoing, other method aspects are described in the claims, drawings, and text forming a part of the present disclosure.","In one or more various aspects, related systems include but are not limited to circuitry and\/or programming for effecting the herein-referenced method aspects; the circuitry and\/or programming can be virtually any combination of hardware, software, and\/or firmware in one or more machines or article of manufacture configured to effect the herein-referenced method aspects depending upon the design choices of the system designer.","A computationally implemented system includes, but is not limited to: means for determining that a computing device that was presenting an item has been transferred from a first user to a second user; and means for presenting, via the computing device, one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining. In addition to the foregoing, other system aspects are described in the claims, drawings, and text forming a part of the present disclosure.","A computationally implemented system includes, but is not limited to: circuitry for determining that a computing device that was presenting an item has been transferred from a first user to a second user; and circuitry for presenting, via the computing device, one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining. In addition to the foregoing, other system aspects are described in the claims, drawings, and text forming a part of the present disclosure.","An article of manufacture including a non-transitory storage medium bearing one or more instructions for determining that a computing device that was presenting an item has been transferred from a first user to a second user; and one or more instructions for presenting, via the computing device, one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining. In addition to the foregoing, other computer program product aspects are described in the claims, drawings, and text forming a part of the present disclosure.","A method for determining that a computing device that was presenting an item has been transferred from a first user to a second user, wherein said determining that a computing device that was presenting an item has been transferred from a first user to a second user is performed via at least one of a machine, article of manufacture, or composition of matter; and for presenting, via the computing device, one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining.","The foregoing summary is illustrative only and is not intended to be in any way limiting. In addition to the illustrative aspects, embodiments, and features described above, further aspects, embodiments, and features will become apparent by reference to the drawings and the following detailed description.","In the following detailed description, reference is made to the accompanying drawings, which form a part hereof. In the drawings, similar symbols typically identify similar components, unless context dictates otherwise. The illustrative embodiments described in the detailed description, drawings, and claims are not meant to be limiting. Other embodiments may be utilized, and other changes may be made, without departing from the spirit or scope of the subject matter presented here.","Advances in computing technologies and related technologies (e.g., visual display technology, battery technology, etc.) in recent years have greatly facilitated in the development of computing devices having increasingly smaller form factors while still maintaining exceptional processing capabilities. Examples of such computing devices include, for example, laptops, Netbooks, tablet computers (i.e., \u201cslate\u201d computers), e-readers, Smartphones, and so forth. Because of their compactness, such devices are becoming much easier to share among multiple users. That is, due to their small form factors, such devices allow users of such devices to easily hand-off such devices to friends, family, co-workers, clients, and so forth, in order to share the content and\/or applications being presented through such devices.","For example, suppose a user of a tablet computer is reading an electronic book (e.g., an eBook, a digital book, etc.) through the tablet computer. While reading the electronic book, the user comes across an interesting passage (e.g., a paragraph) located on a particular portion of a particular page of the electronic book that the user wants to share with a friend sitting across a table from the user. Typically, in order to show the passage of interest to the friend, the user will simply pass or handover the tablet computer to the friend thereby allowing the friend to view the passage that the user was interested in. Unfortunately, by simply passing the tablet computer to the friend, the tablet computer, along with displaying the passage of interest, may also be displaying many other passages from the electronic book that may not be of interest to the user (or the friend), thus making it difficult for the friend to easily find the passage of interest without the help of the user. And even after the user helps the friend find the passage of interest, the friend may not be able to digest the passage of interest because it may not be in a format that is easily digestible by the friend (e.g., if the friend is elderly and has poor eyesight and the passage may be in a textual format that is too small to read or if the friend does not read the language that the passage is written in, such as English, then the friend may not be able to understand the passage).","Suppose further that the same user uses a tablet computer at work for a variety of tasks including, for example, to electronically sign documents. Typically business contracts are signed by a number of people including, for example, the owners or representatives of business, clients, vendors, etc. For various legal and business reasons, contracts that are typically signed in the business context (as well as in familial and personal context) tend to be highly complex and difficult to decipher. Thus, it is often difficult and cumbersome for signers of such electronic documents to quickly and easily figure out where in such documents do the signers actually write their signatures upon receiving the tablet computer that the documents are being displayed through.","In accordance with various embodiments, computationally implemented methods, systems, and articles of manufacture are provided that can determine whether a computing device (e.g., a portable or mobile computing device such as a tablet computer, an e-reader, a smartphone, and so forth) that was presenting an electronic item (e.g., an application or an application interface, a productivity document such as a word processing or spreadsheet document, an audio file, a video file, an image file or folder, a website, an electronic or digital book, and so forth) has been transferred from a first user to a second user; and to visually and\/or audibly present, via the computing device, one or more highlighted portions of the electronic item (herein simply \u201citem\u201d), the one or more highlighted portions being highlighted in response, at least in part, to determining that the computing device has been transferred from the first user to the second user. In various embodiments, a computing device may be defined as an electronic device having electronic circuitry for executing one or more functionalities. In some cases, a computing device may include one or more processors (e.g., microprocessors, central processing units or CPUs, array processors, vector processors, controllers, and so forth).","In various embodiments, the computing device may have been transferred from the first user to the second user when control over the computing device has been transferred from the first user to the second user. For these embodiments, a user (e.g., the first user or the second user) may have control over the computing device when, for example, the user is, relative to other users, nearest or closest to the computing device, when the user is situated in a particular location relative to the particular orientation of the computing device (e.g., when the user is located on the side of the computing device that a display device is located at and is centered with respect to the display device), and\/or when the user has physical possession of the computing device such as by holding the computing device with one or two hands or by simply being in physical contact with the computing device. Thus, a transfer of a computing device from a first user to a second user may have occurred when, for example, the second user replaces the first user as being nearest to the computing device, when the second user replaces the first user generally at a particular location relative to the specific orientation of the computing device and\/or when the possession of the computing device transfers from the first user to the second user.","As will be described in greater detail herein, a portion of an item may be highlighted in a variety of different ways in various alternative embodiments. For example, in some cases, highlighting of the portion of the item may be by formatting (e.g., font style or size, color scheme, brightness, zoom view, increased audio volume or audio bass, language, and so forth) the portion differently from how the portion was formatted prior to the transfer of the computing device and\/or by having a format that is different from the format of non-highlighted portions of that item that may be concurrently presented with the highlighted portions. Alternatively or additionally, a portion of the item may be highlighted by simply encircling the portion with a boarder or boarders such as a line.","As will be further described herein, the portion or portions of the item to be highlighted as well as the type of highlighting that may be applied to the portion or portions may depend on which user is the computing device being transferred to. For example, in some cases, the determination as to whether the computing device has been transferred from a first user to a second user may include an operation to identify the second user, and based on the identification of the second user select the appropriate portion or portions of the item to highlight and\/or the type or types of highlighting to apply. In some embodiments, the second user may be identified based on the biometric characteristics or gestures exhibited by the second user.","Referring now to  illustrating a computing device * in the form of a tablet computer in accordance with various embodiments. For the embodiments, the computing device * may have at least a front-side that includes a display device  (e.g., a display monitor such as a touch screen), and a back-side (not visible in ) that is opposite of the front-side . As further illustrated in , the front-side of the computing device * may include a center  (note that in  a center axis has been drawn-in that represents an axis originating from the center  of the front-side of the computing device * and perpendicular to the surface of the front-side of the computing device *). In various embodiments, the front-side of the computing device * may include one or more camera lens or viewing ports  (e.g., one or more viewing ports  for one or more cameras including one or more digital cameras, webcams, infrared cameras, and\/or other types of image capturing devices) and\/or one or more audio ports  (e.g., one or more audio ports for one or more microphones).","Note that although the front-side of the computing device * of  is illustrated as having three viewing ports  for three image capturing devices  (see ) and three audio ports  for three audio capturing devices  (see ), in alternative embodiments, the front-side may include alternative number of viewing ports  and\/or audio ports  than what is depicted in . Further, and although not shown in , in various embodiments, the backside of the computing device * may also include one or more viewing ports  and\/or audio ports . Note that and illustrate two different implementations of the computing device * of  illustrated in as computing device \u2032 and in as computing device \u2033. Note further that for purposes of the following, \u201c*\u201d represents a wildcard. Thus, references in the following to the \u201ccomputing device *\u201d may be in reference to the computing device * of  as well as to the computing device \u2032 of or the computing device \u2033 of . Although the computing device * illustrated in  is depicted as being a tablet computer, in alternative embodiments, the computationally implemented methods, systems, and articles of manufacture in accordance with various embodiments may be embodied in other types of computer systems having other form factors including form factors of other types of portable computer devices such as, for example, laptops, Netbooks, Smartphones, e-readers, and so forth.","Referring now to illustrating the computing device * of  in an exemplary environment  being transferred between two users (e.g., a first user  and a second user ). As will be further described herein the illustrated computing device * may employ the computationally implemented methods, systems, and articles of manufacture in accordance with various embodiments. The computing device *, in various embodiments, may be endowed with logic that is designed to determine that the computing device * that was presenting item (in , the item being presented is a word processing document ) has been transferred from a first user  to a second user ; and visually and\/or audibly present automatically one or more highlighted portions of the item (e.g., word processing document ), the one or more highlighted portions being highlighted in response, at least in part, to determining that the computing device * has been transferred from the first user  to the second user . The computing device * or its endowed logic may further be designed to select the portion or portions of the item to be highlighted and\/or to select the type of highlighting to be applied to the portion or portions of the item by identifying the second user .","There are a number of ways to determine whether a computing device * is or has been transferred from one user to another user. For instance, in some cases, various sensor-provided data may be collected in order to make such a determination. Such data may indicate various environmental aspects surrounding the computing device * and\/or aspects of the computing device * itself (e.g., movements displayed or exhibited by the computing device * as a result of being in contact with one or more users). For example, when the computing device * of  is passed from, for example, the first user  to another user such as the second user , the first user  may make certain recognizable as well as detectable gestures. Such gestures may include, for example, the first user  extending his\/her arms out with the computing device * in one or both hands (e.g., as if to offer the computing device * to the second user ); the first user  passing the computing device * from one hand to another hand, and extending the second hand with the computing device * out and away from the first user ; the first user  rotating the computing device * around using his\/her hands so that the front side of the computing device * faces away from the first user  and faces the second user , who is standing or sitting across from the first user , and so forth. These movements or gestures made by the first user , when detected, may at least infer that the transfer (e.g., change in possession) of the computing device * from a first user  to a second user  has occurred.","One way to track the movements or gestures of the first user  is to track the movements of the computing device * itself (note that another way to detect the gestures of the first user  is to observe visually the gestures\u2014visual cues\u2014exhibited by the first user  via one or more image capturing devices , which will be described in greater detail below). That is, these gestures that may be exhibited by the first user  during the transfer of a computing device * from the first user  to the second user  may cause the computing device * to be spatially moved in particular ways. Thus, in order to detect whether a computing device * is being transferred from a first user  to a second user , the spatial movements of the computing device * may be tracked in order to detect signature movements that when detected as occurring at least infer the transfer of the computing device * between the first user  and the second user . For example, the computing device * may maintain in its memory  (see and ) a movement library  (see and ), which is a catalog or library that identifies those signature spatial movements that when detected as occurring at least infers (e.g., implies) that a transfer of the computing device * has occurred between two users (e.g., first user  and second user ).","One way to monitor for such movements of the computing device * is to directly detect such movements using one or more \u201cmovement\u201d sensors that are designed to directly detect\/measure spatial movements of the computing device *. Examples of such movement sensors include, for example, inertia sensors, accelerometers (e.g. three-axis or 3D accelerometers), gyroscopes, and so forth. These sensors (herein movement sensors \u2014see which illustrates one or more types of sensors  that may be included in the computing device * of ) when integrated with a computing device * may be used to directly detect\/track the actual spatial movements\/motions of the computing device * as the computing device * is being transferred from, for example, a first user  to a second user  (or from the second user  back to the first user ).","Since not all movements of the computing device * that may be detected will be as a result of the computing device * being transferred between two users, in various embodiments and as will be further described herein, the computing device * may be endowed with particular logic for determining (e.g., identifying) which movements associated with the computing device * that have been detected indicates or at least suggests that the computing device * is or has been transferred from, for example, a first user  to a second user  and which detected movements may merely be \u201cnoise movements.\u201d","Various types of movements of the computing device * may be tracked in order to determine or at least infer that the computing device * is being transferred between, for example, a first user  and a second user . Examples of the types of movements that may be tracked include, for example, the overall three-dimensional movements of the computing device *, or specific types of movements including tilt type movements, spin-rotation type movements, spatial relocation type movements, vibration movements, and so forth of the computing device *. In order to determine or at least infer that the computing device * has been transferred from a first user  to a second user , these movements of the computing device * may be, individually or in combination, tracked using one or more sensors  that may be included with the computing device * as illustrated in . For example, in various embodiments, one or more movement sensors  (e.g., inertia devices, accelerometers, etc.) that can directly detect movements, and\/or other types of sensors (e.g., image capturing devices , audio capturing devices , etc.) that may be able to indirectly detect movements may be employed in order to track the movements of the computing device * as will be further described herein.","Referring now to illustrating various types of tilts and tilt movements of the computing device * that may be detected and monitored using one or more sensors  (e.g., one or more movement sensors ) in order to, for example, determine or infer that the computing device * has been transferred between two users (e.g., from the first user  to the second user  or from the second user  to the first user ) in accordance with various embodiments. That is, shows the backside of the computing device * and some of the tilt-type movements that may be monitored by the computing device * in order to determine whether the computing device * has been transferred from, for example, a first user  to a second user  (or vice versa). Note that for ease of illustration and understanding the computing device * in (as well as in , , and ) is not drawn to scale at least with respect to the first user  and the second user .","One type of tilt that may be detected\/monitored is tilt of the computing device * that may occur when the computing device * is at least partially rotated around a central horizontal axis . A second type of tilt that may be detected is tilt , which may occur when the computing device * is at least partially rotated around a bottom horizontal axis . Although not depicted, another type of tilt that may occur and that may be monitored is when the computing device * is at least partially rotated around an angular axis that is angular with respect to a horizontal axis (e.g., axis or ) and is parallel to the plane of the backside similar to axis and axis . Yet another type of tilt that may occur and that may also be monitored is when the computing device * is at least partially rotated around a vertical axis . Note that although the vertical axis is depicted as being centered along the backside of the computing device *, just like the horizontal axis , the vertical axis does not have to be centered on the backside and instead, may be offset from the center of the backside of the computing device *(e.g., may be closer to one end of the device rather than an opposite end of the device. Although only a few types of tilts were illustrated in , those of ordinary skill in the art will recognize that other types of tilts or tilt movements of the computing device * may alternatively or additionally be monitored in various alternative implementations in order to determine whether the computing device * has been transferred between two users.","By detecting that the computing device * has been tilted in a particular manner from a first tilt orientation to a second tilt orientation, a determination or an inference may be made that the computing device * has been transferred from the first user  to the second user . In particular, when the first user , for example, is handing off or transferring the computing device * to the second user , the first user  may tilt the computing device * in a particular way that may be identifiable. Thus, when the computing device * is being transferred from a first user  to a second user  (or vice versa), the computing device *(or rather the logic endowed with the computing device *) may track the movements of the computing device * as it moves from a first tilt orientation (e.g., the tilt of the computing device * at the beginning of the transfer or when the first user  was using or had possession of the computing device *) to a second tilt orientation (e.g., the tilt of the computing device * at the end of the transfer or when the second user , for example, has obtained possession of the computing device *).","In order to make a determination or at least an inference that a transfer was made between two users such as from the first user  to the second user  (or vice versa), the computing device * or at least the logic endowed in the computing device * may track and examine the particular movements of the computing device *(e.g., how the computing device * was reoriented from a first tilt orientation to a second tilt orientation including speed and cadence of the reorientation) as the computing device * moves from the first tilt orientation to a second tilt orientation. The computing device * may additionally or alternatively analyze the second tilt orientation (e.g., the tilt of the computing device * after it has finished being reoriented) at least with respect to the first tilt orientation in order to determine or infer that the computing device * has been transferred. To further determine or at least infer that the computing device * has been transferred from the first user  to the second user , for example, the examination\/analysis of the detected tilt movements of the computing device * may involve comparing the detected tilt movements of the computing device * with catalogued or library tilt movements (which may be stored in the memory  of the computing device *) that are identified as being movements associated with transfer of the computing device * between two users.","That is, the computing device * may maintain in its memory  (see and ) a movement library  that may include a catalogue or library of movements including signature tilt movements that have been previously identified as tilt movements that may occur when, for example, a computing device * is transferred between two users (e.g., first user  and second user ). Thus, when tilt movements that match with catalogued or library tilt movements (e.g., signature tilt movements) have been detected, then a determination or at least an inference may be made that a transfer of the computing device * between two users has occurred. Note that the above discussed tilt movements relates to the movement of the computing device * as it moves from a first tilt orientation to a second tilt orientation.","Thus, another aspect of tilt orientation changes that may be considered in order to determine or infer that a transfer has taken place is to simply look at the end points of the tilt reorientation and their differences. In other words, to analyze the first tilt orientation (e.g., the tilt orientation of the computing device * before the computing device * being reoriented) and the second tilt orientation (e.g., the end tilt orientation of the computing device * after it has been reoriented) with respect to each other, and the differences between the first tilt orientation and the second tilt orientation. Thus, in some embodiments, the computing device * may also or additionally maintain a catalogue or library of changes of tilt orientation (e.g., tilt orientation changes) that have been previously identified as tilt changes that occur when, for example, a computing device * is transferred between two users. Such catalogue or library of tilt orientation changes may be stored as part of a movement library  stored in memory  (see and ) of the computing device * of  (e.g., the computing device \u2032 of or the computing device \u2033 of ). Therefore, when tilt orientation changes that match with catalogued or library tilt orientation changes (e.g., as stored in the movement library  of the memory ) have been detected, then at least an inference may be made that a transfer of the computing device * between two users has occurred.","Referring now to illustrating another type of movement of the computing device * that may be detected\/monitored in order to determine or at least infer that the computing device * has been transferred between two users. In particular, shows a couple types of spin rotation and spin rotation movements of the computing device * that may be detected\/tracked using one or more sensors  (e.g., one or more movement sensors ) in order to determine or infer that a transfer of the computing device * has occurred between at least two users. Note that this type of rotation (e.g., spin rotation) is different from the type of rotation associated with the previously described tilt movement where the \u201ctilt\u201d rotation involves the entire backside of the computing device * rotating around some axis in a sweeping motion. In a spin rotation, the backside (or the front side ) of the computing device * substantially spins around an axis without the sweeping motion.","Referring back to , which shows some of the various types of spin rotations that may be detected\/monitored by the computing device * in order to, for example, determine whether the computing device * has been transferred between two users such as, for example from a first user  to a second user  (or vice versa). Examples of the type of spin rotations that may be monitored include a spin rotation of the computing device * that occurs when the computing device * is rotated around a center axis that is centered and vertical to the backside of the computing device *. Another type of rotation that may be monitored is a spin rotation of the computing device * that occurs when the computing device * is rotated around a center axis that may be centered but not vertical to the backside of the computing device *. Instead, the center axis is angular to the backside of the computing device * such that when the computing device * is rotating around the center axis , the computing device * will have a constant tilt with respect to the center axis . Another type of rotation that may be monitored is spin rotation of the computing device * that may occur when the computing device * is rotated around an axis that may not be centered on the backside of the computing device * and that may not be vertical to the backside of the computing device *.","By detecting that the computing device * has been spin rotated in a particular manner, a determination or an inference may be made that the computing device * has been transferred from the first user  to the second user . In particular, when the first user  is, for example, handing off or transferring the computing device * to the second user , the first user  may spin rotate the computing device * in a particular way. Thus, when the computing device * is being transferred from, for example, the first user  to the second user , the computing device *(or rather the logic endowed with the computing device *) may track the movements of the computing device * as it moves from a first spin orientation (e.g., the orientation of the computing device * at the beginning of the transfer or when the first user  was using the computing device *) to a second spin orientation (e.g., the orientation of the computing device * at the end of the transfer or when the second user  has obtained possession of the computing device *).","Similar to the tilt or tilt movement detection\/analysis described earlier, in order to make a determination or at least an inference that a transfer was made from, for example, the first user  to the second user  (or vice versa), the computing device * or at least the logic endowed in the computing device * may scrutinize the particular movements of the computing device * as the computing device * spin rotates from a first orientation to a second orientation. The computing device * may additionally or alternatively analyze the second orientation (e.g., the orientation of the computing device * after it has finished being spin rotated) at least with respect to the first orientation (e.g., the orientation of the computing device * before it was spin rotated) in order to determine or at least infer that the computing device * has been transferred.","To further determine or at least infer that the computing device * has been transferred from the first user  to the second user , the examination\/analysis of the detected spin rotation of the computing device * from the first orientation to the second orientation may involve comparing the detected spin rotation movement of the computing device * with catalogued or library spin rotation movements that are identified as being associated with transfer of the computing device *. That is, the computing device * may maintain in its memory  (see and ) a movement library  that may include a catalogue or library of movements including signature spin rotation movements that when detected as occurring may infer that a transfer of the computing device * between two users has occurred.","Turning now to illustrating yet another type of movement of the computing device * that may be detected\/monitored in order to determine or infer that the computing device * has been transferred between two users. In particular, shows the computing device * being relocated by moving from a first spatial location  to a second spatial location  when the computing device * is transferred between two users such as from a first user  to a second user  (or vice versa). In various embodiments, such movements from the first spatial location  to the second spatial location , which will be referred to herein as \u201cspatial relocation movements,\u201d may be detected using one or more sensors  (e.g., one or more movement sensors ). In order to make a determination or inference that a transfer was made from the first user  to the second user , the computing device * or at least the logic endowed in the computing device * may examine\/analyze the particular spatial relocation movements of the computing device * as it moves from the first spatial location  to the second spatial location , and to compare the pattern of spatial relocation movements (e.g., path, speed, acceleration, and so forth) with those catalogued or library signature spatial movements stored in a movement library  that when detected as occurring at least infers that the computing device * has been transferred between at least two users (e.g., between a first user  and a second user ).","In some cases, the computing device *(or rather the logic endowed with the computing device *) may additionally or alternatively analyze the second spatial location  with respect to the first spatial location  in order to determine or at least infer that the computing device * has been transferred from the first user  to the second user . To further determine or at least infer that the computing device * has been transferred from, for example, the first user  to the second user , the examination\/analysis of the detected spatial relocation movements of the computing device * may be compared with catalogued or library signature spatial relocation movements that have been identified as being associated with the transfer of the computing device  between two users. That is, the computing device * may maintain in its memory  (see and ) a movement library  that may include a catalogue or library of movements including signature spatial movements that when detected as occurring may at least infer that a transfer of the computing device * between two users has occurred.","In some embodiments, in order to determine or at least infer that the computing device * has been transferred from the first user  to the second user  (or vice versa), the computing device * may be endowed with logic that detects\/monitors vibrations. That is, each user who may come in contact with the computing device * may pass on to the computing device * unique vibration pattern or signature (e.g., as a result of the heartbeat of the \u201ctouching\u201d user). Thus, when the first user  is holding the computing device *, the computing device * may vibrate in a particular vibration pattern that is associated with the first user . In contrast, when the computing device * has been transferred to the second user  and the second user  is holding the computing device *, the computing device * may vibrate in a manner that is associated with the second user . Therefore, one way to determine whether the computing device * has been transferred from the first user  to the second user  (or vice versa) is to detect\/monitor at least changes in vibrations exhibited by the computing device *.","In some cases, this may involve the computing device *(or at least the logic endowed with the computing device *) initially detecting the particular vibration pattern of the computing device * when the computing device * is being held by, for example, the first user , and to detect when the computing device * no longer vibrates in such a manner. In order to determine whether the computing device * has been transferred from the first user  to the second user , the computing device * in some cases may be further designed to determine that the computing device * is vibrating in a way that matches with a vibration pattern (e.g., signature vibration pattern) of the second user . By making such a determination, an inference may be made that the computing device * is being held or is in contact with the second user .","In some embodiments, the computing device * may include logic that is designed to determine whether the computing device * has moved away from the first user  in order to determine whether, for example, the computing device * has been transferred from the first user  to the second user . That is, by making such a determination, at least an inference may be made that the computing device * has been transferred from the first user  to the second user . In some embodiments, in order to make such a determination, data from a combination of sensors  may be processed and analyzed. That is, in order to determine whether the computing device  has moved away from, for example, the first user , a combination of one or more movement sensors  (see ) for directly detecting movements of the computing device *, one or more image capturing devices  (e.g., webcam or digital camera), and\/or one or more audio capturing devices  (e.g., microphones) may be employed in order to determine whether the computing device * is moving away from the first user  (and thus, an inference that the computing device * has been transferred to the second user ).","For example, the computing device * in some cases may employ one or more movement sensors  to detect the actual movements of the computing device * and one or more image capturing devices  (along with facial recognition system\/application) to determine that a face associated with the first user  is moving away from the computing device * and\/or to detect gestures made or exhibited by the first user  (e.g., such as the first user extending his\/her arm out as to offer the computing device  to another user) that at least infers that the computing device * is moving away from the first user . Based on the data provided by both the movement sensors  and the image capturing devices , at least an inference may be made that the computing device * has moved away from the first user *.","In some embodiments, and as illustrated in , rather than only detecting\/monitoring for a particular type of movement (e.g., tilt-type movements, spin rotation movements, spatial relocation movements, vibration movements, and so forth) the computing device * may be endowed with logic that is designed to detect\/monitor\/track the overall three-dimensional movements of the computing device * and to determine whether the computing device * has moved in a particular three-dimensional way that at least infers that the computing device * has been transferred from the first user  to the second user . In order to accomplish this, the computing device * may maintain in its memory  (see and ) a movement library  that may include a catalogue or library of movements including signature three-dimensional movements that when detected as occurring may infer at least that a transfer of the computing device * between two users has occurred.","As described briefly above, in addition to directly detecting the movements of the computing device * using movement sensors  (e.g., inertia sensors, accelerometers, gyroscopes, and so forth), other types of environmental aspects may be detected\/monitored in order to determine whether the computing device * has been transferred from a first user  to a second user . For instance, in some cases, the computing device * or the logic endowed with the computing device * may be designed to detect, using one or more image capturing devices , certain visual cues that when detected at least infers the transfer of the computing device * from a first user  to a second user . For example, in some embodiments, the computing device * may be endowed with certain logic that is able to detect certain visual cues, such as gestures made by a first user  that when visually detected as occurring at least infers that the computing device * has been transferred from the first user  to another user. In the same or alternative embodiments, the computing device * may additionally or alternatively be endowed with logic that at least detects, via one or more image capturing devices , changes in lighting in the proximate vicinity of the computing device *. That is, generally when an object is moved from one spatial location to another spatial location, as in the case of a computing device * being transferred between two users, the object will be exposed to changes in lighting conditions. Thus, by merely detecting changes in lighting conditions of the computing device *, at least an inference may be made that the computing device * is being transferred between users.","Alternatively or additionally, in some embodiments, the computing device * may be endowed with a facial recognition system (e.g., facial recognition software or application) that when employed with one or more image capturing devices  may be used in order to determine the presence or absence of a face associated with the first user  or the second user  within the proximate vicinity of the computing device *. If the face associated with the first user  is not detected in the proximate vicinity of the computing device * and\/or if a face not associated with the first user  is detected in the proximate vicinity of the computing device *, such as the face of the second user , then a determination or at least an inference may be made by the computing device * or by the endowed logic of the computing device * that a transfer of the computing device * from the first user  to the second user  may have occurred. The phrase \u201cproximate vicinity\u201d as used here is in reference to the immediate area surrounding the computing device * such as within a distance from the computing device * from which an object or a person is visually (or audibly) discernable or identifiable by the computing device * using, for example, a facial recognition system (or a voice verification\/recognition system). Depending on sensitivity of the various systems, this may mean the immediate area around the computing device * that is within three feet, within five feet, within six feet, and so forth, of the computing device *.","In some cases, an inference that the computing device * has been transferred from, for example, the first user  to the second user  will not be made at least until the computing device *(or the logic endowed with the computing device *) determines that the face of a person other than the first user  is detected as being in the proximate vicinity of the computing device * and is detected as being located at one or more specified locations relative to the specific orientation of the computing device *. For example, in some cases, the inference that the computing device * has been transferred from, for example, the first user  to the second user  will not be made at least until it is determined that the face of the second user  is determined to be in the proximate vicinity of the computing device * and is detected as being at or near the center axis of the display side (e.g., front side ) of the computing device *. Note that since the computing device * may be endowed with multiple sensors  (e.g., image capturing devices  and\/or audio capturing devices ) located on both the front side as well as the backside of the computing device *, it may be possible to detect the presence of a person or a face of the person on either side of the computing device *.","Another type of visual cues that the computing device * or the endowed logic of the computing device * may look for in order to determine whether the computing device * has been transferred from, for example, a first user  to a second user  is the presence or absence of one or more eyes (e.g., irises or retinas) in the proximate vicinity of the computing device * that are determined to be associated with the first user  or the second user . In particular, if the eyes of the first user  is determined not to be at least in the field of view of an image capturing device  (e.g., an image capturing device  that employs the viewing port  disposed on the front side ) of the computing device * and\/or if one or more eyes of another person (e.g., second user ) other than the first user  is determined to be in the field of view of the image capturing device , then at least an inference may be made that the computing device * has been transferred from the first user  to the second user .","In some cases, an inference that the computing device * has been transferred from for example, the first user  to the second user  (or vice versa) will not be made until the computing device  (or at least the logic endowed with the computing device *) determines that the eye of a person other than the first user  is detected in the proximate vicinity of the computing device * and is detected as being located at one or more specified locations (e.g., near or along the center axis of the front side ) relative to the specific orientation of the computing device *. In other words, the inference or determination that the computing device * has been transferred from the first user  to the second user , for example, will not be made at least until it is determined that the eye or eyes of the second user  is determined to be in the proximate vicinity of the computing device * and is detected as being at one or more specified locations on the display side (e.g., the front side ) of the computing device *.","In various embodiments, the computing device * or at least the logic that may be endowed with the computing device * may be designed to detect and\/or track absence or presence of one or more audio cues in the proximate vicinity of the computing device * in order to determine or at least infer as to whether the computing device * has been transferred from, for example, a first user  to a second user  (or vice versa). For example, in some embodiments, the computing device * may be endowed with voice verification system or application that may be designed to detect, via one or more audio capturing devices  (e.g., one or more microphones), a voice in the proximate vicinity of the computing device * having a voice pattern that may be different from the signature voice pattern of the first user . By making such a determination and\/or by detecting absence for at least a predefined period of time of a voice pattern associated with the first user  in the proximate vicinity of the computing device *, an inference may be made that the computing device * has been transferred from, for example, the first user . In some embodiments, an inference may be made that the computing device * has been transferred from, for example, the first user  to the second user  when a voice pattern belonging to a person other than the first user  is detected in the proximate vicinity of the computing device * and is detected being originating from a point on the display side (e.g., the front side ) of the computing device *.","In some embodiments, the computing device * or at least the logic endowed with the computing device * may be designed to determine the transfer of the computing device * from the first user  to the second user  based on combination of one or more detected movements of the computing device *, one or more detected visual cues, and\/or one or more detected audio cues. That is, since in many situations, a particular type of data or measurement (e.g., detected movements of the computing device * or detected visual cues in the proximate vicinity of the computing device *) may not reliably or conclusively indicate that the transfer of the computing device * from the first user  to the second user  has occurred, in various embodiments, the computing device * may make the determination as to whether the computing device * has been transferred based on different types of measurements (e.g., movements of the computing device *, visual cues, and\/or audio cues).","As described earlier, in response to determining that the computing device * has been transferred from the first user  to the second user , the computing device * or at least the logic that may be endowed with the computing device * may selectively highlight one or more selective portions of the item that was being presented by the computing device * prior to the transfer of the computing device * from the first user  to the second user . In some cases, the one or more portions to be highlighted may be based, at least in part, to a selection made by a user, such as the first user , as to which portion or portions of the item are to be highlighted. Alternatively or additionally the selection of which portion or portions to be highlighted may be based on determining which portion or portions are associated with the second user . In order to make such a determination, the computing device * or its endowed logic may be designed to identify the second user  based on, for example, biometric data collected using one or more sensors . These concepts will be described in greater detail herein.","Referring now to illustrating various ways that selective portions of an example item that is being presented through the display device  (e.g., a touch screen) of the computing device * may be selected by a user for highlighting. In this example illustration, the item being presented is an electronic or digital book. In particular, shows a page from the electronic book that is made up of several paragraphs, and three of the paragraphs , , and  are selected for highlighting using three different approaches. For purposes of this illustration, each paragraph , , and  that is presented through the display device  represents a portion of the example item that may or may not be highlighted. In various embodiments, the user may not need to select a portion (e.g., a paragraph) of the item entirely (e.g., select or tag an entire paragraph such as paragraph ) in order to have the entire portion of the item highlighted. Instead, the user may merely select (e.g., tag or mark) only part of the portion of the item in order to have the entire portion highlighted. For example, in some embodiments, an entire paragraph  may be selected for highlighting when a user writes (e.g., write via a touch screen or via a mouse) an \u201cx\u201d on part of the paragraph  (e.g., a portion of the example item ) that the user wishes to highlight. In some embodiments, a user may also designate an entire paragraph  for highlighting by drawing an encircling line  around the paragraph . In the same or different embodiments, a user may select a paragraph  (e.g., a portion of the item ) for highlighting by drawing a line  along the side of the paragraph . In still other cases, in order to select a portion (e.g., paragraphs , , or  of ) of an item for highlighting, a user may simply have to click (if there is a mouse available) or tap (if a touch screen is being used to view the item ) on a part of the portion of the item to be highlighted.","Referring now to , and , which illustrates some of the ways in which portions of an example item may be highlighted. Referring particularly now to , which illustrates a highlighted portion (which corresponds to paragraph  of ) of the example item of being highlighted in a particular way. In this example, the highlighted portion being highlighted by having a different background color from background color of the unhighlighted portions of the example item ","Turning now to illustrating another highlighted portion (which again corresponds to paragraph  of ) of the example item of being highlighted in another way. In this example, the highlighted portion being highlighted by having text that has a font style (e.g., bigger font and bolded) that is different from the font style of the text included in the unhighlighted portions of the example item ",{"@attributes":{"id":"p-0087","num":"0102"},"figref":["FIG. 7","FIG. 7","FIG. 7"],"i":["d ","d ","a","a ","a ","d "],"b":["702","742","701","702","706"]},{"@attributes":{"id":"p-0088","num":"0103"},"figref":["FIGS. 7","FIG. 7"],"i":["e ","f ","b ","e","b","b ","a "],"b":["7","701","10","20","30","20","30","10","701","10","701","10","10","10","17","10"]},"In response to a determination that the computing device * is in the control of or is being possessed by Freddy (e.g., first user ), which could be based on detected biometric characteristics (e.g., face, eye, voice, movement, etc.) of Freddy in the proximate vicinity of the computing device *, only portion of the example item may be highlighted. That is, the computing device * may be endowed with logic that is able to automatically identify Freddy using, for example, sensors  that detect biometric characteristics of Freddy, and based on the identification as well as determining that Freddy has control (possession) of the computing device * and determining which portions of the item are associated with Freddy (or his identity), the appropriate portion or portions of the item may be highlighted.","After Freddy (e.g., first user ) has signed the item (e.g., electronic contract) at the portion of the item that has been highlighted, Freddy may then transfer or hand-off the computing device * to Mike Mouse (e.g., second user ) so that Mike can sign the example item . Turning now to , the computing device *, upon detecting that the computing device * has been transferred to Mike Mouse, and upon identifying Mike (e.g., identifying based on biometric characteristics exhibited by Mike) and ascertaining that portion of item is associated with Mike Mouse (or his identity), may alternatively highlight portion while unhighlighting portion of the item that was previously highlighted before the transfer of the computing device * when Freddy still had possession of the computing device *. Thus, in this example illustrated by and , different portions and of an item may be highlighted based on their association with different users and based on ascertaining who has, for example, obtained possession of the computing device *.","Referring now to and , and are two block diagrams representing two different implementations of the computing device * of  illustrated in as computing device \u2032 and in as computing device \u2033. In particular, and as will be further described herein, illustrates a computing device \u2032 that is the \u201chardwired\u201d or \u201chard\u201d implementation of the computing device * of  in which certain logic modules including a transfer determining module \u2032, a highlighted portion presenting module \u2032, and a highlighting selection detecting module \u2032 are implemented using purely hardware or circuitry components (e.g., application specific integrated circuit or ASIC). In contrast, illustrates a computing device \u2033 that is the \u201csoft\u201d implementation of the computing device * of  in which certain logic modules including a transfer determining module \u2033, a highlighted portion presenting module \u2033, and a highlighting selection detecting module \u2033 are implemented using electronic circuitry such as one or more processors (e.g., microprocessors, controllers, etc.) executing one or more programming instructions (e.g., software).","Note that the embodiments of the computing device * illustrated in and are two extreme or opposite versions\/implementations of the computing device * of  in which certain logic modules (e.g., the transfer determining module *, the highlighted portion presenting module *, and the highlighting selection detecting module *) are implemented using purely \u201chardware solutions\u201d (e.g., implemented using circuitry such as ASIC) as illustrated in , or using purely \u201csoftware solutions\u201d (e.g., implemented using software executed by hardware such as one or more processors ) as illustrated in . That is, those of ordinary skill in the art will recognize that the computing device * or at least the logic modules (e.g., the transfer determining module *, the highlighted portion presenting module *, and the highlighting selection detecting module *) illustrated in , , , and may be implemented using essentially any combination of hardware and software solutions. Since, there are many ways of combining hardware, software, and\/or firmware in order to implement the various logic modules (e.g., the transfer determining module *, the highlighted portion presenting module *, and the highlighting selection detecting module *), only the two extreme implementations (e.g., the purely hardware solution as illustrated in and the software solution of ) are illustrated here. It should be noted here that with respect to the \u201csoft\u201d implementation illustrated in , hardware in the form of circuitry such as one or more processors  are still needed in order to execute the software. Further details related to the two implementations of computing device * illustrated in and will be provided in greater detail below.","Referring particularly now to , which illustrates a computing device \u2032 that includes a transfer determining module \u2032, a highlighted portion presenting module \u2032, a highlighting selection detecting module \u2032, a memory that may store one or more applications  (e.g., an operating system (OS) , one or more productivity applications  such as a word processing application and\/or spreadsheet application, one or more communication applications  such as an email or text messaging application, one or more personal information manager applications  such as Microsoft Outlook, one or more facial recognition applications , one or more voice recognition applications , one or more retinal scanning applications , and\/or other applications including gaming applications) and\/or a movement library , one or more processors  (e.g., microprocessors, controllers, etc.), one or more sensors , user interface  (e.g., a display monitor such as a touchscreen, a keypad, a mouse, a microphone, a speaker, a camera, etc.), and a network interface  (e.g., network interface card or NIC).","In various embodiments, the transfer determining module \u2032 of is a logic module that is designed to determine that the computing device * has been transferred from the first user  to a second user . The highlighted portion presenting module \u2032 is a logic module that is designed to present one or more highlighted portions * of an item *, the item * having been presented by the computing device * when the computing device * was being transferred from the first user  to the second user , and the one or more highlighted portions * being highlighted in response, at least in part, to determining by the transfer determining module * that the computing device * has been transferred from the first user  to the second user . In contrast, the highlighting selection detecting module \u2032 is a logic module that is designed to, among other things, detect selection or designation by a user of one or more portions of an item * for highlighting. For this particular embodiment of the computing device * of , , , , , and , the three logic modules (e.g., the transfer determining module \u2032, the highlighted portion presenting module \u2032, and the highlighting selection detecting module \u2032) are implemented using purely circuitry components such as application specific integrated circuit or ASIC. Thus, and as indicated before, the computing device \u2032 illustrated in may be referred to as the \u201chardwired\u201d version or embodiment of the computing device * of , , , , , and (as well as to ).","Turning now to , which illustrates a \u201csoft\u201d version or embodiment of the computing device * of , , , , , , , , , , , and . In particular, shows a computing device \u2033 that has components similar or the same as the components of the computing device \u2032 of . That is, computing device \u2033, similar to computing device \u2032 of , may comprise of a memory  (storing one or more applications  and\/or a movement library ), one or more processors , one or more sensors , user interface , and\/or a network interface . And similar to the computing device \u2032 of , the computing device \u2033 of may include logic modules including a transfer determining module \u2033, a highlighted portion presenting module \u2033, and a highlighting selection detecting module \u2033 that correspond to and mirror the transfer determining module \u2032, the highlighted portion presenting module \u2032, and the highlighting selection detecting module \u2032 of the computing device \u2032 of . However, unlike the logic modules (e.g., the transfer determining module \u2032, the highlighted portion presenting module \u2032, and the highlighting selection detecting module \u2032) of the computing device \u2032 of , the logic modules (e.g., the transfer determining module \u2033, the highlighted portion presenting module \u2033, and the highlighting selection detecting module \u2033) of the computing device \u2033 of are implemented by the one or more processors  executing computer readable instructions  (e.g., software and\/or firmware) that may be stored in the memory .","Note that although illustrates all of the logic modules (e.g., the transfer determining module \u2032, the highlighted portion presenting module \u2032, and the highlighting selection detecting module \u2032) being implemented using purely circuitry components such as ASIC, and although illustrates all of the logic modules (e.g., the transfer determining module \u2033, the highlighted portion presenting module \u2033, and the highlighting selection detecting module \u2033) being implemented using one or more processors  executing computer readable instructions , in other embodiments, these logic modules may be implemented using a combination of specifically designed circuitry such as ASIC and one or more processors  (or other types of circuitry such as field programmable gate arrays or FPGAs) executing computer readable instructions . For example, in some embodiments, at least one of the logic modules may be implemented using specially designed circuitry (e.g., ASIC) while a second logic module may be implemented using a processor  (or other types of programmable circuitry such as FPGA) executing computer readable instructions  (e.g., software and\/or firmware).","In various embodiments, the memory  of the computing device \u2032 of and the computing device \u2033 of may comprise of one or more of mass storage device, read-only memory (ROM), programmable read-only memory (PROM), erasable programmable read-only memory (EPROM), cache memory such as random access memory (RAM), flash memory, synchronous random access memory (SRAM), dynamic random access memory (DRAM), and\/or other types of memory devices.","Turning now to illustrating a particular implementation of the transfer determining module *(e.g., the transfer determining module \u2032 or the transfer determining module \u2033) of and . As illustrated, the transfer determining module * may include one or more sub-logic modules in various alternative implementations. For example, in various implementations, the transfer determining module * may include a particular movement detecting module  (which may further include a tilt detecting module , a spatial location detecting module , a spin rotation detecting module , a moving away detecting module , a vibration detecting module , and\/or a three-dimensional movement detecting module ), a visual cue detecting module  (which may further include a lighting change detecting module , a face detecting module , an eye detecting module , a visual moving away detecting module , and\/or a gesture detecting module ), an audio cue detecting module  (which may further include an audio moving away detecting module  and\/or a voice pattern detecting module ), and\/or a user identifying module  (which may further include a biometric user identifying module ). Specific details related to the transfer determining module * as well as the above-described sub-modules of the transfer determining module * will be provided below with respect to the operations and processes to be described herein.","Referring now to illustrating a particular implementation of the highlighted portion presenting module *(e.g., the highlighted portion presenting module \u2032 or the highlighted portion presenting module \u2033) of and . As illustrated, the highlighted portion presenting module * may include one or more sub-logic modules in various alternative implementations. For example, in various implementations, the highlighted portion presenting module * may include a unhighlighted portion presenting module  and\/or a user association ascertaining module  that may further include a user identity association ascertain module  (which may further include a user identifying module ). Note that in some embodiments, the user identifying module  may be the same module as the user identifying module  of . Specific details related to the highlighted portion presenting module * as well as the above-described sub-modules of the highlighted portion presenting module * will be provided below with respect to the operations and processes to be described herein.",{"@attributes":{"id":"p-0100","num":"0115"},"figref":["FIG. 3","FIG. 3","FIG. 3","FIGS. 1"],"i":["e ","a ","b","a","b","c","d","e","a","b","c","d","e","f"],"b":["120","10","10","10","2","2","2","2","2","7","7","7","7","7","7","120","10","302","304","306","308"]},"A more detailed discussion related to the computing device * of , , , , , , , , , , , and (e.g., the computing device \u2032 of or the computing device \u2033 of ) will now be provided with respect to the processes and operations to be described herein.  illustrates an operational flow  representing example operations for, among other things, determining that a computing device * that was presenting an item *(e.g., a textual document or a portion thereof, an electronic or digital book or a portion thereof, an application or application interface or a portion thereof, a website or a portion thereof, an image file or a portion thereof, a video file or a portion thereof, or other types of electronic items) has been transferred from a first user  to a second user ; and presenting, via the computing device *, one or more highlighted portions * of the item *, the one or more highlighted portions * being highlighted in response, at least in part, to said determining that the computing device * has been transferred from the first user  to the second user . In  and in the following figures that include various examples of operational flows, discussions and explanations will be provided with respect to the computing device * described above and as illustrated in  and\/or with respect to other examples (e.g., as provided in , , , , , , , , , , , , , , , and ) and contexts. However, it should be understood that the operational flows may be executed in a number of other environments and contexts, and\/or in modified versions of , , , , , , , , , , , , , , , , and . Also, although the various operational flows are presented in the sequence(s) illustrated, it should be understood that the various operations may be performed in other orders other than those which are illustrated, or may be performed concurrently.","Further, in  and in the figures to follow thereafter, various operations may be depicted in a box-within-a-box manner. Such depictions may indicate that an operation in an internal box may comprise an optional example embodiment of the operational step illustrated in one or more external boxes. However, it should be understood that internal box operations may be viewed as independent operations separate from any associated external boxes and may be performed in any sequence with respect to all other illustrated operations, or may be performed concurrently. Still further, these operations illustrated in  as well as the other operations to be described herein are performed by at least one of a machine, an article of manufacture, or a composition of matter unless indicated otherwise.","In any event, after a start operation, the operational flow  of  may move to a transfer determining operation  for determining that a computing device that was presenting an item has been transferred from a first user to a second user. For instance, and as an illustration, the transfer determining module *(e.g., the transfer determining module \u2032 of or the transfer determining module \u2033 of ) of the computing device * of  (e.g., the computing device \u2032 of or the computing device \u2033 of ) determining that a computing device * that was presenting an item * has been transferred from a first user  to a second user  (e.g., transferred from the possession of the first user  to the possession of the second user ). Note that in various embodiments a user (e.g., the first user  or the second user ) may have possession of the computing device * when the user has control over the computing device * by holding the computing device *, by being in contact with the computing device *, by being in close proximity of the computing device (e.g., such as within arm's length of the computing device *), and\/or by being closest to the computing device *.","In addition to the transfer determining operation , operational flow  may include a highlighted portion presenting operation  for presenting, via the computing device, one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining. For instance, the highlighted portion presenting module *(e.g., the highlighted portion presenting module \u2032 of or the highlighted portion presenting module \u2033 of ) of the computing device * of  (e.g., the computing device \u2032 of or the computing device \u2033 of ) presenting (e.g., displaying and\/or audibly presenting via display device  and\/or one or more speakers), via the computing device *, one or more highlighted portions * of the item *, the one or more highlighted portions being highlighted in response, at least in part, to determining that the computing device * has been transferred from the first user  to the second user .","As will be further described herein, the transfer determining operation  and the highlighted portion presenting operation  of  may be executed in a variety of different ways in various alternative implementations. , , , , , , , , , and , for example, illustrate at least some of the alternative ways that the transfer determining operation  of  may be executed in various alternative implementations. For example, in various implementations, the transfer determining operation  of  may include an operation  for determining automatically without being prompted by the first user or the second user that the computing device has been transferred from the first user to the second user as depicted in . For instance, the transfer determining module *(see, for example, the transfer determining module \u2032 of or the transfer determining module \u2033 of ) of the computing device * of  (e.g., the computing device \u2032 of or the computing device \u2033 of ) determining automatically without being prompted by the first user  or the second user  that the computing device * has been transferred from the first user  to the second user .","As further illustrated in , in some implementations, the transfer determining operation  may further include an operation  for determining automatically without being affirmatively provided user credential input by the first user or the second user that the computing device has been transferred from the first user to the second user. For instance, the transfer determining module * of the computing device * of  (e.g., the computing device \u2032 of or the computing device \u2033 of ) determining automatically without being affirmatively provided user credential input (e.g., user identification input such as a username and\/or a user password) by the first user  or the second user  that the computing device * has been transferred from the first user  to the second user . In this case, the phrase \u201cdetermining automatically without being affirmatively provided user credential input\u201d is in reference to making the determination automatically that the computing device * has been transferred from the first user  to the second user  without the first user  or the second user  inputting user credential data such as a username or a password. For example, the computing device * may be designed to make the transfer determination that the computing device * has been transferred from the first user  to the second user  without the second user  having to input a username or password as is sometimes required in order to use or log on to a computing device *.","In the same or different implementations, the transfer determining operation  may additionally or alternatively include an operation  for determining that the computing device has been transferred from the first user to the second user based, at least in part, on data provided by one or more sensors. For instance, the transfer determining module * of the computing device * of  determining that the computing device * has been transferred from the first user  to the second user  based, at least in part, on data provided by one or more sensors  (see , , and ).","Data from various types of sensors  may be used in order to determine whether the computing device * has been transferred. For example, and as further illustrated in , operation  may include an operation  for determining that the computing device has been transferred from the first user to the second user based, at least in part, on data provided by one or more movement sensors. For instance, the transfer determining module * of the computing device * of  determining that the computing device * has been transferred from the first user  to the second user  based, at least in part, on data provided by one or more movement sensors  (e.g., an accelerometer, an inertia sensor, or a gyro sensor) that are designed to sense (e.g., directly detect) movements of the computing device *.","In the same or different implementations, operation  may include an operation  for determining that the computing device has been transferred from the first user to the second user based, at least in part, on data provided by one or more image capturing devices as further depicted in . For instance, the transfer determining module * of the computing device * of  determining that the computing device * has been transferred from the first user  to the second user  based, at least in part, on data provided by one or more image capturing devices  (e.g., a webcam, a digital camera, and so forth), which may be integrated in the computing device *. Note that references to \u201ccomputing device *\u201d in the following description, unless indicated otherwise, may be in reference to the computing device \u2032 of or to the computing device \u2033 of ","In the same or alternative implementations, operation  may include an operation  for determining that the computing device has been transferred from the first user to the second user based, at least in part, on data provided by one or more audio capturing devices. For instance, the transfer determining module * of the computing device * of  determining that the computing device * has been transferred from the first user  to the second user  based, at least in part, on data provided by one or more audio capturing devices  (e.g., microphone), which may be integrated in the computing device *.","In some cases, operation  may include an operation  for determining that the computing device has been transferred from the first user to the second user based, at least in part, on data provided by a combination of a movement sensor, an image capturing device, and\/or an audio capturing device. For instance, the transfer determining module * of the computing device * of  determining that the computing device * has been transferred from the first user  to the second user  based, at least in part, on data provided by a combination of a movement sensor , an image capturing device , and\/or an audio capturing device .","In various implementations, the transfer determining operation  of  may involve making the determination that the computing device * has been transferred from the first user  to the second user  based, at least in part, on the detected movements of the computing device *. For example, in some implementations, the transfer determining operation  may include an operation  for determining that the computing device has been transferred from the first user to the second user by at least detecting that the computing device has moved in a particular manner that when detected as occurring at least suggests that the computing device has been transferred between at least two users as depicted in . For instance, the transfer determining module * including a particular movement detecting module  (see ) of the computing device * determining that the computing device * has been transferred from the first user  to the second user  when the particular movement detecting module  at least detects that the computing device * has moved in a particular manner (e.g., has spatially moved along a particular three-dimensional path or moved to a particular spatial location with respect to its initial spatial location) that when detected as occurring at least suggests (e.g., infers or implies) that the computing device * has been transferred between two users.","As further illustrated in , , and , operation  may, in some cases, involve one or more operations for detecting various types of movements of the computing device * in order to determine or at least infer that the computing device * has been transferred from a first user  to a second user . For example, in some implementations, operation  may include an operation  for detecting that the computing device has moved in the particular manner by at least detecting that the computing device is no longer in a particular tilt orientation that the computing device was detected as having when the computing device was in possession of the first user prior to said transfer as illustrated in . For instance, the particular movement detecting module  including the tilt detecting module  (see ) of the computing device *detecting that the computing device * has moved in the particular manner when the tilt detecting module  at least detects that the computing device * is no longer in a particular tilt orientation that the computing device * was detected as having when the computing device * was in possession of the first user  prior to the transfer of the computing device * from the first user  to the second user . Thus, in various implementations, the computing device * may also be endowed with logic to determine whether the computing device  was in the possession of the first user . Such a determination for determining whether the computing device * was in the possession of a particular user, such as the first user , may be made using a variety of sensing means to automatically detect at least the presence of a user in the immediate area (e.g., within arm's length or within some other distances such as five feet) surrounding the computing device *.","For example, a facial recognition system or application may be used in order to determine whether the face of the first user * is detected in the vicinity of the computing device *(e.g., in the visual range of a webcam or other types of image capturing devices  that may be part of the computing device *). In other cases, a voice recognition system or application may be used in order to determine whether the voice of the first user  is detected in the vicinity of the computing device *. In still other cases, other sensing or detecting means for detecting indicators (e.g., signature movements or vibration) that indicate the presence or absence of the first user  in the proximate vicinity (e.g., close vicinity) of the computing device * may be employed in order to determine whether the first user  has possession of the computing device *.","In some cases, operation  may, in turn, include an operation  for detecting that the computing device is no longer in a particular tilt orientation that the computing device was detected as having when the computing device was in the possession of the first user by at least detecting that the computing device has been reoriented from the particular tilt orientation to another tilt orientation that when detected at least suggests that the computing device has been transferred between at least two users as further depicted in . For instance, the tilt detecting module  of the computing device * detecting that the computing device * is no longer in a particular tilt orientation that the computing device * was detected as having when the computing device * was in the possession of the first user  by at least detecting that the computing device * has been reoriented from the particular tilt orientation of the computing device * that the computing device * was detected as having when the computing device * was in the possession of the first user  to another tilt orientation that when detected at least suggests that the computing device * has been transferred between at least two users.","In the same or different implementations, operation  may include an operation  for detecting that the computing device is no longer in a particular tilt orientation that the computing device was detected as having when the computing device was in the possession of the first user by at least detecting that the computing device has been reoriented from the particular tilt orientation to another tilt orientation having an angular tilt that is at least a predefined percentage different from an angular tilt associated with the particular tilt orientation that the computing device was detected as having when the computing device was in the possession of the first user as further depicted in . For instance, the tilt detecting module  of the computing device * detecting that the computing device * is no longer in a particular tilt orientation that the computing device * was detected as having when the computing device * was in the possession of the first user  by at least detecting that the computing device * has been reoriented from the particular tilt orientation of the computing device * that the computing device * was detected as having when the computing device * was in the possession of the first user  to another tilt orientation having an angular tilt that is at least a predefined percentage different from an angular tilt associated with the particular tilt orientation that the computing device * was detected as having when the computing device * was in the possession of the first user . Such an operation may be executed in order to, for example, filter out \u201cnoise\u201d tilts (e.g., random changes in tilt caused by the first user  when, for example, the first user  accidentally or intentionally moves his\/her body or hands in order to, for example, get in a more comfortable body position causing the computing device * to move and change in tilt orientation).","In various implementations, the operation  for determining that the computing device has been transferred from the first user to the second user by at least detecting that the computing device has moved in a particular manner that when detected as occurring at least suggests that the computing device has been transferred between at least two users may involve detecting that the computing device * has at least been relocated away from a particular location. For example, in some implementations, operation  may include an operation  for detecting that the computing device has moved in the particular manner by at least detecting that the computing device is no longer at a particular spatial location that the computing device was detected as being located at when the computing device was in possession of the first user prior to said transfer as depicted in . For instance, the particular movement detecting module  including the spatial location detecting module  (see ) of the computing device * detecting that the computing device * has moved in a particular manner when the spatial location detecting module  at least detects that the computing device * is no longer at a particular spatial location (e.g., see spatial location  of ) that the computing device * was detected as being located at when the computing device * was in the possession of the first user  prior to the transfer of the computing device *.","In various implementations, operation  may include an operation  for detecting that the computing device is no longer at the particular spatial location that the computing device was detected as being located at when the computing device was in the possession of the first user prior to said transfer by at least detecting that the computing device has been relocated from the particular spatial location to another spatial location that when detected at least suggests that the computing device has been transferred from the first user to the second user. For instance, the spatial location detecting module  of the computing device * detecting that the computing device * is no longer at the particular spatial location  (see ) that the computing device * was detected as being located at when the computing device * was in the possession of the first user  prior to the transfer of the computing device *, the detecting by at least detecting that the computing device * has been relocated from the particular spatial location  to another spatial location  that when detected at least suggests that the computing device * has been transferred from the first user  to the second user .","In the same or different implementations, operation  may include an operation  for detecting that the computing device is no longer at a particular spatial location that the computing device was detected as being located at when the computing device was in the possession of the first user prior to said transfer by at least detecting that the computing device has been relocated from the particular spatial location to another spatial location that is at least a predefined distance away from the particular spatial location that the computing device was detected as being located at when the computing device was in the possession of the first user prior to said transfer. For instance, the spatial location detecting module  of the computing device * detecting that the computing device * is no longer at a particular spatial location (e.g., spatial location  of ) that the computing device * was detected as being located at when the computing device * was in the possession of the first user  prior to said transfer of the computing device *, the detecting by at least detecting that the computing device * has been relocated from the particular spatial location  to another spatial location  that is at least a predefined distance away from the particular spatial location  that the computing device * was detected as being located at when the computing device * was in the possession of the first user  prior to the transfer of the computing device *.","Turning to , in various implementations, operation  for determining that the computing device has been transferred from the first user to the second user by at least detecting that the computing device has moved in a particular manner that when detected as occurring at least suggests that the computing device has been transferred between at least two users may include an operation  for detecting that the computing device has moved in the particular manner by at least detecting that the computing device has been spin rotated from a first orientation to a second orientation, the first orientation being an orientation associated with the computing device when the computing device was in possession of the first user prior to said transfer. For instance, the particular movement detecting module  including the spin rotation detecting module  (see ) of the computing device * detecting that the computing device * has moved in the particular manner when the spin rotation detecting module  at least detects that the computing device * has been spin rotated from a first orientation to a second orientation, the first orientation being an orientation associated with the computing device * when the computing device * was in possession of the first user  prior to the transfer of the computing device *.","In the same or different implementations, operation  may include an operation  for detecting that the computing device has moved in the particular manner by at least detecting that the computing device has moved away from the first user. For instance, the particular movement detecting module  including the moving away detecting module  (see ) of the computing device * detecting that the computing device * has moved in a particular manner when the moving away detecting module  at least detects that the computing device * has moved away from the first user . Such detection may be based on data provided by one or more sensors  including one or more movement sensors , one or more image capturing devices  (which may detect the face of the first user  moving away from the computing device *), and\/or one or more audio capturing devices  (which may detect a voice having the voice signature of the first user  diminishing in volume thus inferring or suggesting that the first user  is or was moving away from the computing device *).","In some implementations, operation  may further include an operation  for detecting that the computing device has moved away from the first user by at least detecting that the computing device has moved a predefined distance away from the first user. For instance, the moving away detecting module  of the computing device * detecting that the computing device * has moved away from the first user  by at least detecting that the computing device * has moved a predefined distance away from the first user . In doing so, the computing device * may filter out movements that may be considered \u201cnoise\u201d (e.g., random or accidental relocation movements of the computing device * caused by, for example, the random or accidental movements of the first user  holding the computing device *).","In various embodiments, operation  may involve tracking or sensing one or more vibrations that may be exhibited by the computing device * through its physical contact with one or more users. That is, users may each be associated with different and relatively distinct signature vibration patterns (e.g., distinct heart rates). Thus, by detecting at least a change in vibration as exhibited by the computing device * as a result of, for example, the computing device * being passed from one user to another user, at least an inference may be made that a transfer of the computing device * has occurred. Thus, in various implementations, operation  may include an operation  for detecting that the computing device has moved in the particular manner by at least detecting that the computing device is no longer vibrating in a manner that matches with a vibration pattern that the computing device was detected as having when the computing device was in possession of the first user prior to said transfer as further illustrated in . For instance, the particular movement detecting module  including the vibration detecting module  (see ) of the computing device * detecting that the computing device * has moved in a particular manner when the vibration detecting module  at least detects that the computing device * is no longer vibrating in a manner that matches with a vibration pattern that the computing device * was detected having when the computing device * was in possession of the first user  prior to the transfer of the computing device *.","As further illustrated in , in some implementations, operation  may further include an operation  for detecting that the computing device is no longer vibrating in the manner that matches with the vibration pattern that the computing device was detected as having when the computing device was in the possession of the first user prior to said transfer by at least detecting that the computing device is vibrating in a manner that matches with a signature vibration pattern associated with the second user. For instance, the vibration detecting module  of the computing device * detecting that the computing device * is no longer vibrating in a manner that matches with a vibration pattern that the computing device * was detected as having when the computing device * was in the possession of the first user  prior to the transfer of the computing device *, the detecting by at least detecting that the computing device * is vibrating in a manner that matches with a signature vibration pattern associated with the second user . For example, if the second user  is a regular user, a primary user, or an owner of the computing device * than the computing device * may store in its memory  the signature vibration pattern of the second user .","In the same or different implementations, operation  may include an operation  for detecting that the computing device has moved in the particular manner by at least detecting that the computing device is not vibrating in a manner that matches with a signature vibration pattern that is associated with the first user. For instance, particular movement detecting module  including the vibration detecting module  of the computing device * determining that the computing device * has moved in a particular manner when the vibration detecting module  at least detects that the computing device * is not vibrating in a manner that matches with a signature vibration pattern that is associated with the first user .","Referring now to , in various implementations, operation  for determining that the computing device has been transferred from the first user to the second user by at least detecting that the computing device has moved in a particular manner that when detected as occurring at least suggests that the computing device has been transferred between at least two users may involve tracking the overall movements of the computing device * rather than tracking any particular type of movements (e.g., tilt movements, spin rotation movements, spatial relocation movements, vibration movements, etc.) in order to determine whether the computing device * has been transferred from the first user  to the second user . For example, in some implementations, operation  may include an operation  for detecting that the computing device has moved in the particular manner by at least detecting that the computing device has moved in a particular three-dimensional way that at least suggests that the computing device has been transferred between two users. For instance, the particular movement detecting module  including the three-dimensional movement detecting module  (see ) of the computing device * detecting that the computing device * has moved in the particular manner when the three-dimensional movement detecting module  at least detects that the computing device * has moved in a particular three-dimensional way that at least suggests that the computing device * has been transferred between two users.","As further illustrated in , operation  may include one or more additional operations in various alternative implementations. For example, in some implementations, operation  may include an operation  for detecting that the computing device has moved in the particular three-dimensional way that at least suggests that the computing device has been transferred between two users by detecting that the computing device is exhibiting one or more three-dimensional movements that matches with one or more signature three-dimensional movements that when detected as occurring at least suggests transfer of the computing device between two users. For instance, the three-dimensional movement detecting module  of the computing device * detecting that the computing device * has moved in the particular three-dimensional way that at least suggests that the computing device * has been transferred between two users (e.g., between the first user  and the second user ) by detecting that the computing device * is exhibiting one or more three-dimensional movements that matches with one or more signature three-dimensional movements (e.g., one or more signature three-dimensional movements that may be stored in the movement library  of the memory ) that when detected as occurring at least suggests transfer of the computing device * between two users.","In some cases, operation  may further include an operation  for detecting that the computing device is exhibiting one or more three-dimensional movements that matches with the one or more signature three-dimensional movements by detecting that the computing device is exhibiting one or more three-dimensional movements that matches with one or more signature three-dimensional movements that are particularly associated with the first user and that when detected as occurring at least suggests transfer of the computing device from the first user to another user. For instance, the three-dimensional movement detecting module  of the computing device * detecting that the computing device * is exhibiting one or more three-dimensional movements that matches with the one or more signature three-dimensional movements by detecting that the computing device * is exhibiting one or more three-dimensional movements that matches with one or more signature three-dimensional movements (e.g., as indicated in the movement library  of the memory ) that are particularly associated with the first user  and that when detected as occurring at least suggests transfer of the computing device * from the first user  to another user (e.g., the second user ).","In some implementations, the one or more signature three-dimensional movements of the computing device * may be the one or more signature movements of the computing device * that may be exhibited by the computing device * when the first user  is passing-off (e.g., transferring) the computing device  to another user. For these implementations, the computing device * may be endowed with logic that may allow the computing device * to detect and learn its own movements when the computing device * is being handed-off from the first user  to another user, and based on such detected\/learned movements (e.g., signature movements) the computing device *(or its endowed logic) may determine or at least infer that the computing device * has been transferred from the first user  to another user whenever it detects movements that matches with the previously detected\/learned movements. In various implementations, the movements of the computing device * may be monitored using one or more movements sensors  and\/or one or more image capturing devices .","In the same or different implementations, operation  may include an operation  for detecting that the computing device is exhibiting one or more three-dimensional movements that matches with the one or more signature three-dimensional movements by detecting that the computing device is exhibiting one or more three-dimensional movements that matches with one or more generic signature three-dimensional movements that are not particularly associated with the first user and that when detected as occurring at least suggests transfer of the computing device between two users. For instance, the three-dimensional movement detecting module  of the computing device * detecting that the computing device * is exhibiting one or more three-dimensional movements that matches with the one or more signature three-dimensional movements by detecting that the computing device * is exhibiting one or more three-dimensional movements that matches with one or more generic signature three-dimensional movements that are not particularly associated with the first user  (e.g., one or more generic signature three-dimensional movements of the computing device * that are not associated with any specific user) and that when detected as occurring at least suggests transfer of the computing device * between two users.","Referring now to , in various implementations, the transfer determining operation  of  may involve determining that the computing device * has been transferred from the first user  to the second user  based, at least in part, on one or more visual cues. For example, in some implementations, the transfer determining operation  may include an operation  for determining that the computing device has been transferred from the first user to the second user by at least detecting presence or absence of one or more visual cues in proximate vicinity of the computing device that when detected as occurring at least suggests transfer of the computing device between two users as illustrated in . For instance, the transfer determining module * including the visual cue detecting module  (see ) of the computing device * determining that the computing device * has been transferred from the first user  to the second user  when the visual cue detecting module  at least detects presence or absence of one or more visual cues (e.g., detecting presence or absence of faces of the first user  and\/or second user , detecting background movement relative to the computing device *, and so forth) in proximate vicinity (e.g., within a distance from the computing device * from which an object or a person is visually discernable or identifiable by the computing device *) of the computing device * that when detected as occurring at least suggests transfer of the computing device * between two users (e.g., between the first user  and the second user ).","As further illustrated in , , and , operation  may be implemented in a number of different ways in various alternative implementations. For example, in some implementations, operation  may include an operation  for detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device by at least detecting presence of one or more visual cues located within a predefined distance from the computing device from which a user is able to perceive content being presented through the computing device as illustrated in . For instance, the visual cue detecting module  of the computing device * detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * by at least detecting presence of one or more visual cues located within a predefined distance from the computing device * from which a user is able to (e.g., user can) perceive content being presented through the computing device *. For example, if the face (or eyes) of the second user  is determined to be within a distance (e.g., four feet) from the computing device * from which the second user  is able to visually ascertain what is being displayed through the computing device *, then determining that the transfer of the computing device * has occurred from the first user  to the second user .","In the same or different implementations, operation  may include an operation  for detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device by detecting at least a change in lighting in the proximate vicinity of the computing device that when detected as occurring at least suggests that the computing device has at least moved. For instance, the visual cue detecting module  including the lighting change detecting module  (see ) of the computing device * detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * when the lighting change detecting module  detects at least a change in lighting in the proximate vicinity of the computing device * that when detected as occurring at least suggests that the computing device * has at least moved. That is, typically when a device such as a computing device * is moved from one location to another location, there may be a variation in the type\/amount of light being exposed to the device. Thus, by merely detecting changes in lighting conditions surrounding the computing device *, an inference could be made that, for example, a computing device * is being moved\/transferred.","In some cases, operation  may further include an operation  for detecting at least the change in lighting in the proximate vicinity of the computing device by detecting at least a predefined amount of change in lighting in the proximate vicinity of the computing device within a predefined time period as further depicted in . For instance, the lighting change detecting module  of the computing device * detecting at least the change in lighting in the proximate vicinity of the computing device * by detecting at least a predefined amount of change in lighting in the proximate vicinity of the computing device * within a predefined time period. In doing so, inconsequential lighting changes will be filtered out such as those as a result of changes in daylight, which typically occurs slowly.","In the same or different implementations, operation  may include an operation  for detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device by at least detecting presence of at least one face in the proximate vicinity of the computing device not associated with the first user. For instance, the visual cue detecting module  including the face detecting module  (see ) of the computing device * detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * when the face detecting module  at least detects presence of at least one face (e.g., detecting presence of the at least one face based on image data provided by an image capturing device ) in the proximate vicinity (e.g., close vicinity such as within five feet) of the computing device * not associated with the first user .","As further illustrated in , in some implementations, operation  may include an operation  for detecting the presence of the at least one face in the proximate vicinity of the computing device not associated with the first user by at least detecting presence of at least one face in the proximate vicinity of the computing device that is recognized as being associated with the second user. For instance, the face detecting module  of the computing device * detecting the presence of the at least one face in the proximate vicinity of the computing device * not associated with the first user  by at least detecting presence of at least one face in the proximate vicinity of the computing device * that is recognized or detected as being associated with the second user . In some cases, the computing device * may store in its memory  facial characteristics of one or more users in the form of one or more facial images including, for example, a facial image of the second user .","In some cases, operation  may alternatively or additionally include an operation  for detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device by at least detecting presence of a first face associated with the first user and a second face associated with the second user in the proximate vicinity of the computing device, the second face being detected as being closer to the computing device than the first face. For instance, the visual cue detecting module  including the face detecting module  of the computing device * detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * when the face detecting module  at least detects presence of a first face associated with the first user  and a second face associated with the second user  in the proximate vicinity of the computing device *, the second face being detected as being closer to the computing device * than the first face of the first user . Note that in this particular implementation, the computing device * or at least the logic endowed with the computing device * may only need to recognize that the first face and the second face are two different faces belonging to, for example, two different users.","In the same or different implementations, operation  may include an operation  for detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device by detecting presence of at least one eye in the proximate vicinity of the computing device not associated with the first user as further depicted in . For instance, the visual cue detecting module  including the eye detecting module  (see ) of the computing device * detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * when the eye detecting module  detects presence of at least one eye (e.g., iris or retina characteristics) in the proximate vicinity of the computing device * not associated with the first user . In other words, determining that there is at least one eye having, for example, iris or retina characteristics in the proximate vicinity of the computing device * that is different from the iris or retina characteristics of the eye or eyes of the first user .","In some cases operation  may further include an operation  for detecting the presence of the at least one eye in the proximate vicinity of the computing device not associated with the first user by at least detecting presence of at least one eye in the proximate vicinity of the computing device that is recognized as being associated with the second user. For instance, the eye detecting module  of the computing device * detecting the presence of the at least one eye in the proximate vicinity of the computing device * not associated with the first user  by at least detecting presence of at least one eye in the proximate vicinity of the computing device * that is recognized by, for example, the endowed logic of the computing device * as being associated with the second user . Thus, in some cases, the computing device * may store in its memory  images of eyes (e.g., images of irises or retinas) belonging to one or more users including, for example, the second user .","In the same or different implementations, operation  may include an operation  for detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device by at least detecting presence of a first one or more eyes associated with the first user and a second one or more eyes associated with the second user in the proximate vicinity of the computing device, the second one or more eyes being detected as being closer to the computing device than the first one or more eyes as illustrated in . For instance, the visual cue detecting module  including the eye detecting module  of the computing device * detecting presence or absence of one or more visual cues in the proximate vicinity of the computing device * when the eye detecting module  at least detects presence of a first one or more eyes associated with the first user  and a second one or more eyes associated with the second user  in the proximate vicinity (e.g., immediate proximity) of the computing device *, the second one or more eyes being detected as being closer to the computing device * than the first one or more eyes.","In the same or different implementations, operation  may include an operation  for detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device by at least detecting absence of the one or more visual cues associated with the first user in the proximate vicinity of the computing device for at least a predefined period of time, the absence of the one or more visual cues for at least a predefined period of time being indicative of the first user not being in the proximate vicinity of the computing device as further illustrated in . For instance, the visual cue detecting module  of the computing device * detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * by at least detecting absence of the one or more visual cues associated with the first user  in the proximate vicinity of the computing device * for at least a predefined period of time, the absence of the one or more visual cues (e.g., an eye or a face associated with the first user *) for at least a predefined period of time being indicative of the first user  not being in the proximate vicinity of the computing device *. Note that since it is possible for the one or more visual cues (e.g., an eye or a face) of the first user  to disappear momentarily for short periods of time (such as when the head of the first user  turns to look at something other than the computing device *) even though the first user  has not actually given up control of the computing device * or has not transferred the computing device * to another user (e.g., the second user ), the computing device *(or its logic) may not infer, much less conclude, that the computing device * has been actually transferred to the second user  unless the visual cue (e.g., eye or face of the first user ) is detected as being absent in the proximate vicinity of the computing device * for at least a certain amount of predefined time (e.g., 10 second, 20 seconds, 25 seconds, or some other time period). Further, in some cases, additional indicators (e.g., additional visual cues, detected movements, and\/or audio cues) may be required to confirm that the computing device * has been transferred from the first user  to the second user  since the mere detection of the absence of one or more visual cues (e.g., face of the first user ) may be a weak inference that the computing device * has been transferred to the second user .","As further illustrated in , in some implementations, operation  may include one or more additional operations including an operation  for detecting the absence of the one or more visual cues associated with the first user in the proximate vicinity of the computing device by at least detecting absence of a face associated with the first user in the proximate vicinity of the computing device. For instance, the visual cue detecting module  including the face detecting module  of the computing device  detecting the absence of the one or more visual cues associated with the first user  in the proximate vicinity of the computing device * when the face detecting module  at least detects absence of a face associated with the first user  in the proximate vicinity of the computing device *. For example, if the computing device * includes an image capturing device , such as a webcam, then the computing device * may detect the absence of a visual cue of the first user  that indicates the presence of the first user  when the webcam does not detect the face of the first user * in the proximate vicinity of the computing device *(e.g., within 3 feet, 5 feet, 10 feet, or within some other distance from the computing device * that a face of the first user  can be detected\/identified by the computing device *).","In the same or different implementations, operation  may include an operation  for detecting the absence of the one or more visual cues associated with the first user in the proximate vicinity of the computing device by at least detecting absence of one or more eyes associated with the first user in the proximate vicinity of the computing device as further depicted in . For instance, the visual cue detecting module  including the eye detecting module  of the computing device * detecting the absence of the one or more visual cues associated with the first user  in the proximate vicinity of the computing device * when the eye detecting module  at least detects absence of one or more eyes associated with the first user  in the proximate vicinity of the computing device *. For example, if the computing device * includes an image capturing device , then the computing device * may detect the absence of the visual cue of the first user  that indicates the presence of the first user  when the image capturing device  does not detect the one or more eyes of the first user * near the computing device *(e.g., within 2 feet, 4 feet, 6 feet, or within some other distance from the computing device * that a characteristics of an eye, such as a retinal or iris characteristic, of the first user  can be detected\/identified by the computing device *).","In various implementations, operation  for determining that the computing device has been transferred from the first user to the second user by at least detecting presence or absence of one or more visual cues in proximate vicinity of the computing device that when detected as occurring at least suggests transfer of the computing device between two users may further include an operation  for detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device by at least detecting visually that the computing device has moved away from the first user as further depicted in . For instance, the visual cue detecting module  including the visual moving away detecting module  (see ) of the computing device * detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * when the visual moving away detecting module  at least detects visually (e.g., via an image capturing device ) that the computing device * has moved away from the first user .","Turning now to , in various implementations, operation  may include an operation  for detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device by at least detecting visually the presence or absence of the one or more visual cues in the proximate vicinity of the computing device and with respect to a specific orientation of the computing device. For instance, the visual cue detecting module  of the computing device * detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * by at least detecting visually (e.g., via one or more image capturing devices ) the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * and with respect to a specific orientation of the computing device *. For example detecting the presence or absence of one or more visual cues (e.g., user faces or eyes) on the front-side of the computing device * rather than on the back-side of the computing device *.","As further illustrated in , operation  may include one or more additional operations in various alternative implementations. For example, in some implementations, operation  may include an operation  for detecting visually the presence or absence of the one or more visual cues in the proximate vicinity of the computing device and with respect to the specific orientation of the computing device by at least detecting visually the presence or absence of the one or more visual cues at one or more specific locations relative to a front-side of the computing device, the front-side of the computing device being a side of the computing device having a display device. For instance, the visual cue detecting module  of the computing device * detecting visually the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * and with respect to the specific orientation of the computing device * by at least detecting visually the presence or absence of the one or more visual cues at one or more specific locations (e.g., predefined locations) relative to a front-side of the computing device *, the front-side of the computing device * being a side of the computing device * having a display device .","In some cases, operation  may include an operation  for detecting visually the presence or absence of the one or more visual cues at the one or more specific locations relative to the front-side of the computing device by detecting visually at least disappearance of one or more features associated with the first user at the one or more specific locations relative to the front-side of the computing device. For instance, the visual cue detecting module  of the computing device * detecting visually the presence or absence of the one or more visual cues at the one or more specific locations (e.g., predefined locations) relative to the front-side of the computing device * by detecting visually at least disappearance of one or more features (e.g., face or one or more eyes) associated with the first user  at the one or more specific locations (e.g., predefined locations) relative to the front-side of the compiling device *.","In some cases, operation  may include an operation  for detecting visually the presence or absence of the one or more visual cues at the one or more specific locations relative to the front-side of the computing device by detecting visually at least appearance of one or more features associated with the second user at the one or more specific locations relative to the front-side of the computing device. For instance, the visual cue detecting module  of the computing device * detecting visually the presence or absence of the one or more visual cues at the one or more specific locations relative to the front-side of the computing device * by detecting visually at least appearance of one or more features (e.g., a face or one or more eyes) associated with the second user  at the one or more specific locations relative to the front-side of the computing device *. As those of ordinary skill will recognize, the visual detection of the second user  (e.g., the face or one or more eyes of the second user ) in the proximate vicinity (e.g., immediate surrounding area such as within three, four, or five feet) of the computing device * may be in many cases a better indicator that the computing device * has been transferred to the second user  than the detection of the absence of the first user  (e.g., the face or one or more eyes of the first user ) in the proximate vicinity of the computing device *.","In some implementations, operation  may include an operation  for detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device by at least detecting visually one or more gestures exhibited by the first user that when detected as occurring at least suggests transfer of the computing device from the first user to another user. For instance, the visual cue detecting module  including the gesture detecting module  of the computing device * detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device * when the gesture detecting module  detecting visually one or more gestures exhibited by the first user  (e.g., the first user  extending his\/her arm out as if to offer\/transfer the computing device * to the second user ) that when detected as occurring at least suggests transfer of the computing device * from the first user  to another user .","Turning now to , in some implementations, the transfer determining operation  of  may include an operation  for determining that the computing device has been transferred from the first user to the second user by at least detecting presence or absence of one or more audio cues in proximate vicinity of the computing device that when detected as occurring at least suggests transfer of the computing device between two users. For instance, the transfer determining module * including an audio cue detecting module  (see ) of the computing device * determining that the computing device * has been transferred from the first user  to the second user  by at least detecting presence or absence of one or more audio cues in proximate vicinity of the computing device * that when detected as occurring at least suggests transfer of the computing device * between two users.","As further illustrated in , operation  may include one or more additional operations in various alternative implementations. For example, in some implementations, operation  may include an operation  for detecting the presence or absence of the one or more audio cues in the proximate vicinity of the computing device by at least detecting audibly that the computing device has moved away from the first user. For instance, the audio cue detecting module  including the audio moving away detecting module  (see ) of the computing device * detecting presence or absence of one or more audio cues in the proximate vicinity of the computing device * when the audio moving away detecting module  at least detects audibly (e.g., using one or more audio capturing device ) that the computing device * has moved away from the first user . For example, the audio moving away detecting module  detecting that the volume of an audio cue, such as a voice pattern, that is associated with the first user  is diminishing or has diminished, which may be an inference that the computing device * may be or may have moved away from the first user .","In the same or different implementations, operation  may additionally or alternatively include an operation  for detecting the presence or absence of the one or more audio cues in the proximate vicinity of the computing device by at least detecting presence of at least one audio voice pattern not associated with the first user in the proximate vicinity of the computing device. For instance, the audio cue detecting module  including the voice pattern detecting module  (see ) of the computing device * detecting the presence or absence of the one or more audio cues in the proximate vicinity of the computing device * by at least detecting presence of at least one audio voice pattern (e.g., voice of the second user ) not associated with the first user  in the proximate vicinity of the computing device *.","In some implementations, operation  may further include an operation  for detecting the presence of the at least one audio voice pattern not associated with the first user in the proximate vicinity of the computing device by at least detecting presence of at least one audio voice pattern that is recognized as being associated with the second user in the proximate vicinity of the computing device. For instance, the voice pattern detecting module  of the computing device * detecting the presence of the at least one audio voice pattern not associated with the first user  in the proximate vicinity of the computing device * by at least detecting presence of at least one audio voice pattern that is recognized by, for example, the endowed logic of the computing device * as being associated with the second user  in the proximate vicinity of the computing device *.","In various implementations, the transfer determining operation  of  for determining that a computing device that was presenting an item has been transferred from a first user to a second user may involve determining the transfer of the computing device * based on a combination of detecting direct movements of the computing device *, detecting visual cues, and\/or detecting audio cues. For example, in some implementations and as illustrated in , the transfer determining operation  may include an operation  for determining that the computing device has been transferred from the first user to the second user by detecting that the computing device has moved in a particular manner and by detecting presence or absence of one or more visual cues in proximate vicinity of the computing device. For instance, the transfer determining module * including the particular movement detecting module  and the visual cue detecting module  of the computing device * determining that the computing device * has been transferred from the first user  to the second user  when the particular movement detecting module  detects that the computing device * has moved in a particular manner and the visual cue detecting module  detects presence or absence of one or more visual cues in proximate vicinity of the computing device *.","As further illustrated in , in some cases, operation  may further include an operation  for determining that the computing device has been transferred from the first user to the second user by detecting that the computing device has moved in a particular manner, by detecting the presence or absence of the one or more visual cues in the proximate vicinity of the computing device, and by detecting presence or absence of one or more audio cues in the proximate vicinity of the computing device. For instance, the transfer determining module * including the particular movement detecting module , the visual cue detecting module , and the audio cue detecting module  of the computing device * determining that the computing device * has been transferred from the first user  to the second user  when the particular movement detecting module  detects that the computing device * has moved in a particular manner, the visual cue detecting module  detects the presence or absence of the one or more visual cues in the proximate vicinity of the computing device *, and the audio cue detecting module  detects presence or absence of one or more audio cues in the proximate vicinity of the computing device *.","In some alternative implementations, the transfer determining operation  may include an operation  for determining that the computing device has been transferred from the first user to the second user by detecting presence or absence of one or more visual cues in the proximate vicinity of the computing device and by detecting presence or absence of one or more audio cues in proximate vicinity of the computing device as depicted in . For instance, the transfer determining module * including the visual cue detecting module  and the audio cue detecting module  of the computing device * determining that the computing device * has been transferred from the first user  to the second user  when the visual cue detecting module  detects presence or absence of one or more visual cues in the proximate vicinity of the computing device * and when the audio cue detecting module  detects presence or absence of one or more audio cues in proximate vicinity of the computing device *.","As further illustrated in , in the same or alternative implementations, the transfer determining operation  may include an operation  for determining that the computing device has been transferred from the first user to the second user by determining that the computing device that was presenting at least one portion of the item and that was being held by the first user has been transferred from the first user to the second user. For instance, the transfer determining module * of the computing device * determining that the computing device * has been transferred from the first user  to the second user  by determining that the computing device * that was presenting at least one portion of the item (e.g., a page from a digital book or a portion of a webpage) and that was being held by the first user  (e.g., being in physical contact with the first user ) has been transferred from the first user  to the second user .","In the same or different implementations, the transfer determining operation  may include an operation  for determining that the computing device has been transferred from the first user to the second user by determining that the computing device that was presenting at least one portion of the item and that was determined to be located proximate to and having a particular orientation relative to the first user has been transferred from the first user to the second user. For instance, the transfer determining module * of the computing device * determining that the computing device * has been transferred from the first user  to the second user  by determining that the computing device * that was presenting at least one portion of the item and that was determined to be located proximate to (e.g., within five feet) and having a particular orientation relative to the first user  (e.g., front-side facing the first user ) has been transferred from the first user  to the second user .","In the same or different implementations, the transfer determining operation  may include an operation  for determining that the computing device that was presenting the item has been transferred from the first user to the second user by determining that the computing device that was presenting an open or active item and that was in possession of the first user has been transferred from the first user to the second user. For instance, the transfer determining module * of the computing device * determining that the computing device * that was presenting the item has been transferred from the first user  to the second user  by determining that the computing device * that was presenting an open or active item (e.g., an open electronic document or file, an open website, an active application, and so forth) and that was in possession of the first user  has been transferred from the first user  to the second user .","In the same or different implementations, the transfer determining operation  may include an operation  for determining that the computing device that was presenting the item has been transferred from the first user to the second user by determining that the computing device that was visually and\/or audibly presenting an electronic item has been transferred from the first user to the second user. For instance, the transfer determining module * of the computing device * determining that the computing device * that was presenting the item has been transferred from the first user  to the second user  by determining that the computing device * that was visually and\/or audibly presenting an electronic item (e.g., a digital book, a video file such as a feature movie, an email, and so forth) has been transferred from the first user  to the second user .","In some cases, operation  may further include an operation  for determining that the computing device that was visually and\/or audibly presenting the electronic item has been transferred from the first user to the second user, the electronic item being one of an electronic document, an electronic file, or an electronic message. For instance, the transfer determining module * of the computing device * determining that the computing device * that was visually and\/or audibly presenting the electronic item has been transferred from the first user  to the second user , the electronic item being one of an electronic document (e.g., a productivity document such as a word processing or spreadsheet document), an electronic file (e.g., electronic photo album), or an electronic message (e.g., email or text message).","Referring now to , in various implementations, the transfer determining operation  of  may include an operation  for determining that the computing device that was presenting the item has been transferred from the first user to the second user by at least identifying the second user. For instance, the transfer determining module * including a user identifying module  determining that the computing device * that was presenting the item has been transferred from the first user  to the second user  when the user identifying module  at least identifies (e.g., recognizes) the second user . For example, determining who the second user  is and\/or determining or recognizing whether the second user  has a profile that indicates whether the second user  is associated with any specific portion or portions of the item that is being presented by the computing device * prior to the transfer of the computing device * from the first user  to the second user .","As further illustrated in , in various implementations, operation  may include one or more operations including in some cases an operation  for identifying the second user based on one or more biometric characteristics of the second user. For instance, the biometric user identifying module  (see ) of the computing device * identifying the second user  based on one or more biometric characteristics of the second user  as sensed by, for example, one or more sensors .","In some implementations, operation  may further include an operation  for identifying biometrically the second user based on one or more movement characteristics, one or more facial characteristics, one or more retinal characteristics, and\/or one or more voice characteristics of the second user. For instance, the biometric user identifying module  of the computing device * identifying biometrically the second user  based on one or more movement characteristics (e.g., as sensed by, for example, one or more movement sensors ), one or more facial characteristics (e.g., as sensed by one or more image capturing devices ), one or more retinal characteristics (e.g., as sensed by one or more image capturing devices ), and\/or one or more voice characteristics of the second user  (e.g., as sensed by one or more audio capturing devices ).","In various implementations, operation  may include an operation  for identifying the second user based on data provided by one or more movement sensors, one or more image capturing devices, and\/or one or more audio capturing devices. For instance, the user identifying module  of the computing device * identifying the second user  based on data provided by one or more movement sensors , one or more image capturing devices , and\/or one or more audio capturing devices .","Referring back to the highlighted portion presenting operation  of , the highlighted portion presenting operation  similar to the transfer determining operation  of  may be executed in a number of different ways in various alternative embodiments as illustrated in , , and . In some implementations, for example, the highlighted portion presenting operation  of  for presenting, via the computing device, one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining may include an operation  for presenting the one or more highlighted portions of the item by presenting visually and\/or audibly the one or more highlighted portions of the item as illustrated in . For instance, the highlighted portion presenting module * of the computing device * presenting the one or more highlighted portions * of the item * by presenting visually and\/or audibly (e.g. via a display monitor  such as a touchscreen and\/or one or more speakers) the one or more highlighted portions * of the item *.","In the same or alternative implementations, the highlighted portion presenting operation  of  may include an operation  for presenting the one or more highlighted portions of the item by presenting the one or more highlighted portions with one or more unhighlighted portions of the item, the one or more highlighted portions having one or more visual and\/or audio formats that are different from the one or more unhighlighted portions. For instance, the highlighted portion presenting module * including the unhighlighted portion presenting module  (see ) of the computing device * presenting the one or more highlighted portions * of the item * by presenting the one or more highlighted portions * with one or more unhighlighted portions *of the item as presented by the unhighlighted portion presenting module , the one or more highlighted portions * having one or more visual and\/or audio formats (e.g., text or image size and\/or audio volume) that are different from the one or more unhighlighted portions *. In various implementations, the one or more visual and\/or audio formats to be applied to the one or more highlighted portions may have been selected based, at least in part, on determination that the computing device * was transferred from the first user  to the second user .","As further illustrated in , operation  may include one or more additional operations in various alternative implementations. For example, in some implementations, operation  may include an operation  for presenting the one or more highlighted portions with the one or more unhighlighted portions of the item by presenting the one or more highlighted portions that include text having one or more font styles that are different from one or more font styles of text included with the one or more unhighlighted portions. For instance, the highlighted portion presenting module * including the unhighlighted portion presenting module  of the computing device * presenting the one or more highlighted portions * with the one or more unhighlighted portions * of the item * by presenting the one or more highlighted portions * that include text having one or more font styles that are different from one or more font styles of text included with the one or more unhighlighted portions *.","In the same or different implementations, operation  may include an operation  for presenting the one or more highlighted portions with the one or more unhighlighted portions of the item by presenting the one or more highlighted portions having one or more color and\/or brightness schemes that are different from one or more color and\/or brightness schemes of the one or more unhighlighted portions. For instance, the highlighted portion presenting module * including the unhighlighted portion presenting module  of the computing device * presenting the one or more highlighted portions * with the one or more unhighlighted portions * of the item * by presenting the one or more highlighted portions * having one or more color and\/or brightness schemes (e.g., increased brightness or different color or colors for the background of the highlighted portion or portions *) that are different from one or more color and\/or brightness schemes of the one or more unhighlighted portions *.","In the same or different implementations, operation  may include an operation  for presenting the one or more highlighted portions with the one or more unhighlighted portions of the item by presenting the one or more highlighted portions that include one or more backgrounds that are different from one or more backgrounds of the one or more unhighlighted portions. For instance, the highlighted portion presenting module * including the unhighlighted portion presenting module  of the computing device * presenting the one or more highlighted portions * with the one or more unhighlighted portions * of the item * by presenting the one or more highlighted portions * that include one or more backgrounds (e.g., having different background color or pattern) that are different from one or more backgrounds of the one or more unhighlighted portions *.","In the same or different implementations, operation  may include an operation  for presenting the one or more highlighted portions with the one or more unhighlighted portions of the item by presenting the one or more highlighted portions that include one or more audio schemes that are different from one or more audio schemes of the one or more unhighlighted portions. For instance, the highlighted portion presenting module * including the unhighlighted portion presenting module  of the computing device * presenting the one or more highlighted portions * with the one or more unhighlighted portions * of the item * by presenting the one or more highlighted portions * that include one or more audio schemes (e.g., increase audio volume or more bass) that are different from one or more audio schemes of the one or more unhighlighted portions *.","In the same or different implementations, operation  may include an operation  for presenting the one or more highlighted portions with the one or more unhighlighted portions of the item by presenting the one or more highlighted portions that are encircled by one or more boarders. For instance, the highlighted portion presenting module * including the unhighlighted portion presenting module  of the computing device * presenting the one or more highlighted portions * with the one or more unhighlighted portions * of the item * by presenting the one or more highlighted portions * that are encircled by one or more boarders  (see ). In various embodiments, the one or more boarders  to encircle the one or more highlighted portions * may be in the form of one or more lines or other types of boarders.","In the same or different implementations, operation  may include an operation  for presenting the one or more highlighted portions with the one or more unhighlighted portions of the item, the one or more highlighted portions having been previously presented prior to said transfer of the computing device from the first user to the second user in one or more unhighlighted formats. For instance, the highlighted portion presenting module * including the unhighlighted portion presenting module  of the computing device * presenting the one or more highlighted portions * with the one or more unhighlighted portions * of the item *, the one or more highlighted portions * having been previously presented prior to said transfer of the computing device * from the first user  to the second user  in one or more unhighlighted formats.","In the same or different implementations, operation  may include an operation  for presenting the one or more highlighted portions with the one or more unhighlighted portions of the item by presenting the one or more highlighted portions that are displayed at a greater brightness than the one or more unhighlighted portions. For instance, the highlighted portion presenting module * including the unhighlighted portion presenting module  of the computing device * presenting the one or more highlighted portions * with the one or more unhighlighted portions * of the item * by presenting the one or more highlighted portions * that are displayed via, for example, a display device  at a greater brightness than the one or more unhighlighted portions *.","In some cases the one or more highlighted portions * of the item * to be presented through the highlighted portion presenting operation  of  may have been previously selected form of highlighting. For example, and referring now to , in various implementations, the highlighted portion presenting operation  of  may include an operation  for presenting the one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining and in response to being preselected for being highlighted. For instance, the highlighted portion presenting module * of the computing device * presenting the one or more highlighted portions * of the item *, the one or more highlighted portions * being highlighted in response, at least in part, to determining that the computing device * has been transferred from the first user  to the second user  and in response to being preselected (e.g., selected by the first user  or by a third party prior to the transfer of the computing device *) for being highlighted.","As further illustrated in , operation  may include one or more additional operations in various alternative implementations. For example, in some implementations, operation  may include an operation  for presenting the one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining and in response to being selected for highlighting by the first user prior to the transfer of the computing device from the first user to the second user. For instance, the highlighted portion presenting module * of the computing device * presenting the one or more highlighted portions * of the item *, the one or more highlighted portions * being highlighted in response, at least in part, to the determining that the computing device * has been transferred from the first user  to the second user  and in response to being selected for highlighting by the first user  as detected by, for example, the highlighting selection detecting module *(see and ) prior to the transfer of the computing device * from the first user  to the second user .","Operation , in turn, may include an operation  for presenting the one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining and in response to being selected for highlighting by the first user prior to the transfer of the computing device from the first user to the second user, the first user having provided the selection by selecting from the item one or more portions for highlighting through a user interface in some implementations. For instance, the highlighted portion presenting module * of the computing device * presenting the one or more highlighted portions * of the item *, the one or more highlighted portions * being highlighted in response, at least in part, to determining that the computing device * has been transferred from the first user  to the second user  and in response to being selected for highlighting by the first user  as detected by, for example, the highlighting selection detecting module * prior to the transfer of the computing device * from the first user  to the second user , the first user  having provided the selection by selecting from the item one or more portions (e.g., highlighted portions * prior to transfer) for highlighting through a user interface  (e.g., a touch screen, a keypad or a keyboard, a mouse, and so forth).","In some cases, operation  may further include an operation  for presenting the one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining and in response to being selected for highlighting by the first user prior to the transfer of the computing device from the first user to the second user, the first user having provided the selection by having designated the one or more portions of the item for highlighting via a touch screen. For instance, the highlighted portion presenting module * of the computing device * presenting the one or more highlighted portions * of the item *, the one or more highlighted portions * being highlighted in response, at least in part, to determining that the computing device * has been transferred from the first user  to the second user  and in response to being selected for highlighting by the first user * as detected by, for example, the highlighting selection detecting module * prior to the transfer of the computing device * from the first user  to the second user , the first user  having provided the selection by having designated the one or more portions of the item * for highlighting via a touch screen (e.g., display device ). In various implementations, the first user  may select one or more portions of an item * for highlighting by simply marking (e.g., tagging) the one or more portions to be highlighted via, for example, a touch screen. The marking of the one or more portions may be by, for example, circling , checking or x-ing , writing a line , next to the portion to be highlighted, and so forth as illustrated in , In various implementations, the selection of the portion or portions to be highlighted may be accomplished without having to highlight (e.g., highlight entirely) each of the portion or portions to be highlighted, but by merely marking or tagging only part or parts of each of the portions of the item * to be highlighted.","For example, in some cases, operation  may include an operation  for presenting the one or more highlighted portions of the item, the one or more highlighted portions being highlighted in response, at least in part, to said determining and in response to being selected for highlighting by the first user prior to the transfer of the computing device from the first user to the second user, the first user having provided the selection by only tagging one or more parts respectively of the one or more portions of the item through a display device, the one or more portions being entirely highlighted in response to the marking of the one or more parts of the one or more portions. For instance, the highlighted portion presenting module * of the computing device * presenting the one or more highlighted portions * of the item *, the one or more highlighted portions * being highlighted in response, at least in part, to determining that the computing device * has been transferred from the first user  to the second user  and in response to being selected for highlighting by the first user  as detected by, for example, the highlighting selection detecting module * prior to the transfer of the computing device * from the first user  to the second user , the first user  having provided the selection by only tagging (e.g., marking by writing a check marking, clicking, tapping, etc.) one or more parts respectively of the one or more portions of the item * through a display device , the one or more portions being entirely highlighted in response to the marking of the one or more parts of the one or more portions. In other words, if the first user  wishes to highlight certain portions of an item * after the computing device * has been transferred to the second user , then the first user  may merely mark or tag only part of the portion to be highlighted by simply writing, tapping, or clicking only part of the portion of the item to be highlighted. Thus, in some cases, an item * may be divided into multiple portions. For example, in the example item , each of the illustrated paragraphs may be distinct portions of the item . A user, such as first user , may select a particular portion for highlighting merely by writing a check mark (e.g., or clicking or tapping via a touch screen) only a small part of the portion to be highlighted.","In some cases, the highlighted portion presenting operation  of  may involve highlighting only those portion or portions of the item * that are determined to be linked to the second user . For example, and referring now to , in various implementations, the highlighted portion presenting operation  of  may include an operation  for presenting the one or more highlighted portions of the item, the one or more highlighted portions being selectively highlighted in response, at least in part, to said determining and in response to ascertaining that the one or more portions of the item that are to be highlighted being specifically associated with the second user. For instance, the highlighted portion presenting module * including the user association ascertaining module  (see ) of the computing device * presenting the one or more highlighted portions * of the item *, the one or more highlighted portions * being selectively highlighted in response, at least in part, to determining that the computing device * has been transferred from the first user  to the second user  and in response to the user association ascertaining module  ascertaining that the one or more portions *of the item * that are to be highlighted being specifically associated with the second user  (while those portions of the item * that are ascertained to be not associated with the second user  not being highlighted).","As further illustrated in , in various implementations, operation  may include one or more additional operations in various alternative implementations. For example, in some implementations, operation  may include an operation  for ascertaining that the one or more portions of the item that are to be highlighted are specifically associated with the second user by ascertaining that the one or more portions of the items that are to be highlighted being specifically associated with identity of the second user. For instance, the user association ascertaining module  including the user identity association ascertaining module  (see ) of the computing device * ascertaining that the one or more portions (e.g., one or more highlighted portions *) of the item * that are to be highlighted are specifically associated with the second user  when the user identity association ascertaining module  ascertains that the one or more portions of the items that are to be highlighted are specifically associated with identity (e.g., biometric characteristics or user ID credentials such as username) of the second user .","In some cases, operation  may in turn include an operation  for ascertaining that the one or more portions of the items that are to be highlighted are specifically associated with identity of the second user by identifying the second user based, at least in part, on one or more biometric characteristics of the second user as sensed by one or more sensors. For instance, the user identity association ascertaining module  including the user identifying module  (see ) of the computing device * ascertaining that the one or more portions (see, for example, highlighted portion of ) of the items * that are to be highlighted are specifically associated with identity of the second user  when the user identifying module  at least identifies the second user  based, at least in part, on one or more biometric characteristics of the second user  as sensed by one or more sensors . Note that in some implementations, the user identifying module  of may be the same module as the user identifying module  of ","In some implementations, operation  may include an operation  for identifying the second user based, at least in part, on the one or more biometric characteristics of the second user by identifying the second user based, at least in part, on one or more movement characteristics of the second user as sensed by one or more movement sensors. For instance, the user identifying module  of the computing device * identifying the second user * based, at least in part, on the one or more biometric characteristics of the second user  by identifying the second user  based, at least in part, on one or more movement characteristics (e.g., signature movements including, for example, signature heart or pulse vibration or signature gestures) of the second user  as sensed by one or more movement sensors .","In some implementations, operation  may include an operation  for identifying the second user based, at least in part, on one or more biometric characteristics of the second user by identifying the second user based, at least in part, on one or more facial or retinal characteristics of the second user as sensed by one or more image capturing devices. For instance, the user identifying module  of the computing device * identifying the second user * based, at least in part, on one or more biometric characteristics of the second user  by identifying the second user  based, at least in part, on one or more facial or retinal characteristics of the second user  as sensed by one or more image capturing devices .","In some implementations, operation  may include an operation  for identifying the second user based, at least in part, on one or more biometric characteristics of the second user by identifying the second user based, at least in part, on one or more voice characteristics of the second user as sensed by one or more audio capturing devices. For instance, the user identifying module  of the computing device * identifying the second user * based, at least in part, on one or more biometric characteristics of the second user  by identifying the second user  based, at least in part, on one or more voice characteristics (e.g., signature voice pattern) of the second user  as sensed by one or more audio capturing device .","In some implementations, operation  may include an operation  for identifying the second user based, at least in part, on one or more biometric characteristics of the second user by identifying the second user based, at least in part, on one or more biometric characteristics of the second user as sensed by two or more combinations of a movement sensor, an image capturing device, and\/or an audio capturing device. For instance, the user identifying module  of the computing device * identifying the second user * based, at least in part, on one or more biometric characteristics of the second user  by identifying the second user  based, at least in part, on one or more biometric characteristics of the second user  as sensed by at least two or more combinations of a movement sensor , an image capturing device , and\/or an audio capturing device .","Those having skill in the art will recognize that the state of the art has progressed to the point where there is little distinction left between hardware and software implementations of aspects of systems; the use of hardware or software is generally (but not always, in that in certain contexts the choice between hardware and software can become significant) a design choice representing cost vs. efficiency tradeoffs. Those having skill in the art will appreciate that there are various vehicles by which processes and\/or systems and\/or other technologies described herein can be effected (e.g., hardware, software, and\/or firmware in one or more machines or articles of manufacture), and that the preferred vehicle will vary with the context in which the processes and\/or systems and\/or other technologies are deployed. For example, if an implementer determines that speed and accuracy are paramount, the implementer may opt for a mainly hardware and\/or firmware vehicle; alternatively, if flexibility is paramount, the implementer may opt for a mainly software implementation that is implemented in one or more machines or articles of manufacture; or, yet again alternatively, the implementer may opt for some combination of hardware, software, and\/or firmware in one or more machines or articles of manufacture. Hence, there are several possible vehicles by which the processes and\/or devices and\/or other technologies described herein may be effected, none of which is inherently superior to the other in that any vehicle to be utilized is a choice dependent upon the context in which the vehicle will be deployed and the specific concerns (e.g., speed, flexibility, or predictability) of the implementer, any of which may vary. Those skilled in the art will recognize that optical aspects of implementations will typically employ optically-oriented hardware, software, and or firmware in one or more machines or articles of manufacture.","The foregoing detailed description has set forth various embodiments of the devices and\/or processes via the use of block diagrams, flowcharts, and\/or examples. Insofar as such block diagrams, flowcharts, and\/or examples contain one or more functions and\/or operations, it will be understood by those within the art that each function and\/or operation within such block diagrams, flowcharts, or examples can be implemented, individually and\/or collectively, by a wide range of hardware, software, firmware, or virtually any combination thereof. In one embodiment, several portions of the subject matter described herein may be implemented via Application Specific Integrated Circuitry (ASICs), Field Programmable Gate Arrays (FPGAs), digital signal processors (DSPs), or other integrated formats. However, those skilled in the art will recognize that some aspects of the embodiments disclosed herein, in whole or in part, can be equivalently implemented in integrated circuitry, as one or more computer programs running on one or more computers (e.g., as one or more programs running on one or more computer systems), as one or more programs running on one or more processors (e.g., as one or more programs running on one or more microprocessors), as firmware, or as virtually any combination thereof, and that designing the circuitry and\/or writing the code for the software and or firmware would be well within the skill of one of skill in the art in light of this disclosure. In addition, those skilled in the art will appreciate that the mechanisms of the subject matter described herein are capable of being distributed as a program product in a variety of forms, and that an illustrative embodiment of the subject matter described herein applies regardless of the particular type of signal bearing medium used to actually carry out the distribution. Examples of a signal bearing medium include, but are not limited to, the following: a recordable type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.; and a transmission type medium such as a digital and\/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.).","In a general sense, those skilled in the art will recognize that the various aspects described herein which can be implemented, individually and\/or collectively, by a wide range of hardware, software, firmware, or any combination thereof can be viewed as being composed of various types of \u201celectrical circuitry.\u201d Consequently, as used herein \u201celectrical circuitry\u201d includes, but is not limited to, electrical circuitry having at least one discrete electrical circuit, electrical circuitry having at least one integrated circuit, electrical circuitry having at least one application specific integrated circuit, electrical circuitry forming a general purpose computing device configured by a computer program (e.g., a general purpose computer configured by a computer program which at least partially carries out processes and\/or devices described herein, or a microprocessor configured by a computer program which at least partially carries out processes and\/or devices described herein), electrical circuitry forming a memory device (e.g., forms of random access memory), and\/or electrical circuitry forming a communications device (e.g., a modem, communications switch, or optical-electrical equipment). Those having skill in the art will recognize that the subject matter described herein may be implemented in an analog or digital fashion or some combination thereof.","Those having skill in the art will recognize that it is common within the art to describe devices and\/or processes in the fashion set forth herein, and thereafter use engineering practices to integrate such described devices and\/or processes into data processing systems. That is, at least a portion of the devices and\/or processes described herein can be integrated into a data processing system via a reasonable amount of experimentation. Those having skill in the art will recognize that a typical data processing system generally includes one or more of a system unit housing, a video display device, a memory such as volatile and non-volatile memory, processors such as microprocessors and digital signal processors, computational entities such as operating systems, drivers, graphical user interfaces, and applications programs, one or more interaction devices, such as a touch pad or screen, and\/or control systems including feedback loops and control motors (e.g., feedback for sensing position and\/or velocity; control motors for moving and\/or adjusting components and\/or quantities). A typical data processing system may be implemented utilizing any suitable commercially available components, such as those typically found in data computing\/communication and\/or network computing\/communication systems.","The herein described subject matter sometimes illustrates different components contained within, or connected with, different other components. It is to be understood that such depicted architectures are merely exemplary, and that in fact many other architectures can be implemented which achieve the same functionality. In a conceptual sense, any arrangement of components to achieve the same functionality is effectively \u201cassociated\u201d such that the desired functionality is achieved. Hence, any two components herein combined to achieve a particular functionality can be seen as \u201cassociated with\u201d each other such that the desired functionality is achieved, irrespective of architectures or intermedial components. Likewise, any two components so associated can also be viewed as being \u201coperably connected\u201d, or \u201coperably coupled\u201d, to each other to achieve the desired functionality, and any two components capable of being so associated can also be viewed as being \u201coperably couplable\u201d, to each other to achieve the desired functionality. Specific examples of operably couplable include but are not limited to physically mateable and\/or physically interacting components and\/or wirelessly interactable and\/or wirelessly interacting components and\/or logically interacting and\/or logically interactable components.","While particular aspects of the present subject matter described herein have been shown and described, it will be apparent to those skilled in the art that, based upon the teachings herein, changes and modifications may be made without departing from the subject matter described herein and its broader aspects and, therefore, the appended claims are to encompass within their scope all such changes and modifications as are within the true spirit and scope of the subject matter described herein. Furthermore, it is to be understood that the invention is defined by the appended claims.","It will be understood by those within the art that, in general, terms used herein, and especially in the appended claims (e.g., bodies of the appended claims) are generally intended as \u201copen\u201d terms (e.g., the term \u201cincluding\u201d should be interpreted as \u201cincluding but not limited to,\u201d the term \u201chaving\u201d should be interpreted as \u201chaving at least,\u201d the term \u201cincludes\u201d should be interpreted as \u201cincludes but is not limited to,\u201d etc.). It will be further understood by those within the art that if a specific number of an introduced claim recitation is intended, such an intent will be explicitly recited in the claim, and in the absence of such recitation no such intent is present. For example, as an aid to understanding, the following appended claims may contain usage of the introductory phrases \u201cat least one\u201d and \u201cone or more\u201d to introduce claim recitations. However, the use of such phrases should not be construed to imply that the introduction of a claim recitation by the indefinite articles \u201ca\u201d or \u201can\u201d limits any particular claim containing such introduced claim recitation to inventions containing only one such recitation, even when the same claim includes the introductory phrases \u201cone or more\u201d or \u201cat least one\u201d and indefinite articles such as \u201ca\u201d or \u201can\u201d (e.g., \u201ca\u201d and\/or \u201can\u201d should typically be interpreted to mean \u201cat least one\u201d or \u201cone or more\u201d); the same holds true for the use of definite articles used to introduce claim recitations.","In addition, even if a specific number of an introduced claim recitation is explicitly recited, those skilled in the art will recognize that such recitation should typically be interpreted to mean at least the recited number (e.g., the bare recitation of \u201ctwo recitations,\u201d without other modifiers, typically means at least two recitations, or two or more recitations). Furthermore, in those instances where a convention analogous to \u201cat least one of A, B, and C, etc.\u201d is used, in general such a construction is intended in the sense one having skill in the art would understand the convention (e.g., \u201ca system having at least one of A, B, and C\u201d would include but not be limited to systems that have A alone, B alone, C alone, A and B together, A and C together, B and C together, and\/or A, B, and C together, etc.).","In those instances where a convention analogous to \u201cat least one of A, B, or C, etc.\u201d is used, in general such a construction is intended in the sense one having skill in the art would understand the convention (e.g., \u201ca system having at least one of A, B, or C\u201d would include but not be limited to systems that have A alone, B alone, C alone, A and B together, A and C together, B and C together, and\/or A, B, and C together, etc.). It will be further understood by those within the art that virtually any disjunctive word and\/or phrase presenting two or more alternative terms, whether in the description, claims, or drawings, should be understood to contemplate the possibilities of including one of the terms, either of the terms, or both terms. For example, the phrase \u201cA or B\u201d will be understood to include the possibilities of \u201cA\u201d or \u201cB\u201d or \u201cA and B.\u201d"],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE FIGURES","p":[{"@attributes":{"id":"p-0011","num":"0026"},"figref":"FIG. 1","b":"10"},{"@attributes":{"id":"p-0012","num":"0027"},"figref":"FIG. 2","i":"a ","b":["10","100"]},{"@attributes":{"id":"p-0013","num":"0028"},"figref":["FIG. 2","FIG. 1"],"i":"b ","b":"10"},{"@attributes":{"id":"p-0014","num":"0029"},"figref":["FIG. 2","FIG. 1"],"i":"c ","b":"10"},{"@attributes":{"id":"p-0015","num":"0030"},"figref":["FIG. 2","FIG. 1"],"i":"d ","b":"10"},{"@attributes":{"id":"p-0016","num":"0031"},"figref":["FIG. 2","FIG. 1"],"i":"e ","b":["10","10"]},{"@attributes":{"id":"p-0017","num":"0032"},"figref":["FIG. 3","FIG. 1"],"i":"a ","b":["10","10"]},{"@attributes":{"id":"p-0018","num":"0033"},"figref":["FIG. 3","FIG. 1"],"i":"b ","b":["10","10"]},{"@attributes":{"id":"p-0019","num":"0034"},"figref":["FIG. 3","FIGS. 3"],"i":["c ","a ","b. "],"b":["102","102","102","3"]},{"@attributes":{"id":"p-0020","num":"0035"},"figref":["FIG. 3","FIGS. 3"],"i":["d ","a ","b. "],"b":["104","104","104","3"]},{"@attributes":{"id":"p-0021","num":"0036"},"figref":["FIG. 3","FIGS. 3"],"i":["e ","a ","b. "],"b":["120","10","10","3"]},{"@attributes":{"id":"p-0022","num":"0037"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0023","num":"0038"},"figref":["FIG. 5","FIG. 4"],"i":"a ","b":"402"},{"@attributes":{"id":"p-0024","num":"0039"},"figref":["FIG. 5","FIG. 4"],"i":"b ","b":"402"},{"@attributes":{"id":"p-0025","num":"0040"},"figref":["FIG. 5","FIG. 4"],"i":"c ","b":"402"},{"@attributes":{"id":"p-0026","num":"0041"},"figref":["FIG. 5","FIG. 4"],"i":"d ","b":"402"},{"@attributes":{"id":"p-0027","num":"0042"},"figref":["FIG. 5","FIG. 4"],"i":"e ","b":"402"},{"@attributes":{"id":"p-0028","num":"0043"},"figref":["FIG. 5","FIG. 4"],"i":"f ","b":"402"},{"@attributes":{"id":"p-0029","num":"0044"},"figref":["FIG. 5","FIG. 4"],"i":"g ","b":"402"},{"@attributes":{"id":"p-0030","num":"0045"},"figref":["FIG. 5","FIG. 4"],"i":"h ","b":"402"},{"@attributes":{"id":"p-0031","num":"0046"},"figref":["FIG. 5","FIG. 4"],"i":"i ","b":"402"},{"@attributes":{"id":"p-0032","num":"0047"},"figref":["FIG. 5","FIG. 4"],"i":"j ","b":"402"},{"@attributes":{"id":"p-0033","num":"0048"},"figref":["FIG. 6","FIG. 4"],"i":"a ","b":"404"},{"@attributes":{"id":"p-0034","num":"0049"},"figref":["FIG. 6","FIG. 4"],"i":"b ","b":"404"},{"@attributes":{"id":"p-0035","num":"0050"},"figref":["FIG. 6","FIG. 4"],"i":"c ","b":"404"},{"@attributes":{"id":"p-0036","num":"0051"},"figref":["FIG. 7","FIG. 1"],"i":["a ","a ","a "],"b":["701","10","701"]},{"@attributes":{"id":"p-0037","num":"0052"},"figref":["FIG. 7","FIG. 7"],"i":["b ","b ","a ","a "],"b":["702","701"]},{"@attributes":{"id":"p-0038","num":"0053"},"figref":["FIG. 7","FIG. 7"],"i":["c ","c ","a ","a "],"b":["702","701"]},{"@attributes":{"id":"p-0039","num":"0054"},"figref":["FIG. 7","FIG. 7"],"i":["d ","d ","a ","a "],"b":["702","701"]},{"@attributes":{"id":"p-0040","num":"0055"},"figref":"FIG. 7","i":["e ","e ","b "],"b":["720","701"]},{"@attributes":{"id":"p-0041","num":"0056"},"figref":["FIG. 7","FIG. 7"],"i":["f ","f ","b ","e "],"b":["720","701"]}]},"DETDESC":[{},{}]}
