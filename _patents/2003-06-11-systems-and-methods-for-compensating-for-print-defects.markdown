---
title: Systems and methods for compensating for print defects
abstract: Diminished intensity defects occur in electrostatic printing between image regions having grey levels, i.e., different electrostatic potential and toner densities. Such defects occur when higher density regions “steal” toner from lower density regions. The system and methods according to this invention compensate for these defects by modifying the input image data. The input image data in lighter regions that precede or occur near a light-to-dark transition to a dark region are raised above the input image values. Thus, when printed, the printed image intensity values in such regions are higher than the corresponding image intensity values. As a result, when the higher density regions steal the extra toner provided due to the raised values, the gray level of the printed image corresponds to the desired gray level. The magnitude of these defects is periodically measured with a calibration pattern to generate and/or update compensation factors used in the compensation process.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07295349&OS=07295349&RS=07295349
owner: Xerox Corporation
number: 07295349
owner_city: Stamford
owner_country: US
publication_date: 20030611
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS"],"p":["1. Field of Invention","This invention relates to systems and methods for reducing print defects in electrostatically formed images.","2. Description of Related Art","The electrophotographic printing process is well known. Typically, electrostatic imaging and printing processes include several distinct stages. These stages typically include some or all of (1) charging, (2) exposing, (3) developing, (4) transferring, (5) fusing, and (6) cleaning. An electrophotographic printing system typically includes a printer or a marking engine. The printer or marking engine may include a photoconductive belt or drum as a photoconductive surface.","In the charging stage, a uniform electrical charge is uniformly deposited on the surface of the photoconductive belt or drum to electrostatically sensitize the photoconductive surface. The electrophotographic exposing stage includes rotating or moving the charged photoconductive surface to an exposure station, where the charged portion of the photoconductive surface is exposed to light from, for example, a scanning laser beam. By modulating the light beam, an electrostatic latent image of variable electrostatic potential is recorded on the photoconductive surface. The light beam is modulated with an input serial image information stream so that individual picture elements or pixels of the image represented by the data stream are exposed on the photoreceptor to form the latent image.","The electrophotographic developing stage uses a developer material, such as a toner powder, which is attracted to the latent image in varying densities depending varying electrostatic potential of the latent image. In the transferring and fusing stages, the toner powder image is transferred to a copy sheet, and finally the toner powder image is heated and\/or pressed to permanently fuse the powder image to the copy sheet in the image configuration. In the electrophotographic cleaning stage, the photoconductive surface of toner is cleaned and the charge images are discharged so that the process can be reliably repeated.","Defects in the scanning and printing process can arise from one or more of the stages described above. Defects may occur in the development stage, where parts of the processed image will have regions of diminished toner density. Such regions of diminished intensity tend to occur in electrostatic printing at an interface of two objects of an image having different gray levels, and therefore different electrostatic potential and toner densities. The object that would result in a higher toner density can \u201csteal\u201d toner from the region that would result in a lower toner density, creating a toner \u201cstarvation\u201d or \u201cwhite space\u201d defect.","The electrostatic latent image passes serially through the development process. Some images may contain features that have a darker solid region on top of a lighter solid region. The lead edge of the dark solid is the edge that passes first through the development stage. The trail edge of a dark solid is the edge that passes last through the development state.","The white space can occur either on the lead edge of the interface, the trail edge of the interface, or both. The physical cause can be different for lead edge white space and trail edge white space. Therefore, the magnitude of the white space can be different on the lead edge and the trail edge.","This invention provides systems and methods that compensate for the white space defect.","This invention additionally provides systems and methods that modify the input image pixel densities or gray level of the input image to compensate for the white space defect.","This invention separately provides systems and methods that measure the magnitude of a diminished toner density region or white space defect.","This invention additionally provides systems and methods that measure the magnitude of the white space defect using one of several existing toner area coverage sensors and a calibration pattern.","This invention further provides systems and methods that measure the magnitude of the white space defect using a scanner and a calibration pattern.","This invention also provides systems and methods that measure the magnitude of the white space defect using a modified toner area coverage sensor and a calibration pattern.","This invention additionally provides systems and methods that measure the magnitude of the white space defect by creating, printing, scanning, and processing an image that is sensitive to the magnitude of the white space defect.","This invention separately provides systems and methods that generate compensation factors based on a measured magnitude of a diminished toner density region.","This invention separately provides systems and methods that use efficient image preprocessing to implement white space defect compensation.","In various exemplary embodiments, the systems and methods according to this invention compensate for the white space defect by modifying the input image pixel intensity and\/or the input image bitmap. The input image intensity values in lighter regions that precede or occur near a light-to-dark transition to a dark object are raised above the input image intensity values. Thus, when printed, the printed image intensity values in such regions are higher than the corresponding image intensity values. As a result, the gray level of the printed image corresponds to the desired gray level. In various exemplary embodiments, the magnitude of the white space defect is periodically measured with a calibration pattern to generate and\/or update compensation factors that are used in the compensation process. This is done at least once prior to image processing. In various exemplary embodiments, an approximate method for determining modified pixel intensity parameters is used which only requires the current scan line and an historical state be processed during the real time data flow.","These and other features and advantages of this invention are described in, or are apparent from, the following detailed description of various exemplary embodiments of the systems and methods according to this invention.","The systems and methods according to this invention compensate for diminished toner density regions, also known as \u201cstarvation\u201d defects and\/or \u201cwhite space\u201d defects, arising at the interface of two adjacent objects of a printed image that have different intended gray levels. The formation of this diminished toner density region between two such objects may be caused by the physics of the electrostatic printing process, in particular the difference in charge or electrostatic potential, between the objects of different gray levels in the latent image on the photoreceptor.","In various exemplary embodiments, for example, when the lighter object is adjacent to, or otherwise near to, the leading edge of the darker object, as shown in , when the charged toner particles are brought into contact with the electrostatic image, the higher potential difference of the as yet undeveloped dark region causes some toner particles to \u201cshift away\u201d from the nearby lighter region as that lighter region is developed.","In another example, toner developing a dark image may deplete the supply of toner on the supply roll to some extent. At a trailing edge interface, such as that shown in , this depleted supply will develop the following, lighter-density image less efficiently and it will be lighter. As the supply roll turns, a more well supplied roll will develop the rest of the light gray area away from the interface and it will be darker than what was printed at the interface.","The decreased development efficiency at the interface results in a small \u201cwhite space\u201d or diminished toner density region in the lighter object. The diminished toner region is also known as a \u201cstarvation\u201d defect. Often, the diminished toner density region may have a width of about 0.1 millimeter to about 3.0 millimeters.","This problem is not what is typically called halo in the offset process. In printing processes, halo usually refers to the white area that can appear between two adjacent regions of different colors when the color separation layers are misregistered. The misregistration problem can be solved with trapping, i.e., expanding the boundary of one color beyond what is digitally called for so it overlaps with the other color. The white space defect that is the focus of the systems and methods according to this invention appears in a single color separation. Trapping would not solve the white space defect; rather, the white space defect would just move along with the boundary.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 1","FIG. 1"],"b":["110","120","140","110","130","120","120","110"]},{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 2","FIG. 1","FIG. 2"],"b":["150","110","120","130","120","110"]},"It is believed that the white space defect occurs because the relatively lighter undeveloped object, in this case, the background , in the region above, i.e., prior relative to the process direction, the relatively darker undeveloped object, in this case, the Kani characters , is developed first. Consequently, at least some of the toner that was directed at the region  of the relatively lighter background  was more electrostatically attracted to the relatively-darker, as-yet undeveloped object . As a result, the toner that was to be used to sufficiently densely develop the area  instead developed the region . Thus, the area  is relatively starved of toner.","This occurs in regions where the electrostatic attraction of a first region, at the time a second region is developed, is sufficiently stronger than that of the second region to effectively steal toner from the second region. Accordingly, the defect does not occur, at least to the same degree or visibility, at the side or bottom edges of the Kani characters , because, at the time the surrounding portions of the background  that are close to those edges are developed, the relatively darker Kani characters are also being, or have been, developed, thus reducing the electrostatic attraction of the Kani characters  sufficiently that the Kani characters  generally do not steal, or steal only a little of, the toner destined for those regions the background .",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 3","FIG. 4","FIG. 4"],"b":["310","320","310","330","340","350","350"]},"The input image curve  shown in  indicates the desired halftone density of the input digital image. The region of the input image curve  at a distance between \u22120.5 mm to 0 mm represents a dark object and has a density of 1.0. This region of the input image curve  corresponds to the dark object area  of the uncompensated or unmodified bitmap  shown in  in which every bit in the bitmap is activated. The input image curve  is constant at a density of 0.22 from the edge at 0 mm, and past 1 mm as far as the graph extends. Accordingly, the bitmap spots shown in , between bitmap spot  at 0.2 mm from the edge to spot  at 1.0 mm from the edge all have the same bit count.","The scanned output halftone density curve  shown in  illustrates the actual measured white space defect and is generated from an image of a print taken on a flatbed scanner. The scanned output halftone density curve  shows the periodicity of the halftone. The periodicity shown in the scanned output halftone densely curve  is eliminated by averaging the data over the repeat distance of the halftone, resulting in the smoothed output curve  shown in .","The smoothed output curve  shown in  shows the magnitude of the white space defect. The magnitude of the white space is a function of distance from the edge of the object. At a distance of 0.2 mm, this curve indicates the output halftone density is 0.13, much lower than the input value of 0.22. Accordingly, the halftone spot , 0.2 mm from the edge , in the uncompensated or unmodified halftone image  shown in  is shrunk from toner starvation. At 1 mm from the edge, the smoothed output curve  has returned to its asymptotic value of 0.22. Accordingly, the halftone spot , 1 mm from the edge , in the uncompensated or unmodified halftone image  shown in , is normal sized. The halftone spots between the \u201cshrunken\u201d halftone spot  and the normal halftone spot  increase in size asymptotically, at the same rate as the smoothed output curve .","The method used to compensate for white space defect according to this invention is to modify the input image data, whether the input image intensity data or the bitmap generated based on that input image intensity data, to compensate for the resulting white space defect.  is an illustration of the compensated or modified bitmap  and the corresponding halftone image  produced from that bitmap, both of which have an edge  between a dark object  on the left of the edge and the halftone spots  making up a lighter object  on the right. The arrow  shown in  indicates the process direction.","The compensated or modified input halftone density curve  shown in  indicates the compensation or modification made to either the input image intensity data and\/or the resulting bitmap to compensate for the white space defect. In the compensated or modified input halftone density curve , the density is increased to 0.31 at 0.2 mm from the edge of compensate for the white space defect. Accordingly, in the compensated or modified bitmap , shown in , the compensated or modified bitmap spot , located 0.2 mm from the edge  has an increased number of bits relative to that shown in .","The magnitude of the compensated or modified input halftone density curve  decreases asymptotically from 0.31 at 0.2 mm from the edge to 0.22 at 1 mm from the edge. The number of bits in the bitmap spots also decreases asymptotically from increased number in bitmap spot , shown in , located 0.2 mm form the edge , to the original bitmap spot size at bitmap spot , located 1 mm form the edge . When the compensated or modified bitmap , shown in  is used in the printing process, the result is a compensated or modified halftone image , where the halftone spot  located 0.2 mm form the edge  is the same size as the halftone spot  located 1 mm from the edge .","To implement the white space defect compensations systems and methods and to provide a finished output image that accurately reproduces the gray level of the original input image data, the amount of compensation or modification made to the input image intensity data and\/or to the resulting bitmap must match the magnitude of the white space defect. The magnitude of the white space defect varies as a function of the relative gray levels of the relatively light object and the relatively dark object and the position and angle of the boundary between the light and dark objects relative to the process direction. The magnitude of the white space defect can also be a function of time, and thus can vary over the life of the printer, or other image forming apparatus, and\/or toner supply. As a result, the magnitude of the white space defect should periodically be measured if the white space defect compensation systems and methods according to this invention are to continue to accurately compensate for the white space defect. The magnitude of the white space defect can be measured on a regular schedule or can be measured in response to a request by a user when insufficient or otherwise improper compensation is noticed in a print.","In various exemplary embodiments of the systems and methods according to this invention, the magnitude of the white space defect is measured by printing a calibration pattern onto a substrate, such as paper, with the image forming apparatus, and then scanning the obtained pattern with a scanner. This calibration pattern includes a collection of interfaces between relatively dark objects and relatively light objects that are arranged, in various exemplary embodiments, at different positions and\/or angles relative to the process direction and have different relative gray levels. The gray level of the light objects immediately next to the dark objects in the scanned digital image of the print is compared to the reference digital image of the calibration pattern to measure the resulting magnitude of the white space defect. It should be appreciated that the calibration pattern can be automatically printed and\/or scanned. Alternatively, the calibration pattern can be manually printed and\/or manually scanned.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIG. 6","FIG. 6","FIG. 6","FIG. 18"],"b":["510","520","510","530","512","510"]},"Each of the 70 combinations of dark rectangles  and light background squares  shown in  has a different set of gray levels or toner densities. In this way, a table of the magnitude of both the lead edge and trail edge white space defect, as a function of an absolute gray level and of the gray level difference, can be generated. In various exemplary embodiments, this table is then fit to parameters contained in a compensation function usable to adjust the input image intensity data and\/or the resulting bitmap to compensate for the white space defect. Multilinear interpolation can be used between measured values of the magnitude of the white space to compensate for an arbitrary gray level ratio.","In various exemplary embodiments of the systems and methods according to this invention, an infrared densitometer, such as an enhanced toner area coverage sensor (ETACS), can be used to measure the gray level in the white space region of a calibration pattern. Enhanced toner area coverage sensors are known in the art, and are discussed in U.S. Pat. No. 5,519,497, which is incorporated herein by reference in its entirety.","In various exemplary embodiments, the densitometer is a reflection densitometer and shines a known amount of light onto a developed image on the photoreceptor or printed substrate. The reflection of the specular signal from the photoreceptor is attenuated by the toner, while the diffuse (or scattered) light is increased by presence of toner on the photoreceptor. Both the specular and diffuse light is detected by for example, a photodiode, which generates electrical signals proportional to the amount of received light. Both the specular and diffuse light is a monotonic function of the developed mass. With suitable calibration, the mass or density that was actually developed can be inferred from the optical signal.","In various exemplary embodiments, the densitometer or enhanced toner area coverage sensor typically measures the reflectance of a beam with a diameter of about 2 mm to about 4 mm. The 2 mm to 4 mm beam size is selected to reduce the halftone noise over many beam averages on the halftone cells. The resolution of an enhanced toner area coverage sensor is dependant on beam size. To be useful in measuring the white space regions, a resolution of much less that 1 mm is desirable.",{"@attributes":{"id":"p-0064","num":"0063"},"figref":["FIG. 7","FIG. 7"],"b":["610","620","630"]},{"@attributes":{"id":"p-0065","num":"0064"},"figref":["FIG. 8","FIG. 8","FIG. 8"],"b":["810","720","730","720","730","720","730","720","730"]},"The structured image portion  shown in  has edges perpendicular to the process direction, and, as a result, a white space defect occurs. The structured image portion  shown in  has edges parallel to the process direction and, as a result, little or no white space defect occurs. If white space occurs, as shown in the structured image portion , the enhanced toner area coverage sensor beam will measure a lighter average density than the structured image portion , where white space does not occur.",{"@attributes":{"id":"p-0067","num":"0066"},"figref":["FIG. 9","FIG. 8"],"b":["740","760","930","750","720"]},"By generating additional calibration patterns, such as the one shown in , with different spacing between the edges, the white space as a function of distance from the edge can be determined. This difference in signal output from each of these patterns is then mapped to the compensation function used to generate the compensated image intensity data and\/or the compensated bitmap.","One exemplary embodiment of a method to determine the bitmap modification for each pixel is to examine a neighborhood of the pixel large enough to detect any edges between dark and light objects that can cause a white space defect at that pixel. Examining large clusters of data in this way is an inefficient use of resources, as each pixel being examined requires a minimum of 20-30 scanlines of pixels to be compared to the current pixel and possibly to each other. The bandwidth required to perform the comparison on this large a set of pixels is difficult to meet in a real time process.","A second exemplary embodiment of a method to determine the bitmap modification for each pixel uses an approximation that only requires two scan lines of data be examined at a time. This method uses the current scan line and a one scan line historical state which approximates the effect on a scan line that is many scanlines away of a falling edge from a dark object to a light object. It should be appreciated that, in the following description, in various exemplary embodiments, the image intensity value for a pixel ranges from 0, representing the lowest image intensity value, to 255, representing the highest image intensity value.","The white space defect can occur at the leading edge, a trailing edge, or at both edges in a printed image. When a defect occurs at the trailing edge only, the image is processed from the leading edge of the image to the trailing edge of the image. When a defect occurs at the leading edge only, the image is first send to a buffer. The image is then processed from the trailing edge of the image to the leading edge of the image. When a defect occurs at both the leading edge and the trailing edge, the image data is compensated using a two step process. First, the trailing edge is compensated by processing the image from the leading edge to the trailing edge. The compensated image data is saved in a buffer. Then, the buffered image is processed from the trailing edge to the leading edge to compensate for the leading edge white space defects. The twice-compensated image data is buffered and printed.","Eq. (1) is an exemplary equation usable to determine the compensated or modified image intensity value Ifor a given pixel. That is, the modified or compensated image intensity value Iis:",{"@attributes":{"id":"p-0073","num":"0072"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"msub":{"mi":["I","c"]},"mo":["=","\u2062"],"mi":{},"mrow":{"mrow":[{"msub":{"mi":["I","p"]},"mo":"-","mrow":{"msub":{"mi":["M","p"]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"for","mn":"0"}},{"msub":[{"mi":["I","p"]},{"mi":["M","p"]}],"mo":"-"}],"mo":["<","<"],"msub":{"mi":["I","m"]}}},"mo":","}}},{"mtd":{"mrow":{"mo":["=","\u2062"],"mi":{},"mrow":{"mrow":{"mrow":{"mn":"0","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"4.7em","height":"4.7ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"for","msub":{"mi":["I","p"]}},"mo":"-","msub":{"mi":["M","p"]}},"mo":"<","mn":"0"}}}},{"mtd":{"mrow":{"mo":["=","\u2062"],"mi":{},"mrow":{"mrow":[{"msub":[{"mi":["I","m"]},{"mi":["I","m"]}],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"3.9em","height":"3.9ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"for"},{"msub":[{"mi":["I","p"]},{"mi":["M","p"]}],"mo":"-"}],"mo":"<"}}}}]}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}},"br":{}},"Iis an input intensity value for the current pixel p of the current scan line;","Mis a modification value; and","Iis a maximum image intensity value;","Eq. (2) is an exemplary equation usable to determine the modification Mrequired for a given pixel. That is, the modification Mis:\n\n*()+0.5,\u2003\u2003(2)\n\nwhere:\n","\u221d is a calibration factor for a magnitude of the starvation object;","Cis a modification factor based on an image magnitude of the current pixel p;","His a historical state value for the current pixel p; and","Iis the image value for the current pixel p in the input image.","Eq. (3) is an exemplary equation defining the modification factor Cfor the current pixel based on the image value Iof the current pixel. That is, Cis:\n\n=1\u22124[()\u22120.5)],\u2003\u2003(3)\n\nwhere Iis the maximum image intensity value of the input image data. For example, for 8-bit image data, the maximum image intensity value Iis 255.\n",{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 10","FIG. 10"],"sub":["p ","p "]},"Eq. (4) is one exemplary equation defining the historical state value Hfor the next scanline j relative to the current pixel p. That is, the historical state value His:\n\n=(\u03b2*)\/(1+\u03b2)+0.5\u2003\u2003(4)\n\nwhere:\n","\u03b2 is a calibration factor for the white space defect;","Hthe historical state for the pixel p for the current scan line; and","Iis the image intensity value of the current pixel p.",{"@attributes":{"id":"p-0088","num":"0087"},"figref":"FIG. 11","sub":"p "},{"@attributes":{"id":"p-0089","num":"0088"},"figref":["FIG. 12","FIG. 12"],"b":["100","200","300","400","500"]},"In step S, the one or more magnitudes of the white space defect are measured and the compensation parameters are updated. Then, in step S, the image data to be printed is input. Next, in step S, the image data is analyzed to determine which kind, trailing edge, leading edge, or both, of white space defect compensation is desired or needed. Operation then continues to step S.","In step S, a determination is made whether trailing edge compensation is desired. If trailing edge compensation is desired, operation continues to step S. Otherwise, operation jumps directly to step S. In step S, the image data is processed in a forward direction to determine the trailing edge compensation amounts that each pixel needs to be modified by, and to modify each pixel by the determined trailing edge compensation amount. Operation then continues to step S, where a determination is made whether leading edge compensation is desired. If leading edge compensation is desired, operation continues to step S. Otherwise, operation jumps directly to step S. In step S, the image data is processed in a reverse direction to determine the leading edge compensation amounts that each pixel needs to be modified by, and to modify each pixel by the determined leading edge compensation amount. Operation then continues to step S, where the compensated bitmap data is used to generate the requested hard copy output. Then, in step S, operation of the method ends.",{"@attributes":{"id":"p-0092","num":"0091"},"figref":["FIG. 13","FIG. 13","FIG. 6"],"b":["400","410","8","910","420","430","440"]},"In step S, the differences detected in step S are used to determine one or more updated values for one or more of the compensation parameters. Operation then continues to step S, where operation returns to step S.",{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 14","FIG. 14"],"b":["800","800","810","820","830","840"]},"In step S, the current scan line is identified as the historical scan line. Operation then returns to step S. In contrast, in step S, the first or next pixel in the current scan line is selected as the current pixel. Then, in step S, the compensated input image intensity value for the current pixel is determined. Next, in step S, the historical state value Hof the current pixel for the next scan line is determined. In various exemplary embodiments, the historical state value His determined by first averaging the compensated image intensity value of the current pixel with the input image intensity values of pixels in the neighborhood of the current pixel that are in the current scan line. It should be appreciated that a more complex one-dimensional filter can be used to adjust the input image intensity value. In various other exemplary embodiments, Eq. (4) is then used to finally determine the historical state value H. Operation then continues to step S.","In step S, the compensated image intensity value for the current pixel is stored as part of the trailing edge compensated image data. Next, in step S, a determination is made whether the current pixel is the last pixel in the current scan line. If the current pixel is the last pixel in the current scan line, operation continues to step S. Otherwise, operation returns to step S. In step S, a determination is made whether the current scan line is the last scan line. If the current scan line is the last scan line, operation continues to step S. Otherwise, operation returns to step S. In step S, operation returns to step S.",{"@attributes":{"id":"p-0097","num":"0096"},"figref":["FIG. 15","FIG. 15"],"b":["850","850","851","853","852"],"sub":["p ","p ","p ","p "]},"In step S, the trailing edge compensated image intensity value Iat the current pixel is set to the input image intensity value Iof the current pixel. Operation then jumps to step S. In contrast, in step S, the trailing edge compensated image intensity value Ifor the current pixel is set to the input image intensity value Iof the current pixel minus the trailing edge image intensity value modification Mrequired for the current pixel. In various exemplary embodiments, the trailing edge image intensity value modification Mrequired for the current pixel is determined using Eq. (2). Then, in step S, a determination is made whether the trailing edge compensated image intensity value Ifor the current pixel is greater than a maximum image intensity value I. If the trailing edge compensated image intensity value Ifor the current pixel is not greater than the maximum image intensity value I, operation jumps to step S. Otherwise, operation continues to step S.","In step S, the trailing edge compensated image intensity value Ifor the current pixel is set to the maximum image intensity value I. Operation then jumps to step S. In contrast, in step S, a determination is made whether the trailing edge compensated image intensity value Ifor the current pixel is less than a minimum image intensity value I. If the trailing edge compensated image intensity value Ifor the current pixel is not less than I\u2032, operation jumps to step S. Otherwise, operation continues to step S. In step S, the tailing edge compensated image intensity value Ifor the current pixel is set to I\u2032. Operation then continues to step S, where operation of the method returns to step S.","It should be appreciated that step S operates substantially identically to steps S-S outlined above with respect to , except that the pixels of the trailing edge compensated image date are analyzed from the last line towards the first line. Similarly, rather than determining trailing edge compensated image data, compensated image intensity values Ior Ior trailing edge image intensity value modification Mvalues, leading edge compensated image data, compensated image intensity values Ior Iand leading edge image intensity value modification Mvalues are determined in step S.",{"@attributes":{"id":"p-0101","num":"0100"},"figref":["FIG. 16","FIG. 16"],"b":["800","800","810","820","830","840","850","860","870","880"]},"As shown in , one or more user input devices , one or more calibration sensors , an image data source , and an image data sink  are connected to the print data modifying system  by links , ,  and , respectively.","In general, the image data source  can be any known or later-developed device that is capable of providing image data to the print data modifying system . In general, the image data sink  can be any known or later-developed device that is capable of electrophotographically printing the confirmation sheet generated by the print data modifying system  and that experiences the white space defect, or a storage device or communication network that can store or transmit the data for later and\/or remote printing of the data on such a printer.","The image data source  and\/or the image data sink  can be integrated with the print data modifying system , such as in a digital copier. In addition, the print data modifying system  may be integrated with devices providing additional functions in addition to the image data source  and\/or the image data sink , in a larger system that performs all functions, such as a multi-function printer\/scanner\/copier.","The one or more user input devices  may be any combination of one or more input devices, such as a keyboard, a mouse, a joy stick, a trackball, a touch pad, a touch screen, a pen-based system, a microphone and associated voice recognition software, or any other known or later-developed device usable to input user commands to the print data modifying system . It should be understood that the one or more user input devices , of  do not need to be the same type of device.","Each of the links , ,  and  connecting the input device(s) , the calibration sensor(s) , the image data source  and the image data sink , to the print data modifying system  can be a connection device, such as a direct cable connection, a modem, a local area network, a wide area network, a storage area network an intranet, the Internet, any other distributed processing network, or any other known or later-developed connection device. It should be appreciated that any of these connections may include both wired and wireless portions. In general, each of the links , ,  and  can be of any known or later-developed connection system or structure usable to connect the respective devices to the print data modifying system . It should be understood that the links , ,  and  do not need to be of the same type.","The memory  can be implemented using any appropriate combination of alterable, volatile, or non-volatile memory or non-alterable, or fixed memory. The alterable memory, whether volatile or non-volatile can be implemented using any one or more of static or dynamic RAM, a floppy disk and disk drive, a writable or rewritable optical disk and disk drive, a hard drive, flash memory or the like. Similarly, the non-alterable or fixed memory can be implemented using any one or more of ROM, PROM, EPROM, EEPROM, and gaps an optical ROM disk, such as a CD-ROM or DVD-ROM disk and disk drive or the like.","When operating the print data modifying system , the print request is input from one of the user input devices  over the link . The input\/output interface  inputs the print request, and, under the control of the controller , forwards it to the test image generating circuit, routine or application .","The test image generating circuit, routine or application  then determines if one or more of the one or more compensation parameters need to be updated, either based on an update schedule stored in the memory  and\/or as an operator selected option submitted as part of the request. If one or more compensation parameters need to be updated, the test image generating circuit, routine or application  retrieves, under the control of the controller , the calibration test image data from a calibration test image portion  of the memory . The test image generating circuit, routine or application  then outputs, under the control of the controller , the test image to the image data sink  over the link  for printing by the image data sink  or a printer connected to the image data sink .","The compensation factor generating circuit, routine or application , then retrieves, under control of the controller , white space defect magnitude measurements over the link , obtained from the printed test image by the one or more calibration sensors . The compensation parameters generating circuit, routine or application  then determines the one or more compensation parameters to be used in the bitmap compensation process based on the current white space defect magnitude measurements. Under control of the controller , the compensation parameters generating circuit, routine or application  either stores the compensation parameters in the compensation parameters portion  of the memory , or output the compensation factors directly to the compensated image data generating circuit, routine or application . It should be appreciated that the white space defect magnitude measurements can also be made with a flatbed scanner. In this case, the scanner information would be received over a link from the flatbed scanner by the input\/output interface. Under control of the controller , the scanner information is stored in the compensation parameters portion  or provided directly to the compensation parameters generating circuit, routine or application .","The compensated image data generating circuit, routine or application , under control of the controller , then retrieves the compensation parameters from the compensation parameters portion  or receives the compensation parameters directly from the compensation parameters generating circuit, routine or application . The compensated image data generating circuit, routine or application , under control of the controller , then retrieves the input image data from the input image data portion  or receives the image data directly from the image data source  over the link  and through the input\/output interface .","In various exemplary embodiments, if there are any trailing edge white space defects, the compensated image data generating circuit, routine or application , under control of the controller , first modifies the input image data to generate trailing edge compensated input image data that compensates for the trailing edge white space defects. Next, if there are any leading edge white space defects, the compensated image data generating circuit, routine or application , under control of the controller , modifies the trailing edge compensated image data to generate leading and trailing edge compensated input image data that compensates for the leading and trailing edge white space defects. The leading and trailing edge compensated image data is then stored in an output image data portion  of the memory  or is output directly by the compensated image data generating circuit, routine or application , under control of the controller , to the output image generating circuit, routine or application .","Of course, if there are no leading edge white space defects, the trailing edge compensated image data is stored in the output image data portion  of the memory  or is output directly by the compensated image data generating circuit, routine or application , under control of the controller , to the output image generating circuit, routine or application . Similarly, if there are no trailing edge white space defects, the compensated image data generating circuit, routine or application , under control of the controller , modifies the input image data to generate leading edge compensated input image data that compensates for the leading edge white space defect. The leading edge compensated image data is then stored in the output image data portion  of the memory  or is output directly by the compensated image data generating circuit, routine or application , under control of the controller , to the output image generating circuit, routine or application .","In such exemplary embodiments, the output image generating circuit, routine or application  then, under control of the controller , either retrieves the compensated image data from the compensated image data generating circuit, routine or application . The output image generating circuit, routine or application , under control of the controller , inputs the compensated image data and outputs, under control of the controller , a bitmap image usable to drive a printer to form the desired image, where the image data of the bitmap has been compensated in view of the white space defect, to the image data sink  over the link .","It should be appreciated that, if the image data sink  is a printer, that printer can print an image using the bitmap image data generated from the compensated image data. It should further be appreciated that, if the image data sink is a storage device, the bitmap image data can be stored for later printing by a printer. Alternatively, if the image data sink is a transmission structure, such as the Internet, the bitmap image data can be transmitted to a remote printer or storage device.","It should also be appreciated that in various exemplary embodiments, the compensated image outputting circuit routine or application can be omitted. In this case, the compensated image data itself is output to the image data sink . This is useful when the image data sink is a printer, or conveys the compensated image data to a printer, that itself converts the compensated image data into a bitmap or other raster form suitable for printing.","Each of the various embodiments of the print data modifying system  can be implemented as software executing on a programmed general purpose computer, a special purpose computer, a microprocessor or the like. Alternatively, each of the various embodiments of the print data modifying system  can be implemented as a routine embedded in a library, or a resource residing on a server, or the like. Each of the various embodiments of the various embodiments of the print data modifying system  can be also be implemented by physically incorporating that device into a software and\/or hardware system, such as a speech recognition system or language translation system of a computer or communication device. It should be understood that each of the various embodiments of the print data modifying system  do not need to be implemented the same way.","It should also be understood that each of the circuits, routines, applications or managers shown in  can be implemented as portions of a suitably programmed general-purpose computer. Alternatively, each of the circuits, routines or applications shown in  can be implemented as physically distinct hardware circuits within an ASIC, using a digital signal processor (DSP), using a FPGA, a PDL, a PLA and\/or a PAL, or using discrete logic elements or discrete circuit elements. The particular for of the circuits, routines or applications shown in  will take is a design choice and will be obvious and predictable to those skilled in the art. It should be appreciated that the circuits, routines or applications shown in  do not need to be of the same design.","While particular exemplary embodiments have been described above, alternatives, modifications, variations, improvements, and substantial equivalents that are or may be presently unforeseen may arise to applicants or others skilled in the are. Accordingly, the appended claims as filed and as they may be amended are intended to embrace all such alternatives, modifications variations, improvements, and substantial equivalents."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Various exemplary embodiments of this invention will be described in detail, with reference to the following figures, wherein:",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 9","FIG. 8"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 18"}]},"DETDESC":[{},{}]}
