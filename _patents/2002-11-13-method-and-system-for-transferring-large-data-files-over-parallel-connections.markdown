---
title: Method and system for transferring large data files over parallel connections
abstract: A method and system are disclosed for transferring large data files over parallel connections. A file can be transferred between a first application operating on a first system and a second application operating on a second system. A plurality of connections are established between the first application and the second application. A send buffer is created to store N segments of the file at the first system, N being an integer greater than one. The N segments of the file are read into the send buffer. Each segment in the buffer is sent on a corresponding connection among the plurality of connections for delivery to the second application. The number of connections can be selected by a user.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07716312&OS=07716312&RS=07716312
owner: Avid Technology, Inc.
number: 07716312
owner_city: Tewksbury
owner_country: US
publication_date: 20021113
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This invention relates generally to data processing systems, and, more particularly, to a method and system for transferring large data files over parallel connections.","With the emergence of the Internet, large amounts of information can be shared and distributed between any number of interconnected users. The users can be remotely located, spanning multiple continents. Typically, the users store information in data files (\u201cfiles\u201d). Many user applications such as multimedia applications running on computing systems distribute large files (e.g., multimedia files), which can exceed one gigabyte in memory space. Distributing large files between user applications over a network such as the Internet can be problematic.","For instance, many Internet applications use the Transfer Control Protocol\/Internet Protocol (TCP\/IP) layers to send files separated as packets over the Internet. The IP layer handles the actual delivery of the packets and the TCP layer ensures that each packet is delivered and reordered correctly for its destination application. To deliver packets, TCP establishes a connection between two TCP endpoints, defined by an IP address and a port number. An IP address identifies a computing system and the port number identifies an application operating within that computing system. Each packet contains a sequence number. The sequence numbers are used to acknowledge received packets and to reorder correctly packets at a receiving end in the case of packets being received out of order.","To ensure reliable delivery of packets, TCP must receive acknowledgement that delivered packets were received at a receiving end. In this process, TCP uses a \u201csliding window\u201d algorithm to dynamically calculate the maximum number of unacknowledged (in-transit) packets to allow before enacting flow control (preventing further sends). The sliding window algorithm is designed to prevent congestion while still allowing the window to grow large enough to accommodate fast link speeds. Unfortunately, the algorithm often treats latency induced by sending packets large distances and latency induced by actual congestion similarly as it is programmatically difficult to make a distinction between the two at the level on which TCP operates.","In particular, If a TCP connection experiences high latency, TCP assumes congestion in which case TCP decreases the size of the \u201cwindow.\u201d Furthermore, TCP may also resend the packets if not acknowledged within a certain period of time. However, in many instances, the TCP connection is over a high speed connection line, but the receiving end is at a remote location, which can cause an inherent latency in the delivery and acknowledgement of packets. For example, an 8 mbps connection line used for sending packets to a remote user will experience latency at the receiving end that causes the overall throughput to be a small fraction of the maximum possible due to the congestion control mechanism of TCP. As such, applications may not be able to utilize the full available bandwidth on a connection line when sending large files.","Another limitation with delivering large files over high-speed connections is that the network throughput can exceed the file input\/output (I\/O) capabilities in the sending and receiving computing systems. For instance, multiple memory devices may be required to store and buffer a large file. If multiple memory devices are required to store or buffer a large file, to seek the appropriate segments of the file or location of the segment in memory can be time consuming. Such file I\/O processes can thus limit the throughput on a high speed connection line. Therefore, delivering large files at the maximum possible speed requires efficient file I\/O processes.","There exists, therefore, a need for an improved method and system that overcome the limitations of transferring data files.","According to one aspect of the invention, a method is disclosed for transferring a file between a first application operating on a first system and a second application operating on a second system. A plurality of connections are established between the first application and the second application. A send buffer is created to store N sequential segments of the file at the first system, wherein N is an integer greater than one. The N segments of the file are stored into the send buffer. Each segment in the send buffer is sent on a corresponding connection among the plurality of connections for delivery to the second application.","According to another aspect of the invention, a computing system is that includes first and second systems operating first and second applications, respectively, wherein a plurality of connections are established between the first and second applications. The computing system also includes a server coupled to the first and second systems on the plurality of connections. The server receives segments of a file from the first system on each of the connections, stores the segments in a streaming file for each connection, and streams the segments to the second system for each connection.","Other features and advantages will be apparent from the accompanying drawings, and from the detailed description, which follows below.","Reference will now be made in detail to embodiments and implementations, examples of which are illustrated in the accompanying drawings. Wherever possible, the same reference numbers will be used throughout the drawings to refer to the same or like parts.","A. Overview","The disclosed techniques provide an efficient manner of transferring data files (\u201cfiles\u201d), especially large files. In one implementation, a file can be transferred between a first application operating on a first system and a second application operating on a second system. A plurality of connections are established between the first application and the second application. A send buffer is created to store N segments of the file at the first system, wherein N is an integer greater than one. The N segments of the file are read into the send buffer. Each segment in the send buffer is sent on a corresponding connection among the plurality of connections for delivery to the second application. The number of connections can be selected by a user.","Thus, by using parallel connections between applications, the maximum throughput increases N times per connection over a connection line. This allows applications to utilize the full available bandwidth on a connection line, especially a high speed connection line, when sending data. As a result, throughput on the connection line can be optimized. Additionally, by segmenting a file and using a corresponding connection for each segment stored in a buffer, file I\/O processes can be performed more efficiently. Such a process also allows files to be efficiently reconstructed at a receiving end. As detailed below, the following embodiments and implementations overcome inefficiencies in transferring large amounts of data (e.g., large files) between applications on a network such as the Internet.","B. Exemplary Network and Computing System",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1","b":["100","100","104","106","108","102","108","150","150","150","150","102","100","100"]},"Clients  and  are computing devices or systems such as personal computers or workstations. Clients  and  include network applications  and , respectively. Network applications  and  can provide interfaces such as, for example, a web browser to access and send data between applications over network . Examples of network applications  and  can include collaboration applications such as the Rocket Delivery System by Rocket Networks, Inc. Such applications can be configured to transfer data or files using the file transfer techniques described below. These techniques allow network applications  and  to establish multiple or parallel (\u201cparallel\u201d) connections between each other for sending data or files. In one embodiment, the parallel connections are multiple virtual connections established between network applications  and . Additionally, parallel connections can be established between server  and clients  and .","Server  is a computing device such as, for example, a personal computer, workstation, mini-mainframe, or mainframe computer. In the example of , server  provides store and forward functions for network applications  and  on clients  and , respectively. For example, in sending a file from client  to client , using the techniques disclosed herein, client  sends data for each file to server , which stores the data and then forwards the data to client . Thus, server  includes a file management module  (\u201cmodule \u201d) to handle the store and forward functions. Module  can also manage data or files and\/or updates or changes to the data or files for network applications  and . Module  can be software and\/or hardware to implement techniques disclosed herein. Module  can also have multiple or parallel connections established between network applications  and .","The manner of transferring data or files between network applications  and  operating on clients  and , respectively, over parallel connections will be described in further detail below. Furthermore, the manner of file management module  to handle store and forward functions for network applications  and  over parallel connections will also be described below.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 2","FIG. 1","FIGS. 4-6"],"b":["200","104","106","108"]},"Computing system  includes several components all interconnected via a system bus . System bus  can be bi-directional system bus having thirty-two data and address lines for accessing a memory  and a cache memory  for transferring and storing data or files for computing system  or from other computing systems. Alternatively, multiplexed data\/address lines may be used instead of separate data and address lines.","Examples of memory  or cache memory  include a random access memory (RAM), read-only memory (ROM), video memory, flash memory, or other appropriate memory devices. Additional memory devices (not shown) may be included in computing system  such as, for example, fixed and removable media (including magnetic, optical, or magnetic optical storage media). These types of media may also operate as a cache memory.","Computing system  may communicate with other computing systems (e.g., server  or clients  and ) via a network interface . Examples of network interface  include Ethernet, telephone, or broadband connection interfaces. Computing system  includes a central processing unit (CPU) , examples of which include the Pentium\u00ae family of microprocessors manufactured by Intel\u00ae Corporation. However, any other suitable microprocessor, micro-, mini-, or mainframe type processor may be used as the CPU for the computing system . CPU  provides the support for storing and transferring files to carry out the file transfer techniques described herein.","Memory  may store instructions or code for implementing programs, applications, or modules (e.g., network applications  and  and file management module ) and an application programming interface (API) to one or more other programs or operating systems. For example, CPU  may execute instructions for network applications  and  or file management module  to perform the file transfer techniques disclosed herein. Memory  also stores an operating system, examples of which can include the Microsoft\u00ae family of operating systems, Linux operating system, or other appropriate operating systems that provide networking capabilities.","Cache memory  may store data or files for sending and receiving to and from other computing systems. Computing system  may also receive input data or instructions from any number of input\/output (I\/O) devices via I\/O interface . Examples of I\/O devices may include a keyboard, pointing device, or other appropriate input devices. The I\/O devices may also include external storage devices or computing systems or subsystems. Computing device  may also present information data or information via, e.g., a browser, on a display .",{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 3","FIG. 1"],"b":["302","302","104","106","108","302","302"]},"Referring to , model  includes applications layer , TCP layer , IP layer , and data link layers . The TCP layer , IP layer , and data link layers  provide services for applications layer . Applications layer  includes applications operating on clients  and  and server . Thus, applications layer  can refer to network applications  and  and file management module .","TCP layer  segments data for application layer into packets for delivery to a destination application on a computing system. TCP layer  also receives packets from a sending application and delivers data from the packets to application layer . TCP layer  also provides reliable packet transfer services by performing error-checking and ensuring all packets have been received by the destination application, which can include using the \u201csliding window\u201d algorithm. For example, TCP layer  operating on client  will ensure that packets for delivery to network application  operating on client  are received by network application  or client .","TCP layer  uses sequence numbers for acknowledging and reordering the packets. As such, TCP layer  operating on client  can send acknowledgements of the packets. As described below, TCP layer  can send a set number of packets or window per connection on multiple or parallel connections to a destination application. IP layer  provides routing and forwarding functions so that a packet can reach its destination using an optimal path. This layer can use any number of routing tables to determine the nodes to send packets. Each packet can have an IP address for a destination computing system. Data link layers  provide services handling the actual transfer of the packets on a physical connection. The physical connection can be a wired or wireless connections using standard data link communication protocols.","In the example of , a plurality of connections or parallel connections can be established between applications at TCP layer . This example shows N=5, wherein N can be an integer greater than one. TCP layer  establishes parallel TCP connections from client applications and\/or to server applications. For example, file management module  operating on server  can listen for TCP connection requests on its well-known IP address and single well-known port number.","Moreover, to establish N parallel connections, a client application (e.g., network application ) selects N discrete unused port numbers on the client system. These client port numbers must be unique within the space of valid and unused port numbers on the client system. The actual values of the port numbers can be random. The client system can then initiate the standard TCP connection sequence for each of the N parallel connections. The server application, e.g., file management module , can accept these connection requests and process all N per-connection data transfers independently and concurrently.","The TCP layer  can operate with a plurality of TCP buffers . TCP buffers  includes a number of sub-buffers equal to N. As shown, TCP buffers  includes B through B sub-buffers. The number of sub-buffers and N can be configured or adjusted by a user. As detailed below, a file  can be segmented into a set number of bytes (e.g., \u201cREADCHUNK\u201d). As shown, each segment  through  is stored in a corresponding sub-buffer B through B. Each of these segments  through  and sub-buffers B through B have a corresponding connection. The data in sub-buffers B through B are sent on the corresponding connections to a destination computing system, which can include client  and\/or server . The process of sending or transferring data of files is detailed below regarding the methods of .","C. File Transfer Techniques","The following methods of  illustrate file transfer techniques over parallel connections between applications such as network applications  and . For purposes of explanation, with reference to diagram  of , the following methods are described for transferring a data file A at client  to client  via server  over parallel connections. Conversely, a data file can be sent in the opposite direction from client  to client  via server . In this manner, each client  and client  can include both a send and receive buffer.","Additionally, these examples are described with N=4 connections having been established between network applications  and  operating on clients  and  and with file management module  operating on server . Nevertheless, the following methods can be implemented with N number of connections where N is greater than one. The connections can include transfer control protocol (TCP) connections described above.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 4","b":["400","104","110","104"]},"Initially, a send buffer  is created to store N\u00d7READCHUNK of a data file A (step ). In one example, send buffer  can be a 1 MB buffer storing N=4 256K segments of data file A. Send buffer  includes four sub-sections B through B to store N=4 READCHUNK segments of data file A. N\u00d7READCHUNK segments of data file A are read or stored into send buffer  (step ). Each stored READCHUNK segment in sub-buffers B through B is sent on one of the N=4 parallel connections to server  (step ). In this step, for each connection, READCHUNK segments in sub-buffers B through B can be read and sent independently of the other connections. For example, for connection , READCHUNK segment  of data file A would be stored in sub-buffer B of send buffer  and READCHUNK segment  would be sent to server  on connection . The process of storing and forwarding each READCHUNK segment of data file A from client  by server  is described in .","A check is then made to determine if the last READCHUNK segment of data file A has been sent. If it has not, method  continues back to step  to continue reading and sending READCHUNK segments of data file A to server . If the last READCHUNK segment has been sent, method  ends. This process can be performed while methods  and  are being performed by server  and client . Furthermore, while each READCHUNK segment of data file A is being sent on a respective connection, standard TCP congestion protocols can be implemented on a per connection basis.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 5","b":["500","702","112","108"]},"Initially, server  allocates memory to create N=4 stream files through . That is, if there are N connections server  will create N stream files. Each of these stream files stores incoming READCHUNK segments from a corresponding connection. Alternatively, stream buffers, e.g., FIFO buffers, can be created or used to store incoming READCHUNK segments. For example, stream file stores READCHUNK segments stored in B sub-buffer of send buffer . For each READCHUNK segment received on a connection, the READCHUNK segment is appended to the appropriate stream file (step ). For example, stream file will append the second READCHUNK segment received on connection  after the first READCHUNK segment has been stored in stream file .","Next, the READCHUNK segments stored in the stream files through can be \u201cstreamed out,\u201d i.e., transmitted, to client  (step ). In this step, for each connection, the streaming of READCHUNK segments can be performed independently. For example, stream buffer can stream out READCHUNK segments before stream buffer . A check is then made to determine if the last READCHUNK segment of data file A has been streamed out. If has not, method  continues to step  and continues appending and streaming out READCHUNK segments from streaming files through . If the last READCHUNK segment of data file A has been streamed out, method  ends. This process can be performed while methods  and  are being performed by clients  and , respectively.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 6","b":["600","108","106","112","106"]},"Initially, a receive buffer  is created to store N=4 READCHUNK segments from stream files through , respectively, from server  on client  (step ). Receive buffer  can be configured in the same manner is send buffer . Receive buffer  includes four sub-buffers B through B to store N=4 READCHUNK segments of data file A that are streamed out of stream files through , respectively. Received READCHUNK segments from server  are store in respective sub-buffers B through B based on the received connection (step ). For example, READCHUNK segment  in stream file received on connection  is stored in sub-buffer B in receive buffer .","Next, the READCHUNK segments in receive buffer  are ordered into data file B to match the order in data file A (step ). In this step, data file B can be persisted in one or more memory devices. A check is then made to determine if the last READCHUNK segment of data file has been received. If it has not, method  continues back to step  to continue receiving and ordering READCHUNK segments from server . If the last READCHUNK segment has been received and ordered in data file B, method  ends. This process can be performed while methods  and  are being performed by client  and server . Furthermore, while each READCHUNK segment is being received at client , standard TCP congestion protocols can be implemented on a per connection basis for client .","Thus, a method and system for transferring large data files over parallel connections have been described. Furthermore, while there has been illustrated and described what are at present considered to be exemplary embodiments, implementations, and methods of the present invention, various changes and modifications can be made, and equivalents can be substituted for elements thereof, without departing from the true scope of the invention. In particular, modifications can be made to adapt a particular element, technique, or implementation to the teachings of the present invention without departing from the spirit of the invention.","In addition, the described embodiments and implementations comprise computing systems, which can run software to implement the methods, steps, operations, or processes described herein. Other embodiments of the invention will be apparent from consideration of the specification and practice of the invention disclosed herein. Therefore, it is intended that the specification and examples be considered as exemplary only, with a true scope and spirit of the invention being indicated by the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate exemplary embodiments implementations and, together with the detailed description, serve to explain the principles of the invention. In the drawings,",{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
