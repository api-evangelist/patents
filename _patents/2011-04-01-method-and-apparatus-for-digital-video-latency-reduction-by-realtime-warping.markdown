---
title: Method and apparatus for digital video latency reduction by real-time warping
abstract: In one aspect, video latency reduction by real-time warping is described. In one aspect, an original geometric image model of a digital video frame is adjusted according to a video frame latency, to form an adjusted geometric image model. A geometric image model may represent a field of view from a remote camera used to capture the digital video frame. The adjusted geometric image model may be overlaid onto the original geometric image model to capture a warped image. In one aspect the warped image is re-projected according to the adjusted geometric image model to form a re-projected image. The re-projected image may then be displayed to approximate a real-time field of view from a camera used to capture the digital video frame. In one aspect, an attitude and runway alignment of an unmanned aerial vehicle may be controlled using a displayed, re-projected image. Other aspects are described and claimed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08917322&OS=08917322&RS=08917322
owner: Lockheed Martin Corporation
number: 08917322
owner_city: Bethesda
owner_country: US
publication_date: 20110401
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["An aspect of the present disclosure relates to the field of digital video, and more particularly, to digital video latency reduction of a received digital video frame captured by a remote camera.","Digital video is popular due to its high quality, ease of transmission, and encryption capability. Unfortunately, digital video requires compression to retain reasonable bandwidth. This generally creates several video frames of latency, adding as much as 200-400 milliseconds (ms) of delay. In other words, the received digital video is not representative of a scene in real-time due to the latency caused by the compression. Highly interactive tasks, such as remote control tasks require low latency. Remote control tasks require reacting to displayed images with precision, which varies in difficulty depending on the magnitude of the latency. Some current methods for reducing video latency focus on reducing the actual latency of a video stream. Other techniques provide completely synthetic views.","One aspect of the subject disclosure describes a method for digital video latency reduction of a received digital video frame captured by a remote camera. In one aspect, an image model of the received digital video frame is adjusted according to an approximate field of view from the remote camera at a time the digital video frame is received to form an adjusted image model. In one aspect, the adjusted image model may be overlaid onto the original image model of the received digital video frame to capture a warped image. In one aspect, the warped image is re-projected according to the adjusted image model to form a re-projected image. The re-projected image may then be displayed to approximate a real-time field of view from the remote camera used to capture the digital video frame. In one aspect, an attitude and runway alignment of an unmanned aerial vehicle may be controlled using a displayed, re-projected image having an on-board, remote camera.","It is understood that other configurations of the subject technology will become readily apparent to those skilled in the art from the following detailed description, wherein various configurations of the subject technology are shown and described by way of illustration. As will be realized, the subject technology is capable of other and different configurations and its several details are capable of modification in various other respects, all without departing from the scope of the subject technology. Accordingly, the drawings and detailed description are to be regarded as illustrative in nature and not as restrictive.","The detailed description set forth below is intended as a description of various configurations of the subject technology and is not intended to represent the only configurations in which the subject technology may be practiced. The appended drawings are incorporated herein and constitute a part of the detailed description. The detailed description includes specific details for the purpose of providing a thorough understanding of the subject technology. However, it will be apparent to those skilled in the art that the subject technology may be practiced without these specific details. In some instances, well-known structures and components are shown in block diagram form in order to avoid obscuring the concepts of the subject technology. Like components are labeled with identical element numbers for ease of understanding.","Digital video is popular due to its high quality, ease of transmission, and encryption capability. Unfortunately, digital video requires compression to retain reasonable bandwidth. For example, if digital video is encoded using motion picture experts group (MPEG) technology, the latency required to decode and display the video is in the range of 200-400 milliseconds (ms). In other words, the received digital video is not representative of a scene in real-time due to the latency caused by the compression. This digital video latency is commonly experienced by viewers of digital television who do not notice that the content displayed on their screen does not represent a real-time view for live events.","While digital video latency may be acceptable to viewers of digital television, digital video latency is unacceptable for highly interactive tasks, such as remote control tasks. Remote control tasks require reacting to displayed images with precision, which varies in difficulty depending on the magnitude of the digital video latency. One example of a remote control task is the remote control of a vehicle, such as a remotely piloted unmanned aerial vehicle (UAV). Unfortunately, digital video latency prohibits the viewing of changes to a scene in real-time since changes may occur between the time a scene is captured and a time at which the scene is displayed at a remote location. The total latency for the remote control of a vehicle may depend on properties such as the vehicle response, a radio communication link, and the digital video latency. A total latency in excess of, for example, 200 ms may cause pilot induced oscillations because a display of the digital video frames from an on-board camera does not reflect the commands issued to the vehicle, which causes the pilot to issue additional commands, resulting in a loss of control.","According to various aspects of the subject disclosure, digital video latency reduction by real-time warping is described. In one aspect, each frame of digital video is re-projected (warped) to approximate a geometry of a future video frame in real-time. In one aspect, a camera geometry for each digital video frame captured by the camera is recorded according to a location of the camera at a digital video frame capture time. Subsequently, an estimate is made of an actual, current camera geometry at a time a digital video frame is received. In one aspect, a difference between the recorded geometry and the current camera geometry (location) is used to re-project or warp the video image to correct for the difference in the form of a re-projected image. When the re-projected image is displayed, the content of the original image does not represent a real-time image due to the above-mentioned delay in receiving the image. The re-projected image, although based on a non-real-time image, will approximate a real-time field of view from the camera at the video frame receive time. In one aspect of the subject disclosure, a current camera geometry may be provided by sensors, such as an inertial navigation system, or can be estimated from the scene itself.","As described herein, digital video latency may refer to a time delay between a digital video frame capture time and a time at which the video frame is displayed, which may be in the range of 100 to 200 milliseconds (ms). As further described herein, real-time warping may refer to the remapping of an original geometric image model of digital video frame according to an adjusted geometric image model representing an approximate real-time camera location to approximate a geometry of a future video frame in real-time. As further described herein, a geometric image model (image model) may refer to an intersection between a camera field of view and a plane perpendicular to a camera focal plane at a predetermined distance in front of the camera, such that an original geometric image model (original image model) may refer to a field of view from a remote camera used to capture the digital video frame at a time that the digital video frame is captured, and an adjusted geometric image model (adjusted image model) may refer to a field of view from the remote camera at a time a digital video frame is received.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 1","FIG. 3"],"b":["100","100","162","164","100","110","130","120","100","102","104","106","100","310","340","114"]},"Computer platform  is operable to transmit data across a network, and is operable to receive and execute routines and applications and display data generated within system  or received from any network device or other computer device connected to the network or connected to system . Computer platform  may be embodied in, for example, one or any combination of hardware, firmware, software, data and executable instructions.","Memory  may comprise one or any combination of volatile and nonvolatile memory, such as read-only and\/or random-access memory (RAM and ROM), EPROM, EEPROM, flash cards, flash memory cells, an electronic file system, and any memory common to computer platforms. Further, memory  may include one or more of any secondary or tertiary storage device, such as magnetic media, optical media, tape, or soft or hard disk, including removable memory mechanisms.","Further, processor  may be one or more of an application-specific integrated circuit (\u201cASIC\u201d), a chipset, a processor, a logic circuit, and any other data processing device. In some aspects, processor , or another processor such as an ASIC, may execute an application programming interface (API) layer  that interfaces with any resident programs stored in memory  of system . API  may be a runtime environment executing on system . In one aspect, API , in combination with navigation menu , may be used control the operation of a remote vehicle.","Additionally, processor  may include graphic processing unit (GPU)  embodied in hardware, firmware, software, data, executable instructions and combinations thereof, which enable video latency reduction according to one embodiment. For example, GPU  in combination with video re-projection logic  of latency reduction module  may enable video latency reduction by real-time warping.","Further, communications module  may be embodied in hardware, firmware, software, data, executable instructions and combinations thereof, and is operable to enable communications among the various wireless data links. For example, communication module  may include the requisite hardware, firmware, software, data, executable instructions and combinations thereof, including transmit and receive chain components for establishing a wireless communication connection.","Further, for example, communication module  is operable to receive a plurality of digital video frames  and the associated respective camera locations  at a video frame capture time, and forwards them to real-time image selector  or provides image selector  with access to the data. Similarly, for example, communication module  is operable to receive navigation data regarding a camera location  at a video frame receive time and either forwards them to image selector  or provides image selector  with access to the data. Subsequently, for example, communications module  is operable to forward digital video content to other device components for further processing.","Additionally, one or more input devices  for generating inputs into system , and one or more output devices  for generating information for consumption by the user of the system are provided. For example, input device  may include a mechanism such as a key or keyboard, a navigation mechanism (e.g. a joy stick), a mouse, a touch-screen display, a microphone in association with a voice recognition module, etc. In certain aspects, input device  provides an interface for receiving user input, such as to activate or interact with an application or module on a remote vehicle. Further, for example, output device  may include a display, an audio speaker, a haptic feedback mechanism, etc. Further, user interface  may comprise one or any combination of input devices  and\/or output devices .",{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 2","b":["200","202","204","206","208","210","212","214"]},"Referring again to , latency reduction module  in combination with GPU  may be operable to perform the features of . Representatively, latency reduction module , may include video re-projection logic  and navigation menu . In one aspect, navigation menu  may be provided to control the operation of a vehicle. As shown in , real-time image selector , may be responsible for receiving digital video frames  and camera locations  for storage within storage device . In one aspect, a digital video latency may refer to a delay between a time at which a video frame is captured by a camera  () and a time at which the video frame is received at communications module .","Referring again to , in response to a received digital video frame , real-time image selector  may determine a camera location  at the time the frame is received, which is later in time than the time at which the frame was captured due to video latency. According to the described aspects, original image model  may represent a field of view of the camera at a time that digital video frame was captured. As further shown in , adjusted image model  may approximate a field of view of a camera at real-time, which may be a time at which the digital video frame was received. According to the described aspects, although the received digital video frame  is not current (due to the video latency), video re-projection logic  may re-project digital video frame  using the adjusted image model  to approximate a current real-time view from a camera  ().",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 3","FIG. 3","FIG. 3"],"b":["300","104","302","308","104","330","332","336","320","322","326","330","330","320","340","310"]},"As shown in , the delay required to receive or approximate a real-time location of camera  is less than the video frame latency path . By taking advantage of the reduced video frame warping path , a geometric image model may be used to approximate a current real-time location of camera . Using this approximate model, an original digital frame image may be remapped according to the approximated model to provide a warped image, for example as shown in .",{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 4","FIG. 4"],"b":["400","402","310","404","410","310","410","406","408","410"]},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 5","b":["420","422","310","310","422","310","310","430","416","418"]},{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIG. 6","FIG. 6","FIGS. 9-13"],"b":"440"},"As described herein, frustum view  may be referred to as an original geometric image model of a digital video frame, which represents a field of view of a camera at a time that the digital video frame is captured. Unfortunately, for the reasons described above, by the time the digital video frame represented by  is received by, for example, system , that digital video frame no longer represents a real-time view from camera . According to one aspect of the present disclosure, this latent image may be modified to form a warped image to illustrate a real-time location of camera .",{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 7","FIG. 8"],"b":["450","440","450","416","418","452","454","450","440"]},{"@attributes":{"id":"p-0042","num":"0041"},"figref":["FIG. 8","FIG. 8","FIG. 8"],"b":["416","418","452","454","460","480","470","480"]},{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIGS. 9-13","FIGS. 5-8","FIG. 9","FIG. 10","FIG. 11","FIG. 13","FIG. 13"],"b":["514","522","310","540","512","546","506","508","542","544","550","540","550","516","518","552","554","524","556","550","540"],"i":["c","e"]},{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 13","FIG. 13","FIG. 13"],"b":["540","550","516","518","552","554","524","556","560","550","550","580","570","580"]},"Aspects of the subject technology bypass the extra latency inherent to digital compression\/decompression and delay by using a wireless data link and an inertial navigation system to provide a low latency data path for determining a real-time location of a camera included within a vehicle. Although received digital video data from a vehicle including the camera is still latent, a relative position and attitude indicated by the digital video data may be corrected to approximate a geometry of a future video frame in real-time. In some aspects, the subject technology may be applied in radio communication, wireless communication, and electronics. In some aspects, the subject technology may be applied in non-aerial vehicle control, for example, such as standard automobiles.","In accordance with various aspects of the subject disclosure, the subject technology is related to video latency reduction. In some aspects, the subject technology may be used in various markets, including for example and without limitation, remote control tasks based on a video image that require low latency. For example, the video reduction latency, according to one aspect, is described for landing a remotely piloted vehicle. The described aspects, however, are not limited to landing a remotely piloted vehicle, and may be applied to any control task that requires low latency.","It is to be understood that the embodiments described herein may be implemented by hardware, software, firmware, middleware, microcode, or any combination thereof. When the systems and\/or methods are implemented in software, firmware, middleware or microcode, program code or code segments, they may be stored in a machine-readable medium, such as a storage component. A code segment may represent a procedure, a function, a subprogram, a program, a routine, a subroutine, a module, a software package, a class, or any combination of instructions, data structures, or program statements. A code segment may be coupled to another code segment or a hardware circuit by passing and\/or receiving information, data, arguments, parameters, or memory contents. Information, arguments, parameters, data, etc. may be passed, forwarded, or transmitted using any suitable means including memory sharing, message passing, token passing, network transmission, etc.","For a software implementation, the techniques described herein may be implemented with modules (e.g., procedures, functions, and so on) that perform the functions described herein. The software codes may be stored in memory units and executed by processors. The memory unit may be implemented within the processor or external to the processor, in which case it can be communicatively coupled to the processor through various means as is known in the art.","Moreover, various aspects or features described herein may be implemented as a method, apparatus, or article of manufacture using standard programming and\/or engineering techniques. The term \u201carticle of manufacture\u201d as used herein is intended to encompass a computer program accessible from any computer-readable device, carrier, or media. For example, computer-readable media can include but are not limited to magnetic storage devices (e.g., hard disk, floppy disk, magnetic strips, etc.), optical disks (e.g., compact disk (CD), digital versatile disk (DVD), etc.), smart cards, and flash memory devices (e.g., EPROM, card, stick, key drive, etc.). Additionally, various storage media described herein can represent one or more devices and\/or other machine-readable media for storing information. The term \u201cmachine-readable medium\u201d can include, without being limited to, wireless channels and various other media capable of storing, containing, and\/or carrying instruction(s) and\/or data.","It is understood that the specific order or hierarchy of steps in the processes disclosed is an illustration of exemplary approaches. Based upon design preferences, it is understood that the specific order or hierarchy of steps in the processes may be rearranged. Some of the steps may be performed simultaneously. The accompanying method claims present elements of the various steps in a sample order, and are not meant to be limited to the specific order or hierarchy presented.","The previous description is provided to enable any person skilled in the art to practice the various aspects described herein. The previous description provides various examples of the subject technology, and the subject technology is not limited to these examples. Various modifications to these aspects will be readily apparent to those skilled in the art, and the generic principles defined herein may be applied to other aspects. Thus, the claims are not intended to be limited to the aspects shown herein, but is to be accorded the full scope consistent with the language claims, wherein reference to an element in the singular is not intended to mean \u201cone and only one\u201d unless specifically so stated, but rather \u201cone or more.\u201d Unless specifically stated otherwise, the term \u201csome\u201d refers to one or more. Pronouns in the masculine (e.g., his) include the feminine and neuter gender (e.g., her and its) and vice versa. Headings and subheadings, if any, are used for convenience only and do not limit the invention.","A phrase such as an \u201caspect\u201d does not imply that such aspect is essential to the subject technology or that such aspect applies to all configurations of the subject technology. A disclosure relating to an aspect may apply to all configurations, or one or more configurations. An aspect may provide one or more examples. A phrase such as an aspect may refer to one or more aspects and vice versa. A phrase such as an \u201cembodiment\u201d does not imply that such embodiment is essential to the subject technology or that such embodiment applies to all configurations of the subject technology. A disclosure relating to an embodiment may apply to all embodiments, or one or more embodiments. An embodiment may provide one or more examples. A phrase such an embodiment may refer to one or more embodiments and vice versa. A phrase such as a \u201cconfiguration\u201d does not imply that such configuration is essential to the subject technology or that such configuration applies to all configurations of the subject technology. A disclosure relating to a configuration may apply to all configurations, or one or more configurations. A configuration may provide one or more examples. A phrase such a configuration may refer to one or more configurations and vice versa.","The word \u201cexemplary\u201d is used herein to mean \u201cserving as an example or illustration.\u201d Any aspect or design described herein as \u201cexemplary\u201d is not necessarily to be construed as preferred or advantageous over other aspects or designs.","All structural and functional equivalents to the elements of the various aspects described throughout this disclosure that are known or later come to be known to those of ordinary skill in the art are expressly incorporated herein by reference and are intended to be encompassed by the claims. Moreover, nothing disclosed herein is intended to be dedicated to the public regardless of whether such disclosure is explicitly recited in the claims. No claim element is to be construed under the provisions of 35 U.S.C. \u00a7112, sixth paragraph, unless the element is expressly recited using the phrase \u201cmeans for\u201d or, in the case of a method claim, the element is recited using the phrase \u201cstep for.\u201d Furthermore, to the extent that the term \u201cinclude,\u201d \u201chave,\u201d or the like is used in the description or the claims, such term is intended to be inclusive in a manner similar to the term \u201ccomprise\u201d as \u201ccomprise\u201d is interpreted when employed as a transitional word in a claim."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 7","FIG. 6"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 13","FIG. 12"]}]},"DETDESC":[{},{}]}
