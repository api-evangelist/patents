---
title: Techniques for using paper documents as media templates
abstract: Techniques for creating a composite image are provided. The techniques include receiving an electronic representation of a paper document. Features in the electronic representation are then extracted and compared to recorded information to determine matching information. For example, the matching information may be presentations and/or pages in the recorded information. Information is then determined based on the matching information and the received electronic representation. The composite electronic representation is then created using the determined information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07779355&OS=07779355&RS=07779355
owner: Ricoh Company, Ltd.
number: 07779355
owner_city: Tokyo
owner_country: JP
publication_date: 20040330
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCES TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["The present application incorporates by reference for all purposes the entire contents of the following:","U.S. application Ser. No. 09\/728,560, entitled \u201cTECHNIQUES FOR CAPTURING INFORMATION DURING MULTIMEDIA PRESENTATIONS\u201d, filed Nov. 30, 2000;","U.S. application Ser. No. 09\/728,453, entitled \u201cTECHNIQUES FOR RECEIVING INFORMATION DURING MULTIMEDIA PRESENTATIONS & COMMUNICATING THE INFORMATION\u201d, filed Nov. 30, 2000;","U.S. application Ser. No. 09\/521,252, entitled \u201cMETHOD & SYSTEM FOR INFORMATION MANAGEMENT TO FACILITATE THE EXCHANGE OF IDEAS DURING A COLLABORATIVE EFFORT\u201d, filed Mar. 8, 2000;","U.S. application Ser. No. 10\/001,895, entitled \u201cPAPER-BASED INTERFACE FOR MULTIMEDIA INFORMATION\u201d, filed Nov. 19, 2001;","U.S. application Ser. No. 10\/660,985, entitled \u201cTECHNIQUES FOR STORING MULTIMEDIA INFORMATION WITH SOURCE DOCUMENTS\u201d, filed Sep. 12, 2003;","U.S. application Ser. No. 10\/661,052, entitled \u201cTECHNIQUES FOR PERFORMING OPERATIONS ON A SOURCE SYMBOLIC DOCUMENT\u201d, filed Sep. 12, 2003;","U.S. application Ser. No. 10\/660,867, entitled \u201cTECHNIQUES FOR ACCESSING INFORMATION CAPTURED DURING A PRESENTATION USING A PAPER DOCUMENT FOR THE PRESENTATION\u201d, filed Sep. 12, 2003;","U.S. application Ser. No. 10\/696,735, entitled \u201cTECHNIQUES FOR USING A CAPTURED ELECTRONIC REPRESENTATION FOR THE RETRIEVAL OF RECORDED INFORMATION\u201d, filed Sep. 12, 2003; and","U.S. application Ser. No. 10\/412,757, entitled \u201cAUTOMATED TECHNIQUES FOR COMPARING CONTENTS OF IMAGES\u201d, filed Apr. 11, 2003.","The present application relates to field of accessing recorded information, and more particularly to techniques for creating an electronic representation that includes inserted information that is related to recorded information.","Recording information during presentations has gained a lot of popularity in recent years. For example, colleges and universities have started to program classes and lectures, corporations have started to record meetings and conferences, etc. One or more capture devices may record information during a presentation. The recorded information may comprise different types or streams of information including audio information, video information, and the like.","After the presentation, the recorded information is then available for use by a user. A user may review their notes and may want to view the recording of the presentation. The conventional way for accessing these recordings has been by viewing the recordings sequentially. More efficient techniques are desired for accessing or retrieving the recorded information or indexing into the recorded information.","Embodiments of the present invention generally relate to techniques for creating a composite electronic representation. The techniques include receiving an electronic representation of a paper document. Features in the electronic representation are then extracted and compared to recorded information to determine matching information. For example, the matching information may be presentations and\/or pages in the recorded information. Information to insert is then determined based on the matching information and the received electronic representation. The composite electronic representation is then created using the determined information.","In one embodiment, a method for creating a composite electronic representation is provided. The method comprises: receiving an electronic representation of a document; extracting a feature from the electronic representation of the document; comparing the feature to the recorded information to determine information in the recorded information that matches the feature; determining information to insert based on the information in the recorded information that matches the feature and the received electronic representation of a document; and creating a composite electronic representation comprising the determined information.","In another embodiment, a method for creating a composite electronic representation of a document using information recorded during a presentation is provided. The method comprises: receiving an electronic representation of a document for the presentation, the electronic representation including a feature that was presented during the presentation; extracting the feature from the electronic representation; comparing the feature to the information recorded during the presentation to determine information in the recorded information that matches the one or more features; and determining information to insert based on the information in the recorded information that matches the feature and the received electronic representation of a document; and creating a composite electronic representation comprising the determined information.","The foregoing, together with other features, embodiments, and advantages of the present invention, will become more apparent when referring to the following specification, claims, and accompanying drawings.","In the following description, for the purposes of explanation, specific details are set forth in order to provide a thorough understanding of the invention. However, it will be apparent that the invention may be practiced without these specific details.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 1","FIG. 1"],"b":["100","100"]},"System  includes a computer system  that may be used by a user to prepare material to be presented at a presentation. Examples of presentations include lectures, meetings, conferences, classes, speeches, demonstrations, etc. The presentation material may include slides, photos, audio messages, video clips, text information, web pages, etc. The user may use one or more applications  executed by computer  to generate the presentation material. An example of a commonly used application for preparing slides to be presented at a presentation is PowerPoint\u2122 provided by Microsoft\u2122 Corporation. For example, as depicted in , the user may use PowerPoint\u2122 application  to create a \u201cpresentation.ppt\u201d file  (*.ppt file). A *.ppt file created using a PowerPoint\u2122 application can comprise one or more pages, each page comprising one or more slides. A *.ppt file may also store information as to the order in which the slides are to be presented at the presentation and the manner in which the slides will be presented.","In addition to PowerPoint\u2122 presentation files comprising slides, other types of files comprising other presentation material may also be created using different applications executed by computer . These files may be referred to in general as \u201csymbolic presentation files\u201d. A symbolic presentation file is any file created using an application or program and that comprises at least some content that is to be presented or output during a presentation. A symbolic presentation file may comprise various types of contents such as slides, photos, audio messages, video clips, text, web pages, images, etc. A *.ppt file created using a PowerPoint\u2122 application is an example of a symbolic presentation file that comprises slides.","The user may print portions of the presentation material on a paper medium to generate paper documents (also referred to as \u201cpaper documents\u201d) that are usually handed out at the presentation. The term \u201cpaper medium\u201d is intended to refer to any tangible medium on which information can be printed. The term \u201cprint\u201d or \u201cprinting\u201d is intended to include writing, imprinting, drawing, embossing, and the like. Each paper document may comprise one or more paper pages. Depending on the number of people attending the presentation, multiple paper documents may be printed.","An electronic representation of a paper document is received. As shown in , scanner  may be used to scan a paper document . Various other devices that are capable of scanning information on a paper medium may also be used to scan paper documents. Examples of such devices include facsimile machines, copiers, scanners, and the like.","Various different features may be on a paper document. Generally, the features on a document relate to information to be presented or discussed during the presentation for which the document is created. The features may include portions of presentation material or other material. Examples of features that can be printed include slides, photos, web pages, text information (e.g., a list of agenda features to be discussed at a meeting), and the like. For example, the user may print one or more slides from a *.ppt file on a paper document. The PowerPoint\u2122 application provides tools for printing one or more slides from a *.ppt file to generate a paper document. Each page of the paper document may have one or more slides printed on it. Examples of paper document pages with slides on them are depicted in , and B and described below in further detail.","The electronic representation may also be an electronic image of paper document. For example, a *.ppt file may be converted to images and used as the electronic representation of the paper document. Although paper document is used, an electronic representation of any document may be received. A document that is printed in paper does not need to be used to generate the electronic representation.","Capture devices  are configured to capture information presented at a presentation. Various different types of information output during a presentation may be captured or recorded by capture devices  including audio information, video information, images of slides or photos, whiteboard information, text information, and the like. For purposes of this application, the term \u201cpresented\u201d is intended to include displayed, output, spoken, etc. For purposes of this application, the term \u201ccapture device\u201d is intended to refer to any device, system, apparatus, or application that is configured to capture or record information of one or more types. Examples of capture devices  include microphones, video cameras, cameras (both digital and analog), scanners, presentation recorders, screen capture devices (e.g., a whiteboard information capture device), symbolic information capture devices, etc. In addition to capturing the information, capture devices  may also be able to capture temporal information associated with the captured information.","A presentation recorder is a device that is able to capture information presented during a presentation, for example, by tapping into and capturing streams of information from an information source. For example, if a computer executing a PowerPoint\u2122 application is used to display slides from a *.ppt file, a presentation recorder may be configured to tap into the video output of the computer and capture keyframes every time a significant difference is detected between displayed video keyframes of the slides. The presentation recorder is also able to capture other types of information such as audio information, video information, slides information stream, etc. The temporal information associated with the captured information indicating when the information was output or captured is then used to synchronize the different types of captured information. Examples of presentation recorders include a screen capture software application, a PowerPoint\u2122 application that allows recording of slides and time elapsed for each slide during a presentation, presentation recorder described in U.S. application Ser. No. 09\/728,560, filed Nov. 30, 2000, U.S. application Ser. No. 09\/728,453, filed Nov. 30, 2000, and U.S. application Ser. No. 09\/521,252, filed Mar. 8, 2000, and are hereby incorporated by reference for all purposes.","A symbolic information capture device is able to capture information stored in symbolic presentation documents that may be output during a presentation. For example, a symbolic information capture device is able to record slides presented at a presentation as a sequence of images (e.g., as JPEGs, BMPs, etc.). A symbolic information capture device may also be configured to extract the text content of the slides. For example, during a PowerPoint\u2122 slide presentation, a symbolic information capture device may record the slides by capturing slide transitions (e.g., by capturing keyboard commands) and then extracting the presentation images based on these transitions. Whiteboard capture devices may include devices such as a camera appropriately positioned to capture contents of the whiteboard, a screen, a chart, etc.","The information captured or recorded by capture devices  during a presentation may be stored in a repository or database  as recorded information . Recorded information  may be stored in various formats. For example, a directory may be created in repository  for storing recorded information , and the various types of information (e.g., audio information, video information, images, etc.) included in recorded information  may be stored in the directory. In another embodiment, recorded information  may be stored as a file. Various other techniques known to those skilled in the art may also be used for storing the recorded information.","Images of the slides found in the paper document are displayed during a presentation. In one embodiment, a presentation recorder may capture slide images as they are displayed. In addition, association information that may be used to index into recorded information  may be stored. For example, time information may be stored indicating a time that the slide was displayed. The time information may then be used to determine portions of recorded information  that correspond to when the slide was displayed.","In addition to the time information, source information identifying the location where the recorded information for the presentation is stored may also be determined. This storage location information for recorded information  may be updated when the recorded information is moved to a new storage location. In this manner, embodiments of the present invention allow the storage location of recorded information  to be changed over time.","According to an embodiment of the present invention, the association information is stored in the XML structure. For example, the association information may include time information and source information for presentations and\/or pages determined in step . The source information may be an identifier used to access a presentation. For example, the source information may be a location and file name. The time information is then used to index into a portion of a presentation. The presentation may have been a presentation determined in step  or a presentation that is related to information determined in step  (e.g., a presentation from which slide images were captured using a presentation recorder). The portion of the presentation may include information that matches the extracted features determined in step . For example, the portion of the presentation may include a slide that was displayed during the presentation.","Server  creates a composite electronic representation . In one embodiment, features are extracted from an electronic representation of a paper document received. The features are compared to recorded information  to determine matching information. In one embodiment, matching information may be determined using various techniques. It will be recognized that a slide image may not have to match a slide image exactly. For example, text in a slide may be compared with text to determine text that substantially matches.","Information to insert is then determined based on the matching information and the electronic representation of the paper document. Composite electronic representation  is then created based on the information inserted. Composite electronic representation  may include the features extracted. Also, composite electronic representation  may include the information determined based on the matching information and the electronic representation of the paper document.","A user may select the inserted information in composite electronic representation  and have recorded information  accessed and\/or played. For example, an electronic representation of a slide in the paper document may be used to determine information that is related to recorded information . The inserted information may include an object showing a picture of a portion of a presentation. When the object is selected, recorded information  when the slide was displayed during the presentation is accessed and\/or played. Thus, when a user desires additional information related to a slide in the paper document, the inserted information in composite electronic representation  may be used to retrieve recorded information  of the presentation when the slide was displayed and\/or discussed.",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 2","FIG. 2","FIG. 2"],"b":["200","122","200"]},"In step , an electronic representation of a document is received. In one embodiment, the document was printed as a paper document. The user may have taken notes on the paper document. The notes may be typically written on a paper document for a presentation. Other ways of taking notes may be appreciated also, such as typing in notes on an electronic version of the document. Although notes may be written on the paper document, it is not necessary that any notes be present.","Although an electronic representation of a paper document will be assumed as received, it will be understood that an electronic copy of a document may be received. One or more pages in the paper document may be received as the electronic representation. For discussion purposes, it is assumed that the electronic representation includes a single page but it should be understood that the electronic representation may include any number of pages. As discussed above, an electronic representation of a paper document may be received from a document that is scanned.","In another embodiment, an electronic version of the paper document may be used. For example, the electronic version may be images of slides found in a *.ppt file. A *.ppt file may be converted to images. For example, techniques are known where *.ppt slides may be converted into images in a .pdf or flash file. These images may be used as images of a document. For example, an electronic representation of a document may be received using the following process. A user may open the electronic representation in an application, such as a pdf reader. For example, the electronic representation from the scanned document or the electronic version may be opened in the application. An input may be provided in the pdf reader that initiates the following steps.","In step , features are extracted from the electronic representation of the document. The document may include images of one or more slides that were presented in the presentation. The images of the slides are then extracted from the electronic representation of the document. Although the processing is described as extracting slides, it will be understood that other features may be extracted. For example, pictures, text, etc. may be extracted. For example, instead of using slides in a presentation, the user may display pictures of certain features. The pictures are then extracted.","In one embodiment, segmentation may be used if more than one slide is present on a page. Segmentation separates and determines separate slides on the electronic representation of the paper document. This may be desirable when the individual slides should be associated with different portions of recorded information . Segmentation may not be required in some cases, such as when only one slide is on a page, etc.","Techniques for segmenting documents and images are well known in the art. Many of the current segmentation techniques may be used for segmenting individual slide regions from an electronic representation of a paper document. An example of segmentation techniques will be described below in more detail. Although segmentation is described, it should be understood that other techniques may be used to determine slide images in an electronic representation of a paper document. For example, the content of an electronic representation may be analyzed to determine slide images. In one example, a rectangular box may be recognized and the information in the box may be used as a slide image.","In step , extracted features are compared with recorded information  to determine matching information in recorded information . For example, portions of recorded information  that match the extracted features may be determined. The portions may include, pages of a presentation, video, audio, etc. In one embodiment, slide images extracted from the electronic representation of the document are compared to slide images in recorded information  for different presentations. Recorded information  for the presentations may have been presented at different times and thus all include matching information (e.g., one slide may occur in different recorded information for presentations).","In one embodiment, the extracted features may include a plurality of slides. The slides may be compared to slide images to determine a presentation that includes matching information. In one embodiment, each slide in the plurality of slides is compared to slides in recorded information  for presentations. Portions of recorded information  that include information that match the slides are determined.","In another embodiment, the plurality of slides are treated as a set and all slides are used in comparing slides in all presentations. Thus, in order for a presentation to be identified to include matching information, the presentation should include slides that match each of the plurality of slides taken as a set.","Various techniques may be used to determine matching information in recorded information . In one embodiment, techniques described in U.S. application Ser. No. 10\/412,757, entitled \u201cAUTOMATED TECHNIQUES FOR COMPARING CONTENTS OF IMAGES\u201d, filed Apr. 11, 2003; U.S. application Ser. No. 10\/660,985, entitled \u201cTECHNIQUES FOR STORING MULTIMEDIA INFORMATION WITH SOURCE DOCUMENTS\u201d, filed Sep. 12, 2003; U.S. application Ser. No. 10\/661,052, entitled \u201cTECHNIQUES FOR PERFORMING OPERATIONS ON A SOURCE SYMBOLIC DOCUMENT\u201d, filed Sep. 12, 2003; U.S. application Ser. No. 10\/660,867, entitled \u201cTECHNIQUES FOR ACCESSING INFORMATION CAPTURED DURING A PRESENTATION USING A PAPER DOCUMENT FOR THE PRESENTATION\u201d, filed Sep. 12, 2003; U.S. application Ser. No. 10\/696,735, entitled \u201cTECHNIQUES FOR USING A CAPTURED ELECTRONIC REPRESENTATION FOR THE RETRIEVAL OF RECORDED INFORMATION\u201d, filed Sep. 12, 2003 and other techniques known to those skilled in the art may be used to find matching images (i.e., images from the recorded information that comprise the extracted features).","In one embodiment, the extracted features may be used to determine recorded information  for presentations that include information that match the extracted features. For example, this is done by first extracting images from recorded information . The images that are extracted from recorded information  may include images captured during the presentation by various electronic representation capture devices, images captured by a presentation recorder, keyframe images obtained from video information captured during the presentation, and the like.","The extracted images are then compared with the extracted features determined in step . The extracted images may have been pre-processed to determine time information indicating the time(s) during the presentation when the slide was displayed or presented. The time information for a slide may also identify one or more spans of time during the presentation when the slide was presented or displayed. The spans of time may be non-contiguous.","In one embodiment, the matching information may be determined using techniques described in the \u201cMatching Techniques\u201d section described below. The matching information may be determined using presentation level matching. A document-matching algorithm receives a document electronic representation Ii as input and it compares that to the database of Presentation Recorder documents. This may be referred to as a presentation-matching step. It locates every presentation recording session that may have been used to give the presentation. The next step, called slide matching, maps each segmented slide electronic representation pin the identified Presentation Recorder sessions onto the slide images on the document. The techniques are described in more detail below. This provides the mapping from each slide in the documents to the source and time stamps in the audio and video tracks.","In step , information to insert is determined based on the matching information determined in step  and the electronic representation of the paper document received in step . In one example, the information determined may be based on slide images that match the extracted features. The association information determined for a matching slide image may be used to index into a presentation. An image extracted from the presentation recording at the time indicated by the association information may then be determined.","In step , a composite electronic representation  is created with the information determined in step . Composite electronic representation may include many types of information. For example, the features extracted may be included in composite electronic representation .","Also, the information may include metadata that is determined based on recorded information . The metadata may be derived from the matching information determined in step . For example, metadata may also be determined and inserted in the created electronic representation. Recorded information  may be post processed to extract metadata to be included in composite electronic representation  (created using documents as templates). For example, how long a slide was discussed may be calculated and inserted. It should be understood that there is no limit on what kind of metadata is extracted or in what form they can be included in composite electronic representation , some examples for extraction of metadata are provided for illustrative purposes. Techniques for determining metadata will be described in more detail below.","Also, a selectable object, such as an icon or a link, may be inserted. When selected, the object uses association information that is related to the matching information determined in step  to access recorded information . For example, the accessed information may be a presentation recording at a time when a slide was displayed. Thus, an image extracted from recorded information , when selected, may cause the presentation recorded to be accessed at a time specified by association information for the image. In another embodiment, recorded information  may be embedded or stored with the image. When an object is selected, the embedded information is accessed and played. Thus, a central database may not need to be accessed. For example, a video player object may be embedded in the image. When play is selected, recorded information  is automatically played.","In one embodiment, the electronic representation received in step  is used to create composite electronic representation . For example, information is inserted into the electronic representation received. Also, a new document may be created that includes the electronic representation received and the inserted information. In both cases, composite electronic representation  is created with information relating to recorded information  inserted into it. For example, a paper document may be printed and handed out for a presentation. A user may take notes on the paper document. The paper document is then scanned to generate an electronic representation of the paper document. Information is then inserted in the scanned electronic representation.","In another embodiment, a document that is different from the electronic representation received is created. A different document may include the features extracted in step  and the inserted information. For example, just the extracted images of slides in a paper document and the determined information may be included in composite electronic representation .","Composite electronic representation  created in step  may then be emailed, reprinted, stored on a server for later access, copied to storage medium, such as a CD, display, etc. When a user needs to review that particular presentation, the user can review the notes taken in composite electronic representation  (assuming that composite electronic representation  included the notes of the paper document). If more information is needed, the information inserted in composite electronic representation  may be selected and recorded information  corresponding to association information for the inserted information may be accessed and displayed. For example, a presentation playback interface may be invoked and playback starts from a time stored in the association information. In other embodiments, the inserted information may be used to add information to composite electronic representation . For example, metadata may indicate how long the slide was discussed.",{"@attributes":{"id":"p-0068","num":"0067"},"figref":["FIG. 3A","FIG. 3"],"b":["300","300"]},"As shown in , information  identifying the presentation and the presenter is printed on page . Other information such as the time when the presentation takes place, the duration of the presentation, etc. may also be included in information . In the embodiment depicted in , three slides (features) -, -, and - are printed on page . Additionally, spaces  are provided for a user to take notes during the presentation for each slide.",{"@attributes":{"id":"p-0070","num":"0069"},"figref":["FIG. 3B","FIG. 3A"],"b":["300","308","1","308","2"]},{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 3C","FIG. 3C"],"b":["122","122","122","120","310","122","300","300"]},"Composite electronic representation  also includes information . As shown, images of recorded information  are included in information . The images, in one embodiment, correspond to a portion in recorded information  for a presentation. The portion may be when a slide that matches a slide  was outputted. For example, information - includes information extracted from recorded information  where an image of slide - was outputted.","In one embodiment, information , when selected, may cause an action to be performed. Each image in information  may be associated with association information, such as time and source information, that is used to access recorded information . Although not shown, information  may also include information other than images, such as hypertext links, icons, metadata, etc.","Composite electronic representation  may include the received electronic representation of paper document . In this case, information  is inserted into the scanned electronic representation. Thus, a user that took notes on a paper document may view the paper document with the notes in addition to the inserted information . In one example, an electronic representation of a user's paper document becomes a template for a media document that includes the inserted information . Thus, a user may view the media document and, if more information is desired, the inserted information may be selected and related recorded information  may be accessed and viewed.","Also, composite electronic representation  may be a different document than the received electronic representation. The different document may include any or all of the features from the electronic representation received. For example, a user may desire a different format than the electronic representation of the paper document. The slide images or notes in the electronic representation of the paper document may be removed or moved to a different location on the page. For example, composite electronic representation  with just the user's notes and inserted information  may be generated.","Composite electronic representation  may be stored in various formats. For example, composite electronic representation  may be a PDF, HyperText Transfer Language (HTML), Flash, MS Word, etc. formatted document. In one embodiment, the format supports the insertion of information that may be used to link to recorded information .","As described above, features extracted are used to determine matching information. In alternative embodiments, other types of information may be used to determine matching information. For example, bar codes found on a paper document may be used to determine portions of recorded information . For example, in one embodiment, documents may be printed with barcodes associated with each slide. The bar codes may be used to make the link between the slides and the recorded information. For example, techniques described in U.S. application Ser. No. 10\/660,867, entitled \u201cTECHNIQUES FOR ACCESSING INFORMATION CAPTURED DURING A PRESENTATION USING A PAPER DOCUMENT FOR THE PRESENTATION\u201d, filed Sep. 12, 2003.","In another embodiment, barcodes, or some other markings may be used to represent signature information of each slide. This signature information may include the text from the slide, image feature vectors, etc. The signature is generated at the time of generating the document (e.g., during printing). The signature may also include information regarding the location on the document where the information related to recorded information  may be inserted. After the document image is captured (e.g., after scanning), these printed markings are identified (extracted & decoded) and used for matching, accessing, and inserting the information related to recorded information .",{"@attributes":{"id":"p-0079","num":"0078"},"figref":"FIG. 4","b":["314","314"]},"As shown, an interface  may be displayed when an image in information  is selected. Interface  includes a window  that displays recorded information  and a window  that includes an image of a slide . For discussion purposes, it assumed that a user has selected an image in information -. After the selection, association information for the image is used to access recorded information . For example, the association information may be source and time information. The source information may used to access a presentation and the time information is used to determine a portion of the presentation at the time. For example, the time information may be a start time where a slide - was displayed.","Window  includes a media player and may be used to display a portion of accessed recorded information . As shown, recorded information  is displayed in a media player window . In this case, a starting image corresponds to the image displayed in information -. A user then may select play in the media player and portions of the presentation are played. Alternatively, the accessed recorded information  may be automatically played.","An image of slide - may also be displayed in window . Also, the original slide in the *.ppt file may be displayed in window . Thus, a user may watch a presentation in window  in addition to viewing slide -. Accordingly, a user may not need to view the paper copies of the document. Also, window  may include other information, such as the notes that a user took as shown in . Additionally, metadata that is determined may also be displayed in window .",{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 5","FIG. 5"],"b":"600"},"An electronic representation receiver  receives an electronic representation of a paper document. In one embodiment, the electronic representation may be received from a scanner that scanned a paper document to generate the image. Also, an electronic copy of a paper document may be received.","A feature extracter  receives the electronic representation and is configured to extract features from the image. For example, slide images are extracted from the electronic representation of the paper document. As discussed above, various techniques may be used to determine individual slide images.","A comparer  receives the extracted features and is configured to determine matching information for the extracted features. In one embodiment, a database  that stores recorded information  and association information  is queried. The extracted features are compared to recorded information  to determine matching information. Association information for the matching information in recorded information  may be determined also. The association information may be used to access portions of presentations.","An information inserter  receives the matching information, association information, and image. Also, recorded information  (e.g., audio and video information), metadata, etc. may be received. Information inserter  is configured to determine information to insert and to generate a composite electronic representation , as described above. For example, information  related to the matching information in recorded information  is inserted in composite electronic representation . Information  may also be associated with the association information. In this case, when the inserted information  is selected, the association information may be used to access portions of recorded information . Also, recorded information  (e.g., audio and video information), metadata, etc. may be inserted into electronic representation . Thus, database  does not need to be accessed when recorded information  is played.","Applications:","I. Play Program","Although embodiments of the present invention have been described using presentation recordings, it will be recognized that embodiments described may be used with recorded information other than presentation recordings. A paper document may be various forms including any medium that includes recognizable features you can extract. For example, a paper document may be a program of a play. Before a play in a theater starts, the program of the play is distributed to the audience. The program may include some scenes from the play, images of actors, or some text from the play. The play is then recorded. After the play, composite electronic representation  of the play program is received. For example, a user may scan or capture the play program with their digital camera. Using processing described above, composite electronic representation  includes information related to the recorded play. The processing may include comparing the play scenes in the program to the captured video frames of the recorded play, comparing the actor's pictures in the program to the face recognition results from the play recording, and comparing the text in the program to the captured audio (speech recognition) to determine matching information.","Information related to the matching information may then be inserted into composite electronic image. Composite electronic representation  of the play program may have objects inserted that are associated with portions of the play. A user may store composite electronic representation  in their digital camera. Alternatively, composite electronic representation  may be e-mailed to the user or to others for sharing purposes. Accordingly, when a user is interested in a feature in the program, the inserted information may be selected and a portion of the recorded play may be accessed and played in one example.","II. Symphony","Another application example is as follows, before a symphony practice takes place, music notes are printed and distributed to the players as paper documents. During the symphony, music is recorded, and players may take notes on the documents. After the practice, electronic representations of the documents are received. An association between the recorded audio is determined by OCR'ing the captured music notes and automatically extracting notes from the audio and matching them. The user then may receive composite electronic representation , such as a PDF document, that contains the scanned music notes, the personal notes, and inserted information that associates the information to the audio recorded during the practice (or audio played by another symphony). Composite electronic representation  may also be helpful to another person for practicing who may have missed the original practice.","Techniques for performing segmentation, techniques for matching, and techniques for determining metadata will now be described.","Segmentation","Embodiments of the present invention may segment an electronic representation of a paper document using the following process. Horizontal and vertical protections of an electronic representation are first obtained. It should be noted that some pre-processing of the electronic representation may be required before this step, such as skew correction, down sampling, smearing, connecting component analysis, etc.","The distance between extracted projections to the projections obtained from a set of document templates is computed.  depicts possible templates that may be included in the set of document templates. Document templates  include possible layouts that may have been used to create the pages. The layouts include different images. For example, documents - and - include layouts for slide images. Document template - includes two columns of slide images . Document template - includes a single column of slide images . Document template - also includes a left column that includes three slide images  and a right column that includes three areas  where a user may enter notes. The extracted projection is then compared to document templates . In one embodiment, these templates are used to create paper documents. For example, the images shown do not have to be images of slides. Rather, windows that indicate a slide should be placed in certain locations where the slide images are shown in  may be used.","The document template  that has a minimum distance to the document image is then determined. For example, a page that includes three slide images in a left column and a space for notes in the right column may substantially match document template -.","The document image is then segmented into rectangular regions using the slide placement information of a matched document template . For example, because the slides are located in the left column with a certain spacing, the document may be segmented into portions that include individual portions that include a slide.","Matching Techniques","In one embodiment, the following techniques may be used to determine association information using the electronic representation of the document and presentation recording document. A document-matching algorithm receives an image Ii as input and it compares that to the database of recorded Presentation recorder documents. This may be referred to as a presentation-matching step. It locates every presentation recorder document that could have been captured during the presentation where the slides in the document are presented. The next step, called slide matching, maps each slide image in the segmented document image onto the slide images captured by the Presentation Recorder in one presentation session.","The presentation-matching algorithm applies OCR to the Presentation Recorder document and it saves the text it outputs together with an indication of the page that the text occurred on. An issue is the presence of potentially a large number of both duplicate and spurious images in the Presentation Recorder document caused by people going back and forth in their PowerPoint file while they give a talk, the use of custom animations that cause only minor differences to occur in the captured images, and the use of video clips that can cause the Presentation Recorder to capture hundreds of frames. A pseudo code statement according to one embodiment of the presentation-matching algorithm is shown below.","for every slide s in Document Ii","for every word n-gram w in s\n\n","if (score {Pj}\/num_words {Pj}>t &&\n\n","then return (Pj);","end","The first step looks up all the Presentation Recorder files that contain each word n-gram in the Document Ii and increments a score for that document. The second step considers the Presentation Recorder files with a minimum percentage of their words in Ii, as specified by t, and determines the percentage of pages with more than t of their n-grams in Ii. If this exceeds t, then we say this Pj is the matching Presentation Recorder document.","The presentation-matching algorithm is tolerant of OCR errors in the Presentation Recorder document. Since it contains color jpeg images, we expected the OCR would make many mistakes. However, because presenters typically choose fonts carefully and use short text phrases, errors may not be a significant problem. Also, the requirement that a percentage of the pages in the Presentation Recorder file be contained in the Document takes into account duplicate and spurious images. These factors let thresholds be set liberally.","An additional consideration in the design of the presentation-matching algorithm was the use of existing full text indexes. This was achieved by using word n-grams as query terms to propose potentially matching PowerPoint files. This is supported by almost every full text index, e.g., Google.","The slide-matching algorithm determines images in the Document I, that match each slide in the Presentation Recorder files located by the presentation-matching algorithm. It uses a combination of string matching on the OCR results for the images that contain text, and edge histogram matching for images that do not contain text. Examples of slide matching techniques are described in more detail in U.S. application Ser. No. 10\/412,757, entitled \u201cAUTOMATED TECHNIQUES FOR COMPARING CONTENTS OF IMAGES\u201d, filed Apr. 11, 2003.","Metadata","Text and Keywords","Text is extracted from each captured screen image. Test localization and binarization of each electronic representation is achieved with a scheme that uses not only the luminance component of a captured image, but also its color components. This is because, unlike common document images, background\/foreground contrast in a slide electronic representation may be obtained by color contrast as well as luminance contrast. Details of this scheme are described in U.S. application Ser. No. 10\/412,757, entitled \u201cAUTOMATED TECHNIQUES FOR COMPARING CONTENTS OF IMAGES\u201d, filed Apr. 11, 2003. A commercial OCR package may be used to extract text from the binarized text regions. Extracted text is indexed in XML format with the captured image and line number. Keywords are found by TF-IDF analysis performed on the text extracted from all the screen captured images for a presentation session.","Electronic Representation Features","A number of image feature vectors, i.e., edge histogram and color layout [ID-RII-311], are computed for the screen capture images. These features are later employed for duplicate slide detection and linking screen images to the original presentation slides.","Symbolic Presentation Slides","Presenters can submit the original presentation document to the server prior to their talk. After the submission, presentation file is assigned an ID, ID. and text and slide titles are extracted from each slide by parsing the presentation file. A rendered JPEG electronic representation of the slide, S, is extracted and used to compute the edge histogram and color layout feature vectors. Presentation file, JPEG images, text, titles, and feature vectors are indexed and placed to a directory of unresolved presentations.","After each presentation session finishes, image features and text extracted from the screen capture images are matched with the image features and text extracted from the unresolved presentation files. When there is a match found, the file is removed from the directory of unresolved presentations and linked to the recorded presentation. After presentation level matching, electronic representation and text features are used to match each presentation slide, S, to a set of screen capture images, {C, . . . , C}. The electronic representation matching process is 98% accurate.","Key Frame Extraction","The conference room is equipped with 2 cameras, a Pan-Zoom-Tilt camera and an omni-directional camera with 360\u00b0 capture. The PTZ camera focuses on either the presenter or the entire conference room. PTZ camera location is controlled by the meeting room portal and each time the camera location changes a keyframe is extracted from the video sequence. The omni-directional camera is placed in the middle of the conference room and captures a panoramic view of the room. Four microphones are attached to the camera and sound source localization (SSL) is performed real-time on the 4 channel audio. Each time the sound source changes direction, a key frame showing only a perspective view from the direction of the sound is extracted from the panoramic video.  shows these key frames , which are very useful when navigating meeting\/presentation recordings as they coincide with speaker changes. All the extracted key frames are indexed with their source and timestamps.","Time Spent on Each Slide","The amount of time spend on a presentation slide, sT, can be a good indicator of the importance of that particular slide and computed as",{"@attributes":{"id":"p-0116","num":"0119"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":["sT","i"]},"mo":"=","mrow":{"mrow":[{"mfrac":{"mn":"1","mi":"pT"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"msub":[{"mi":["C","n"]},{"mi":["S","i"]}],"mo":"\u2248"},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"T","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"C","mrow":{"mi":"n","mo":"+","mn":"1"}}}}}},{"mi":"T","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["C","n"]}}}],"mo":"-"}},"mo":","}}},"br":{},"sub":["i ","n ","i","n","n "],"sup":"th "},"Question & Answer Activity","The amount of discussions, questions, comments around a particular presentation slide can be an indication of the interest around the topic it discusses. On the other hand, segmentation of speakers, Q&A sessions, are quite challenging and often require prior training of the speaker segmentation systems. Our approach for identifying audio segments with Q&A activity is somewhat different. It is based ion SSL and works quite robustly in practice. Our experiments showed that during a presentation, 93% of the time the speaker stays in the same 20 degree azimuth (region) of the SSL device. Clearly, the azimuth range could change based on the conference room setup. Nevertheless, for most conference room setups, it is often a reasonable assumption to make that the presenter has a limited platform to move around. Let's indicate this range of this platform wrt the SSL with [\u03b1\u03b1]. Assuming that there is no audience between the presenter and the SSL device, sound coming from the direction other than the presenter can be interpreted as a comment or a question from an audience member. The question and answer activity for a given presentation slide Si is defined as the number of times the sound source change directions between the audience and the presenter as follows:",{"@attributes":{"id":"p-0119","num":"0122"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":["sQA","i"]},"mo":"=","mrow":{"mfrac":{"mn":"1","mi":"pD"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"msub":[{"mi":["C","n"]},{"mi":["S","i"]}],"mo":"\u2248"},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"t","mo":"=","mrow":{"mi":"T","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["C","n"]}}}},{"mrow":{"mi":"T","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"C","mrow":{"mi":"n","mo":"+","mn":"1"}}}},"mo":"-","mn":"1"}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}}],"mo":"-"}}}}}},"mo":","}}},"br":{},"sub":["n ","i","n","n "],"sup":"th "},{"@attributes":{"id":"p-0120","num":"0123"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":"pD","mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"t","mo":"=","mn":"0"},"mi":"pT"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}}],"mo":"-"}}}},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0121","num":"0124"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":"D","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mo":["{","}"],"mtable":{"mtr":[{"mtd":[{"mrow":{"msub":[{"mi":"\u03b1","mrow":{"mi":"s","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"1"}},{"mi":"\u03b1","mrow":{"mi":"s","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mn":"2"}}],"mo":["\u2264","\u2264"],"mrow":{"mi":"SSL","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}}},{"mn":"1"}]},{"mtd":[{"mi":"ow"},{"mn":"0"}]}]}}],"mo":"="},"mo":","}}},"br":{}},"Notes Activity","The amount of note taking activity takes place around certain topics in a seminar is most of the time directly relevant to the interest of the audience to that topic. A notes activity measure is computed as follows:",{"@attributes":{"id":"p-0123","num":"0126"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":["sN","i"]},"mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"mi":"\u03b7","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"0","mo":",","mi":"pT"}}}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"msub":[{"mi":["C","n"]},{"mi":["S","i"]}],"mo":"\u2248"},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"\u03b7","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"T","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["C","n"]}}},{"mi":"T","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"C","mrow":{"mi":"n","mo":"+","mn":"1"}}}}],"mo":","}}}}}},"mo":","}}},"br":{},"sub":["1","2"],"b":["1","2"]},{"@attributes":{"id":"p-0124","num":"0127"},"figref":["FIG. 8","FIG. 8"],"b":["900","900","902","904","906","908","910","912","914","916","902"]},"Network interface subsystem  provides an interface to other computer systems, networks, and storage resources. The networks may include the Internet, a local area network (LAN), a wide area network (WAN), a wireless network, an intranet, a private network, a public network, a switched network, or any other suitable communication network. Network interface subsystem  serves as an interface for receiving data from other sources and for transmitting data to other sources from data processing system . For example, data processing system  may access stored recorded information for a presentation and XML data structures via network interface subsystem . Embodiments of network interface subsystem  include an Ethernet card, a modem (telephone, satellite, cable, ISDN, etc.), (asynchronous) digital subscriber line (DSL) units, and the like.","User interface input devices  may include a keyboard, pointing devices such as a mouse, trackball, touchpad, or graphics tablet, a scanner, a barcode scanner, a touchscreen incorporated into the display, audio input devices such as voice recognition systems, microphones, and other types of input devices. In general, use of the term \u201cinput device\u201d is intended to include all possible types of devices and ways to input information to data processing system .","User interface output devices  may include a display subsystem, a printer, a fax machine, or non-visual displays such as audio output devices. The display subsystem may be a cathode ray tube (CRT), a flat-panel device such as a liquid crystal display (LCD), or a projection device. In general, use of the term \u201coutput device\u201d is intended to include all possible types of devices and ways to output information from data processing system .","Storage subsystem  may be configured to store the basic programming and data constructs that provide the functionality of the present invention. For example, according to an embodiment of the present invention, software modules implementing the functionality of the present invention may be stored in storage subsystem . These software modules may be executed by processor(s) . Storage subsystem  may also provide a repository for storing data used in accordance with the present invention. Storage subsystem  may comprise memory subsystem  and file\/disk storage subsystem .","Memory subsystem  may include a number of memories including a main random access memory (RAM)  for storage of instructions and data during program execution and a read only memory (ROM)  in which fixed instructions are stored. File storage subsystem  provides persistent (non-volatile) storage for program and data files, and may include a hard disk drive, a floppy disk drive along with associated removable media, a Compact Disk Read Only Memory (CD-ROM) drive, an optical drive, removable media cartridges, and other like storage media.","Bus subsystem  provides a mechanism for letting the various components and subsystems of data processing system  communicate with each other as intended. Although bus subsystem  is shown schematically as a single bus, alternative embodiments of the bus subsystem may utilize multiple busses.","Data processing system  can be of varying types including a personal computer, a portable computer, a workstation, a network computer, a mainframe, a kiosk, or any other data processing system. Due to the ever-changing nature of computers and networks, the description of data processing system  depicted in  is intended only as a specific example for purposes of illustrating the preferred embodiment of the computer system. Many other configurations having more or fewer components than the system depicted in  are possible.","Although specific embodiments of the invention have been described, various modifications, alterations, alternative constructions, and equivalents are also encompassed within the scope of the invention. The described invention is not restricted to operation within certain specific data processing environments, but is free to operate within a plurality of data processing environments. Additionally, although the present invention has been described using a particular series of transactions and steps, it should be apparent to those skilled in the art that the scope of the present invention is not limited to the described series of transactions and steps. It should be understood that the equations described above are only illustrative of an embodiment of the present invention and can vary in alternative embodiments of the present invention.","Further, while the present invention has been described using a particular combination of hardware and software, it should be recognized that other combinations of hardware and software are also within the scope of the present invention. The present invention may be implemented only in hardware, or only in software, or using combinations thereof.","The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense. It will, however, be evident that additions, subtractions, deletions, and other modifications and changes may be made thereunto without departing from the broader spirit and scope of the invention as set forth in the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 3B","FIG. 3A"]},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 3C"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
