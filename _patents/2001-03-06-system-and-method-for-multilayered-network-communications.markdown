---
title: System and method for multi-layered network communications
abstract: A multi-layered network for transporting data comprises a first network layer that provides a first session topology, and a second network layer that provides a second session topology. The second network layer uses the first network layer to transport data. In one embodiment of the invention, the data sent by the second layer is real-time audio data, such as voice. Each session topology may be either peer-to-peer or client/server. The first and second layers may have different topologies and/or different session hosts. A deterministic algorithm is provided whereby a new session host is selected when the current host leaves the session.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07720908&OS=07720908&RS=07720908
owner: Microsoft Corporation
number: 07720908
owner_city: Redmond
owner_country: US
publication_date: 20010306
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED CASES","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION","APPENDIX A","Exemplary Application Programmer Interface for an Audio Layer","APPENDIX B","Exemplary IDirectPlayVoiceNotify and IDirectPlayVoiceTransport Interfaces"],"p":["This application claims the benefit of U.S. Provisional Application No. 60\/187,511, entitled \u201cDirectPlay Voice For DirectX 8.0,\u201d filed on Mar. 7, 2000, which is hereby incorporated by reference.","The present invention relates generally to the field of computer networking. More particularly, the invention provides an audio engine which sends audio or other data using a transport layer, and which creates and dynamically morphs an audio session whose topology is independent of the underlying transport layer's session topology.","The world-wide increase in computer networking bandwidth has enabled large amounts of data to be transmitted quickly and at low cost. The availability of great bandwidth has invited the creation of applications that communicate data in quantities that were previously thought to be too costly or too cumbersome. One such application is real-time voice transmission. The notion of carrying on a video-conference or a video game between participants in different cities around the world was once unheard of. Today, applications that permit such activities are available as a cutting-edge technology; soon, such applications and the devices that support them will become commonplace. However, such applications require the transmission of real-time voice over a data network, and such voice transmission presents various problems.","First, network topologies are constantly evolving. Traditionally, network communication has used a \u201cclient\/server\u201d model in which one network node (the server) is the focal point for all communication from a group of other nodes (the clients); the clients communicate with the server but do not communicate with each other. The client\/server model is, in some contexts, giving way to a \u201cfederated\u201d or \u201cpeer-to-peer\u201d model, in which each node can communicate directly with any other node (or, at least, in which the network provides a level of abstraction that makes it appear to each node as if such communication is possible). A voice transport that is dependent upon one model may not work in an environment that is dependent upon another model.","Second, the networks that provide the underlying data transport are constantly evolving as well. For example, data may be transmitted over a telephone line, Digital Subscriber Line (DSL), cable, Ethernet, etc. Each type of connection may use different protocol. Networks are typically built in layers, each of which provides its own protocol that may be used on top of another layer. As future communication technologies become more widespread (e.g., wireless data networking, satellite networking, etc.), these technologies may have their own peculiarities. If voice transport is dependent upon any protocol, structure of network layers, or underlying communications medium, it cannot easily be adapted to future technologies\u2014or even to the multitude of presently-available communication technologies.","Third, conventional voice networking implementations require a fixed host for the voice session, and if the host leaves the session, the session cannot continue, which results in termination of the session.","While systems exist that either support real-time voice communication or can be adapted to do so (e.g., NetMeeting\u2122, Hear Me, Net-2-Phone, AOL Messenger, applications based on the H.323 suite of protocols), they do not address the drawbacks discussed above. Thus, in view of the foregoing, there is a need for a networking system that overcomes the drawbacks of the prior art.","The present invention provides a communication architecture that transports voice using any network (or combination of network layers) that supports both guaranteed and non-guaranteed messaging. The voice transport system of the present invention supports various topologies for digital voice communication. For example, a voice transport system in accordance with the invention may support: (a) peer-to-peer; (b) forwarding; (c) mixing; and (d) echo. Additionally, the invention supports all of these voice topologies regardless of whether the underlying session\/transport layer used to transport voice packets employs a client\/server or peer-to-peer topology for data delivery.","A voice transport system in accordance with the invention packages voice data into frames and provides the frames to an underlying data network for delivery. For example, the voice transport system may deliver data using the DirectPlay networking protocol, which is part of the DirectX\u00ae application programming interface provided by Microsoft Corporation of Redmond, Wash. The voice transport system provides a protocol that enables voice connections and communications to take place on top of such a data network.","The protocol includes: a connection process; a disconnection process; a format for the transmission of voice data; a host migration process; and a set of general messages used during a voice session. The connection process includes the exchange of a set of messages that permits a node to join a voice session, provided that the joining node has a connection in the underlying transport. The disconnection process includes the exchange of a set of messages that permits a node to leave a voice session. The voice transmission format includes a voice packet header with a variety of message types.","The host migration process is used to change the host of a voice session\u2014e.g., if the current host has left the session. The host is the primary keeper of the name-table in a peer-to-peer session. When such a host leaves a voice session, a new host must be selected in order for the session to continue. Each node in a session has a \u201chost order ID,\u201d which may be assigned at the time the node joins the session. At the time that a host leaves the session, it runs a host migration election algorithm to determine whether there is any node that can take over as host. If there is no such node, the host sends a \u201csession lost\u201d message, which tells any node in the process of connecting that the host is leaving. If there is a node that can take over as host, the host sends a \u201chost migrate leave\u201d message. In response, all nodes run the host selection algorithm. The new host discovers that it is, in fact, the new host by running the algorithm. Once the new host discovers that it is the new host, it sends a \u201chost migrated\u201d message to all other nodes to notify those nodes that it is the new host. The other nodes respond with a confirmation message.","Communication between the voice layer and the session\/transport layer is provided by a set of application programmer interfaces (APIs). The transport layer exposes an API which is callable by the voice layer. The voice layer calls this API in order to send and receive data over the session\/transport layer. The voice layer exposes an API which is used by the session\/transport layer to notify the voice layer of events\u2014e.g., the entry or exit of a node from the session\/transport layer.","One exemplary application of the invention is voice messaging in a multi-player game, where the different players are connected by a data network, such as the Internet. The different player machines may use a session\/transport layer to communicate various information with each other (e.g., the position of the player in the playing domain), and the voice transport layer may use the session\/transport layer to transmit voice packets during the game (e.g., a player uses a microphone to send a voice message to other players, which is transmitted by the voice layer over the session\/transport layer). However, it will be appreciated that the invention may be used in any context in which real-time voice communication is desirable, particularly those contexts in which voice data is transmitted together with other types of data\u2014e.g., video conferencing, virtual meetings, telephony, etc. It should also be appreciated that digital voice is merely a type of data, and the architecture of the present invention may be used to transport any type of data, whether or not such data is voice, or even audio.","Overview","Networks are built in layers. One layer of a typical network is a basic data delivery protocol, such as the User Datagram Protocol (UDP). A next (second) layer may be a transport protocol, which provides such features as session management and guaranteed delivery. The second layer provides these features by performing various bookkeeping tasks (e.g., keeping track of which nodes are current members of a session), and by using the first layer to send administrative data between the nodes. In some applications, it may be useful to provide a third layer. For example, the second layer may perform general data transport, and the third layer may be an \u201caudio engine\u201d which collects audio data (e.g., with a microphone), packages the audio data, and uses the second layer to perform the actual sending and receiving of audio data. The third layer may provide its own protocol and\/or networking features. For example, the third layer may provide audio sessions that can be connected to, disconnected from, hosted, configured, etc.\u2014independently of any sessions that may exist on the second layer. The present invention provides a protocol for such a third layer, as well as various techniques used in the course of operating such a layer.","Exemplary Computing Environment",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 1","b":["100","100","100","100"]},"The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like.","The invention may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network or other data transmission medium. In a distributed computing environment, program modules and other data may be located in both local and remote computer storage media including memory storage devices.","With reference to , an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer . Components of computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus (also known as Mezzanine bus).","Computer  typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CDROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can accessed by computer . Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules , and program data .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk , such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through an non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in , provide storage of computer readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer  through input devices such as a keyboard  and pointing device , commonly referred to as a mouse, trackball or touch pad. An audio input device, such as microphone , may be provided. Other input devices (not shown) may include a joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . In addition to the monitor, computers may also include other peripheral output devices such as speakers  and printer , which may be connected through an output peripheral interface .","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Layered Networks","As described above in connection with , two or more computing devices may communicate with each other via a computer network. For example,  shows computing devices  and  communicatively coupled by, inter alia, wide-area network . As previously noted, wide-area network  may comprise the Internet. A computer network, such as wide-area network , may be built in layers.  shows an example of a network that is built in layers.","In the example of , wide-area network  comprises various layers, including layers ,  and . Layer  is the basic network layer that provides a delivery protocol allowing data to be delivered over network . Layer  uses layer  to provide actual data delivery, but layer  provides some level of abstraction beyond mere data delivery. For example, layer  may implement one or more networking abstractions. As one non-limiting example, layer  may be a session\/transport layer that supports the networking model of a \u201csession\u201d\u2014i.e., two nodes can communicate if they are in the same session. In this case, layer  provides the function of allowing nodes to connect to or disconnect from a session, as well as generating and sending between nodes the administrative data that supports the model of a \u201csession.\u201d However, layer  employs layer  to provide the actual data delivery. That is, when layer  receives data to be sent from one node to another, it packages the data and provides the package to layer  with instructions to deliver the package to a specified destination (as indicated by arrow ). Likewise, when layer  generates \u201cadministrative\u201d data that supports, say, the \u201csession\u201d concept (e.g., requests to connect or disconnect from a session, dropped session signals, etc.), layer  provides such messages to layer  for delivery to their destinations.","Exemplary network  includes a third layer , which may, for example, be a session\/presentation layer that provides an additional level of networking abstraction on top of layer . In the present example, layer  provides basic data delivery, layer  supports the model of \u201csessions\u201d between nodes, and layer  may provide support for, say, audio delivery. For example layer  may receive live audio (e.g., a human voice from a microphone attached to a computing device) in the form of a digital signal, for delivery to a particular node on the network. In this case, layer  may package the audio into \u201cframes\u201d as it is captured, and provide the frames to layer  for delivery to a destination node in the session provided by layer  (as indicated by arrow ). (As discussed below, layer  may provide its own \u201csessions\u201d independently of the session that layer  provides.) When layer  receives the packaged audio frame, it uses layer  to provide the actual delivery of the data in the frames. When data is received at the receiving node, the data may be unpackaged by each of the successive layers. That is when, a package is received at the receiving node, layer  unpackages the contents and provides the contents to layer  (as indicated by arrow ). In the case where the package contents is actually a second package to be process by layer , layer  further unwraps this second package and provides the second package's contents to layer  (as indicated by arrow ).","In one example, layer  is a basic data delivery protocol that is capable of providing at least non-guaranteed packet delivery. A non-limiting example of such a protocol is the User Datagram Protocol (UDP), although it will be appreciated that layer  may comprise any data delivery protocol. Moreover, layers  and  may include any protocol that provides any sort of networking abstraction beyond basic data delivery. For example, layer  may be a protocol that handles all data delivery between players' computing devices in multi-player games. Moreover, these multi-player games may allow players to exchange data with each other, and layer  may support a voice communication facility that packages digital audio data captured by the respective players' microphones and transmits the digital audio data using layer . While  depicts network  having three layers, it will be appreciated that three layers are merely exemplary, and a network may have any number of layers.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 3","b":["210","201","202","203","210","201"]},"Data  is first delivered to layer , which wraps data  in package . For example, if layer  is an audio networking layer, then data  may be digital audio data captured by a microphone as noted above. Layer  wraps a frame of audio data into package  and provides package  to layer . Layer , in turn, wraps package  into package  and provides package  to layer . Layer  then wraps package  into package . The result is the series of nested packages shown in .","The nesting of packages may be accomplished by each layer's appending its own header to data , as shown in . For example, when raw data  is provided to layer , layer  appends header , thereby producing a package that contains header  followed by data . When layer  provides the package to layer , layer  appends header , thereby producing a package that contains header , followed by header . Layer  then provides the package to layer ; layer  appends header , thereby producing a package that contains header , followed by header , followed by header , followed by data . When the data is transported to its destination, the headers may be stripped in reverse order: i.e., layer  receives a package with headers , , and , strips header , and provides the resulting package (i.e., a package with headers  and ) to layer , and so on. The top level then strips the last header to yield data . It should be understood that the reference to \u201cheaders\u201d , , and  is merely exemplary, as each layer may append data to the package in any manner, regardless of whether such data is a \u201cheader.\u201d For example, one or more of the layers may append data to the end of the package, as a \u201cfooter.\u201d","Data Session Topologies","Networks may provide \u201csessions\u201d having various topologies. Examples of such topologies are \u201cpeer-to-peer,\u201d and \u201cclient\/server.\u201d In a peer-to-peer topology, each node in a session can communicate directly with each other node in the session. One node in the session may be designated as a \u201chost.\u201d The host maintains a \u201cname table\u201d of all the nodes in the session. Like a peer-to-peer session, a client\/server session also has a host. However, in a client server session, each \u201cclient\u201d node can communicate directly only with the host (or \u201cserver\u201d). Any message from one client node to another is routed through the host.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 5","b":["500","500","502","504","506","508","502","504","506","508","504","508","502","502","504","506","508","500","504","506","508"]},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 6","b":["600","600","602","600","604","606","608","602","604","606","608","604","606","608","602","602","600"]},"A session\/transport layer may provide a session topology such as the peer-to-peer topology depicted in , or the client\/server topology depicted in . For example, layer  (shown in ) may implement a client\/server topology, wherein every node in a session communicates with every other node through a host. In this case, layer  may use layer  to communicate data from a client node to the host. For example, if client node  (shown in ) uses layer  to send data to client node , then layer  uses layer  to send the data from client node  to host node . The layer  logic at host node  receives the data and delivers it to layer . Layer  at host node  determines that the data is destined for client node  (e.g., the destination information may be in the layer  header attached to the data). Layer  at host node  provides the data to layer  for delivery to client node .","Alternatively, layer  may implement a peer-to-peer session topology. In this case, layer  uses layer  to send data directly from the source node to the destination node, without routing each message through the host.","Audio Session Topologies","Just as a session\/transport layer may provide a session having a particular topology (as shown in ), an audio layer may also provide an audio session having a topology. As discussed above in connection with , inasmuch as audio is merely a type of data, a network may provide an audio layer (e.g., layer ) on top of a session\/transport layer (e.g., layer ). That is, the audio layer may provide various functionality for processing audio, but may use the session\/transport layer to send the audio data. Moreover, the audio layer may provide a session that is independent of the data transport session; the audio layer session may have a topology that differs from the topology of the underlying data transport session.  show examples of audio session topologies.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 7","FIG. 7","FIG. 5"],"b":["700","700","702","704","706","708","702","700","700","702","704","706","708","700","702","704","706","708"]},{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIG. 8","FIG. 8"],"b":["800","800","802","804","806","808","802","800","804","806","808","804","806","808","802","802","804","806","808","802","804","806","802","808"]},{"@attributes":{"id":"p-0060","num":"0059"},"figref":["FIG. 9","FIG. 9"],"b":["900","900","902","904","906","908","902","900","900","800","904","906","908","902","902","900","902","904","906","908","904","906","908","902","902","908","800"]},{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 10","b":["1000","1000","1002","1004","1002","1000","1004","1004","1002","1002","1004","1000"]},"Using an Audio Session Topology with a Data Session Topology","An audio network layer may be built \u201con top of\u201d a session\/transport layer. For example, an audio layer may provide any (or all) of the audio session topologies depicted in , and may then use a session\/transport layer to send the audio data to the other nodes in the audio session. With reference to the \u201clayer\u201d model shown in  and discussed above, the audio layer may, for example, correspond to layer , while the session\/transport layer may correspond to layer . Moreover, the session\/transport layer may have a session topology that differs from, and is independent of, the audio layer. For example, the audio layer may provide a peer-to-peer session topology (depicted in ), while the session\/transport layer provides a client\/server session topology (depicted in ). In a preferred embodiment of the invention, an audio layer having any of the session topologies shown in  may be built on top of a session\/transport layer that has any of the session topologies shown in .",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 11","FIG. 11"],"b":["1104","1106","1108","1106","1102","1104","1106","1108","1102","1102","1104","1106","1108","1104","1108","1106","1104","1108","1106","1102"]},"Suppose, for example, that node  (\u201cA\u201d) sends audio data to node  (\u201cB\u201d). Since the audio session is client\/server with node  as the host, node  can send directly only to node  within the audio session. As noted above, the underlying transport session is a peer-to-peer session which does permit node  to communicate directly with node ; however, from the perspective of the audio layer, node  is not directly addressable from node . Thus, audio layer provides the audio data to the transport layer with instructions to deliver the data to node . The data may be packaged with a header that indicates that node  is to forward the data to node . It will be observed that the transport layer is configured to deliver data directly from node  to node , but the audio layer is not configured to communicate in this manner. Thus, when the transport layer receives the data, it simply delivers the data to node , as it has been requested to do by the audio layer. It should further be observed that the transport layer's delivery of the data from node  to  is performed in accordance with the transport layer's topology. In this example, the transport layer is peer-to-peer, and thus supports direct communication between any nodes in the session. In another example, the transport session could be client\/server where node  is the host of the transport session. In such a case, the transport layer would fulfill delivery of the data provided by the audio layer by sending the data through the host node ; this is another example of how transport layer sends data in accordance with the transport layer's topology.","The ability of the audio layer to support a session model (e.g., client\/server, in this example) without concern as to how the data actually gets delivered demonstrates the generality and flexibility provided by building one network layer on top of another. In a preferred embodiment of the invention, an audio layer having any session topology may work with a session\/transport layer having any session topology. That is, the session topology of the audio layer may be selected without regard to the session topology of the underlying transport.","Exemplary Name Table Data Structure",{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 12","b":["1200","203","1200","1204","1206"]},"The audio layer ID is a number used to identify the node in audio layer . Transport layer  and audio layer  may have different identifiers for the same node, but transport layer 's identifier for a particular node is not known to audio layer . Transport layer  maintains a table that correlates transport session IDs with audio session IDs. The host order ID iS a number that is used by an exemplary host migration algorithm (discussed below) in order to elect the new host of a session if the existing host leaves the session.","Protocol for an Audio Layer","As discussed above, an audio layer may be built on top of a session\/transport layer. One exemplary use of such a multi-layered structure is in the case of multi-player games, where the different players communicate with each other over a computer network. For example, a game may employ a session\/transport layer to communicate basic information about the game (e.g., player position, player score, players entering and leaving the game, etc.). Such a game may also employ an audio layer to support voice communication between the players. In other words, the audio layer may collect audio data (e.g., through the players' microphones) and use the session\/transport layer to transport that audio data to other players. An example of such a multi-layered system is the DirectX\u00ae application programming interface (API) provided by Microsoft Corporation. The DirectX\u00ae API provides a data communication API that supports data communication between players in multi-player games. The data communications API uses a protocol that facilitates communication between players' machines over various different types of network connections. Moreover, the DirectX\u00ae API also provides a voice communication API that supports voice communication between players, and that uses the data communication protocol to transport voice data between players. This is an example of a voice layer being built on top of a session\/transport layer. It will be understood that the DirectX\u00ae API, as well as gaming environment, are merely exemplary. The invention applies to any application in which it may be useful transport both audio and other types of data between nodes in a network, whether or not such application is a game. Moreover, the DirectX\u00ae API is merely one example of a system that supports an audio layer built on top of a session\/transport layer.","An exemplary protocol for an audio layer includes five aspects: (1) connection; (2) disconnection; (3) transmission of audio data; (4) general messages; and (5) host migration. These aspects of the exemplary audio layer protocol are described below.","Connection","Connection is the process by which a client node connects to an audio session. Preferably, the client is connected to a session in the underlying transport before connecting to the audio session (i.e., the transport is a member of the underlying data-layer session that is used to transport audio data). Messages sent during the connection process are sent by \u201cguaranteed\u201d delivery.","An exemplary process for connecting to a session is shown in . A client node initiates the connection process (block ) by sending a connection request (\u201cCONREQ\u201d) message to all other nodes in the session. (If the session is a client\/server session, then the CONREQ message is sent to the host, since it is only possible for a non-host node to send to the host in a client\/server session.). If the client does not hear a response from the host within a timeout period, then the client re-sends the CONREQ message. Preferably, the CONREQ message contains the protocol version of the client.","The host, after receiving the CONREQ message (block ) responds with a connection-accept (\u201cCONACCEPT\u201d) message if the client is allowed to connect. Preferably, the CONACCEPT message contains a compression type used for the session, session type, session flags and protocol version. If the client is to be denied the connection, a connection-reject message is sent from the server to the client, which describes the reason the client was denied the connection. For example, a client may be denied a connection if its protocol version is incompatible with the audio session, or if the host encounters an internal error. Receipt of a connection-reject message causes the client to discontinue the attempt to connect to the session.","The client, upon receiving the CONACCEPT message attempts to initialize itself using the settings specified in the CONREQ message (block ). If the client cannot initialize itself with the given settings (e.g. the protocol version is not compatible, or the client does not have the specified compression type) then it discontinues its connection attempt. If the client is successful in initializing itself with the given settings it responds to the server with a confirmation (\u201cSETTINGSCONFIRM\u201d) message. The SETTINGSCONFIRM message preferably contains configuration information about the client.","The server, upon receiving the SETTINGSCONFIRM message (block ) adds the newly-connected client to the list of members in the audio session\u2014e.g., by adding the newly-connected client to the name table. If the audio session is peer-to-peer, then the host sends all the clients in the session a message to that effect. (In the example of  where the audio session is a voice communication session for a multi-player game, the message is labeled \u201cPLAYERJOIN\u201d. It will be understood, however, that audio sessions are not limited to the gaming context where clients are \u201cplayers.\u201d Any message that indicates that a new client has joined the audio session, regardless of whether the new client is a \u201cplayer,\u201d may be used without departing from the spirit and scope of the invention.) The exemplary PLAYERJOIN message preferably contains information about the newly-connected client, including; their host order ID (described below in connection with host migration), configuration information, and an audio session ID. The audio session ID is a numeric identifier given to the audio protocol by the transport it is using (e.g., the session\/transport layer used by the voice layer may assign an audio session ID to each client that joins the audio session). The audio session ID is used to uniquely identify a client within the audio session. The other clients in the audio session receive the PLAYERJOIN message and update their local list of clients (e.g., their local copy of the name table) to include the newly-connected client (block ).","If the session is peer-to-peer the server then sends a \u201cNAMETABLE\u201d message to the client. The NAMETABLE message contains a list of the clients who are currently in the audio session, including configuration information about those clients (host order ID and audio session Ids for each node in the session). Receipt of the NAMETABLE message finalizes the new client's connection to the session (block ). In the case where the audio session has a client\/server topology, a NAMETABLE message is typically not sent to the newly connected client, since clients generally do not store a copy of the name table in client\/server topologies.","Disconnection","Disconnection is the process by which a client node that is a member of an audio session disconnects from that session. All messages related to the disconnection process are preferably sent by guaranteed delivery.","An exemplary disconnection process is shown in . A client node initiates the process of disconnecting from an audio session by sending the host a disconnection request (\u201cDISCONNECTREQ\u201d) message (block ), which is received by the host (block ). If the session is peer-to-peer, then the host sends the other clients in the session a message indicating that the client is disconnecting from the session. (In the example of  where the audio session is a voice session between players in a multi-player game, the message that is sent to the other clients in the session is labeled \u201cPLAYERQUIT.\u201d However, it will be understood that this label is merely exemplary, and any message may be sent which indicates to other members of the session that the disconnecting client is leaving the session.) The exemplary PLAYERQUIT message preferably contains a \u201creason code\u201d for the disconnection as well as the audio session ID of the disconnecting client. For example, the reason code may indicate \u201csuccess\u201d in the case where a client leaves the session upon its own request. However, if the client disconnects abnormally in a peer-to-peer session, then the host sends all of the other clients in the session a PLAYERQUIT message with a reason code indicating \u201cconnection lost.\u201d Upon receiving the PLAYERQUIT message (block ), the other clients in the audio session delete the disconnecting client from their respective local copies of the name table","Upon receiving the DISCONNECTREQ message from the disconnecting client, the host responds to the disconnecting client with a confirmation message (\u201cDISCONNECTCONFIRM\u201d). Once the client receives the DISCONNECTCONFIRM message, it is disconnected from the voice session (block ). It should be noted that if a server receives a DISCONNECTREQ message from any client, it responds with a DISCONNECTCONFIRM message regardless of whether it knows about the client. This is to handle a condition where the host leaves the session after a client has sent a DISCONNECTREQ.","Transmission of Audio Data","Audio data is transmitted from one member of an audio session to another in the form of an audio packet.  shows an exemplary format for an audio packet . Audio packet  comprises a header  followed by a frame of audio data . In a preferred embodiment of the invention, audio data  is compressed, although it should be appreciated that an audio packet may contain uncompressed audio. Header  comprises fields for audio packet type , message number , and sequence number .","The audio packet \u201ctype\u201d contained in field  indicates the packet type from among several types of packets. Preferably the packet type is one of the following:\n\n","Message number  indicates which \u201cmessage\u201d an audio packet is a part of. Messages may be delimited in various ways. In the case where the audio data to be transmitted over a network is speech, a message may, for example, be defined as a single sequence of unbroken speech: the current message ends when the speaker pauses, and a new message begins when the speaker resumes speaking. (When messages are delimited by pauses, one optimization that may reduce the number of messages transmitted is to allow a message to contain a pre-determined number of pauses, or to require that a pause be a minimum duration\u2014e.g., one second, although the optimal duration depends on the type of compression used.) Each delimited message is assigned a message number, typically in a sequence where the first message is number zero. A message may be transmitted in more than one packet; each packet  that contains audio data from a given message includes that message's number in message number field .","Sequence number  indicates a packet's position in the sequence of packets used to transmit a message. Each packet in a message is assigned a sequence number, which is included in header  of audio packet . Thus, when a message is transmitted using more than one packet, sequence number  can be used to reconstruct a voice message from its component packets. Sequence numbers preferably start at zero for the first packet in a voice message and increment by one for each subsequent packet. Sequence numbers may \u201cwrap\u201d after a certain value has been reached.","Audio data may be lost, received out of order or duplicate packets may be received. The data in packet header  (e.g., message number  and sequence number ) allows a voice engine to handle all of these cases.","General Messages","A protocol for an audio layer may include a miscellaneous set of messages, as described below. These messages support various \u201chousekeeping\u201d tasks in the functioning of the audio layer:\n\n","As previously described, every session has a host. When a host leaves the session, another node in the session must become the host. Host migration is the process by which another node becomes the host when the host leaves the session. The host migration technique provided by the invention uses a \u201chost election algorithm.\u201d The host election algorithm deterministically identifies a host based on which nodes are in a session. The premise of using a host election algorithm is that every node in a session uses the same algorithm, and thus each node in the session, acting independently, can identify the same host by running the host election algorithm.",{"@attributes":{"id":"p-0086","num":"0091"},"figref":"FIG. 16","b":["1602","1604"]},"In response to receiving the message sent at step , each of the remaining clients runs the host election algorithm (step ). As noted above, since each client uses the same host election algorithm, each client will independently identify the same node as the new host. In one example, each node is assigned a \u201chost order ID\u201d at the time the node joins the session. Such a host order ID is a sequence number that indicates the node's order of preference to become the host. Thus, the host election algorithm may be to use the node having the lowest host order ID among all of the nodes that remain in the session. It will be understood, however, that using a host order ID in this manner is merely exemplary, and any host election algorithm that deterministically identifies the host may be used without departing from the spirit and scope of the invention.","At step , the node that has been identified as the new host by the host election algorithm sends the other remaining nodes a message indicating that it is ready to take over as the new host. At step , the remaining non-host nodes send the host a message in order to confirm their presence.",{"@attributes":{"id":"p-0089","num":"0094"},"figref":["FIGS. 16A-16D","FIG. 16A"],"b":["1652","1654","1656","1658","1652","1652","1652","1652","1654","1656","1658"]},"In , host  is disconnected from the session, and nodes , , and  run the host election algorithm. The host election algorithm selects the new host, e.g., by selecting the remaining node with the lowest host order ID. The new host discovers that it is the new host by running this algorithm. In the example of , node  is the newly-elected host.","In , new host  has initialized itself as host, and sends a message (\u201cHOSTMIGRATED\u201d) to the remaining non-host nodes  and  to indicate that it is ready to be the new host.","In , the clients have received the HOSTMIGRATED message and respond with a SETTINGSCONFIRM message. The SETTINGSCONFIRM message is similar to the SETTINGSCONFIRM message discussed above and shown in  in relation to the connection process. However, where the SETTINGSCONFIRM message is issued during host migration by a client who is already in the session, the client's SETTINGSCONFIRM message includes the client's host order ID, which indicates to the new host that the new host should not assign a new host order ID to the existing client node. The host then runs the portion of the connection process that begins as step  (shown in FIG. )\u2014i.e., by issuing PLAYERJOIN and NAMETABLE messages. If a client is connecting during a host migration process, the new client re-sends its SETTINGSCONFIRM message to the newly elected host; this allows a client to connect even if the host changes during the connection. Any new clients who connect after a host migration are given a host order ID that is offset by the client's host order ID when it was elected. The purpose of using an \u201coffset\u201d value is to ensure that newly-added session members are always assigned higher host order IDs than nodes that are already in the session. Thus, the \u201coffset\u201d from the current host's host order ID is chosen to be large enough so that it is unlikely that a newly assigned host order ID will be lower than any existing host order ID in the session.","Communication Between Session\/Transport Layer and Audio Layer",{"@attributes":{"id":"p-0093","num":"0098"},"figref":"FIG. 17"},"Audio layer includes a protocol engine , one or more data queues , and a name table . Protocol engine  contains the functionality to engage in the various aspects of the \u201cprotocol for an audio layer,\u201d as described above. For example, protocol engine  generates and receives the various messages related to connection, disconnection, host migration, etc. Data (e.g., audio data captured with a microphone) is provided to protocol engine  for delivery to other nodes in an audio session. Name table  includes a list of members of an audio session, as described above in connection with . Data queue(s)  buffer data received from other nodes, so that such data may be rendered over a sound rendering system. Audio layer exposes an API , which in the example of  is named \u201cIDirectPlayVoiceNotify.\u201d API  is called by transport layer to communicate events (e.g., the arrival of data) to audio layer ","Session\/transport layer is a data transport which is used by audio layer to send and receive audio data and audio session data, as described above. Session\/transport layer exposes an API , which in the example of  is named \u201cIDirectPlayVoiceTransport.\u201d Audio layer uses session\/transport layer by calling API . For example, Audio layer may call a method in API  in order to provide session\/transport layer with a frame of audio data to be sent to another node.","The IDirectPlayVoiceNotify interface (e.g., API ) implemented by audio layer contains methods to allow session\/transport layer to inform audio layer when important transport level events occur. The types of events that can be generated are described below:\n\n","When these events occur data transport layer calls into audio layer through the IDirectPlayVoiceNotify::NotifyEvent function. Audio layer then handles the event and returns.","Additionally, the IDirectPlayVoiceNotify interface is used to inform audio layer that data has arrived that it is audio-layer specific. The session\/transport layer strips any transport specific headers\/footers from the audio data before giving it to audio layer . This result is that audio layer does not have to perform any additional processing to determine the contents of a data packet. The DirectPlayVoice API (described below in Appendix A) provides an implementation of the specified interface.","The IDirectPlayVoiceTransport API (e.g., API ) preferably provides the following functions to the voice engine:\n\n","To support this interface (i.e., API ), session\/transport layer preferably meets the following requirements:\n\n","If these requirements are met then the session\/transport layer can implement the IDirectPlayVoiceTransport interface and the audio layer will run on the transport. The DirectPlayVoice API (described below in Appendix A) supports this interface.","In order to start using the interfaces, the audio layer and transport layer must be linked. To perform the link the audio layer must first be given a pointer to the transport layer interface. Give the pointer, the audio layer queries the transport layer , preferably using COM to retrieve the transport layer's IDirectPlayVoiceTransport interface. It then calls the IDirectPlayVoiceTransport::Advise method, which passes transport layer a pointer to audio layer . The transport layer then queries the audio layer , using COM to retrieve the audio layer's IDirectPlayVoiceNotify interface. Once this process is complete the two layers are linked and communication can begin. When the audio layer wishes to disconnect from the transport layer , it uses the IDirectPlayVoiceTransport::UnAdvise method.","The combination of the above two interfaces address provides the following features:\n\n","It is noted that the foregoing examples have been provided merely for the purpose of explanation and are in no way to be construed as limiting of the present invention. While the invention has been described with reference to various embodiments, it is understood that the words which have been used herein are words of description and illustration, rather than words of limitations. Further, although the invention has been described herein with reference to particular means, materials and embodiments, the invention is not intended to be limited to the particulars disclosed herein; rather, the invention extends to all functionally equivalent structures, methods and uses, such as are within the scope of the appended claims. Those skilled in the art, having the benefit of the teachings of this specification, may effect numerous modifications thereto and changes may be made without departing from the scope and spirit of the invention in its aspects.","The following is an exemplary Application Programmer Interface (API) for a voice engine as described above. For example, the voice engine may be layer  of network  in , which uses data transport layer  to transport the audio data that is generates. The voice engine may expose the following exemplary API in order to allow applications to use the voice engine. The API includes various functions, structures, and constants. It will be understood that these functions, structures, and constants are merely exemplary; any combination or subset of these components (or equivalent components) is included within the spirit and scope of the invention.","IDirectPlayVoiceClient","Applications use the methods of the IDirectPlayVoiceClient interface to manage clients in a voice session.","The methods of the IDirectPlayVoiceClient interface can be organized into the following groups.",{"@attributes":{"id":"p-0108","num":"0143"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Buffer management","Create3DsoundBuffer"]},{"entry":[{},{},"Delete3DsoundBuffer"]},{"entry":[{},"Miscellaneous","GetCaps"]},{"entry":[{},{},"GetCompressionTypes"]},{"entry":[{},{},"GetSoundDeviceConfig"]},{"entry":[{},{},"SetNotifyMask"]},{"entry":[{},"Session management","Connect"]},{"entry":[{},{},"Disconnect"]},{"entry":[{},{},"GetClientConfig"]},{"entry":[{},{},"GetSessionDesc"]},{"entry":[{},{},"GetTransmitTargets"]},{"entry":[{},{},"Initialize"]},{"entry":[{},{},"SetClientConfig"]},{"entry":[{},{},"SetTransmitTargets"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}},"br":[{},{},{}],"ul":{"@attributes":{"id":"ul0014","list-style":"none"},"li":{"@attributes":{"id":"ul0014-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0015","list-style":"none"},"li":["PDVSOUNDDEVICECONFIG pSoundDeviceConfig,","PDVCLIENTCONFIG pdvClientConfig,","DWORD dwFlags\n\n);\n\nParameters\n\npSoundDeviceConfig\n"]}}}},"Pointer to a DVSOUNDDEVICECONFIG structure that describes the sound device configuration.","pdvClientConfig","Pointer to a DVCLIENTCONFIG structure that describes the general configuration of the client.","dwFlags","Flag. You can specify the following flag.","DVFLAGS_SYNC","The method does not return until the operation is completed.","Return Values","If the method is processed synchronously and is successful, it returns DV_OK. By default, this method is run asynchronously and returns DVERR_PENDING. On error, this method will return one of the following values.","DVERR_ALREADYPENDING","DVERR_COMPRESSIONNOTSUPPORTED","DVERR_INCOMPATIBLEVERSION","DVERR_INVALIDBUFFER","DVERR_INVALIDDEVICE","DVERR_INVALIDFLAGS","DVERR_INVALIDOBJECT","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTINITIALIZED","DVERR_OUTOFMEMORY","DVERR_RUNSETUP","DVERR_SENDERROR","DVERR_SOUNDINITFAILURE","DVERR_TIMEOUT","DVERR_TRANSPORTNOPLAYER","DVERR_TRANSPORTNOSESSION","DVERR_CONNECTED","DVERR_NOVOICESESSION","Remarks","You must test the sound devices selected for playback and capture by invoking the setup wizard before connecting the client to the DirectPlay Voice session. On application startup, check the audio configuration by using IDirectPlayVoiceTest::CheckAudioSetup. If this method returns DVERR_RUNSETUP, the sound configuration specified has not been tested. The setup wizard needs to be run only once for any configuration.","If you specify a buffer that is not the right format, the method will return DVERR_INVALIDBUFFER.","If the buffer or a portion of the buffer is locked when DirectPlay Voice attempts to write to it, the method will return DVERR_INVALIDBUFFER, and DirectPlay Voice will disconnect from the session. You will also receive a DVMSGID_SESSIONLOST message. The hResult member of the associated structure will be set to DVERR_LOCKEDBUFFER. Subsequent method calls will return a DVERR_NOTCONNECTED error code.","If full duplex operation is not supported, DirectPlay Voice falls back to half duplex (listen only) mode. To determine if you are in half-duplex mode, call IDirectPlayVoiceClient::GetSoundDeviceConfig after you have completed the connection. If you are in half-duplex mode, the dwFlags member of the DVSOUNDDEVICECONFIG structure will have the DVSOUNDCONFIG_HALFDUPLEX flag set.","Regardless of how the interfaces are obtained, the DirectPlayVoiceClient object maintains a reference, through a call to AddRef, to the IDirectSound and IDirectSoundCapture interfaces it uses until IDirectPlayVoiceClient::Disconnect is called. When Disconnect is called, the DirectPlayVoiceClient object calls Release on both interfaces.","If this method is called synchronously by setting the DVFLAGS_SYNC flag, the DVMSG_CONNECTRESULT message is not sent to the message handler. In this case, the connection result is determined by the return value of this method.","If this method is called asynchronously (by default), calling this method immediately returns a DVERR_PENDING error value and proceeds to process the connection request in the background. The status of the connection is not be known until the DirectPlay Voice client generates a DVMSG_CONNECTRESULT message with the connection result.","Any calls to IDirectPlayVoiceClient::Connect while a connection is pending return DVERR_ALREADYPENDING. Additionally, only one connection can be pending at a time.","A transport session must be started on the specified DirectPlay object before calling this method. A successful call to IDirectPlayVoiceClient::Initialize must be made before calling the Connect method.","IDirectPlayVoiceClient::Create3DSoundBuffer","Retrieves a 3-D sound buffer for a player or group. You can use the methods of the 3-D sound buffer object to change the virtual 3-D position of incoming voice transmissions from the specified group or player.","HRESULT Create3DSoundBuffer(",{"@attributes":{"id":"p-0123","num":"0000"},"ul":{"@attributes":{"id":"ul0016","list-style":"none"},"li":{"@attributes":{"id":"ul0016-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0017","list-style":"none"},"li":["DVID dvID,","LPDIRECTSOUNDBUFFER lpdsSourceBuffer,","DWORD dwPriority,","DWORD dwFlags,","LPDIRECTSOUND3 DBUFFER* lpUserBuffer\n\n);\n\nParameters\n\ndvID\n"]}}}},"Variable of type DVID that specifies the identification of the player or group that the user wants to reserve a buffer for. You can also specify DVID_REMAINING to create a 3-D user buffer for all players or groups that do not have a user buffer. If DVID_REMAINING is specified, the lpdsBufferDesc must be NULL and the dwPriority and dwFlags parameters must be set to 0.","lpdsSourceBuffer","Pointer to an IDirectSoundBuffer interface, which is used to create the Microsoft\u00ae DirectPlay\u00ae Voice main buffer. This can be either NULL or a user-created Microsoft DirectSound\u00ae buffer. If this member is set to NULL, then DirectPlay Voice creates a buffer for you.","dwPriority","Direct pass-through. This value is passed in the dwPriority parameter when the call to IDirectSoundBuffer::Play is made. For more information, see IDirectSoundBuffer8::Play, which is publicly available in the document of Microsoft\u00ae DirectX\u00ae. This parameter must be 0 if lpdsMainBufferDesc is NULL.","dwFlags","Direct pass-through. This value is passed to the dwFlags parameter when the call to IDirectSoundBuffer::Play is made. For more information, see IDirectSoundBuffer8::Play, which is publicly available in the document of Microsoft\u00ae DirectX\u00ae. This parameter must be 0 if lpdsMainBufferDesc is NULL.","lpUserBuffer","Pointer to memory where the reserved buffer is placed.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_ALREADYBUFFERED","DVERR_INVALIDOBJECT","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTALLOWED","DVERR_NOTCONNECTED","DVERR_NOTINITIALIZED","DVERR_OUTOFMEMORY","DVERR_SESSIONLOST","Remarks","If the DirectPlay voice session is a mixing server session, this method fails and returns DVERR_NOTALLOWED.","Although you can access all the member functions of the 3-D sound buffer object, because the DirectPlay voice client uses the buffer to stream incoming audio, do not use the Lock, UnLock, or Play methods of the DirectSound3 DBuffer object.","If the user specifies a buffer, DirectPlay uses that buffer for the player's or group's buffer. User-created buffers have the following restrictions.","The buffer must be 22 kilohertz, 16-bit, Mono format.","The buffer must be at least 1 second in length.","The buffer must have been created with the DSBCAPS_GETCURRENTPOSITION2 and DSBCAPS_CTRL3D flags.","The buffer must not be a primary buffer.","The buffer must not be playing when it is passed to DirectPlay.","If the buffer is not the right format, the method will return DVERR_INVALIDBUFFER.","The buffer must not be locked when you pass it to DirectPlay. When the buffer for the individual user is no longer required or when a player leaves the voice session, it is important to call IDirectPlayVoiceClient::Delete3DSoundBuffer to free up resources.","If the buffer or a portion of the buffer is locked when DirectPlay Voice attempts to write to it, the method will return DVERR_INVALIDBUFFER. If you lock the buffer after the method has returned, you will receive a DVMSGID_SESSIONLOST message. The hResult member of the associated structure will be set to DVERR_LOCKEDBUFFER. Subsequent method calls will return a DVERR_NOTCONNECTED error code.","IDirectPlayVoiceClient::Delete3DSoundBuffer","Returns exclusive control of the 3-D sound buffer object to the Microsoft\u00ae DirectPlay\u00ae voice client object.","HRESULT Delete3DSoundBuffer(",{"@attributes":{"id":"p-0142","num":"0000"},"ul":{"@attributes":{"id":"ul0018","list-style":"none"},"li":{"@attributes":{"id":"ul0018-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0019","list-style":"none"},"li":["DVID dvID","LPDIRECTSOUND3 DBUFFER*lpUserBuffer\n\n);\n\nParameters\n\ndvID\n"]}}}},"DVID of the player or group that the user wants to delete a buffer for.","lpUserBuffer","Pointer to the user buffer to delete. This must be a user buffer obtained through the IDirectPlayVoiceClient::Create3DSoundBuffer method.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_ALREADYBUFFERED","DVERR_INVALIDOBJECT","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTALLOWED","DVERR_NOTBUFFERED","DVERR_NOTCONNECTED","DVERR_NOTINITIALIZED","DVERR_SESSIONLOST","Remarks","If the DirectPlay Voice session is a mixing server session, this method fails and returns DVERR_NOTALLOWED.","IDirectPlayVoiceClient::Disconnect","Disconnects the Microsoft\u00ae DirectPlay\u00ae Voice client from the existing DirectPlay Voice session.","HRESULT Disconnect(",{"@attributes":{"id":"p-0148","num":"0000"},"ul":{"@attributes":{"id":"ul0020","list-style":"none"},"li":{"@attributes":{"id":"ul0020-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0021","list-style":"none"},"li":"DWORD dwFlags\n\n);\n\nParameters\n\ndwFlags\n"}}}},"Flag. You can specify the following flag.","DVFLAGS_SYNC","Do not return until the operation is completed.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_ALREADYPENDING","DVERR_CONNECTABORTING","DVERR_INVALIDFLAGS","DVERR_INVALIDPARAM","DVERR_NOTCONNECTED","DVERR_NOTINITIALIZED","DVERR_PENDING","DVERR_SESSIONLOST","DVERR_TIMEOUT","Remarks","On calling this method, all recording and playback is stopped. If a connection is being processed, it is canceled by this call.","Unless the DVFLAGS_SYNC is specified, calling this method immediately returns a DVERR_PENDING error value and proceeds to process the disconnection request in the background. The status of the disconnection is not known until the DirectPlay Voice client generates a DVMSG_DISCONNECTRESULT message that contains the disconnection result. Only one disconnection can be pending at a time. If you call IDirectPlayVoiceClient::Disconnect while a disconnect is pending, DirectPlay will return a DVERR_ALREADYPENDING error value.","If this method is called synchronously by setting the DVFLAGS_SYNC flag, the method does not return until the Disconnect method completes. The result of the disconnection is the return value from this method. No DVMSGID_DISCONNECTRESULT message is generated.","IDirectPlayVoiceClient::GetCaps","Retrieves the Microsoft\u00ae DirectPlay\u00ae Voice capabilities.","HRESULT GetCaps(",{"@attributes":{"id":"p-0154","num":"0000"},"ul":{"@attributes":{"id":"ul0022","list-style":"none"},"li":{"@attributes":{"id":"ul0022-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0023","list-style":"none"},"li":"PDVCAPS pCaps\n\n);\n\nParameters\n\npCaps\n"}}}},"Pointer to the DVCAPS structure that contains the capabilities of the DirectPlayVoiceClient object.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","IDirectPlayVoiceClient::GetClientConfig","Retrieves the client configuration.","HRESULT GetClientConfig(",{"@attributes":{"id":"p-0158","num":"0000"},"ul":{"@attributes":{"id":"ul0024","list-style":"none"},"li":{"@attributes":{"id":"ul0024-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0025","list-style":"none"},"li":"PDVCLIENTCONFIG pClientConfig\n\n);\n\nParameters\n\npClientConfig\n"}}}},"Pointer to a DVCLIENTCONFIG structure that contains the configuration of the local client.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTCONNECTED","DVERR_NOTINITIALIZED","DVERR_SESSIONLOST","Remarks","Before calling this member, you must set the dwSize member of the DVCLIENTCONFIG structure.","You can call this method only after a connection is successfully established with a Microsoft\u00ae DirectPlay\u00ae Voice session.","IDirectPlayVoiceClient::GetCompressionTypes","Retrieves the available compression types on the system.","HRESULT GetCompressionTypes(",{"@attributes":{"id":"p-0164","num":"0000"},"ul":{"@attributes":{"id":"ul0026","list-style":"none"},"li":{"@attributes":{"id":"ul0026-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0027","list-style":"none"},"li":["PVOID pData,","PDWORD pdwDataSize,","PDWORD pdwNumElements,","DWORD dwFlags\n\nParameters\n\npData\n"]}}}},"Pointer to buffer that receives an array of DVCOMPRESSIONINFO structures, one structure for every compression type supported through this object.","pdwDataSize","Pointer to a DWORD that contains the size of the buffer, in bytes, passed in the pData parameter.","pdwNumElements","Pointer to a DWORD where the method writes the number of elements returned in the array of DVCOMPRESSIONINFO structures. This contains the number of structures only if the buffer specified in the pData is large enough to hold the information.","dwFlags","Reserved. Must be 0.","Return Values","Returns DP_OK if successful, or one of the following error values.","DVERR_BUFFERTOOSMALL","DVERR_INVALIDFLAGS","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","Remarks","If the buffer passed is not large enough to store the list of compression types, the method returns DVERR_BUFFERTOOSMALL and the pdwDataSize parameter is set to the minimum required size.","IDirectPlayVoiceClient::GetSessionDesc","Retrieves the session properties.","HIRESULT GetSessionDesc(",{"@attributes":{"id":"p-0172","num":"0000"},"ul":{"@attributes":{"id":"ul0028","list-style":"none"},"li":{"@attributes":{"id":"ul0028-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0029","list-style":"none"},"li":"PDVSESSIONDESC pvSessionDesc\n\n);\n\nParameters\n\npvSessionDesc\n"}}}},"Pointer to a DVSESSIONDESC structure to receive the session description.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTCONNECTED","DVERR_NOTINITIALIZED","DVERR_SESSIONLOST","Remarks","Before calling this method, make sure to set the dwSize member of the DVSESSIONDESC structure.","This method may be called only after a connection is successfully established with a Microsoft\u00ae DirectPlay\u00ae Voice session.","IDirectPlayVoiceClient::GetSoundDeviceConfig","Retrieves the sound device configuration of the session.","HRESULT GetSoundDeviceConfig(",{"@attributes":{"id":"p-0178","num":"0000"},"ul":{"@attributes":{"id":"ul0030","list-style":"none"},"li":{"@attributes":{"id":"ul0030-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0031","list-style":"none"},"li":["PDVSOUNDDEVICECONFIG pSoundDeviceConfig,","PDWORD pdwSize\n\n);\n\nParameters\n\npSoundDeviceConfig\n"]}}}},"Pointer to a DVSOUNDDEVICECONFIG structure that is filled with the configuration of the sound device.","pdwSize","Pointer to a DWORD that specifies the size of the buffer in pSoundDeviceConfig parameter. If the buffer is too small, the method returns DVERR_BUFFERTOOSMALL and this parameter contains the size of the required buffer.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTCONNECTED","DVERR_NOTINITIALIZED","DVERR_SESSIONLOST","Remarks","You can call this method only after a connection is successfully established with a Microsoft\u00ae DirectPlay\u00ae Voice session.","IDirectPlayVoiceClient::GetTransmitTargets","Retrieves the transmit targets, if any, of the voice stream from this client.","HRESULT GetTransmitTargets(",{"@attributes":{"id":"p-0184","num":"0000"},"ul":{"@attributes":{"id":"ul0032","list-style":"none"},"li":{"@attributes":{"id":"ul0032-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0033","list-style":"none"},"li":["PDVID pdvIDTargets,","PDWORD pdwNumTargets,","DWORD dwFlags\n\n);\n\nParameters\n\npdvIDTargets\n"]}}}},"Member to fill with an array of DVIDs that specify the targets that were set by the IDirectPlayVoiceClient::SetTransmitTargets or IDirectPlayVoiceServer::SetTransmitTargets method. You can retrieve the number of targets by specifying NULL for this parameter.","pdwNumTargets","Number of DVIDs in the array. When you call this method, this should be the same value as the number of targets set in the IDirectPlayVoiceClient::SetTransmitTargets method. If the call is successful, Microsoft\u00ae DirectPlay\u00ae returns the number of elements written to the pdvIDTargets array.","If pdvIDTargets is NULL, this must be 0.","dwFlags","Reserved. Must be 0.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_BUFFERTOOSMALL","DVERR_INVALIDFLAGS","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTALLOWED","DVERR_NOTCONNECTED","DVERR_NOTINITIALIZED","Remarks","The value returned in the pdvIDTargets parameter can be player or group DVIDs or the DVID_ALLPLAYERS constant.","If the buffer specified in pdvIDTargets is not large enough to store the list of targets, this method returns DVERR_INVALIDPOINTER and pdwNumTargets is set to the required number of elements.","If there is no target specified, pdwNumTargets is set to 0 and the return value is DV_OK.","IDirectPlayVoiceClient::Initialize","Initializes the DirectPlayVoiceClient object by associating it with a DirectPlay object. Additionally, this method registers a message handler with the DirectPlayVoiceClient object.","This method must be called successfully before IDirectPlayVoiceClient::Connect method is called.","HRESULT Initialize(",{"@attributes":{"id":"p-0194","num":"0000"},"ul":{"@attributes":{"id":"ul0034","list-style":"none"},"li":{"@attributes":{"id":"ul0034-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0035","list-style":"none"},"li":["PVOID pVoid,","PDVMESSAGEHANDLER pMessageHandler,","PVOID pUserContext,","PDWORD pdwMessageMask,","DWORD dwMessageMaskElements\n\n);\n\nParameters\n\npVoid\n"]}}}},"Pointer to the IUnknown interface for the DirectPlay object that this DirectPlayVoiceClient object should use.","pMessageHandler","User-defined callback function that is called when there is a DirectPlayVoiceClient message to be processed. Threads within the DirectPlayVoiceClient object call the callback function, so it will not be called in the context of your process's main thread.","pUserContext","Pointer to an application-defined structure that is passed to the callback function each time the function is called.","pdwMessageMask","Array of DWORDs that contain the message identifiers that you want DirectPlay Voice to send to your callback function. If a message identifier is not specified in this array, it is not sent. Each message identifier should appear only once in the array and only valid message identifiers are allowed. For example, DVMSGID_CONNECTRESULT is not valid for the server interface, but is for the client interface. To enable all messages, specify NULL for this value.","dwMessageMaskElements","Number of elements specified in the pdwMessageMask parameter. If pdwMessageMask is NULL, this must be 0.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_ALREADYINITIALIZED","DVERR_GENERIC","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOCALLBACK DVERR_TRANSPORTNOTINIT","Remarks","You can call IDirectPlayVoiceClient::SetNotifyMask to change the notify mask during the course of the voice session.","IDirectPlayVoiceClient::SetClientConfig","Sets the client configuration.","HRESULT SetClientConfig(",{"@attributes":{"id":"p-0203","num":"0000"},"ul":{"@attributes":{"id":"ul0036","list-style":"none"},"li":{"@attributes":{"id":"ul0036-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0037","list-style":"none"},"li":"PDVCLIENTCONFIG pClientConfig\n\n);\n\nParameters\n\npClientConfig\n"}}}},"Pointer to the DVCLIENTCONFIG structure that contains the configuration description to set.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDFLAGS","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTCONNECTED","DVERR_NOTINITIALIZED","DVERR_SESSIONLOST","Remarks","You can call this method only after a connection is successfully established with a Microsoft\u00ae DirectPlay\u00ae Voice session.","Calling this method sets all the parameters in the DVCLIENTCONFIG structure. Therefore, to leave a setting unmodified, you must retrieve the current configuration with IDirectPlayVoiceClient::GetClientConfig. Then modify the parameters to change and call IDirectPlayVoiceClient::SetClientConfig.","If the session is running in half duplex, the members of GetClientConfig related to recording are ignored.","IDirectPlayVoiceClient::SetNotifyMask","Specifies which messages are sent to the message handler.","HRESULT SetNotifyMask(",{"@attributes":{"id":"p-0210","num":"0000"},"ul":{"@attributes":{"id":"ul0038","list-style":"none"},"li":{"@attributes":{"id":"ul0038-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0039","list-style":"none"},"li":["PDWORD pdwMessageMask,","DWORD dwMessageMaskElements\n\n);\n\nParameters\n\npdwMessageMask\n"]}}}},"Pointer to an array of DWORDs containing the message identifiers that you want Microsoft\u00ae DirectPlay\u00ae Voice to send to your callback function. If a message identifier is not specified in this array, it is not sent. Each message identifier should appear only once in the array, and only valid message identifiers are allowed. For example, DVMSGID_CONNECTRESULT is not valid for the server interface, but is for the client interface. To enable all messages, specify NULL for this value.","dwMessageMaskElements","Number of elements specified in the pdwMessageMask parameter. If pdwMessageMask is NULL, this must be 0.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOCALLBACK","DVERR_NOTINITIALIZED","IDirectPlayVoiceClient::SetTransmitTargets","Specifies which players and\/or groups receive audio transmissions from the local client.","HRESULT SetTransmitTargets(",{"@attributes":{"id":"p-0215","num":"0000"},"ul":{"@attributes":{"id":"ul0040","list-style":"none"},"li":{"@attributes":{"id":"ul0040-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0041","list-style":"none"},"li":["PDVID pdvID Targets,","DWORD dwNumTargets,","DWORD dwflags\n\n);\n\nParameters\n\npdvID Targets\n"]}}}},"Pointer an array of DVIDs that specify your targets. To specify no targets, pass NULL for this parameter. Additionally, this parameter can be set to the following value.","DVID_ALLPLAYERS","The client is targeting all players in the session. This must be the only element in the array.","dwNumTargets","Number of DVIDs in the array. This value cannot exceed 64. If pdvIDTargets is NULL, this must be 0.","dwflags","Reserved. Must be 0.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDFLAGS","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_INVALIDTARGET","DVERR_NOTINITIALIZED","Remarks","For Microsoft\u00ae DirectX\u00ae 8.0, the number of individual targets that you can transmit to is limited to 64. If you exceed this value, the method will fail, and return DVERR_NOTALLOWED. However, you can transmit to more than 64 players. To do so, form the players into groups, and then use the group as your target.","The pdvIDTargets parameter specifies an array of player and\/or group DVIDs. There must be no duplicate targets in this parameter, and all entries must be valid DVIDs. If a target contains a player as its individual DVID and through a group that the target belongs to, Microsoft\u00ae DirectPlay\u00ae Voice ensures duplicate speech packets are not sent to the player.","If the session was created with the DVSESSION_SERVERCONTROLTARGET flag, only the server can set the targets for this local client. A call to this method returns DVERR_NOTALLOWED.","IDirectPlayVoiceServer","Applications use the methods of the IDirectPlayVoiceServer interface to manage the host of the voice session.","The methods of the IDirectPlayVoiceServer interface can be organized into the following groups.",{"@attributes":{"id":"p-0226","num":"0282"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Miscellaneous","GetCaps"]},{"entry":[{},{},"GetCompressionTypes"]},{"entry":[{},{},"SetNotifyMask"]},{"entry":[{},"Session management","GetSessionDesc"]},{"entry":[{},{},"GetTransmitTargets"]},{"entry":[{},{},"Initialize"]},{"entry":[{},{},"SetSessionDesc"]},{"entry":[{},{},"SetTransmitTargets"]},{"entry":[{},{},"StartSession"]},{"entry":[{},{},"StopSession"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"Retrieves the capabilities of the Microsoft\u00ae DirectPlay\u00ae Voice server for this system.","HRESULT GetCaps(","PDVCAPS pDVCaps",");","Parameters","pDVCaps","Pointer to the DVCAPS structure that contains the capabilities of the DirectPlayVoiceServer object.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDOBJECT","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","IDirectPlayVoiceServer::GetCompressionTypes","Retrieves available compression types for the system.","HRESULT GetCompressionTypes(",{"@attributes":{"id":"p-0231","num":"0000"},"ul":{"@attributes":{"id":"ul0042","list-style":"none"},"li":{"@attributes":{"id":"ul0042-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0043","list-style":"none"},"li":["PVOID pData,","PDWORD pdwDataSize,","PDWORD pdwNumElements,","DWORD dwFlags\n\n);\n\nParameters\n\npData\n"]}}}},"Pointer to the buffer that receives an array of DVCOMPRESSIONINFO structures that describe the compression types supported by this object.","pdwDataSize","Pointer to a DWORD that contains the size of the buffer, in bytes, passed in the pData parameter.","pdwNumElements","Pointer to a DWORD where the method writes the number of elements returned in the array of DVCOMPRESSIONINFO structures.","dwFlags","Reserved. Must be 0.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_BUFFERTOOSMALL","DVERR_INVALIDFLAGS","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","Remarks","If the buffer is not large enough to store the list of compression types, the method returns DVERR_BUFFERTOOSMALL and the pdwDataSize parameter is set to the minimum required size.","IDirectPlayVoiceServer::GetSessionDesc","Retrieves the Microsoft\u00ae DirectPlay\u00ae Voice session settings.\n\n","Pointer to a DVSESSIONDESC structure to receive the session description.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDOBJECT","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTHOSTING","DVERR_NOTINITIALIZED","DVERR_SESSIONLOST","Remarks","Before calling this method, make sure to set the dwSize member of the DVSESSIONDESC structure.","A successful call to IDirectPlayVoiceServer::StartSession must be made before this method can be called.","IDirectPlayVoiceServer::GetTransmitTargets","Retrieves the transmit targets, if any, of the voice stream for a player in a session.","RESULT GetTransmitTargets(",{"@attributes":{"id":"p-0244","num":"0000"},"ul":{"@attributes":{"id":"ul0046","list-style":"none"},"li":{"@attributes":{"id":"ul0046-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0047","list-style":"none"},"li":["DVID dvSource,","PDVID pdvIDTargets,","PDWORD pdwNumTargets,","DWORD dwflags\n\n);\n\nParameters\n\ndvSource\n"]}}}},"DVID of the user or group whose target is returned.","pdvIDTargets","Array of DVIDs that specify the current targets of the player or group that were set by the IDirectPlayVoiceServer::SetTransmitTargets method. You can retrieve the number of targets by specifying NULL for this parameter.","pdwNumTargets","Number of DVIDs in the array. When you call this method, this should be the same value as the number of targets set in the IDirectPlayVoiceServer::SetTransmitTargets method. If the call is successful, Microsoft\u00ae DirectPlay\u00ae returns the number of elements in the pdvIDTargets array.","If pdvIDTargets is NULL, this must be 0.","dwFlags","Reserved. Must be 0.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_BUFFERTOOSMALL","DVERR_INVALIDFLAGS","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTALLOWED","DVERR_NOTCONNECTED","DVERR_NOTINITIALIZED","Remarks","This method can be used only if the DVSESSION_SERVERCONTROLTARGET flag is specified on creation of the DirectPlay Voice session. If the flag is not specified, this method returns DVERR_NOTALLOWED.","IDirectPlayVoiceServer::Initialize","Initializes the DirectPlayVoiceServer object by associating it with a DirectPlay object. Additionally, this method registers a message handler with this interface.","RESULT Initialize(",{"@attributes":{"id":"p-0253","num":"0000"},"ul":{"@attributes":{"id":"ul0048","list-style":"none"},"li":{"@attributes":{"id":"ul0048-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0049","list-style":"none"},"li":["LPVOID lpVoid,","PDVMESSAGEHANDLER pMessageHandler,","PVOID pUserContext,","LPDWORD lpdwMessageMask,","DWORD dwMessageMaskElements\n\n);\n\nParameters\n\nlpVoid\n"]}}}},"Pointer to the IUnknown interface for the DirectPlay object that this DirectPlayVoiceServer object should use.","pMessageHandler","User-defined callback function that is called when there is a DirectPlayVoiceClient message to process. A thread within the DirectPlayVoiceClient object calls the callback function, so it is not called in the context of your process's main thread.","pUserContext","Pointer to an application-defined structure that is passed to the callback function each time the method is called.","lpdwMessageMask","Array of DWORDs that contain the message identifiers that you want DirectPlay Voice to send to your callback function. If a message identifier is not specified in this array, it is not sent. Each message identifier should appear only once in the array, and only valid message identifiers are allowed. For example, DVMSGID_CONNECTRESULT is not valid for the server interface but is for the client interface. To enable all messages, specify NULL for this value.","dwMessageMaskElements","Number of elements specified in the lpdwMessageMask parameter. If lpdwMessageMask is NULL, this must be 0.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_ALREADYINITIALIZED","DVERR_GENERIC","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOCALLBACK","DVERR_TRANSPORTNOTINIT","Remarks","You can call IDirectPlayVoiceServer::SetNotifyMask to change the notify mask during the course of the voice session.","IDirectPlayVoiceServer::SetNotffyMask","Specifies which messages are sent to the message handler.","HRESULT SetNotifyMask(",{"@attributes":{"id":"p-0261","num":"0000"},"ul":{"@attributes":{"id":"ul0050","list-style":"none"},"li":{"@attributes":{"id":"ul0050-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0051","list-style":"none"},"li":["PDWORD pdwMessageMask,","DWORD dwMessageMaskElements\n\n);\n\nParameters\n\npdwMessageMask\n"]}}}},"Pointer to an array of DWORDs that contain the message identifiers that you want Microsoft\u00ae DirectPlay\u00ae Voice to send to your callback function. If a message identifier is not specified in this array, it is not sent. Each message identifier should appear only once in the array, and only valid message identifiers are allowed. For example, DVMSGID_CONNECTRESULT is not valid for the server interface but is for the client interface. To enable all messages, specify NULL for this value.","dwMessageMaskElements","Number of elements specified in the pdwMessageMask parameter. If pdwMessageMask is NULL, this must be 0.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOCALLBACK","DVERR_NOTINITIALIZED","IDirectPlayVoiceServer::SetSessionDesc","Sets the session settings.","HRESULT SetSessionDesc(\n\n","Pointer to a DVSESSIONDESC structure that contains the session description.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDOBJECT","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTHOSTING","DVERR_NOTINITIALIZED","DVERR_SESSIONLOST","Remarks","After the Microsoft\u00ae DirectPlay\u00ae voice session has started, not all the session properties of the DVSESSIONDESC structure can be changed. For more information, see DVSESSIONDESC.","IDirectPlayVoiceServer::SetTransmitTargets","Controls the transmission of audio from the client to the specified members of the session.","HRESULT SetTransmitTargets(",{"@attributes":{"id":"p-0271","num":"0000"},"ul":{"@attributes":{"id":"ul0054","list-style":"none"},"li":{"@attributes":{"id":"ul0054-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0055","list-style":"none"},"li":["DVID dvSource,","PDVID pdvID Targets,","DWORD dwNumTargets,","DWORD dwFlags\n\n);\n\nParameters\n\ndvSource\n"]}}}},"DVID of the user whose targets are set.","pdvIDTargets","List of player DVIDs and\/or group DVIDs that are the target for audio transmission. To specify no targets, pass NULL for this parameter. Additionally, this parameter can be set to the following value.","DVID_ALLPLAYERS","This client is targeting all players in the session. This must be the only element in the array.","dwNumTargets","Number of DVIDs in the array. This value cannot exceed 64. If pdvIDTargets is NULL this must be 0.","dwFlags","Reserved. Must be 0.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_INVALIDFLAGS","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_INVALIDTARGET","DVERR_NOTALLOWED","DVERR_NOTINITIALIZED","Remarks","For Microsoft\u00ae DirectX\u00ae 8.0, the number of individual targets that you can transmit to is limited to 64. If you exceed this value, the method will fail, and return DVERR_NOTALLOWED. However, you can transmit to more than 64 players. To do so, form the players into groups, and then use the group as your target.","There must be no duplicate targets in this parameter, and all entries must be valid DVIDs. If a target contains a player as its individual DVID and through a group that the target belongs to, Microsoft\u00ae DirectPlay\u00ae Voice ensures duplicate speech packets are not sent to the player.","This method can be used only if the DVSESSION_SERVERCONTROLTARGET flag is specified on creation of the DirectPlay Voice session. If the flag is not specified, this method returns DVERR_NOTALLOWED.","IDirectPlayVoiceServer::StartSession","Starts an initialized Microsoft\u00ae DirectPlay\u00ae Voice session within a running DirectPlay transport session. This method must be successfully called before the clients can complete a connection-to-the-voice session.","HRESULT StartSession(",{"@attributes":{"id":"p-0282","num":"0000"},"ul":{"@attributes":{"id":"ul0056","list-style":"none"},"li":{"@attributes":{"id":"ul0056-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0057","list-style":"none"},"li":["PDVSESSIONDESC pSessionDesc,","DWORD dwFlags\n\n);\n\nParameters\n\npSessionDesc\n"]}}}},"Pointer to a DVSESSIONDESC structure that contains the session description.","dwflags","Reserved. Must be 0.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_ALREADYPENDING","DVERR_HOSTING","DVERR_INVALIDFLAGS","DVERR_INVALIDOBJECT","DVERR_INVALIDPARAM","DVERR_INVALIDPOINTER","DVERR_NOTINITIALIZED","Remarks","The IDirectPlayVoiceServer::Initialize method must be called before this method is called. The voice session can be hosted on any client in the session if the voice session is peer-to-peer. If the voice session is not peer-to-peer, it must be hosted on the transport client, which is the host of a active transport session.","The DVSESSIONDESC structure contains the type of voice session to start. The type of voice session can have a dramatic effect on the CPU and bandwidth usage for both the client and the server. You can set the guidCT member of DVSESSIONDESC to DPVCTGUID_DEFAULT.","IDirectPlayVoiceServer::StopSession","Stops the Microsoft\u00ae DirectPlay\u00ae Voice session.","HRESULT StopSession(",{"@attributes":{"id":"p-0289","num":"0000"},"ul":{"@attributes":{"id":"ul0058","list-style":"none"},"li":{"@attributes":{"id":"ul0058-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0059","list-style":"none"},"li":"DWORD dwFlags\n\n);\n\nParameters\n\ndwFlags\n"}}}},"Flag. The following flag can be set.","DVFLAGS_NOHOSTMIGRATE","The host will not migrate regardless of session and transport settings. Use this flag when you want to shut down the voice session completely.","Return Values","Returns DV_OK if successful, or one of the following error values.","DVERR_ALREADYPENDING","DVERR_INVALIDFLAGS","DVERR_INVALIDOBJECT","DVERR_INVALIDPARAM","DVERR_NOTHOSTING","DVERR_NOTINITIALIZED","DVERR_SESSIONLOST","Remarks","This method returns DVERR_ALREADYPENDING if it is called while another thread is processing a StopSession request.","IDirectPlayVoiceTest","Applications use the CheckAudioSetup method of the IDirectPlayVoiceTest interface to test the Microsoft\u00ae DirectPlay\u00ae Voice audio configuration.","Audio Configuration CheckAudioSetup","IDirectPlayVoiceTest::CheckAudioSetup","Runs the Audio Setup Wizard on the specified devices. This wizard runs a series of tests on the devices to determine if they are capable of full duplex audio and to ensure that the microphone is plugged in and working correctly on the capture device.","HRESULT CheckAudioSetup(",{"@attributes":{"id":"p-0296","num":"0000"},"ul":{"@attributes":{"id":"ul0060","list-style":"none"},"li":{"@attributes":{"id":"ul0060-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0061","list-style":"none"},"li":["const GUID * pguidPlaybackDevice,","const GUID * pguidCaptureDevice,","HWND hwndParent,","DWORD dwFlags\n\n);\n\nParameters\n\npguidPlaybackDevice\n"]}}}},"Pointer to the GUID that identifies the playback device to test. If NULL is passed for this parameter, Microsoft\u00ae DirectPlay\u00ae Voice tests the system default playback device defined by Microsoft\u00ae DirectSound\u00ae. You can also pass one of the DirectSound\u00ae default GUIDs:","DSDEVID_DefaultPlayback","The system default playback device.","DSDEVID_DefaultVoicePlayback","The default voice playback device.","pguidCaptureDevice","Pointer to the GUID that identifies the capture device to test. If NULL is passed for this parameter, DirectPlay Voice tests the system default capture device defined by DirectSound\u00ae. You can also pass one of the DirectSound default GUIDs: DSDEVID_DefaultCapture","The default system capture device. You can also specify this device by passing a NULL pointer in the device GUID parameter.","DSDEVID_DefaultVoiceCapture","The default voice communications capture device. Typically, this is a secondary device such as a USB headset with microphone.","hwndParent","The test wizard invoked by this method is modal. If the calling application has a window that should be the parent window of the wizard, it should pass a handle to that window in this parameter. If the calling application does not have a window, it can pass NULL. If the DVFLAGS_QUERYONLY flag is specified, this parameter is not used and the application can pass NULL.","dwFlags","Flags. The following flags can be set.","DVFLAGS_QUERYONLY","Audio setup is not run. Instead, the method checks the registry to see if the devices have been tested. If the devices have not been tested, the method returns DVERR_RUNSETUP. If the devices have been tested, the method returns DV_FULLDUPLEX if the devices support full duplex audio, or DV_HALFDUPLEX if the devices do not support full duplex audio.","DVFLAGS_ALLOWBACK","Passing this flag enables the Back button on the wizard's Welcome page. If the user clicks the Back button on the Welcome page, the wizard exits, and CheckAudioSetup returns DVERR_USERBACK.","Return Values","Returns DV_OK, DV_FULLDUPLEX, DV_HALFDUPLEX if successful, or one of the following error values.","DVERR_INVALIDPARAM","DVERR_RUNSETUP","DVERR_INVALIDDEVICE","Remarks","This method contains user interface (UI) elements and displays dialog boxes. If the DVFLAGS_QUERYONLY flag is specified, the tests are not actually run and no UI is raised. Instead, the registry is checked to determine the results of a previous test of these devices.","If the user cancels the wizard, the CheckAudioSetup call returns DVERR_USERCANCEL. The calling application can then handle the situation appropriately. For example, in DirectPlay Voice part of the gaming options control panel application, if the user clicks Cancel, the dialog box displays a message indicating that voice cannot be used because the wizard has been canceled.","This method might return DVERR_INVALIDDEVICE if the device specified does not exist. Also, if you specify the default device and this method still returns this error, then there are no sound devices on the system.","DirectPlay\u00ae Voice Messages","The following messages are handled by Microsoft\u00ae DirectPlay\u00ae voice callback message handlers.","DVMSGID_CONNECTRESULT","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_CONNECTRESULT message when the connect request generated through a call to the IDirectPlayVoiceClient::Connect method has completed. This message is sent only if the Connect method is called asynchronously.","DVMSG_CONNECTRESULT","The DVMSG_CONNECTRESULT structure contains information for the DVMSGID_CONNECTRESULT system message.","typedef struct {",{"@attributes":{"id":"p-0314","num":"0000"},"ul":{"@attributes":{"id":"ul0062","list-style":"none"},"li":{"@attributes":{"id":"ul0062-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0063","list-style":"none"},"li":["DWORD dwSize;","HRESULT hrResult;\n\n} DVMSG_CONNECTRESULT, *LPDVMSG_CONNECTRESULT,\n\n*PDVMSG_CONNECTRESULT;\n\ndwSize\n"]}}}},"Size of the DVMSG_CONNECTRESULT message structure.","hrResult","Result of the connection attempt.","DVMSGID_CREATEVOICEPLAYER","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_CREATEVOICEPLAYER message when a new player joins the voice session.","Upon connecting to a voice session, clients will receive one of these messages for each player in the voice session. These messages are sent only to clients in peer-to-peer voice sessions.","The host receives these messages when players join the voice session.","Players do not join the voice session until they have called IDirectPlayVoiceClient::Connect. Therefore, it is possible for a player to be in the transport session but not part of the voice session.","DVMSG_CREATEVOICEPLAYER","The DVMSG_CREATEVOICEPLAYER structure contains information for the DVMSGID_CREATEVOICEPLAYER system message.","typedef struct {","DWORD dwSize;","DVID dvidplayer;","DWORD dwFlags;","PVOID pvPlayerContext;","} DVMSG_CREATEVOICEPLAYER, *LPDVMSG_CREATEVOICEPLAYER, *PDVMSG_CREATEVOICEPLAYER;","dwSize","Size of the this message structure.","dvidplayer","DVID of the player who connected.","dwFlags","Flag specifying information about the player:","DVPLAYERCAPS_HALFDUPLEX","The specified player is running in half duplex mode. The player will only be able to receive voice, not transmit it.","DVPLAYERCAPS_LOCAL","The player is the local player.","pvPlayerContext","Player context value for the player in the voice session. This value is set through this parameter when this message is received.","DVMSGID_DELETEVOICEPLAYER","For clients, Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_DELETEVOICEPLAYER message when a player quits the voice session. This message is available only to clients in peer-to-peer voice sessions.","For the host, Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_DELETEVOICEPLAYER message when a player quits the voice session.","Players do not leave the voice session until they have called IDirectPlayVoiceClient::Disconnect or they have disconnected from the transport session. Therefore, a client might be part of the transport session but not part of the voice session.","DVMSG_DELETEVOICEPLAYER","The DVMSG_DELETEVOICEPLAYER structure contains information for the DVMSGID_DELETEVOICEPLAYER system message.","typedef struct {","DWORD dwSize;","DVID dvidPlayer;","PVOID pvPlayerContext;","} DVMSG_DELETEVOICEPLAYER, *LPDVMSG_DELETEVOICEPLAYER, *PDVMSG_DELETEVOICEPLAYER;","dwSize","Size of the DVMSG_DELETEVOICEPLAYER message structure.","dvidPlayer","DVID of player who disconnected.","pvPlayerContext","Pointer to the context value set for the player. This value is set through the pvPlayerContext member of the DVMSG_CREATEVOICEPLAYER message structure.","DVMSGID_DISCONNECTRESULT","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_DISCONNECTRESULT message when the disconnect request generated through a call to the IDirectPlayVoiceClient::Disconnect method has completed. This message is sent only if the Disconnect method is called asynchronously.","DVMSG_DISCONNECTRESULT","The DVMSG_DISCONNECTRESULT structure contains information for the DVMSGID_DISCONNECTRESULT system message.","typedef struct {","DWORD dwSize;","HRESULT hrResult;","} DVMSG_DISCONNECTRESULT, *LPDVMSG_DISCONNECTRESULT, *PDVMSG_DISCONNECTRESULT;","dwSize","Size of the DVMSG_DISCONNECTRESULT message structure.","hrResult","Result of the disconnect request.","DVMSGID_GAINFOCUS","The DVMSGID_GAINFOCUS message is sent to notify you that you have begun capturing audio. It is sent when an application that has lost capture focus recovers it. There is no data associated with this message. Refer to the Microsoft\u00ae DirectSound\u00ae documentation for more information on capturing audio.","DVMSGID_HOSTMIGRATED","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_HOSTMIGRATED message when the voice host has changed.","DVMSG_HOSTMIGRATED","The DVMSG_HOSTMIGRATED structure contains information for the DVMSGID_HOSTMIGRATED system message.",{"@attributes":{"id":"p-0351","num":"0429"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"typedef struct {"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"DWORD","dwSize;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"DVID","dvidNewHostID;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"LPDIRECTPLAYVOICESERVER pdvServerInterface;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} DVMSG_HOSTMIGRATED, *LPDVMSG_HOSTMIGRATED,"},{"entry":"*PDVMSG_HOSTMIGRATED;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Size of the DVMSG_HOSTMIGRATED message structure.","dvidNewHostID","DVID of the new host.","pdvServerInterface","If the local client has become the new voice session host, this member will point to a newly created IDirectPlayVoiceServer object that can be used by the local client for providing host services. If the local client is not the new host, then this member will be NULL. If this parameter points to an IDirectPlayVoiceServer interface, you must call IDirectPlayVoiceServer::AddRef to increment the interface's reference count. Call IDirectPlayVoiceServer::Release when you no longer need the interface.","DVMSGID_INPUTLEVEL","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_INPUTLEVEL message periodically to notify the user of the input level from the microphone. The period of notification is set by the dwNotifyPeriod member of the DVCLIENTCONFIG structure. If the notification period is set to 0, this message will not be sent. In addition, if the client is running in half duplex mode, this message is not available.","DVMSG_INPUTLEVEL","The DVMSG_INPUTLEVEL structure contains information for the DVMSGID_INPUTLEVEL system message.","typedef struct {",{"@attributes":{"id":"p-0357","num":"0000"},"ul":{"@attributes":{"id":"ul0064","list-style":"none"},"li":{"@attributes":{"id":"ul0064-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0065","list-style":"none"},"li":["DWORD dwSize;","DWORD dwPeakLevel;","LONG lRecordVolume;","PVOID pvLocalPlayerContext;\n\n} DVMSG_INPUTLEVEL, *LPDVMSG_INPUTLEVEL, *PDVMSG_INPUTLEVEL;\n\ndwSize\n"]}}}},"Size of the DVMSG_INPUTLEVEL message structure.","dwPeakLevel","Integer representing peak level across the current frame, which corresponds to approximately 1\/10 second of audio stream. The current frame typically lags 50-200 ms behind real-time. This value can range from 0 through 99, with 0 being completely silent and 99 being the highest possible input level.","lRecordVolume","Current recording volume for the client. The value can range from 10,000 to 0. This member is available even when automatic gain control is active.","pvLocalPlayerContext","Pointer to the context value set for the local player. This value is set through the pvPlayerContext member of the DVMSG_CREATEVOICEPLAYER message structure.","DVMSGID_LOCALHOSTSETUP","The DVMSGID_LOCALHOSTSETUP message is sent when the local client is elected to become the new voice host during host migration. The message is sent before the DVMSGID_HOSTMIGRATED message and gives you the chance to set the callback function and context value that will be used when creating the new host object. If you do not set either of the values, then the new server interface will have no callback function. Once the application returns from handling this message it will receive the DVMSGID_HOSTMIGRATED message. The new message has the following associated structure, which is passed in the void * field of the message handler.","DVMSG_LOCALHOSTSETUP","The DVMSG_LOCALHOSTSETUP structure contains information for the DVMSGID_LOCALHOSTSETUP system message.","typedef struct {",{"@attributes":{"id":"p-0364","num":"0000"},"ul":{"@attributes":{"id":"ul0066","list-style":"none"},"li":{"@attributes":{"id":"ul0066-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0067","list-style":"none"},"li":["DWORD dwSize;","PVOID pvContext;","PDVMESSAGEHANDLER pMessageHandler;\n\n}DVMSG_LOCALHOSTSETUP, *LPDVMSG_LOCALHOSTSETUP, *PDVMSG_LOCALHOSTSETUP;\n\ndwSize\n"]}}}},"Size of the DVMSG_LOCALHOSTSETUP message structure.","pvContext","Set to the context value you want to set for the new server.","pMessageHandler","Set to the callback function to be used for the new server.","DVMSGID_LOSTFOCUS","The DVMSGID_LOSTFOCUS message is sent to notify you that you have stopped capturing audio. It is sent when an application that has capture focus loses it to another application. There is no data associated with this message. Refer to the Microsoft\u00ae DirectSound\u00ae documentation for more information on capturing audio.","DVMSGID_OUTPUTLEVEL","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_OUTPUTLEVEL message periodically to notify the user of the output level of playback. The period of notification is set by the dwNotifyPeriod member of the DVCLIENTCONFIG structure. If the notification period is set to 0, this message will not be sent.","DVMSG_OUTPUTLEVEL","The DVMSG_OUTPUTLEVEL structure contains information for the DVMSGID_OUTPUTLEVEL system message.","typedef struct {",{"@attributes":{"id":"p-0371","num":"0000"},"ul":{"@attributes":{"id":"ul0068","list-style":"none"},"li":{"@attributes":{"id":"ul0068-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0069","list-style":"none"},"li":["DWORD dwSize;","DWORD dwPeakLevel;","LONG lOutputVolume;","PVOID pvLocalPlayerContext;\n\n} DVMSG_OUTPUTLEVEL, *LPDVMSG_OUTPUTLEVEL, *PDVMSG_OUTPUTLEVEL;\n\ndwSize\n"]}}}},"Size of the DVMSG_OUTPUTLEVEL message structure.","dwPeakLevel","Integer representing the current output level of playback. This value is in the range from 0 through 99, with 0 being completely silent and 99 being the highest possible output level.","IOutputVolume","Current playback volume for the client.","pvLocalPlayerContext","Pointer to the context value set for the local player. This value is set through the pvPlayerContext member of the DVMSG_CREATEVOICEPLAYER message structure.","IDVMSGID_PLAYEROUTPUTLEVEL","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_PLAYEROUTPUTLEVEL message periodically to notify the user of the output level of an individual player's voice stream. It is generated while voice is being played back for an individual player. If multiple player voices are being played, one message for each player speaking will be sent each notification period.","The period of notification is set by the dwNotifyPeriod member of the DVCLIENTCONFIG structure. If the notification period is set to 0, this message will not be sent.","DVMSG_PLAYEROUTPUTLEVEL","The DVMSG_PLAYEROUTPUTLEVEL structure contains information for the DVMSGID_PLAYEROUTPUTLEVEL system message.","typedef struct {",{"@attributes":{"id":"p-0379","num":"0000"},"ul":{"@attributes":{"id":"ul0070","list-style":"none"},"li":{"@attributes":{"id":"ul0070-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0071","list-style":"none"},"li":["DWORD dwSize;","DVID dvidSourcePlayerID;","DWORD dwPeakLevel;","PVOID pvPlayerContext;\n\n} DVMSG_PLAYEROUTPUTLEVEL, *LPDVMSG_PLAYEROUTPUTLEVEL, *PDVMSG_PLAYEROUTPUTLEVEL;\n\ndwSize\n"]}}}},"Size of the DVMSG_PLAYEROUTPUTLEVEL message structure.","dvidSourcePlayerID","DVID of the player whose voice is being played back.","dwPeakLevel","Integer representing the current output level of the player's voice stream. This value is in the range from 0 through 99, with 0 being completely silent and 99 being the highest possible output level.","pvPlayerContext","Pointer to the context value set for the player. This value is set through the pvPlayerContext member of the DVMSG_CREATEVOICEPLAYER message structure.","DVMSGID_PLAYERVOICESTART","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_PLAYERVOICESTART message when an incoming audio stream begins playing back.","DVMSG_PLAYERVOICESTART","The DVMSG_PLAYERVOICESTART structure contains information for the DVMSGID_PLAYERVOICESTART system message.","typedef struct {",{"@attributes":{"id":"p-0386","num":"0000"},"ul":{"@attributes":{"id":"ul0072","list-style":"none"},"li":{"@attributes":{"id":"ul0072-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0073","list-style":"none"},"li":["DWORD dwSize;","DVID dvidSourcePlayerID;","PVOID pvPlayerContext;\n\n} DVMSG_PLAYERVOICESTART, *LPDVMSG_PLAYERVOICESTART, *PDVMSG_PLAYERVOICESTART;\n\ndwSize\n"]}}}},"Size of the DVMSG_PLAYERVOICESTART message structure.","dvidSourcePlayerID","DVID of the player where the voice transmission originated.","pvPlayerContext","Pointer to the context value set for the player. This value is set through the pvPlayerContext member of the DVMSG_CREATEVOICEPLAYER message structure.","DVMSGID_PLAYERVOICESTOP","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_PLAYERVOICESTOP message when an incoming audio stream stops.","DVMSG_PLAYERVOICESTOP","The DVMSG_PLAYERVOICESTOP structure contains information for the DVMSGID_PLAYERVOICESTOP system message.","typedef struct {","DWORD dwSize;",{"@attributes":{"id":"p-0392","num":"0000"},"ul":{"@attributes":{"id":"ul0074","list-style":"none"},"li":{"@attributes":{"id":"ul0074-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0075","list-style":"none"},"li":["DVID dvidSourcePlayerID;","PVOID pvPlayerContext;\n\n} DVMSG_PLAYERVOICESTOP, *LPDVMSG_PLAYERVOICESTOP, *PDVMSG_PLAYERVOICESTOP;\n\ndwSize\n"]}}}},"Size of the DVMSG_PLAYERVOICESTOP message structure.","dvidSourcePlayerID","DVID of the player where the voice transmission originated.","pvPlayerContext","Pointer to the context value set for the player. This value is set through the pvPlayerContext member of the DVMSG_CREATEVOICEPLAYER message structure.","DVMSGID_RECORDSTART","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_RECORDSTART message when audio input on the local client begins. This can be caused by the voice activation sensitivity level being exceeded or when a valid target is specified in push-to-talk mode.","DVMSG_RECORDSTART","The DVMSG_RECORDSTART structure contains information for the DVMSGID_RECORDSTART system message.","typedef struct {",{"@attributes":{"id":"p-0398","num":"0000"},"ul":{"@attributes":{"id":"ul0076","list-style":"none"},"li":{"@attributes":{"id":"ul0076-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0077","list-style":"none"},"li":["DWORD dwSize;","DWORD dwPeakLevel;","PVOID pvLocalPlayerContext;\n\n} DVMSG_RECORDSTART, *LPDVMSG_RECORDSTART, *PDVMSG_RECORDSTART;\n\ndwSize\n"]}}}},"Size of the DVMSG_RECORDSTART message structure.","dwPeakLevel","Voice activation level that caused the transmission to begin. In push-to-talk mode, this value is 0.","pvLocalPlayerContext","Pointer to the context value set for the local player. This value is set through the pvPlayerContext member of the DVMSG_CREATEVOICEPLAYER message structure.","DVMSGID_RECORDSTOP","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_RECORDSTOP message when audio input on the local client stops. This can be caused by the voice activation sensitivity level not being reached or when a target is deselected in push-to-talk mode.","DVMSG_RECORDSTOP","The DVMSG_RECORDSTOP structure contains information for the DVMSGID_RECORDSTOP system message.","typedef struct {",{"@attributes":{"id":"p-0404","num":"0000"},"ul":{"@attributes":{"id":"ul0078","list-style":"none"},"li":{"@attributes":{"id":"ul0078-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0079","list-style":"none"},"li":["DWORD dwSize;","DWORD dwPeakLevel;","PVOID pvLocalPlayerContext;\n\n} DVMSG_RECORDSTOP, *LPDVMSG_RECORDSTOP, *PDVMSG_RECORDSTOP;\n\ndwSize\n"]}}}},"Size of the DVMSG_RECORDSTOP message structure.","dwPeakLevel","Voice activation level that caused the transmission to stop. In push-to-talk mode, this value is 0.","pvLocalPlayerContext","Pointer to the context value set for the local player. This value is set through the pvPlayerContext member of the DVMSG_CREATEVOICEPLAYER message structure.","DVMSGID_SESSIONLOST","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_SESSIONLOST message when the voice session terminates.","DVMSG_SESSIONLOST","The DVMSG_SESSIONLOST structure contains information for the DVMSGID_SESSIONLOST system message.","typedef struct {",{"@attributes":{"id":"p-0410","num":"0000"},"ul":{"@attributes":{"id":"ul0080","list-style":"none"},"li":{"@attributes":{"id":"ul0080-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0081","list-style":"none"},"li":["DWORD dwSize;","HRESULT hrResult;\n\n} DVMSG_SESSIONLOST, *LPDVMSG_SESSIONLOST, *PDVMSG_SESSIONLOST;\n\ndwSize\n"]}}}},"Size of the DVMSG_SESSIONLOST message structure.","hrResult","HRESULT indicating why the session was terminated.","DVMSGID_SETTARGETS","Microsoft\u00ae DirectPlay\u00ae Voice generates the DVMSGID_SETTARGETS message when the IDirectPlayVoiceClient::SetTransmitTargets or IDirectPlayVoiceServer::SetTransmitTargets methods are called.","DVMSG_SETTARGETS","The DVMSG_SETTARGETS structure contains information for the DVMSGID_SETTARGETS system message.","typedef struct {",{"@attributes":{"id":"p-0415","num":"0000"},"ul":{"@attributes":{"id":"ul0082","list-style":"none"},"li":{"@attributes":{"id":"ul0082-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0083","list-style":"none"},"li":["DWORD dwSize;","DWORD dwNumTargets;","PDVID pdvidTargets;\n\n} DVMSG_SETTARGETS, *LPDVMSG_SETTARGETS, *PDVMSG_SETTARGETS;\n\ndwSize\n"]}}}},"Size of the DVMSG_SETTARGETS message structure.","dwNumTargets","Number of DVIDs contained in the pdvidTargets member.","pdvidTargets","Array of DVIDs specifying the set targets. This can also be set to NULL if there are no targets.","Structures","Structure for DirectPlay\u00ae Voice are:","DVCAPS","DVCLIENTCONFIG","DVCOMPRESSIONINFO","DVSESSIONDESC","DVSOUNDDEVICECONFIG","DVCAPS","Describes the capabilities of the Microsoft\u00ae DirectPlay\u00ae VoiceClient object.","typedef struct{",{"@attributes":{"id":"p-0426","num":"0000"},"ul":{"@attributes":{"id":"ul0084","list-style":"none"},"li":{"@attributes":{"id":"ul0084-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0085","list-style":"none"},"li":["DWORD dwSize;","DWORD dwFlags;\n\n} DVCAPS, *LPDVCAPS, *PDVCAPS;\n\nMembers\n\ndwSize\n"]}}}},"Must be set the to size of this structure, in bytes, before using this structure.","dwFlags","Reserved. Must be 0.","DVCLIENTCONFIG","Controls the run-time parameters for the client. The structure is first used in the call to IDirectPlayVoiceClient::Connect, where it sets the initial state of these parameters. The structure can be retrieved after a connection has been made by calling IDirectPlayVoiceClient::GetClientConfig, and set using IDirectPlayVoiceClient::SetClientConfig.","typedef struct {",{"@attributes":{"id":"p-0430","num":"0000"},"ul":{"@attributes":{"id":"ul0086","list-style":"none"},"li":{"@attributes":{"id":"ul0086-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0087","list-style":"none"},"li":["DWORD dwSize;","DWORD dwFlags;","LONG lRecordVolume;","LONG lPlaybackVolume;","DWORD dwThreshold;","DWORD dwBufferQuality;","DWORD dwBufferAggressiveness;","DWORD dwNotifyPeriod;\n\n} DVCLIENTCONFIG, *LPDVCLIENTCONFIG, *PDVCLIENTCONFIG;\n\nMembers\n\ndwSize\n"]}}}},"Must be set the to size of this structure, in bytes, before using this structure.","dwFlags","Combination of the following flags.","DVCLIENTCONFIG_AUTORECORDVOLUME","Activates automatic gain control. With automatic gain control, Microsoft\u00ae DirectPlay\u00ae Voice adjusts the hardware input volume on your sound card automatically to get the best input level possible. You can determine the current input volume by looking at the lRecordVolume member after a call to IDirectPlayVoiceClient::GetClientConfig, or by looking at the lRecordVolume member of DVMSG_INPUTLEVEL messages.","DVCLIENTCONFIG_ECHOSUPPRESSION","Activates the echo suppression mode. This mode reduces echo introduced by configurations with external speakers and extremely sensitive microphones. While remote players' voices are being played back on the local speaker, the microphone is automatically muted. If the local player is transmitting, the playback of remote player voices is buffered until local input stops. After local input stops, playback resumes.","DVCLIENTCONFIG_MUTEGLOBAL","Mutes playback of the main sound buffer. Only sound buffers created through calls to IDirectPlayVoiceClient::Create3DSoundBuffer will be heard.","DVCLIENTCONFIG_PLAYBACKMUTE","Mutes playback of all DirectPlay Voice output and stops playback. This also stops decompression of incoming packets so CPU usage is reduced. Packets are effectively discarded while this flag is specified.","DVCLIENTCONFIG_RECORDMUTE","Mutes input from the microphone and stops recording. This also stops compression so CPU usage is reduced.","In addition to the preceding flags, the method of transmission is controlled by setting only one of the following flags or by not specifying either flag.","DVCLIENTCONFIG_AUTOVOICEACTIVATED","Places the transmission control system into automatic voice activation mode. In this mode, the sensitivity of voice activation is determined automatically by the system. The input level is adaptive, adjusting itself automatically to the input signal. For most applications this should be the setting used. This flag is mutually exclusive with the DVCLIENTCONFIG_MANUALVOICEACTIVATED flag.","DVCLIENTCONFIG_MANUALVOICEACTIVATED","Places the transmission control system into manual voice activation mode. In this mode, transmission of voice begins when the input level passes the level specified by the dwThreshold member. When input levels drop below the specified level, transmission stops. This flag is mutually exclusive with the DVCLIENTCONFIG_AUTOVOICEACTIVATED flag.","If you do not specify either DVCLIENTCONFIG_MANUALVOICEACTIVATED or DVCLIENTCONFIG_AUTOVOICEACTIVATED, the system will operate in push-to-talk mode. In push-to-talk mode, as long as there is a valid target specified the input from the microphone will be transmitted. Voice transmission stops when a NULL target is set or the current target leaves the session or is destroyed.","lRecordVolume","Value indicating what the volume of the recording should be set to. See the IDirectSoundBuffer8::SetVolume method for valid values.","If automatic gain control is enabled, this value can be set to DVRECORDVOLUME_LAST, which tells the system to use the current volume as determined by the automatic gain control algorithm. If a value other than DVRECORDVOLUME_LAST is specified in combination with automatic gain control, this value will be used to restart the algorithm at the specified value.","On return from a call to IDirectPlayVoiceClient::GetClientConfig, this value will contain the current recording volume. When adjusting the recording volume, DirectPlay Voice will adjust the volume for the microphone (if a microphone volume is present for the card) and the master recording volume (if one is present on the card). If neither a microphone volume nor a master record volume is present, DirectPlay Voice will be unable to adjust the recording volume.","lPlaybackVolume","Value indicating what the volume of the playback should be set to. Adjusting this volume adjusts both the main buffer and all 3-D sound buffers. See the IDirectSoundBuffer8::SetVolume method for valid values. You can specify DVPLAYBACKVOLUME_DEFAULT to use a default value that is appropriate for most situations (full volume).","dwThreshold","Input level used to trigger voice transmission if the DVCLIENTCONFIG_MANUALVOICEACTIVATED flag is specified in the dwFlags member. When the flag is specified, this value can be set to anywhere in the range of DVTHRESHOLD_MIN to DVTHRESHOLD_MAX. Additionally, DVTHRESHOLD_DEFAULT can be set to use a default value.","If DVCLIENTCONFIG_MANUALVOICEACTIVATED or DVCLIENTCONFIG_AUTOVOICEACTIVATED is not specified in the dwFlags member of this structure (indicating push-to-talk mode) this value must be set to DVTHRESHOLD_UNUSED.","dwBufferQuality","Buffer quality setting for the adaptive buffering algorithm. For most applications, this should be set to DVBUFFERQUALITY_DEFAULT. It can be set to anything in the range of DVBUFFERQUALITY_MIN to DVBUFFERQUALITY_MAX. In general, the higher the value, the higher the quality of the voice but the higher the latency. The lower the value, the lower the latency but the lower the quality.","dwBufferAggressiveness","Buffer aggressiveness setting for the adaptive buffer algorithm. For most applications, this can be set to DVBUFFERAGGRESSIVENESS_DEFAULT. It can also be set to anything in the range of DVBUFFERAGGRESSIVENESS_MIN and DVBUFFERAGGRESSIVENESS_MAX. In general, the higher the value, the quicker the adaptive buffering adjusts to changing conditions. The lower the value, the slower the adaptive buffering adjusts to changing conditions.","dwNotifyPeriod","Value indicating how often you want to receive DVMSGID_OUTPUTLEVEL and DVMSGID_INPUTLEVEL (if session is full duplex) messages. If this value is set to 0, these messages are disabled. The value specifies the number of milliseconds between these messages. DVNOTIFYPERIOD_MINPERIOD specifies the minimum period between messages that is allowed.","DVCOMPRESSIONINFO","Describes the attributes of a specific Microsoft\u00ae DirectPlay\u00ae Voice compression type.",{"@attributes":{"id":"p-0452","num":"0559"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"typedef struct{"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"DWORD","dwSize;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"GUID","guidType;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"LPWSTR","lpszName;"]},{"entry":[{},"LPWSTR","lpszDescription;"]},{"entry":[{},"DWORD","dwFlags;"]},{"entry":[{},"DWORD","dwMaxBitsPerSecond;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"} DVCOMPRESSIONINFO, *LPDVCOMPRESSIONINFO,"]},{"entry":[{},"*PDVCOMPRESSIONINFO;"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":[{},{}]},"Must be set the to size of this structure, in bytes, before using this structure.","guidType","GUID used to identify this compression type by DirectPlay Voice.","lpszName","Pointer to a name describing the codec.","lpszDescription","Pointer to a longer name of the codec.","dwFlags","Reserved; must be 0.","dwMaxBitsPerSecond","Maximum number of bits per second claimed by the codec.","DVSESSIONDESC","Describes the desired or current session settings for the Microsoft\u00ae DirectPlay\u00ae Voice server. This structure is used by the voice session host to configure the session, and by the session host and clients to retrieve information about the current session. The dwFlags, dwSessionType, and guidCT members can only be set when the host starts the voice session. The host can change the buffer settings at any time.","typedef struct {",{"@attributes":{"id":"p-0460","num":"0000"},"ul":{"@attributes":{"id":"ul0088","list-style":"none"},"li":{"@attributes":{"id":"ul0088-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0089","list-style":"none"},"li":["DWORD dwSize;","DWORD dwFlags;","DWORD dwSessionType;","GUID guidCT;","DWORD dwBufferQuality;","DWORD dwBufferAggresiveness;\n\n} DVSESSIONDESC, *LPDVSESSIONDESC, *PDVSESSIONDESC;\n\nMembers\n\ndwSize\n"]}}}},"Must be set the to size of this structure, in bytes, before using this structure.","dwFlags","Combination of the following flags.","DVSESSION_NOHOSTMIGRATION","The voice host will not migrate regardless of the transport settings. If this flag is not specified, the voice host will migrate if the transport supports it.","DVSESSION_SERVERCONTROLTARGET","The clients are unable to control the target of their speech. Only the server player can control the target of their speech. If the server does not specify this flag, only the clients can control the target of their speech. This flag can be specified only in multicast and mixing sessions.","dwSessionType","The type of DirectPlay Voice session to run. The DVSESSIONTYPE_PEER flag is not available in client\/server sessions; all other flags are valid for all session types. This member can be one of the following values.","DVSESSIONTYPE_PEER","Voice messages will be sent directly between players.","DVSESSIONTYPE_MIXING","Voice session will use a mixing server. In this mode of operation, all voice messages are sent to the server, which mixes them and then forwards a single, premixed stream to each client. This reduces the bandwidth and CPU usage on clients significantly at the cost of increased bandwidth and CPU usage on the server.","DVSESSIONTYPE_FOWARDING","Voice messages will be routed through the session host. This will save bandwidth on the clients at the expense of bandwidth usage on the server. This option is only useful if the session host has a high-speed connection.","guidCT","GUID specifying the compression type of the session.","dwBufferQuality","The buffer quality setting. This member is unused for all session types except mixing sessions. For all sessions except mixing sessions, set this member to","DVBUFFERQUALITY_DEFAULT.","Allowable values are between DVBUFFERQUALITY_MIN and DVBUFFERQUALITY_MAX. Additionally, this member can be set to the following value.","DVBUFFERQUALITY_DEFAULT","Specifying this value tells DirectPlay Voice to use the system default for this value, which is adjustable through a registry entry that can also be set through Sounds and Multimedia in Control Panel.","dwBufferAggresiveness","Buffer aggressiveness setting. This member is unused for all session types except mixing sessions. For all sessions except mixing sessions, set this member to DVBUFFERAGGRESIVENESS_DEFAULT.","Allowable values are between DVBUFFERAGGRESIVENESS_MIN and DVBUFFERAGGRESIVENESS_MAX. Additionally, this member can be set to the following value.","DVBUFFERAGGRESIVENESS_DEFAULT","Specifying this value tells DirectPlay Voice to use the system default for this value, which is adjustable through a registry entry that can also be set through Control Panel.","DVSOUNDDEVICECONFIG","Used to set and retrieve information about the sound device configuration and cannot be changed once a connection has been made. After a connection is made, you can retrieve the current sound device configuration by calling IDirectPlayVoiceClient:: GetSoundDeviceConfig.",{"@attributes":{"id":"p-0477","num":"0589"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"typedef struct {"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DWORD","dwSize;"]},{"entry":[{},"DWORD","dwFlags;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"GUID","guidPlaybackDevice;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"LPDIRECTSOUND","lpdsPlaybackDevice;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"GUID","guidCaptureDevice;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"LPDIRECTSOUNDCAPTURE","lpdsCaptureDevice;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"HWND","hwndAppWindow;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"LPDIRECTSOUNDBUFFER","lpdsMainBuffer;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DWORD","dwMainBufferFlags;"]},{"entry":[{},"DWORD","dwMainBufferPriority;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} DVSOUNDDEVICECONFIG, *LPDVSOUNDDEVICECONFIG,"},{"entry":"*PDVSOUNDDEVICECONFIG;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":[{},{}]},"Must be set the to size of this structure, in bytes, before using this structure.","dwFlags","A combination of the following flags.","DVSOUNDCONFIG_AUTOSELECT","Tells Microsoft\u00ae DirectPlay\u00ae Voice to attempt to automatically select (or unmute) the microphone line in the mixer for the specified recording device.","DVSOUNDCONFIG_HALFDUPLEX","Tells DirectPlay Voice to initialize itself in half-duplex mode. In half-duplex mode no recording takes place. If the initialization of the sound system fails in full-duplex mode, this flag will be set by the system.","DVSOUNDCONFIG_NORMALMODE","Tells DirectPlay Voice to use Microsoft\u00ae DirectSound\u00ae Normal Mode when initializing the DirectSound object. If this flag is not specified, the DirectSound object is initialized with DirectSound Priority Mode. See documentation for IDirectSound8::SetCooperativeLevel for more information. If a valid DirectSound object is specified in the lpdsPlaybackDevice member, this flag is ignored.","DVSOUNDCONFIG_SETCONVERSIONQUALITY","Enables better quality audio at the expense of higher CPU usage.","DVSOUNDCONFIG_NORECVOLAVAILABLE","Set by DirectPlay Voice if there are no volume controls available on the recording device you specified. You cannot set this flag.","DVSOUNDCONFIG_NOFOCUS","The voice application will never go out of focus. In other words, the application will never release the sound capture device. Use of this flag is not recommended.","DVSOUNDCONFIG_STRICTFOCUS","The voice application will lose focus whenever its window is not the foreground window.","Note","Applications should set the DVSOUNDCONFIG_NOFOCUS or DVSOUNDCONFIG_STRICTFOCUS flags only when strictly necessary. Instead, you should normally use the default behavior that results when neither flag is set.","guidPlaybackDevice","When this structure is used in the IDirectPlayVoiceClient::Connect method, this member specifies the GUID of the device used for playback. This must be specified even if the lpdsPlaybackDevice member is used. You can also specify the following default GUIDs provided by DirectSound.","DSDEVID_DefaultPlayback","The system default playback device.","DSDEVID_DefaultVoicePlayback","The default voice playback device.","When this structure is used in the IDirectPlayVoiceClient::GetSoundDeviceConfig method, this member contains the actual device GUID used for playback.","lpdsPlaybackDevice","When this structure is used in the IDirectPlayVoiceClient::Connect method, this member specifies the DirectSound object you want DirectPlay Voice to use for playback. The GUID specified in guidPlaybackDevice must match the one used to create the device specified by this parameter. If you used NULL when specifying the device when you created your DirectSound object, pass DSDEVID_DefaultPlayback for this member.","When this structure is used in the IDirectPlayVoiceClient::GetSoundDeviceConfig method, this member contains a pointer to the DirectSound object being used by DirectPlay Voice. This will either be a pointer to the object specified when Connect was called or a pointer to a newly created and initialized DirectSound object. If you want to use this DirectSound object, you must store the pointer and increment the reference count by calling AddRef on the DirectSound interface.","guidCaptureDevice","When this structure is used in IDirectPlayVoiceClient::Connect method, this member specifies the GUID of the device used for capture. This must be specified even if the lpdsCaptureDevice member is used. If you used NULL when specifying the device when you created your DirectSoundCapture object, pass DSDEVID_DefaultCapture for this member.","When this structure is used in the IDirectPlayVoiceClient::GetSoundDeviceConfig method, this member will contain the actual device GUID used for capture.","lpdsCaptureDevice","When this structure is used in the IDirectPlayVoiceClient::Connect method, this member specifies the DirectSound object you want DirectPlay Voice to use for capture. The GUID specified in guidCaptureDevice must match the one used to create the device specified by this parameter. If you want to have DirectPlay Voice create the DirectSoundCapture object for you, specify NULL for this member.","When this structure is used in the IDirectPlayVoiceClient::GetSoundDeviceConfig method, this member contains a pointer to the DirectSoundCapture object being used by DirectPlay Voice. This will either be a pointer to the object specified when Connect was called or a pointer to a newly created and initialized DirectSoundCapture object. If you want to use this DirectSoundCapture object, you must store the pointer and increment the reference count by calling AddRef on the IDirectSoundCapture8 interface. If the DirectPlay Voice object is operating in half duplex mode, this member will be NULL.","hwndAppWindow","Must be set to the handle of the window that will be used to determine focus for sound playback. See IDirectSound8::SetCooperativeLevel for information on DirectSound focus. If you do not have a window to use for focus, use GetDesktopWindow to use the desktop window.","lpdsMainBuffer","Pointer to an IDirectSoundBuffer8 interface, which is used to create the DirectPlay Voice main buffer. This can be either NULL or a user-created DirectSound buffer. If this member is set to NULL, DirectPlay Voice will create a buffer for the main voice buffer. If users specify a buffer here, DirectPlay Voice will use their buffer for the main voice buffer. User-created buffers have the following restrictions.","The buffer must be 22 kilohertz, 16-bit, Mono format.","The buffer must be at least 1 second in length.","The buffer must have been created with the DSBCAPS_GETCURRENTPOSITION2 and DSBCAPS_CTRL3D flags.","The buffer must not be a primary buffer.","The buffer must not be playing when it is passed to the DirectPlay Voice software.","The buffer must not be locked when it is passed to the DirectPlay Voice software.","dwMainBufferFlags","Passed directly to the dwFlags parameter of the IDirectSoundBuffer8::Play method when Play is called for the main buffer. The DSBPLAY_LOOPING flag is automatically added to this field. See the documentation on IDirectSoundBuffer8::Play for details. This parameter must be 0 if the lpdsMainBufferDesc member of this structure is NULL.","dwMainBufferPriority","Passed directly to the dwPriority parameter of the IDirectSoundBuffer8::Play method when Play is called on the main buffer. See documentation for IDirectSoundBuffer8::Play for more information. This member must be set to 0 if lpdsMainBufferDesc is NULL.","Return Values","Errors are represented by negative values and cannot be combined.","Success Codes","S_OK","The operation completed successfully.","Error Codes","DV_OK","The request completed successfully.","DV_FULLDUPLEX","The sound card is capable of full-duplex operation.","DV_HALFDUPLEX","The sound card can only be run in half-duplex mode.","DVERR_BUFFERTOOSMALL","The supplied buffer is not large enough to contain the requested data.","DVERR_EXCEPTION","An exception occurred when processing the request.","DVERR_GENERIC","An undefined error condition occurred.","DVERR_INVALIDBUFFER","The buffer is invalid.","DVERR_INVALIDFLAGS","The flags passed to this method are invalid.","DVERR_INVALIDOBJECT","The DirectPlay object pointer is invalid.","DVERR_INVALIDPARAM","One or more of the parameters passed to the method are invalid.","DVERR_INVALIDPLAYER","The player ID is not recognized as a valid player ID for this game session.","DVERR_INVALIDGROUP","The group ID is not recognized as a valid group ID for this game session.","DVERR_INVALIDHANDLE","The handle specified is invalid.","DVERR_OUTOFMEMORY","There is insufficient memory to perform the requested operation.","DVERR_PENDING","Not an error, this return indicates that an asynchronous operation has reached the point where it is successfully queued.","DVERR_NOTSUPPORTED","The operation is not supported.","DVERR_NOINTERFACE","The specified interface is not supported. Could indicate using the wrong version of DirectPlay.","DVERR_SESSIONLOST","The transport has lost the connection to the session.","DVERR_NOVOICESESSION","The session specified is not a voice session.","DVERR_CONNECTIONLOST","The connection to the voice session has been lost.","DVERR_NOTINITIALIZED","The IDirectPlayVoiceClient::Initialize or IDirectPlayVoiceServer::Initialize method must be called before calling this method.","DVERR_CONNECTED","The DirectPlayVoice object is connected.","DVERR_NOTCONNECTED","The DirectPlayVoice object is not connected.","DVERR_CONNECTABORTING","The connection is being disconnected.","DVERR_NOTALLOWED","The object does not have the permission to perform this operation.","DVERR_INVALIDTARGET","The specified target is not a valid player ID or group ID for this voice session.","DVERR_TRANSPORTNOTHOST","The object is not the host of the voice session.","DVERR_COMPRESSIONNOTSUPPORTED","The specified compression type is not supported on the local computer.","DVERR_ALREADYPENDING","An asynchronous call of this type is already pending.","DVERR_ALREADYINITIALIZED","The object has already been initialized.","DVERR_SOUNDINITFAILURE","A failure was encountered initializing the sound card.","DVERR_TIMEOUT","The operation could not be performed in the specified time.","DVERR_CONNECTABORTED","The connect operation was canceled before it could be completed.","DVERR_NO3DSOUND","The local computer does not support 3-D sound.","DVERR_ALREADYBUFFERED","There is already a user buffer for the specified ID.","DVERR_NOTBUFFERED","There is no user buffer for the specified ID.","DVERR_HOSTING","The object is the host of the session.","DVERR_NOTHOSTING","The object is not the host of the session.","DVERR_INVALIDDEVICE","The specified device is invalid.","DVERR_RECORDSYSTEMERROR","An error in the recording system occurred.","DVERR_PLAYBACKSYSTEMERROR","An error in the playback system occurred.","DVERR_SENDERROR","An error occurred while sending data.","DVERR_USERCANCEL","The user canceled the operation.","DVERR_UNKNOWN","An unknown error occurred.","DVERR_RUNSETUP","The specified audio configuration has not been tested. Call the IDirectPlayVoiceTest::CheckAudioSetup method.","DVERR_INCOMPATIBLEVERSION","The client connected to a voice session that is incompatible with the host.","DVERR_INITIALIZED","The Initialize method failed because the object has already been initialized.","DVERR_INVALIDPOINTER","The pointer specified is invalid.","DVERR_NOTRANSPORT","The specified object is not a valid transport.","DVERR_NOCALLBACK","This operation cannot be performed because no callback function was specified.","DVERR_TRANSPORTNOTINIT","Specified transport is not yet initialized.","DVERR_TRANSPORTNOSESSION","Specified transport is valid but is not connected\/hosting.","DVERR_TRANSPORTNOPLAYER","Specified transport is connected\/hosting but no local player exists.","The following are the functions for exemplary IDirectPlayVoiceNotify and IDirectPlayVoiceTransport interfaces. The functions are, for the purpose of this example, described in C and C++. In C++ the THIS and THIS_parameters are not required. In \u2018C\u2019 they are and they specify a pointer to the interface that the function is being called on. It will be understood that the interfaces provided in this Appendix is exemplary, and an interface that includes any combination or subset of these (or equivalent) functions and structures, is included within the spirit and scope of the invention.","IDirectPlayVoiceNotify","The following three functions are standard COM interfaces which are described at http:\/\/msdn.microsoft.com","HRESULT QueryInterface (THIS_REFIID riid, PVOID *ppvObj);","Returns a pointer within this object instance that implements the interface.","ULONG AddRef (THIS);","Adds one reference to the interface instance.","ULONG Release (THIS);","Removes one reference from the interface instance. If the reference count reaches 0 the interface instance is destroyed. Returns 0 if the reference count is 0, a positive number otherwise.","The following are specific to the IDirectPlayVoiceNofity interface.","HRESULT Initialize (THIS);","Initializes the DirectPlayVoice interface associated with this interface. During this call DirectPlayVoice will call GetSessioninfo on the associated Transport interface.","HRESULT NotifyEvent (THIS_DWORD dwEventID, DWORD_PTR dwParam1, DWORD_PTR","dwParam2);","Called by the DirectPlay engine (or applicable session\/transport layer) when an event occurs that DirectPlayVoice needs to be informed about. See descriptions of DVEVENT_XXXXX (listed in Appendix A) for how the parameters are used for each message.","dwEventID\u2014Type of message (DVEVENT_XXXXXX).","dwParam1\u2014First parameter for the notification.","dwParam2\u2014Second parameter for the notification.","HRESULT ReceiveSpeechMessage (THIS_DVID dvidFrom,","DVID dvidTo, PVOID pvMessage, DWORD dwSize);","Called when a message is received by the transport that is for DirectPlayVoice.","dvidFrom\u2014Audio session ID for client this message came from.","dvidTo\u2014Audio session ID for who this message is targetted for.","pvMessage\u2014Pointer to the contents of the message.","dwSize\u2014Size of the message in bytes","IDirectPlayVoiceTransport","The following three functions are standard COM interfaces, which are described at http:\/\/msdn.microsoft.com","HRESULT QueryInterface (THIS_REFIID riid, PVOID *ppvObj);","Returns a pointer within this object instance that implements the interface.","ULONG AddRef (THIS);","Adds one reference to the interface instance","ULONG Release (THIS);","Removes one reference from the interface instance. If the reference count reaches 0 the interface instance is destroyed.","The following functions are specific to IDirectPlayVoiceTransport.","HRESULT Advise (THIS_LPUNKNOWN IpUnk, DWORD dwObjectType);","Advises the transport to call us back via the interface passed in the LPUNKNOWN parameter. This function calls QueryInterface on the LPUNKNOWN for an IDirectPlayVoiceNotify. Must call IDirectPlayVoiceNotify::Initialize on the interface before returning.","LPUNKNOWN\u2014IUnknown interface instance that supports the IDirectPlayVoiceNotify interface for the IDirectPlayVoiceNotify to make notifications on.","DWORD\u2014Voice Object Type","DVTRANSPORT_OBJECTTYPE_SERVER or","DVTRANSPORT_OBJECTTYPE_CLIENT).","HRESULT UnAdvise (THIS_DWORD dwObjectType);","Tells the transport that we no longer need to be called back on our notify interface. The transport should Release the instance of the notify interface that they have.","DWORD\u2014Voice Object Type","(DVTRANSPORT_OBJECTTYPE_XXXX, which are described above in Appendix A).","HRESULT IsGroupMember (THIS_DVID dvidGroup, DVID dvidPlayerToCheck);","This function returns S_OK if the specified user is a member of the specified group.","DVID dvidGroup\u2014DVID of the group to check.","DVID dvidPlayerToCheck\u2014DVID of the player.","HRESULT SendSpeech (THIS_DVID dvidFrom, DVID dvidTo, PDVTRANSPORT_BUFFERDESC pdvBufferDesc, LPVOID pvContext, DWORD dwFlags) PURE;","Transmits a message from the specified user ID to the specified user ID. (Speech specific).","dvidFrom\u2014DVID of the player this is from.","dvidTo\u2014DVID of the player to send the packet to.","pdvBufferDesc\u2014A reference counted structure describing the data to be sent.","pvContext\u2014User context for send. This will be passed back to the application when the send completes.","dwFlags\u2014Flags for the send, this can have either both, just one or neither of the following specified:","DVTRANSPORT_SEND_GUARANTEED:\n\n","DVTRANSPORT_SEND SYNC:\n\n","Fills the passed structure with details on the session that is running on the transport object. See description of DVTRANSPORTINFO for details.","HRESULT IsValidEntity (THIS_DVID, PBOOL) PURE;","Checks to see if specified ID is a valid player or group in session.","dvidToCheck=ID to check for validity.","LPBOOL=Pointer to BOOL to place result. TRUE for Valid Player\/Group, FALSE if it is not.","HRESULT SendSpeechEx (THIS_DVID dvidFrom, DWORD dwNumTargets,","UNALIGNED DVID *pdvidTargetList,","PDVTRANSPORT_BUFFERDESC pdvTransportDesc,","LPVOID pvUserContext, DWORD dwFlags);","Transmits a message from the specified user ID to a list of user IDs.","dvidFrom\u2014DVID of the player this is from.","dwNumTargets\u2014Number of targets.","pdvidTargetList\u2014An array of targets that this packet should be sent to. The number of elements must equal the value passed to dwNumTargets.","pdvBufferDesc\u2014A reference counted structure describing the data to be sent.","pvContext\u2014User context for send. This will be passed back to the application when the send completes.","dwFlags\u2014Flags for the send, this can have either both, just one or neither of the following specified:","DVTRANSPORT_SEND_GUARANTEED:\n\n","DVTRANSPORT_SEND_SYNC.\n\n","Checks to see if the specified ID is a valid Group ID dvidGroup=ID of the entity to check LPBOOL=Pointer to BOOL to place result. TRUE for Valid Group, FALSE if it is not.","HRESULT IsValidPlayer (THIS_DVID dvidPlayer, PBOOL pfResult);","Checks to see if the specified ID is a valid Player ID.","dvidPlayer\u2014ID of the player to check.","PBOOL=Pointer to BOOL to place result. TRUE for Valid Group, FALSE if it is not.","Structures","The following structures are used by the exemplary IDirectPlayVoiceNotify and IDirectPlayVoiceTransport interfaces:","DVTRANSPORT_BUFFERDESC",{"@attributes":{"id":"p-0618","num":"0734"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef struct _DVTRANSPORT_BUFFERDESC"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"DWORD","dwBufferSize;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"PBYTE","pRufferData;"]},{"entry":[{},"LONG","lRefCount;"]},{"entry":[{},"PVOID","pvContext;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DWORD","dwObjectType;"]},{"entry":[{},"DWORD","dwFlags;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} DVTRANSPORT_BUFFERDESC, *PDVTRANSPORT_BUFFER-"},{"entry":"DESC;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Fields:","dwBufferSize\u2014Size of buffer passed in pBufferData in bytes.","pBufferData\u2014Pointer to a buffer containing dwBufferSize bytes.","1RefCount\u2014Reference count of the structure, when this reaches 0 it should be destroyed. It is set to 1 initially.","pvContext\u2014Internal value used for the voice engine","dwObjectType=DVTRANSPORT_OBJECTTYPE_SERVER if this object belongs to a voice host, DVTRANSPORT_OBJECTTYPE_CLIENT if this object belongs to a voice client.","DVTRANSPORTINFO",{"@attributes":{"id":"p-0625","num":"0741"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"typedef struct"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DWORD","dwSize;"]},{"entry":[{},"DWORD","dwFlags;"]},{"entry":[{},"DWORD","dwSessionType;"]},{"entry":[{},"DVID","dvidSessionHost;"]},{"entry":[{},"DVID","dvidLocalID;"]},{"entry":[{},"DWORD","dwMaxPlayers;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} DVTRANSPORTINFO, *LPDVTRANSPORTINFO, *PDVTRANS-"},{"entry":"PORTINFO;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Fields:","dwSize\u2014Should be set to the size of the structure in bytes","dwFlags\u2014Combination of any of the following flags, can also be none of these flags:\n\n","dwSessionType=DVTRANSPORT_PEERTOPEER for a peer to peer transport, DVTRANSPORT_SESSION_CLIENTSERVER for a client\/server transport.","dvidSessionHost\u2014Voice session ID of the host.","dvidLocalID\u2014Voice session ID for the local client.","dwMaxPlayers\u2014Maximum # of players allowed, 0=no maximum."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing summary, as well as the following detailed description of preferred embodiments, is better understood when read in conjunction with the appended drawings. For the purpose of illustrating the invention, there is shown in the drawings exemplary constructions of the invention; however, the invention is not limited to the specific methods and instrumentalities disclosed. In the drawings:",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 4","FIG. 2"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIGS. 16A-D"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 17"}]},"DETDESC":[{},{}]}
