---
title: Executing system actions corresponding to user inputs
abstract: In an embodiment, the user input and a corresponding user input pattern is received on a computer generated user interface (UI). Based upon the user input pattern, a probable succeeding user input is predicted, and a network repository is queried to determine a system action corresponding to the probable succeeding user input. The system action may be an action that is estimated to be processed based upon the user input. This system action is processed to determine associated metadata, which is persisted in a UI buffer associated with the UI. A correlation between the succeeding user input and the predicted probable succeeding user input is determined; and based upon the correlation the metadata is retrieved from the UI buffer for execution.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09335832&OS=09335832&RS=09335832
owner: SAP SE
number: 09335832
owner_city: Walldorf
owner_country: DE
publication_date: 20111223
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The field generally relates to computer systems and software, and more particularly to various methods and systems to execute a system action corresponding to a user input.","In enterprise related applications, one factor influencing a computer system's response time to transactions is the productivity of the applications running on the system. Besides this, the response time may depend on various factors associated with the computer system, including a frequency at which a processor of the system functions, a bandwidth of a data transfer medium, a memory of the system, computing intelligence of the processor, and the like. In spite of designing a computer system with ideal hardware conditions, the response time may be affected by network latency. Network latency may be described as time taken to transmit and receive data between a source and a destination in a network. In addition, for server based computer systems, the network latency may increase, since the server provides services to various clients over the network. Hence, server based systems have a higher latency compared to self contained systems.","Various embodiments of systems and methods to execute a system action corresponding to a user input are disclosed. In an embodiment, a system action is a functional attribute of a system (for e.g. computer system) that is triggered based upon an input to the system. The input to the system may be in a form of a user input provided on a user interface, a system generated input provided as a resultant of another process, a determined value assigned to the action, and the like. Based upon the input provided to the system, the system executes the system action to compute an execution resultant. In an embodiment, for a user input provided on a computer generated user interface, the system executes a corresponding system action.","In an embodiment, the user input and a corresponding user input pattern is received on a computer generated user interface (UI). Based upon the user input pattern, a probable succeeding user input is predicted, and a network repository is queried to determine a system action corresponding to the probable succeeding user input. The system action may be an action that is estimated to be processed based upon the user input. This system action is processed to determine associated metadata, which is persisted in a UI buffer associated with the UI. A correlation between the succeeding user input and the predicted succeeding user input is determined; and based upon the correlation the metadata is retrieved from the UI buffer for execution.","These and other benefits and features of embodiments will be apparent upon consideration of the following detailed description of preferred embodiments thereof, presented in connection with the following drawings.","Embodiments of techniques for systems and methods to execute a system action corresponding to a user input are disclosed. In the following description, numerous specific details are set forth to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize, however, that the invention can be practiced without one or more of the specific details, or with other methods, components, materials, etc. In other instances, well-known structures, materials, or operations are not shown or described in detail to avoid obscuring aspects of the invention.","Reference throughout this specification to \u201cone embodiment\u201d, \u201cthis embodiment\u201d and similar phrases, means that a particular feature, structure, or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus, the appearances of these phrases in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore, the particular features, structures, or characteristics may be combined in any suitable manner in one or more embodiments.","In an embodiment, a system action is estimated to be processed and executed based upon the input to render an estimated result. The system may determine a corresponding system action for a user input instantaneously or with some delay based upon the system's response time. The response time of a self contained system (e.g. a desktop system) is quicker compared to a server based system since the network latency is absent. However, a storage device associated with the self contained system may be overloaded with a large amount of data, thereby creating latency in response time. To mitigate a latency of the system's response time and avoid overload, minimal information that is accessed via a network may be loaded anticipatorily to a local storage space. This anticipatorily loaded information may be extracted from the local storage space when a corresponding action is selected on the UI, thereby eliminating the network latency.",{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 1","FIG. 1"],"b":["100","105","110","115","120","125","130","135","140","145","150","155","160","165","170","105","135","155","155","105","135","160","160","160","165","170","165","160","160","160","170","165","170","160","135","170","165","135"]},"Computer generated user interface (UI)  is utilized for establishing interactions between a user and backend server  to execute one or more system actions corresponding to one or more user inputs. In an embodiment, UI  includes UI elements (e.g.  , , , ) that allow the user to interact with the computer. A user input may be received on UI  as one of one or more inputs to execute the system action. A user input to UI  may be received as, but is not limited to, a keyboard entry, a mouse click, a touch of a display screen, an audio input, a visual input, or the like. A person skilled in the related art will appreciate various other types of modes through which a user input may be received at UI . Based upon the received user input, UI controller  identifies a user input pattern associated with the user input. For instance, user inputs may include values entered at the UI elements (, ,  and ) or a process triggered at UI element , or the like, that represent one or more parameters based upon which the system action is executed. For example, consider a UI illustrating a PROFIT INCURRED BY SALES (UI ) that has received three user inputs PRODUCT (UI element ), QUANTITY (UI element ) and DELIVERY DATE (UI element ) and one user input trigger CALCULATE (UI element ). Consider that a user of the computer device provides values \u2018ABC\u2019, \u201810\u2019 and \u201820 Jan. 2012\u2019 as three user inputs via a keyboard. UI controller  identifies a pattern of the user input before the user triggers the system (computer) by activating (UI element ) that represents CALCULATE associated with the (UI element ). UI controller  predicts a probable succeeding user input and queries network repository  to determine associated system action corresponding to the probable expected user input. Here, UI controller determines a probable trigger of (UI element ) to CALCULATE the profit incurred by sales, and queries network repository  to determine associated system actions SELLING PRICE and COST PRICE of the PRODUCT ABC and associated metadata which is a formula to calculate the PROFIT (PROFIT=SELLING PRICE-COST PRICE). UI controller stores the metadata along with the corresponding system actions in UI buffer . In an embodiment, storing (or persisting) the metadata of the system action in UI buffer  includes prefetching a system action corresponding to a predicted probable succeeding user input and preloading UI buffer  with the prefetched system action.","Further, when the user triggers UI controller  by providing a succeeding user input to (UI element ), UI controller determines a correlation between the succeeding user input and the predicted probable user input. The correlation represents a determination of whether the provided user input is equivalent to the predicted probable succeeding user input. In an embodiment, the correlation is determined by determining a succeeding user input to a succeeding UI element on UI  and determining whether the succeeding user input is identical to the predicted probable succeeding user input. For an identical succeeding user input, the metadata of the system action is retrieved and the system action is executed for the succeeding user input. In the above example, UI controller  determines if the predicted probable succeeding user input is equivalent to the actual succeeding user input CALCULATE received at a current instance. Based upon this determination of the correlation, UI controller  retrieves the metadata from UI buffer  and executes the system action according to the user inputs (received at UI elements , , ,  and ). In an embodiment, retrieving the metadata of the corresponding system actions include instantaneously executing the system action based upon the metadata to reduce the network latency of the associated transmission medium .","In an embodiment, the user input patterns include a current location or position of the user input for example, a movement of a mouse pointer, a movement of a keyboard cursor, a touch on a touch screen display, or the like. For instance, if a UI  includes ten UI elements that accept user input, where the tenth UI element is a trigger to execute a corresponding system action associated with UI ; UI controller  continually identifies the location of the keyboard cursor and when the keyboard cursor reaches the ninth UI element, the UI controller predicts a probable user input to the tenth UI element and queries network repository  to retrieve one or more system actions and corresponding metadata. Upon receiving the tenth user input, UI controller determines a correlation between the actual tenth user input received and the predicted probable tenth user input. Based upon a determination of equivalence between the predicted user input and the actual user input, UI controller retrieves the system actions and the corresponding metadata from a local buffer (UI buffer) and executes the system action. Thus, the time period between the ninth user input received and the tenth user input received is used to retrieve the system action that correspond to the tenth user input, and is stored locally at UI buffer. Thus the network latency occurred while retrieving relevant information subsequent to receiving the tenth user input is reduced.","In another example, UI controller  identifies a location and position of a mouse pointer along with a movement pattern for instance, a speed of movement of the mouse pointer on UI . For instance, if a user input is to be received at a bottom right corner of a current page in UI , and a current location of the mouse pointer is top left corner, the mouse has to be moved across the current page. The speed of movement of the mouse pointer varies as the pointer gets closer to its destination (UI element that receives user input). For example, if the current position of the mouse pointer is far from the UI element that accepts user input, a user may briskly drag the mouse pointer until the pointer reaches close to the UI element. The movement pattern of the pointer slows down here, to click the UI element that further executes a corresponding action. UI controller  determines the user input pattern which is the brisk movement of the mouse pointer from top left corner to bottom right corner, and predicts a probable succeeding user input, which is a mouse-click on the UI element. Based upon the pattern, UI controller  queries network repository  and determines the corresponding system actions along with the metadata and stores this information in UI buffer . Upon receiving the user input on the UI element, UI controller  determines if the user input was received on the predicted probable UI element, and retrieves the information from UI buffer  for execution. A person skilled in the related art will appreciate various other types of predictive methods that may be used based upon the user input and\/or UI elements available at UI .","In an embodiment, UI controller  records the movement pattern of the user input by tracking the movement and the movement pattern of the mouse pointer from a first section to a second section of UI . Based upon a change in the movement pattern of the mouse pointer, for instance a click of the mouse, UI controller  is triggered to predict the probable succeeding user input. UI controller  may also record the movement pattern of the user input by tracking a location of the keyboard cursor.","In an embodiment, the user input pattern is a representation of structural criteria, and is determined by determining attributes of the structural criteria. A structural criterion of the user input pattern may include an occurrence of recurring events or objects associated with a business process to be executed by receiving inputs on UI . For instance, to calculate a profit of sales of product ABC, the same set of objects (or UI elements\u2014PRODUCT; SELLING PRICE and COST PRICE) may be used; however, the values entered for each objects may vary. Hence, by determining the structural criteria, UI controller statistically predicts a probable succeeding user input. In an embodiment, a plurality of probable succeeding user inputs may be included. For instance, in place of UI element CALCULATE, UI  may include CALCULATE FOR YEAR 2010, CALCULATE FOR YEAR 2011 and CALCULATE FOR YEAR 2012. In such cases, UI controller  may query and retrieve information related to all three UI elements. In an embodiment, UI controller  may determine user input pattern for a combination of types of user inputs, for instance a mouse pointer and a keyboard cursor. For example, UI controller  identifies a movement of the mouse pointer, and if the pointer is moved away from one or more of the UI elements, UI controller excludes a determination of system actions and\/or metadata for such UI elements. In an embodiment, a UI element may accept multiple user inputs, for example a mouse point hover and a mouse click. UI controller determines a hover of the mouse pointer on the UI element and queries network repository  to determine the system actions and metadata associated with the predicted probable \u2018mouse click\u2019 and stores the information in UI buffer . If the user input received is a mouse click on the UI element, UI controller  retrieves the system action and the metadata from UI buffer  and performs the execution.","In an embodiment, statistically predicting the probable succeeding user input includes determining one or more available succeeding UI elements succeeding from the previous UI element or from the UI element that has currently received the user input. Further, UI controller  processes the user input pattern and the available succeeding UI elements to predict the probable succeeding user input. In another embodiment, one or more navigational inputs are predicted prior to occurrence of the succeeding user inputs. Navigational inputs include hyperlinks that are reference to a data stored in backend server . Based upon a user input pattern associated with the navigational input, UI controller  predicts a probable succeeding user input prior to the occurrence, and retrieves the corresponding system actions. Predicting the probable succeeding user input for the navigational input includes determining the reference of a navigational UI element and identifying associated information including system action and the associated metadata. Upon receiving the user input on the UI element, UI controller  determines if the user input was received on the predicted probable UI element, and retrieves the information from UI buffer  for execution.","In an embodiment, UI controller  includes a UI control grid that represents a structural illustration (for e.g. a UI backend) of UI . The UI control grid includes multiple intersecting vertical and horizontal axes to create multiple structures, where each structure represents a grid element. The UI control grid facilitates in organizing UI elements on UI , thus being in correlation with a corresponding part of UI  and associated UI elements. The user input pattern at each grid element is determined to identify one or more preceding user inputs. The identified user input at each UI element may be translated into a grid element understandable correlation. Based upon the user input pattern, a probable succeeding user input is predicted. In an embodiment, each grid element is mapped to a corresponding section of UI , and the user input pattern at the corresponding section of UI  is identified and notified to the grid element by UI controller .",{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 2","b":["205","210"]},"In process block , a network repository is queried to determine a system action corresponding to the probable succeeding user input. A network repository may be a backend system associated with a server, and is accessible via network. The network repository stores system action and associated metadata for the system action to be processed and\/or executed. The network repository may further include a mapping between the UI element that receives the user input and the system action to identify a system action for a received user input. In process block , the system action is processed and the associated metadata is retrieved and stored in a UI buffer. A UI buffer may be a local storage space that is in communication with a UI controller that manages and maintains the UI. In process block , a succeeding user input is received, and a correlation between the received succeeding user input and the predicted probable succeeding user input is determined. Based upon the correlation, in process block , the corresponding metadata is retrieved from the UI buffer and the corresponding system action is executed.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 3","b":["305","305","310","310","300","305","305","310","310","310","310","310","310","310","310","310","310"]},"In an embodiment, the UI controller includes a UI control grid that represents a structural illustration of UI . The UI control grid includes grid elements representing the UI elements , A, A to E. The user input pattern at each grid element is determined to identify the preceding user inputs. The identified user input at each UI element may be translated into a grid element understandable correlation. Based upon the user input pattern, a probable succeeding user input is predicted. Each grid element is mapped to a corresponding section of UI , and the user input pattern at the corresponding section of UI  is identified and notified to the grid element by the UI controller.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 4","b":["405","405","410","410","400","405","410","410","410"]},"In an embodiment, the UI controller may also determine a movement pattern, for example a speed of movement of the mouse pointer on UI . For instance, if a user input is to be received at UI element E in UI , and a current location of the mouse pointer is at UI element B, the mouse has to be moved across the current page. The speed of movement of the mouse pointer varies as the pointer gets closer to its destination (UI element that receives user input). For example, if the current position of the mouse pointer is far from the UI element that accepts user input, a user may briskly drag the mouse pointer until the pointer reaches close to UI element E. The movement pattern of the pointer, as illustrated by , slows down here, to click UI element E that further executes a corresponding action. The UI controller determines the user input pattern which is the movement pattern of the mouse pointer from UI element B to UI element E, and predicts a probable succeeding user input, which is a mouse-click on UI element E. Based upon the pattern, the UI controller queries a network repository and determines the corresponding system action along with the metadata and stores this information in the UI buffer. Upon receiving the mouse click on UI element E, the UI controller determines if the user input was received on the predicted probable UI element, and retrieves the information from the UI buffer for execution.","In an embodiment, the UI controller includes a UI control grid that represents a structural illustration of UI . The UI control grid includes grid elements representing the UI elements A to F, A to G. The user input pattern at each grid element is determined to identify the preceding user inputs. The identified user input at each UI element may be translated into a grid element understandable correlation. Based upon the user input pattern, a probable succeeding user input is predicted. Each grid element is mapped to a corresponding section of UI , and the user input pattern at the corresponding section of UI  is identified and notified to the grid element by the UI controller.","Some embodiments of the invention may include the above-described methods being written as one or more software components. These components, and the functionality associated with each, may be used by client, server, distributed, or peer computer systems. These components may be written in a computer language corresponding to one or more programming languages such as, functional, declarative, procedural, object-oriented, lower level languages and the like. They may be linked to other components via various application programming interfaces and then compiled into one complete application for a server or a client. Alternatively, the components maybe implemented in server and client applications. Further, these components may be linked together via various distributed programming protocols. Some example embodiments of the invention may include remote procedure calls being used to implement one or more of these components across a distributed programming environment. For example, a logic level may reside on a first computer system that is remotely located from a second computer system containing an interface level (e.g., a graphical user interface). These first and second computer systems can be configured in a server-client, peer-to-peer, or some other configuration. The clients can vary in complexity from mobile and handheld devices, to thin clients and on to thick clients or even other servers.","The above-illustrated software components are tangibly stored on a computer readable storage medium as instructions. The term \u201ccomputer readable storage medium\u201d should be taken to include a single medium or multiple media that stores one or more sets of instructions. The term \u201ccomputer readable storage medium\u201d should be taken to include any physical article that is capable of undergoing a set of physical changes to physically store, encode, or otherwise carry a set of instructions for execution by a computer system which causes the computer system to perform any of the methods or process steps described, represented, or illustrated herein. Examples of computer readable storage media include, but are not limited to: magnetic media, such as hard disks, floppy disks, and magnetic tape; optical media such as CD-ROMs, DVDs and holographic devices; magneto-optical media; and hardware devices that are specially configured to store and execute, such as application-specific integrated circuits (\u201cASICs\u201d), programmable logic devices (\u201cPLDs\u201d) and ROM and RAM devices. Examples of computer readable instructions include machine code, such as produced by a compiler, and files containing higher-level code that are executed by a computer using an interpreter. For example, an embodiment of the invention may be implemented using Java, C++, or other object-oriented programming language and development tools. Another embodiment of the invention may be implemented in hard-wired circuitry in place of, or in combination with machine readable software instructions.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 5","b":["500","500","505","555","500","540","555","510","515","510","515","505","515","500","525","530","500","525","530","500","535","500","550","550","500","545","500","520","560","560","560","550","560"]},"A data source is an information resource. Data sources include sources of data that enable data storage and retrieval. Data sources may include databases, such as, relational, transaction, hierarchical, multi-dimensional (e.g., OLAP), object oriented databases, and the like. Further data sources include tabular data (e.g., spreadsheets, delimited text files), data tagged with a markup language (e.g., XML data), transaction data, unstructured data (e.g., text files, screen scrapings), hierarchical data (e.g., data in a file system, XML data), files, a plurality of reports, and any other data source accessible through an established protocol, such as, Open DataBase Connectivity (ODBC), produced by an underlying software system (e.g., ERP system), and the like. Data sources may also include a data source where the data is not tangibly stored or otherwise ephemeral such as data streams, broadcast data, and the like. These data sources can include associated data foundations, semantic layers, management systems, security systems and so on.","In the above description, numerous specific details are set forth to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize, however that the invention can be practiced without one or more of the specific details or with other methods, components, techniques, etc. In other instances, well-known operations or structures are not shown or described in details to avoid obscuring aspects of the invention.","Although the processes illustrated and described herein include series of steps, it will be appreciated that the different embodiments of the present invention are not limited by the illustrated ordering of steps, as some steps may occur in different orders, some concurrently with other steps apart from that shown and described herein. In addition, not all illustrated steps may be required to implement a methodology in accordance with the present invention. Moreover, it will be appreciated that the processes may be implemented in association with the apparatus and systems illustrated and described herein as well as in association with other systems not illustrated.","The above descriptions and illustrations of embodiments of the invention, including what is described in the Abstract, is not intended to be exhaustive or to limit the invention to the precise forms disclosed. While specific embodiments of, and examples for, the invention are described herein for illustrative purposes, various equivalent modifications are possible within the scope of the invention, as those skilled in the relevant art will recognize. These modifications can be made to the invention in light of the above detailed description. Rather, the scope of the invention is to be determined by the following claims, which are to be interpreted in accordance with established doctrines of claim construction."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The claims set forth the embodiments of the invention with particularity. The invention is illustrated by way of example and not by way of limitation in the figures of the accompanying drawings in which like references indicate similar elements. The embodiments of the invention, together with its advantages, may be best understood from the following detailed description taken in conjunction with the accompanying drawings.",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
