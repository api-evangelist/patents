---
title: Managing and predicting component failure based on pattern recognition of subcomponent exposure to failure
abstract: Methods, systems, and articles of manufacture consistent with the present invention provide for predicting system failure based on pattern recognition of subcomponent exposure to failure. A dataset is generated that has at least one exposure level to failure of a computer-based system and a corresponding rule identifier of a rule used to calculate the exposure level. The rule asynchronously receives information about the computer-based system and calculates the exposure level based on the received information. The generated dataset is compared to a previously generated dataset by comparing the at least one exposure level of the dataset to an at least one exposure level with the same rule identifier in the previously generated dataset, where the previously generated dataset is associated with a known problem with the computer-based system. A probability of a problem with the computer-based system is calculated based on a number of exposure levels in the generated dataset matching exposures levels in the previously generated dataset.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07293042&OS=07293042&RS=07293042
owner: Sun Microsystems, Inc.
number: 07293042
owner_city: Palo Alto
owner_country: US
publication_date: 20031022
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This Application claims the benefit of the filing date and priority to the following patent applications, all of which are incorporated herein by reference to the extent permitted by law:","U.S. Provisional Application Ser. No. 60\/469,767, entitled \u201cMETHODS AND SYSTEMS FOR INTELLECTUAL CAPITAL SHARING AND CONTROL\u201d, filed May 12, 2003.","Additionally, this Application is related to the following U.S. patent applications, which are filed concurrently with this application, and which are incorporated herein by reference to the extent permitted by law:","Application Ser. No. 10\/690,917, entitled \u201cNEAREST NEIGHBOR APPROACH FOR IMPROVED TRAINING OF REAL-TIME HEALTH MONITORS FOR DATA PROCESSING SYSTEMS\u201d;","Application Ser. No. 10\/690,866, entitled \u201cDYNAMIC RULE DEPLOYMENT FOR A SCALEABLE SERVICES RULES ENGINE\u201d;","Application Ser. No. 10\/690,951, entitled \u201cMANAGING EXPOSURE TO FAILURE FOR COMPUTER BASED SYSTEMS\u201d;","Application Ser. No. 10\/690,952, entitled \u201cMANAGING AND PREDICTING RISK FOR COMPUTER DEVICES USING EXPOSURE MANAGEMENT TECHNIQUES\u201d; and","Application Ser. No. 10\/691,039, entitled \u201cA PUBLISH-SUBSCRIBE SYSTEM FOR INTELLECTUAL CAPITAL MANAGEMENT\u201d.","The present invention relates to risk management of computer-based systems and, more particularly, to detecting system problems using pattern recognition.","Some of the challenges in managing and supporting computer systems are the growing complexity of the components and their relationships within the greater system. To avoid unpredictable results, vendors set forth constraints for systems to describe what components are supported within a certain tolerance. Customers, however, typically do not want to be restricted by the vendors' constraints and prefer to control the types of components used in their systems and to manage those components. This presents a conflict, which is compounded by increasing system complexity.","One approach to avoiding unpredictable results is to implement a risk management system that determines whether a customer's system configuration meets the criteria of an ideal configuration. Conventional risk management systems use simple checks or rule engines to determine whether a customer's existing configuration meets the requirements of a new component. Each rule engine defines a simple If . . . Then . . . relationship, such as if the customer wants to install disk driver X and has hard disk drive Y, then there is a compatibility problem.","A problem arises in that the knowledge built into these conventional risk management systems and rule engines is static or difficult to update. Computer systems continually increase in complexity and the knowledge required to maintain the computer systems increases and changes. Therefore, conventional risk management systems are inadequate for services organizations that support dynamic computer systems.","An additional problem is that, although conventional systems can define a simple If . . . Then . . . relationship to diagnose a fault, they are unable to understand why a failure happened or preempt the failure.","Further, in serviced computer systems, problems tend to repeat and the more complex the problems are, the more difficult it typically is to detect the problems. Thus, conventional fault management systems typically cannot detect the problems as often the problems are not manifested as known faults in the system.","Methods, systems, and articles of manufacture consistent with the present invention dynamically monitor the exposure to failure of computer-based systems and calculate a risk level of the systems based on the exposure to failure. Computer-based systems, such as data processing systems, storage devices, and computer programs are each registered as entities on a publish-subscribe network, or bus. A client module associated with each entity asynchronously publishes hardware and software configuration information and fault information relating to the entity to the bus. One or more rule engines, which are deployed in the publish-subscribe network, asynchronously subscribe to the configuration and fault information. Each rule engine performs a unique test on the incoming information to determine whether there is a potential future problem. If a rule engine fires, indicating a potential problem, the result indicates a level of exposure to failure for the entity. In turn, each exposure level is assigned a confidence level, which identifies how accurate the exposure level is believed to be. If two or more rule engines that are analyzing a similar problem fire, then the confidence level is accordingly increased.","Therefore, the output of the rule engine processing is a series of exposure levels. The range of the exposure levels and their respective confidence levels are used to predict potential future problems and measure the system's service stability.","The series of exposure levels for an entity, which exposure levels are referred to as exposure sets, are then plotted on a curve for each rule relating to the entity. The curve is compared to known curves that are each attributed to a particular known problem. Depending on how close a match there is between the curve and one of the known curves, the program calculates a probability of the system having the potential problem associated with the known curve. In other words, if the exposure levels on the curve matches most of the exposure levels on the known curve, then there is a high probability that there is a potential problem.","In an illustrative example, a data processing system comprises a number of customer systems connected to a publish-subscribe bus. One of the customer systems has a hard disk type X, and a hard disk driver Y was recently installed on the customer system. A services organization system has deployed in its memory a number of rule engines, with each rule engine asynchronously subscribing, via the bus, to specific information about customer systems to determine whether there is a potential problem. Through its experience with the customer systems, the services organization has determined that if a customer system is configured with hard disk type X and hard disk driver Y, there is a chance of failure of the customer system at some point after installation of the hard disk driver. Therefore, the services organization has configured one of the rule engines to fire if it receives input data indicating that a customer system has hard disk type X and hard disk driver Y. Another rule engine is configured to fire if it receives input data indicating that a customer system has hard disk type X and does not have hard disk driver Z, version 2.0 or greater. Since the services organization has determined that each of these potential problems can cause detrimental effects on the overall data processing system, it has assigned the exposure level value for each of these rules firing to be 100 in a range from 0 to 100.","When the first rule engine receives the customer hardware configuration information, it identifies the potential problem and outputs an exposure level of 100 and a confidence level of 0.5 in a range from 0 to 1.0. The second rule engine then fires and outputs an exposure level of 100, but with a confidence level of 1.0, based on the knowledge that a similar rule also fired. Further processing using these exposure levels and confidence levels, leads to a service action message being published that identifies a potential problem with the customer system. New rule engines are asynchronously dynamically deployed or existing rule engines are discontinued as required to service the changing customer systems and as the services organization's knowledge increases.","Therefore, unlike typical risk management systems that are run on demand to perform discrete checks, such as to check a system configuration during a product installation, and that use static knowledge, methods and systems consistent with the present invention asynchronously monitor the correctness of computer systems using dynamic rule engines.","In accordance with methods consistent with the present invention, a method in a data processing system having a program is provided. The method comprises the steps performed by the program of: generating a dataset having at least one exposure level to failure of a computer-based system and a corresponding rule identifier of a rule used to calculate the exposure level, the rule asynchronously receiving information about the computer-based system and calculating the exposure level based on the received information; comparing the generated dataset to a previously generated dataset by comparing the at least one exposure level of the dataset to an at least one exposure level with the same rule identifier in the previously generated dataset, the previously generated dataset being associated with a known problem with the computer-based system; and calculating a probability of a problem with the computer-based system based on a number of exposure levels in the generated dataset matching exposures levels in the previously generated dataset.","In accordance with articles of manufacture consistent with the present invention, a computer-readable medium containing instructions that cause a data processing system having a program to perform a method is provided. The method comprises the steps performed by the program of: generating a dataset having at least one exposure level to failure of a computer-based system and a corresponding rule identifier of a rule used to calculate the exposure level, the rule asynchronously receiving information about the computer-based system and calculating the exposure level based on the received information; comparing the generated dataset to a previously generated dataset by comparing the at least one exposure level of the dataset to an at least one exposure level with the same rule identifier in the previously generated dataset, the previously generated dataset being associated with a known problem with the computer-based system; and calculating a probability of a problem with the computer-based system based on a number of exposure levels in the generated dataset matching exposures levels in the previously generated dataset.","In accordance with systems consistent with the present invention, a data processing system is provided. The data processing system comprises: a memory having a program that\n\n","In accordance with systems consistent with the present invention, a data processing system is provided. The data processing system comprises: means for generating a dataset having at least one exposure level to failure of a computer-based system and a corresponding rule identifier of a rule used to calculate the exposure level, the rule asynchronously receiving information about the computer-based system and calculating the exposure level based on the received information; means for comparing the generated dataset to a previously generated dataset by comparing the at least one exposure level of the dataset to an at least one exposure level with the same rule identifier in the previously generated dataset, the previously generated dataset being associated with a known problem with the computer-based system; and means for calculating a probability of a problem with the computer-based system based on a number of exposure levels in the generated dataset matching exposures levels in the previously generated dataset.","Other systems, methods, features, and advantages of the invention will become apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional systems, methods, features, and advantages be included within this description, be within the scope of the invention, and be protected by the accompanying drawings.","Reference will now be made in detail to an implementation consistent with the present invention as illustrated in the accompanying drawings. Wherever possible, the same reference numbers will be used throughout the drawings and the following description to refer to the same or like parts.","Methods, systems, and articles of manufacture consistent with the present invention dynamically monitor the exposure to failure of computer-based systems. A client module associated with each computer-based system (i.e., an entity) asynchronously publishes hardware and software configuration information and fault information relating to the entity to a publish-subscribe network, or bus. One or more rule engines, which are deployed in the publish-subscribe network, asynchronously subscribe to the configuration and fault information. Each rule engine performs a unique test on the incoming information to determine whether there is a potential future problem. If a rule engine fires, indicating a potential problem, the result indicates a level of exposure to failure for the entity. In turn, each exposure level is assigned a confidence level, which identifies how accurate the exposure level is believed to be. If two or more rule engines that are analyzing a similar problem fire, then the confidence level is accordingly increased.","Therefore, the output of the rule engine processing is a series of exposure levels. The range of the exposure levels and their respective confidence levels are used to predict potential future problems and measure the system's service stability.","The series of exposure levels for an entity, which exposure levels are referred to as exposure sets, are then plotted on a curve for each rule relating to the entity. The curve is compared to known curves that are each attributed to a particular known problem. Depending on how close a match there is between the curve and one of the known curves, the program calculates a probability of the system having the potential problem associated with the known curve. In other words, if the exposure levels on the curve matches most of the exposure levels on the known curve, then there is a high probability that there is a potential problem.",{"@attributes":{"id":"p-0053","num":"0055"},"figref":"FIG. 1","b":["100","100","110","112"]},"As shown in the illustrative data processing system of , support assets can be bundled into asset groups ,  and . In , asset group  comprises support assets ,  and ; asset group  comprises support asset ; and asset group  comprises support assets  and . The groupings can be automatically derived by the services organization or manually defined by the services organization or a customer. The grouping of assets can be related, for example, to a business or organizational function or a topological group, or to other criteria such as hardware or software type. For example, the support assets of asset group  can be data processing systems of a similar type at one or more customer locations. If the support assets are data processing systems, each support asset can comprise components similar to those described below with respect to the services system, such as a CPU, an I\/O, a memory, a display device, and a secondary storage. Individual support assets and asset groups are collectively referred to herein as support entities.","Additional devices can also be connected to the network for use by the services organization. In the depicted example, a legacy data storage system , which has a legacy storage controller  and a legacy data storage device , is connected to the network. The services system can access information stored on the legacy data storage system to assist in servicing support entities.",{"@attributes":{"id":"p-0056","num":"0058"},"figref":"FIG. 2","b":["110","202","204","206","208","210"]},"Memory  contains a program , which comprises the following functional blocks for performing exposure detection and risk analysis: a rule deployment manager , a fault knowledge enrichment block , an exposure state management block , an exposure set curve fitting block , an exposure set risk calculation block , a risk trending block , an availability mapping block , and an availability outage calculation block . Each of these functional blocks will be described briefly immediately below with reference to  and then described in more detail further down in the description. One of skill in the art will appreciate that each functional block can itself be a stand-alone program and can reside in memory on a data processing other than the services system. The program  and the functional blocks may comprise or may be included in one or more code sections containing instructions for performing their respective operations. While the program  is described as being implemented as software, the present implementation may be implemented as a combination of hardware and software or hardware alone. Also, one having skill in the art will appreciate that the program may comprise or may be included in a data processing device, which may be a client or a server, communicating with services system .",{"@attributes":{"id":"p-0058","num":"0060"},"figref":"FIG. 3","b":["222","250","251","252","253","304","312","314","300"]},"If a rule engine check determines that there is a potential problem with a support entity, then the rule engine produces an output (i.e., the rule engine fires). The wrapper publishes an exposure level and a confidence level of the exposure level  as outputs based on the rule engine firing. The exposure level is a measure of the importance of the rule firing, which measure corresponds to an exposure to failure of the entity being checked. The confidence value is a measure of how confident the wrapper is that the exposure level is the correct level. For example, if two or more rule engines fired responsive to the same problem the confidence level is higher than if one rule engine fired.","Fault knowledge enrichment block  subscribes to hardware and software configuration information  and fault information , which is captured and published by the client module , adds available business logic and knowledge to the fault information, and publishes the knowledge enriched fault information . Thus, the fault information received by the rule engines is knowledge enriched, allowing the rule engines to make accurate determinations.","Exposure statement management block  is a state machine that manages the current state of the support entities. It subscribes to the exposure and confidence levels  and publishes an exposure set  when a support entity's exposure or confidence levels change. The exposure set contains all current exposure and confidence levels for each rule that relates to a particular support entity. Accordingly, the exposure set provides a snapshot of a support entity's exposure.","Exposure set curve fitting block  subscribes to exposure sets  and fits curves onto the exposure sets to determine known patterns in exposure values that match pre-discovered problems. If the exposure set curve fitting block determines that there is a match to a pre-discovered problem, then it publishes a service action , which is a notification of the potential problem. This block receives new curves by subscribing to new exposure curves  that are created and published by a curve creation editor block .","Exposure set risk calculation block  analyses exposure sets  and calculates a risk level for a support asset that corresponds to an exposure set. This block subscribes to the exposure sets  and to risk calculation algorithms , which it applies to the exposure sets. Based on the application of the business rules, the exposure set risk calculation block  publishes a quantified risk level and probability of being at that risk level  for the support asset.","Risk trending block  identifies trend information in the risk levels. The risk trending block subscribes to business rule thresholds  and the risk level , and publishes a service action  based on its analysis.","Availability outage block  subscribes to customer system availability events , and constructs and publishes formatted availability outage information . Availability mapping block  subscribes to the availability outage information  and to the service action  from the risk trending block , and maps the availability outage information onto the risk trend information. Any matching can increase the probability of a trending problem occurring. The availability mapping block  publishes service action  based on the matching results.","Each of the above-described functional blocks will be described in more detail below.","Although aspects of methods, systems, and articles of manufacture consistent with the present invention are depicted as being stored in memory, one having skill in the art will appreciate that these aspects may be stored on or read from other computer-readable media, such as secondary storage devices, like hard disks, floppy disks, and CD-ROM; a carrier wave received from a network such as the Internet; or other forms of ROM or RAM either currently known or later developed. Further, although specific components of the data processing system  have been described, one skilled in the art will appreciate that a data processing system suitable for use with methods, systems, and articles of manufacture consistent with the present invention may contain additional or different components.","One having skill in the art will appreciate that the services system  can itself also be implemented as a client-server data processing system. In that case, the program  can be stored on the services system as a client, while some or all of the steps of the processing of the functional blocks described below can be carried out on a remote server, which is accessed by the server over the network. The remote server can comprise components similar to those described above with respect to the server, such as a CPU, an I\/O, a memory, a secondary storage, and a display device.","The program  includes a data structure  having an entry reflecting an exposure level to failure of an entity.  depicts a more detailed diagram of the data structure . The sample data structure that is depicted in  represents an exposure level datatype output from the wrapper. The data structure comprises an exposure level to failure of the entity , a confidence level  of the exposure level, and an identifier of the entity .","As noted above, functional blocks of the program on the services system subscribe to information and publishes information via the bus . The bus is a term used for purposes of this disclosure to described an infrastructure established on the network that provides publish-subscribe capability. In the illustrative example, the bus is the intellectual-capital bus described in U.S. patent application Ser. No. 10\/691,039, filed concurrently with this application, for \u201cA Publish-Subscribe System for Intellectual Capital Management,\u201d to Michael J. Wookey, Attorney Docket No. 30014200-1117, which is incorporated herein by reference. The bus provides capability for each functional block, regardless of its location on the network, to publish and subscribe to datatypes. One having skill in the art will appreciate that the bus is not limited to the one used in the illustrative example. Another publish-subscribe network infrastructure suitable for use with methods and systems consistent with the present invention can also be implemented. Publish-subscribe network infrastructures are known in the art and will not be described in more detail herein.","Each rule engine runs one rule. A rule is introduced into the data processing system by a rule publisher program  that creates the rule  and publishes it via the bus as a rule datatype. The rule publisher program runs in the memory of the services system or another device connected to the network. In the illustrative example, the rule publisher runs in a memory of the services system . There can be any number of rule publisher programs that can publish rules to the bus from any one of the devices connected to the network.","When a user at the services system  wants to generate a rule, the user inputs into the rule publisher program a rule signature, which defines the rule and information describing the rule. The user enters the rule signature, for example, by creating an eXtensible Markup Language (XML) file, which identifies the rule inputs, the rule logic, and the rule outputs. A rule can utilize three classes of inputs: data received via the bus, rule triggers from other rules (this enables the execution of one rule to trigger the execution a subsequent rule), and side effects from other rules. As will be described in more detail below, a rule trigger indicates that a rule has started execution, and a side effect indicates that a side effect occurred in a rule engine.","The rule logic can be, for example, any algorithm, calculation, look-up function, or logic. In the illustrative example, the rule logic in one of the rule engines determines whether a disk driver Y to be used on the customer system is compatible with the customer system hard disk X. To make this determination, the rule logic compares the disk driver type to the customer system hard disk type in an If . . . Then . . . analysis. The rule logic is implemented as: if hard disk X and disk driver Y, then there is a problem. In the illustrative example, there is a problem, therefore the rule engine fires upon completion of execution.","For purposes of the illustrative example, the rule signature comprises the following information in an XML format:","rule name (rule 1)","rule version(1)","rule inputs(hard disk driver type, hard disk type)","rule outputs(fired state, exposure level, confidence level)","rule (IF (hard disk Y) and NOT (hard disk driver Y) THEN (configuration error))","A rule has three possible completed execution states: fired, not-fired, and error. Errors can occur while the rule engine is executing the rule due to, for example, lack of data, coding errors, or rule engine anomalies. Rules that run without error in the rule engine will then take on one of the other two states, fired and not-fired. If a rule exits execution early, it will be in the not-fired state. If the rule runs to completion, it will be in the fired state.","During the course of rule execution, a side effect may occur in the rule engine, such as a fact assertion, a variable setting, or a sub-rule firing. The side effect contains information that could trigger other rules or processing. The user can define the rule signature to request that the wrapper receive and publish one or more of these side effects at the completion of rule execution. The signature can also be defined to indicate whether the side effects should be published on rule fired, rule not-fired, or both, as well as indicate that a lack-of-side-effects message needs to be published if a side effect is not present.","The user can also include an applicability rule in the rule signature in addition to the rule. The applicability rule describes conditions that must be fulfilled before the rule can execute. For example, the applicability rule can fire, effecting execution of the rule, if the customer system is currently supported by the services organization.",{"@attributes":{"id":"p-0083","num":"0085"},"figref":"FIG. 5","b":["502","502","504"]},"After the rule signature is created in step , the rule publisher program issues a query message to the bus to identify a rule deployment manager that subscribes to the relevant rule name or rule type (step ). The query message includes a key identifying the rule name or rule type. The rule type identifies a category of the rule, such as a rule relating to hard disk driver software. A rule deployment manager that subscribes to the key contained in the query message issues a response message including a rule manager datatype, which contains a rule manager key that identifies, to the rule publisher program, the appropriate rule deployment manager to which to route the rule data type. The response message is then received by the rule publisher program (step ).","The rule publisher program then prepares the rule datatype, which comprises the rule name and rule version as unique keys for bus identification, the rule manager key for deployment routing, and the rule signature (step ). After the rule datatype is prepared, the rule publisher program publishes the rule datatype to the bus (step ).","Therefore, rules can be published from any system on the network that runs an instance of the rule publisher program. For example, if a services organization employee is at a customer site and identifies a new problem associated with the customer's system, the services organization employee can publish a new rule to the bus from the customer site using an instance of the rule publisher program running on the customer's system. The new rule datatype is received by an instance of the rule deployment manager, which deploys a corresponding rule engine. Accordingly, the new rule is implemented asynchronously and begins analysing input data network-wide almost instantaneously.","The rule deployment manager  identified by the rule manager key receives the rule datatype via the bus by subscribing to the rule datatype. To facilitate horizontal scalability, load balancing, and a flexible configuration, there may be multiple rule deployment managers communicating with the bus.  depicts a flow diagram illustrating the steps performed by the rule deployment manager for deploying the wrapper, which includes one or more rule engines. Although the illustrative example describes one wrapper, a plurality of wrappers can be implemented simultaneously, with each wrapper having independent rule engines. Referring to , when the rule deployment manager first starts, it knows its name but is not cognizant of other information. First, the rule deployment manager issues a query (shown as item  in ) to the bus requesting the one or more rule manager keys that will act as filters for the rules to which it will subscribe (step ). The query includes the name of the rule deployment manager. Responsive to the rule deployment manager's query, a bus administrator program  publishes a response message (shown as item  in ) including the rule manager keys that correspond to the name of the rule deployment manager. The bus administrator program does this by looking to a lookup table for the appropriate rule manager keys that correspond to the rule deployment manager name. The bus administrator program keeps a lookup table of devices and functional blocks communicating via the bus. The bus administrator program subscribes to queries for keys and publishes the corresponding keys responsive to the identity of the issuer of the query.","The rule deployment manager then receives the response message, which includes the rule manager keys (step ). After the rule deployment manager has the rule manager keys, it issues another query to the bus requesting existing rules from other rule deployment manager instantiations (step ). The query is received by any other instantiated rule deployment managers, which responsively send a response including zero or more rule datatypes that they manage. Using its assigned rule manager keys to filter the responses so as to only receive rules matching its rule manager key set, the rule deployment manager receives its rules (step ).","Then, the rule deployment manager configures a rule engine instance for each rule and places a wrapper around the rule engines (step ). The wrapper provides an integration interface to the bus that the rule engine will need to fulfill the rule. As described above, each instance of the rule engine runs one rule and is instantiated when the interface described in the wrapper is fulfilled. This model provides for the dynamic commissioning of new rules without the need for release cycles around rule sets. Further, rules fire asynchronously as data to which they subscribe becomes available. Since rules can fire other rules, methods and systems consistent with the present invention provide for horizontal scaling of rules. An illustrative example of an execution map of rule firings is shown in .","Referring to ,  depicts a more detailed view of step  for illustrating the steps performed by the rule deployment manager for initializing the wrapper and deploying the rule engines contained in the wrapper. In , first, the rule deployment manager extracts the rule and information about the rule from the rule signature, which has been received from the rule publisher (step ). As described above, the rule signature is an XML file that identifies the inputs and outputs of the rule, as well as the rule itself. In the illustrative example, the rule deployment manager extracts the following information from the illustrative rule signature:","rule name: rule 1","rule version: 1","rule inputs: hard disk driver type, hard disk type","rule outputs: fired state, exposure level, confidence level","rule: IF (hard disk X) and (hard disk driver Y) THEN (configuration error)","Then, the rule deployment manager initializes the wrapper (step ). The initialization of wrappers, in general, is known to one having skill in the art and will not be described in greater detail herein. The wrapper consistent with the present invention is responsible for semantic validation of the rule information contained in the rule signature and for providing an interface between the rule and the bus. With respect to semantic validation, the wrapper validates, for example, proper rule inputs, joining of rule inputs, and proper rule outputs.","A rule input is received by a rule by the wrapper, which subscribes to input data pertinent to the rule and passes the input data to the rule's rule engine. Similarly, once a rule engine generates an output, the wrapper publishes the output to the bus.","As described above, rules receive different types of inputs, such as input data received from the bus, rule triggers, and rule side effects. The wrapper uses a subscription model for joining related inputs as defined in the rule signature. For example, a plurality of input data that relates to a particular host or asset group is joined for delivery to a relevant rule engine. These input data relationships are defined by, for example, relationship maps, latch maps, and historical retrieval maps. The wrapper uses the relationship map to determine which inputs are joined to fulfill the rule inputs described in the rule signature, including any filters. A latch map is maintained to determine which inputs have been received, and therefore latched, and a waiting period associated with the maintenance of the latches. If the wrapper receives a rule trigger as an input, and has not received other inputs required by a rule, the wrapper can retrieve other inputs from a historical database, such as a database stored on storage , or continue processing with any latched inputs that have been received. All of this information allows the wrapper to fulfill the input data requirements for a rule without the rule's rule engine being aware of how the data arrived.","As described above, the rule signature can comprise an applicability rule associated with a rule. If an applicability rule is present in the signature, the specification of the inputs to the wrapper is a superset required to execute both the applicability rule and the rule.","On the output side, once an engine has completed processing the rule, the wrapper is responsible for capturing the execution state of the rule and rule engine, and publishing the information as designated by the rule signature to the bus. A rule can have three possible execution states: fired, not-fired, and error. The wrapper publishes one of these execution states at a rule's completion of execution. If an error is detected by the engine, the wrapper captures the error and publishes the error to the bus as a rule error datatype. The rule error datatype includes, for example, the rule name, the rule version, the relevant host\/asset group, and the date and time of the error. Further, the rule error datatype contains a field for error data describing the error.","If a rule exits early, it is in the not-fired state, and the wrapper publishes a rule fired datatype with a field indicating that the fired state is set to false, and with no other fields present. The rule fired datatype includes, for example, the rule name, rule version, the relevant host\/asset group, and the date and time of the fired\/not-fired state.","If a rule runs to completion, it is in the fired state, and the wrapper publishes a rule fired datatype with the fired state field set to true. Additionally, the wrapper populates an exposure level field and a confidence level field of the rule fired datatype responsive to information from the rule signature. Exposure level is a measure of the importance of the rule firing, where a high level of exposure suggests that a rule has detected a serious problem with the entity. The exposure level has a range, for example, of 0-100 with 100 being the highest exposure. The exposure level assigned by the wrapper for a rule engine firing is predetermined by a parameter set forth in the rule signature. Just because a rule engine outputs an exposure level of 100 does not mean that the entity has a serious problem.","To assist with determining exposure to failure, a confidence level also output. The confidence level is a measure of confidence that the exposure level is the correct level. The confidence level has a range, for example, of 0-1, with a level of zero indicating no confidence that the exposure level is correct, and a level of 1 indicating complete confidence that the exposure level is correct. The confidence level is determined based on parameters set forth in the rule signature. For example, the rule signature may provide that if a first rule and a second rule, which each relate to a same problem, each fire then there is a confidence level of 1 in a range of 0-1.","Therefore, the wrapper itself does not apply a meaning to the exposure level and confidence level fields, it just publishes them responsive to the rule signature upon a rule firing. The interpretation of these fields is left to the rule signature developers and any downstream processing that utilizes the rule fired datatype.","During the course of rule execution, a side effect may occur in the rule engine, such as a fact assertion, a variable setting, or a sub-rule firing. These side effects contain information that the wrapper could use to trigger other rules or processing. For example, the rule signature may designate that the wrapper pick up and publish one or more of these side effects at the completion of a rule execution. Further, the rule signature may indicate whether the wrapper should publish the side effect on rule fired, rule not-fired, or both, as well as designating whether a lack-of-side-effect message should be published if a side effect is not present. In the latter case, another rule or processor may want to trigger on the fact that a side effect did not occur. When publishing a side effect, the wrapper publishes a side effect datatype. The side effect datatype contains the rule name, rule version, the relevant host\/asset group, and the date and time of the side effect. Also, the side effect datatype contains a field including data about the side effect.","If there is an applicability rule associated with a rule, the wrapper sets up the rule engine to execute the applicability rule prior to executing the rule. On an applicability rule error, the wrapper publishes the error. If the applicability rule does not fire, the wrapper acts as if the input data conditions required by the rule have not been satisfied and does not execute the rule. If the applicability rule fires, then the rule begins execution.","One having skill in the art will appreciate that rules can have inputs and outputs other than those described above, and that the datatypes can have other fields.","Referring back to , after the rule deployment manager initializes the wrapper in step , it instantiates a rule engine for each rule within the wrapper (step ). Then, the rule deployment manager deploys each rule engine (step ). Deploying the rule engines means that the instantiated rule engines are enabled for performing their processing. Upon deployment, the rule engines may receive inputs, process their rule, and provide an output.","Referring back to , after the rule deployment manager implements the wrapper and deploys the rule engines in step , the rule deployment manager subscribes to any new rule datatypes that are destined for this particular rule deployment manager (step ). Similar to step , in step , the rule deployment manager uses its rule manager keys as a filter to subscribe to those rules, which are sent out by rule publishers, that are destined for this particular rule deployment manager. Then, the rule deployment manager determines whether it has received a new rule (step ). If it has received a new rule, then the rule deployment manager configures a rule engine for the rule and deploys the rule engine within the wrapper, as described above in step  (step ).",{"@attributes":{"id":"p-0110","num":"0112"},"figref":["FIG. 9","FIG. 9"],"b":["902","904"]},"After performing any required join in step , the wrapper determines the appropriate rule engine to which it will provide the input data (step ). This is performed, for example, by looking up, in a lookup table, the appropriate rule engine that corresponds to the input data. The wrapper then provides the input data to the rule engine and latches the input data as having been received (step ). By activating a latch for an input data, which identifies when the input data was received by the wrapper, this latching information can be used to determine how long it has been since the same type of input data was last received. For example, if a newly received input data is more timely than a previously received input data of the same type, then the newly received input data may be more relevant for determining an exposure.","Then, the wrapper waits for the rule engine to produce an output (step ). If the wrapper receives an output from the rule engine in step , then the wrapper prepares the output for publication (step ). As described above, the rule engine can provide outputs for rule fired, rule not-fired, rule error, and side effect. The wrapper prepares a datatype corresponding to one of these rule outputs, and populates the datatype's values and fields. For example, if the rule engine outputs that its rule has fired, then the wrapper prepares a rule fired datatype, and populates the datatype with the rule name, rule version, host\/asset group, date and time the rule fired, the fired state, the exposure level, and the confidence level. The rule name, rule version, host\/asset group, and date and time are known to the wrapper, while the fired state is provided by the rule engine. The wrapper determines the exposure level as a value from 1 to 100 as defined by the rule signature. Also, the wrapper determines the confidence level as a value from 0 to 1, based on whether related rules have also fired within a predetermined period of time. For example, if the rule fired and the same rule or another rule relating to the same asset group also fired within the past week, then the wrapper assigns a confidence level of 1. After the wrapper prepares the output datatype in step , it publishes the datatype to the bus (step ).","Referring to ,  shows a flow diagram illustrating the steps performed by the rule engine after its deployment by the rule deployment manager. First, the rule engine receives input data from the wrapper (step ). Then, the rule engine determines whether there is an applicability rule associated with the rule (step ). If there is an applicability rule, the rule engine executes the applicability rule first, before executing the rule (step ). If there is no applicability rule as determined in step , or after the applicability rule has completed processing in step , then the rule engine starts the rule's execution (step ). The rule executes by performing the logic within the rule based on the received data input. In the illustrative example, the rule receives input data including configuration data for the customer system that identifies that the customer system has hard disk driver Y and hard disk X. Accordingly, based on the rule \u201cIF (hard disk X) and (hard disk driver Y) THEN (configuration error)\u201d, the rule fires indicating a configuration error. Further, after the rule starts execution, the rule engine publishes a rule trigger to indicate that the rule has started execution (step ).","When the rule engine determines that the rule has completed processing in step , the rule engine then determines whether the rule finished executing (step ). In other words, the rule engine determines whether the rule has arrived at a fired or not-fired state. If the rule engine determines in step  that the rule has not finished executing, then the rule engine outputs an error (step ). If the rule engine determines in step  that the rule has finished executing, then the rule engine outputs any side effects from the rule (step ).","After outputting the side effects, the rule engine determines whether the rule fired (step ). If the rule did not fire, then the rule engine outputs that the rule is in the not-fired state (step ). If the rule fired, then the rule engine outputs that the rule is in the fired state (step ).","One of the datatypes to which a rule engine can subscribe is the knowledge enriched fault datatype. Faults and entity configuration data are captured by the client module, which resides for example at the customer system. The capture of faults and their publication is known to one having skill in the art and will not be described in more detail herein. The client module also captures and publishes entity configuration data, for example, by observing changes in the registry of the customer system. Each fault that is published via the bus has a type identifier, which is a classification of that fault. For example, the type identifier can identify a system failure, a driver conflict, or version conflict. The services organization can learn more about faults and their relationship to other faults over the lifetime of a product. To assist with this understanding, the fault knowledge enrichment block binds the latest services organization's knowledge, which has been published to the bus, to a received fault datatype having a matching type identifier. Then, the fault knowledge enrichment block publishes the knowledge enriched fault datatype to the bus, where it can be subscribed to by a rule engine.","Referring to , this figure depicts a flow diagram of the illustrative steps performed by the fault knowledge enrichment block. In , the fault knowledge enrichment block first receives a fault datatype to which it has subscribed (step ). The fault datatype includes a type identifier, which is read by the fault knowledge enrichment block to determine the fault type (step ). Knowing the type identifier, the fault knowledge enrichment block retrieves, from the services system secondary storage, any stored knowledge or exposure levels that are also identified by that type identifier. For example, if a services person previously encountered a problem using hard disk driver Y with hard disk X, the services person may have published information on the bus that identifies the problem. The fault knowledge enrichment block would have subscribed to that publication and stored the report on the services system secondary storage classified by its type identifier.","Then, the fault knowledge enrichment block retrieves any stored knowledge or exposure levels classified by the same type identifier as the fault (step ). If any stored knowledge or exposure levels are retrieved, then the fault knowledge enrichment block supplements, or knowledge enriches, the fault by adding the knowledge or exposures levels as fields in the fault datatype (step ). After the fault is knowledge enriched, the fault knowledge enrichment block publishes the knowledge enriched fault to the bus (step ). The published knowledge enriched fault is received, for example, by a rule engine, where it is used for a rule processing.","The exposure state management block  operates as a state machine that manages the states of all rules that have fired for each entity, such as, each support asset or asset group. Each fired rule is associated with an exposure value. The exposure state management block can therefore maintain an exposure set for each entity, where an exposure set is the group of exposure and confidence values resulting from each fired rule for a particular entity. When any exposure or confidence value changes for an entity, the exposure state management block then publishes the entire updated exposure set for that entity. Thus, the exposure state management block continually notifies the bus of changes in exposure or confidence values for each support asset and asset group.",{"@attributes":{"id":"p-0120","num":"0122"},"figref":["FIG. 12","FIG. 12"],"b":["1202","1204","1206"]},"The exposure set's data structure includes, for example, the support asset\/group asset name and an array having values for each relevant rule name and the rule's corresponding exposure value and confidence value. An illustrative example of an exposure set for a support asset is shown below:",{"@attributes":{"id":"p-0122","num":"0124"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Support Asset id"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"91pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Rule id 1","Exposure value","Confidence value"]},{"entry":["Rule id 2","Exposure value","Confidence value"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"One having skill in the art will appreciate that the exposure set can have additional table entries for additional rules or additional values. Once the exposure set is retrieved, the exposure state management block either updates the exposure and confidence values corresponding to a rule existing in the exposure set or adds a new entry with a new rule and its corresponding exposure and confidence values (step ). Then, the exposure state management block stores the updated exposure set in the secondary storage (step ), and then publishes the updated exposure set to the bus as an exposure set datatype (step ).","The exposure set can be used by downstream processing. For example, the exposure set curve fitting block  fits known problem-related exposure plotted curves onto exposure sets and assesses with a probability if a known problem has occurred or is about to occur.  depicts a block diagram illustrating the steps performed by the exposure set curve fitting block for analyzing a received exposure set. In , first, the exposure set curve fitting block receives an exposure set via the bus (step ). To receive the exposure set, the exposure set curve fitting block subscribes to the exposure set datatype. Then, the exposure set curve fitting block plots a curve data set comprising the (exposure level*confidence level) for each rule in the exposure set (step ).","Once the exposure set plot is generated, the exposure set curve fitting block compares the plot to known curves (step ). To do this, the exposure set curve fitting block retrieves known curves, one at a time, from the services system secondary storage, and executes a numerical curve fitting algorithm to look for matching problem curves. Numerical curve fitting algorithms are known to one having skill in the art and will not be described in greater detail herein. If the exposure set curve fitting block determines that there is a match between the exposure set curve and one of the known curves (step ), then the exposure set curve fitting block calculates a probability that the match presents a potential problem (step ). The probability has a value from 0 to 100 based on how close the exposure set curve matches the known curve. If the exposure set curve has no points that match the points of the known curve, then the probability of a hit is 0. However, if each point of the exposure set curve matches each point of the known curve, then the probability is 100.","The exposure set curve fitting block then compares the calculated probability to a predetermined threshold to determine whether the probability has a great enough value to cause concern (step ). For example, if the probability has a value greater than a threshold value of 80 percent in step , then the exposure set curve fitting block determines that there is a likely a problem and publishes a service action to the bus (step ). Each known curve has a service action associated with the known curve, which service action is a message that provides a textual description of the problem and an identifier of the problem. Since the exposure set curve fitting block knows the identity of the known curve, it retrieves the corresponding service action from the secondary storage and publishes the service action to the bus. Therefore, the services organization can asynchronously identify if a problem has occurred or is about to occur based on historical trends.","New curves are inputted into the system using a curve creation editor block , which is located in the memory of the services system. Alternatively, the curve creation editor block can be located in the memory of another device on the network. The curve creation editor block can be used, for example, to create new known curves for problems that are identified outside of the realm of the exposure set curve fitting block process. For example, if a services person identifies a services problem that is associated with an exposure set for a certain support asset, the services person can use the curve creation editor block to generate a new known curve that can be used in the future by the exposure set curve fitting block. At the time that the services person generates the new known curve, the services person can also create a service action corresponding to the new known curve.",{"@attributes":{"id":"p-0128","num":"0130"},"figref":["FIG. 14","FIG. 14"],"b":["1402","1404","1406"]},"The curve creation editor block then publishes the new known curve with its service action in a new curve datatype to the bus (step ). The exposure set curve fitting block receives the new curve datatype by subscribing to the datatype and stores the new known curve and its service action in the secondary storage of the services system for future use.","In addition to managing exposure to failure of computer-based systems, methods and systems consistent with the present invention also manage the risk of failure. The exposure set risk calculation block calculates a risk level for an entity (i.e., a support asset or asset group) based on an exposure set for that entity. This block takes a risk calculation algorithm and applies it to the exposure set, and publishes the risk level and probability of being at that risk level. The risk calculation algorithm is received in a risk calculation algorithm datatype to which the exposure set risk calculation block subscribes, and is used until a new algorithm is received. Therefore, the algorithm can be revised and improved over time.","The risk calculation datatype is created and published to the bus using a risk calculation editor block . The risk calculation editor block receives user input including the risk calculation algorithm and creates the risk calculation datatype, which includes an identifier and risk calculation algorithm. Then, the risk calculation editor block publishes the risk calculation algorithm datatype to the bus.",{"@attributes":{"id":"p-0132","num":"0134"},"figref":["FIG. 15","FIG. 15"],"b":["1502","1504"]},"Referring to , this figure depicts a flow diagram illustrating the steps performed by the exposure set risk calculation block for executing the risk calculation. In , first, the exposure set risk calculation block receives an exposure set by subscribing to the exposure set datatype (step ). Then, the exposure set risk calculation block retrieves from the secondary storage a mitigating factor corresponding to the entity associated with the exposure set (step ). The mitigating factor is a constant factorial that is used in the risk calculation algorithm to mitigate the risk factor for the associated entity, and is based on known topological factors. For example, if an asset group has a history of having a lower probability of encountering problems, a support asset within the asset group has a higher mitigating factor associated with it. For the illustrative example, sample mitigating factors have a value in a range of 0-10 and are shown below. One having skill in the art will appreciate that the mitigating factors can have values in a range other than 0-10.",{"@attributes":{"id":"p-0134","num":"0136"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Factor:","Measure:"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Asset Group 120 non-domain","1.3"]},{"entry":[{},"Asset Group 150 non-domain","1.4"]},{"entry":[{},"Support Asset 140","2.0"]},{"entry":[{},"Asset Group 120 domain","1.5"]},{"entry":[{},"Asset Group 150 domain","1.7"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"After the mitigating factor is retrieved in step , the exposure set risk calculation block executes the risk calculation algorithm using the retrieved mitigating factor and the exposure set information (step ). In the illustrative example, the following algorithm is used:\n\nRisk Level=((Sum of Exposure Values*Sum of Confidence Values)\/Number of Exposures)\/Mitigating Factor\n","Accordingly, in the illustrative example, if there is one exposure value in the exposure set, and the mitigating factor has a value of 1.5, then\n\nRisk Level=((100*1.0)\/1)\/1.5)=66.7.\n","One having skill in the art will appreciate that other algorithms can be used for the risk level calculation. Further, as described above, the algorithm can be replaced with new algorithms. After the risk level is calculated, the exposure set risk calculation block publishes the risk level in a risk level datatype to the bus (step ).","The exposure set risk calculation block can also calculate a difficulty value associated with fixing an entity to reduce its exposure level and a cost to perform the fix, and include these items in the risk level datatype. To calculate the difficulty value, the exposure set risk calculation block can, for example, look up the difficulty value in a look-up table. The look-up table contains one or more difficulty values associated with corresponding problems. The problems can be identified, for example, by a rule identifier or an entity name. For example, the look-up table can comprise an entry with an identifier of Rule 1, which is associated with a hard disk driver conflict problem, and a difficulty value of 10 in a range of 0 to 100. Further, the look-up table can also include a cost to repair a respective problem. In the above-described example, the look-up table can include entries for the service organization's fee and product costs associated with changing the hard disk driver. Based on these calculated risk-related values, a customer can determine whether they can continue to operate their system at the present risk level or whether they should repair their system.","To further assist in making this decision, the published risk levels can be analyzed for trends to predict problems. Typical trending techniques compare a single data stream against a threshold, and signal a problem if the data stream crosses the threshold. This can lead to false alerts when the data stream oscillates about the threshold.","The risk trending block  consistent with the present invention trends the risk level associated with an entity by calculating a moving average of the risk level for that entity. To compute the moving average, an incoming stream of exposure levels is compared to a known good stream. If there is a significant fluctuation across exposure levels that is not considered within normal fluctuations, then the risk trending block publishes a service action datatype.","To perform the moving average calculation, the risk trending block utilizes a training engine, such as the one described in U.S. patent application Ser. No. 10\/690,917, filed concurrently with this application, for \u201cNearest Neighbor Approach for Improved Training of Real-Time Health Monitors for Data Processing Systems,\u201d to Michael J. Wookey, et al., which is incorporated herein by reference. Unlike typical trending techniques that analyse a single data set, the training engine can receive multiple data streams and analyse them against a known good state.","In order to obtain a known good stream that can be used for comparison to the incoming data streams, the risk trending block has three modes of operation: training mode, library mode, and observation mode. In the training mode, the risk trending block is trained to recognize the exposure levels of a typical entity in a class. The data stream obtained for a typical entity is referred to as a trained signal set. While in the library mode, the risk trending block associates the trained signal set with a hardware and software configuration, and stores this information in the services system as a signal library set. Then in observation mode, the risk trending block measures incoming current data streams against a nearest match of the signal library sets.",{"@attributes":{"id":"p-0143","num":"0145"},"figref":["FIG. 17","FIG. 17"],"b":["1702","1702","1704"]},"The risk trending block then subscribes to exposure sets for the identified support assets (step ), and supplies the received exposure sets to the training engine (step ). Exposure sets are continued to be received by the risk trending block until it determines that it has completed receiving exposure sets (step ). This can be determined, for example, by the risk trending block receiving a user input requesting to exit the training mode. Alternatively, the risk trending block can stop receiving exposure sets after a predetermined number of exposure sets have been received. If the risk trending block determines in step  that it has not completed receiving exposure sets, then it determines whether the risk level for one of the identified support assets has increased (step ). If the risk level has increased, then the risk trending block stops subscribing to exposure sets for that support asset (step ). If the risk level has not increased, then the risk trending block returns to step  to receive more incoming exposure sets.","Once the risk trending block determines in step  that it is finished receiving exposure sets, then it retrieves the trained signal set for each identified support asset from the training engine and publishes the trained signal sets (step ). Each trained signal set represents a good risk level for that support asset.","After the risk trending block has generated the trained signal sets, as described above with reference to , the risk trending block is placed in library mode to associate hardware and software configuration information with the trained signal set. The risk trending block can be placed in library or observation mode automatically upon completion of precessing in the previous mode or manually by a user. In the library mode, for each support asset, the risk trending block creates a signal library entry that includes the trained signal set and its corresponding hardware and software configuration information.  depicts a flow diagram showing the illustrative steps performed by the risk trending block in the library mode. In , the risk trending block first subscribes to and receives a new trained signal set (step ). After a trained signal set is received in step , the risk trending block subscribes to and receives the hardware configuration datatype and software configuration datatype for the support asset identified in the trained signal set (step ).","Once the hardware and software configuration information is received, the risk trending block creates a signal library entry that includes the trained signal set, the hardware configuration and the software configuration (step ). The block then publishes the signal library entry to the bus (step ).","After the risk trending block completes processing in the library mode, the risk trending block is placed in observation mode. In the observation mode, current exposure sets are measured against a match or nearest match from the signal library entries.  depicts a flow diagram showing the illustrative steps performed by the risk trending block in observation mode. Referring to , the risk trending block first subscribes to and receives new exposure sets (step ) and new signal library entries (step ). For each support asset identified in the exposure sets, the risk trending block then determines whether there is a matching signal library entry (step ). If there is a match in step , the risk trending block provides the exposure set and signal library entry to the training engine (step ). Otherwise, the risk trending block matches the exposure set to a nearest hardware and software configurations among the signal library entries (step ) and then provides the nearest match exposure set and signal library entry to the training engine in step .","The training engine compares the received exposure set to the signal library entry. If there is a predetermined difference between the exposure set and the signal library entry, then it calculates a probability of an existing problem. For example, if the exposure set varies from the signal library entry by more than 10 percent across all entries, then there is a certain probability of an existing problem. The risk trending block obtains the results of the training engine analysis and identifies whether the training engine found a potential problem (step ). If there is a potential problem, then the risk trending block publishes a service action identifying the potential problem (step ).","In addition to analysing fault information and configuration data, methods and systems consistent with the present invention also consider the availability of entities when managing exposure to failure and risk. The availability outage calculation block  calculates the availability of an entity based on received availability events. For purposes of this disclosure, the term availability event is used to cover events, which can be caught, that cause the entity to go out of service. Some illustrative examples of such events are, for example, a reboot, a panic, or a hardware failure.",{"@attributes":{"id":"p-0151","num":"0153"},"figref":["FIG. 20","FIG. 20"],"b":["2002","240","140"]},"After the availability outage calculation block receives the event in step , the availability outage block calculates the availability outage (step ). The availability outage calculation used for the illustrative example is as shown below, however, a different calculation can be used.\n\nAvailability Outage=(Downtime seconds\/Total detection period)*100, where downtime is non-intentional\n","After the availability outage is calculated in step , the availability outage calculation block publishes the availability outage in an availability outage datatype to the bus (step ).","The availability mapping block  subscribes to availability outages and to service actions, which are published by the risk trending block, and compares availability outage history to risk trend information. A match can increase the probability of a trending problem occurring. For example, if a support asset was unavailable at specific times and the risk trending block published service actions relating to that support asset at those times, then there is a probability of a trending problem occurring.",{"@attributes":{"id":"p-0155","num":"0157"},"figref":["FIG. 21","FIG. 21"],"b":["2102","2104","2106","2108"]},"Having compiled the availability outage and risk trending information for each entity, the availability mapping block compares the availability outages to the service actions at corresponding times for a particular entity (step ). The availability mapping block performs this operation when a new availability outage or service action is received. If there is a match in mapping of the two plots, then the availability mapping block publishes an augmented service action that identifies the increased probability of a trending problem occurring (step ).","Therefore, unlike typical risk management systems that are run on demand to perform discrete checks during a product installation and that use static knowledge, methods and systems consistent with the present invention asynchronously monitor the correctness of computer systems using dynamic rule engines, which are asynchronously deployable.","The foregoing description of an implementation of the invention has been presented for purposes of illustration and description. It is not exhaustive and does not limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practicing the invention. For example, the described implementation includes software but the present implementation may be implemented as a combination of hardware and software or hardware alone. The invention may be implemented with both object-oriented and non-object-oriented programming systems. The scope of the invention is defined by the claims and their equivalents."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate an implementation of the invention and, together with the description, serve to explain the advantages and principles of the invention. In the drawings,",{"@attributes":{"id":"p-0028","num":"0030"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0029","num":"0031"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0030","num":"0032"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0031","num":"0033"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0032","num":"0034"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0033","num":"0035"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0034","num":"0036"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0035","num":"0037"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0036","num":"0038"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0037","num":"0039"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0038","num":"0040"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0039","num":"0041"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0040","num":"0042"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0041","num":"0043"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0042","num":"0044"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0043","num":"0045"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0044","num":"0046"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0045","num":"0047"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0046","num":"0048"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0047","num":"0049"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0048","num":"0050"},"figref":"FIG. 21"}]},"DETDESC":[{},{}]}
