---
title: Data processing, analysis, and visualization system for use with disparate data types
abstract: Furthermore, the user may explore the information contained in sets of records and their associated attributes through the use of interactive 2-D line charts and interactive summary miniplots.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06990238&OS=06990238&RS=06990238
owner: Battelle Memorial Institute
number: 06990238
owner_city: Richland
owner_country: US
publication_date: 19990930
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION","CONCLUSION"],"p":["The following identified U.S. patent applications are relied upon and are incorporated by reference in this application:","U.S. patent application Ser. No. 09\/409,260, entitled \u201cMETHODS AND APPARATUS FOR EXTRACTING ATTRIBUTES OF GENETIC MATERIAL,\u201d filed on the same date herewith by Jeffrey Saffer et al.;","U.S. patent application Ser. No. 08\/695,455, entitled \u201cTHREE-DIMENSIONAL DISPLAY OF DOCUMENT SET,\u201d filed on Aug. 12, 1996; and","U.S. patent application Ser. No. 08\/713,313, entitled \u201cSYSTEM FOR INFORMATION DISCOVERY,\u201d filed on Sep. 13, 1996.","The disclosures of each of these applications are herein incorporated by reference in their entirety.","This invention relates to data mining and visualization. In particular, the invention relates to methods for analyzing text, numerical, categorical, and sequence data within a single framework. The invention also relates to an integrated approach for interactively linking and visualizing disparate data types.","A problem today for many practitioners, particularly in the science disciplines, is the scarcity of time to review the large volumes of information that are being collected. For example, modern methods in the life and chemical sciences are producing data at an unprecedented pace. This data may include not only text information, but also DNA sequences, protein sequences, numerical data (e.g., from gene chip assays), and categoric data.","Effective and timely use of this array of information is no longer possible using traditional approaches, such as lists, tables, or even simple graphs. Furthermore, it is clear that more valuable hypotheses can be derived by simultaneous consideration of multiple types of experimental data (e.g., protein sequence in addition to gene expression data), a process that is currently problematic with large amounts of data.","Visualization-based tools for analyzing data are discussed in, for example, Nielson G M, Hagen H, Muller H, eds., (1997) , IEEE Computer Society, Los Alamitos); (Becker R A, Cleveland W S (1987) , Technometrics 29:127\u2013142; Cleveland W S (1993) , Hobart Press, Summit, N J); (Bertin J (1983) , University of Wisconsin Press, London; Cleveland W S (1993) , Hobart Press, Summit, N J). These tools have focused largely on data characterization, and have provided limited user interactivity. For example, the user may gain access to underlying information by selecting an item with a pointer.","These tools, however, have significant drawbacks. Although current tools can handle certain data types (e.g., text, or numerical data), they do not allow a user to interact with disparate data types (i.e., text, numerical, categoric, and sequence data) within an integrated data analysis, mining, and visualization framework. Furthermore, these tools do not allow a user to interact well between different visualizations in the manner required to gain knowledge.","What is needed, therefore, is a tool that allows a user to analyze, mine, link, and visualize information of disparate data types within an integrated framework.","Systems and methods consistent with the present invention aid a user in analyzing large volumes of information that contain different types of data, such as textual data, numeric data, categorical data, or sequential string data. Such systems and methods determine and display the relative content and context of information and aid in identifying relationships among disparate data types.","More specifically, one such method defines a uniform data structure for representing the content of an object of different data types, selects attributes of different objects of a variety of different data types that may be represented in the uniform data structure and operates on the selected attributes to produce first representations of the objects in correspondence with the uniform data structure.","The data types may include numeric, sequence string, categorical and text data types. An index may be produced that includes second representations of non-selected attributes of a particular object and that associates the non-selected attributes with a particular first representation. The first and second representations may be vector representations. A first set of the selected attributes associated with a first set of objects may be used to determine the relationships among the first set of objects of a particular data type and non-selected attributes associated with the first set of selected attributes may be used to correlate objects represented by the first set of selected attributes with a second set of objects represented by a second set of selected attributes. The first and second set of objects may be displayed in first and second windows on a display screen and the second set of objects that corresponds to the selected object or objects may be highlighted.","A method consistent with the present invention identifies relationships among different visualizations of data sets and includes displaying first graphical results of a first type analysis performed on selected attributes of a first set of objects and displaying second graphical results of a second type analysis performed on selected attributes of a second set of objects. Certain objects represented in the first graphical results may be selected and corresponding objects represented by the second graphical results that correspond to the certain objects are highlighted. The highlighting may be based on attributes not used for creating the first graphical results.","Another aspect of the present invention is directed to a system and a method for visualization of multiple queries to a database that includes selecting multiple queries to a database, querying records in the database based on the multiple queries, creating a query matrix indexed based on the selecting, and populating the query matrix based on the querying.","Another method consistent with the present invention interactively displays records and their corresponding attributes and includes generating a first 2-D chart for a first record, where at least two attributes associated with the first record are shown along one axis, and the values of the attributes are shown along the other axis. Input is received from a user selecting the first record on the first 2-D chart and an index is analyzed to determine if the first record is shown in another view. If the first record is shown in another view, the visual representation of the first record is altered in the another view based on the user input.","Another method consistent with the present invention interactively displays records and their corresponding attributes and includes generating a 2-D scatter chart that depicts a plurality of records. A 2-D line chart is generated for a group of records contained in a portion of the 2-D scatter chart. At least two attributes associated with the group of records are shown along one axis, and a statistical value for each of the at least two attributes is shown along the other axis. A 2-D line chart is superimposed at a location on the 2-D scatter chart that is based on the location of the group of records on the 2-D scatter chart.","Reference will now be made in detail to one or more embodiments of the present invention as illustrated in the accompanying drawings. The same reference numbers may be used throughout the drawings and the following description to refer to the same or like parts.","A. Overview","Systems and methods consistent with the present invention are useful in analyzing information that contains different types of data and presenting the information to the user in an interactive visual format that allows the user to discover relationships among the different data types. Such methods and systems include high-dimensional context vector creation for representing elements of a dataset, visualization techniques for representing elements of a dataset including methods for indicating relationships among objects in a proximity map, and interaction among datasets including linking the visualizations and a common set of interactive tools. In an embodiment, the interactions, regardless of data type, among the visualizations and the common set of tools for the interactions is enabled by maintaining meta data, as discussed herein, in a common set of file structures (or database).","Methods and systems consistent with the present invention may include various visualization tools for representing information. A tool for visualizing multiple queries to a database is provided. In another visualization tool, if a first record of a 2-D chart of one view is shown in a second view, the visual representation of the first record is altered in the second view based on the user input. In another visualization tool, a 2-D line chart is superimposed at a location on a 2-D scatter chart that is based on the location of a group of records on the 2-D scatter chart. Other tools consistent with the present invention may be used in conjunction with the methods and systems described herein.","As used herein, a record (or object) generally refers to an individual element of a data set. The characteristics associated with records are generally referred to herein as attributes. A data set containing records is generally processed as follows. First, the information represented by the records (including text, numeric, categoric, and sequence\/string data) are received in electronic form. Second, the records are analyzed to produce a high-dimensional vector for each record. Third, the high-dimensional vectors may be grouped in space (i.e. a coordinate system) to identify relationships, such as clustering among the various records of the data set. Fourth, the high-dimensional vectors are converted to a two-dimensional representation for viewing purposes. The two-dimensional representation of the high-dimensional vectors is generally referred to herein as \u201cprojection.\u201d Fifth, the projections may be viewed in different formats according to user-selected options, as shown by the four views (, , , and ) on display monitor  in .","Systems and methods consistent with the present invention enable a user to select a record in view  and cause the corresponding record in another view to be highlighted. For example, selecting a particular record in view  causes the corresponding records  and  to be highlighted in views  and , respectively. The highlighted points may represent different analyses performed on the same records or may represent different data types associated with the records.","B. Architecture",{"@attributes":{"id":"p-0058","num":"0056"},"figref":"FIG. 2","i":"a ","b":["200","210","280","210"]},"Memory unit  contains databases, tables, and files that are used in carrying out the processes associated with the present invention. CPU , in combination with computer software and an operating system, controls the operations of the computer system. Memory unit , CPU , and other components of the computer system communicate via a bus . Data or signals resulting from the processes of the present invention are output from the computer system via an input\/output (I\/O) interface .","The computer program modules and data used by methods and systems consistent with the present invention include visualization set up programs , processing programs , meta data files , interactive graphics and tools programs , and an application interface . The visualization set up programs  determine the name to be used for a collection of records identified by a user, determine the formats to be used for reading files associated with the records, identify formatting conventions for storing and indexing the records, and determine parameters to be used for analysis and viewing of the records. The processing programs  transform the raw data of the identified records into meta data, which in turn is used by the interactive visualization tools. The meta data files  include the results of statistical feature extraction, n-space representation, clustering, indexing and other information used to construct and interact among the different views. The interactive graphics and tools programs  enable the user to explore and interact with various views to identify the relationships among records. The application programming interface (API)  enables the components , , , and  to exchange and interface information as needed for use in analysis and visual display.","The visualization setup programs  further include a data set editor  and a view editor . The processing programs  further include vector programs , cluster programs , and projection programs . The meta data files  are a subset of databases and files .","The data set editor  enables the user to define the collection of records (i.e., a data set) to be analyzed, identifies the data type, and creates directories for use in organizing the data of the data set. The view editor  sets up the user's raw data for viewing by the interactive tools and graphics. Vector programs  create high-dimensional context vectors that represent attributes of the records of the data set. Cluster program  groups related records near each other in a given space (cluster) to enable a user to visually determine relationships. Projection programs  convert high-dimensional representations of the records of a data set to a two-dimensional or three-dimensional representation that is used for display. The databases and files  contain data used in conjunction with the present invention, such as the meta data .","C. Architectural Operation","1. Data Collection (Data Set Editor)",{"@attributes":{"id":"p-0064","num":"0062"},"figref":"FIG. 3","b":["212","302","304","310","312","314","316","316","320"]},"If the validation process determines that the data is sequence data, such as genome sequence data (step ), the process determines whether the sequence data is in FastA file format (step ) or whether the sequence data is in a SwissProt file format (step ). An example FastA input file is provided in Appendix B. The operations and data associated with processing sequence data is discussed in more detail in U.S. patent application Ser. No. 09\/409,260, now issued as U.S. Pat. No. 6,898,530, entitled \u201cMethods and Apparatus for Extracting Attributes of Genetic Material\u201d filed on the same day herewith by Jeffrey Saffer, et al. As stated in that patent, the steps for processing sequence data may comprise:\n\n","If the sequence data is not in either of these formats, an error message is generated (step ). If, however, the data is either a FASTA file (step ) or a SwissProt file (step ), the appropriate formats and delimiters, as discussed herein, are determined to be used for the respective FASTA file or SwissProt file (step ). After the appropriate format\/delimiters for the data type are determined (step ), the corresponding format file\/record delimiters are established (step ). The format file\/record delimiters specify the valid formats for reading the files and identifies the meta data files that are to be used to for subsequent processing of the data set as discussed herein.","A file directory  is created for storing the meta data files associated with the data set (step ). The file directory  includes a document catalog file (DCAT)  and a data set properties file . The DCAT file  is used as a master index for all records in the data set. The indexes stored in the DCAT file are used to integrate the information associated with the various views selected for the data set. For example, the DCAT file  contains indexes that associate all the data of a data set with a particular view, although only a subset of the data set is used to create the view. The properties file  is also produced and stored in the file directory and contains information about the source data files for the view, including their type (corpus type), the number and full path (location) for the source files, the format used, and the date created. In addition, the properties file keeps track of subsequently processed views including the subdirectory where those views reside. An example properties file is provided in Appendix A.",{"@attributes":{"id":"p-0068","num":"0069"},"figref":"FIGS. 4","i":["a ","b "],"b":["4","212","212","400","400","410"]},"The user may enter a name for the data set in a field  and may specify the data set type as indicated by the selection options , such as array data, protein or nucleotide sequences, or text. The source of this data set may be specified in the field  as indicated by the directory and subdirectory specification . The user may select the add, view, or delete options  to perform the function indicated by the name on the data set source. The user may save the data as indicated by the option  or continue to a new view as indicated by the option .","By selecting the format tab , the user may specify how fields contained within the source file are delimited by selection of a field delimiter option . The field delimiter options illustrated include an option to delimit the field by a colon, comma, space, tab, or a user defined delimiter.","2. Analysis and View Setup (View Editor)",{"@attributes":{"id":"p-0072","num":"0073"},"figref":["FIG. 5","FIG. 6"],"i":["a ","a"],"b":["216","604","610","630","660","680","690"]},"The user is first requested to name the view (step ) and also is requested to identify the directory locations of the source files (step ). The user is requested to specify the format of the source data (step ). is a screen display showing the options presented to a user when the format tab  is selected. The user may provide in the format file field , a file to use for formatting the view such as medline 31.fmt. The user may also specify a stop words file such as the default text stop file shown in the field . This stop words file is a list of words that the text engine will ignore during analysis. The user may input a file to specify the default punctuation of the file as indicated by the default.punc file indicated in the field . The punctuation file tells the text engine how to handle non-alphabet characters. For each of the files requested, the user may use the default file specified by the system or choose another. The user may select or view any of the files of the format screen of by selecting the select option  or the view option .","The user is also requested to provide preparation parameters (step ). The processes associated with step  are discussed in more detail in . The user may specify vector creation, cluster, and projection parameters to be used in constructing a view (steps , , and , respectively). The projection parameters include cluster cohesion, cluster area, and cluster spread. Vector creation and clustering parameter processes are discussed in more detail in and , respectively.","Referring to , the view editor processes are discussed. The view editor first checks the data type (step ) by evaluating whether the data is sequence data (step ). If the data is sequence data, sequence specific preparation information is requested (step ), such as requesting number and length of n grams, SEG parameters, substitution filter values, and motif pattern file parameters (step ). If the data is not sequence data (step ), the process determines whether the data is numeric data (step ). If the data is not numeric data, no preprocessing or preparation information is required for text information (step ). If the data is numeric data, a display screen that requests numeric data and preparation information from a user (step ) is presented. The numeric preparation data request may include column\/row specifications, operation sets, and clustering fields (step ).",{"@attributes":{"id":"p-0076","num":"0077"},"figref":["FIG. 5","FIG. 2"],"i":"c ","b":["216","216","551","552","553","554"]},"If the data is not sequence data (step ), the view editor determines whether the data is text data (step ). If the data is text data, text specific text engine parameters are requested from the user (step ) such as the text engine parameters discussed above (step ). If the data is not text data (step ), no user specified parameters are needed and default parameters may be used (step ). The text engine parameters may be used if desired (step ).",{"@attributes":{"id":"p-0078","num":"0079"},"figref":"FIG. 5","i":"d ","b":["216","561","562","562","563","564","562","565","566","567","565","568"]},"Referring to , when the preparation tab  is selected, the user is presented with a data specification option , an operation set option  and a clustering selection option . The user may enter a value for the columns in the field . For the data set specified, the user may identify the type of data, such as numeric data, categorical data, sequence data, or text data by selecting a data type . The user may specify the columns  in which that data type is located and may specify a field name for that specific data as indicated under the field name . A predefined selection field  may be used to specify the types of data for the field name and columns provided.","A user may perform any number of mathematical manipulations on the numeric data (one or more manipulations or transformations of the data is referred to as an operation set). These options include various logarithmic operations, methods for normalizing data, methods for filing missing data points, and all algebraic functions. Referring to , for example, the reciprocal or the value for each numeric data item may be requested and then the logarithm taken for that reciprocal, creating a new field  called Operation Set.",{"@attributes":{"id":"p-0081","num":"0082"},"figref":"FIG. 6","i":"e ","b":["650","652","1","1"]},"Referring to , for a sequence, the user may have motifs\/n-grams, complexity filtering, exclusions, and amino acid substitutions options from which to select. Operation on or with sequence data is discussed in more detail in U.S. patent application entitled \u201cMethod and Apparatus for Extracting Attributes from Sequence Strings and Biopolymer Materials\u201d filed concurrently herewith and is expressly incorporated herein by reference. If the user wants to represent the sequence as a high-dimensional vector based on the occurrence of functional or structural motifs, a file is specified which defines those motifs. The user can have that vector based on the number of occurrences of each motif or, if desired, have the vector based on a binary format (the motif is either there or not) by checking the single motif output option. Alternatively, or in addition, the user may specify any combination of overlapping n-grams to be created to represent the sequence in field . The user also has the option to specify whether the n-gram should be included based on number of occurrences within the sequence. If neither motif nor n-gram options are selected, the program will analyze the text (e.g., annotations) associated with the sequence records. The complexity filtering options provide the user the ability to include the entire sequence dr eliminate regions of low or high complexity, for example, using the public domain tool SEG. The user may also specify certain records to be excluded, for example, based on sequence length, or title, by selecting options in the exclusion interface. Finally, the use of amino acid or nucleotide substitutions can be defined in the Amino Acid Substitution interface.","Referring to , the options provided to the user for processing data is illustrated. The user may use a sliding scale to specify the magnitude or weight to give to associations as indicated by the association field . The user may enter the number of topics to be used in the field . The topics are the features that describe the vectors. For text, these are the vocabulary words that best describe the thematic content of the records; for sequences, the topics are the n-gram vocabulary words that best distinguish one sequence from another. The user may specify the requested number of cross terms as indicated in the field . Cross terms are the vocabulary words that are not topics. The user may specify the number of times that the topics may appear in a record before being identified as a topic and an upper limit may be included as well as indicated in the fields and . In the field and , the user may specify the number of times that the terms must appear in other documents by specifying a lower limit in field and an upper limit in field . These fields are used as filtering fields for processing. The topicality method for is \u2018Specify the settings by the number of terms.\u2019","Referring to , the topicality method for the processing option is specified as \u2018Specify the settings by threshold.\u2019 The user may use the sliding scale field  to specify the number of associations needed. The user may use a sliding scale input for identifying the minimum topicality for topics weight and the minimum topicality for cross terms as indicated by the fields  and , respectively. The user may specify upper and lower limits for defining the number of appearances to trigger identification for topics and cross terms, as indicated by the fields , , , ","Referring to , the user may specify a topicality method that automatically calculates the setting for the view all indicated in the display screen illustrated. The user may use a sliding scale selection field that specifies the weights of association as indicated by the field . Referring to , the user may specify the weights of association for the topicality method that automatically calculates the settings with emphasis on local topics.","Referring to , when a user selects the clustering tab , the user may specify a clustering method such as hierarchical or k-means. When hierarchical clustering is chosen, the user may select an option to compute clusters based on coherence. The user may indicate the number of clusters, and the cluster coherence. The user may also select whether to correlate the order after clustering.","Referring to , the graphical interface used for specifying the parameters of the k-means is illustrated. The user may specify the number of clusters or the number of iterations to be used for the k-means. When k-means is used, the user may select the cluster seeding parameters such as using random seeding or using dimensional seeding. The seeding may also occur by using the computer's internal clock (system time) to seed random number generator. The user may alternatively specify a value for the random generator seed.","Referring to , the user may select the type of projection to use by selecting the projection tab . The user may select cluster cohesion, cluster area, or cluster spread. When the user selects either of these options, the user may use a weighted scale for each of the options to identify the weight to be associated with each projection option.","3. Common Formatting, Vector Creation, and Index Creation",{"@attributes":{"id":"p-0090","num":"0091"},"figref":"FIG. 2","i":["b ","a","b. "],"b":["222","222","222"]},"Referring to , the general processes performed by the processing programs are discussed. Certain types of data, such as sequence data, is preprocessed (step ) prior to data being input into the text engine. The sequence data is modified to a form that is acceptable to the text engine for generating the high-dimensional context vectors.","High-dimensional context vectors are created based upon the attributes of the objects or records to be used for a view and vector indices that correspond to the particular view are created and stored in a vector file associated with the data set (step ). The vectors are clustered using known clustering programs based upon information from the vector files (step ). The cluster assignment file (.hcls), as discussed below, is created (step ). Two dimensional coordinates of the records and centroids are calculated for creating a two dimensional projection of the clustered vectors (step ). Two dimensional coordinate files are created (.docpt) for each document.","i. Vector Creation and Formatting","The visualizations discussed herein are based on high-dimensional context vector representations of the data. Thus, each type of data is represented in that manner. For purely numeric data, the vector representation is simply the values associated with each record attribute. For categorical data, the vector representation can be based on any method that translates categorical values or the distances between values as a number. For text data, the vector representation can be derived by latent semantic indexing as known to those skilled in the art or by related methods, such as described in U.S. patent application Ser. No. 08\/713,313, entitled \u201cSystem for Information Discovery,\u201d filed on Sep. 13, 1996 (now issued as U.S. Pat. No. 6,772,170). As stated in that patent, the steps for processing text data may comprise:\n\n","For sequence data, the context vector can be derived from any combination of numerical or categorical attributes of the sequence or by methods described herein. In addition, a user skilled in the art will recognize that the vectors created for each record do not have to be created from a single data type. Rather, the vectors can be created from mixed mode data, such as combined numeric and text data.","Not only are high-dimensional vectors created for each record of a data type, but also a common method is used to store that information about the records and their vectors so that later processes can access the data. Methods consistent with the present invention create a group of meta data files through the action of a series of computational steps (collectively referred to as the numeric engine) alone, or in conjunction with another series of computational steps, referred to as the text engine. The files that are produced are binary, for reasons of access speed and storage compactness. The files produced during vector creation are discussed below in more detail.","Unless otherwise noted, the files discussed below have the following characteristics: (1) Files are binary, and remain within a directory established for the analysis; (2) IDs and positions are 0-based; (3) Terms have been converted to lowercase, and are listed in ascending lexical order; (4) Record IDs are listed in ascending order; (5) Index files (.<x>index) contain cumulative counts of records written to the file they are indexing (.<x>). This cumulative count is for the current record and all previous records. This cumulative count is equivalent to the record no. of the next record; and (6) Internal Numerical representations in a Sun Microsystem Operating System are:",{"@attributes":{"id":"p-0098","num":"0104"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"140pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"TermID (4 bytes)"]},{"entry":[{},"TermCount (4)"]},{"entry":[{},"DocID (4)"]},{"entry":[{},"DocCount (4)"]},{"entry":[{},"streampos (4)"]},{"entry":[{},"double (8)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Although the examples provided refer to flat file storage of the relevant information, one skilled in the art will recognize that a database could equally serve as the method for storing and retrieving the meta data.","The files produced during vector creation are:",{"@attributes":{"id":"p-0101","num":"0107"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},".dcat (document catalog)"]},{"entry":[{},"number of records in the source file"]},{"entry":[{},"for each record (line number-2 is the record id)"]},{"entry":[{},"Source file id"]},{"entry":[{},"Starting byte offset with the source file"]},{"entry":[{},"Length (in bytes) of the record"]},{"entry":[{},".tl (title file)"]},{"entry":[{},"for each record (line number-1 is the record id)"]},{"entry":[{},"title field"]},{"entry":[{},".docv (vector file)"]},{"entry":[{},"no. of records in view"]},{"entry":[{},"no. of dimensions for vectors (= no. of topics)"]},{"entry":[{},"for each record"]},{"entry":[{},"for each dimension"]},{"entry":[{},"coordinate value (float)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"ii. Visualization and Formatting","The visualization methods keep track of the location of the record representation and may use an object-oriented design. One type of visualization that is especially effective with high-dimensional data is a proximity map or a galaxy view. This and related visualizations can take advantage of methods to group the records in the high-dimensional space (clustering) and to project the arrangement of objects in high-dimensional space to two or three dimensions (projection).","Clustering can be by any of a number of methods including partition methods (such as k-means) or hierarchical methods (such as complete linkage). Any of these type methods can be used with the present invention. Despite the different methods, the computational processes that carry out the clustering create a common set of meta files that allow the chosen visualization method to access the clustering information, regardless of original data type.","The files produced during cluster analysis are:",{"@attributes":{"id":"p-0106","num":"0112"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},".hcls (cluster assignment file)"]},{"entry":[{},"This file contains the assignments for each record to a cluster. The"]},{"entry":[{},"format of the file is as follows:"]},{"entry":[{},"Number of total Clusters"]},{"entry":[{},"For each cluster (in correlation order)"]},{"entry":[{},"Cluster ID"]},{"entry":[{},"Cluster vector as determined by taking the average of the record"]},{"entry":[{},"vectors assigned to the cluster"]},{"entry":[{},"Number of Records in the Cluster"]},{"entry":[{},"The record id's of the records assigned to the cluster"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"After the .hcls file is produced, it may be resorted in correlation order (a user-definable option).","An example .hcls file:",{"@attributes":{"id":"p-0109","num":"0115"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"9 (number of clusters)"]},{"entry":[{},"6 (cluster ID)"]},{"entry":[{},"0.0457451 0.0399342 0.0864002 0.0652852 0.0635923 0.0429373"]},{"entry":[{},"0.0650352 0.0661765 0.0487868 0.0885645 0.10 0173 0.0482019"]},{"entry":[{},"0.048553 0.091455 0.0991594 (cluster vector)"]},{"entry":[{},"4 (number of records in the cluster)"]},{"entry":[{},"7 (record ID)"]},{"entry":[{},"4 (record ID)"]},{"entry":[{},"3 (record ID)"]},{"entry":[{},"5 (record ID)"]},{"entry":[{},"5"]},{"entry":[{},"0.0392523 0.0364486 0.0897196 0.0626168 0.0598131 0.0364486"]},{"entry":[{},"0.0616822 0.0794393 0.0448598 0.0925234 0.11"]},{"entry":[{},"215 0.0429907 0.0420561 0.0962617 0.103738"]},{"entry":[{},"1"]},{"entry":[{},"6"]},{"entry":[{},"1"]},{"entry":[{},"0.0341207 0.0209974 0.0918635 0.0682415 0.0603675 0.0314961"]},{"entry":[{},"0.0629921 0.0656168 0.0393701 0.11811 0.1049"]},{"entry":[{},"87 0.0393701 0.0393701 0.112861 0.110236"]},{"entry":[{},"1"]},{"entry":[{},"8"]},{"entry":[{},"3"]},{"entry":[{},"0.0587949 0.0578231 0.0739416 0.0695847 0.0651338 0.0544486"]},{"entry":[{},"0.0705118 0.0665825 0.0739358 0.0612976 0.07"]},{"entry":[{},"11892 0.0697833 0.0711892 0.0645948 0.0711892"]},{"entry":[{},"3"]},{"entry":[{},"12"]},{"entry":[{},"13"]},{"entry":[{},"2"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"iii. Projection and Formatting","Projection can also be by any number of methods, for example, multidimensional scaling. Like cluster analysis, a specific projection method is not required for use with the present invention. However, as with clustering, the results of that projection are stored in a common format so that the visualization operations can retrieve the data independent of the original data type.","Files created during projection from high-dimensional space to 2 or 3 dimensions are:",".cluster (2-D Coordinates for the Cluster Centroids)","This file contains the 2-D coordinates for placing the cluster centroid on a galaxy view). For each cluster, a single line in the file contains:\n\n",{"@attributes":{"id":"p-0114","num":"0123"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"6 0.770783 0.831761"]},{"entry":[{},"5 1 1"]},{"entry":[{},"1 0.920542 0.989886"]},{"entry":[{},"3 0.073888 0.210541"]},{"entry":[{},"7 0.0206639 0.109404"]},{"entry":[{},"4 0 0.13854"]},{"entry":[{},"0 0.0187581 0.153266"]},{"entry":[{},"2 0.139079 0.0695485"]},{"entry":[{},"8 0.374849 0"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]},{"entry":[{},"@"]}]}}}},"br":{}},{"@attributes":{"id":"p-0115","num":"0124"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"char"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["0","0.374849 \u22124.46282e-07 8"]},{"entry":["1","0.0300137 0.145639 0"]},{"entry":["2","0.0890008 0.222 3"]},{"entry":["3","0.861783 0.90898 6"]},{"entry":["4","0.745403 0.813245 6"]},{"entry":["5","0.84583 0.896318 6"]},{"entry":["6","1 1 5"]},{"entry":["7","0.630116 0.708499 6"]},{"entry":["8","0.920542 0.989886 1"]},{"entry":["9","0.0206639 0.109405 7"]},{"entry":["10","0.0206639 0.109405 7"]},{"entry":["11","\u22124.91018e-08 0.1385 4"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"Note that the X and Y coordinates in the cluster and .docpt files are represented by a number between 0 and 1 inclusive. Also note that analogous file structures would be used for a 3D projection.","iv. Data Linkage and Formatting","Advantageously, the present invention enables linkage among all visualizations and data types (text, categorical, numerical, or sequence). Prior methods enabled linkage between views of the same data visualized using different attributes or visualizations. In addition to the attributes used to create the visualization, other attributes or descriptors for each data record are linked and readily available for interaction. These interactions are possible with any of the data types. That is, additional attributes related to a record, as well as those used for vector creation, are equally available regardless of data type. This is accomplished through the use of a common set of file or database structures created by the numeric or text engines. These files store information about each record attribute, which itself can be any of the data types. These files are created during an initial processing of the data and are independent of the specific visualization method to be employed. These files provide a common framework that can be addressed by any visualization or interactive tool through an API.","The files created to store and manage the ancillary data, such as data not used in creating a view, are:",{"@attributes":{"id":"p-0120","num":"0129"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":".headings (used for data input through a matrix array only)"},{"entry":"for each record (line number-1 is the record id)"},{"entry":"name of the column heading"},{"entry":".vocab (text)"},{"entry":"for each term in the view"},{"entry":"term (i.e., a word)"},{"entry":".vocabindex"},{"entry":"for each term in the view"},{"entry":"cumulative no. of chars written to .vocab (including \\n's);"},{"entry":".fieldoff"},{"entry":"for each record"},{"entry":"for each field defined in the format file"},{"entry":"starting position (in bytes) of the field from the start of the record and"},{"entry":"the number bytes in the field"},{"entry":".corrv"},{"entry":"for each correlatable field defined in the format file"},{"entry":"number of unique values of field"},{"entry":"for each unique value of the field"},{"entry":"number of records that contain the unique value"},{"entry":"record id's of the records that contain the value"},{"entry":".ifi (inverted file index)"},{"entry":"for each term in the view"},{"entry":"for each record containing that term"},{"entry":"doc ID"},{"entry":"frequency of term within the record"},{"entry":".ifiindex"},{"entry":"for each term in the view"},{"entry":"cumulative no. of records written to .ifi"},{"entry":".docterm (document term file)"},{"entry":"for each record"},{"entry":"for each term in the record"},{"entry":"term ID"},{"entry":"frequency of term within the record"},{"entry":".doctermindex"},{"entry":"for each record"},{"entry":"cumulative no. of records written to .docterm"},{"entry":".topic (topic file)"},{"entry":"no. of topics"},{"entry":"minimum topicality for topics"},{"entry":"minimum no. of docs containing a topic"},{"entry":"maximum no. of docs containing a topic"},{"entry":"no. of cross terms"},{"entry":"minimum topicality for cross terms"},{"entry":"minimum no. of docs containing a cross term"},{"entry":"maximum no. of docs containing a cross term"},{"entry":"for each major term (topic or cross term)"},{"entry":"term ID"},{"entry":"topicality"},{"entry":"no. of docs containing the term"},{"entry":"term strength (4 bytes; 0 = MINORTERM, 1 = CROSSTERM,"},{"entry":"2 = TOPICTERM)"},{"entry":".rel (Association matrix file)"},{"entry":"no. of major terms"},{"entry":"no. of topics"},{"entry":"conditional correction"},{"entry":"for each major term"},{"entry":"for each topic"},{"entry":"relation value of major term to topic (values are encoded as"},{"entry":"four-bits and packed into bytes)"},{"entry":"four zero bits to pad last byte for major term, if needed"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"In each of the above files, \u201cterms\u201d refer to text vocabulary words; \u201ctopics\u201d refer to text vocabulary words deemed by statistical analysis to be most likely to convey the thematic meaning of the text; and \u201ccrossterms\u201d refer to text vocabulary words that provide some meaningful description of the text content but are not topics. U.S. patent application Ser. No. 08\/713,313, entitled \u201cSystem for Information Discovery,\u201d filed on Sep. 13, 1996 discusses topics and crossterms in more detail.","Many of the binary files are paired, with the first file holding the information, and the second providing an easily accessed index into the first. For example, the inverted file index consists of .ifi and .ifiindex files. Each index is a list of the cumulative number of records in the data file.","Together these files provide indexing of and access to the textual information associated with each record including the distribution of keywords within each record and co-occurrences of those keywords. Furthermore, the files provide a catalog of all the categorical data including the distribution of the values. For numerical attributes not used in the actual vector representation, additional files are created using the .docv format so that this type of ancillary information will also be readily available to establish interaction among the various views.","The processes associated with producing the series of common files described above are depicted in . Referring to , the text engine () creates the files associated with text or categorical fields. The expected input for the text engine (block ) is a tagged formatted file. For text data sets, the input is either the original format for the input or the result of a processing step to identify the beginning and end of each record along with special information, such as the record title. An example original input file to the text engine is provided in Appendix C.","For sequence data in the commonly used formats FASTA () or SwissProt (), a software module () reformats the input file to contain a series of fields that delineate the initial input and meta data created for the vector representation (). The reformatting and processing of sequence data is discussed in more detail in the U.S. patent application entitled \u201cMethod and Apparatus for Extracting Attributes from Sequence Strings and Biopolymer Materials\u201d filed concurrently herewith and incorporated herein by reference. Once in this tagged format (), the text engine () is able to create all the required meta data files.","Numerical data, or any other data presented in a data matrix, () is received at the numeric engine (). The data in the input file can be tab delimited or use any other delimiter. The numeric engine () creates the record vectors for data presented in a data matrix instead of the text engine. In addition to the numerical columns, the user may specify other columns within the table that can contain textual, sequence, or categorical information or additional numerical data that will not be used for the vector created. Usually, each row in the table becomes a record; however, the user can choose to make each column the record. Each user-defined set of columns becomes an attribute (also called fields) within the record. A set of numeric columns is specified by the user for subsequent clustering. The other fields, which can be numeric, text, categorical, or sequence, will become attributes of the record that can be queried, listed, or otherwise made available within the interactive tools.","If categorical data is specified by the file format (), as indicated by the index  for the view used, categorical data is processed during the text engine processing steps for all types of data. The categorical data shown in  records where each unique character strain and the categorical field occurs in the data set. Thus, subsequent categorical tools are enabled to correlate various records based upon the categorical values.","Each field expected in the input file is defined by a section beginning with | F followed by the field number (e.g., ||F0). For each field, the name is defined (in this case, title). Then the type of field is defined; this could be string (text or categorical), numeric, or sequence. Next, the delimiter tag for the field is defined. The METHOD line indicates whether the field is on a single line or continues to the next field. The DOCVECTOR line tells the clustering module whether to use this information in the cluster analysis. The next item designates whether the field should be accessible within the query tools. The CORR line determines whether the contents of the field should be indexed for all possible associations. The next item defines whether the content is case sensitive or not. The following lines describe the behavior of the delimiter tag. WHOLEBOUNDARY indicates whether the tag must be a single word or could be embedded within other text; LINEPOS indicates whether the tag must start at the beginning of a line or may be found elsewhere. Similar information would be given about each field in the data. This format file is stored in a directory associated with the view created.","Referring again to , the numeric engine () is executed on the set of columns that the user specified for clustering. The numeric engine () performs any number of user defined mathematical operations and creates a record vector that is identical in format to those produced for sequence or text data. In contrast to the text engine (), which automatically determines the features to use in the record vector, the vector creation in the numeric engine () utilizes a user specified set of columns from the users column\/row formatted source file.","Once the record vector is created (), the numeric engine automatically creates a text engine compatible source file (i.e., reverse engineered tagged text file, ), and corresponding format file () from the input column\/row formatted table. An example format file produced from the numeric engine is shown in Appendix D. The new tagged text source file and format files () are used so that any text, categorical, or sequence information that may have been embedded within the original column\/row files, can be processed by the same programs that operate on text, categorical, or sequence information. This subsequent processing is performed by the text engine (), which reads the reverse-engineered tagged text source file and indexes the textual and\/or categorical data fields within each record (,  and ). The result is a standardized set of meta data which is related to the user source data and which is available to all tools regardless of data type.","Although the numeric engine processes numerical data, the processing steps of the numeric engine places any of the other data types (text, categorical, or sequence) into an appropriate tagged field in the data file so that the text engine will handle it appropriately.","In summary, if the data input is array data, the array data (column\/row formatted tables) is processed by the numeric engine (). The numeric engine  creates a second vector that is identical to the format of the context vectors for sequence and text data produced by the text engine (). However, in contrast to the text engine, which can automatically determine the features to use in the second vector, the numeric engine  accepts a user defined series of mathematical operations to be performed on specified columns of the array data source file. In order to make the non-numeric contents, such as annotated notes, associated with the array file accessible for subsequent analysis, a format file is produced and a tag text format file is produced for the non-numeric contents associated with the numeric file. The associated non-numeric contents is used as an input to the text engine and the output is associated with the numeric data. Thus, the textual or categorical data associated with the numeric array data may be indexed and associated with the data as produced for other text data sets that are input to the text engine (). Plain text data should be in a tagged text format and does not require any pre-processing prior LAW OFFICES to input to the text engine ().","4. Clustering",{"@attributes":{"id":"p-0134","num":"0143"},"figref":"FIG. 2","i":["c ","a","b","c ","a "],"b":["224","224","224","224"]},"The k-means module moves documents to minimize the sum of squares between objects and centroids as known by those skilled in the art. The cluster-sid is an agglomerative\/hierarchical clustering method that minimizes the maximal between clusters distance (farthest neighbor method). The output of the clustering process is a file containing a correlation ordered list of clusters and the record's IDs of their members. Those skilled in the art will recognize that other clustering algorithms can be used.",{"@attributes":{"id":"p-0136","num":"0145"},"figref":"FIG. 9","b":["760","904","906","908","904","910","912","914","916","910","920"]},"5. Projection",{"@attributes":{"id":"p-0137","num":"0146"},"figref":"FIG. 2","i":["d ","a","b","c","a ","b ","c ","c "],"b":["226","226","226","226","226","226","226","226"]},"Referring to , the processes associated with creating a two dimensional projection from the cluster assignment files is illustrated. The cluster assignment file (.hcls) is retrieved from storage (step ) and the principle component analysis of the cluster centroid vectors are performed (step ). Two dimensional coordinates for the cluster (.clster) are created (step ). Delaunay triangulation is performed (step ) based on the vector file retrieved from storage (step ) that is associated with the data set. Nearest neighbor assignments are associated with the Delaunay triangulation results (step ). The projection program determines the two dimensional coordinates for each record (step ) based upon the vector files retrieved from storage (step ). The projection program also accesses and retrieves the cluster assignment file (.hcls) (step ) associated with the data set. The two dimensional coordinates for the group of documents of the data set are stored in a document file (.docpt) (step ).","6. Graphic Modules and Tools","Referring to , the interactive tools and graphics modules are illustrated. The interactive tools and graphics modules  include a galaxy module , a master query module , a plot data module , a record viewer module , a query (word) module , a query (number) module , a group module , a gist module , and a surface map module ","The galaxy module displays records as a scatter plot. The master query module applies a correlation algorithm to all indexed categorical data and creates a two dimensional matrix with values of a category along each axis. At each intersection in the matrix, a rectangle is drawn with sections colored to show the correlation between the categories. The following are analytical tools. The plot data module displays a two dimensional line plot of the n-dimensional vectors created for analysis by the user, this is done for all records in the analysis or just those selected by the user. This module can also be used to examine any ancillary numerical attributes associated with the records. The record viewer module displays a list of the currently selected documents, displays a text of a document, highlights terms selected by other tools, such as the query tool . The query tools and enable the user to input requests to search for information that has been represented by a vector during the processing and analysis of the user's data set. The query tools and compare the user input to vectors representing the processed data set. The query tool performs Boolean or phrase queries in any text or categorical field based on a user's input. The query tool also performs n-space queries based on the user's input and compares the input to the n-dimensional vector used for clustering. Thus, vectors that correspond to the users input can be identified and highlighted. The numeric query tool performs queries based on numeric values. The group tool enables users to create groups of records of a data set, based on queries or based on user selections, and colors the groups for display in the galaxy visualization created by the galaxy module . The gist tool determines the most frequently used terms in the currently selected set of records. The surface map module provides a surface map that shows records and a plurality of attributes associated with those records.","Referring to , a table is shown that illustrates meta data files that result from statistical analyses and indexing of the data sets consistent with an embodiment of the present invention. The table also depicts the meta data files that are used for the various interactive tools and graphics modules. All of the meta data files except for the tab delimited column\/row file, the tagged text source file(s), and the re-engineered tag text file are defined by the data set name or view name as created by the data set editor  or view editor  () plus an \u201c.extension,\u201d such as [data set name].dcat or [view name].cluster. The meta data files include a data set name.dcat file, a data set name.properties file, a view name.clsp file, a view name.cluster file, a view name.corrv file, a view name.d cat file, a view name.docpt file, a view name.docterm file, a view name.docterm index file, a view name.docv(vector) file, a view name.edge file, a view name.fieldoff file, a view name.gif file, a view name.groups file, a view name.fmt file, a view name.hcls file, a view name.headings file, a view name.ifi file, a view name.ifi index file, a view name.properties file, a view name.punc file, a view name.rel file, a view name.repository file, a view name.stop file, a view name.tl file, a view name.topic file, a view name.vocab file, a view name.vocab index file, a tab delimited column\/row file, a tag text source file(s), and a re-engineered tag text file. The table indicates which program modules create, read or update files as indicated by the letters C, R, and U, respectively. For example, the view name.clsp file is created by the view editor  () and is read by the k-means module and the cluster-sid module () and is read by the galaxy module (). The view name.groups file is updated by the group module . All file access is performed through the API layer ().","After the clustering and projection processes have been completed, the user may now view the results of the various operations performed on the user's data set. As discussed above, prior methods of visualization do not adequately provide access to relationships among attributes of data records other than those used in creating the visualization and, consequently, do not enable the identification of relationships between attributes of different visualizations or views. A system operating according to the present invention enables a user to identify relationships among different visualizations or views by maintaining all attributes associated with the data record for indexing although all attributes are not used in creating the visualization. Referring to , the processes consistent with an embodiment of the present invention used to link different visualizations or views is discussed. When a user is viewing a particular visualization or view, the user may request to identify the relationships that exist between the attributes used to create the current visualization with the attributes used to create another visualization (step ). After the user initiates a request to explore the data of another view (a target view) an index file associated with the user's current view or data set is accessed (step ). After the index file is accessed (step ), the process determines whether objects selected by the user in the current view, such as by initiating a query, correspond to objects of a target view based upon all of the attributes contained in the index file (step ). If objects of the target view or file correspond to the selected objects of the current view, the objects of the target view are highlighted (step ). Therefore, relationships among attributes of data records other than those used in creating the visualization can be used to identify relationships of another visualization as discussed in connection with .","Methods and apparatus consistent with the invention also provide tools that allow a user to display information interactively so that the user can explore the information to discover knowledge. One such tool displays a set of records and their associated attributes in the form of superimposed two-dimensional line charts. The tool can also generate a single two-dimensional line chart that provides the average values for the attributes associated with the set of records. Each of these charts are linked to other views, such that a record selected in the charts is highlighted in the other views, and vice versa.","Another tool generates summary miniplots that may be quickly used by a user to obtain an overview of the attributes associated with a particular group of records. In particular, records shown in a scatter chart are organized into groups. The average values for the attributes associated with each group of records is used to form a two-dimensional line chart. The line chart is superimposed on the scatter chart, based on the location of the set of records.","As described above, one basic visual tool implemented by the invention for viewing information is a \u201cgalaxy view\u201d as produced by the galaxy tool . A galaxy view is shown in window  of . The galaxy view is a two-dimensional scatter graph in which records are organized and depicted in groups (or \u201cclusters\u201d) based on relationships between one record and another. In addition to this galaxy view tool, the invention provides numerous interactive visual tools that allow a user to explore and discover knowledge.",{"@attributes":{"id":"p-0147","num":"0156"},"figref":"FIG. 13","b":"1305"},"Next, a two-dimensional line chart is generated to visually depict the records and their associated attributes (stage ).  represents an implementation of two-dimensional charts that are consistent with the invention.  contains line chart , and legends  and .","Chart  contains a collection of superimposed line charts that depict a set of records. For example, line chart  depicts one record within the set, while line chart  depicts another. In the line charts, the x-axis (e.g., as shown by ) represents attributes associated with the records, and the y-axis (e.g., as shown by ) represents the value of each attribute. The scale of each axis and the colors of the line charts may be modified by the user. Although this description focuses on line charts, other types of charts may be used to depict a set of records, as shown for example by the point chart shown as  in . Legend  contains a text-based description of records. For example, legend  contains a record described as \u201c122C\u201d, as shown by . Legend  contains a text-based description of attributes.","Methods consistent with the invention can also generate a two-dimensional line chart that shows relationships between the records shown in  (stage ). For example,  shows a line chart  that depicts a statistical value corresponding to the set of records shown in . In the example shown in , chart  depicts the average attribute value for each record shown in . In alternative implementations, however, chart  may depict other relevant characterizations of the set of records, such as median attribute values, standard deviations (as shown by ), etc.","In addition to viewing the information in graphical form, the user can interact with the line charts. The invention is capable of receiving input from a user selecting a portion of a chart (stage ). This may be achieved, for example, by using a device to point to a portion of map  or by clicking a pointing device on a portion of map . In response to this user input, the text-based description of the selected record and\/or attribute is highlighted in legends  and  (stage ). In the example shown in , the user has selected record \u201c122C\u201d, as shown by the highlighting in legend . Similarly, the value of a particular attribute being pointed to in charts  or  can be displayed in text format. In the example shown in , the user has selected attribute \u201cRBC\u201d, as shown by the highlighting  in the legend and  on the x-axis.","Furthermore, any selections made by the user on charts  or  are propagated to other views. For example, in response to receiving input from a user selecting a record on chart , an index, as discussed above, is analyzed to determine if the record is shown in another view (stage ). If the record is shown in another display (stage ), the visual representation of that record in the other view is altered (stage ).  is a diagram showing both (1) charts  and , and (2) a galaxy view  of records. If a record is selected on map , the record is highlighted in galaxy view , and vice versa. Similarly, the group of records shown on map  may be highlighted in galaxy view  (as shown by ), and vice versa.",{"@attributes":{"id":"p-0153","num":"0162"},"figref":"FIG. 17","b":["1705","1710"]},"Next, a two-dimensional scatter chart is generated to visually depict the records (stage ). An example of such a chart is galaxy view  shown in . Galaxy view  contains a collection of records, one example of which is shown as . The records within galaxy view  are organized into groups (or clusters) (stage ), based on relationships between one record and another.","For each group shown in galaxy view , a two-dimensional line chart (summary miniplot) is generated that depicts some information about the records contained within that group (stage ). Each such summary miniplot is superimposed onto the two-dimensional scatter chart, based on the location of the group of records on the scatter chart (stage ). For example, chart  contains a group of records , for which summary miniplot  represents the average attribute values. In the example shown, summary miniplot  is superimposed at the centroid coordinate for the records in group .","In alternate implementations, summary miniplots may be used to represent other groupings of record. For example, the records shown in a scatter chart may be grouped into quadrants of the scatter chart; and four summary miniplots could be used to represent the quadrants. Furthermore, each line charts, such as line chart , can also be coded in a variety of ways (e.g., size, color, thickness of lines, etc.) to represent additional information (e.g., the variability within the group's records, the value of an unrelated field, etc.).","In addition to viewing the information in graphical form, the user can interact with the summary miniplots. The invention is capable of receiving input from a user selecting a summary miniplot (stage ). This may be achieved, for example, by using a device to point to a portion of map  or by clicking pointing device on a portion of map . In , the user input constitutes selecting group , as shown by the fact that group  is highlighted. In response to this user input, a graph is generated that contains a series of superimposed line charts, with each line chart representing a record (stage ). An example of such a graph is shown in  as , which is a series of superimposed line charts that represent attribute values for the records selected by the user in group .","Furthermore, any selections made by the user of a summary miniplot on chart  is propagated to other views. For example, in response to receiving input from a user selecting summary miniplot , an index, as discussed above, is analyzed to determine if the records represented by summary miniplot  are shown in another view (stage ). If the records are shown in another display (stage ), the visual representation of the records in the other view are altered (stage ). Similarly, if a user selects a record in another view, the summary miniplot corresponding to that record can be highlighted.","The preceding visualizations provide the opportunity to query records by attributes represented, e.g., by categorical and numerical values and by sequence of text content. Because the visualizations support a limited number of queries, the visualizations cannot analyze large associations efficiently. A multiple query tool creates a visualization that provides an overview of a large number of comparisons automatically, presenting the user with information, e.g., about associations and their expectation. Further, the multiple query tool also provides information about associations between clusters and attributes as well as associations between sets of attributes.",{"@attributes":{"id":"p-0160","num":"0169"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0161","num":"0170"},"figref":"FIG. 20","b":"2010"},"Visualization of data begins with the selection of a data file. As shown in step , a user selects a data file of interest. Alternatively, the data file can be preselected, when, e.g., the multiple query visualization is linked to another visualization analysis.","After a data set is selected, as shown in step , the user sets the type of query. As shown in , a dialog box can be displayed to the user with a drop-down menu of query types. While  shows a selection between query types records vs. attributes, attributes vs. attributes, current data vs. historical data, and current data vs. expert data, other query types are within the scope of the invention. Once selected, the drop-down menu is rolled up to display only the selected query.","Upon selection of a query type, a dialog box specific to the query type is displayed so that the user can set the parameters of the query.  display exemplary parameter-setting dialog boxes for query types shown in .","For example, , a record vs. attributes query dialog box  is displayed. In this query, records are correlated to selected attributes. In one of its aspects, the records can be viewed as clusters of the records, for example, as clusters such as those defined in the galaxy view of a previous visualization or those defined using any other process.  displays four attribute sources, although other sources could be displayed.","In attribute source area , labeled \u2018Vocabulary Word(s),\u2019 of dialog box , the user types in the word or words that serve as attributes. For multiple words, a delimiter, such as a semicolon, could be used to separate entries. Other processing could also intelligently separate the words. Also, logical operators, such as Boolean AND, OR, NOT, could be included to produce a single composite attribute.","Also, the user can identify attribute words by pointing to a text file that contains a list of words. The user can identify the text file in attribute source area , labeled \u2018Vocabulary File.\u2019 One format for this list would be a single keyword per line or a single phrase per line. With the text file, synonyms can also be identified. Vocabulary files including synonyms may have the following formats in one aspect of the present invention:",{"@attributes":{"id":"p-0168","num":"0177"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Format 1"]},{"entry":[{},"Keyword1: altword1A; altword1B"]},{"entry":[{},"Keyword2:"]},{"entry":[{},"Keyword3: altword3A"]},{"entry":[{},"Format 2"]},{"entry":[{},"Keyword1"]},{"entry":[{},"-altword1A"]},{"entry":[{},"-altword1B"]},{"entry":[{},"Keyword2"]},{"entry":[{},"Keyword3"]},{"entry":[{},"-altword3A"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"The processing of the identified text file will operate on files of the format(s) of existing user files, so as to avoid issues of file format conversion.",{"@attributes":{"id":"p-0170","num":"0179"},"figref":"FIG. 22A","b":["2230","2240","2230","2250"]},"In attribute source area , labeled \u2018Category File,\u2019 the user can identify attribute categories by pointing to a text file that contains a list of categories. Selecting categories from a file enables to the user to specify easily the order in which the categorical values would be displayed in the visualization and to allow the user to specify a hierarchy for those values. One format for the categorical value file is:",{"@attributes":{"id":"p-0172","num":"0181"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"126pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["categoricalvalue1","1","(tab delimited lines with value indicating"]},{"entry":["categoricalvalue1.1","2","hierarchy level)"]},{"entry":["categoricalvalue2","1"]},{"entry":["categoricalvalue2.1","2"]},{"entry":["categoricalvalue2.2","2"]},{"entry":["categoricalvalue2.2.1","3"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"Further, to collapse the number of attribute columns, the categories could be combined, similarly to the use of synonyms, or, for hierarchical categorical data, the user could select a maximum hierarchical level. As shown in step  of , after the user selects the attributes, the database is queried using the multiple query. In step , the results of the multiple query are used to create a query matrix.","For example, as shown in , from the attribute words or categories, the multiple query tool creates a query matrix of record rows and attribute columns. The cells of the matrix are set to binary values indicating the presence or absence of the attribute in each record. When a vocabulary file with synonyms is used, a single matrix cell should be created for each keyword, and the cell is marked if either the keyword or any of the alternate forms are found. One method of determining the presence of attribute would be to search the original data file or any indexed files describing the distribution of words or categorical values within the data set.","Following creation of the query matrix, the query matrix is visualized, in step . One visualization is a binary, co-occurrence scheme, as shown in , where cells having a value of \u201c1\u201d are marked in a color or shade, , while cells having a value of \u201c0\u201d are marked in a different color or shade, . The user can select a size of cells, so that more cells or less cells are shown in a display of the visualization.","To minimize the display, the user can select a visualization based on cluster rows. When large numbers of records are to be analyzed, the cluster row visualization could be set as the default.","In this case, as shown in , the cells of the visualization matrix are set to indicate the presence or absence of the attribute in each record. To set the cell values, the query matrix is created or processed to create a composite value for a cell, for example, a basic scheme would involve summing the binary co-occurrence scores for a cluster and dividing by the number of records in the cluster.","When the matrix using cluster rows is visualized in step , cells are colored or shaded to indicate their composite values.  shows a binary co-occurrence shading scheme that illustrates the query matrix of , if records  and ,  and , and  and  are assumed to be in clusters , , and , respectively. To enhance the interactive nature of the visualization, as shown in , an overall visualization can be displayed as a three-dimensional view of the rows vs. columns vs. values, with the value of each cell represented by a cube at an appropriate height on the Z-axis. The overall visualization is rotatable, so that the user can view 2-D scatter plots corresponding to the rows and columns. A 2-D row scatter plot is shown in .","Another more complex visualization, however, serves as the default when cluster rows are used. In this alternative visualization of cluster rows, the cells show association probabilities. The scheme of showing association probabilities would be to represent deviations as a difference from an expected value under a random distribution assumption. To calculate expected values, the total number of records containing each attribute, or the sum of the columns of the query matrix, is computed. Lower than expected values could be, for example, cool colors (blue (=\u22121) to green) and higher than expected will be hot colors (inverted black body with red=1). Deviations from an expected value under a random distribution assumption could also be represented as a ratio. Also, the probability of observing a number of attributes in a cluster of this size given this many total number of attributes are randomly distributed over all the clusters could also be represented. In this case, the values will range from 0 to 1 and the color display would have blue=0, white=0.5, and red=1; for example. To highlight extreme behaviors, the scale could be non-linear so that only the very high and very low probabilities are highlighted.","To compute association probabilities either an exact or approximate method is used for each of the association methods of the present invention. The exact method is precise at the cost of being computationally intensive. The approximate method can reduce the number of computations when the total number of objects and total number of occurrences of the attributes are relatively large. Further, the use of the laws of logarithms to reduce products and quotients to sums and differences, respectively, and exponentiation to a product will also save computing time.","The probability of observing what is observed given a random distribution indicates the possibility of observing certain number of occurrences of an attribute in a given cluster if the attribute is randomly distributed over all clusters. The lower the probability, the further the attribute distribution deviates from randomness. Described below are the exact method and approximate method for calculating this probability.","Equation 1 provides the exact method. Equation 1 is the discrete density function for a random variable having a hypergeometric distribution. The numerator consists of the product of two terms. The first term calculates how many ways to choose exactly m attributes out of M possible for the cluster of interest; the second term calculates the ways to assign the other (n-m) attributes which are not in the cluster of interest to the other clusters collectively. The denominator calculates the total number of ways to assign N objects to a cluster of size n. \n\n\n","Equation 2 provides the approximate method. Equation 2 is the discrete density function for a random variable having a binomial distribution, where the probability of a success is M\/N and the probability of failure is (1\u2212M\/N). When N and M are large, (N\u2212n)\/(N\u22121) is close to one; thus, Equation 2 provides a reasonably good approximation to the hypergeometric distribution. N, M, n, and m denote the same quantities as defined above in Equation 1. \n\n","Alternatively, the association probability can be represented as a measure of an unusual number of occurrences, which is a deviation of observed occurrence from the expected occurrence if the attribute is randomly distributed over all clusters. An exact method (Equation 3) or an approximate method (Equation 4) can be used. N, M, n, and m denote the same quantities in Equation 1. Note that the expectation is the sum over the range of the random variable of x of x multiplies p(x). Equation 3 uses hypergeometric distribution and Equation 4 uses a binomial method, similar to Equations 1 and 2, respectively. The exact method is very computationally expensive due to the summation, while summation in the approximate method can be calculated through and written into the simple form of Equation 4. \n\n\n","The deviation from expected occurrence can be measured using ether ratio or difference of the observed number of occurrences over (or from) the expected number of occurrences. The range of the ratio is between zero and infinity. A ratio value further away from 1 indicates a larger deviation from randomness. \n\n","Alternatively to make the deviation more comparable for various sizes of clusters, the difference between observed and expected occurrences is divided by the size of the cluster (Equation 6). Therefore, the range of this deviation measure is normalized between \u22121 and 1. A value further away from zero indicates a larger deviation from randomness. \n\n","While the order of attributes along the columns and the order of rows or clusters along the columns of the matrix can be selected by the user, using a menu item or by dragging rows and columns to new positions. For example, the order of the records or the order of the clusters is automatically set to same correlation order as known to those skilled in the art. The default display for attributes is based on correlation order, with the attribute having the highest column sum being on the left-hand side.","Thus, visualizations for the record vs. attributes query type is explained. The processing involved in creating the query matrix and visualization for the remaining query types is similar to the process of records vs. attributes query type.","If the user selects an attribute vs. attributes query type in step , as shown in , an attributes vs. attributes query dialog box  is displayed. The attributes vs. attributes query type is not interested in occurrences with specific records, only in defining the associations among attributes.","Query dialog box  operates similarly to records vs. attribute query dialog box , except that the user will be specifying two sets of attributes (vocabulary words or categories).","When querying the database in step  and creating the query matrix in step , the matrix cell scores are generated as a cumulative measure of the number of records that contain both test attributes. Then, the score should be normalized against the number of records. In other words, for n records, i row attributes, and j column attributes:",{"@attributes":{"id":"p-0192","num":"0201"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"for rowattribute = 1 to i"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"for columnattribute = 1 to j"]},{"entry":[{},"score(i,j)=0"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"for record=1 to n"]},{"entry":[{},"if record contains both rowattribute(i) and columnattribute"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"(j), then score(i,j)=score(i,j)+1"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"next record"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"normscore(i,j)=score(i,j)\/n"]},{"entry":[{},"next columnattribute"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"next rowattribute"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Also, the total number of records that have each attribute is counted so that deviation from expected frequency can be calculated.","In step , the attribute vs. attribute visualization follows the same mechanics as for records vs. attributes, but with a few differences. Specifically, in the default view for the attributes vs. attributes visualization, the default order for both axes would be the correlation order, with the column with the highest total score (e.g., the highest average value) on the top of left, and the default mode for showing associations uses deviation from expectation using with lower than expected values shown as cool colors (blue (=\u22121) to green) and higher than expected shown as hot colors (inverted black body with red=1).","Another use of the multiple query tool visualization is rapid assessment of the correlation between the current experiment being analyzed and historical data. Such a visualization points to the similarities or differences for all equivalent data points (record and condition).","As shown in , a current data vs. historical data query dialog box  is displayed when the user selects such a visualization. A file containing a data matrix is used as the historical data. In other words, the user would select the files of a prior visualization. Alternatively, a data matrix, similar to those currently used to input data into the numerical engine, could be designated.","In step , the method determines where the current and historical experiments overlap. For example, if the current experiment contains records  through  and the historical experiment contains records  through  and records  through , then correlations would only be performed with the common records  to  and  to . Similarly, if the current experiment used conditions (components) A through E (e.g., 5 time points or distinct treatments) and the historical experiment used conditions A, C, D, and F, then the correlation would be calculated only using the common conditions A, C, and D.","In step , a query data matrix would then be created comparing the ES common entries. For record, a correlation with the historical data set would be performed using all the common conditions (intersection). In the example given, this would be a correlation between currentrecord(A,C,D) and historicalrecord(A,C,D). A similar score would be derived for each record present in both data sets. For a record in the current data set that is not present in the historical set, the query matrix would be blank (or set to some flag). The calculations would be repeated for each historical set requested.","In step , the query matrix is visualized as follows. The color code in each cell is based on the correlation of that record to its counterpart in the historical data. The correlation values will range from \u22121 to +1 and be presented using, for example, a modified rainbow with negative correlations being cool colors (blue=\u22121) and positive correlations being hot colors (red=1). For records that are not shared with the historical data set, the matrix cell should have no color (or be colored the same as the background) or, alternatively, these cells can be hidden. If the cells not shared with the historical data set are shown, the degree of overlap between the current and the historical data sets can be visualized. This visualization could also be selected as a separate visualization that shows the overlap, for example by using a gray-scale color code in the matrix, where black indicates full overlap with the historical data components and white indicates no overlap. This query type would also be useful with other data mining tools.","Instead of comparisons of the records of the current and historical data, cluster assignments from one experiment to the next, even when the experiment types are quite different, can be compared. For each record in a current data cluster, the method can assess what fraction of other current cluster records exist in the same cluster in the historical set. Then, an average of the results from each current cluster record to is computed to get a score for that cluster. Another example assesses, for each record in a current cluster, what fraction of other current cluster records are found in the historical data within x Euclidean distance. An interactive slider would allow the user to change x and the method would allow viewing of the results dynamically.","When records are combined into clusters, the overall value for the cluster will be represented as the average or other statistical measure, such as median of the record correlations, based only on those records that are common between the data sets. An indication of variation is provided since a cluster that contains 10 records with a correlation of 0.8 and a cluster that contains 10 records with a correlation of 0.9 and 1 with a correlation of \u22121 (both cluster with average of 0.8) may be of different interest to the user. Such an indication can be achieved using multiple visualizations, for example by duplicating the previous query, that simultaneously show the average and the standard deviation, the minimum value or the maximum value.","The default order of clusters and records in this visualization should be the same as in the records vs. attributes query tool. In addition, a row is added that summarizes the comparison of the entire current data against each historical data set. For example, a row labeled \u201cSummary\u201d will be the average of all record correlations.","Alternatively, the user or system could identify specific records to group together at the top of the visualization. For example, all the controls could be grouped together as opposed to in separate clusters. Also, while only one set each of current and historical data is used, several sets data could be visualized contemporaneously. That is, any one of the data sets is treated as the prototype against which others are measured. A slider bar having each visualization would allow the user to run through multiple experiments. The progress through the slider (data sets) could be semiautomated to play like a movie, stopping whenever certain similarities or dissimilarities are found.","The \u2018current data vs. literature\/expert knowledge\u2019 query is similar to the other queries. Correlations between the current data and the literature or expert knowledge are defined either as what records have previously been found to group together or as similarity to actual published\/historical values.","Regardless of the query type, the visualization, as shown in , will be displayed in an interactive area of a display screen, so that the user may adapt the visualization to her preferences.","For example, to provide commands, the visualization could include a menu bar and a toolbar. A menu bar , with associated sub-menus, of the visualization could include the features shown in .","The Duplicate command in the File menu of menu bar  allows access to previously stored queries, so that the user can either re-run or adjust a previously run multiple query. The other commands in the File order are self-explanatory.","The Row Order menu of menu bar  provides option for organizing the records, clusters, or row attributes. The Cluster from View command results in a correlation ordering for the records and clusters (if correlation ordering was not done for the view, then it is also not done here in the default), as discussed above this ordering is the default for a records vs. attributes query type or a current data vs. historical data query type. The Correlation with Columns command is an option for recalculating the cluster order based on the values in the query matrix. In a cluster view, records would remain with their cluster and the clusters are reordered according to correlation ordering. If a cluster was expanded to show records, the records in the cluster would be reordered according to correlation ordering. As discussed above, for an attributes vs. attributes query, correlation with columns is the default.","The Advanced sub-menu of the Row Order menu allows access to the following commands. The Cluster Based on Column Values command recalculates the clustering of the records or the attributes using the scores along the row as the vectors for clustering. The user would have the choice of using any clustering algorithm, such as either the hierarchical or partition methods. The Sum command is an option to order the records or attributes based on the sum of the scores across the row, with the record\/attribute with the highest sum being at the top and the lowest being at the bottom, for example. Rows having a value below a predetermined threshold could be placed in a low value row or removed from the visualization matrix. The Sum command is not valid for visualization using clusters and would be deactivated. The File Order sets the order of clusters or attributes to that specified by the user, for example in an input file. If no file is provided or record rows are selected, this option would be deactivated.","The Column Order menu of menu bar  provides analogous options as the Row Order menu for organizing the column attributes, expect that there will be no clustering from the view, as records and clusters do not appear in the columns, in one aspect of the present invention.","To provide the user the ability to choose a custom coloring scheme, the Color menu of menu bar  permits a selection of display colors within the multiple query tool.","A tool bar is also provided in the visualization, either as a separate pop-up area or a bar, for example, located below a status bar, to provide access to functions with a single click.  illustrates examples of functions of a tool bar.","The RecordViewer function displays the currently highlighted record (or records in the highlighted cluster). For a record vs. attribute cell, this shows the single record with the specific attribute highlighted in the record. For a cluster vs. attribute cell, the RecordViewer shows all the records in that cluster with the specific attribute highlighted in the records. For an attribute vs. attribute cell, the RecordViewer would display all records that contain both attributes, with both attributes highlighted. To access the records, the RecordViewer calls a process that parses the data source file in the galaxy cluster view. An interpretation tool, such as the plot data tool, could also be provided. A double click on a cell can also call the RecordViewer function.","The Zoom function operates similarly to a zoom in the galaxy visualization. Primarily, the zoom will zoom out, so that an overview of a large multiple query tool can be obtained. The maximum zoom out should be based on the number of records and a user's desired minimum resolution, so that the colors of the visualization will be readily discernable. A possible default size for a cell in the multiple query tool is 12 by 12 pixels. This is large enough to display text labels at 10 point Helvetica for both rows and columns. Zooming out would provide an overview for large data sets. The Zoom Reset function returns the visualization to its default size.","The Pan function takes the form of a hand and allows the user to drag the graphic around the window, so that area hidden by display objects or the physical dimensions of a display screen can be viewed. Scroll bars, as shown in the multiple query tool above, could be employed instead of, or in addition to, the Pan tool. Nevertheless, labels for the rows and columns would always remain visible.","The Expand Row Clusters and Expand Column Clusters functions open the selected cluster(s) to display all their records or attributes as separate rows. If no clusters are selected, all clusters are expanded. If no clusters are defined (either from the associated view or by having done a cluster ordering within the multiple query tool), these functions are deactivated.","The Collapse Row Clusters and Collapse Column Clusters functions closes the cluster that contains the selected record(s) or attribute(s). If no record or attribute is selected, all clusters are collapsed. If no clusters are defined (either from the associated view or by having done a cluster ordering within the multiple query tool, these functions are deactivated. Although not illustrated in , a single button could also collapse all row and columns with a deviation from expectation between, e.g., \u22120.5 and +0.5 (or other definable range) into a single group or remove rows and columns that do not have values above a predetermined threshold.","The Orient Rows vs. Values and Orient Columns vs. Values functions orient the visualization so that the view is perpendicular to the row axis or column axis, respectively. This provides views of the 2-D scatterplot, as shown in , for example. The Reset Orientation function orients the visualization to the default \u2018overhead\u2019 view showing rows vs. columns.","The Spacing Toggle function toggles the matrix between the two types of views shown in . Providing a grid as shown in  allows viewing of cells as discrete entities, for easier selection. Removing the grid, as shown in , allows more information to be compressed into the same space and could improve enhance structure distinctions in the visualization matrix.","In addition to the command bars, the visualization area itself, as shown in , consists not only of the colored visualization matrix, but also includes labels for the rows and columns.","When the rows are records, the row labels are the record titles. Since record titles may be long, the initial substantially 20 characters could be displayed with a scroll bar or pop-up function to enable viewing of all of the characters. When collapsed into clusters, the row labels are labeled by cluster number. For attributes, the categorical value or vocabulary word itself serve as the label. In addition to the labels themselves, the rows and columns could have a master label indicating the content. For records as rows, the label would say \u201cRECORDS.\u201d For vocabulary words input directly in the initial dialog box, the label would be \u201cVOCABULARY\u201d. For vocabulary words input through a file, the label would be the file name. For categories as attributes, the field name would be shown. If multiple fields were requested, each field name would be shown, centered over its collection of row or column labels. The user could also edit or define the row, column, and major labels.","Rows and columns are selected and highlighted by clicking on the row and column labels using a mouse input device, for example. Shift-clicking and control-clicking can be used to select multiple labels.","The visualization is interactive. In addition to highlighting labels for selecting rows and columns, clicking on a cell should display key information regarding the cell. This pop-up information would be context sensitive, depending on the type of query and whether the cell represents an individual record or attribute as opposed to a cluster or group. The following provide suggested formats of the key attributes of a cell of the different groups and query types:","For a cell intersecting a record and attribute in a records vs. attributes query:",{"@attributes":{"id":"p-0224","num":"0000"},"ul":{"@attributes":{"id":"ul0006","list-style":"none"},"li":{"@attributes":{"id":"ul0006-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0007","list-style":"none"},"li":["Row: Recordname","Column: Columnattributename","Co-occurrence: 0 (or 1)","Attribute found in ##\/totalrows records\n\nFor a cell intersecting a cluster and attribute in a records vs. attributes query:\n","Row: Cluster# containing ## members","Column: Columnattributename","Co-occurrences: ##","Number of co-occurrences expected: #","Deviation from expected co-occurrence: ##","Probability of observation: ##\n\nFor a cell intersecting an attribute and attribute in an attributes vs. attributes query:\n","Row: Rowattributename","Column: Columnattributename","Co-occurrences: ##","Row attribute found in ##\/totalcolumns columns","Column attribute found in ##\/totalrows rows","Number of co-occurrences expected: ##","Deviation from expected co-occurrence: ##","Probability of observation: ##\n\nFor the cell intersecting a record and historical data in a current data vs. historical data query:\n","Probability of observation: #","Row: Recordname","Column: historical experimentname","Correlation: ## (if this record does not intersect with historical data, \u2018no intersection\u2019)\n\nFor the cell intersecting a cluster and historical data in a current data vs. historical data query:\n","Probability of observation: ##","Row: Recordname","Column: historical experimentname","Average Correlation: ## (if this cluster does not contain any genes that intersect with historical data this should say \u2018no intersection\u2019)","Maximum Correlation: # with recordname","Minimum Correlation: ## with recordname","Records that do not intersect historical data (could be a scrollable list):\n        \n        "]}}}},"Systems and methods consistent with the present invention employ an open architecture that enables different types of data to be used for analysis and visualization.","It will be understood by those skilled in the art that various changes and modifications may be made, and equivalents may be substituted for elements thereof without departing from the true scope of the invention.","Modifications may be made to adapt a particular element, technique, or implementation to the teachings of the present invention without departing from the spirit of the invention. For example, any genetic material, from organism to microbe, could be represented using the context vectors of the present invention. Further, the present invention is not limited to genetic material, and any material or energy could also be represented. Additionally, the rows and columns used in the description are illustrative only, and, for example, records could be placed along the columns. Also, the attributes used are not limited to text and categorical features. Numerical values could be set as attributes, for example using binning where adjacent ranges of numbers are defined. Additionally, for queries against individual records, categorical data could be presented in a single column rather than multiple columns for each categorical value as described above; in this case, the occurrence of a specific categorical value could be represented as a specific color. The resulting matrix could also be dynamically controllable by the user. The order of rows or columns could be adjusted by dragging or sorted according to the information within the row or column.","Moreover, although the described implementation includes software, the invention may be implemented as a combination of hardware and software or in hardware alone. Additionally, although aspects of the present invention are described as being stored in memory, one skilled in the art will appreciate that these aspects can also be stored on other types of computer-readable media, such as secondary storage devices, like hard disks, floppy disks, or CD-ROM; a carrier wave from the Internet; or other forms of memory.","Therefore, it is intended that this invention not be limited to the particular embodiment and method disclosed herein, but that the invention include all embodiments falling within the scope of the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings, which are incorporated in, and constitute a part of, this specification illustrate at least one embodiment of the invention and, together with the description, serve to explain the advantages and principles of the invention.","In the drawings,",{"@attributes":{"id":"p-0022","num":"0020"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0023","num":"0021"},"figref":"FIG. 2","i":"a "},{"@attributes":{"id":"p-0024","num":"0022"},"figref":"FIGS. 2","i":["b","c","d ","e "],"b":["2","2","2"]},{"@attributes":{"id":"p-0025","num":"0023"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0026","num":"0024"},"figref":"FIGS. 4","i":["a ","b "],"b":"4"},{"@attributes":{"id":"p-0027","num":"0025"},"figref":"FIGS. 5","i":["a","d "],"b":"5"},{"@attributes":{"id":"p-0028","num":"0026"},"figref":"FIGS. 6","i":["a","m "],"b":"6"},{"@attributes":{"id":"p-0029","num":"0027"},"figref":"FIGS. 7","i":["a ","b "],"b":"7"},{"@attributes":{"id":"p-0030","num":"0028"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0031","num":"0029"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0032","num":"0030"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0033","num":"0031"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0034","num":"0032"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0035","num":"0033"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0036","num":"0034"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0037","num":"0035"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0038","num":"0036"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0039","num":"0037"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0040","num":"0038"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0041","num":"0039"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0042","num":"0040"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0043","num":"0041"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0044","num":"0042"},"figref":["FIGS. 22A\u201322C","FIG. 21"]},{"@attributes":{"id":"p-0045","num":"0043"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0046","num":"0044"},"figref":["FIG. 24","FIG. 23"]},{"@attributes":{"id":"p-0047","num":"0045"},"figref":["FIG. 25","FIG. 23"]},{"@attributes":{"id":"p-0048","num":"0046"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0049","num":"0047"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0050","num":"0048"},"figref":["FIG. 28","FIG. 19"]},{"@attributes":{"id":"p-0051","num":"0049"},"figref":["FIG. 29","FIG. 19"]},{"@attributes":{"id":"p-0052","num":"0050"},"figref":"FIGS. 30A and 30B"}]},"DETDESC":[{},{}]}
