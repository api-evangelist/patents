---
title: System and method for automatically generating systematic reviews of a scientific field
abstract: A system and method are provided for automatically generating systematic reviews of received information in a field of science and technology, such as scientific literature, where the systematic review includes a systematic review of a research field in the scientific literature. The method is preferably implemented by a programmed computer and includes the steps of constructing a time series networks of words, passages, documents, and citations and/or co-citations within received information into a synthesized network, decomposing the networks into clusters of fields or topics, performing part-of-speech tagging of text within the received information to provide tagged text, constructing semantic structures of concepts and/or assertions extracted from the source text, generating citation-based and content-based summaries of the clusters of fields or topics and the semantic structures including measuring the saliency, novelty, significance, and transformative features of individual entities in the clusters of fields or topics and semantic structures, and generating structured narratives of the clusters of fields or topics and the summaries of the generated semantic structures, including labeling and summarizing features of the clusters of fields or topics and delinearizing the resulting clusters into templates that provide summarizations of the structure and trends of the information in the clusters at multiple levels of abstraction. Narratives of the citation-based and content-based summaries are merged into a systematic review having a predetermined arrangement.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08566360&OS=08566360&RS=08566360
owner: Drexel University
number: 08566360
owner_city: Philadelphia
owner_country: US
publication_date: 20110527
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","STATEMENT OF GOVERNMENT INTEREST","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS"],"p":["This application claims benefit of Provisional Application No. 61\/349,632 filed May 28, 2010.","This invention was made with government support under Grant No. IIS-0612129 awarded by the National Science Foundation. The government has certain rights in the invention.","The invention relates to a system and method for automatically generating systematic reviews of a scientific field and, more specifically, to a system and method for transforming textual documents representing a scientific domain into an automatically constructed systematic narrative of the domain in terms of the structure and semantics of the underlying scientific literature. The invention also relates to a system and method for quantifying the potential value of newly available scientific work with reference to the systematic representation of the relevant scientific fields.","The volume of scientific publications in general has been increasing tremendously and rapidly across a wide range of scientific fields and disciplines. Such a rapid and tremendous increase means that scientists have to deal with an increasingly thick layer of transient information and that they have to distill the valuable knowledge from more noises and uncertainties associated with the overwhelming amount of input as a whole in a timely way.","The core knowledge of a scientific field is largely documented in its literature in the form of peer reviewed and non-peer reviewed publications. Peer reviewed publications are considered of higher value than non-peer reviewed ones because the science reported in peer reviewed publication is safeguarded by peer scientists and they are more likely to have met the rigorous and stringent criteria. This description will primarily focus on peer reviewed publications; however, those skilled in the art will appreciate that the method described herein is equally applicable to non-peer reviewed publications and other types of text such as patent applications and technical reports.","A body of scientific literature serves two primary roles in the advancement of science: archival and communicative roles. A well-known conception of the structure of scientific literature in the study of science is that scientific literature consists of two principal components: one is classic and the other is transient. The classic component of scientific literature contains well-documented and well-established knowledge of a scientific field; or collective domain knowledge associated with the underlying scientific community. The classic component forms the backbone of the domain knowledge because it represents the fundamental value of the scientific domain, including its principles, methodologies, and major claims. In contrast, the transient component represents the most recent attachment to the backbone structure. It includes the latest publications of new results and new findings. The nature of such attachment remains transient until new publications have been subject to the selection of the scientific community. Such transient layers are sometime known as research fronts. The selection can lead to one of the outcomes: acceptance, rejection, and indifference, although both the structure of such backbones and these outcomes regarding the research fronts are subject to further change as new evidence becomes available or new theories become predominant. The degree of a selection is often measured in terms of the citations received, i.e. the number of times subsequently published articles make references to the work. The more citations of a work, the greater its perceived impact is on the scientific field and therefore the more value it adds to the development of scientific knowledge.","Systematic reviews, comprehensive surveys, and meta analytical studies are among the most common and effective means used by scientists, scholars, and people with similar needs to maintain their understanding of their fields. These methods share similar goals of identifying significant contributions and potential challenging issues and future research directions. They all rely on scientific literature as a primary source of input and try to clarify the state of the art. On the other hand, they have some inherited shortcomings: time consuming, labor intensive, biased by the view of the few. As a result, such reviews are often separated by an extensive period of time. These reviews and surveys are typically performed by experts. Since experts tend to be specialized in some but not all areas of a field, the coverage can be biased by their own preferences and knowledge.","A new approach to reviewing developments in a scientific field without the bias and time consuming approach of the prior art is desired. In particular, a technique is desired whereby quantitative, as opposed to qualitative, reviews of a scientific field may be generated automatically with high scalability and medium to low cost. The present invention is designed to address these needs in the art.","The invention addresses the afore-mentioned needs in the art by transforming a stream of textual documents representing a scientific domain into an automatically constructed systematic narrative of the domain in terms of the structure and semantics of its literature. The system and method described herein overcomes some of the major weaknesses of the traditional labor-intensive approaches so that it can automatically generate a summary of the state of the art of a field. The invention may be applied to the study of a field repeatedly, periodically, and on-demand. New reports and updates can be generated at minimum costs. Automatically generated summaries will be valuable in their own right as a new form of documentation. In addition, the summaries may be incorporated into a traditional review method with a considerably reduced amount of overhead.","In accordance with an exemplary embodiment of the invention, a method of automatically generating systematic reviews of information received from a source text in a field of literature, such as scientific literature, includes the steps of constructing associative networks of entities such as words, sentences, documents, journals, institutions, and citations within the received information; decomposing the associative networks into clusters of topics or fields; performing information extraction with natural language techniques such as part-of-speech tagging of text within the received information; constructing semantic and ontological structures of concepts and\/or assertions extracted from the source text; generating citation-based and content-based summaries of the clusters of topics or fields and the semantic and ontological structures; and generating structured narratives of the clusters of field or topic-characterizing entities and the summaries of the generated semantic structures. The method also includes the step of merging narratives of the citation-based and content-based summaries into a systematic review having a predetermined arrangement.","In an exemplary embodiment, the step of generating citation-based and content-based summaries of the clusters of fields or topics and the semantic structures includes measuring the saliency, novelty, significance, and transformative features of individual entities in the clusters of fields or topics and semantic representations of the underlying knowledge. In the exemplary embodiment, the step of generating structured narratives of the cluster of fields or topics and the summaries of the generated semantic structures includes labeling and summarizing features of the clusters of fields or topics and delinearizing the characteristics of such clusters into templates that provide summarizations of the structure and trends of the topic or field evolution at multiple levels of abstraction.","Particular embodiments of the method include constructing associative networks of scientific publications, including citation, co-citation, and other types of semantic networks, within the received information by selecting node types and link types for each time slice of the received information, computing similarity or proximity scores for the nodes, constructing networks of the node information, and merging respective networks from different time slices. The associative networks are then decomposed into clusters of research topics by clustering nodes and measuring quality of the clustering by calculating structural diagnostic scores such as modularity and mean silhouette scores. In such embodiments, generating citation-based and content-based summaries of the clusters of fields or topics and the semantic structures includes identifying citers to and cited members of a cluster, summarizing structural and temporal properties of the cluster, computing metrics of saliency and novelty for an associative network formed by the cluster, ranking the clusters based on the saliency and\/or novelty metrics, and generating structured narratives from the ranked clusters. The structured narratives of the clusters of fields or topics and the summaries of the generated semantic structures may be generated by selecting a narrative template from a set of predefined templates.","The part-of-speech tagging is performed by annotating the received information by a type of each word in the received information and segmenting the received information into sentences, paragraphs, or other types of passages. On the other hand, constructing semantic structures of concepts and\/or assertions extracted from the tagged text includes the step of constructing a structured representation of concepts and a semantic network of assertions in the received information and merging a newly constructed semantic structure with an existing semantic structure to differentiate different sources for the newly constructed and existing semantic structures. The merged structures may be ranked based on saliency and novelty, generating narratives of top ranked concepts and\/or assertions in the received information, and merging generated narratives in a predetermined order.","The scope of the invention also includes systems having programmed processors and computer readable storage media having instructions stored thereon for implementing the methods of the invention.","A detailed description of illustrative embodiments of the present invention will now be described with reference to . Although this description provides a detailed example of possible implementations of the present invention, it should be noted that these details are intended to be exemplary and in no way delimit the scope of the invention.","System Overview",{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 1","FIG. 2","FIG. 2"]},"1. Time Slicing","The purpose of time slicing is to establish the sampling rate that should be applied to the events of interest. The window of observation w is the entire time interval of interest, for example, a century, a few decades, or several weeks. Time slicing divides the window of observation into consecutive time slices {w}. The process of time S slicing can be expressed as a mapping from w\u2192{w}, where w=[t, t], for t<t:\n\n(,overlap(), width())=()\u2003\u2003(1)\n",{"@attributes":{"id":"p-0041","num":"0040"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":{"munder":{"mo":"\u22c3","mi":"i"},"mo":"\u2062","msub":{"mi":["w","i"]}},"mo":"=","mi":"w"}},{"mrow":{"mo":["(",")"],"mn":"2"}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"overlap","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"msub":[{"mi":["w","n"]},{"mi":"w","mrow":{"mi":"n","mo":"-","mn":"1"}}],"mo":"\u22c2"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}]}}},"br":{},"in-line-formulae":[{},{}],"i":["n","t","\u2212t"],"sub":["n","n\u22121"]},"The function overlap(n) defines whether adjacent time slices should overlap. The width(n) function defines the duration of each time slice. Equation 2 ensures that the partition covers the entire window of observation.","Most observation windows can be meaningfully divided using one of the three most common strategies, a, b, or c, as shown in . As illustrated in , a non-overlapping varying-length time slicing is defined with the following overlap and width functions:",{"@attributes":{"id":"p-0043","num":"0042"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"overlap","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"mrow":{"msub":[{"mi":["w","n"]},{"mi":"w","mrow":{"mi":"n","mo":"-","mn":"1"}}],"mo":"\u22c2"},"mo":"=","mi":"\u2205"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}},"br":{},"in-line-formulae":[{},{}],"i":["n","t","\u2212t","=f","n"],"sub":["n","n\u22121"]},"A non-overlapping even-length time slicing is defined with the following overlap and width functions:",{"@attributes":{"id":"p-0044","num":"0043"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"overlap","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"mrow":{"msub":[{"mi":["w","n"]},{"mi":"w","mrow":{"mi":"n","mo":"-","mn":"1"}}],"mo":"\u22c2"},"mo":"=","mi":"\u2205"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"7"}}]}}}},"br":{},"in-line-formulae":[{},{}],"i":["n","t","\u2212t"],"sub":["n","n\u22121"]},"An overlapping even-length time slicing is defined with the following overlap and width functions, for example, with a 25% of overlap between adjacent time slices:",{"@attributes":{"id":"p-0045","num":"0044"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"overlap","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"mrow":[{"msub":[{"mi":["w","n"]},{"mi":"w","mrow":{"mi":"n","mo":"-","mn":"1"}}],"mo":"\u22c2"},{"mo":["[","]"],"mrow":{"mrow":{"mn":"0.75","mo":"*","msub":{"mi":["t","n"]}},"mo":",","msub":{"mi":["t","n"]}}}],"mo":"="}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}},"br":{},"in-line-formulae":[{},{}],"i":["n","t","\u2212t"],"sub":["n","n\u22121"]},"The type b of time slicing is the simplest and the most common choice. For continuity reasons, one may consider overlapping time slicing strategy c. For density reasons, one may consider the option a so that each time slice contains the same number of observations.","The time slicing of text can be done based on the creation time or the last updated time of the text. On the other hand, the time slicing of references can be done based on the time a reference was made, for example, all the references made in year 2009.","2. Constructing Associative Networks","For each time slicing strategy, one can derive a time series of associative networks. These networks serve as a sequence of snapshots of an evolving process. Each network is defined by a set of entities (nodes or vertices) and a set of relations (links or edges). The following notations are used for G=G(V, E, w), the network defined in the itime slice w:\n\n","If the only available source is text, i.e. with no references, possible choices of entities include words, phrases, and index terms (either given by the original authors or assigned by human indexers) as well as documents. Interrelations among these entities include direct counts of co-occurrence in containing units such as sentences, paragraphs, or documents. Other types of interrelations may be derived from higher order matrix operations such as singular value decomposition of term-by-document matrices. Interrelations may be also derived from linguistic patterns, for example, associations between a head noun and its modifiers as the connection between star and formation from star formation. Table 1 illustrates possible types of entities and relations for text, including but not limited to (1) co-occurrence and (2) similarity (including mutual information, vector space model etc.).",{"@attributes":{"id":"p-0051","num":"0053"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"8"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"28pt","align":"center"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"7","align":"center","rowsep":"1"}}]},{"entry":[{},{},{},"Index","Sen-",{},{},{}]},{"entry":[{},"Word","Phrase","term","tence","Passage","Document","Cluster"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"7","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"8"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"7","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"8","colwidth":"28pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Word","1","1","1","2","2","2","2"]},{"entry":["Phrase",{},"1","1","2","2","2","2"]},{"entry":["Index term",{},{},"1","2","2","2","2"]},{"entry":["Sentence",{},{},{},"2","2","2","2"]},{"entry":["Passage",{},{},{},{},"2","2","2"]},{"entry":["Document",{},{},{},{},{},"2","2"]},{"entry":["Cluster",{},{},{},{},{},{},"2"]},{"entry":{"@attributes":{"namest":"1","nameend":"8","align":"center","rowsep":"1"}}}]}}]}}},"If references are available in the sources of input, network entities include cited references as well as all the entities derivable from text. The citation context of a cited reference is defined as the hosting sentence, paragraph, document, or a cluster of documents based on textual similarity or citation similarity. Table 2 illustrates relations in associative networks involving cited references.",{"@attributes":{"id":"p-0053","num":"0055"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"63pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 2"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},{},"Citation Context","Cited Reference"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Citation Context ","Similarity","Citation"]},{"entry":[{},"Cited Reference","Citation","Co-citation"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}}}},"3. Synthesizing a Time Series of Networks","Individual networks corresponding to a given time slicing scheme are synthesized over the entire time span of interest. Different networks G=G(V, E, w) are synthesized into G(V, E, w) in one of the two methods: na\u00efve or advanced. The na\u00efve method is defined in equations 11-13, by simply taking set unions of the entities and all relations.",{"@attributes":{"id":"p-0056","num":"0058"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"V","mo":"=","mrow":{"munderover":{"mo":"\u22c3","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"n"},"mo":"\u2062","msub":{"mi":["V","i"]}}}},{"mrow":{"mo":["(",")"],"mn":"11"}}]},{"mtd":[{"mrow":{"mi":"E","mo":"=","mrow":{"munderover":{"mo":"\u22c3","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"n"},"mo":"\u2062","msub":{"mi":["E","i"]}}}},{"mrow":{"mo":["(",")"],"mn":"12"}}]},{"mtd":[{"mrow":{"mi":"w","mo":"=","mrow":{"munderover":{"mo":"\u22c3","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"n"},"mo":"\u2062","msub":{"mi":["w","i"]}}}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}]}}},"br":{}},{"@attributes":{"id":"p-0057","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"V","mo":"=","mrow":{"munderover":{"mo":"\u22c3","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"n"},"mo":"\u2062","msub":{"mi":["V","i"]}}}},{"mrow":{"mo":["(",")"],"mn":"14"}}]},{"mtd":[{"mrow":{"mi":"E","mo":"=","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"munderover":{"mo":"\u22c3","mrow":[{"mi":"i","mo":"=","mn":"0"},{"mi":"n","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["E","i"]},"mo":"\u22c3","mrow":{"msub":[{"mi":"E","mrow":{"mi":"i","mo":"+","mn":"1"}},{"mi":["E","i"]},{"mi":"E","mrow":{"mi":"i","mo":"+","mn":"1"}}],"mo":["-","\u22c2"]}}}},{"mo":["(",")"],"mrow":{"munderover":{"mo":"\u22c3","mrow":[{"mi":"i","mo":"=","mn":"0"},{"mi":"n","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mi":"pruning","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["E","i"]},{"mi":"E","mrow":{"mi":"i","mo":"+","mn":"1"}}],"mo":"\u22c2"}}}}}],"mo":"\u22c3"}}}},{"mrow":{"mo":["(",")"],"mn":"15"}}]},{"mtd":[{"mrow":{"mi":"w","mo":"=","mrow":{"munderover":{"mo":"\u22c3","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"n"},"mo":"\u2062","msub":{"mi":["w","i"]}}}},{"mrow":{"mo":["(",")"],"mn":"16"}}]}]}}}},"Candidate pruning functions include minimal spanning tree (MST), Pathfinder network scaling (PFnet), and any other link reduction operations. It is known that a Pathfinder network is the set union of all the possible minimal spanning trees of the original network:",{"@attributes":{"id":"p-0059","num":"0061"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"PFnet","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"G"}},{"mo":"\u22c3","mrow":{"mi":"MST","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"G"}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"17"}}]}}}},"br":{}},"The synthesized network can be visualized with visual encoding to highlight temporal aspects of the underlying knowledge transformation. For example, edges can be colored in corresponding to the time slice in which associative connections were made for the first time. Alternatively, edges can be colored by the most recent time slice.",{"@attributes":{"id":"p-0061","num":"0063"},"figref":"FIG. 4"},"4. Clustering the Synthesized Network","Once the time series of networks are synthesized into a panoramic network spanning the entire time frame, the next step is to aggregate individual nodes and links and form components of higher-level abstraction. By grouping similar nodes and links together, one can identify emergent patterns at higher levels and produce a clarified macroscopic structure. The aggregated structure will be used as key components in the subsequent narrative generation steps. Since this step is clustering by nature, it is referred to herein as the clustering step. However, this step is also known as graph decomposition because as a result of the step, the network is divided into a number of groups, or cluster's, such that members of the same cluster are more similar, as measured in a chosen metric, than members from different clusters.","The best clustering algorithm would make no assumption about the structure or the distributions of nodes and links. It should be purely based on the strengths of linkage. The spectral clustering family of algorithms provides the best candidate clustering algorithms to meet this requirement.","Hard clustering approaches partition a network into a number of non-overlapping clusters. It is more efficient to use non-overlapping clusters than overlapping ones to differentiate the nature of different co-citation clusters, although it is conceivable to derive a soft clustering version of this particular component.","Co-citation similarities between items i and j are measured in terms of cosine coefficients. If A is the set of papers that cites i and B is the set of papers that cite j, then",{"@attributes":{"id":"p-0067","num":"0069"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":["w","ij"]},"mo":"=","mfrac":{"mrow":{"mo":["|","|"],"mrow":{"mi":["A","B"],"mo":"\u22c2"}},"msqrt":{"mrow":{"mo":["|","|"],"mi":"A","mrow":{"mo":"\u00d7","mrow":{"mo":["|","|"],"mi":"B"}}}}}},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0068","num":"0070"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":["w","ij"]},"mo":"=","mfrac":{"mrow":[{"mo":["|","|"],"mrow":{"mi":["A","B"],"mo":"\u22c2"}},{"mo":["|","|"],"mrow":{"mi":["A","B"],"mo":"\u22c3"}}]}},"mo":","}}},"br":{}},"A good partition of a network would group strongly connected nodes together and assign loosely connected ones to different clusters. This idea can be formulated as an optimization problem in terms of a cut function defined over a partition of a network. Technical details of spectral clustering algorithms are given by (Luxburg in \u201cA tutorial on spectral clustering,\u201d http:\/\/www.kyb.mpg.de\/publications\/attachments\/Luxburg06_TR_%5B0%5D.pdf, Ng, et al. in \u201cOn spectral clustering: Analysis and an algorithm,\u201d Advanced in Neural Information Processing Systems, Vol. 14(2), pp. 849-856 (2002), and Shi, et al in \u201cNormalized Cuts and Image Segmentation,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 22(8), pp. 888-905 (2000). A partition of a network G is defined by a set of sub-graphs {G} such that",{"@attributes":{"id":"p-0070","num":"0072"},"maths":[{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"G","mo":"=","mrow":{"munderover":{"mo":"\u22c3","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","msub":{"mi":["G","k"]}}}}},{"@attributes":{"id":"MATH-US-00010-2","num":"00010.2"},"math":{"@attributes":{"overflow":"scroll"},"mi":"and"}},{"@attributes":{"id":"MATH-US-00010-3","num":"00010.3"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":{"msub":[{"mi":["G","i"]},{"mi":["G","j"]}],"mo":"\u22c2"},"mo":"=","mi":"\u03d5"},"mo":","}}}],"br":{}},{"@attributes":{"id":"p-0071","num":"0073"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":"cut","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["A","B"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mrow":[{"mi":["i","A"],"mo":"\u2208"},{"mi":["j","B"],"mo":"\u2208"}],"mo":","},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","msub":{"mi":["w","ij"]}}],"mo":"="},"mo":","}}},"br":{},"sub":"ij"},{"@attributes":{"id":"p-0072","num":"0074"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","mrow":{"mrow":{"mi":"cut","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["G","k"]},{"mi":["G","k"]}],"mo":","}}},"mo":"."}}}},"br":{}},{"@attributes":{"id":"p-0073","num":"0075"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","mrow":{"mrow":{"mi":"cut","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["G","k"]},"mo":",","mrow":{"mi":"G","mo":"-","msub":{"mi":["G","k"]}}}}},"mo":"."}}}},"br":{}},{"@attributes":{"id":"p-0074","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","mfrac":{"mrow":[{"mi":"cut","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["G","k"]},"mo":",","mrow":{"mi":"G","mo":"-","msub":{"mi":["G","k"]}}}}},{"mi":"vol","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["G","k"]}}}]}}}},"br":{},"sub":["k","k"]},{"@attributes":{"id":"p-0075","num":"0077"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"vol","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["G","k"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"\u2208","msub":{"mi":["G","k"]}},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mi":"j","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"msub":{"mi":["w","ij"]},"mo":"."}}}],"mo":"="}}}},"Spectral clustering algorithms identify clusters based on eigenvectors of Laplacian matrices derived from the original network. Spectral clustering has several desirable features compared to traditional algorithms such as k-means and single linkage. For example, spectral clustering is more flexible and robust because it does not make any assumptions on the forms of the clusters, because it makes use of standard linear algebra methods to solve clustering problems, and because it is often more efficient than traditional clustering algorithms.",{"@attributes":{"id":"p-0077","num":"0079"},"figref":["FIG. 5","FIG. 5"]},"5. Measuring Saliency, Novelty, and Significance","The resultant clusters provide an appropriate context for defining the saliency, novelty, and significance of individual entities. Several types of importance can be derived from a given clustered structure.","Saliency","The saliency of a node can be defined within the scope of its cluster, its cluster plus neighboring clusters, or the entire network. The one that is defined by its own cluster is the most meaningful choice because its hosting cluster will give enough contextual information while maintaining a clearly differentiable focus.","As illustrated in , the saliency of a node measures the prominence of it within the scope of a cluster, for example, the frequency of a node n, f(n), or a citation of a reference. The homogeneity within a cluster makes it more meaningful to compare the saliency function of nodes in the same cluster than comparing nodes in different clusters. In other words, the saliency of nodes in the red, green, and blue clusters may not be meaningful to compare across clusters, especially across disciplinary boundaries and fields. Candidates of saliency measures include frequency, appearances, probability, likelihood, information entropy, in degree, out degree, age, and many others.","Novelty","The novelty of an entity or a relation in a network measures the extent to which the entity or the relation is new with respect to the history of the network evolution. The simplest notion of novelty can be defined as something that has never seen in the past. A more useful measure of novelty needs to identify not only something that is new, but also potentially valuable. The potential value of an entity or a relation can be estimated with reference to their positions in the network, especially in terms of clusters.","There are three relevant aspects of the novelty measurement: structural, temporal, and semantic metrics. Structural metrics include measurements such as centrality, modularity, and silhouette. Temporal and hybrid metrics include citation burstness and novelty. Structurally, an entity or a relation that links distinct clusters is potentially valuable. The emergence of such items may imply noteworthy novelty. Betweenness centrality can be used to identify bridges or gatekeepers between clusters. The betweenness centrality metric is defined for each node, also possible for each link, in a network. The metric measures the probability that the node, or the link, is in the middle of an exclusive path connecting other nodes or distinct areas of a network. The higher such a probability is, the higher the centrality value is. High betweenness centrality values identify potentially revolutionary scientific publications as well as gatekeepers in social networks. Other types of centrality measures are also available, including the power centrality introduced by Bonacich in \u201cPower and centrality: A family of measures,\u201d American Journal of Sociology, Vol. 92, pp. 1170-1182 (1987) and PageRank. The strategically significant positions of these bridges and gatekeepers should be closely watched as these are the important candidates to be featured in systematic reviews of the subject matter. For example, in , the unique positions of the three highlighted nodes (of high betweenness centrality) make them more likely to host novel ideas than other positions in the network.","The novelty of a connection made by an article in a co-citation network reflects the potential novelty of the underlying idea with reference to the structure prior to the publication of the article. Modularity variation rate (\u0394Modularity), inter-cluster brokerage, and centrality variation divergence (\u0394Centrality) are introduced herein as novel metrics of structural variation. The first two are defined based on the cluster structure of the underlying network, whereas the third is defined based on individual nodes. These three measures are referred as intrinsic measures of creativity. For comparison, the number of cited references (NR) and the length of each article in terms of the number of pages (Length) are also included because they are among the most commonly used predictors of future citations of an article. These two measures are referred as extrinsic measures.","A \u0394is defined to measure the novel associations added across aggregations of nodes. First, decompose G(V, E) to a set of clusters, {C}; in this case, Cis a co-citation cluster. Given a cluster configuration, the modularity of the network can be computed. The modularity measures whether the network can be decomposed nicely with the given clusters. A high modularity means that the given cluster configuration can divide the network into relatively independent partitions with few cross cluster edges. In contrast, a low modularity means that the given cluster configuration cannot divide the network without many cross-cluster edges. If a new paper s\u2032 adds an edge connecting members of the same cluster, it will have no impact on the modularity. It will not make any difference to the value of \u0394. On the other hand, if s\u2032 adds an edge between different clusters and the two clusters are previously not connected, the modularity of the new structure will be lower than that of the original structure.","The modularity of a network is a function of a set of alternative partitions of the network. Some partitions lead to a higher modularity, whereas others lead to lower modularity scores. The optimal partition can be determined based on the variation of modularity scores over different partitions of the same network. Since the maximum modularity implies the maximum separation of various network components, it is often used as a criterion to choose the corresponding clusters as the most representative solution.","The modularity variation rate of an article a is defined to capture the extent to which the modularity of the co-citation network changes as a result of connections made by a particular article. This definition assumes that the network is decomposed into a number of clusters.",{"@attributes":{"id":"p-0090","num":"0092"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"Modularity","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"a"}}},"mo":"=","mfrac":{"mrow":[{"mi":"Modularity","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"G","mo":"\u22c3","mrow":{"mi":"Citations","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"a"}}}}},{"mi":"Modularity","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"G"}}]}}}},"br":{}},"Inter-cluster brokerage is also defined as the basis of a network decomposed into clusters. For each article a, this metric is defined as follows:",{"@attributes":{"id":"p-0092","num":"0094"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["Brokerage","Clusters"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"a"}},{"munderover":{"mo":"\u2211","mi":"ij","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"msub":{"mi":["\u03b4","ij"]},"mo":"\u00b7","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msub":{"mi":["w","ij"]}}}}}],"mo":"="}}},"br":{},"in-line-formulae":[{},{}],"sub":["u","j"]},"The function \u03b4scores 1 if the article a adds a link between references i and j across different clusters. The score is weighted by the overlap between the corresponding clusters \u03c9. This metric takes the position of each node in the network into account. It is defined according to the change of centrality scores of all the nodes in the network. The node centrality of a network G(V, E), C(G), is a distribution of the centrality scores of all the nodes, <c, c, . . . , c>, where cis the centrality of node nand n is |V|, the total number of nodes. The degree of structural change \u03b4E can be defined in terms of the K-L divergence; this metric is denoted as \u0394.","Temporally, it is more valuable to identify an entity or a relation as part of an emerging trend rather than an isolated event. Burst detection determines whether a given frequency function has statistically significant fluctuations during a short time interval within the overall time period. Burst detection is valuable for citation analysts to detect whether and when the citation count of a particular reference has surged. It can also be used to detect whether a particular connection has been significantly strengthened within a short period of time. The notion of burst detection provides a useful candidate for identifying the temporal aspect of novelty. The goal of burst detection is to identify a particularly intensified attention spell directed towards an entity or a relation with respect to others during the same period of time.  illustrates the burst of a function f(t) over time. Burst detection algorithms such as the one described by Kleinberg in \u201cBursty and hierarchical structure in streams,\u201d Proceedings of the 8ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 91-101, ACM Press (2002) may be used in an exemplary embodiment of the invention as described herein.","The third aspect of novelty is semantics. An idea that either is introduced for the first time or that contradicts previous or existing beliefs defines a semantically novel idea. The semantic novelty of an entity or a relation can be identified by algorithms that model ontological relations based on natural language processing techniques. For example, when the term gastric bacteria was first mentioned, it contradicted the then-contemporary knowledge that bacteria cannot survive in gastric organs. The appearance of the two words gastric and bacteria can be used by algorithms to construct a knowledge representation based on published articles on a given topic. If a particular instance is not found in the existing knowledge representation, then it is likely to be semantically novel. The coverage and accuracy of novelty detection can be improved by using domain-independent resources such as WordNet and domain-specific controlled vocabulary systems such as the Metathesaurus in UM LS so that different expressions of the same underlying concept in natural language text can be detected.","As illustrated in , if the connection between a square and a circle has never been documented in scientific literature, the relation is regarded as semantically novel. The degree of novelty can be measured in terms of the likelihood that such relations exist based on their distance in the knowledge representation. A semantic distance is defined as the least number of links along the shortest path connecting two entities in an ontological representation, e.g. a hierarchical structure of concepts.","It is possible to define integrative metrics of saliency, novelty, and significance by incorporating each individual metric. For example, a sigma metric a has been derived by Chen et al. in \u201cTowards an explanatory and computational theory of scientific discovery,\u201d Journal of Informetrics, Vol. 3(3), pp. 191-209 (2009) to identify transformative research (scientific novelty) by combining betweenness centrality \u03c6 and burstness \u03b4 as:\n\n\u03c3=(\u03c6+1)\u2003\u2003(18)\n\nWith the definition as Equation 18, the transformativeness becomes equivalent to betweenness centrality plus one if no burstness is detected. Holding the burstness constant, the higher the betweenness centrality, and the stronger the indicator of the potential of being transformative. Similarly, holding the betweenness centrality constant, the stronger the burstness, and the stronger the indicator. By defining sigma in this manner, the brokerage mechanism plays a more prominent role than the rate of recognition by peers.\n","In Chen et al. 2009, the inventors also proposed a generic method of combining multiple metrics using a geometric mean. For example, suppose there are n metrics {\u03c1}, i=1, . . . , n. The geometric mean \u03c1is defined as follows:",{"@attributes":{"id":"p-0099","num":"0101"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"\u03c1","mo":"=","msup":{"mrow":{"mo":["(",")"],"mrow":{"munderover":{"mo":"\u220f","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u03c1","i"]}}},"mfrac":{"mn":"1","mi":"n"}}}},{"mrow":{"mo":["(",")"],"mn":"19"}}]}}}}},"6. Cluster Labeling and Summarization","The procedure for cluster labeling and summarization is slightly-different between text only and cited references.","Text Only","First, assume that the input data contains text only with no cited references. In this case, networks should be derived from the input text. Entities are units of text, such as terms and passages extracted from text as well as documents, and\/or, metadata such as controlled vocabularies assigned to the text. Relations in such networks include co-occurrence, similarity, or probability measures derived from syntactic, statistical, and behavioral patterns using methods such as vector space models, latent semantic indexing, probabilistic latent semantic index, and more generic non-negative matrix factorization (NNMF) and tensor factorization models.","The source text for labeling and summarizing a cluster is the same source of text with restrictions as follows. Given an identified cluster C, its labeling and summarization source text Text(C) is made of all the documents {d\u03b5D} that contain a sufficient supporting evidence of entities and relations in the network. The level of sufficiency can be determined either based on a predefined threshold for a statistical significance level p, i.e. (\u03bd(d(Ci, f(\u03bd)(\u03b5(p(\u03bd)(pO. Thus:\n\nText()={\u2260\u00d8\u039b(\u2200\u03bd\u03b5(\u03bd)\u2267\u03b5(\u03bd)\u2267}\u2003\u2003(20)\n","Text with References","Second, if references are available in the source data, two alternative ways of choosing a body of source text become possible for Equation 20: Text(C) and Text(C). Text(C) consists of text of citers to members of the cluster Cr's, and it is more suitable to represent the impact of the cluster on subsequent research. In contrast, Text(C) forms by text of cited references r, thus it represents what the cluster is about. Note these two are not necessarily always the same.\n\nText()={:cites()}\u2003\u2003(21)\n\nText()={:bibliography()=\u2003\u2003(22)\n","Each of such Text(C) can be processed as a whole by statistical methods, linguistic methods, or a combination of both so as to reduce its dimensionality. The objective of the dimensionality reduction is to identify the top k most significant factors or components that can adequately cover the essence of the cluster. It should be sufficient to limit the k to the first three dimensions, which correspond to the three most important aspects of the underlying cluster.","Statistical dimensionality reduction can be achieved by using standard information retrieval models such as the simple bag-of-word models (vector space models), or singular value decomposition (SVD) of term-by-document matrices, or non-negative matrix factorization. For example, SVD can approximate an otherwise large matrix with a truncated matrix with less amounts of noise.","Linguistic patterns based on part-of-speech (POS) tagging can identify phrases more naturally than bag-of-word models. For example, a noun phrase can be identified by the pattern of adj.+{noun}, or {noun} to capture phrases like gastric bacteria or cancer cells.","Equation 23 illustrates how a cluster can be characterized by a subset of major dimensions:\n\nText()\u2248\u03b1biological_weapons+\u03b1medical_response\u2003\u2003(23)\n\nA cluster's label can be selected from either a single dimension or a composite of terms from multiple dimensions.\n","In an exemplary embodiment, candidates of cluster labels are selected from ranked lists of noun phrases and index terms of citing articles of each cluster. Candidate terms can be ranked by different algorithms. They can also be ranked by a consensus-based algorithm that synthesizes rankings from individual algorithms. For example, noun phrases extracted from titles and abstracts of citing articles can be selected from ranked lists generated by term ranking algorithms such as tf*idf(Salton et al., \u201cA Vector Space Model for information Retrieval,\u201d Communications of the ACM, Vol. 18(11), pp. 613-620 (1975)), log-likelihood ratio (LLR) tests (Dunning, \u201cAccurate methods for the statistics of surprise and coincidence,\u201d Computational Linguistics, Vol. 19(1), pp. 61-74 (1993)), and mutual information (MI). Labels selected by tf*idf weighting tend to represent the most salient aspect of a cluster, whereas those chosen by log-likelihood ratio tests and mutual information tend to reflect a unique aspect of a cluster.","Summarizing a Cluster","Summarization of a cluster can be achieved by enumerating major dimensions by selecting sentences from each dimension or by automatically generating sentences based on corresponding knowledge representations. Specifically, the most representative sentences can be selected as follows to represent one dimension: identify the terms that are most characteristic along this dimension, e.g., in terms of the strengths of their projections on the dimension. Then highly representative terms are used to find sentences that are associated with such terms. For example, selected sentences can form a network. Each sentence is a node. The connection between two sentences indicates how similar they are, e.g. as measured by Jaccard similarity or projections based on eigenvectors of the corresponding matrix. Taking the network of sentences as the input, sentences of the following type are chosen: the sentences that have the highest degree, which are the sentences most central to this particular dimension of the cluster, OR the sentences that have the highest PageRank or other centrality scores. Selected sentences then form the summary of the dimension. Alternatively, summarizations can be constructed by automatic sentence generation based on knowledge representations such as Bayesian belief networks and\/or semantic networks of predicates extracted from text.","Transition sentences that link different dimensions are selected as follows. Take sentences for all dimensions and construct a network of sentences. Sentences of high betweenness centrality will be chosen as transition sentences.","The summarization process is iterative in that each cluster is summarized based on summarizations of its component dimensions. At a higher level, all clusters as a whole are summarized in terms of clusters and interrelationships among them.","7. Linearization","The goal of the final stage of the procedure, linearization, is to generate narratives of individual clusters (at least the largest K clusters and their interrelationship). The linearization mechanism traverses the synthesized network of knowledge and provides summarizations of its structure and trends at multiple levels of abstraction, namely prominent members of clusters, clusters, and the system of clusters. The linearization can be made to comply with predefined templates, for example, of narratives in chronological order, in the size of specialties, in the order of novelty, or a nested combination.",{"@attributes":{"id":"p-0118","num":"0120"},"figref":"FIG. 10","ul":{"@attributes":{"id":"ul0003","list-style":"none"},"li":{"@attributes":{"id":"ul0003-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0004","list-style":"none"},"li":["1. Construct a time series of networks of terms and cited references with a time slicing of 1-year intervals.","2. Synthesize the networks to form a synthesized, panoramic network across the entire time frame.","3. Decompose, or divide, the panoramic network into non-overlapping clusters.","4. For each cluster, apply dimensionality reduction techniques to identify up to three most prominent dimensions, factors, or principle components.","5. For each cluster, choose labels and select summarization sentences (sentences with the highest degrees, PageRank, or other centrality scores) to form narratives for the cluster (See ).","6. For each cluster, generate the narratives in the following order: a description of the most prominent dimensions and key members of each major dimension (the earliest, the most frequently occurred, the most highly cited, or the fastest growing).","7. At the overall domain level, generate the narratives in the following order: start with the largest cluster and expand its narrative generated in step , then move to the next largest cluster until either 80% of the total nodes in the synthesized network are covered, or top 20% of the clusters covered, whichever is reached first. Splits other than 80-20 can be used as needed."]}}}},{"@attributes":{"id":"p-0119","num":"0128"},"figref":"FIG. 10"},"In addition to automatically generate a template-filled systematic review of a domain, the procedure of the invention can support the creation of interactive online exploration of the domain with multiple-level, interactive, and coordinated views.  illustrates an illustrative interface design for exploring the source data.","Exemplary Embodiment","The systems and methods of the invention are preferably implemented in software executed by a processor of a computer system of the type illustrated in  The hardware system will be described in connection with  and then the overall procedure as implemented in software will be described with respect to .","System Hardware",{"@attributes":{"id":"p-0123","num":"0132"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0124","num":"0133"},"figref":"FIG. 11","b":["120","121","122","123","121","123","124","125","126","120","124"]},"The personal computer  may further include a hard disk drive  for reading from and writing to a hard disk (not shown), a magnetic disk drive  for reading from or writing to a removable magnetic disk , and an optical disk drive  for reading from or writing to a removable optical disk  such as a CD-ROM or other optical media. The hard disk drive , magnetic disk drive , and optical disk drive  are connected to the system bus  by a hard disk drive interface , a magnetic disk drive interface , and an optical drive interface , respectively. The drives and their associated computer-readable media provide non-volatile storage of computer readable instructions, data structures, program modules and other data for the personal computer .","Although the exemplary environment described herein employs a hard disk, a removable magnetic disk , and a removable optical disk , it should be appreciated that other types of computer readable media which can store data that is accessible by a computer may also be used in the exemplary operating environment. Such other types of media include a magnetic cassette, a flash memory card, a digital video\/versatile disk, a Bernoulli cartridge, a random access memory (RAM), a read-only memory (ROM), and the like.","A number of program modules may be stored on the hard disk, magnetic disk , optical disk , ROM  or RAM , including an operating system , one or more application programs , other program modules  and program data . A user may enter commands and information into the personal computer  through input devices such as a keyboard  and pointing device . Other input devices (not shown) may include a microphone, joystick, game pad, satellite disk, scanner, or the like. These and other input devices are often connected to the processing unit  through a serial port interface  that is coupled to the system bus, but may be connected by other interfaces, such as a parallel port, game port, or universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video adapter . In addition to the monitor , a personal computer typically includes other peripheral output devices (not shown), such as speakers and printers. The exemplary system of  also includes a host adapter , a Small Computer System Interface (SCSI) bus , and an external storage device  connected to the SCSI bus .","The personal computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be another personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the personal computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet.","When used in a LAN networking environment, the personal computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the personal computer  typically includes a modem  or other means for establishing communications over the wide area network , such as the Internet. The modem , which may be internal or external, is connected to the system bus  via the serial port interface . In a networked environment, program modules depicted relative to the personal computer , or portions thereof, may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Computer  typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media include both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media include, but are not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CDROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer . Combinations of any of the above should also be included within the scope of computer readable media that may be used to store source code for implementing the flow charts described in detail below.","Software Processes","The methodology of the invention will now be described with respect to .","As illustrated in , the input data may contain two major types: text and citations of the scientific literature of a research field. Citations are also referred to herein as cited references and may not always be available from a given data source. The type of data is thus selected at step  and the flow branches to Step  or Step  depending upon the availability of citation data. Step  may utilize the results of Steps  and  or of Steps  through  to summarize the clusters. Narratives on the citation-shaped structure are generated at Step  and\/or narratives on semantic contents are generated at Step . The final output of the procedure is an automatically generated, structured systematic review of the research field as generated at Step . The process of  will be described in more detail below, where each numbered step in  is shown in an individual flow chart in .",{"@attributes":{"id":"p-0134","num":"0143"},"figref":["FIG. 13","FIG. 12"],"b":["2","2","1","2","2","2","3","2","4","2","5"]},"Individual networks from all the time slices, scaled or non-scaled, are merged at step .. Networks are merged with an optional local network scaling applied to the overlapping sub-networks. It should be noted that network scaling can be applied to the merged network (., .) as well as individual networks (.). A technique for time slicing and merging adjacent networks is described, for example, by Chen in \u201cSearching for intellectual turning points: Progressive Knowledge Domain Visualization,\u201d Proc. Natl. Acad. Sci., USA, Vol. 101 (suppl.), pp. 5303-5310 (2004). The contents of these citations are hereby incorporated by reference in their entireties. Sample pseudo code of merging networks includes:",{"@attributes":{"id":"p-0136","num":"0145"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"Let M be merged network;"},{"entry":"For networks g1, g2, ..., gn:"},{"entry":"If edge e in gi or gj only, add e to M;"},{"entry":"If edge e in both gi and gj,"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"If exist e1 and e2 such that weight(e) > weight(e1) + weight(e2),"]},{"entry":[{},"discard e;"]},{"entry":[{},"otherwise add e to M;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"Return M;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0137","num":"0146"},"figref":["FIG. 14","FIG. 12"],"b":["3","3","1","3","2","3","3"]},"Accordingly, a network with a higher modularity is structurally better defined. A cluster configuration with a higher mean silhouette score is of high homogeneity in terms of the relations between the members of a cluster and other connecting clusters. These metrics can be used to guide the refinement of the clustering quality until the results are satisfactory. Alternatively, predefined parameters can be used based on empirical heuristics to avoid any human intervention at runtime. A description of using a non-overlapping clustering algorithm\u2014spectral clustering\u2014and the use of modularity and silhouette metrics is described in the context of labeling co-citation clusters by Chen, et al. in \u201cthe Structure and Dynamics of Co-Citation Clusters: A Multiple-Perspective Co-Citation Analysis,\u201d Journal of the American Society for Information Science and Technology (2010) (submitted).",{"@attributes":{"id":"p-0139","num":"0148"},"figref":["FIG. 15","FIG. 12"],"b":"4"},"Each co-citation cluster corresponds to two sets of items: cited members and citers to these members. The cited members of a cluster are identified at step ., and the citers to a cluster are identified at step .. They are treated differently by sub-processes starting with steps . and ., respectively. Usually cited items contain a lesser amount of information than citing items, which is the case for the Web of Science, Scopus, and Google Scholar, the three most widely used sources of literature data. Data enrichment at step . is thus optional for retrieving additional information for cited items so that they have the same level of detail. Both cited items and citing items contain text data, notably in terms of abstracts, titles, and, to some extent, the full text. The summarization process branches off to two possible routes: summarization based on structural and temporal properties at step . and summarization based on text analysis, including natural language-based summarization (See Steps  through  of ). The summarization based on text analysis may treat the cluster as semantic networks of concepts and assertions, as illustrated at step ..","To summarize structural and temporal properties of a cluster, the cluster is treated as an associative network and metrics of saliency and novelty are computed at step .. Saliency metrics may include the total number of citations received by cited items, the total number of collaborating papers published by authors, and the frequency of term occurrence. As noted above, saliency metrics aim to identify prominent items to the associated scientific field, while novelty metrics aim to measure the extent to which an item is new with respect to the existing time frame of analysis. Useful measures include the degree of sudden increases of access or citation (so-called burst), and the recentness of an item (when it is published for the first time). Items in each cluster are ranked by these numerical metrics at step .. The summarization of the cluster at step . consists of narratives that run through the ranked list of items according to the descending order of saliency and novelty. Users may configure the system so as to start with saliency features or novelty features.","A cluster may be referred to either by its serial number or by labels chosen for the cluster. Cluster labels can be chosen based on the most frequent or most common terms found in its members, or based on available indexing models such as vector space models or variant versions such as latent semantic indexing, probabilistic latent semantic indexing, or non-negative matrix factorization. Statistical term distribution models may be also used to choose a cluster label. Log-likelihood ratio tests and mutual information are possible term ranking mechanisms. Once candidate terms are ranked, top-ranked terms are chosen as the titles of clusters.","The following is an illustrative example narrative of a summary of a cluster:",{"@attributes":{"id":"p-0144","num":"0153"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"441pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"Cluster XXX is the th largest cluster among the total of  clusters. Cluster XXX contains  members, which is the  % of"},{"entry":"the total number of nodes in the entire merged network."},{"entry":"Cluster XXX is labeled as  according to algorithm1,  according to algorithm2, and  according to algorithm3. The mean"},{"entry":"silhouette score of this cluster is , which is relatively high\/low, suggesting a concentration or the lack of a concentration."},{"entry":"These members are cited collectively by  articles. The most cited member is  ( times). The second most cited member is"},{"entry":{"u":["\u2003\u2003\u2003","\u2003\u2003\u2003","\u2003\u2003\u2003"]}},{"entry":{"u":["\u2003\u2003\u2003","\u2003\u2003","\u2003\u2003\u2003"]}},{"entry":"item that has the largest citation burst is (burst rate ). Item  has the highest centrality score. Item  has the highest sigma score"},{"entry":"(a combination of structural and temporal properties). [A figure of citation history can be automatically inserted here for one of the items"},{"entry":"described.]"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"427pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"The most prominent citer to Cluster XXX is , which cites  members of the cluster. The second most prominent citer is"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"441pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"u":["\u2003\u2003\u2003\u2003","\u2003\u2003\u2003","\u2003\u2003\u2003","\u2003\u2003\u2003","\u2003\u2003\u2003"]}},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0145","num":"0154"},"figref":["FIG. 16","FIG. 12"],"b":["5","5","1","5","2","5","3"]},{"@attributes":{"id":"p-0146","num":"0155"},"figref":["FIG. 17","FIG. 12"],"b":["6","6","1","6","2","6","3","6","4"]},{"@attributes":{"id":"p-0147","num":"0156"},"figref":["FIG. 18","FIG. 12"],"b":["7","8","7","1","7","2","7","3","8","1","8","2","8","1","8","2"]},"Regular Expression Patterns","The following patterns illustrate the pattern matching technique that can be used for Step  illustrated in . These patterns are defined hierarchically. Complex patterns are built on simple patterns. The syntax follows the Java language.",{"@attributes":{"id":"p-0149","num":"0158"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"280pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ a white space is defined as one or more space characters, possibly"},{"entry":"\/\/ proceeded by a comma or a semicolon."},{"entry":"Public static String w = \u201c[,;]*\\\\s+\u201d;"},{"entry":"\/\/ a word is defined as a string of printable characters, including one or more hyphens."},{"entry":"\/\/ (?: pattern) instructs the program not to memorize the matched pattern."},{"entry":"Public static String word = \u201c(?:[\u2212\\\\w]+)\u201d;"},{"entry":"\/\/ a single tagged word is defined as a word followed by a part-of-speech tag. Note that"},{"entry":"\/\/ if source text contains \/, it should be replaced with a different character, such as @"},{"entry":"\/\/ For example: international\/nnp is a POS-tagged word"},{"entry":"public static String tagged_word = \u201c(?:\u201d + word + \u201c\/[\\\\w+]+)\u201d;"},{"entry":"\/\/ multiple tagged words consists of one or more tagged_word"},{"entry":"public static String tagged_words = \u201c(?:\u201d + tword + w + \u201c)+\u201d;"},{"entry":"\/\/ a single verb is defined by POS tags such as \/vb, \/vbd, \/vbz , \/vbp, and \/vbn,"},{"entry":"\/\/ but except \/vbg"},{"entry":"public static String single_verb = \u201c(?:\u201d + word + \u201c\/vb[dzpn[{circumflex over (\u2009)}g]])\u201d;"},{"entry":"\/\/ a joint verb group is defined as two single verbs jointed by an and or an or"},{"entry":"public static String verbs = \u201c(?:\u201d + single_verb + \u201c(?:\u201d + w + word + \u201c\/cc\u201d + w +"},{"entry":"single_verb + \u201c)*\u201d + \u201c)\u201d;"},{"entry":"\/\/ a verb group consists of auxiliary terms such as could, should, and would, which are"},{"entry":"\/\/ tagged as \/md and followed by verbs and possibly indefinite verb phrases such as to apply."},{"entry":"Public static String verb = \u201c(?:\u201d + word + \u201c\/md\\\\s+)*\u201d + \u201c(\u201c + _verb1 +"},{"entry":"\u201c(?:(?:\\\\s+\u201d + word + \u201c\/in)|(?:\\\\s+\u201d + word + \u201c\/to\\\\s+\u201d + _verb1 + \u201c))*)+\u201d;"},{"entry":"\/\/article"},{"entry":"public static String dt = \u201c(?:\u201d + word + \u201c\/dt)\u201d;"},{"entry":"\/\/ adverb"},{"entry":"public static String rb = \u201c(?:\u201d + word + \u201c\/rb)\u201d;"},{"entry":"\/\/ single adjective, e.g., really hot"},{"entry":"public static String adj = \u201c(?:\u201d + \u201c(?:\u201d + rb + \u201c\\\\s+)*\u201d + word + \u201c\/jj[s]*)+\u201d;"},{"entry":"\/\/ multiple adjectives, e.g., hot and sore"},{"entry":"public static String adjs = \u201c(?:\u201d + adj + \u201c(?:\\\\s+\u201d + word + \u201c\/cc\\\\s+\u201d + adj + \u201c)*)\u201d;"},{"entry":"\/\/ a single noun. Note that Stanford tagger may tag a word along with a punctuation, e.g.,"},{"entry":"Water,\/nn"},{"entry":"public static String _noun = \u201c(?:\u201d + word + \u201c\/nn[sp]*)\u201d;"},{"entry":"\/\/ a noun may be modified by an article and\/or a number of adjectives."},{"entry":"\/\/ for example, really\/rb hot\/jj and\/cc sore\/jj vinger\/nn, cold\/jj water\/nn"},{"entry":"public static String noun = \u201c(?:\u201d + \u201c(?:\u201d + dt + \u201c\\\\s+)*\u201d + \u201c(?:\u201d + adjs + \u201c\\\\s+)*\u201d +"},{"entry":"_noun + \u201c)\u201d;"},{"entry":"\/\/ two nouns jointed by an and or an or"},{"entry":"public static String nouns2 = \u201c(?:(?:\u201d + noun + \u201c(?:\u201d + w + \u201c)*(?:\u201d+ word + \u201c[,;]*\/cc\u201d"},{"entry":"+ w + \u201c)*)*\u201d + noun + \u201c)\u201d;"},{"entry":"\/\/ auxiliary definition"},{"entry":"public static String nouns = \u201c(?:\u201d + noun +\u201d)\u201d;"},{"entry":"\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/ noun_phrase \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/"},{"entry":"\/\/ a noun of noun"},{"entry":"public static String noun_phrase = \u201c((?:\u201d + nouns2 + w + \u201cof\/in\u201d + w+ \u201c)*\u201d + nouns2 +"},{"entry":"\u201c)\u201d;"},{"entry":"\/\/ gerund, used as part of a predicate"},{"entry":"public static String vbg = \u201c(\u201c + word + \u201c\/vbg\u201d + w + twords + \u201c(?:\u201d + noun + \u201c|\u201d +"},{"entry":"noun_phrase +\u201d)*)\u201d;"},{"entry":"\/\/ a subject is defined either as a noun, a noun phrase, or a proposition"},{"entry":"public static String subject = \u201c(\u201c + noun + \u201c|\u201d + noun_phrase + \u201c|\u201d + word + \u201c\/prp)\u201d;"},{"entry":"\/\/ relation, such as greater than, less than, equal to"},{"entry":"public static String relation = \u201c(?:\u201d + word + \u201c\/jjr\\\\s+\u201d + word + \u201c\/in)\u201d;"},{"entry":"\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/ action \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/"},{"entry":"\/\/ example: can be classified: can\/md be\/vb classified\/vbn"},{"entry":"public static String action = \u201c(\u201c + word + \u201c\/md\\\\s+)*\u201d + \u201c(?:\u201d + word + \u201c\/rb\\\\s+)*\u201d +"},{"entry":"\u201c(?:\u201d + _verb + \u201c[\\\\s+]*)+\u201d;"},{"entry":"public static String actions = \u201c((?:\u201d + action + \u201c(?:\u201d + w + word + \u201c\/cc\u201d + w + action"},{"entry":"+ \u201c)*)|\u201d + relation + \u201c)\u201d;"},{"entry":"\/\/ clause"},{"entry":"public static String clause =\u201d(\u201c + noun + w + \u201cthat\/in\u201d + w + twords + \u201c)\u201d;"},{"entry":"\/\/ an object is defined as either a gerund, a noun phrase, or a clause"},{"entry":"public static String object = \u201c(?:\u201d + vbg + \u201c|\u201d + noun_phrase + \u201c|\u201d + clause + \u201c)*\u201d;"},{"entry":"\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/ assertion \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/"},{"entry":"\/\/ an assertion is defined as the structure of a subject + a verb group + a noun phrase or a gerund"},{"entry":"public static String assertion = \u201c(?:\u201d + subject1 + w + verb + w + \u201c(\u201c + noun_phrase"},{"entry":"+ \u201c|\u201d + noun + \u201c|\u201d + vbg + \u201c))\u201d;"},{"entry":"\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/ predicate \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/"},{"entry":"public static String predicate = \u201c(\u201c + noun + w + verb + \u201c)\u201d;"},{"entry":"\/\/ rhetorical pattern"},{"entry":"public static String rhetorical = \u201c(\u201c + subject + w + actions + w + \u201cthat\/in)\u201d;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"Semantic networks generated at . can be stored as a network or a hierarchical structure. In order to be stored as a hierarchy, head nouns are treated as parent nodes and their attributive nodes are treated as children nodes. For example, \u201calgorithm\u201d is the parent of \u201cnew\u201d in the above example. Similarly, \u201cwe\u201d is the parent node of \u201cpropose,\u201d which is in turn the parent node of \u201calgorithm.\u201d","A new semantic structure can be merged with an existing semantic structure at .. For comparative studies, it is often useful to differentiate two different sources. Two semantic components from two different sources may be related in two possible ways: 1. The two components overlap, 2. The two components do not overlap. Merging two structures can be done by merging common ancestor nodes up to where they differ. For example, merging \u201cwe propose a new algorithm\u201d with \u201cwe propose a faster algorithm\u201d would align \u201cwe,\u201d \u201cpropose,\u201d and \u201calgorithm,\u201d but branch off to two different nodes \u201cnew\u201d and \u201cfaster\u201d as the children nodes of \u201calgorithm.\u201d Sample pseudo code for a pattern matching routine is set forth below:","Pseudo code of pattern matching:",{"@attributes":{"id":"p-0153","num":"0162"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"Let C be a concept tree;"},{"entry":"Let P be a predicate tree;"},{"entry":"For sentences s1, s2, ..., sn:"},{"entry":"Find concept patterns and assertion patterns in si;"},{"entry":"If c is found, add c to C;"},{"entry":"If p is found, add p to P;"},{"entry":"Return C, P;"},{"entry":"Add c to C:"},{"entry":"Find parent(c) in C;"},{"entry":"If found, find children(c) in C;"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"If found, update frequencies of parent(c) and children(c)"]},{"entry":[{},"Otherwise, add children(c) to parent(c)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"Otherwise, add parent(c) to the root, then add children(c) to parent(c)"},{"entry":"Return;"},{"entry":"Add p to P:"},{"entry":"Find subject(p) in P;"},{"entry":"If found, find verb(p) in P;"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"If found, find object(p) in P,"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"if found, update existing p;"]},{"entry":[{},"otherwise add object(p) to verb(p);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"Otherwise, add verb(p) to subject(p) and add object(p) to verb(p);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"Otherwise, add subject(p) to the root,"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"add verb(p) to subject(p);"]},{"entry":[{},"add object(p) to verb(p);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"Return;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":{},"figref":["FIG. 18","FIG. 18"]},{"@attributes":{"id":"p-0154","num":"0163"},"figref":["FIG. 19","FIG. 12"],"b":["9","10","9","10","9","1","9","2","9","3","9","2","9","3"]},"Merged structures contain assertions further annotated by concept trees, for example, we+propose+algorithm+(a) new; (b) faster. The saliency of such structures can be derived from the saliency of corresponding assertion and concept components. The novelty measure can be similarity derived. Narratives of the top-ranked concepts (.), assertions (.), and items (.) are generated and all narratives for both types of patterns are merged in a user predefined order at ., for example, narratives of concepts first, then narratives of assertions, and finally both. The following is an illustrative example:",{"@attributes":{"id":"p-0156","num":"0165"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"441pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"The most important concept based on the first  years of text is . It has a total of  generations of  children nodes. The size of"},{"entry":"its sub-tree contains % of all the nodes in the concept tree. The most novel concept is , which has a burst of occurrence of "},{"entry":"between  and ."},{"entry":"The most prominent assertion is  +  + . The object  has a total of  generations of  attributive nodes. The"},{"entry":"most novel assertion is  +  + , which first appears in year  with a burst duration of  years since ."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The final step of generating systematic reviews (Step  of ) is illustrated in . The goal is to merge the narratives of two types of data: citation-based and content-based summaries. The order of the appearance between citation-based and content-based summarized can be predefined by users, for example, citation-based summaries to be followed by content-based ones. Corresponding references will be inserted into narratives accordingly.","As illustrated in , the process of generating systematic reviews includes retrieving the citation-based narratives at step . and retrieving the content-based narratives at step .. The retrieved narratives are matched with corresponding references at step . and arranged at step . and automatically generated systematic reviews are exported at step .. The resultant automatic systematic review consists of summaries of the main intellectual structure defined by citation behavior of the corresponding scientific community and summaries of contents in terms of salient and novel concepts and assertions made by citers as well as cited articles. The systematic review identifies key components of a scientific field. It will serve either as a jump start for additional manual refinements or as a machine-generated and periodically renewed systematic review.","It should be understood that this invention is not limited to the particular embodiments disclosed, but it is intended to cover modifications within the spirit and scope of the present invention as defined by the appended claims. All such modifications of the invention are intended to be covered by the appended claims."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing summary, as well as the following detailed description of the embodiments of the present invention, will be better understood when read in conjunction with the appended drawings. For the purpose of illustrating the invention, there are shown in the drawings embodiments which are presently preferred. As should be understood, however, the invention is not limited to the precise arrangements shown. In the drawings:",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 13","FIG. 12"],"b":"2"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 14","FIG. 12"],"b":"3"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 15","FIG. 12"],"b":"4"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 16","FIG. 12"],"b":"5"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 17","FIG. 12"],"b":"6"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 18","FIG. 12"],"b":["7","8"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 19","FIG. 12"],"b":["9","10","9","10"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 20","FIG. 12"],"b":"11"}]},"DETDESC":[{},{}]}
