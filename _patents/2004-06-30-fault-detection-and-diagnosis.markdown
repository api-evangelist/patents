---
title: Fault detection and diagnosis
abstract: A network troubleshooting framework is described. In an implementation, a method includes detecting discrepancy in operation of a network by supplying data that describes the network to a network simulation so that the network simulation provides an estimation of network performance. A determination is made as to whether the estimation of network performance differs from observed network performance of the network. A root cause of the discrepancy is diagnosed by injecting one or more of a plurality of faults into the network simulation until the estimation of network performance approximates the observed network performance.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07583587&OS=07583587&RS=07583587
owner: Microsoft Corporation
number: 07583587
owner_city: Redmond
owner_country: US
publication_date: 20040630
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The present invention claims priority under 35 U.S.C. \u00a7 119(e) to U.S. Provisional Patent Application Ser. No. 60\/540,738, filed Jan. 30, 2004, which is titled \u201cFault Detection, Isolation, and Diagnosis in Multi-Hop Wireless Networks\u201d.","The present invention generally relates to wired and wireless networks, and more particularly relates to a network troubleshooting framework for detection and diagnosis of faults in a network.","Network management, although a key ingredient in a successful deployment of a multi-hop wireless network, has received limited attention by both industry and research communities. Troubleshooting a network is an aspect of network management that is responsible for maintaining the \u201chealth\u201d of the network and for ensuring its smooth and continued operation. Troubleshooting a network, whether wired or wireless, is complicated by interactions encountered among different network entities, among different faults, and so on.","Troubleshooting a multi-hop wireless network is further complicated by a variety of additional factors. For instance, typical multi-hop wireless networks are generally prone to link errors caused by signal propagation fluctuations. The signal propagation fluctuations may be caused by a variety of factors, such as fluctuating environmental conditions. These fluctuations result in a network topology that is dynamic and unpredictable. Node mobility further aggravates these factors, as nodes may be positioned in a variety of locations while connected to the network, thereby increasing the dynamic and unpredictable nature of the network. Additionally, the capacity of multi-hop wireless networks is generally limited due to scarcity of resources (e.g., bandwidth, battery power, and so on), which constrains the amount of management traffic overhead that the network can tolerate. Further, a wireless network may be vulnerable to link attacks from malicious parties. The attackers, for example, can inject false information to disrupt or interfere with the network management effort.","Traditional heuristic and theoretical techniques that were traditionally utilized to perform network troubleshooting typically do not capture the behavior of the network as implemented in a \u201creal\u201d environment. For example, network behavior may be governed by node interaction, one to another, as well as by external noise sources positioned in the vicinity of the nodes. Traditional heuristic or theoretical techniques do not adequately address interaction between the different components of the network with its surrounding environment and therefore do not capture the behavior of such a network.","Accordingly, there is a need for a framework for network troubleshooting that provides improved fault detection and diagnosis.","A network troubleshooting framework is described. The framework may employ a simulation of a real network to detect and diagnose faults in the operation of the real network. For example, a network simulation may be driven by data that describes the operation of the real network. In practice, raw data that is collected for use in driving the network simulation may contain errors for a variety of reasons, such as due to hardware, software, and\/or network errors. To ensure that the data used to drive the network simulation is consistent, the raw data may be cleaned. For example, each node in a network may provide data for use in driving the network simulation. The data provided by a particular node may describe not only that particular node's operation, but also the operation of one or more neighboring nodes. Therefore, the data obtained from the nodes in the network may be redundant. The redundant data is then compared, one to another, to identify any inconsistencies, which may then be rectified in a variety of ways, such as through data averaging, removal of inconsistent data, and so on.","The network simulation may then estimate network performance based on this data. The estimated network performance is compared with observed network performance of the real network performance to detect if the real network is performing as expected. If not, a fault is detected in the operation of the real network. In other words, a difference between the estimated network performance as indicated by the network simulation and the observed network performance as indicated by the real network may be utilized to detect the occurrence of faults in the real network. The network simulation may then be utilized for fault diagnosis by selectively injecting one or more faults into the network simulation until network performance of the network simulation approximates the network performance of the real network.","Once the set of one or more faults that resulted in the approximated network performance are identified, one or more modifications may be identified and implemented to correct the faults. For example, the network simulation may then be utilized to perform what-if analysis such that modifications may be made to the simulated network to test whether the modification corrects the fault and\/or otherwise improves network performance. Thus, the network simulation may provide quantitative feedback on the network performance impact of a variety of modifications that may be made to the network, such as modifications made to correct the faults and\/or improve network performance.","The same numbers are used throughout the disclosure and figures to reference like components and features.","Overview","A network troubleshooting framework is described for use in wired and\/or wireless networks to maintain efficient and reliable network operations. The framework described herein may employ an online trace-driven network simulation to detect faults and perform root cause analysis of the faults. The network simulation is \u201conline\u201d in that it may obtain network performance data from a \u201creal\u201d network.","The framework may be applied to diagnose a wide variety of performance problems (i.e., faults), such as faults caused by packet dropping, link congestion, medium access control (MAC) misbehavior, external noise, and so on. The framework may also be used to evaluate alternative network configurations to improve network performance. Although the following discussion describes the framework in an exemplary wireless network, the framework may also be employed in wired networks.","Exemplary Environment","As previously described, network management has received limited attention by both industry and research communities. Implementation of network management may involve continual monitoring of the functioning of the network, collection of information about the nodes and links in the network, removal of inconsistencies and noise from the reported data, analysis of the data, and performance of appropriate actions to improve network reliability and performance.","Troubleshooting a network is an aspect of network management that is responsible for maintaining the \u201chealth\u201d of the network and for ensuring its smooth and continued operation. Troubleshooting a network, whether wired or wireless, may be complicated by a variety of interactions, such as interactions encountered between different network entities, interactions between faults, and so on. Troubleshooting a multi-hop wireless network is further complicated by a variety of additional factors. For instance, typical multi-hop wireless networks are generally prone to link errors caused by signal propagation fluctuations, which result in a network topology that is dynamic and unpredictable. Additionally, the capacity of multi-hop wireless networks is generally limited due to scarcity of resources (e.g., bandwidth, battery power, and so on), which also constrains the amount of management traffic overhead that the network can tolerate.","A framework is described which addresses these complications. The framework may utilize an online trace-driven simulation to detect faults and perform root cause analysis. The simulation may be utilized to reproduce events that took place in the network which resulted in a fault, and therefore identify and rectify these faults.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 1","FIG. 1"],"b":["100","102","1","102","2","102","3","102","102","102","1","102","100"],"i":"n"},"The framework may utilize one or more of a variety of existing network simulators to simulate the network , such as QUALNET (QUALNET is a trademark of Scalable Network Technologies, Inc. of Los Angeles, Calif.), OPNET MODELER (OPNET MODELER is a trademark of OPNET Technologies, Inc. of Washington D.C.), and so on. The traces that are provided to the simulators are obtained from the network being diagnosed, i.e., a \u201creal\u201d network. Use of traces from the real network removes the dependency of the framework on generic theoretical models that may not capture the nuances of the hardware, software, and environment of the particular network in question, thereby improving the accuracy of the framework.","The framework may also employ a fault diagnosis scheme to perform root cause analysis. For instance, the scheme may utilize estimated network performance data emitted by the online trace-driven simulator as the baseline for expected performance of the real network. Deviation from the expected performance is then utilized to indicate a potential fault. Further, the scheme may selectively inject a set of candidate faults into a simulator to perform root-cause analysis by reducing fault diagnosis to a problem of searching a set of faults. A root cause may therefore be identified based on the faults that, when injected, cause the simulation to approximate the observed performance of the real network. Therefore, the framework may employ a search algorithm to detect and diagnose faults such as packet dropping, link congestion, external noise sources, MAC misbehavior, and so on. These faults may have relatively long lasting impact on performance, and are more difficult to detect than fail-stop errors, such as when a node turns itself off due to power or battery outage.","In this way, the framework may utilize a simulation as an analytical tool for troubleshooting and testing of alternative and potentially performance-enhancing configurations in a network. In the following sections, network traces are identified which, when provided to a simulator, provide a network simulation that gives an accurate depiction of actual network behavior. A technique is also described that reduces or eliminates erroneous data from the trace, further discussion of which may be found in relation to . Consequently, the simulator is supplied with high-quality data. Additionally, a search algorithm is described which is effective for diagnosing multiple faults in the network, further discussion of which may be found in relation to . The simulator can also be used to carry out what-if analysis and quantify the performance benefit of possible actions on the current network, further discussion of which may be found in relation to .","The troubleshooting framework may be employed in a wide variety of network configurations. One such example is illustrated by the network  of , which is depicted as a wireless mesh network. A mesh network can employ a variety of arrangements, such as full mesh topology or a partial mesh topology. In a full mesh topology, each node is directly connected to each other node in the network. In a partial mesh topology, each node is connected to at least one other node, but not necessarily to each other node in the network.","A mesh network, for instance, may be utilized as an enabling technology for neighbors to collaboratively form a self-managed community wireless mesh network. Each neighbor may provide one or more of the plurality of nodes ()-(N) of the network . With such a network, neighbors can, for example, share an Internet gateway  in a cost-effective way.","In an example of a mesh network as utilized in a neighborhood, routers which are utilized to communicatively couple the plurality of nodes ()-(N) reside inside a home and are plugged in electrical outlets. Therefore, each of the routers in this example has limited mobility. The relative stability of such a network, however, makes network troubleshooting even more important because faults might have lasting influence on network performance. It should be noted that the lack of router mobility in this example does not take away the dynamism in the network topology because wireless links can be accessible or inaccessible due to environmental changes. In another example, nodes of the mesh network may be mobile, such as through use of mobile computing devices having wireless communication capabilities, such as personal digital assistants (PDA), tablet personal computers (PCs), laptop computers, and so on.","Additionally, growth of a community mesh network is organic as users buy and install equipment to join the mesh network. Traditional mesh networks had a lack of a centralized entity responsible for network administration. However, the self-manageability and self-healing capabilities provided through the framework described herein may be provided such that each node ()-(N) implements troubleshooting capabilities. In the illustrated implementation, a single node is provided having management capabilities.","In the network  illustrated in , each of the nodes has a processor, memory, and a network connection device, an example of which is shown by node () as including a processor (), memory (), and a network connection device (). Processors (e.g., processors (), (N)) are not limited by the materials from which they are formed or the processing mechanisms employed therein. For example, processors may be comprised of semiconductor(s) and\/or transistors (e.g., electronic integrated circuits (ICs)). In such a context, processor-executable instructions may be electronically-executable instructions. Alternatively, the mechanisms of or for processors, and thus of or for a node, may include, but are not limited to, quantum computing, optical computing, mechanical computing (e.g., using nanotechnology), and so forth.","Memory (e.g., memory (), (N)) includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM), random access memory (RAM), and so on. Memory may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. Memory provides storage of computer-readable instructions, data structures, software components, and other data for nodes.","The network connection devices (e.g., network connection devices (), (N)) may assume a variety of configurations for communicatively coupling the nodes to the network . When used in a local area network (LAN) environment, for instance, the node () is communicatively connected to the LAN through a network interface or adapter, which may be wired and\/or wireless. When used in a wide area network (WAN) environment, the network connection device may be configured as a modem or other means for establishing communications, such as a wired connection over a digital subscriber line (DSL), a wireless connection provided with a satellite, and so on. Logical connections are depicted in  through the use of arrows. Although the network  shown in  is a wireless mesh network, a variety of other networks may be employed, such as the Internet, intranets, and so on.","Nodes (), (N) illustrate an exemplary management architecture composed of software modules. Generally, any of the functions described herein can be implemented using software, firmware (e.g., fixed logic circuitry), manual processing, or a combination of these implementations. The terms \u201cmodule,\u201d \u201cfunctionality,\u201d and \u201clogic\u201d as used herein generally represents software, firmware, or a combination of software and firmware. In the case of a software implementation, the module, functionality, or logic represents program code that performs specified tasks when executed on a processor, such as one or more central processing units (CPUs). The program code can be stored in one or more computer readable memory devices. The features of the framework described below are platform-independent, meaning that the troubleshooting techniques may be implemented on a variety of commercial computing platforms having a variety of processors.","An agent module () is provided for execution on each node () of the network . The agent module () is illustrated as being executed on the processor () and is storable in memory (). The agent module () includes a data collection module () (hereinafter \u201ccollection module\u201d) that, when executed, may gather data from various protocol layers and\/or from the network connection device (). In the illustrated network  of , the agent module () then reports this data to the node (N) having management functionality, which hereinafter will be referenced as a manager node. The manager node (N) performs an analysis of the data (e.g., through implementation of a simulation that accepts the data as an input) and takes appropriate actions for troubleshooting the network. Management of the network can be centralized by placing the manager on a single node as illustrated in the network  of , or distributed such that a plurality of the nodes of a network each include management functionality.","The agent modules (), (N), when executed on the respective processors (), (N), collect and communicate data describing their (local) view of the network's behavior to the manager node (N). Examples of the data sent may include traffic statistics, received packet signal strength on various links, retransmission counts on each link, and so on.","The manager node (N) includes a manager module (N) that is storable in the memory (N) and executable on the processor (N) to process the data from the agents (), (N) for troubleshooting the network . The manager module (N), for instance, includes a network simulator (N) (hereinafter, \u201csimulator\u201d) that is executable on the processor (N) and storable in the memory (N) to simulate the network .","Data received by the manager node (N) from the various agents (), (N) may result in an inconsistent view of the network . Such inconsistencies can be the result of topological and environmental changes, measurement errors, misbehaving nodes, and so on. Therefore, the manager node (N) includes a data cleaning module (N) (hereinafter \u201ccleaning module\u201d) that is executable on the processor (N) to resolve such inconsistencies. Cleansed data output from cleaning module (N) is then provided for processing by a root cause analysis module (N) (hereinafter \u201canalysis module\u201d), further discussion of which may be found in relation to the following figure. Although the manager node (N) is illustrated as including the agent module (N) and the manager module (N), in another implementation the manager node (N) is a dedicated manager node in that it does not include the agent module (N). Also, as previously described, the functionality of the manager module (N) may be provided by more than one node in the network .",{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 2","FIG. 1","FIG. 1"],"b":["200","122","120","122"]},"The analysis module (N) utilizes an online trace-driven simulation to determine root causes of discrepancies from expected network performance as indicated by the simulated network perform. In the following discussion, expected network performance and simulated network performance are utilized interchangeably to indicate network performance as provided by a network simulation. The analysis module (N) may utilize cleansed data  obtained from a trace utility, examples of such data are illustrated in  as link received signal strength (RSS) , link location , and routing update , to drive online simulations and establish the expected performance under the given network configuration and traffic patterns.","The analysis module (N) is illustrated as including a network simulation  that is provided through execution of the simulator (N). The network simulation  may be provided by execution of one or more software modules that provide simulations of characteristics of a network, examples of which are illustrated in  by an interference injection module , a traffic simulator module , and a topology change module . The interference injection module  is executable to simulate external noise sources by injecting the effect of external noise on the network simulation . The traffic simulator module  is executable to ensure that traffic of the network simulation  approximates that of the real network. The topology change module  is executable to simulate changes to the topology, such as by adding and\/or removing nodes in the network simulation .","The analysis module (N) detects faults in the network  of  by comparing the expected performance as indicated by the network simulation  with the observed performance. When discrepancies are observed, the analysis module (N) determines the root cause for the discrepancies by searching for one or more faults stored in a faults directory  that result in the best match between the simulated and observed network performance.","The analysis module (N), for example, may receive observed data  from one or more of the agent modules () of  which describes a loss rate, throughput, and noise , which is illustrated in  as \u201closs rate, throughput, and noise \u201d. The network simulation  computes expected data  that describes an expected loss rate, an expected throughput, and expected noise, which is illustrated in  as \u201cexpected loss rate, throughput, and noise \u201d. The observed data  is communicated through a delay  to a comparator  such that the comparator  receives the observed and expected data ,  simultaneously. The comparator  then determines whether the observed data  exceeds the expected data . If so, the comparator  outputs an error message  for communication to the network administrator and communicates the error to the faults directory  to determine a root cause of the error.","After the root cause of the error has been identified through selection of one or more of the faults from the faults directory , the analysis module (N) may simulate one or more alternative actions for rectifying the fault. The alternative actions may be simulated under the current traffic pattern and network topology as provided by the traffic simulator  and topology change module , respectively. Based on the simulations, the analysis module (N) may suggest one or more appropriate actions to alleviate the faults and enhance overall performance of the network, an example of which is illustrated as link node fault  of . For example, the network administrator can be notified if the software or hardware are suspected as faulty, the topology can be changed via transmission-power adjustment if poor connectivity is detected, the routers can employ rate limitations to alleviate congestion, and so on.","Use of the network simulation  for online diagnosis offers a variety of benefits over traditional heuristic or theoretical diagnostic techniques. For instance, the network simulation  can provide increased insight into the behavior of the network over traditional heuristic or theoretical techniques. An operational wireless network, for example, is a complex system having intricate pieces, such as traffic flows, networking protocols, signal processing algorithms, hardware, radio frequency (RF) propagation and so on. Additionally, interactions may occur between all of the pieces of the network. Interactions between faults may be effectively diagnosed and addressed through selection of one or more faults from the faults directory  that result in a network simulation  that corresponds to the actual behavior of the \u201creal\u201d network.","Further, network behavior may be governed by node interactions, one to another, as well as by external noise sources positioned in the vicinity of the nodes. Traditional heuristic or theoretical techniques do not capture the behavior of such networks and do not adequately address interactions between the different components of the network.","As an example, consider a seven-by-three grid topology network  shown in . Five flows are illustrated in the network  and are denoted as F, F, F, F, and F. In the illustrated example, each of the flows - has a similar amount of traffic to communicate. For example, each of the flows - may receive substantially similar amounts of data from respective applications.","Additionally, in this example, adjacent nodes can \u201chear\u201d one another and the interference range is twice the communication range. Traffic between node A  and node O , for instance, interferes with the traffic between nodes C and Q , . Similarly, traffic between nodes G and U ,  interferes with the traffic between nodes E and S , . However, traffic between G and U ,  and traffic between nodes A and O ,  do not interfere with traffic between nodes D and R , .","The following table describes an example of throughput of the flows - when each flow sends constant bit rate (CBR) traffic at a rate of eleven Mbps.",{"@attributes":{"id":"p-0057","num":"0056"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"49pt","align":"center"}}],"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}},{"entry":["F","F","F","F","F"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["2.50 Mbps","0.23 Mbps","2.09 Mbps","0.17 Mbps","2.53 Mbps"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}}},"br":{},"sub":["3 ","2 ","4 ","3 "],"b":["306","304","308","306","300"]},"Traditionally, application of heuristic techniques may have lead to a conclusion that flow F receives an unduly larger share of the bandwidth. Through use of an online trace-driven simulation, however, the manager node (N) may conclude that this is normal behavior. For example, the network simulation may take link quality into account and therefore determine that flows F and F interfere with flows F and F. Therefore, flow F is provided with additional bandwidth because of the lack of interference from flows F and F, as opposed to flows F and F. In this way, the simulation can determine that even though all the flows may have the same application-level sending rate, the observed throughput is expected. A simple heuristic, however, may come to an erroneous conclusion that nodes D and R ,  are misbehaving.","The network simulation is utilized by the analysis module (N) to manage the network by knowing \u201cwhat to expect\u201d from the network given the current traffic flows and link qualities. In other words, the analysis module (N) can comment on what constitutes normal behavior based on estimations provided by the network simulation. In the previous example, even though F utilizes a greater share of the bandwidth of the network  than other flows in the network , this will not be flagged as a fault by the manager module because this behavior is expected. When the observed behavior deviates from the expected behavior, the manager module can invoke the fault search algorithms that utilize the faults directory  of  to determine the root cause of the deviation.","In addition, while it might be possible to apply traditional signature-based or rule-based fault diagnosis approach to a particular type of network and under a specific environment and configuration, simple signatures or rules are insufficient to capture the intrinsic complexity for fault diagnosis in general settings. In contrast, a simulator is highly customizable and may be applied, with appropriate parameter settings, to a large class of networks that are configured for use in different environments. Fault diagnosis built on top of such a simulator inherits this generality.","Yet another advantage of simulation-based approach is the ability to perform what-if analysis. That is, by modifying the settings or performing certain actions in the simulator, a simulator can predict performance for an imaginary scenario. Based on this data, a manager module can instruct the agent modules (e.g., agent module () of ) to take an appropriate action to optimize the performance of the network. As previously described, such what-if analysis is valuable because it may be difficult to foresee the consequences of a corrective action due to the interaction of multiple factors in a network. For example, transmitter power may be increased to improve link quality, but the increase may also create additional interference that affects other nodes in the network.","Fault Detection and Diagnosis","A simulation-based diagnostic approach is described which provides for creation of an environment inside a simulator (e.g., network simulation ) that approximates the functionality of a real network. The created environment (i.e., the network simulation) may then be utilized to determine expected behaviors of the real network as well as determine when discrepancies in the operation of the real network occur. To find a root cause of these discrepancies, the manager module is executed to search over a fault space to determine which fault or set of faults can reproduce network performance which approximates the network performance that is observed in the real network. The simulated network may reproduce a variety of network aspects, such as network topology, routing behavior, traffic patterns observed in the real network, and so on.","Using online trace-driven simulation as a building block, a diagnostic algorithm is described which is executable to find root-causes for faults. The diagnostic algorithm, for instance, may first estimate performance of the network under a given set of faults. Then, based on differences between the estimated and observed performance, the diagnostic algorithm searches a fault space to reproduce any observed discrepancies. In an implementation, the diagnostic algorithm can diagnose multiple faults of the same type (e.g., network topology), as well as diagnose the presence of multiple types of faults (e.g., noise and topology).","Faults may be diagnosed even when the trace data used to drive the simulation contains errors. For example, data provided by the agent module () of  may contain errors due to a variety of reasons, such as measurement errors, false information, software\/hardware errors in the execution of the node (), network communication errors, and so on. The cleaning module (N) is executed by the manager node (N) to reduce or eliminate erroneous data from the trace such that quality trace data is utilized to drive the simulation-based fault diagnosis. Further discussion of cleaning module (N) execution may be found in relation to .","Trace-Driven Simulation",{"@attributes":{"id":"p-0065","num":"0064"},"figref":["FIG. 4","FIG. 2"],"b":["400","118","210","118"]},"Network Topology ","Network topology  data describes the topology of the network, such as which nodes are currently members of the network and corresponding links between the nodes. Each node in the network, for instance, may be configured to report on the status (e.g., connected or disconnected) of neighboring nodes and nodes referenced in one or more routing tables of the node. In this way, node membership in the network may be communicated to the manager node (N) of . In an implementation, only changes in neighbors or routes are reported. This data may be used to drive a route simulation, which is described in greater detail in relation to a route simulator of .","Traffic Statistics ","Traffic statistics  data may be utilized to describe amounts of data that is communicated through the network and particular nodes that communicate that data. The traffic statistics  may be utilized as an input by the traffic simulator module  of  such that the network simulation  has a traffic flow which approximates that o the real network. Each node of the network may maintain one or more counters which describe the volume of traffic sent to and received from its immediate neighbors. This data is used to drive a route traffic simulation provided by the traffic simulation module , which is also described in greater detail in relation to .","Physical Medium ","Physical medium  data may describe effects on network performance of the physical medium that is utilized to implement the network. For example, in a wireless network each node may report its noise level and the signal strength of the wireless links from its neighboring nodes. In an implementation, variations in signal strength are periodically captured through time averaging, standard deviation, or other statistical aggregate.","Network Operation ","Network operation  data describes network operation  of the real network. As previously described, observed network operation is compared with the estimated network operation output from the network simulation to detect network operation discrepancies. Network operation may include both link operation and end-to-end operation, both of which can be measured through a variety of metrics, such as packet loss rate, delay, and throughput. The following description focuses on link level operation.","Data collection may involve two steps: (1) collecting raw performance data at a local node and (2) distributing the collected data to collection points for analysis. A variety of tools may be utilized for local data collection, such as native routing protocols and packet sniffers.","In an implementation, even though distribution of data to the manager module introduces network overhead, the network overhead is low and has little impact on the data traffic in the network. Additionally, network overhead may be reduced by using compression, delta encoding, multicast, adaptive changes of a time scale and\/or spatial scope of distribution, and so on. For example, a minimum set of data is collected and exchanged during normal operation of a network. Once a need arises for additional data (e.g., when the information being collected indicates a discrepancy), the manager module may request additional information and increase the frequency of data collection for the subset of the nodes that need increased monitoring.","Simulation Methodology","Network characteristics that are modeled by the simulator may be classified in a variety of categories, such as traffic load, routing, wireless signal, faults, and so on. The following sections describe simulation examples of each of these exemplary categories as individual modules that are utilized to cause the simulator to simulate the corresponding network characteristics.","Traffic Load Simulator ","A network simulation generated by a simulator may be configured such that it provides a traffic pattern that approximates the traffic pattern of the real network. An example of a traffic load simulation approach involves the simulation of end-to-end application demands. However, an N-node network can include potentially Ndemands. Moreover, end-to-end application demands may be difficult to obtain given the heterogeneity of application demands and the use of different transport protocols, such as a transmission control protocol (TCP), a user datagram protocol (UDP), a rapid transport protocol (RTP), and so on.","In an implementation, a traffic load simulator  module is a portion of the traffic simulator module  of  and provides a link-based traffic simulation that is utilized for scalability and to avoid the need for obtaining end-to-end application demands. The link-based traffic simulation, when implemented, may adjust an application-level sending rate at each link to match the observed link-level traffic counts of the real network. In this way, higher layers (e.g., a transport layer, an application layer, and so on) are abstracted away, which allows the simulation to concentrate on packet size and traffic rate.","Matching the sending rate on a per-link basis in a simulator may be nontrivial when the sending rate on a link cannot be directly controlled, such as when only the application-level sending rate may be adjusted and the medium access control (MAC) protocol must be addressed. For example, when an application sending rate of a link is set at one Mbps, the actual sending rate (on the air) can be lower due to back-off at the MAC layer, or higher due to MAC level retransmission. The issue is further complicated by interference, which introduces interdependency between sending rates on different links.","An iterative search technique may be utilized to address these issues by determining the sending rate at each link. A variety of iterative search techniques may be utilized, such as (i) multiplicative increase and multiplicative decrease, and (ii) additive increase and additive decrease. As shown in the following procedure depicted using exemplary pseudo-code, each link individually tries to reduce the difference between the current sending rate in the simulator and the actual sending rate in the real network.",{"@attributes":{"id":"p-0082","num":"0081"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"while (not converged and i < maxIterations)"]},{"entry":[{},"\u2003\u2003i = i + 1"]},{"entry":[{},"\u2003\u2003If (option = = multiplicative)"]},{"entry":[{},"\u2003\u2003\u2003\u2003for each link (j)"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003prevRatio = targetMacSent(j)\/simMacSent(J);"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003currRatio = (1 \u2212 \u03b1) + \u03b1 * prevRatio;"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003simAppSent(J) = prevAppSent(j) * currRatio;"]},{"entry":[{},"\u2003\u2003else \/\/ additive"]},{"entry":[{},"\u2003\u2003\u2003\u2003for each link (j)"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003diff = targetMacSent(j) \u2212 prevMacSent(j);"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003simAppSent(j) = prevAppSent(j) + \u03b1 * diff;"]},{"entry":[{},"\u2003\u2003run simulation using simAppSent as input"]},{"entry":[{},"\u2003\u2003determine simMacSent for all links from simulation results"]},{"entry":[{},"\u2003\u2003conveyed = isConverge (simMacSent, targetMacSent)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},"Route Simulator ","Routing plays an important role in network performance, particularly in multi-hop wireless networks. One route simulation approach involves the simulation of a routing protocol used in the real network inside the simulator. In order to reproduce the same routing behavior as in a real network, detailed traces of packets are obtained to set up the routing.","The actual routes taken by packets may be utilized as an input to the route simulator  module. When routes do not frequently fluctuate, routing changes may be tracked instead of collecting routes on a packet-by-packet basis at the manager. For this purpose, the route simulator  module may be trace-driven. For example, the route simulation module may be implemented inside the simulator (N), such as a QUALNET simulator (QUALNET is a trademark of Scalable Network Technologies, Inc. of Los Angeles, Calif.). The route simulation  module accepts routing updates and corresponding timestamps as inputs, and then ensures that the packets in the network simulation follow the same route as in the real network.","Signal Strength Simulator ","Signal strength has an impact on both wired and wireless network performance. Due to variations across different network connection devices (e.g., wireless cards) and environments, a general propagation model may be difficult to derive which captures all of these factors. To address this issue, the signal strength simulator  may be driven from real measurement of signal strength in the real network, such as obtained from the network connection devices themselves.","Fault Injection ","The framework may include a fault injection  module that is executable to inject different types of faults into the simulator, such as packet dropping at hosts, external noise sources, MAC misbehavior, and so on. In this way, the analysis module may examine the impact of faults on the network. Packet dropping at hosts, for instance, occurs when a misbehaving node drops a portion of the traffic from one or more neighboring nodes, such as due to hardware\/software errors, buffer overflow, malicious drops, and so forth. The ability to detect such end-host packet dropping is useful, since it allows the manager to differentiate losses caused by end hosts from losses caused by the network.","The framework, through execution of the fault injection  module, also supports the ability to inject external noise sources in the network. Thus, the framework may provide a simulation that replicates the effect of noise sources that lie outside the network (i.e., are not provided by a node) but nevertheless affect the network.","MAC misbehavior occurs when a faulty node does not follow the MAC etiquette and obtains an unfair share of the channel bandwidth. For example, in IEEE 802.11, a faulty node can choose a smaller contention window (CW) to aggressively send traffic.","Link congestion may also be simulated by the framework by supplying a high data transmit load on the simulated network. Unlike the other types of faults, link congestion is implicitly captured by the traffic statistics gathered from each node. Therefore, the trace-driven simulation can directly assess the impact of link congestion on the real network. Further discussion of fault diagnosis may be found in the following section.","Fault Diagnosis","Root causes for failures and performance problems may be diagnosed through execution of the analysis module (N) of . By applying faults to a network simulation, diagnosis of network discrepancies may be reduced to searching for a set of faults that, when injected into the simulated network, result in an estimated performance by the simulated network that approximates the observed performance of the real network. More formally, given network settings NS, FaultSet is found such that:\n\nSimPerf(NS; FaultSet)\u2248RealPerf\n\nwhere the network performance is a functional value that can be quantified using a variety of different metrics.\n","The search space for a fault may contain a multitude of searching dimensions due to the different combinations of faults which may be encountered. In an implementation, the analysis module (N) is optimized for efficient searching due to a realization that different types of faults often change a few particular network performance metrics. For example, packet dropping at hosts generally affects link loss rate, but does not affect other network performance metrics. Therefore, network performance metrics may be used to diagnosis network performance by noting differences between observed and estimated network performance indicated by the metrics.","In an implementation, it is not necessary to provide a predictive model for the purpose of fault diagnosis. Rather, it is sufficient to simulate what happened in the network after the fact. For instance, agent modules may periodically report information about link conditions and traffic patterns to the manager module. This information is processed and then fed into the simulator to create a network simulation that may then be utilized to determine a likely root cause of the fault.","Initial Diagnosis",{"@attributes":{"id":"p-0097","num":"0096"},"figref":"FIG. 5","b":"500"},"As previously described, a trace-driven simulation, when fed with current network settings of a real network, may be utilized to establish estimated network performance of the network. Based on the difference between the estimated network performance and observed network performance, the type of faults may be determined using a decision tree, an example of which is depicted in .","Due to a variety of factors, estimated network performance is unlikely to be identical with the observed network performance, even in the absence of faults. Therefore, discrepancies in network performance may be determined using a threshold. For example, a discrepancy may be determined based on whether a difference between estimated and observed (i.e., real) network performance values exceeds a corresponding threshold. The threshold may be computed in a variety of ways, such as by observing the historical difference between simulated and actual network performance.","A fault classification scheme, an example of which is depicted in , is configured to determine the type of fault which caused the discrepancy by noting that different faults exhibit different respective behaviors. While the behaviors exhibited by each of the faults may still overlap (e.g., both noise sources and packet dropping at hosts increase loss rates, lowering a contention window increases the amount of traffic and hence increases interference noise, and so on), the faults may first be categorized by checking the differentiating respective behavior. For example, an external noise source increases noise levels experienced by neighboring nodes, but does not increase the sending rates of any node. Therefore, the external noise source can be differentiated from MAC misbehavior and packet dropping at hosts.","Reference will now be made again to . The following discussion includes parentheticals having italicized text which describe alternate notations as utilized in exemplary pseudo-code that is included in the discussion of the related figures. At block , the analysis module selects one or more faults from a plurality of faults, such as from the faults directory  of . At a first iteration of the procedure , none of the plurality of faults is selected to derive an expected performance of the network under normal operating conditions, i.e., without faults. In another implementation, the procedure  of  is utilized to perform an initial diagnosis and is not iterative, i.e. it is a \u201cone pass\u201d procedure. In such an implementation, block  may be removed from the procedure  and the fault set provided as an empty set {}.","At block , the fault set (FS) and network settings (NS) are provided to a network simulation as an input. A variety of network settings may be supplied, such as signal strength, traffic statistics, routing tables, and so on.","At block , the expected performance (SimPerf) is predicted by executing the network simulation with the provided inputs. At decision block , a determination is made as to whether the difference (Diff) between the expected performance (SimPerf) and the real performance (RealPerf) is greater than a threshold. If the difference is greater than the threshold (block ), the fault type (FT) is determined (block ). Further discussion of determination of a fault type may be found in relation to .","After the fault type is determined, the faults are located (block ) by finding a set of nodes and links that have differences between the observed and expected network performance that exceeds a threshold for that particular fault type (block ). The fault type determines what network performance metric is used to quantify the performance difference. For instance, packet dropping may be identified by finding links having a significant difference between expected and observed loss rates.","At block , the magnitude of the fault is determined. A function (denoted as \u201cg( )\u201d), for instance, may be utilized to map the impact of a fault into a corresponding magnitude. For example, in an end-host packet dropping scenario, the go function is an identity function, since the difference in a link's loss rate can be directly mapped to a change in a packet dropping rate on a link (fault's magnitude). In an external noise fault scenario, the g( ) function is a propagation function of a noise signal. Blocks - may be repeated for each link or node. The fault with a corresponding magnitude may then be added to the fault set at .","The following depicts exemplary pseudo-code which may be executed to implement a procedure similar to the procedure  of , which is shown as follows:",{"@attributes":{"id":"p-0107","num":"0106"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"Let NS denote the network settings (i.e., signal strength, traffic statistics,"},{"entry":"\u2003\u2003routing table)"},{"entry":"Let RealPerf denote the real network performance"},{"entry":"FaultSet = { }"},{"entry":"Predict SimPerf by running simulation with input (NS; FaultSet)"},{"entry":"if |Diff (SimPerf, RealPerf )| > threshold"},{"entry":"\u2003\u2003determine the fault type ft using a decision tree for each link or node i"},{"entry":"\u2003\u2003if (|Diff(SimPerf (i), RealPerf(i))| > threshold)"},{"entry":"\u2003\u2003\u2003\u2003add fault(ft, i) with"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003magnitude(i) = g(Diff(SimPerf (i), RealPerf (i))"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0108","num":"0107"},"figref":["FIG. 6","FIG. 6","FIG. 5"],"b":["600","600","510","602","604"]},"If the threshold of block  is not exceeded, then at decision block , a determination is made as to whether there is a discrepancy (i.e., a threshold noise differential ThreshNoiseDiff has been exceed) between the real noise (RealNoise) indicated on the real network and the expected noise (SimNoise) of the simulated network. If so, a noise fault is determined (block ).","If the noise threshold has not been exceeded (block ), then at decision block , a determination is made as to whether simulated packet loss (SimLoss), i.e., the expected packet loss, differs from the real pack loss (RealLoss) by more than a threshold loss difference (ThreshLossDiff). If so, a packet dropping fault has been encountered (block ). Otherwise, the node is operating normally (block ). It should be apparent that a wide variety of other fault types may also be determined in a similar manner.",{"@attributes":{"id":"p-0111","num":"0110"},"figref":["FIG. 7","FIG. 7","FIG. 5"],"b":["700","500"]},"During the initial diagnostic stage, a one-pass diagnosis algorithm is applied to derive an initial set of faults. During the second stage, the fault set is iteratively refined by (i) adjusting the magnitude of the faults that have been already inserted into the fault set, and (ii) adding a new fault to the set if necessary. The procedure  may be reiterated until the change in fault set is negligible, such as when the fault types and locations do not change, the magnitudes of the faults change by minimal amounts, and so on.","An iterative approach may also be used to search for the magnitudes of the faults. At a high level, this approach is similar to the link-based simulation, described in relation to , where the difference between the target and current values were utilized as a feedback to progressively move towards the target.","At block , for example, the expected network performance is estimated under the existing fault set for each iteration. For example, the expected network performance may be estimated through simulation of the network using network settings obtained from the real network. The network settings are provided through execution of agent modules on each node. The network settings provided by each node may describe local network performance of the node as well as network performance of neighboring nodes.","At block , the difference between estimated network performance (under the existing fault set) and real performance is computed. The difference, for instance, may be computed by a manager node through execution of a manager module. The manager module, when executed, compares the estimated (i.e., expected) network performance obtained from a simulated network with real (i.e., observed) network performance as indicated by additional network settings obtained from the plurality of agents.","The procedure  of  first makes an initial fault diagnosis in a manner similar to the procedure  described in relation to . At decision block , for instance, a determination is made as to whether the computed difference is greater than a corresponding threshold. If not, the fault set is reported (block ). In this instance, because the computed difference is not greater than the threshold, this indicates to the analysis module that the network is operating normally. If the computed difference is greater than the corresponding threshold (block ), however, the fault type is determined (block ). The fault type may be determined in a variety of ways, an example of which was described in relation to .","At block , the difference is translated into a change in the fault's magnitudes and the fault magnitudes are adjusted according to the computed change (block ). For example, the function g( ) as previously described in relation to  may be utilized to compute a fault magnitude for each of the faults based on the respective differences between expected and real network performance. In this way, the faults may be compared, one to another, to determine which fault has an effect on network performance that corresponds to the observed discrepancy. In an implementation, the largest fault magnitude is first utilized to explain the discrepancy, and thereby identify a particular fault which caused the discrepancy. In another implementation, the fault magnitudes are compared to locate a fault which results in a difference which approximates the computed difference. For example, each of a plurality of faults may have respective differences between expected and real network performance. One or more of the faults may be selected by matching the respective differences with the computed difference in network performance. At block , faults are removed which have magnitudes which are below a corresponding threshold, thereby optimizing the fault set.","At decision block , a determination is made as to whether the expected performance of the network using the current fault set is converging with real network performance. For example, the analysis module may store heuristic data which describes one or more previous iterations of fault sets and resultant performance values in the network simulation. The difference between the target values (i.e., real network performance values) and current values (i.e., simulated network performance values) is used as feedback by the analysis module to progressively \u201cmove\u201d the network simulation to approximate the real network.","If the expected performance is not converging with real network performance (block ), a new fault candidate is added to the fault set. In addition to searching for the correct magnitudes of the faults, for example, membership in the fault set may be iteratively refined by selecting new fault candidates that can best explain the difference between expected and real network performance (block ). These new faults are added to the fault set (block ). The fault set including the new fault candidate is then utilized as an input to a network simulation to estimate expected network performance under existing fault set (block ). In an implementation, a fault is added during each iteration of the procedure  which can explain the largest discrepancy, thereby controlling false positives. The procedure  may then be repeated until the expected performance of the simulated network approximates the real performance of the real network. In this way, the simulated network may be moved through inclusion of faults such that it provides an accurate depiction of faults which cause the observed network performance in the real network.","The following illustrates exemplary pseudo code which may be executed to provide the procedure  of .",{"@attributes":{"id":"p-0121","num":"0120"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"1) Let NS denote the network settings"},{"entry":"\u2003\u2003\u2003(i.e., signal strength, traffic statistics, and routing tables)"},{"entry":"\u2002\u2009 Let RealPerf denote the real network performance"},{"entry":"2) FaultSet = { }"},{"entry":"3) Predict SimPerf by running simulation with input (NS; FaultSet)"},{"entry":"4) if |Diff (SimPerf, RealPerf)| > threshold"},{"entry":"\u2003\u2003\u2003go to (5)"},{"entry":"\u2003\u2003else"},{"entry":"\u2003\u2003\u2003go to (7)"},{"entry":"5) Initial diagnosis: initialize FaultSet by applying the algorithm of FIG. 5"},{"entry":"6) while (not converged)"},{"entry":"\u2003\u2003\u2003a) adjusting fault magnitude"},{"entry":"\u2003\u2003\u2003\u2002\u2009 for each fault type ft in FaultSet (in the order of decision tree"},{"entry":"\u2003\u2003\u2003\u2002\u2009 in FIG. 6)"},{"entry":"\u2003\u2003\u2003\u2003\u2003for each fault i in (FaultSet, ft)"},{"entry":"\u2003\u2003\u2003\u2003\u2003magnitude(i) \u2212 = g(Diff(SimPerf(i), RealPerf (i)))"},{"entry":"\u2003\u2003\u2003\u2003\u2003if (|magnitude(i)| < threshold)"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003delete the fault (ft, i)"},{"entry":"\u2003\u2003\u2003b) adding new candidate faults if necessary"},{"entry":"\u2003\u2003\u2003\u2002\u2009 foreach fault type ft (in the order of decision tree of FIG. 6)"},{"entry":"\u2003\u2003\u2003\u2003\u2003i) find a fault i s.t. it is not in FaultSet and has the"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2002\u2009 largest |Diff(SimPerf (i);RealPerf (i))|"},{"entry":"\u2003\u2003\u2003\u2003\u2003ii) if |Diff(SimPerf(i), RealPerf(i))| > threshold)"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003\u2009\u2009add (ft, i) to FaultSet with magnitude(i) ="},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003\u2009\u2009g(Diff(SimPerf(i), RealPerf (i))"},{"entry":"\u2003\u2003\u2003c) simulate"},{"entry":"7) Report FaultSet"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}},"br":[{},{}]},"In the previous sections, fault diagnosis was described in which trace data was utilized to drive an online simulation. In practice, raw trace data that is collected by agent modules, when executed on respective nodes, may contain errors for various reasons as mentioned earlier, such as due to hardware, software, and\/or network errors. Therefore, the cleaning module (N) of  may be executed to clean the \u201craw\u201d trace data received from the plurality of agents to provide cleansed trace data as an input to the simulator (N) for fault diagnosis.",{"@attributes":{"id":"p-0123","num":"0122"},"figref":["FIG. 8","FIG. 1"],"b":["800","102","1","102","102","1","102"]},"Due to neighbor monitoring, multiple reports from different sources (i.e., nodes) are likely to be submitted for each link. Node (), for example, may obtain a report () from node () that describes network performance of node (), as well as the network performance of nodes (), (). Parentheticals utilized in the reference numbers of the reports in  are selected to show correspondence of the report with its respective node, e.g., node () and report ().","Node () includes network performance data from the report () (which is illustrated in phantom in ) in report () that is formed for communication to the manager node (N). The report () may also include network performance data obtained by node () by monitoring nodes (), (). In an implementation, the report () is optimized through execution of an agent module to remove redundant information. For instance, the agent module of node () may remove information that is consistent and repeated by nodes (), () in the respective reports (), (), but leave data describing any inconsistencies in the data. Likewise, node () may execute the collection module () to obtain network performance data from nodes (), (). The network performance data is configured as a report () for communication to the manager node (N).","The redundant reports can be used by the manager node (N) to detect one or more inconsistencies in network performance. For example, reports (), () may be compared to each other through execution of the cleaning module (N) by the manager node (N) to find inconsistencies in the network performance data described therein. The inconsistencies may be found in a variety of ways, an example of which is described in the following figure.",{"@attributes":{"id":"p-0127","num":"0126"},"figref":"FIG. 9","b":["900","900"]},"In the procedure  described in relation to , a sending node i reports a number of packets sent and a number of MAC-level acknowledgements received for a directed link  as (sent(), ack()). A receiving node j reports the number of packets received on the link as recv(). In addition, a sending or receiving node's immediate neighbor k also reports the number of packets and MAC-level acknowledgements that are sent or received on the link as (sent(), recv(), ack()). An inconsistency in the reports is defined as one of the following cases.","At decision block , a determination is made as to whether a number of packets received on a link, as reported by its destination, is significantly greater (as described by a threshold) than the number of packets sent on the same link, as reported by its source. That is, for the link  from node i to node j, and given a threshold t, the following determination is made:\n\nrecv(1)\u2212sent(1)>\n\nThe threshold t is utilized, since the communication of the reports by the respective nodes is not typically synchronized. If the number of packets received is significantly greater than the number of packets sent, then an inconsistency in the reports is noted, which will be described in greater detail in relation to block . If the numbers of packets received and sent by the respective nodes correspond, then the procedure  progresses to block .\n","At decision block , a determination is made as to whether a number of MAC-level acknowledgments transmitted on a link, as reported by its source, corresponds to a number of packets received on that link, as reported by its destination. In other words, for the link l from node i to node j, and given a threshold t, the following is determined:\n\n|ack(1)\u2212recv(1)|>\n\nThus, if the number of acknowledgments do not correspond (i.e., approximates) the number of packets received (block ), then an inconsistency in the reports is noted. If the numbers of acknowledgments and packets received do correspond (block ), then the procedure  progresses to block .\n","At decision block , a determination is made as to whether a number of packets received on a link, as reported by a neighbor of its destination, is significantly greater than the number of packets sent on the same link, as reported by its source. That is, for link  from node i to node j, in which node j's neighbor is node k, and given a threshold t, the following is determined:\n\nrecv(1)\u2212sent(1)>\n\nThus, if the number of packets received corresponds (i.e., approximate) the number of packets sent (block ), then an inconsistency in the reports is noted. Otherwise, the procedure  then progresses to block .\n","At decision block , a determination is made as to whether a number of packets sent on a link, as reported by a neighbor of its source, is significantly greater than a number of packets sent on the same link, as reported by its source. In other words, for the link  from node i to node j, i's neighbor k, and given a threshold t, the following is determined:\n\nsent(1)\u2212sent(1)>\n\nAs shown in the above equation, if the number of packets sent approximates the number of packets sent (block ) as indicated, respectively, by the source and neighboring nodes, then an inconsistency in the reports is noted. Otherwise, the reports are consistent (block ).\n","At decision block , a determination is made as to whether an inconsistent pair of nodes is already included in the inconsistency graph. If not, the nodes are added to an inconsistency graph (block ). If the inconsistent pair of nodes are already in the inconsistency graph (block ) or have been added to the inconsistency graph (block ), an edge is added between the nodes in the inconsistency graph (block ).","After each of the inconsistent pairs have been identified, then at block  a smallest set (i.e., least number) of nodes is found in the inconsistency graph that can explain the observed inconsistencies. For instance, an assumption may be made that most nodes in the network send reliable reports. Therefore, the smallest set of nodes that can explain the observed inconsistencies is found. This can be achieved, for instance, by finding the smallest set of vertices that covers the inconsistency graph, where the identified vertices represent the misbehaving nodes.","The smallest set of vertices may be found through utilization of a minimum vertex cover problem, which is known to be NP-hard. A greedy algorithm is applied which iteratively picks and removes the node and the incident edges from a current inconsistency graph until no edges are left.","A history of reports can be used to further improve the accuracy of inconsistency detection. For example, at block  a new report may be added to update the inconsistency graph without deleting previous information. Inconsistent pairs of nodes in the new report may then be processed using blocks - of the procedure . For instance, the same greedy algorithm of block  may be reapplied to identify misbehaving nodes.","What-If Analysis","In the previous sections, faults were selectively injected into a network simulation to identify which faults, if any, may have cause a difference between expected and observed network performance. The network simulation may also be utilized to perform \u201cwhat-if\u201d analysis to improve operation of the network. What-if analysis allows the manager module, when executed, to determine the effect of different possible network and node configurations on network performance. The result of the what-if analysis is a set of actions that allows the manager module to operate the network efficiently, such as by causing the agent module on selected nodes in the network to configure the respective node accordingly.","What-if analysis, for instance, may be carried out through the use of an online trace-driven simulation as previously described. Exemplary traces are identified in the following discussion which may that collected to drive the simulator (e.g., simulator (N) of ). For instance, the simulator may be utilized to provide a network simulation of a real network. The network simulation may be reconfigured to test different node and network configurations and determine which configuration yields the best overall network performance for the existing traffic conditions. The manager module may then determine a set of actions for implementation by particular nodes in the network based on the configuration.","Traditional techniques that were employed for what-if analysis used simplified network models and derived the expected performance analytically. The online trace-driven simulation, however, has advantages over theoretical analysis in that the use of a simulator offers improved insight into the behavior of the network than is possible by a heuristic or theoretical technique by itself. For example, an operational wireless network is a complex system with many intricate pieces including traffic flows, networking protocols, signal processing algorithms, hardware, RF propagation, and most importantly the interaction between each of these pieces. Further, the network behavior may be governed by the interaction between nodes within range of one another and by noise sources in the vicinity. Neither heuristic nor theoretical techniques capture the behavior of such networks and the interactions between the different components.",{"@attributes":{"id":"p-0140","num":"0139"},"figref":"FIG. 10","b":["1000","1000"]},"At block , one or more of a plurality of modifications are selected through execution of the manager module. Modifications may be selected in a variety of ways. For instance, modifications may be considered by the manager module as a fault that causes an increase instead of a decrease in network performance. Modifications in such an instance may be stored in the faults directory  of  and arranged based on type. At block , the analysis module provides network settings of a real network and a modification set that includes the selected modifications to a network simulation as an input.","At block , expected performance of the network is predicted based on the inputs. For instance, the simulator may create a network simulation based on the network settings of the real network and the modification set. The network simulation, as previously described, may then be utilized to determine the consequences of the modifications to the real network.","The analysis module, when executed, derives one or more actions to be performed by agent modules of the network to implement the modification (block ). The analysis module, for instance, may include a directory of actions that are mapped to corresponding modifications. The analysis module may then obtain corresponding actions based on the modifications.","At block , the analysis module forms a communication describing the one or more action for communication to the corresponding agent modules. The corresponding agent modules may then cause the respective nodes of the network to implement the actions described therein. Thus, the manager and agent modules may be utilized to perform what-if analysis based on an online trace-driven simulation in a manner similar to fault detection. What-if analysis may be utilized for correcting faults and improving network performance.","In another exemplary implementation, simulation is used to determine a modification to be made to a network to improve network performance, such as by using an iterative approach to perform what-if analysis. This approach is similar to the simulation as described in relation to . Thus, iteration refining could be used when multiple modification actions are needed.",{"@attributes":{"id":"p-0146","num":"0145"},"figref":["FIG. 11","FIGS. 1 and 2"],"b":["1100","1102","116","1104"]},"At block , for instance, network settings are collected that describes target end-to-end demands and the routing protocols that is in use. It should be noted that these network settings may be different from the traces used for troubleshooting, because the procedure  examines how the network (e.g., link loads and routing) will react to the changes in network configuration.","At block , the effect on the aggregate network throughput is examined based on removal, one at a time, of each flow from a network simulation. In an implementation, a damaging flow is identified as the one flow whose removal yield the most significant overall improvement to network performance. For example, a network  is shown in  that includes a plurality of flows -. Flow eight  (illustrated as Fin ), crosses each of the other flows - in the illustrated network . Therefore, the removal of flow eight  may result in the largest increase in throughput, as opposed to removal of any of the other flows -. In other words, the presence of flow eight  causes the greatest amount of damage to the performance of the network . In this way, a modification (e.g., removal or reduction of the influence of flow eight  on the other flows of the system) to the network  may be determined which results in the greatest increase in network performance.","At block , one or more actions are derived based on the modification which may be utilized to improve network performance. Exemplary actions may include rate-limiting, rerouting, and topology control of flow eight . The network simulation enables the manager module to further evaluate the benefit of these actions accurately. For example, the following table shows an expected throughput for exemplary corrective actions.",{"@attributes":{"id":"p-0150","num":"0149"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"119pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"center"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},{},"Total"]},{"entry":[{},"Action","Throughput (Mbps)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"No Action","1.064"]},{"entry":[{},"Reduce Flow 8's rate by half","1.148"]},{"entry":[{},"Route Flow 8 via Grid Boundary","1.217"]},{"entry":[{},"Increase transmission power to 20 dBM","0.990"]},{"entry":[{},"Increase transmission power to 25 dBm","1.661"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}},"br":[{},{}]},"An example of the described framework has been implemented on a WINDOWS XP platform (WINDOWS XP is a trademark of the Microsoft Corp., Redmond WA). Components of the exemplary implementation, design principles, and its features are described in this section.","The exemplary framework in this instance includes two separate components: agent modules and manager modules. As previously described in relation to , the agent module is executed on each node of the network to report local data either periodically or on-demand. A manager module collects relevant data from the agent modules and is executed to analyze the data, such as through execution of an included analysis module as described in relation to .","The exemplary framework employs simplicity and extensibility design principles. For example, the data gathered and propagated for monitoring and management may be cast into performance counters supported on WINDOWS (WINDOWS is a trademark of Microsoft Corp, Redmond Wash.). Performance counters may be provided as (name, value) pairs grouped by categories.","The described framework is also extensible. Adding to the data being monitored involves creation of a new category of performance counters and writing a module that updates the performance counter values as the information changes. Performance data related to transmission control protocol (TCP), user datagram protocol (UDP), internet protocol (IP), and workstation remote application programming interface (WRAPI) may be incorporated into the framework with little additional work.","Values in these performance counters may be read-only or writable. Writable counters, for instance, offer a way for an authorized manager node to change the values and influence the behavior of a node in order to fix problems or initiate experiments remotely, such as through communication of a manager module with an agent module being executed on difference respective nodes.","Each manager node may also be equipped with a graphical user interface (GUI) , an example of which is illustrated in , to interact with network administrators. The GUI allows an administrator to visualize the network as well as to issue management requests through the manager module. The GUI  displays a topology for an exemplary network test-bed. The GUI  in this instance depicts a manager window with agents deployed over a test-bed of 23 nodes. The manager module can display the topology based on the relative coordinates of the nodes either directly obtained or inferred. The GUI  may also allow the administrator to zoom-in on a particular part of the network for more detailed information and to click on a link to cause a display of network performance data about a particular link in a table format.","Conclusion","Although the invention has been described in language specific to structural features and\/or methodological acts, it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described. Rather, the specific features and acts are disclosed as exemplary forms of implementing the claimed invention."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 4","FIG. 2"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 8","FIG. 1"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
