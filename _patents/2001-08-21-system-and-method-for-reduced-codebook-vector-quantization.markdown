---
title: System and method for reduced codebook vector quantization
abstract: The present invention extends the generalized Lloyd algorithm (GLA) for vector quantizer (VQ) codebook improvement and codebook design to a new linearly-constrained generalized Lloyd algorithm (LCGLA). The LCGLA improves the quality of VQ codebooks, by forming the codebooks from linear combinations of a reduced set of base codevectors. The present invention enables a principled approach for compressing texture images in formats compatible with various industry standards. New, more flexible compressed texture image formats are also made possible with the present invention. The present invention enhances signal compression by improving traditional VQ approaches through the integrated application of linear constraints on the multiple pattern and signal prototypes that represent a single pattern or block of signal samples.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06968092&OS=06968092&RS=06968092
owner: Cisco Systems Canada Co.
number: 06968092
owner_city: Halifax
owner_country: CA
publication_date: 20010821
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["The present invention relates generally to the field of signal processing, more particularly to the field of vector quantization as applied to lossy signal compression.","Although the present invention may be directed toward any number of signal compression areas, to aid the reader in understanding the present invention, we refer to a single area by way of example. This example being the compression of data that adds texture to a digital image.","Conventional graphics systems such those as found in personal computers and home video game computers, use a frame buffer to store all the graphic data information that will be displayed on the computer screen. A graphics engine must \u201crender\u201d or draw graphics information into the frame buffer. Textures such as bumps, scratches, and surface features were not modeled by early graphics rendering engines. Rather, extremely smooth surfaces were constructed over a framework of graphics primitives such as polygons and vectors. Current graphics engines map textures onto these surfaces to replace artificially smooth surfaces with realistic detail. Examples of a texture of an object include the grass on a lawn, or the skin-tone variations and wrinkles on a human face.","A texture map is comprised of texels (texture elements) that are stored in texture memory. Texture memory is a scarce resource, so in order to efficiently use it, the digital signal representing the texture map is often compressed with a fixed compression ratio.","U.S. Pat. No. 5,822,452 discloses a method and system for \u201ccompressing and decompressing a texture image\u201d. This method and various obvious improvements and modifications have been widely studied and adopted. The method is the following: a compression color space is selected either manually or using a neural network, each texel in the texture image is converted to an 8-bit value in the selected color space, and a decompression table is generated that represents the RGB values for each texel stored in the selected color space. When rendering a pixel representing an object with a texture, the texture image is mapped to the representation of the object, and one or more texels that are associated with each pixel are decompressed.","The inventors in U.S. Pat. No. 5,822,452 go to great lengths to describe their neural network algorithm for selecting the compression color space. In fact, this method is an ad hoc, heuristic, and sub-optimal example of a gradient descent method. Neural networks are frequently found to produce performance that may be superior to random guessing for poorly characterized and\/or mathematically intractable optimization problems. The neural network as disclosed operates by iteratively modifying the choice of color space such that for each individual texel value, in turn, the distortion is lowered. However, lowering the distortion for a particular input may raise the distortion for the rest of the inputs leading to a net overall increase in distortion. In practice, more often than not, by using ad hoc techniques such as these, supplemented with user intervention to tune various optimization parameters, acceptable performance may be realized, but with much greater effort, both computational and human, than what may be possible with a principled approach.","Although the above referenced prior art patent deals specifically with the compression of color spaces, there is a more general need for a simple improved method of optimally compressing digital signals. In other words, an improvement to manual, neural network, and other ad hoc approaches. The present invention addresses this need.","The present invention relates to a system and method for utilizing a modified LCVQ algorithm to produce optimal codebooks for use in minimizing the content required in a digitized data stream.","One aspect of the present invention is a modified LCVQ method for creating an optimal codebook; the method having the steps of:\n\n","In another aspect of the present invention, there is provided a computer system for creating optimal codebooks, the system having:\n\n","In another aspect of the present invention there is provided a system for creating an optimal codebook; the system having:\n\n","In yet another aspect of the present invention, there is provided a computer readable medium containing instructions for creating an optimal codebook; the instructions having the steps of:\n\n","The present invention is directed toward a system and method of compressing image signals. Vector quantization is commonly used to compress image signals. Vector quantization takes as input a set of source vectors and calculates a smaller set of codevectors. These codevectors are then stored in a codebook. To better illustrate this concept, we refer now to .",{"@attributes":{"id":"p-0022","num":"0043"},"figref":["FIG. 1","FIG. 1","FIG. 2","FIG. 1","FIG. 1"],"b":["10","12","14","10","16","16","14","14","12","16","14","10","10","10"]},{"@attributes":{"id":"p-0023","num":"0044"},"figref":"FIG. 2","i":"a ","b":["20","20","22","26","26","14","22","12","14","12","26","24","22","14","14","26","28","22","14","20","30","28","14","30"]},"Referring now to , a diagram of a decoder is shown generally as . Decoder  takes as input an index  passed on channel  by encoder . Index  is then used to locate the corresponding codevector  in codebook . Codevector  is output via link  as output vector .","We will now discuss in general the concepts of compression and the specific method used by the present invention.","Effectiveness of any lossy compression technique can be measured in terms of the distortion introduced in order to obtain a required compression ratio. The distortion can be expressed in terms of the square difference between corresponding original and decompressed pixels averaged over the image (i.e., mean squared error for which less is better). The compression ratio (more is better) is the number of bits in the input divided by the number of bits in the compressed code that is the output of the compression apparatus. Ideally compression would be achieved with zero distortion (no loss). Lossless compression techniques introducing no distortion do exist. For typical inputs these methods will achieve modest compression ratios on average. However, for any lossless technique it is possible to find an input that will result in zero-compression, or even expansion of the signal. It is well known in the art that a truly random input is not compressible without loss. For this reason, when a fixed or minimum compression ratio must be consistently achieved, only lossy techniques are applicable.","A conventional example of lossy compression is to replace each 8-bits of each color component of a vector value that was in a red-green-blue (RGB) color space (RGB888) with a number of its most significant bits (MSBs) in a reduced color space (e.g., RGB565). That is, a 24-bit value is compressed in a 3:2 ratio by replacement with a 16-bit value, by reducing the number of bits to 5-bits of red, 6-bits of green, and 5-bits of blue. To achieve a 3:1 compression ratio RGB332 could, theoretically, be used, but practically the decompressed image quality is much too poor when the data is reduced in this straightforward manner.","Recent methods achieve acceptable visual quality with high compression ratios (e.g, 6:1). One broadly used technique is a linearly-constrained vector quantization (LCVQ) representation of blocks of vectors.","In a vector quantizer, lossy compression is introduced by representing vectors with a reduced number of codevectors that introduce only an almost imperceptible distortion when replacing the original vectors. That is, each vector in a block of T vectors (e.g., T=16 vectors in a 4\u00d74 block from the texture image) is represented by M possible Y-bit codevectors (e.g., M=4, Y=2) such that a 2-bits look-up table index is required to specify which codevector is used to represent a given vector. Linearly-constrained VQ places the restriction on these M codevectors that they must be formed from a simple linear combination of a much smaller set of L base codevectors (e.g., L=2). For example, a codevector C may be constructed from two base codevectors through a linear construction such as:\n\n=0.5+0.3+0.2\n\nThe above referenced linear equation is illustrative only, as the dimension of base codevectors may be greater than three and the weights for each dimension of B will vary.\n","This restriction is motivated by the fact that the complete compressed representation of each block of T vectors requires two sets of information: a block specific set of base codevectors, and T individual indices. Each of the T vectors in a block is represented by a Y-bit index specifying their representative codevector from the matrix C. Since the L base codevectors that form the base codevector matrix B are also unique for each block of T vectors, these base codevectors also form part of the compressed representation of the block. This flexibility allows the codevectors to adapt to colors present in each unique image block. For example, if L=2 and the base codevectors are stored in RGB565 format then each block requires two 16-bit base codevectors and 16 2-bit indices, for a total of 64-bits (4-bits per vector). This compression ratio is therefore twice that of the method described in U.S. Pat. No. 5,822,452, which requires 8-bits per vector.","We will now describe a principled, mathematical description of an LCVQ representation of a block of a texture image. Let X be a D row by T column matrix. For the example of texel compression, D=3 is the number of components in each texel\/vector, thus D represents the three values of RGB for each texel\/vector. The value T is the number of vectors in an image block I, each vector in that block forms one column of X. Let C be a D row by M column matrix containing the current codevectors for block I. Let N be a M by M diagonal matrix with the number of vectors in block I which are closest to each codevector (i.e. produce the least mse distortion and therefore assigned to that codevector) in matrix C appearing along the diagonal in the corresponding column of matrix N. Let S be a D by M matrix where each column contains the sum of the vectors currently assigned to each codevector. Let B be a D by L matrix where each column contains the current base codevectors for block I, such that C=BW is found by matrix multiplication with a fixed L by M weight matrix that specifies what proportion of each base codevector is used to form the current codevectors that represent the vectors.","For an example of present art, the mixed LCVQ format of S3 Inc., of Santa Clara, Calif. uses T=16=4\u00d74, L=2, M=4, and RGB=565 for the base codevectors. This is one of the most widely accepted formats used for texture compression for 3D graphics. Each subblock of 4\u00d74 pixels is coded with a four entry codebook (2 bits per pixel), where two of the entries are derived by linear interpolation from the two base codevectors that are quantized in 565 format. The red, green, and blue (RGB) channels are quantized to five, six, and five bits respectively.","As a further example of present art, the high LCVQ format utilized by 3dfx Interactive Inc., of Alviso, Calif., uses T=32=4\u00d78, L=2, M=8, and RGB=565 for the base codevectors. Each subblock of 4\u00d78 pixels is coded with eight codevectors (3 bits) derived by linear interpolation from two base codevectors that are quantized in 565 format.","Finally, the chroma LCVQ format of 3dfx uses T=32=4\u00d78, L=M=4, and RGB=565 for the base codevectors. Each subblock of 4\u00d78 pixels is coded with four codevectors (2 bits) that are stored in 565 format. This accommodates complex color regions; however, since no codevectors are derived, it is a block VQ rather than block LCVQ format (the weight matrix is the identity matrix).","The problem with these 3 examples of prior art is that:\n\n","Thus, the present invention is directed toward finding an improved system for finding a superior base codebook B for each block of vectors of a texture image. The present invention makes use of a general algorithm that is computationally scalable, and that guarantees convergence towards a minimum distortion compressed representation for the wide class of signal compression techniques that use \u201clinearly-constrained vector quantization\u201d (LCVQ).","Given this framework, the generalized Lloyd algorithm (GLA\/LBG) may be fundamentally modified and extended to a new algorithm that has similar properties to what the original GLA\/LBG has for unconstrained vector quantization. The new linearly-constrained generalized Lloyd algorithm (LCGLA) has two steps:\n\n","Furthermore, by limiting the number of iterations of these two steps that are performed, it is possible to limit the computational complexity of the algorithm to a fixed quantity\u2014making it suitable for hardware implementation. (i.e. the method is computationally scalable).","The present invention works with both two-dimensional and three-dimensional LCVQ codebooks.","The present invention provides LCVQ formats that are more effective than those used in the present art in which linear interpolation of base codevectors to form the codebook C is the sole technique. Also, a larger block size of 8\u00d78 is proposed rather than a block size of 4\u00d74 or 4\u00d78 such that more distinct colors are possible within a block. Three such formats are the following:\n\n","The only restriction on a weight matrix W is that it be non-singular. In other words, there are many different possible matrices that may be used instead of the ones suggest above by the inventor. For example, one efficient method of utilizing the present invention may be to pick a set of different weight matrices W that provide good distortion performance for representing certain types of images and allow one of the set to be used for each block, as specified on a block by block basis.","In summary, when quantizing a texture image, the image is partitioned into non-overlapping blocks of 8\u00d78 vectors\/pixels. These blocks are compressed, communicated, and decompressed in conventional raster-scan top-left to bottom-right order. Within each 8\u00d78 block, the vector\/pixels themselves are also represented in conventional raster-scan top-left to bottom-right order by an index which indicates what codevector is used to represent each vector. The base codevectors (B) themselves are present in the compressed representation of each block and are transmitted via channel  (see ). The matrix W is stored in both the encoder  and decoder . Thus, through the use of fixed matrix W and dynamic matrix B, the codevectors in codebook  (i.e. matrix C) are dynamically derived by matrix multiplication. By transmitting B, bandwidth is saved by not requiring the transmission of C. In addition, as discussed earlier, a number of matrices W may be employed by both the encoder and the decoder and an optimal matrix W selected for each individual block.","Referring now to  a block diagram of a computer system in which the present invention operates is shown generally as . In the preferred embodiment, the computer system  is a conventional personal computer such as an IBM compatible PC with a conventional DirectX 5.0 (or later) compatible graphics engine , and a non-conventional compression module  stored in conventional random access memory .","DirectX is a suite of multimedia application programming interfaces provided by Microsoft Corporation. DirectX provides a standard development platform for Windows-based PCs by enabling software developers to access specialized hardware features without having to write hardware-specific code.","Processor  of computer system  is a processor, capable of running the DirectX functions, such as a Pentium series processor commercially available from Intel Corp. Processor\/memory bus  and I\/O (input\/output) bus  are conventional. A conventional I\/O bus controller  controls the data flow between I\/O bus  and processor\/memory bus . Conventional I\/O devices , such as a keyboard and disk drive, are connected to I\/O bus . A conventional computer monitor  is driven by the graphics engine unit .","For an embodiment in which the graphics engine  is non-conventional, texture data is communicated across processor\/memory Bus , I\/O Bus Controller  and I\/O Bus  from compression module  to graphics engine  in at least one of the following non-conventional formats for each block of 8\u00d78 pixels from the original texture image:\n\n","The pseudo code required to implement the preferred embodiment of compression module  is provided in Appendix 1 in Matlab format. The two algorithms, which may be written in any computing language, are used to encode each image block. The routine \u201cInitcluster\u201d is used to find a random initial base codebook B given an 8\u00d78 block of 64 vectors that are the columns of the matrix X. The routine \u201clgbo\u201d. iteratively improves any codebook B using the unconventional LCGLA algorithm, which is a modified version of the convention generalized Lloyd algorithm that functions for linearly constrained codebooks C.",{"@attributes":{"id":"p-0048","num":"0099"},"figref":["FIG. 4","FIG. 4","FIG. 1"],"b":["200","202","10","204"],"br":[{},{}],"in-line-formulae":[{},{}],"i":"C=B*W; "},"Should the result of the creation of B provide a singular matrix, than B is reinitialized at step  to contain an outlying source vector, i.e. a vector that is far from what will ultimately be a code vector and control is returned to step . As one skilled in the art will recognize there are many methods to reinitialize matrix B so that it is not singular. The use of an outlier to reinitialize B is only a single example suggested by the inventors to resolve the problem of the matrix B being singular.","At step  matrix B is recalculated so that C (which is derived from B) provides a minimum distortion of the 64 source vectors in the 8\u00d78 block. This is done by updating B based upon the formula:\n\n*inverse()\n","At step  it is determined if the values in B have converged, i.e. B now contains the locally optimal set of base codevectors that are used to derive the codevectors in codebook C. If this is not the case, the process repeats by returning to step .","To further illustrate the invention, we refer now to  a block diagram of the components of compression module  (see ). Module  performs the functions illustrated in the flowchart of . Initialize module  randomly initializes matrix B, based upon the source vectors contained in the current block of data (i.e. the space  of ). Nearest neighbour module  modifies matrix B so that each vector in B is a \u201cnearest neighbour\u201d to the source vectors and calculates matrix C. Centroid module  calculates the centroid of all the base vectors contained in B and corresponds to step  of . Convergence module  determines if the vectors in B have converged and if not, control is returned to nearest neighbour module .","In an alternate embodiment, system  is a video game platform or a PC with a graphics card supporting alternative conventional industry standard LCVQ-based texture compression methods.","In another alternate embodiment, the graphics engine  is non-conventional and supports 2D and 3D LCVQ formats.","It is not the intent of the inventor to limit the present invention to vector quantization for images. As one skilled in the art of signal compression will appreciate, the present invention has use in any area of signal compression or pattern recognition where linearly-constrained nearest neighbour techniques are used. The use of the present invention for vector compression of texture images is meant to be illustrative of one use. As an example of a use other than compression of video images, the present invention may be utilized in pattern recognition and in particular optical character recognition.","While the present invention minimizes mean squared error for LCVQ, the extension of the algorithm to minimize weighted mean squared error and other such commonly practiced modifications of the error criterion as considered from VQ in the present art, are considered by the inventor to be extensions to the present invention requiring only the transfer of VQ techniques to LCVQ as would be obvious to anyone skilled in the art.","Although the invention has been described with reference to certain specific embodiments, various modifications thereof will be apparent to those skilled in the art without departing from the spirit and scope of the invention as outlined in the claims appended hereto.",{"@attributes":{"id":"p-0058","num":"0109"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":"APPENDIX 1"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"%%%"},{"entry":"function B = Initcluster(X,m)"},{"entry":"% Get an initial base codebook B at random from input data"},{"entry":"% INPUTS"},{"entry":"% X = input data: each column is a RGB \u2018vector\u2019"},{"entry":"% m = number of base codevectors"},{"entry":"% OUTPUTS"},{"entry":"% B = base codevector matix"},{"entry":"%need to duplicate some columns of B if X is small"},{"entry":"[n,N] = size(X);"},{"entry":"if(N > m)"},{"entry":"\u2003replace = 0;"},{"entry":"else"},{"entry":"\u2003replace = 1;"},{"entry":"end"},{"entry":"%track what inputs put in B, so no duplication for X large"},{"entry":"chosen = zeros(1,N);"},{"entry":"B = zeros(n,m);"},{"entry":"for i=1:m"},{"entry":"\u2003draw = floor(N*rand + 1);"},{"entry":"\u2003if(~replace)"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"while(chosen(draw))"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"draw = floor(N*rand + 1);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"\u2003end"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end"]},{"entry":[{},"B(:,i) = X(:,draw);"]},{"entry":[{},"chosen(draw) = 1;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"end"},{"entry":"%%%"},{"entry":"function [B,Bq,d,iters,rd,nX] = lgbo(X,m,base)"},{"entry":"% INPUTS"},{"entry":"% X = input data: each column is a RGB \u2018vector\u2019"},{"entry":"% m = number of codevectors (columns in C)"},{"entry":"% base = number of base codevectors (columns of B)"},{"entry":"% OUTPUTS"},{"entry":"% B = base codevector matrix"},{"entry":"% Bq = quantized base codevector matrix"},{"entry":"% d = distortion of X when replaced with chosen codevectors"},{"entry":"% iters = # of iterations to reach convergence"},{"entry":"[d,N] = size(X); % d = dimension, N = blocksize"},{"entry":"%random initialization"},{"entry":"Init = initcluster(X,base);\u2003% choose random initial set"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["if base==2","%1D (linear interpolation)"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"W = [1:(\u22121\/(m\u22121)):0; 0:(1\/(m\u22121)):1]; %weight matrix"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"elseif base==3 %2D"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"W=[1,0,0;0,1,0;.25,.25,.5;\u2212.25,\u2212.25,1.5; . . ."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"1,\u22121,1;\u22121,1,1;0,\u22121,2;\u22121,0,2;]\u2032;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"elseif base==4 %3D"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"%W=[eye(4),.25*[2,2,1,\u22121;2,\u22121,2,1;1,2,\u22121,2;\u22121,1,2,2]];"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"%W=[eye(4),.125*[3,2,2,1;2,3,2,1;3,1,2,2;1,2,3,2]];"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"end"},{"entry":"%variable initialization"},{"entry":"stoppingeps = 1.e-5;"},{"entry":"vi = ones(1,m);"},{"entry":"index=zeros(1,N);mind=index;"},{"entry":"cumdist = Inf; lastdist = 0;"},{"entry":"C= Init*W; %interpolate codevectors"},{"entry":"# iterate until convergence"},{"entry":"while(abs(cumdist \u2212 lastdist) > stoppingeps)"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"lastdist = cumdist;"]},{"entry":[{},"cumdist = 0;"]},{"entry":[{},"iters=iters+1;"]},{"entry":[{},"while(1) %1 iteration that repeats if B goes singular"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"% step (A)"]},{"entry":[{},"% form Voronoi regions: for each input,"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"% determine which centroid it is closest to"]},{"entry":[{},"for i=1:N"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"V=X(:,i(vi))-C;"]},{"entry":[{},"nm=sum(V.*V); %Euclidean distance squared (MSE)"]},{"entry":[{},"%input i's closest codevector"]},{"entry":[{},"[mind(i),index(i)]=min(nm);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end"]},{"entry":[{},"cumdist = sum(mind);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"%find diagonal matrix N"},{"entry":"for j=1:m"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"n(j) = sum(index==j);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"end"},{"entry":"% check if B is singular"},{"entry":"% and force it to be non-singular"},{"entry":"num=sum(n~=0);"},{"entry":"if num<base %fewer than base non-zero!"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"nz = find(n);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if (base-num)==1 %base==2"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"[jy,ji]=max(mind);"]},{"entry":[{},"Init(:,1:(base-1))=B(:,nz);"]},{"entry":[{},"Init(:,base)=X(:,ji);"]},{"entry":[{},"else"]},{"entry":[{},"[jy,ji]=sort(mind);"]},{"entry":[{},"Init(:,1:num)=B(:,nz);"]},{"entry":[{},"jl=N;"]},{"entry":[{},"for jk=(num+1):base"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Init(:,jk)=X(:,ji(jl));"]},{"entry":[{},"while(sum(abs(X(:,ji(jl))\u2212X(:,ji(jl\u22121))))==0)"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"jl=jl\u22121;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end"]},{"entry":[{},"jl=jl\u22121;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end % for jk"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"end % else"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"C= Init*W; %start all over if hit a singular matrix"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"else"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"break;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"end % if not singular then end while loop"},{"entry":"end %while(1)"},{"entry":"s = zeros(d,m); %get sum matrix S"},{"entry":"for j=1:m"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"if n(j)==1"]},{"entry":[{},"s(:,j) = X(:,index==j);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"elseif n(j)"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"s(:,j)= sum(X(:,index==j)\u2018)\u2019;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"end"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"end %for j=1:m"},{"entry":"Init = s*W\u2032*inv(W*diag(n)*W\u2032); %new base codevector matrix B"},{"entry":"C= Init*W; %new codevector matrix C"},{"entry":"end %% while not converged"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["nX = B(:,index);","% save re-constructed block"]},{"entry":["d = cumdist;","% total block distortion"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"end % function"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["For a better understanding of the present invention, and to show more clearly how it may be carried into effect, reference will now be made, by way of example, to the accompanying drawings which aid in understanding an embodiment of the present invention and in which:",{"@attributes":{"id":"p-0015","num":"0036"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0037"},"figref":"FIG. 2","i":"a "},{"@attributes":{"id":"p-0017","num":"0038"},"figref":"FIG. 2","i":"b "},{"@attributes":{"id":"p-0018","num":"0039"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0040"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0041"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
