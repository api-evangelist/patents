---
title: Method and device for introducing human interactions in audio sequences
abstract: A method for combining first second audio tracks includes modifying at least one of the two audio tracks; and storing the first and the second audio track in a non-volatile medium, characterized in that the interbeat intervals of the modified first and the second audio track exhibit long-range cross-correlations (LRCC).
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09349362&OS=09349362&RS=09349362
owner: 
number: 09349362
owner_city: 
owner_country: 
publication_date: 20140613
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"p":["The present invention relates to a method and device for introducing human interactions in audio sequences.","Post-processing has become an integral part of professional music production. A song, e.g. a pop or rock song or a film score is typically assembled from a multitude of different audio tracks representing musical instruments, vocals or a software instruments. In audio engineering, tracks are often combined where musicians have not actually played together. This may eventually be recognized by a listener.","It is therefore an object of the present invention to provide a method and a device for combining audio tracks, where the result sounds like a simultaneous recording of the individual tracks, even if they were recorded separately.","This object is achieved by a method and a device according to the independent claims. Advantageous embodiments are defined in the dependent claims.","According to the invention, determining these characteristics of scale-free (fractal) musical coupling in human play can be used to imitate the generic interaction between two musicians in arbitrary audio tracks, comprising, in particular, electronically generated rhythms.","More particularly, the interbeat intervals exhibit long-range correlations (LRC) when one or more audio tracks are modified and the interbeat intervals exhibit long-range cross-correlations (LRCC) when two or more audio tracks are modified.","A time series contains LRC if its power spectral density (PSD) asymptotically decays in a power law, p(f)\u02dc1\/f for small frequencies f and 0<\u03b2<2. The limits \u03b2=0 (\u03b2=2) indicate white noise (Brownian motion) while \u22122<\u03b2<0 indicates anti-correlations. In the literature, different normalizations for the power spectral frequency f can be found, which can be converted into one another. Here, f is measured in units of the Nyquist frequency (f=\u00bd Hz), which is half the sampling rate of the time series.","Long-Range Cross-Correlations (LRCC) between two sequences of interbeat intervals, i.e. two non-stationary time series, exist if the covariance F(s) defined below asymptotically follows a power law F(s)\u02dcs with 0.5<\u03b4<1.5. In contrast, \u03b4=0.5 indicates absence of LRCC.","The presence of such cross-correlations may be measured using a variant of detrended cross-correlation analysis (DCCA) [Podobnik B, Stanley H (2008), Detrended Cross-Correlation Analysis: A New Method for Analyzing Two Nonstationary Time Series. Phys. Rev. Lett. 100:084102]. Global detrending with a polynomial of degree k may be added as an initial step prior to DCCA, which has been shown crucial in analyzing slowly varying non-stationary signals [Podobnik B, et al. (2009), Quantifying cross-correlations using local and global detrending approaches. Eur. Phys. J. B 71:243-250.]. In fact, global detrending proved to be a crucial step to calculate the DCCA exponent of the non-stationary time series of interbeat intervals analyzed by the inventors. Without global detrending much larger DCCA exponents are obtained, i.e., spurious LRCC are detected that reflect global trends.","Given two time series X, X\u2032, where n=1 . . . N, the DCCA method including prior global detrending thus consists of the following steps:","(1) Global detrending: fitting a polynomial of degree k to Xand a polynomial to X\u2032, where typically k=1 . . . 5. One may use k=3. It should carefully be checked that the obtained DCCA scaling exponents do not change significantly with k.","(2) Integrating the time series R=\u03a3Xand R\u2032=\u03a3X\u2032.","(3) Dividing the series into windows of size s, (3) Least-squares fit {tilde over (R)}and {tilde over (R)}\u2032 for both time series in each window.","(4) Calculating the detrended covariance",{"@attributes":{"id":"p-0016","num":"0015"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"msub":{"mi":["F","DCCA"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"s"}},{"mrow":[{"mn":"1","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["N","s"]},"mo":"-","mn":"1"}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"msub":{"mi":["N","s"]}},"mo":"\u2062","mrow":{"mrow":[{"mo":["(",")"],"mrow":{"msub":[{"mi":["R","k"]},{"mover":{"mi":"R","mo":"~"},"mi":"k"}],"mo":"-"}},{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["R","k","\u2032"]},{"mover":{"mi":"R","mo":"~"},"mi":["k","\u2032"]}],"mo":"-"}}],"mo":"\u2062"}}],"mo":"\u2062"}],"mo":"="},"mo":","}}},"br":{},"sub":"s "},"For fractal scaling, F(s) \u03b1 s with 0.5<\u03b4<1.5. Absence of LRCC are indicated by \u03b4=0.5. Another indicator of absence of LRCC is that the detrended covariance F(s) changes signs and fluctuates around zero as a function of the time scale s [Podobnik B, et al. (2009), Quantifying cross-correlations using local and global detrending approaches, Eur. Phys. J. B 71:243-250].","The invention may be embodied in a computer-implemented method or a device for combining a first and a second audio track, in a software plugin product, e.g. for a digital audio workstation (DAW) that, when executed, implements a method according to the invention, in an audio signal, comprising one or more audio tracks obtained by a method according to the invention and\/or in a medium storing an audio signal according to the invention.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 1"},"The procedure to introduce human-like musical coupling in two audio tracks A and B is demonstrated using an instrumental version of the song \u2018Billie Jean\u2019 by Michael Jackson. The song Billie Jean was chosen because drum and bass tracks consist of a simple rhythmic and melodic pattern that is repeated continuously throughout the entire song. This leads to a steady beat in drum and bass, which is well suited to demonstrate their generic mutual interaction. For simplicity, all instruments were merged into two tracks: track A includes all drum and keyboard sounds, while track B includes the bass.","In step , the interbeat intervals of the first and the second audio track are determined. The interbeat intervals of tracks A and B read I=X+T and I=Y+T, where T is the average interbeat interval given by the tempo (here, T=256 ms, which corresponds to 234 beats per minute in the eighth notes). In case the audio tracks are MIDI files, this may be done based on the \u2018note on\u2019 messages. In other case, known suitable beat detection procedures may be used.","If the time series Xand Yare long-range cross-correlated, a musical coupling between drum and bass tracks is obtained.","In step , the interbeat intervals of at least one of the first audio track A and the second audio track B are modified. Small deviations are added to the interbeat intervals in order to modify a long-range cross-correlation (LRCC) between the interbeat intervals of the first and the second audio track. More particularly, the interbeat intervals are modified in order to induce LRCC between the interbeat intervals of the two audio tracks with a power law exponent, also called DCCA exponent \u03b4, which measures the strength of the LRCC. For \u03b4=0.5, there are no LRCC, while the strength of the LRCC increases with \u03b4.","More than two audio tracks can be modified by having each additional track responding to the average of all other tracks' deviations.","In particular, musical coupling between Xand Yis introduced using a two-component Autoregressive Fractionally Integrated Moving Average (ARFIMA) process with \u03b4=0.9, (2), that generates two time series xwhich exhibit LRCC [Podobnik B, Stanley H (2008), Detrended Cross-Correlation Analysis: A New Method for Analyzing Two Nonstationary Time Series. Phys. Rev. Lett. 100:084102; Podobnik B, Wang D, Horvati\u0107 D, Grosse I, Stanley H E (2010), Time-lag cross-correlations in collective phenomena, Europhys. Lett. 90:68001].","The process is defined by",{"@attributes":{"id":"p-0035","num":"0034"},"maths":[{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["X","t"]},"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mn":"1"},"mi":"\u221e"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":["w","n"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b1","A"]},"mo":"-","mn":"0.5"}}},"mo":"\u2062","msub":{"mi":"x","mrow":{"mi":["t","n"],"mo":"-"}}}}}}},{"@attributes":{"id":"MATH-US-00002-2","num":"00002.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["Y","t"]},"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"=","mn":"1"},"mi":"\u221e"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":["w","n"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b1","B"]},"mo":"-","mn":"0.5"}}},"mo":"\u2062","msub":{"mi":"y","mrow":{"mi":["t","n"],"mo":"-"}}}}}}},{"@attributes":{"id":"MATH-US-00002-3","num":"00002.3"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["x","t"]},"mo":"=","mrow":{"mrow":{"mo":["[","]"],"mrow":{"msub":{"mi":["WX","t"]},"mo":"+","mrow":{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"W"}},"mo":"\u2062","msub":{"mi":["Y","t"]}}}},"mo":"+","msub":{"mi":"\u03be","mrow":{"mi":["t","A"],"mo":","}}}}}},{"@attributes":{"id":"MATH-US-00002-4","num":"00002.4"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["y","t"]},"mo":"=","mrow":{"mrow":{"mo":["[","]"],"mrow":{"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"W"}},"mo":"\u2062","msub":{"mi":["X","t"]}},"mo":"+","msub":{"mi":["WY","t"]}}},"mo":"+","msub":{"mi":"\u03be","mrow":{"mi":["t","B"],"mo":","}}}}}}],"br":{},"sub":["A,B","n","t,A ","t,B ","t ","t","A","B"]},"The standard deviation chosen for Xand Ywas 10 ms. The time series of deviations Xand Yfor musical coupling are shown in . The measured DCCA exponent reads \u03b4=0.93 (in agreement with the analytical value 0.9 within margins of error) showing LRCC.","Introducing LRC in audio tracks is referred to as \u201chumanizing\u201d. For separately humanized sequences (i.e., without adding cross-correlations between the sequences), however, absence of LRCC is expectable. Indeed, when humanizing the time series of interbeat intervals separately (e.g., with an exponent \u03b2=0.9), the detrended covariance of Xand Yoscillates around zero, i.e., no LRCC are found.","All other characteristics, such as pitch, timbre and loudness remain unchanged.","In step , the combined audio tracks are stored in a non-volatile, computer-readable medium.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 2","FIG. 2"],"sub":["A","B"]},"Other processes than the ARFIMA process that generate LRCC can also be used to induce musical coupling. More particularly, when two subjects A and B are synchronizing a rhythm, each person attempts to (partly) compensate for the deviations d=t=tperceived between the two n'th beats when generating the n+1'th beat. This is reflected by the following model referred to as the Mutually Interacting Complex Systems (MICS) model\n\n=\u03c3\u2212\u03be\n\n=\u03c3\u2212\u03be\u2003\u2003(1)\n\nwhere Cand Care Gaussian distributed 1\/f noise time series with exponents 0<\u03b2<2, \u03beand \u03beis Gaussian white noise and T is the mean beat interval. We set d=0. The model assumes that the generation of temporal intervals is composed of three parts: (i) an internal clock with 1\/f noise errors, (ii) a motor program with white noise errors associated with moving a finger or limb, referred to in  as the motor error, (iii) an coupling term between the subjects with coupling strengths Wand W.\n","The deviations dwhich the musicians perceive and adapt to can be written as a sum over all previous interbeat intervals",{"@attributes":{"id":"p-0043","num":"0042"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["d","n"]},"mo":"=","mrow":{"mrow":[{"msub":[{"mi":"t","mrow":{"mi":["A","n"],"mo":","}},{"mi":"t","mrow":{"mi":["B","n"],"mo":","}}],"mo":"-"},{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"n"},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"I","mrow":{"mi":["A","j"],"mo":","}},{"mi":"I","mrow":{"mi":["B","j"],"mo":","}}],"mo":"-"}}}],"mo":"="}}}},"br":{}},"The coupling strengths o<W<2 describe the rate of compensation of a deviation in the generation of the next beat. In the limit W=W=0 and \u03b2=\u03b2=1 the second model reduces to the model introduced by Gilden et al., in the following called the Gilden model [Gilden D L, Thornton T, Mallon M W (1995), 1\/f noise in human cognition, Science 267:1837-1839]. The MICS model diverges for W+W\u22672, i.e., when subjects are over-compensating.","A possible extension of the second model is to consider variable coupling strengths W=W(d). Since larger deviations are likely to be perceived more distinctly, one possible scenario is to introduce couplings W that increase with d. For example, W may increase when large deviations such as glitches are perceived.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 3"},"The experimental setup comprises a keyboard  connected to speakers  and a recorder  for recording notes played by test subjects  and  on the keyboard . Preferably, the keyboard  has a midi interface and the recording device  records midi messages.","The performances were recorded at the Harvard University Studio for Electroacoustic Composition (See Supporting Information for details) on a Studiologic SL 88o keyboard yielding 57 time series of Musical Instrument Digital Interface (MIDI) recordings. However, the results presented here apply not only to MIDI but also to acoustic recordings.","Each recording typically lasted 6-8 minutes and contained approx. 1000 beats per subject. The temporal occurrences t, . . . , tof the beats were extracted from the MIDI recordings and the interbeat intervals read I=t. . . twith t=0. The subjects were asked to press a key with their index finger according to the following. Task type (Ia): Two subjects played beats in synchrony with one finger each. (Ib) \u2018Sequential recordings\u2019 were made, where subject B synchronized with prior recorded beats of subject A. Sequential recordings are widely used in professional studio recordings, where typically the drummer is recorded first, followed by layers of other instruments. Task type (II): One subject played beats in synchrony with one finger from each hand. Task type (III): One subject played beats with one finger (\u2018finger tapping\u2019). Finger tapping of single subjects is well-studied in literature [Repp B H, Su Y H (2013), Sensorimotor synchronization: A review of recent research, (2006-2012). Psychon B Rev 20:403-452.] and serves as a baseline, whereas our focus is on synchronization between subjects. In addition to periodic tapping, a 4\/4 rhythm {1, 2.5, 3, 4}, where the second beat is replaced by an offbeat, was used in tasks (I-III).",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 4","FIG. 4"],"sub":["A","B ","Nyquist ","A ","B","A","B"]},"A comparison of the MICS model (, right panel) with the experiments (left panel) shows excellent agreement. The vertex at the characteristic frequency fin the PSD is reproduced by the MICS model (cf. ).","The MICS model predicts emergence of LRCC (). This MICS model also predicts that, asymptotically, the DFA scaling exponents \u03b1of the interbeat intervals are determined by the \u2018clock\u2019 with the strongest persistence: \u03b1=\u03b1=[max(\u03b2, \u03b2)+1]\/2. This result is valid for long time series of length N\u2267105, see . Surprisingly, even when turning off, say, clock A (i.e., \u03b2=0), the long-time behavior of both Iand Iis asymptotically given by the exponent of the long-range correlated clock B (and vice versa) for large N. Thus, the musician with the higher scaling exponent determines the partner's long-term memory in the IBIs. However, in experiments the exponents can differ significantly in shorter time series of length N\u22481000 which can be seen by comparing the PSD exponents in .",{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 5","sub":["A","A","B","A","B","A","B","A","B"],"sup":"17"},"Evidence for LRCC between Iand Ion time scales up to the total recording time is reported in  with DCCA exponent \u03b4=0.69\u00b10.05. The two subjects are rhythmically bound together on a time scale up to several minutes and the generation of the next beat of one subject depends on all previous beat intervals of both subjects in a scale-free manner. LRCC were found in all performances of both laypeople and professionals, when two subjects were synchronizing simple rhythms. Thus, rhythmic interaction can be seen as a scale-free process.","In contrast, when a single subject is synchronizing his left and right hands (tasks (II)), no significant LRCC were observed, suggesting that the interaction of two complex systems is a necessary prerequisite for rhythmic binding.","The inventor identified two distinct regions in the PSD of the interbeat intervals separated by a vertex of the curve at a characteristic frequency f\u22480.1 f(see : (i) The small frequency region asymptotically exhibits long-range correlations. This region covers long periods of time up to the total recording time. (ii) The high frequency region exhibits short-range anti-correlations. This region translates to short time scales. These two regions were first described in single subjects finger tapping without a metronome [Gilden D L, Thornton T, Mallon M W (1995), 1\/f noise in human cognition, Science 267:1837-1839]. Because these two regions are observed in the entire data set (i.e., in all 57 recorded time series across all tasks), this suggests that these regions are persistent when musicians interact.",{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 4()","sub":["c ","n","A,n","B,n ","n "],"o":"\u03b1"},"In the present data set, exponents where found to be in a broad range 0.5<\u03bb<1.5, hence the analysis suggests to couple audio tracks using LRCC with a power law exponent 0.5<\u03bb<1.5. However, even larger exponents \u03bb>1.5 are found when no global detrending of the interbeat intervals is used or in cases when the nonstationarity of the time series is not easily removed by global detrending.","There is a fundamental difference between settings where individuals are provided with a metronome click (e.g., over headphones) while playing and where no metronome is present (also referred to as self-paced play) that manifests in the PSD of the interbeat intervals.",{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 6","sub":"Nyquist"},"For self-paced play of musical rhythms, the PSD of the interbeat intervals exhibits two distinct regions [Hennig H, et al. (2011), The Nature and Perception of Fluctuations in Human Musical Rhythms, PLoS ONE 6:e26457]. Long-range correlations are found asymptotically for small frequencies in the PSD. This region relates to correlations over long time scales of up to several minutes (as long as the subject does not frequently lose rhythm). On the other hand, for high frequencies in the PSD anti-correlations are found.","In contrast, a different situation is observed in presence of a metronome: For play of both complex musical rhythms [Hennig H, Fleischmann R, Geisel T (2012), Musical rhythms: The science of being slightly off, Physics Today 65:64-65.] and finger tapping [Repp B H, Su Y H (2013), Sensorimotor synchronization: A review of recent research, (2006-2012). Psychon B Rev 20:403-452.], long-range correlations were found in the time series of deviations of the beats from the metronome clicks. Below, the difference between the deviations and the interbeat intervals in the PSD will be quantified. The deviations from the metronome clicks are defined as e=t\u2212M, where tis the temporal occurrence (e.g., the onset) of the n'th beat, M=nT is the temporal occurrence of the n'th metronome click and T is the time period between two consecutive metronome clicks. The interbeat intervals read\n\n\n","Hence, the interbeat intervals are the derivative of the deviations (except for a constant). In the following, a relation is derived between the PSD exponents of eand I. Given a time series xwhere the PSD asymptotically decays in a power law 1\/f with exponent \u03b2. Let the time series {dot over (x)}=x\u2212xdenote the derivative of x. Then it can be shown analytically that the PSD of the derivative time series {dot over (x)}asymptotically follows a power law with exponent \u03b2\u22122 [Beran, J, Statistics for long-memory processes, Chapman&Hall\/CRC 1994]. Applying this general result to the present case, one finds\n\n\u03b2()=\u03b2()\u22122\n","As a consequence, when eexhibits long-range correlations with exponent 0<\u03b2(e))<2, the derivative Iexhibits long-range anti-correlations with \u22122<\u03b2(I)<0.","When subjects are synchronizing beats with a metronome, the time series of deviations exhibits long-range correlations with PSD exponents reported in the range \u03b2(e)=[0.2; 1.3] [Hennig H, Fleischmann R, Geisel T (2012), Musical rhythms: The science of being slightly off, Physics Today 65:64-65.]. Hence, one may expect the PSD exponents for the time series of interbeat intervals in the range \u03b2(I)=\u03b2(e)\u22122=[\u22121.8; \u22120.7]. Thus, the interbeat intervals are long-range anti-correlated for settings where a metronome is present. Humanizing a time series of deviations ewith an exponent 0<\u03b2<2 thus is equivalent to humanizing the interbeat Iintervals with \u22122<\u03b2<0. In contrast, for self-paced play as found by the inventor (i.e., in absence of a metronome), the interbeat intervals are long-range correlated on time scales of up to several minutes.",{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 7","b":"700"},"Different audio tracks are represented as channels  and . For each channel the standard deviation of the timing error may be set. In addition, the timing error for the spectrum of each channel may be set (\u03b2). Further, the motor error standard deviation may also be adjusted for each channel. Finally, the user may also set the coupling strength W for each channel. Given these data, the software device calculates an offset. More than two channels can be modified by having each additional channel responding to the average of all other channels' deviations.","Once the relevant parameters are set, the plug-in combines the audio tracks according to the previously described method."],"heading":["SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE FIGURES","p":["These and other aspects and advantages of the present invention are described more thoroughly in the following detailed description of embodiments of the invention and with reference to the drawing in which",{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 7","b":"700"}]},"DETDESC":[{},{}]}
