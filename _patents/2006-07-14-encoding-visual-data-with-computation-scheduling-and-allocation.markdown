---
title: Encoding visual data with computation scheduling and allocation
abstract: Computation scheduling and allocation for visual communication is described. In one aspect, multiple frames of video data are encoded by allocating for at least a subset of inter-coded frames, on frame-by-frame basis, computational resources to encode the inter-coded frame. To this end, a computational budget to encode a current inter-coded frame is estimated. The estimate is based on the actual computational costs to encode a previous inter-coded frame of video data. Next, sets of operations associated with encoding the current inter-coded frame are analyzed to determine computational resources to implement the operations. If the computational resources exceed the computational budget, complexity of the operations is reduced until the associated computational resources are less than or equal to the computational budget. At this point, the current inter-coded frame is encoded using the operations and the computational budget. This process is repeated for the remaining inter-coded frames of video data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08358693&OS=08358693&RS=08358693
owner: Microsoft Corporation
number: 08358693
owner_city: Redmond
owner_country: US
publication_date: 20060714
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Computation Resource Scheduling","Complexity-Adjustable Motion Estimation (CAME)","Exemplary Architecture for a Video Encoder"],"p":["With rapid increases in network communications bandwidth, real-time visual communication transmissions of video are generally not restricted by bandwidth availability. However, computational costs (i.e., processor workloads) to encode different frames of video content typically vary. That is, as video frame content changes, so does computational requirements to encode the content. For instance, an early termination mechanism adopted in H.264 video encoding motion estimation (ME) operations results in varying computational costs to encode different frames of video data. This is potentially problematic, especially since availability of a processor's limited computational resources generally changes over time. When necessary computational resources are not available, it is often difficult to maintain a consistent frame encoding rate for real-time video transmission. Generally this causes computation overflow, dropped video frames, and the introduction of jitter (transmission delays) into a video stream, resulting in low-quality video playback.","Computation scheduling and allocation for visual communication is described. In one aspect, multiple frames of video data are encoded by allocating for at least a subset of inter-coded frames, on frame-by-frame basis, computational resources to encode the inter-coded frame. To this end, a computational budget to encode a current inter-coded frame is estimated. The estimate is based on the actual computational costs to encode a previous inter-coded frame of video data. Next, sets of operations associated with encoding the current inter-coded frame are analyzed to determine computational resources to implement the operations. If the computational resources exceed the computational budget, complexity of the operations is reduced until the associated computational resources are less than or equal to the computational budget. At this point, the current inter-coded frame is encoded using the operations and the computational budget. This process is repeated for the remaining inter-coded frames of video data.","This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the detailed description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.","Overview","Techniques using motion history memory and sorted distortion-computation slopes have been used to estimate and allocate computation resources for video transmission. These techniques, however, are problematic in that they may introduce prohibitive memory demands and computational costs into video encoding and transmission operations. As discussed above, the may result in dropped frames and the introduction of jitter. These techniques are also limited in that they do not produce precise enough results to utilize H.264 fast motion estimation (FME) techniques.","In contrast, systems and methods for computation scheduling and allocation for visual communication, described below in reference to , balance computation adaptation with coding efficiency to guarantee that frames of video data are encoded before a certain delay. Since this is performed on a frame-by-frame basis, the systems and methods ensure a consistent encoding rate for real-time video transmission, and thereby, prevent dropped frames and\/or introduction of jitter into resulting real-time video transmissions.","An Exemplary System","Although not required, systems and methods for computation scheduling and allocation for visual communication are described in the general context of computer-executable instructions executed by a computing device such as a personal computer. Program modules generally include routines, programs, objects, components, data structures, etc., that perform particular tasks or implement particular abstract data types. While the systems and methods are described in the foregoing context, acts and operations described hereinafter may also be implemented in hardware.",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1","b":["100","100","102","104","106","102","106","104","102","106"]},"For example, server  includes processor  coupled to system memory . Processor  may be a microprocessor, microcomputer, microcontroller, digital signal processor, etc. System memory  includes, for example, volatile random access memory (e.g., RAM) and non-volatile read-only memory (e.g., ROM, flash memory, etc.). System memory  comprises program modules  and program data . Program modules  include, for example, video encoder , computation resource scheduling and allocation (\u201cCSA\u201d) , complexity-adjustable motion estimation (CAME) , and \u201cother program modules\u201d  such as an Operating System (OS), device drivers, and\/or so on.","Video encoder  employs operations of CSA  and CAME  to encode frames of video data . In one implementation, for example, CSA  and CAME  expose respective application programming interfaces (APIs)  and  to allow video encoder  to utilize their respective operations. In another implementation, operations of one or more of CSA  and CAME  are encapsulated by video encoder , independent of one or more exposed APIs. For purposes of exemplary illustration, encoded video data that has been generated by video encoder  according to the following described operations is shown as a respective portion of \u201cother program data\u201d .","More particularly, for each of at least a subset of frames of video data  (i.e., inter-coded frames), video encoder  uses CSA  to calculate and schedule a computational budget  (i.e., b) to encode the frame. Detailed aspects of CSA  are described below in the section titled \u201cComputation Resource Scheduling\u201d. In general, however, CSA  determines computational budget  in view of (a) actual computational cost to encode a previous frame of video data ; (b) calculated upper and lower computational bounds of processor  in view of buffer constraints; and (c) smallest and largest encoding complexities associated with encoding the current frame (i.e., current inter-coded frame) of video data . At this point, CAME  analyzes ME operations of the current frame to balance motion (RD) and computational costs, and thereby identify an optimal set of ME operations for the frame to at least match computational budget . (Detailed aspects of CAME  are described below in the section titled \u201cComplexity-Adjustable Motion Estimation\u201d).","Video encoder  encodes the frame using the identified optimal set of ME operations using the allocated computational budget  of processor . Server  then transmits the encoded video to a remote server  for decoding (e.g., using decoder module ) and playback (e.g., using player module ), including presentation (e.g., via display device ), to a user. After a frame is encoded, the encoded frame is ready to be transmitted. The instant of its transmission depends on \u201cother program modules\u201d . For purposes of exemplary illustration, such video transmission logic is shown as a respective portion of \u201cother program modules\u201d .","In one implementation, CAME  directs processor  to allocated computational budget  to encode the frame. In another implementation, a different module (e.g., CSA , etc) directs processor  to allocated computational budget  to encode the frame.",{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 2","FIG. 2","FIG. 2"],"b":["1","2"],"sup":"th "},"Video encoder  utilizes CSA  to balance computation resource adaptation and coding efficiency, thereby providing computation control guaranteeing that each frame of input video data  (a video stream) is successfully encoded before a certain delay. That is, CSA  maintains actual computation consumption (e.g., between line Aand line Aof ). This provides a consistent encoding frame rate with no jitter, no buffer overflow (frame dropping), and no buffer underflow.","More particularly, assume T, Tand Trespectively denote time instants that: (1) a kframe arrives at an encoding buffer; (2) video encoder  starts encoding the kframe; and, (3) video encoder  () ends encoding of the kframe. An exemplary encoding buffer is shown as a respective portion of other program data  as a \u201ccomputation buffer\u201d. Tof  denotes a time when the kframe is removed by video encoder  from the computation buffer. Suppose computation cost of encoding the kframe is b, size of the computation buffer is B, and fullness of the computation buffer when the kframe arrives is B. Suppose the computation rate is C, and frame encoding delay is a constant \u03b4. Thus, the time when the kframe is removed by video encoder  from the computation buffer is: T=T+\u03b4. Suppose the rate at which frames of video data  arrive at the computation buffer (i.e., frame rate) is M frames per second. The time instant a kframe arrives at the computation buffer is: T=(k\u22121)\/M. CSA  guarantees the time when the kframe is removed by video encoder  from the computation buffer is greater than or equal to the time when video encoder  () ends encoding of the kframe (i.e., T\u2267T) to avoid overflow (overload) of computational cost.","Since the time when video encoder  starts encoding a kframe (T) is equal to the time when the kframe arrives at an encoding buffer (T), plus an indication of fullness of the computation buffer when the kframe arrives (i.e., B), divided by the computation rate (C) (i.e., T=T+B\/C), then T+\u03b4\u2267T+b\/C. Supposing the frame encoding delay \u03b4=B\/C, we get b\u2266B\u2212B. (i.e., computation cost of encoding the kframe is less than or equal to the size (B) of the computation buffer minus fullness (B) of the computation buffer when the kframe arrives). Thus, the upper computation bound (upper bound of processor workload) for a current frame is U=B\u2212B. Additionally, CSA  guarantees b+B\u2267C\/M so as to avoid underflow of computational cost. Accordingly, the lower computation bound (lower bound of processor workload) for the current frame k is L=max{0, C\/M\u2212B}. With the upper and lower bounds representing respective states of the computation buffer (\u201cbuffer states\u201d), CSA  schedules for allocation of computation resources of processor  to encode a current frame of video data .","CSA  determines the number of overall processing cycles to a current frame, not the number of processing cycles to perform a task such ME. (A certain number of processing cycles to a specific task such as ME is determined, for example, with CAME ). To this end, CSA  estimates computational cost of the current frame bbased on the actual computational cost of encoding a previous frame of video data  and estimated task complexities of encoding a previous frame of video data. In this implementation, the previous frame is an immediately previous frame. In another implementation, the previous frame is the immediately previous frame or a frame prior to the immediately previous frame. CSA  then calculates a computational budget  (b) according to computation bound statuses of the computation (encoding) buffer and encoding complexities of the current frame. This is accomplished as follows:",{"@attributes":{"id":"p-0025","num":"0024"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":"b","mrow":{"mi":["k","alloc"],"mo":","}},"mo":"=","mrow":{"mo":"{","mrow":{"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["C","low"]},{"mi":["L","k"]}],"mo":","}}}},{"mrow":{"msub":{"mi":"b","mrow":{"mi":["k","est"],"mo":","}},"mo":"\u2264","mrow":{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["C","low"]},{"mi":["L","k"]}],"mo":","}}}}}]},{"mtd":[{"mrow":{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["C","high"]},{"mi":["U","k"]}],"mo":","}}}},{"mrow":{"msub":{"mi":"b","mrow":{"mi":["k","est"],"mo":","}},"mo":"\u2265","mrow":{"mi":"min","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["C","high"]},{"mi":["U","k"]}],"mo":","}}}}}]},{"mtd":[{"msub":{"mi":"b","mrow":{"mi":["k","est"],"mo":","}}},{"mi":"else"}]}]},"mo":","}}}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}},"br":{},"sub":["low ","high ","low ","high ","low ","high ","high ","high ","low "],"b":["116","116"]},"After a current frame of video data  has been encoded, CSA  (or a different module) updates state (buffer computational statuses) of the computation buffer to reflect the actual computational cost to encode of the current frame.","In real-time video communication systems there is a high computational cost of full search motion estimation operations. Such costs are based on encoding rates and distortion. To address this, CAME  analyzes ME path costs. This analysis provides an objective determination of whether select one of ME operations and associated operational paths of the current frame are compatible with the computational budget  (b). In this implementation, operations of CAME  are performed done after the determination of computation budget  of a current frame. After the encoding of the current frame, parameters related to CAME  will be updated for the encoding of a following frame.","In general, a fast motion estimation algorithm: (1) checks motion vector predictors using both spatial and temporal correlations to determine an initial searching point; (2) evaluates candidate points around the initial searching point using searching patterns to obtain motion vector(s); and (3) locally searches around the obtained motion vectors using a small search pattern to refine the motion vector(s). Exemplary motion vector predictors include, for example, the median prediction, the (0, 0) vector and the motion vectors of the neighboring left, top, and top-right blocks. A \u201csearching point\u201d is a location of a candidate predicting block in the reference frame.","Of steps (1)-(3), step (2) utilizes the majority of processor  computational resources. This is because step (2) evaluates candidate-searching points. Step (1) may identify very good motion vector(s), and if so, the second step (2) could be skipped. However, step (2) is still efficient to identify motion vector(s) for video sequences with complex motions and textures. In this implementation, CAME  determines whether use of a particular step (e.g., step (2)) will provide gain (i.e., not overflow computational resources) during frame encoding operations. If such objectively determined gain is evident, CAME  will implement the particular set of operations. Otherwise, CAME  will skip the particular step. To this end, and in this implementation, CAME  separates fast ME operations from slower ME operations implemented by video encoder  into multiple ME operational paths (e.g., two paths), as shown for example in . In another implementation, CAME  separates (segments) fast motion estimation operations implemented by video encoder  into more than two paths based on the particular encoding algorithm being employed.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 3","FIG. 3","FIG. 3"],"b":"124"},{"@attributes":{"id":"p-0031","num":"0030"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Exemplary Motion Estimation Operations"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"A","Without motion search (e.g., by setting motion vector as zero)"]},{"entry":[{},"B","Reduced Integer pixel ME (step 1 skipped)"]},{"entry":[{},"C","Integer pixel ME"]},{"entry":[{},"D","Integer ME + sub pixel ME"]},{"entry":[{},"D\u2032","Reduced Integer pixel ME + sub pixel ME"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}},"br":{},"figref":["FIG. 1","FIG. 3"],"b":["116","116","116"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 3","b":["108","120","120","124"]},{"@attributes":{"id":"p-0033","num":"0032"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"msub":{"mi":["J","motion"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","c"],"mo":","}}},{"munder":{"mi":"min","mrow":{"msub":{"mi":["MV","i"]},"mo":"\u2208","mrow":{"mi":"\u03a9","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"c"}}}},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"mrow":[{"mi":"SAD","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["MV","i"]},"mo":",","mi":"m"}}},{"mi":"\u03bb","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"R","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["MV","i"]},"mo":",","mi":"m"}}}}],"mo":"+"}}}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}},"br":{},"b":["124","118","120","118"],"sub":["k,alloc","motion"]},"The following equation can be used to select a best mode:",{"@attributes":{"id":"p-0035","num":"0034"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"J","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"c"}},{"munder":{"mi":"min","mrow":{"mi":["m","M"],"mo":"\u2208"}},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":{"mi":["J","motion"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["m","c"],"mo":","}}}}}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}},"br":{},"b":"116","sub":["\u2014","\u2014"]},"CAME  provides complexity level c for use equations (1) and (2), defines \u03a9(c)\u2014a set of candidate motion vectors, and selects a best ME search path in terms of these motion vectors. CAME  implements path selection criterion based, for example, on the following ratio:",{"@attributes":{"id":"p-0037","num":"0036"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"mrow":[{"mrow":[{"msub":{"mi":["J","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"B"}},{"msub":{"mi":["J","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"C"}}],"mo":"-"},{"msub":{"mi":["J","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"B"}}]},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}},"br":{},"sub":"i","sup":"th "},"For example, in the above described path selection process, J(B) and J(C) are used to select a certain path of A-B-D\u2032 or A-C-D. To further select a stopping point at the selected path, for example, when the path of A-B-b\u2032 is selected, we can use J(B) and J(D\u2032) to select the stopping point to be either B or D\u2032 with a second pre-defined threshold. In this implementation, for example, the second threshold is 0.01, although it could be a different value to tune the results to the data being encoded.","Since ME cost at each step prior to coding of a current frame of video data  is not available, CAME  employs actual cost of a previously coded frame of video data  to estimate ME cost of the current frame of video data . The estimate is denoted as J(X), wherein \u201cX\u201d represent a specific searching point, or ME operation. This process is called forward path selection. In the forward path selection. In this implementation, and to guarantee that there is minimal performance loss, CAME  assumes computation budget  (determined by CSA ) is enough to encode the current frame. CAME  determines whether computation budget  is enough by comparing it with the motion cost associated with various ME paths and stopping points in forward path selection operations. TABLE 2 shows exemplary forward path selection operations that are implemented independent of computational cost of operations associated with an ME path, according to one embodiment.",{"@attributes":{"id":"p-0040","num":"0039"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"EXEMPLARY FORWARD PATH SELECTION OPERATIONS"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"if ( (J(B)\u2212J(C)) \/ J(B) < \u03b8)"},{"entry":"\/\/ B and C represent different exemplary candidate paths to be selected."},{"entry":"\/\/ Actual computation costs of ME operations for the candidate paths are"},{"entry":"\/\/ evaluated for previous frame in view of threshold theta. When smaller"},{"entry":"\/\/ than theta, path A-B has similar rate-distortion performance but less"},{"entry":"\/\/ computation cost than A-C. (Note that A-B and A-B-D' indicate the"},{"entry":"\/\/ same ME path but different stopping points)"},{"entry":"\u2003\u2003if ( (J(B)\u2212J(D')) \/ J(B) < \u03c6)"},{"entry":"\/\/ B and D' represent two different stopping points in the path A-B-D'."},{"entry":"\/\/ Evaluate actual computation costs of ME operations (B and D') for"},{"entry":"\/\/ previous frame in view of threshold phi"},{"entry":"\u2003\u2003\u2003\u2003path = A-B"},{"entry":"\u2003\u2003else"},{"entry":"\u2003\u2003\u2003\u2003path = A-B-D'"},{"entry":"else"},{"entry":"\u2003\u2003if ( (J(C)\u2212J(D)) \/ J(C) < \u03c6)"},{"entry":"\u2003\u2003\u2003\u2003path = A-C"},{"entry":"\u2003\u2003else"},{"entry":"\u2003\u2003\u2003\u2003path = A-C-D"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"If CAME  determines that computation budget  (b) is not enough to encode the current frame k, CAME  adjusts the operations of selected ones of the ME operational paths by calculating slopes of ME operational paths to trace backward to a certain point to meet computation budget . In this process, a path with smaller slope indicates more coding gain per computation. Therefore CAME  selects a path with a smaller slope as compared to slope(s) of other path(s). Referring to the example of , please note that the slope of path A-B is not always larger than that of path A-C. The above process is called the backward path selection. TABLE 3 shows exemplary backward path selection operations to refine computational cost of ME path operations, according to one embodiment.",{"@attributes":{"id":"p-0042","num":"0041"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 3"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"EXEMPLARY BACKWARD PATH SELECTION OPERATIONS"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"If (computation unavailable)"]},{"entry":[{},"\u2003\u2003Switch (path)"]},{"entry":[{},"\u2003\u2003\u2003\u2003case A-B-D':"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003path = A-B"]},{"entry":[{},"\u2003\u2003\u2003\u2003case A-C:"]},{"entry":[{},"\u2003\u2003\u2003\u2003if (D' available) \u2003\u2003path = A-B-D'"]},{"entry":[{},"\u2003\u2003\u2003\u2003else \u2003\u2003\u2003\u2003path = A-B"]},{"entry":[{},"\u2003\u2003\u2003\u2003case A-C-D:"]},{"entry":[{},"\u2003\u2003\u2003\u2003if (C available)"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003if (D' available && slopA-D' >slopA-C)"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003path = A-B-D'"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003else \u2003\u2003path = A-C"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003else \/\/ C unavailable"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003go to case A-C"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"Again, CAME  implements \u201cforward path selection\u201d operations first to select a ME path and stopping point, independent of available computation resources. After this resource independent ME path and stopping point have been determined, ME path computation resources to implement the path are identified. For purposes of exemplary illustration, such E path computation resources are shown as a respective portion of \u201cother program data\u201d . If the determined ME path computation resources are greater than computational budget , CAME  performs the backward path selection operations (e.g., TABLE 2) to change the selected ME path and the stopping point. This process is iteratively performed until a selected ME path and stopping point are determined to use less than or equal amounts of computational resources as computational budget .","At this point, CAME  allocates computational budget  to encode a current frame of video data . Techniques to direct a processor to allocate a certain number of processing cycles to execute a set of operations are known. For example, in one implementation, CAME  sets a register used by processor  to indicate the number of processing cycles to allocate to encode a current frame of video data . Video encoder  encodes the frame to generate encoded video data for transmission to client computing device .",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 4","FIG. 4","FIG. 1"]},"Referring to , CSA component  implements operations of CSA  of  to schedule computational budget  to encode a current frame of video data , as described above with respect to . Component  implements operations of CAME  as described above with respect to  to identify a select set of motion vectors (a path) between a current frame F  and a reference frame F\u2032  of video data  () that meet computational budget . Remaining blocks  through  of  represent conventional video encoding operations implemented by video encoder  of .","An Exemplary Procedure",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 5","FIG. 1","FIG. 5"],"b":["500","500"]},"At block , video encoder  (or CSA ) calculates upper and lower computational bounds of processor . In one implementation, these computational bounds are determined in view of encoding buffer constraints such as size of the computation buffer, fullness of the computation buffer when a current frame arrives, computation rate, frame encoding delay, time when the frame is removed by encoder for encoding, and\/or so on. At block , video encoder  determines whether the current frame of video data  is an inter-coded frame of video data . If not, operations continue at block , where the frame is encoded using conventional frame encoding operations. At this point, the procedure continues at block , wherein the encoded frame is communicated to a remote computing device  for real-time presentation to a user. At block , video encoder  determines if there is a next frame of video data  to encode. If so, operations continue at on-page reference \u201cA\u201d and block , as discussed above for non-inter-coded frames and below for inter-coded frames.","Referring again to block , if the current frame of video data  is an inter-coded frame, operations continue at block , wherein the procedure determines if the frame is a first interceded frame encountered in this encoding operation. If so, operations continue at block , where the frame is encoded using conventional frame encoding operations, and actual computational cost to encode the inter-coded frame is determined. Techniques to determine computational costs of a set of operations are known. In one implementation, this and other computational costs are stored as statuses of an encoding or computational buffer. At this point, operations continue at block , as discussed above.","Referring again to block , if the current frame of video data  is not the first interceded frame encountered in this encoding operation, operations continue at block . At block , video encoder  leverages operations of CSA  to determine and schedules computational budget  () to encode the current frame of video data. This computational budget is based at least on actual computational costs to encode a previous frame of video data. More particularly, the computational budget is calculated based on an evaluation of complexity levels associated with coding the current frame, upper and lower computational balance of the processor that is being used to encode the current frame, and the actual computational cost of encoding a previous inter-coded frame.","At block , video encoder  uses CAME  to calculate computational costs of respective ones of multiple motion estimation operations associated with the current frame of video data . CAME  utilizes these computational costs to adjust encoding complexity of to include at least a subset of these operations so that they conform to the computational budget  (the computational budget was generated at block ). At block , video encoder  encodes the current frame of video data using the selected motion estimation operations and the computational budget, and calculated the actual computational cost to encode the current frame of video data. Operations of procedure  continue at block , as discussed above.","Conclusion","Although systems and methods for computation scheduling and allocation for visual communication have been described in language specific to structural features and\/or methodological operations or actions, it is understood that the implementations defined in the appended claims are not necessarily limited to the specific features or actions described above. Rather, the described features are disclosed as exemplary forms of implementing the claimed subject matter."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["In the Figures, the left-most digit of a component reference number identifies the particular Figure in which the component first appears.",{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
