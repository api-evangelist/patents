---
title: Network load balancing with traffic routing
abstract: In an exemplary method implementation, a method includes: receiving a packet requesting a new connection at a forwarding component; sending the packet from the forwarding component to a classifying component; selecting, by the classifying component, a route for the new connection; and plumbing, by the classifying component, the route for the new connection by causing a new entry to be added in a local routing table of the forwarding component. In an exemplary media implementation, one or more processor-accessible media include processor-executable instructions that, when executed, enable a system to perform actions including: receiving a first packet for a connection at first forwarding functionality; plumbing a route for the connection at the first forwarding functionality; receiving a second packet for the connection at second forwarding functionality; and plumbing the route for the connection at the second forwarding functionality using a distributed session tracking table.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07567504&OS=07567504&RS=07567504
owner: Microsoft Corporation
number: 07567504
owner_city: Redmond
owner_country: US
publication_date: 20030908
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED PATENT APPLICATIONS","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Exemplary Network Load Balancing Paradigms","Exemplary Approach to Flexible Network Load Balancing","Exemplary Health and Load Handling","Exemplary Session Tracking","Exemplary Classifying, Forwarding, and Request Routing","Exemplary Connection Migrating with Optional Tunneling and\/or Application-Level Load Balancing","Exemplary Operating Environment for Computer or Other Device"],"p":["This U.S. Nonprovisional Application for Letters Patent (i) is a continuation-in-part of co-pending U.S. Nonprovisional application Ser. No. 10\/610,506 (filed Jun. 30, 2003), (ii) is a continuation-in-part of co-pending U.S. Nonprovisional application Ser. No. 10\/610,519 (filed Jun. 30, 2003), and (iii) is a continuation-in-part of co-pending U.S. Nonprovisional application Ser. No. 10\/610,321 (filed Jun. 30, 2003).","Specifically, this U.S. Nonprovisional application for Letters Patent is a continuation-in-part of, and hereby incorporates by reference herein the entire disclosure of, co-pending U.S. Nonprovisional application Ser. No. 10\/610,506, filed Jun. 30, 2003, and entitled \u201cFlexible Network Load Balancing\u201d.","Specifically, this U.S. Nonprovisional Application for Letters Patent is also a continuation-in-part of, and hereby incorporates by reference herein the entire disclosure of, co-pending U.S. Nonprovisional application Ser. No. 10\/610,519, filed Jun. 30, 2003, and entitled \u201cNetwork Load Balancing with Host Status Information\u201d.","Specifically, this U.S. Nonprovisional Application for Letters Patent is also a continuation-in-part of, and hereby incorporates by reference herein the entire disclosure of, co-pending U.S. Nonprovisional application Ser. No. 10\/610,321, filed Jun. 30, 2003, and entitled \u201cNetwork Load Balancing with Session Information\u201d.","This disclosure relates in general to network load balancing and in particular, by way of example but not limitation, to network load balancing with traffic routing and the high availability thereof.","Communication, and many facets of life that involve communication, has been greatly impacted by the Internet. The Internet enables information to be communicated between two people and\/or entities quickly and relatively easily. The Internet includes many network nodes that are linked together such that information may be transferred between and among them. Some network nodes may be routers that propagate a packet from one link to another, may be individual client computers, may be personal networks for different entities (e.g., intranets for businesses), and so forth.","For this personal network case, as well as others, packets arriving at an Internet node or nodes are distributed to other nodes within the personal network. Such a personal network may be formed, for example, from a set of servers that can each work on packets that arrive at the personal network. A business, a university, a government office, etc. may receive many packets in a short timeframe at its personal network. In order to respond in a timely manner and to reduce the likelihood of rejection or loss of arriving packets, the personal network may rely on multiple servers that can each work on the arriving packets simultaneously.","The arriving packets are often inquiries pertaining to certain information, such as a document, a catalog item, a web page, and so forth. The arriving packets can also pertain to an economic transaction between a customer and a merchant. Other purposes for the packets of a packet-based communication are possible. Regardless, the arriving packets are distributed among different servers of a set of servers to accommodate a rapid arrival of the packets and\/or complex communication exchanges.","The distribution of arriving packets among different servers of a set of servers is often termed network load balancing. In other words, a load balancing operation may be performed on packets as they arrive at a node or nodes of the Internet when the node or nodes constitute a personal network and\/or when they connect the personal network to the Internet.","Such a load balancing operation is accomplished using dedicated hardware that fronts the personal network at the node or nodes that connect the personal network to the Internet and\/or that provide a presence for the personal network on the Internet. The physical hardware that performs the load balancing operation is usually duplicated in its entirety to realize redundancy and improve availability of the load balancing operation. To increase capacity for load balancing operations, more-powerful hardware that replicates the entirety of the previous load balancing hardware, and thus the operational capability thereof, is substituted for the previous load balancing hardware. Such scaling up of the load balancing operational capabilities is therefore confined to increasing the power of the hardware via substitution thereof.","To implement a load balancing operation, the hardware usually performs a round robin distribution of arriving connection requests. In other words, arriving connection requests are distributed to servers of a set of servers in a linear, repeating manner with a single connection request being distributed to each server. This round-robin load balancing distribution of connections is typically utilized irrespective of the condition of the personal network or the nature of an arriving connection request. If a load balancing operation does extend beyond a round robin distribution, these other factors are only considered to the extent that they may be inferred from network traffic and\/or from a congestion level of the personal network.","Accordingly, there is a need for schemes and\/or techniques that improve network load balancing and\/or the options associated therewith.","In an exemplary method implementation, a method includes: receiving a packet requesting a new connection at a forwarding component; sending the packet from the forwarding component to a classifying component; selecting, by the classifying component, a route for the new connection; and plumbing, by the classifying component, the route for the new connection by causing a new entry to be added in a local routing table of the forwarding component.","In an exemplary media implementation, one or more processor-accessible media include processor-executable instructions that, when executed, enable a system to perform actions including: receiving a first packet for a connection at first forwarding functionality; plumbing a route for the connection at the first forwarding functionality; receiving a second packet for the connection at second forwarding functionality; and plumbing the route for the connection at the second forwarding functionality using a distributed session tracking table.","In an exemplary system implementation, a system includes: a forwarding component that forwards packets; a classifying component that classifies packets and is capable of classifying packets for the forwarding component; a session tracking component that tracks sessions for at least one of the forwarding component and the classifying component; a health and load handling component that is capable of providing health and load information to the classifying component; and a high availability mechanism that provides detection of, handling of, and recovery from a failure of one or more of the forwarding component, the classifying component, the session tracking component, and the health and load handling component.","In another exemplary media implementation, one or more processor-accessible media include processor-executable instructions that, when executed, direct a system to perform actions including: receiving a token allotment at traffic routing functionality from health and load functionality, the token allotment having a first multiplicity of tokens for a first destination and a second multiplicity of tokens for a second destination; consuming, by the traffic routing functionality, a token of the first multiplicity of tokens when selecting the first destination for a connection request; and consuming, by the traffic routing functionality, a token of the second multiplicity of tokens when selecting the second destination for a connection request.","In yet another exemplary media implementation, one or more processor-accessible media include processor-executable instructions for load balancing infrastructure that, when executed, enable a system to perform actions including: establishing a first connection with a client; receiving a first request from the client via the first connection; determining, responsive to session information and\/or health and load information, that the first request is to be routed to a first host via a second connection; receiving a second request from the client via the first connection; and determining, responsive to the session information and\/or the health and load information, that the second request is to be routed to a second host via a third connection.","Other method, system, approach, apparatus, application programming interface (API), device, media, procedure, arrangement, etc. implementations are described herein.","This section describes exemplary paradigms for network load balancing and is used to provide foundations, environments, contexts, etc. for the descriptions in the following sections. This section primarily references .",{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 1","b":["100","106","108","100","102","1","102","2","102","108","1","108","2","108","104","106"],"i":["m","n"]},"Each of clients  may be any device that is capable of network communication, such as a computer, a mobile station, an entertainment appliance, another network, and so forth. Clients  may also relate to a person and\/or entity that is operating a client device. In other words, clients  may comprise logical clients that are users and\/or machines. Network  may be formed from one or more networks, such as the Internet, an intranet, a wired or wireless telephone network, and so forth. Additional examples of devices for clients  and network types\/topologies for network  are described below with reference to  in the section entitled \u201cExemplary Operating Environment for Computer or Other Device\u201d.","Individual clients  are capable of communicating with one or more hosts , and vice versa, across network  via load balancing infrastructure . Hosts  host one or more applications for interaction\/communication with clients , for use by clients , and so forth. Each host  may correspond to a server and\/or a device, multiple servers and\/or multiple devices, part of a server and\/or part of a device, some combination thereof, and so forth. Particular implementations for hosts  are described further below in the context of different network load balancing situations. (However, back-end support for hosts  is generally not shown for the sake of clarity.) Furthermore, additional examples of devices for hosts  are also described below with reference to  in the section entitled \u201cExemplary Operating Environment for Computer or Other Device\u201d.","Load balancing infrastructure  is reachable or locatable through network  at one or more virtual internet protocol (IP) addresses. Communications from clients  (or other nodes) that are directed to the virtual IP address of load balancing infrastructure  are received there and forwarded to a host . Load balancing infrastructure  is comprised of hardware and\/or software components (not explicitly shown in ).","Although load balancing infrastructure  is shown as an integral ellipse, the infrastructure to effectuate load balancing may also be distributed to other aspects of exemplary network load balancing paradigm . For example, software component(s) of load balancing infrastructure  may be located at one or more of hosts  as is described further below. Examples of architectures for load balancing infrastructure  are described below with reference to  in the section entitled \u201cExemplary Operating Environment for Computer or Other Device\u201d.","As indicated at (1), one or more of hosts  may provide host status information from hosts  to load balancing infrastructure . This host status information may be application specific. Examples of such host status information are described further below and include health and\/or load information, session information, etc. for hosts . A particular implementation that includes providing health and\/or load information from hosts  to load balancing infrastructure  is described below in the section entitled \u201cExemplary Health and Load Handling\u201d.","At (2), a request is sent from client () across network  to load balancing infrastructure  at the virtual IP address thereof. The content, format, etc. of a request from a client  may depend on the application to which the request is directed, and the term \u201crequest\u201d may implicitly include a response or responses from host(s) , depending on the context. Kinds of client requests include, but are not limited to:\n\n","At (3), load balancing infrastructure  forwards the request from () to host () (in this example). Load balancing infrastructure  may consider one or more of many factors when selecting a host  to which the request is to be forwarded, depending on which implementation(s) described herein are being employed. For example, load balancing infrastructure  may take into account: the application health and\/or load information of each host , session information relating to client () as stored at a host , and so forth.",{"@attributes":{"id":"p-0072","num":"0077"},"figref":"FIG. 2","b":["200","106","108","106","106","1","106","2","106","200","202","1","202","2"],"i":"u"},"Router\/switches , if present, may be considered as part of or separate from load balancing infrastructure  (of ). Router\/switches  are responsible for directing overall requests and individual packets that are received from network  to the shared virtual IP (VIP) address(es) of load balancing units . If a first router\/switch  fails, the second router\/switch  may takeover for the first. Although two router\/switches  are illustrated, one or more than two router\/switches  may alternatively be employed.","Router\/switches  may be ignorant of the load balancing infrastructure or load-balancing aware. If router\/switches  are not load-balancing aware, one of two exemplary options may be employed: For a first option, one load balancing unit  is \u201cassigned\u201d the shared VIP address, and all network traffic is forwarded thereto. This one load balancing unit  then evenly redistributes the traffic across the other load balancing units . However, there are bottleneck and failover issues with this first option (which can be mitigated if multiple VIP addresses are shared and are split between multiple load balancing units ). For a second option, router\/switches  are \u201ctricked\u201d into directing network traffic to all load balancing units , which individually decide what traffic each should accept for load balancing. However, there are inefficient effort duplication and switch performance\/compatibility issues with this second option.","If, on the other hand, router\/switches  are load-balancing aware, router\/switches  can be made to distribute incoming network traffic between\/among multiple load balancing units  (e.g., in a round-robin fashion). It should be understood that such load-balancing-aware routers\/switches  are capable of performing load balancing functions at a rudimentary level (e.g., in hardware). For example, load-balancing-aware routers\/switches  can perform simple IP-address-based session affinity so that all packets from a specific source IP address are directed to a same load balancing unit .","Each separately-illustrated load balancing unit  of load balancing units  may represent one physical device, multiple physical devices, or part of a single physical device. For example, load balancing unit () may correspond to one server, two servers, or more. Alternatively, load balancing unit () and load balancing unit () may together correspond to a single server. An exemplary load balancing unit  is described further below from a functional perspective with reference to .","Two exemplary request paths [] and [] are illustrated in . For request path [], client () transmits a request over network  that reaches router\/switch (). Router\/switch () directs the packet(s) of the request that originated from client () to load balancing unit (). Load balancing unit () then forwards the packet(s) of the request to host () in accordance with some load-balancing functionality (e.g., policy). For request path [], client () transmits a request over network  that reaches router\/switch (). Router\/switch () directs the packet(s) of the request that originated from client () to load balancing unit (). Load balancing unit () then forwards the packet(s) of the request to host () in accordance with some load-balancing functionality. Exemplary load-balancing functionality is described further below with reference to .",{"@attributes":{"id":"p-0078","num":"0083"},"figref":"FIG. 3","b":["106","108","106","302","314","106","108","316","106","302","304","306","308","310","312","314"]},"Health and load handler  is located partly at hosts  and partly on devices of load balancing units . Health and load handler  monitors the health and\/or load (or more generally the status) of hosts  so that health and\/or load information thereof may be used for the load-balancing functionality (e.g., when making load-balancing decisions). Exemplary implementations for health and load handler  are described further below, particularly in the section entitled \u201cExemplary Health and Load Handling\u201d.","Session tracker  may also be located partly at hosts  and partly on devices of load balancing units . Session tracker  monitors sessions that are established by clients  so that reconnections\/continuations of previously-established sessions may be facilitated by the load-balancing functionality. For example, some applications keep application-specific client session data on the hosts (which is also a type of host status information). These applications typically expect that clients use the same host for the duration of any given session. Exemplary types of sessions include: (i) a TCP connection (which is, strictly speaking, a session); (ii) an SSL session; (iii) a secure IP (IPsec) session; (iv) an HTTP cookie-based session; and so forth.","Although session tracker  is illustrated as a discrete block in load balancing unit , session tracking functionality of session tracker  may actually be implemented at a global level. In other words, session affinity is supported across multiple load balancing units . Session tracker  includes a centralized database and\/or a distributed database of session information in order to preserve session affinity. Exemplary implementations for session tracker , with an emphasis on a distributed database approach, are described further below, particularly in the section entitled \u201cExemplary Session Tracking\u201d.","Classifier  uses the data acquired and maintained by health and load handler  and\/or session tracker , possibly in conjunction with other factors, to classify incoming requests. In other words, classifier  selects a target host  for each incoming request from a client . Forwarder  forwards client requests (and\/or the packets thereof) in accordance with the targeted host  as selected by classifier . Forwarder  and classifier  may operate on a per-packet basis. Exemplary implementations for forwarder  and classifier  are described further below, particularly in the sections entitled \u201cExemplary Approach to Flexible Network Load Balancing\u201d and \u201cExemplary Classifying, Forwarding, and Request Routing\u201d.","Request router , as contrasted with per-packet implementations of forwarder  and classifier , can act as a proxy for an application running on a host . For example, request router  may terminate TCP connections, parse (perhaps partially) each logical request from a client , and resubmit each logical request to the targeted host . Consequently, each logical request from a client  may be directed to a different host , depending on the decisions made by request router . Furthermore, request router  may perform pre-processing on a connection (e.g., SSL decryption), may choose to absorb certain requests (e.g., because request router  maintains a cache of responses), may arbitrarily modify requests before forwarding them to hosts , and so forth. Exemplary implementations for request router  are also described further below, particularly in the sections entitled \u201cExemplary Approach to Flexible Network Load Balancing\u201d and \u201cExemplary Classifying, Forwarding, and Request Routing\u201d.","Connection migrator  enables a connection to be initially terminated at load balancing unit  and then migrated such that the connection is subsequently terminated at host . This connection migration can facilitate application-level load balancing. Connection migrator  is capable of migrating a connection from load balancing unit  to a host  in such a manner that that the original termination at load balancing unit  is transparent to a requesting client  and to applications  of the newly-terminating host . Tunneler  may utilize an encapsulation scheme for the tunneling of packets that does not introduce an overhead to each tunneled packet.","The functionality of tunneler  may also be used in situations that do not involve a connection migration. Furthermore, connection migrator  and\/or tunneler  may additionally be used in non-load-balancing implementations. Exemplary implementations for connection migrator , as well as for tunneler , are described further below, particularly in the section entitled \u201cExemplary Connection Migrating with Optional Tunneling and\/or Application-Level Load Balancing\u201d.","Any given implementation of a load balancing unit  may include one or more of the illustrated functions. Although illustrated separately, each of the functions of blocks - may actually be interrelated with, overlapping with, and\/or inclusive of other functions. For example, health and\/or load information of health and load handler  may be used by classifier . Also, connection migrator  and tunneler  work in conjunction with forwarder  and classifier . Certain other exemplary overlapping and interactions are described herein below.","In a described implementation, host  runs and provides access to one or more applications . Generally, applications  include file delivery programs, web site management\/server programs, remote access programs, electronic mail programs, database access programs, and so forth. Specifically, applications  may include, but are not limited to, web servers such as Internet Information Server\u00ae (IIS) from Microsoft\u00ae Corporation, terminal servers such as Microsoft\u00ae Terminal Server\u2122, and firewall and proxy products such as Internet Security and Acceleration Server\u2122(ISA). Although the specific application  examples in the preceding sentence relate to Microsoft\u00ae products, network load balancing as described herein is not limited to any particular vendor(s), application(s), or operating system(s).","This section illuminates how the network load balancing implementations described in this and other sections herein provide a flexible approach to network load balancing. This section primarily references .","As noted above, network load balancing functionality may be scaled up by replacing a first network load balancer with a second, bigger and more powerful network load balancer. The hardware capabilities of the second network load balancer replicate the entirety of the hardware capabilities of the first network load balancer, except that a greater capacity is provided. This is an inflexible approach that can be very inefficient, especially when only one network load balancing feature is limiting performance and precipitating an upgrade of a network load balancer.",{"@attributes":{"id":"p-0090","num":"0095"},"figref":"FIG. 4","b":["304","302","108"]},"In a described implementation, forwarder  corresponds to, and is the network endpoint for, the virtual IP (VIP) address (or addresses). Forwarder  is a relatively low-level component that makes simplified and\/or elementary policy decisions, if any, when routing packets to a further or final destination. Forwarder  consults a routing table to determine this destination. Classifier  populates the routing table based on one or more factors (e.g., host status information), which are described further in other sections herein.","Clients  and hosts  also correspond to indicated network addresses. Specifically, client () corresponds to address C, client () corresponds to address C . . . client () corresponds to address Cm. Also, host () corresponds to address H, host () corresponds to address H . . . host () corresponds to address Hn.","Five communication paths ()-() are shown in . Communication path () is between client () and forwarder , and communication path () is between forwarder  and host (). Communication paths ()-() are between forwarder  and classifier . For simplicity in this example, the connection associated with communication paths ()-() is an HTTP TCP connection. Furthermore, load balancing in this example relates to routing incoming connections to the least loaded host , at least without any explicit consideration of application-level load balancing.","Communication paths ()-() indicate how forwarder  and classifier  load-balance a single HTTP TCP connection from client (). At (1), client () initiates the TCP connection by sending a TCP SYN packet addressed to the VIP address. The routing infrastructure of network  routes this packet to forwarder  via router\/switch (), which is the \u201cclosest\u201d router\/switch  to forwarder .","At (2), forwarder  consults a routing table, which may be internal to forwarder  or otherwise accessible therefrom, in order to look up this connection. This connection may be identified in the routing table by the TCP\/IP 4-tuple (i.e., source IP address, source TCP port, destination IP address, destination TCP port). Because this is the first packet of the connection, there is no entry in the routing table. Forwarder  therefore applies the \u201cdefault route\u201d action, which is to send this packet to classifier .","At (3), classifier  consults its (e.g., consolidated) cache of host status information for hosts (), () . . . (). Classifier  concludes that host () is available and the least loaded host  at this instant for this example. Classifier  also \u201cplumbs\u201d a route in the routing table consulted by forwarder  for this TCP connection. For example, classifier  adds a route entry or instructs forwarder  to add a route entry to the routing table that maps the TCP connection (e.g., identified by the TCP 4-tuple) to a specific destination host , which is host () in this example. More particularly, the route entry specifies the network address H of host ().","At (4), classifier  sends the TCP SYN packet back to forwarder . Alternatively, classifier  may forward this initial TCP SYN packet to host () without using forwarder . Other options available to classifier  are described further below.","At (5), forwarder  can access a route entry for the connection represented by the SYN packet, so it forwards the packet to host () at address H. Forwarder  also forwards all subsequent packets from client () for this connection directly to host (). In other words, forwarder  can avoid further interaction with classifier  for this connection. One or a combination of mechanisms, which are described further below, may be used to delete the route entry when the connection ceases.","For communication path () in many protocol environments, forwarder  cannot simply send the packets from client () as-is to host () at network address H because these packets are addressed to the VIP address, which is hosted by forwarder  itself. Instead, forwarder  may employ one or more of the following exemplary options:\n\n","Although  show two specific separated functions, namely classifying and forwarding, it should be understood that other functions, such as those of request router , session tracker , connection migrator , and health and load handler , may also be scaled out independently (e.g., factored out independently), as is described further below. Furthermore, it should be noted that one or more than two functions may be separated and scaled out independently at different times and\/or simultaneously. Also, although TCP\/IP is used for the sake of clarity in many examples in this and other sections, the network load balancing principles described herein are applicable to other transmission and\/or communication protocols.","In the exemplary manner of , network load balancing functions (such as those shown in ) may be separated from each other for scalability purposes. They may also be separated and duplicated into various configurations for increased availability. Exemplary configurations for scalability and\/or availability are described below with reference to  after the method of  is described.",{"@attributes":{"id":"p-0102","num":"0110"},"figref":["FIG. 5","FIGS. 1-4"],"b":["500","500","502","506","500","6","9"]},"At block , network load balancing infrastructure is operated in a first configuration. For example, each configuration may relate to one or more of a selection, proportion, and\/or interrelationship of different load balancing functionalities; a number of and\/or type(s) of different devices; an organization and\/or layout of different components; a distribution and\/or allocation of resources; and so forth. At block , the network load balancing infrastructure is scaled out. For example, separated load balancing functionalities may be expanded and\/or concomitantly contracted on an individual and\/or independent basis. At block , the scaled out network load balancing infrastructure is operated in a second configuration.","As noted above, a monolithic network load balancer may be scaled up by increasing network load balancing functionality in its entirety by supplanting previous network load balancing hardware with more-powerful network load balancing hardware. In contradistinction, scaling out network load balancing infrastructure can enable network load balancing (sub-)functions to be scaled out individually and\/or independently. It can also enable network load balancing functions to be scaled out together or individually between and among different numbers of devices. Device, component, and resource-oriented scaling out examples are provided below.",{"@attributes":{"id":"p-0105","num":"0113"},"figref":"FIG. 6","b":["602","1","602","2","602","3","602"]},"As illustrated, a forwarder (), a classifier (), and a host () are resident at and executing on device (). A forwarder (), a classifier (), and a host () are resident at and executing on device (). Also, a forwarder (), a classifier (), and a host () are resident at and executing on device (). Thus, in this first device-oriented network load balancing infrastructure configuration, a respective forwarder , classifier , and host  are sharing the resources of each respective device .","In operation, forwarders  are the network endpoints for the VIP address(es). Any classifier  may plumb a route for a connection to any host , depending on host status information. For example, classifier () may plumb a route for a new incoming connection to host (). In accordance with a new route entry for this connection, forwarder () forwards subsequent packets to host ().","In one alternative device-oriented network load balancing infrastructure configuration to which the illustrated first one may be scaled out, a fourth device () (not explicitly shown in ) may be added that includes a forwarder (), a classifier (), and a host (). If, on the other hand, sufficient classification functionality is already present with classifiers (-) but additional forwarding functionality can benefit the request handling of hosts , a fourth device () may be added that includes a forwarder () and optionally a host (). For this scaled-out configuration, another classifier (, , or ) may plumb routes for forwarder () to any of hosts (, , or ) and host (), if present.","The first device-oriented exemplary network load balancing infrastructure configuration of  may be especially appropriate for smaller hosting situations in which separate devices for the network load balancing infrastructure are not technically and\/or economically worthwhile or viable. However, as the hosting duties expand to a greater number (and\/or a greater demand on the same number) of hosts  or if the network load on hosts  is significant, the first device-oriented exemplary network load balancing infrastructure configuration may be scaled out to accommodate this expansion, as represented by a second device-oriented exemplary network load balancing infrastructure configuration of .",{"@attributes":{"id":"p-0110","num":"0118"},"figref":"FIG. 7","b":["602","1","602","2","602","3","602"]},"As illustrated, forwarder () and classifier () are resident at and executing on device (). Forwarder () and classifier () are resident at and executing on device (). Also, forwarder () and classifier () are resident at and executing on device (). Thus, in this second device-oriented network load balancing infrastructure configuration, each respective forwarder  and classifier  are not sharing the resources of each respective device  with a host . Furthermore, the network load balancing infrastructure may be servicing any number of hosts .","In operation, forwarders  are again the network endpoints for the VIP address(es). Also, any classifier  may plumb a route for a connection to any host , depending on host status information. For example, classifier () may plumb a route for a new incoming connection to host (). In accordance with a new route entry for this connection, forwarder () forwards subsequent packets to host ().","Hence, network load balancing infrastructure as realized in software, for example, may be scaled out by moving the network load balancing infrastructure (or part thereof) from devices that are shared with hosts  to devices that are not shared with hosts . Also, as alluded to above for , another device () may be added to the network load balancing infrastructure to provide additional forwarding functionality, additional classifying functionality, additional functionality of both types, and so forth.",{"@attributes":{"id":"p-0114","num":"0122"},"figref":"FIGS. 8A and 8B","b":["800","850","850"]},"Specifically, first component-oriented exemplary network load balancing infrastructure configuration  (or first configuration ) includes (i) two forwarders () and () and (ii) two classifiers () and (). Second exemplary component-oriented network load balancing infrastructure configuration  (or second configuration ) includes (i) four forwarders (), (), (), and () and (ii) two classifiers () and (). Thus, first configuration  is scaled out to second configuration  by adding two components, which are forwarding components in this example.","In a described implementation, each respective network-load-balancing-related functional component corresponds to a respective device (not explicitly shown in  or B); however, each component may alternatively correspond to part of a device or more than one device. For example, forwarders () and () may be distributed across three devices. Or forwarder () and classifier () may correspond to a first device, and forwarder () and classifier () may correspond to a second device.","Two network-load-balancing-related functional components are added to scale out first configuration  to second configuration . However, one component (or more than two) may alternatively be added to scale out the network load balancing infrastructure. Furthermore, two or more different types of functional components may be scaled out \u201csimultaneously\u201d. For example, as illustrated by the dashed-line block, another classifying component (e.g., classifier ()) may also be added when scaling out first configuration  to second configuration .","Moreover, scaling by two or more different types of functional components may be performed in similar (e.g., equivalent) or dissimilar proportions to each other. As illustrated, adding forwarder components () and () while not adding any classifier component  or while adding a single classifier component () represent a scaling out at dissimilar proportions. However, two classifier components () and () (the latter of which is not explicitly illustrated in ) may be added while the two forwarder components () and () are added for a scaling out at similar proportions. Regardless, each individual network-load-balancing-related functional component may consume a different amount of the available network load balancing infrastructure resources, as is described with reference to .",{"@attributes":{"id":"p-0119","num":"0127"},"figref":"FIGS. 9A and 9B","b":["900","900","106","950","950","106"]},"As illustrated, first configuration  includes a 70%-30% resource distribution, and second configuration  includes a 40%-60% resource distribution. Such resources may include total device resources (e.g., number of devices), processing resources (e.g., number of processor cycles), memory resources (e.g., portion of cache, main memory, etc.), network bandwidth and\/or interface resources (e.g., bits per second and\/or physical network interface cards (NICs)), and so forth.","Specifically for first configuration , forwarder  consumes 70% of the resources of load balancing unit  while classifier  consumes 30% of these resources. After reallocation during a scaling out procedure to produce second configuration , forwarder  consumes 40% of the resources of load balancing unit  while classifier  consumes 60% of these resources.","In an exemplary situation, first configuration  might facilitate better network load balancing performance when fewer, longer transactions are being handled by the associated hosts (not shown in ) because classification functionality is utilized upon initial communication for a connection and forwarding functionality is utilized thereafter. Second configuration , on the other hand, might facilitate better network load balancing performance when more, shorter transactions are being handled by the associated hosts because the classification functionality is utilized for a greater percentage of the total number of packets funneled through the network load balancing infrastructure. In this situation, if request routing functionality is also being employed, then request router(s)  are also allocated a percentage of the total computing resources. The resource distribution among the three functionalities may be adjusted while handling connections (e.g., adjusted \u201con the fly\u201d) depending on current resource consumption and\/or deficits.","As indicated above with reference to , each load balancing unit  may correspond to all or a part of a total network load balancing infrastructure . For any given physically, logically, arbitrarily, etc. defined or stipulated load balancing unit , the resources thereof may be re-allocated during a scale out procedure. More specifically, a resource distribution between\/among different network-load-balancing-related separated functions of a load balancing unit  may be altered in a scale out procedure. Furthermore, more than two different functions, as well as other network-load-balancing-related functions that are not specifically illustrated in , may be allocated differing resource percentages.","The percentage of total system resources allocated to all load balancing functions may also be altered in a scale out procedure. As a general processing power example, the percentage of total processing power that is devoted to load balancing may be gradually increased as the amount of traffic that needs to be load balanced increases.","Network load balancing software may optionally perform monitoring to analyze and determine whether resources should be reallocated. For example, the network load balancing software may monitor the processor utilization of different network-load-balancing-related functions. The actual reallocation may also optionally be performed automatically by the network load balancing software in an offline or online mode.","It should be understood that a scaling out capability of network load balancing infrastructure (e.g., as realized at least partially in software) as described herein may relate to different installations and not necessarily a change to a single installation. In a resource-oriented example, network load balancing infrastructure as described herein may be configured in accordance with one resource distribution in one installation environment and may be configured in accordance with another different resource distribution in another installation environment having different operational parameters. Additionally, the capabilities, features, options, etc. described above with regard to scaling out are also applicable for \u201cscaling in\u201d. In other words, resources devoted to network load balancing infrastructure (or sub-functions thereof) may also be reduced.","This section describes how host status information, such as health and\/or load information, may be collected for and utilized in network load balancing. This section primarily references  and illuminates health and load functionality such as that provided by health and load handler  (of ). As described above with reference to , each host  hosts one or more applications . Health and load handler  utilizes health and\/or load information that relates to applications  and\/or hosts  for certain described implementations of network load balancing.",{"@attributes":{"id":"p-0128","num":"0136"},"figref":"FIG. 10","b":["1006","108","1","108","2","108","316","1","316","2","316","108","316"],"i":["n","n"]},"For example, hosts  and applications  may be accepting new connections or not accepting new connections. Also, they may be quickly handling client requests or slowly handling client requests. Furthermore, they may have many resources in reserve or few unused resources. All or any part of such data, or other data, may comprise host status information . Generally, host status information  provides an indication of the status of some aspect of hosts  and\/or applications  that are running thereon.","In a described implementation, each host (), () . . . () includes a host status information (HSI) determiner (), () . . . and (), respectively. Each host (), () . . . () also includes a host status information (HSI) disseminator (), () . . . and (), respectively. Each host status information determiner  and\/or host status information disseminator  may be part of load balancing infrastructure (LBI) .","Each host status information determiner  determines host status information  for its respective host  and\/or applications  that are running thereon. Exemplary techniques for determining such host status information  are described below with reference to , and particularly . Each host status information disseminator  disseminates host status information  for its respective host  and\/or applications  to load balancing infrastructure  (e.g., those portion(s) of load balancing infrastructure  that are not located on hosts ). Exemplary techniques for disseminating such host status information  are described below with reference to , and particularly FIGS. B and -.","Specifically, each host status information disseminator  disseminates host status information  (directly or indirectly) to each load balancing unit (LBU)  of load balancing infrastructure  that includes at least one health and load handler  and\/or classifier . Load balancing infrastructure  refers to host status information  when implementing network load balancing. For example, as indicated by logic , load balancing infrastructure  is capable of making load balancing decisions responsive to host status information .","In operation at (1), host status information determiners  determine host status information  for respective hosts  and\/or applications . At (1) and (2), host status information disseminators  disseminate host status information  from hosts  to load balancing infrastructure . For example, host status information  may be disseminated to individual load balancing units . At (3), logic  makes network load balancing decisions responsive to host status information . At (4), connections are forwarded to targeted hosts  based on these network load balancing decisions.",{"@attributes":{"id":"p-0134","num":"0142"},"figref":["FIG. 11","FIGS. 1-3"],"b":["1100","1100","1102","1106","1100","10"]},"At block , host status information is sent from hosts to load balancing units. For example, host status information  may be sent from hosts  to load balancing units . At block , the host status information is received from the hosts at the load balancing units. For example, load balancing units  may receive host status information  from hosts . At block , load balancing decisions are made responsive to the received host status information. For example, logic  at load balancing units  may make decisions for network load balancing responsive to host status information .","Thus in , load balancing infrastructure  collects host status information  from hosts  (and\/or applications  thereof) and load balances incoming requests that are directed to hosts  responsive to host status information . As described further below with reference to , this host status information  may be application-specific. As also described further below, examples of host status information  include health and\/or load information.",{"@attributes":{"id":"p-0137","num":"0145"},"figref":"FIG. 12","b":["1206","108","1","108","2","108","106","1","106","2","106","1210"],"i":["n","u"]},"As illustrated, hosts  communicate health and load information  to load balancing units  using communication linkage . The bi-directional communication of health and load information , as indicated by the double-pointed arrow, refers to a two-way communication from load balancing units  to hosts  that provides certain completeness, coherency, correctness, etc. such that hosts  and\/or load balancing units  may fail independently of one another. Such two-way communications from load balancing units  to hosts  are described further below with particular reference to .","Health information reflects whether a given host and\/or application is capable of handling client requests. Load information reflects the number, amount, and\/or level of client requests that the given host and\/or application is capable of handling at a particular moment. In other words, load can reflect directly and\/or inversely an available number, amount, and\/or level of total capacity of the given host and\/or application. As noted above, implementations described with reference to  focus on health and\/or load information; however, those implementations are also applicable to general status information for hosts (including the applications thereof).","In a described implementation, each host (), () . . . () includes a respective health and load infrastructure (H&LI) component (), () . . . (). Each health and load infrastructure component  may optionally be a portion of load balancing infrastructure  that is resident at and executing on each host . Health and load information  may be realized in software. When functioning, each health and load infrastructure (), () () creates and maintains a respective health and load (H&L) table (), () . . . ().","These health and load tables  may include application-specific entries. Health and load information  that is stored in health and load tables  may be independent of load balancing infrastructure . For example, administrators, designers, etc. may specify criteria for health and load information  at configuration time. Additionally, entities external to a device that is or that has a host  may contribute to determining health and load information  for applications  on the device. An exemplary health and load table  is described further below with reference to .","Each load balancing unit (), () . . . () includes a respective consolidated health and load (H&L) cache (), () . . . (). Each consolidated health and load cache  includes the information from each health and load table (), () . . . (). Consequently, each load balancing unit  is provided with quick (e.g., cached) access to health and load information  for each host  for which load balancing units  are load balancing network traffic.","In operation, health and load infrastructures  push health and load information  from health and load tables  to consolidated health and load caches . The mechanism to provide health and load information  is event driven such that changes to health and load tables  are provided to consolidated health and load caches  in a timely, scaleable manner.",{"@attributes":{"id":"p-0144","num":"0152"},"figref":["FIG. 13A","FIG. 12"],"b":["1204","1204","1302","316","1302","1204","1302","1302","1302"]},"Because each entry  is associated with a particular application , a row is added as each application is spun up (e.g., by an administrator). Likewise, a row is deleted\/removed each time an application is closed down. Similarly, individual fields in columns (A), (B), and\/or (C) are modified\/updated when a value thereof changes. For example, when a status characterization value changes for a given application , a value in a field of application status characterization (B) for entry  of the given application  is updated.","The additions and deletions of entries  for applications  may be effectuated with input from a control manager at the host . For example, a control manager portion of an operating system knows when an application  is started and stopped because it is actively involved in the starting and stopping of applications . Hence, a control manager may identify that it has, at least in part, started an application , and the control manager may establish that it has, at least in part, stopped the application . Health and load infrastructure  may therefore be informed of the starting and stopping of applications  by the control manager. Hence, no such explicit communication from applications  has to be provided to health and load infrastructure . An example of a control manager is the Service Control Manager (SCM) of the Windows\u00ae Operating System from Microsoft\u00ae Corporation.","Application identifier (A) includes information that is used to uniquely identify the application  to which entry  is associated. Application identifier (A) may include one or more of the following for the associated application : the virtual IP address and port, the physical IP address and port, the protocol used, and any protocol-specific information. The protocol may be HTTP, IPsec, SOAP, and so forth. The protocol-specific information may be a URL pattern or string to further delineate the application associated with entry . Thus, application identifier (A) more particularly refers to a specific application endpoint on a particular host .","Other application identifiers may alternatively be employed. For example, to reduce communication bandwidth, application identifier (A) may be a 32-bit number that maps to the above exemplary information at health and load infrastructure  and at load balancing units . Moreover, any of the fields in entry  may actually contain a globally unique identifier (GUID) that is used as a key to look up the true information for the field.","Application status characterization (B) includes information that reflects the status of the application  to which entry  is associated. Application status characterization (B) includes the following for the associated application : application health, application load, and application capacity. Application health is a quasi-Boolean value that indicates whether an application is functioning. Application health can be healthy, failing, or unknown. Application health is a relatively-instantaneous value and is communicated with relatively low latency (e.g., of approximately a second or a few seconds) to load balancing units  when the application health value changes.","Application load is a value that indicates how occupied or busy a given application is and thus, directly or inversely, how much additional load the given application can handle. Application load is a relatively slowly-changing or averaged value that can be smoothed with a hysteresis-inducing mechanism, if desired, to eliminate transient spikes of increased or decreased load. It is communicated relatively infrequently to load balancing units  (e.g., approximately one to four times a minute). The value of application load is given meaning with regard to application capacity.","Application capacity is a value that indicates the maximum capacity of the application. It is selected in a generic manner to be meaningful for a given context but still sufficiently flexible for other contexts. Application capacity is a unit-less, bounded number (e.g., 0-99) that is determinable at configuration time. It may be based on processing power, memory size\/speed, network access, some combination thereof, and so forth. Application capacity expresses relative capacities between and among other applications of the same type in a set of hosts (,  . . . ).","Thus, relative to application capacity, application load gains meaning. Application load for a given application is a percentage of application capacity for the given application. Alternatively, application load can be expressed as a unit-less number from which the percentage can be ascertained in conjunction with the value of application capacity.","Load balancer directive (C) includes information that reflects the desired and\/or expected state of the directive established by health and load infrastructure  for load balancing units  with respect to an application  to which entry  is associated. Load balancer directive (C) includes the following for the associated application : target load balancing state and current load balancing state.","The target load balancing state reflects the state of the directive to load balancing units  as desired by health and load infrastructure . The current load balancing state reflects what health and load infrastructure  understands the current state of the directive to load balancing units  to be as recorded at load balancing units . The current load balancing state thus reflects the load balancing directive that health and load infrastructure  expects load balancing units  to be currently operating under as dictated using a communication protocol. Such an exemplary communication protocol is described further below with reference to . The interaction and relationship between the target load balancing state and the current load balancing state is also further clarified with the description of .","The target load balancing state and the current load balancing state may each take a value of active, inactive, or draining. An active directive indicates that new requests\/connections are welcome and may be targeted at the application that is associated with entry . An inactive directive indicates that no additional packets should be forwarded to the associated application. A draining directive indicates that no packets for new requests\/connections should be sent to the associated application but that packets for existing requests\/connections should continue to be forwarded to the associated application.","In a described implementation, the definitive version of respective health and load information  is stored at health and load tables  that are located at each respective host  of multiple hosts . With this implementation, if a host  crashes, the health and load information  that is lost pertains to those applications  that also crashed. A measure of high availability is therefore gained automatically without duplicating data. However, the definitive version of health and load information  may alternatively be stored elsewhere. Other such storage options include load balancing units  themselves, a host  that (as its sole task or along with hosting duties) stores and maintains health and load information  for multiple other (including all other) hosts , another separate and\/or external device, and so forth.","If the definitive version of health and load information  is stored and maintained elsewhere besides being distributed across hosts (,  . . . ), such health and load information  may be stored redundantly (e.g., also stored in a duplicative device, backed-up, etc.) for high-availability purposes. Exemplary proxy scenarios for storing health and load information  are described below with reference to .  is directed to a proxy scenario for health and load tables , and  is directed to a proxy scenario for consolidated health and load caches .",{"@attributes":{"id":"p-0158","num":"0166"},"figref":["FIG. 13B","FIG. 12"],"b":["1208","1208","106","1204","1202","108","1208"]},"As illustrated, consolidated health and load cache  includes a cache for each host (), () . . . () that replicates part or all of the information in the health and load table  of each respective host (,  . . . ). Specifically, consolidated health and load cache  includes a cache for host # (), a cache for host # () . . . a cache for host #n (). Thus, the illustrated consolidated health and load cache  is organized at a broad level by host (,  . . . ), with each individual cache  including application-specific entries for the corresponding respective host (,  . . . ). Alternatively, consolidated health and load cache  may be organized at a broad level by type of application , with individual blocks that are directed to a specific application type further divided by host (,  . . . ). Other data structure formats may also be employed.",{"@attributes":{"id":"p-0160","num":"0168"},"figref":["FIG. 14","FIGS. 1-3"],"b":["1400","1402","1416","1400","12","13","1402","1404","108","1406","1416","106"]},"At block , health and load information at a host is determined. For example, health and load information  for applications () may be ascertained by health and load infrastructure () and stored in health and load table () at host (). At block , the determined health and load information is disseminated to load balancing units. For example, health and load infrastructure () may send health and load information  for applications () to load balancing units (,  . . . ). As indicated by arrow , the actions of blocks  and  are repeated so that (application) health and load may be continually monitored and updated as changes occur.","At block , health and load information is received from hosts. For example, load balancing unit () may receive health and load information  from multiple hosts (,  . . . ), which includes health and load information  for applications () of host (). At block , the received health and load information is cached. For example, load balancing unit () may store health and load information  from hosts (,  . . . ) into consolidated health and load cache (). With reference to the  implementation of a consolidated health and load cache (), health and load information  for applications () from host () may be stored in cache for host # (). As indicated by arrow , the actions of blocks  and  are repeated so that (application) health and load information may be continually received and updated as changes occur.","As indicated by dashed arrow , load balancing units  are also handling communications from clients  while handling (application) health and load issues. At block , a packet requesting a new connection is received. For example, load balancing unit () may receive a TCP SYN packet from client () through network . At block , the cached health and load information is consulted. For example, load balancing unit () may consult consolidated health and load cache (). More particularly, load balancing unit () may consult entries that are associated with the application to which the TCP SYN packet is directed across caches for hosts #, # . . . #n (,  . . . ).","At block , a host is selected responsive to the cached health and load information. For example, load balancing unit () may select host () having application(s) () responsive to health and load information  that is cached in consolidated health and load cache (). The selected application  (and host ) should be healthy and able to accept additional load (e.g., possibly the least loaded application among those applications that are of the application type to which the TCP SYN packet is directed).","The consulting of the cached health and load information (at block ) and the host-selecting responsive to the cached health and load information (at block ) may be performed prior to reception of a specific new-connection-requesting packet and\/or using a batched scheme. Also, the selecting may be in accordance with any of many schemes. For example, a token based or a round-robin based scheme may be employed. With either scheme, the selection may involve a weighting of relative loads among the application options. This consultation and selection, along with the token and round-robin based schemes, are described further below with reference to  and in the section entitled \u201cExemplary Classifying, Forwarding, and Request Routing\u201d, especially with regard to classifying functionality.","After the target host is selected at block , the new-connection-requesting packet may be sent thereto. At block , the packet received from the client is forwarded to the selected host. For example, the TCP SYN packet is forwarded from load balancing unit () to selected host (). The forwarding of this initial packet may be effectuated directly by a classifier  or by a forwarder , as is also described further below in the section entitled \u201cExemplary Classifying, Forwarding, and Request Routing\u201d.","For a described implementation, health and load infrastructure  is resident at and distributed across multiple hosts  as well as being located at load balancing units  (as represented by health and load handler ). Health and load infrastructure  has three responsibilities. First, it exposes listening point(s) to attain application status updates for application status characterizations (B) of health and load tables . Second, it synthesizes the application status information to determine what load balancing units  should do, which is embodied in load balancer directive (C). Third, health and load infrastructure  communicates this directive from hosts  to load balancing units .","The directive content of load balancer directive (C) is effectively a digested version of the information for application status characterizations (B). However, load balancing units  may also receive the raw information of application status characterizations (B) as well as this processed directive. The communication of the content of these and other fields of health and load tables  is accomplished using a message protocol that is described below with reference to .",{"@attributes":{"id":"p-0169","num":"0177"},"figref":["FIG. 15","FIG. 12"],"b":["1500","108","106","1204","108","106","108","106","1204","1204","1202"]},"Message protocol  may be implemented using any available message transport mechanism. Such mechanisms include reliable multicast transmission, point-to-point transmission (e.g., user datagram protocol (UDP)), and so forth. As illustrated, message protocol  includes seven message types -: a heartbeat message , a goodbye message , a row change message , a get table snapshot message , a send table snapshot message , a postulate table state message , and a postulate wrong message .","It should be understood that, with the exception of arrows  and , no temporal relationship between or among the different messages types - is implied by the illustration. For example, a row change message  does not typically follow a goodbye message .","Heartbeat message  indicates that a particular host  is functioning and provides some error checking for the content of a corresponding particular health and load table  with respect to a corresponding particular cache for the particular host  in consolidated health and load cache . Each health and load infrastructure  at each host  sends a heartbeat message directly or indirectly to each consolidated health and load cache  at each load balancing unit .","Heartbeat messages  address the aging-out problem for data in consolidated health and load caches  that arises, in part, because a snapshot of the entirety of each health and load table  is not periodically transmitted to each load balancing unit . A transmission scheme for heartbeat messages  is described further below with reference to .","Heartbeat messages  include an identifier for the host, error checking data, and optionally a DNS name. The identifier of the host may be a unique (e.g., 32-bit) number that is selected at configuration time. The error checking data may be a checksum, a state-change sequence number, a generation number, a CRC value, etc. that enables a receiving load balancing unit  to validate that the contents of its consolidated health and load cache  comports with the contents of the health and load table  of the transmitting host . If a generation number approach is employed, then multiple generation IDs can be used with each generation ID assigned to a \u201cchunk\u201d of applications. Messages can then refer to a chunk number or a chunk number\/generation ID pair, depending on the context.","The error checking data (or, more generally, a content indicator) may be a single value for the health and load table  overall, or it may be multiple values determined on a per-entry  basis. The DNS name may optionally be sent (e.g., every \u201cx\u201d heartbeats) to verify or update the current correct network address for the host.","Goodbye message  is sent from a particular host  to load balancing units  to indicate that the particular host  is planning to shutdown. Goodbye message  includes a host identifier that may be indexed\/mapped to a network address for the particular host . Goodbye message  is used for clean, intentional shutdowns by hosts  to precipitate a \u201cfast clear\u201d. However, if a goodbye message  is lost, caches eventually age out the particular host's  entries because heartbeat messages  are no longer sent.","Row change message  is sent from a particular host  to load balancing units  to indicate that the health and\/or load for a given application  of the particular host  has changed. Row change message  includes a host identifier, an application identifier, an operation, and data for the operation. Exemplary host identifiers are described above with regard to heartbeat messages  and goodbye messages . Exemplary application identifiers are described above with regard to application identifier (A) of an application-associated entry  of health and load tables .","The row change operation may be add, delete, or update. In other words, the data for the operation may be added to (for an add operation) or a replacement for (for an update operation) information already present at consolidated health and load caches  at load balancing units . For a delete operation, no data need be provided. Message protocol  is defined such that multiple operations may be stipulated to be performed for a single row change message . Hence for a particular host identifier, sets of an application identifier, operation, and operation data may be repeated for multiple applications  of the host  that is identified by the particular host identifier.","Get table snapshot message  is sent from a particular load balancing unit  for a particular consolidated health and load cache  to an individual host  or hosts . This get table snapshot message  requests that health and load infrastructure  at hosts  provide a snapshot of the respective health and load table  for the respective host . This message includes an identification of the requesting load balancing unit  and may be used by a load balancing unit  (i) after it has failed and then recovered; (ii) after a host  fails, recovers, and begins sending heartbeat messages  again; (iii) if a row change message  is sent to load balancing unit , but the message gets dropped, so its consolidated health and load cache  is out of sync with the respective health and load table  for the respective host ; and (iv) so forth.","For the third (iii) situation, the lack of synchronization between consolidated health and load cache  and the respective health and load table  for the respective host  is discovered by a subsequent heartbeat message  from the respective host  because the \u201cerror checking\u201d will indicate that consolidated health and load cache  is out of date. Load balancing unit  can then send a get table snapshot message  so that it can update its consolidated health and load cache . Thus, for any of the three (i, ii, iii) exemplary situations, load balancing unit  subsequently reconstitutes its consolidated health and load cache  using get table snapshot . Get table snapshot  may be sent repeatedly to each host  in a point-to-point manner or may be sent one time to many hosts  in a multicast manner.","Send table snapshot message  is sent from an individual host  to a particular load balancing unit  after the individual host  has received a get table snapshot message  from the particular load balancing unit  as indicated by arrow . The contents of a send table snapshot message  is prepared by health and load infrastructure  and may include all or at least multiple rows of the health and load table  of the individual host  so that the particular load balancing unit  may rebuild its consolidated health and load cache . Send table snapshot message  may be a separately designed message, or it may be equivalent to a sequence of add operations in a row change message .","Postulate table state message  and postulate wrong message  are related to the target load balancing state and the current load balancing state of load balancer directive (C) of an entry  in a health and load table . The target load balancing state is the directive that health and load infrastructure  desires load balancing units  to be operating under. The current load balancing state is the directive that health and load infrastructure  expects or believes that load balancing units  are currently operating under. Generally, the two load balancing states are identical.","However, the target load balancing state may differ from the current load balancing state during a transitional period for a state directive change. For example, the target load balancing state and the current load balancing state are both initially set to active. A problem with host  and\/or an application  thereof is detected and the target load balancing state directive is switched to draining. This draining directive is communicated to load balancing units  using a row change message .","There is a delay before this directive change is noted in all consolidated health and load caches  of all load balancing units . During this transitional period, the target load balancing state is draining while the current load balancing state is still active at health and load table  of host . Before changing the current load balancing state to draining, health and load infrastructure  wants to ensure that consolidated health and load caches  have actually been updated to the new directive state of draining.","To verify that consolidated health and load caches  of load balancing units  have been updated to a new state directive, health and load infrastructure  sends a postulate table state message  to load balancing units . Postulate table state message  is sent some time (e.g., a predetermined delay period) after transmission of a row change message  indicating that the state directive is to be changed. The postulate table state message , in this example, indicates that the table state should be draining. As indicated by the dashed arrow , a load balancing unit  responds to this postulate table state message  if its consolidated health and load cache  differs from the postulated state directive.","If the directive in consolidated health and load cache  does differ from the postulated state directive, then that load balancing unit  sends a postulate wrong message  to the health and load infrastructure  of the host  that issued the postulate table state message . This health and load infrastructure  then periodically resends postulate table state message  until no further postulate wrong messages  are received from consolidated health and load caches . At that point, health and load infrastructure  sends a row change message  with the new current load balancing state. In this sense, consolidated health and load caches  are the definitive determiners of the current load balancing state, and health and load infrastructure  is the definitive determiner of the target load balancing state.",{"@attributes":{"id":"p-0187","num":"0195"},"figref":["FIG. 16","FIG. 12","FIG. 16"],"b":["108","106","1502","1210","1502","1500"]},"A group of hosts (), (), () . . . (), and () are illustrated along with load balancing units (), () . . . (). Each line represents membership linkage or inclusion among the group of hosts (,  . . . ). The group of hosts (,  . . . ) form a membership of nodes that work together to propagate heartbeat information to load balancing units . Although twelve hosts are shown, more or fewer may be part of any given group of hosts. Also, a total set of hosts  that are being served by a load balancing infrastructure  may be divided into one, two, three, or more groups of hosts.","In a described implementation, the membership of nodes for group of hosts (,  . . . ) elect a leader that is responsible for transmitting heartbeat messages  to load balancing units . Each (non-leading) host  in group of hosts (,  . . . ) sends its heartbeat messages  to the elected leader. Host () is the elected leader in this example.","With the membership of nodes, heartbeat information for each host  in group of hosts (,  . . . ) propagates to the group leader host (). Host () collects the heartbeat information and consolidates it into a consolidated heartbeat message . Consolidated heartbeat messages (), () . . . () are then sent to respective load balancing units (), () . . . (). These consolidated heartbeat messages  may optionally be compressed to further reduce bandwidth consumption.","As another alternative, the leader host () may only forward changes in group membership to consolidated health and load caches . In other words, in this mode, consolidated health and load caches  deal primarily if not solely with state changes to membership. It is the responsibility of the leader host () to ensure that the first hello is forwarded when a host  comes online and that a goodbye message  gets sent when that host  goes offline. Additionally, a host  can periodically specify that a heartbeat message  is to be \u201cforwarded\u201d. This indicates to the leader host () to send it to consolidated health and load caches  even though it does not represent a membership change.","Heartbeat messages  (including consolidated heartbeat messages ) are used by load balancing units  when their consolidated health and load caches  are unsynchronized with health and load tables . This lack of synchronization may arise, for example, from a crash or other failure of consolidated health and load cache  and\/or of load balancing unit . As described above, each heartbeat message  includes error checking data that is usable to verify equivalency between a consolidated health and load cache  and health and load tables . If non-equivalency is discovered with regard to a particular host  and\/or an application  thereof, the DNS name of the particular host  is acquired from the heartbeat messages .","The DNS name is used by consolidated health and load cache  to send a get table snapshot message  to the particular host  in order to get updated health and load information  in the form of a send table snapshot message . A different or the same get table snapshot message  is sent to each host  for which non-equivalency is discovered. Eventually, the health and load information  in the consolidated health and load cache  is equivalent to the health and load information  in health and load tables  as verifiable by new heartbeat messages . In this manner, a failed consolidated health and load cache  can be bootstrapped back into operation without manual oversight using message protocol  and an equivalency-checking scheme.",{"@attributes":{"id":"p-0194","num":"0202"},"figref":["FIG. 17A","FIG. 17B","FIGS. 12-16"],"b":["1204","1208","108","1202","1202"]},"For example, a host may be running a version of application(s) and\/or an operating system for which health and load infrastructure is either not implemented or for policy reasons may not be installed on the host. Consequently, these types of hosts do not have health and load infrastructure  executing thereon. Host  is such a host that does not execute health and load infrastructure . Nevertheless, host  can utilize a health and load infrastructure  that is executing on one or more proxies, such as proxy .","Proxy  has resident thereat and executing thereon a health and load infrastructure , which includes a health and load table . Host  can use the functionality of health and load infrastructure  by providing health and load information  to health and load table  for applications that are running on host . Alternatively, proxy  can deduce health and load on host  by performing external monitoring actions. Proxy  is illustrated as proxy () and () for redundancy and the resulting high availability.","In implementations described above with reference to  and below with reference to , load balancing is effectuated with load balancing units  that include consolidated health and load caches . However, other implementations may entail load balancing that does not include consolidated health and load caches .","For example, load balancing may be effectuated by monolithic load balancing hardware or other load balancing infrastructure that does not and\/or cannot store or otherwise include a consolidated health and load cache . Load balancer  reflects such a load balancing device or devices that do not have a consolidated health and load cache . Nevertheless, load balancer  can utilize a consolidated health and load cache  that exists on one or more proxies, such as proxy .","Proxy  includes a consolidated health and load cache , which stores health and load information  for hosted applications being serviced by load balancer . Load balancer  can use the health and load information  of consolidated health and load cache  when performing load balancing functions by accessing such information using application programming interfaces (APIs) native to and supported by load balancer . Alternatively, consolidated health and load cache  can invoke APIs to push health and load information , including directives, to load balancer . Proxy  is illustrated as proxy () and () for redundancy and the resulting high availability.",{"@attributes":{"id":"p-0200","num":"0208"},"figref":"FIG. 18","b":["304","314","106","314","1208","1206"]},"As described above with reference to , consolidated health and load cache  includes cached health and load information  for multiple hosts . To facilitate the creation and updating of consolidated health and load cache  from health and load information  that originates from multiple hosts , the health and load information  therein is organized so that it may be accessed by identifier of each host . However, the health and load information  therein is also organized such that it can be accessed by type of application  in order to facilitate application endpoint selection.","In other words, health and load handler  is capable of accessing health and load information  on a per-application  basis across health and load information  for multiple hosts . Once health and load information  for a given application  has been accessed for each host , allocation of incoming connection requests may be performed in accordance with such health and load information . For example, possible endpoints for the given application  may be allocated to incoming connection requests by selection of the endpoints of the given application  with consideration of available relative load capacity among healthy endpoints for the given application .","In a described implementation, classifier  makes a target application endpoint allotment request  to health and load handler . As illustrated, target application endpoint allotment request  includes (i) a virtual IP address and port, (ii) a protocol, and (iii) protocol-specification information. Target application endpoint allotment request  therefore identifies a type of application  to which incoming connection requests are directed.","Health and load handler  receives target application endpoint allotment request  and selects at least one physical endpoint corresponding to the identified type of application  using any one or more of many selection mechanisms. To reduce latency, health and load handler  selects an allotment of application endpoints to be used over a number of incoming connection requests. This allotment is provided from health and load handler  to classifier  using target application endpoint allotment response . As illustrated, target application endpoint allotment response  includes an allotment of physical IP addresses and ports (such as endpoints IP, IP, and IP) for the identified type of application .","The allotment for target application endpoint allotment response  may be completed using one or more allotment schemes. By way of example, a token allotment scheme  and a percentage allotment scheme  are illustrated. Token allotment scheme  is a unit-based allotment scheme, and percentage allotment scheme  is a time-based allotment scheme.","Token allotment scheme  allocates tokens for each healthy endpoint IP, IP, and IP responsive to their relative load and capacity ratios. For the example as illustrated, of the total available capacity, IP has 40% of the available capacity, IP has 35% of the available capacity, and IP has 25% of the available capacity. Thus, the total number of tokens is divided along these percentages. The total number of tokens may be provided as part of target application endpoint allotment request  or determined by health and load handler .","Any value for the total number of tokens may be used, such as 10, 45, 100, 250, 637, 1000, and so forth. This value may be set in dependence on the number of connection requests per second and the speed\/frequency at which application health and\/or load is changing. Classifier  \u201cuses up\u201d\/consumes one token when responding to each connection request with an application endpoint allocation until the tokens are exhausted; classifier  then requests another token allotment using target application endpoint allotment request .","Percentage allotment scheme  determines available relative capacity in a similar manner. However, instead of tokens, these determined available relative capacities per application endpoint are provided to classifier  along with a duration timer . Classifier  allocates target application endpoints to incoming connection requests in accordance with these available relative capacity percentages until expiration of duration timer .","For percentage allotment scheme , classifier  maintains a running record of application endpoint allocations to adhere to the allotted percentages and keeps track of time for duration timer . When the timer expires, classifier  then requests another percentage allotment using target application endpoint allotment request .","It should be noted that token allotment scheme  can also use a time limit. If allotted tokens are too old, they should be discarded and new ones acquired. Otherwise, classifier  may consume stale tokens that were previously allocated based on health and load information that is currently too outdated. Use of application endpoint allotments by classifier  is described further below in the section entitled \u201cExemplary Classifying, Forwarding, and Request Routing\u201d.","This section describes how host status information, such as session information, may be collected for and utilized in network load balancing. This section primarily references  and illuminates session affinity preservation functionality such as that provided by session tracker  (of ). As described above with reference to , each host  hosts one or more applications  that provide service(s) to clients . Session tracker  utilizes session information that relates to contexts for the connections established between applications  and clients  for certain described implementations of network load balancing.",{"@attributes":{"id":"p-0212","num":"0220"},"figref":["FIG. 19","FIG. 19"],"b":["1902","1","102","1","108","2","106","106","106","106","108","108","316"]},"When connection [] is made, a session is established between client () and the servicing application , which is on host () in this example. The session provides a context for the communication exchange between client () and host (). The information for the session context is stored at host (). When connection [] is completed, the session context may not be used again. On the other hand, the session context may be useful again if client () attempts to initiate another connection with hosts  for the service provided by application . If this other connection is not routed to the same host () that stores that session context, then client () has to establish a new session context, which can be time consuming, data\/processing intensive, and\/or frustrating to the human user of client (). With health and\/or load information-based network load balancing, there is no likelihood greater than random chance that the second connection will be routed to ().","However, if load balancing infrastructure  has access to a mapping between session information and hosts , load balancing infrastructure  can route connection requests that relate to previously established sessions to the appropriate host . Some session information may be inferred from the contents of packets flowing through load balancing infrastructure . However, this approach is imprecise and haphazard for a number of reasons. First, session establishment and termination is merely inferred. Second, some sessions are not \u201cofficially\u201d terminated with an appropriate indication that is included in a packet. For example, some sessions simply time out. Third, packets being transmitted from host () to client () may take a path that does not include load balancing infrastructure , which precludes any snooping of such packets by load balancing infrastructure  for session information.","As shown in , hosts  provide session information (SI)  to load balancing infrastructure . Using session information  from hosts , a session affinity preserver  can preserve the affinity between an established session and the host  on which the session was established. Session information  includes a linkage between or a mapping from each session established between a client  and a particular host  to that particular host . This mapping is accessible to session affinity preserver  as part of host-session information mapping . More-specific examples of session information  are provided below especially with reference to , , A, and B.","In certain described implementations for session tracking, the logical nature of clients  is pertinent. As noted above with reference to , a client  may be a specific device and\/or a specific user of a device. Consequently, session affinity for a user client  that is accessing hosts  from different devices can still be preserved. Session continuations using session information  can therefore still be effectuated in proxy scenarios (e.g., those of some internet service providers (ISPs)).","Continuing with the connection [] example, the session established at host () is provided to load balancing infrastructure  as session information . Specifically, a linkage\/mapping between (i) the session context of client () and host () and (ii) an identifier for host () is created at host-session information mapping . When a connection request for connection [] subsequently arrives for the same session context, session affinity preserver  locates this session context in host-session information mapping  and ascertains that host () is associated with this session context from the linkage\/mapping.","Responsive to the mapping of host () to the requested session context as ascertained by session affinity preserver  from host-session information mapping , connection [] is routed to host (). In this sense, preserving session affinity is a higher priority for load balancing infrastructure  than application health and load-based network load balancing decisions. However, health and\/or load may be a more important network load balancing factor than session tracking when, for example, loading is extremely heavy or when the session-relevant application and\/or host is in a failed condition.","Many types of connections may be session-related. Examples include: a TCP connection, a transport layer security (TLS)\/SSL session, a PPTP session, an IPSec\/L2TP session, an ISA session, an HTTP cookie-based session, a Terminal Server session, an administrator-defined session, and so forth. By way of clarification, a TCP connection is considered to be a session of TCP packets. Also, a model for defining sessions by an administrator may be enumerated and supported. Furthermore, client IP-address-based sessions that are delineated by timeouts may also be supported. This is relatively non-intelligent session support, but is expected by some users.","A connection request from a client  varies by the type of desired session. For example, for sessions of type \u201cTCP connection\u201d, the connection request comprises a TCP packet. For sessions of type \u201cSSL session\u201d, the connection request comprises a TCP connection. Other such connection requests correspond to other session types. These examples also show how there may be session layers. At a lower session level, a session context for a TCP connection may include a TCP 4-tuple, a session number, the number of bytes sent\/received, and so forth. At a higher session level, a session context for an SSL session may include a 32-byte session ID, a public key of the client  that is provided to the host , and so forth.",{"@attributes":{"id":"p-0221","num":"0229"},"figref":"FIG. 20","b":["2006","2008","106","1","106","2","106","108","1","108","2","108","108","1","108","2","108","316","1","316","2","316","2006","316","2008","108","106"],"i":["u","n","n","n"]},"As illustrated, each respective host (), () . . . () includes respective session tracking infrastructure (STI) (), () . . . (). Each respective session tracking infrastructure (), () . . . () includes a respective session table (), () . . . () (although only session table () is explicitly illustrated in ).","Each respective load balancing unit (), () . . . () includes respective traffic routing functionality (TRF) (), () . . . (). Traffic routing functionality  may comprise, for example, classifying and\/or requesting routing functionality, such as that provided by classifier  and request router , respectively. Distributed across load balancing units (), () . . . () is a distributed session tracking manager .","In a described implementation, traffic routing functionality  and distributed session tracking manager  are part of load balancing infrastructure . Session tracking infrastructure  may also be (e.g., a remote) part of load balancing infrastructure .","An API  is employed to provide session information from applications  to session tracking infrastructure . Using API , applications  are empowered to notify session tracking infrastructure  of session information, including various changes thereto. More specifically, each application  is capable of providing, and session tracking infrastructure  is capable of accepting, notifications .","A notification that a session has been established (or session establishment notification (E)) is provided from application  when a session is newly established or opened. Session establishment notification (E) includes a session identifier and optionally an identifier of application . A notification that a session has been terminated (or session termination notification (T)) is provided from application  when a session is terminated or closed. Session termination notification (T) also includes the session identifier and optionally the identifier of application .","When session tracking infrastructure  accepts a session establishment notification (E), it inserts an entry in session table  for the new session. An exemplary session table  is described further below with reference to . When session tracking infrastructure  accepts a session termination notification (T), it removes the entry in session table  for the old session.","Session table () is the authoritative source for session information  with respect to applications () on host (). There is generally too much latency, however, to require traffic routing functionality  to contact hosts  for access to session tables  upon receipt of each incoming connection request having a session reference. Session information  is therefore cached at load balancing units .","At load balancing units , distributed session tracking manager  caches session information  as part of its session tracking management responsibilities. Generally, distributed session tracking manager  is a distributed application and\/or virtual service that resides partially on each load balancing unit . For each logical session, distributed session tracking manager  keeps at least one cached copy of session information therefor in a reliable and scalable manner that may be quickly utilized for routing traffic as incoming connection requests that have a session reference are received by load balancing infrastructure .","Communications between hosts  and load balancing units  are effectuated with a reliable protocol that ensures that messages  sent from a host  arrive at the intended load balancing unit . Each host  is bound to at least one specific load balancing unit  that is the intended load balancing unit  for messages . This binding is created by assigning an IP address of a specific load balancing unit  to each host  for sending session-tracking messages  between session tracking infrastructure  and distributed session tracking manager . To facilitate high availability of load balancing infrastructure , if a load balancing unit  fails, another load balancing unit  assumes the IP address of the failed load balancing unit . Failure detection for IP address assumption may be accomplished using a heartbeat or another aliveness monitoring scheme.","Thus, messages  communicate session information  from session tracking infrastructure  to distributed session tracking manager . For example, when session tracking infrastructure  accepts a session establishment notification (E), it also sends a session up message (U) to distributed session tracking manager . Session up message (U) includes the session identifier, a host identifier, and optionally other information. Contents for a session up message (U) are described further below with reference to  with respect to information that may be stored for each session by an implementation of distributed session tracking manager . When session tracking infrastructure  accepts a session termination notification (T), it also sends a session down message (D) to distributed session tracking manager . Messages  can be sent before, during, or after session tracking infrastructure  appropriately modifies session table  in response to notifications .",{"@attributes":{"id":"p-0232","num":"0240"},"figref":["FIG. 21","FIGS. 1-3"],"b":["2100","2100","2102","2130","2100","19","20"]},"For example, the actions of four blocks - and - are performed by an application , the actions of six blocks - and - are performed by session tracking infrastructure , and the actions of five blocks - and - are performed by a distributed session tracking manager . The actions of eight of these blocks - are primarily directed to opening a session, and the actions of seven of these blocks - are primarily directed to closing a session.","At block , a session is opened. For example, application  may open a session with a client . At block , a session establishment notification is provided. For example, application  may provide a session establishment notification (E) to session tracking infrastructure  using API  as a consequence of and\/or in conjunction with opening the session.","At block , the session establishment notification is accepted. For example, session tracking infrastructure  may accept session establishment notification (E) from application  in accordance with API . At block , an entry in a session table is inserted. For example, session tracking infrastructure  may insert an entry in session table  for the opened session. Examples of such insertion are described further below especially with reference to . At block , a session up message is sent. For example, session tracking infrastructure  may send a session up message (U) to distributed session tracking manager  using a reliable communication protocol.","At block , the session up message is received. For example, distributed session tracking manager  may receive session up message (U) from session tracking infrastructure  in accordance with the reliable communication protocol. At block , a session information entry is created. For example, distributed session tracking manager  may create a session information entry for cached session information  at one or more load balancing units . Examples of such creating and subsequent adding are described further below especially with reference to .","At block , network traffic is routed with the session information. For example, traffic routing functionality  in conjunction with distributed session tracking manager  may use cached session information , including the created session information entry, to route incoming connection requests that have a session reference. An example of such traffic routing is described further below especially with reference to . Additional examples are described below in the section entitled \u201cExemplary Classifying, Forwarding, and Request Routing\u201d.","At block , the session is closed. For example, application  may close the session with client . At block , a session termination notification is provided. For example, application  may provide a session termination notification (T) to session tracking infrastructure  using API  as a consequence of and\/or in conjunction with closing the session.","At block , the session termination notification is accepted. For example, session tracking infrastructure  may accept session termination notification (T) from application  in accordance with API . At block , the entry in the session table is removed. For example, session tracking infrastructure  may remove the entry in session table  for the closed session. At block , a session down message is sent. For example, session tracking infrastructure  may send a session down message (D) to distributed session tracking manager  using the reliable communication protocol.","At block , the session down message is received. For example, distributed session tracking manager  may receive session down message (D) from session tracking infrastructure  in accordance with the reliable communication protocol. At block , the session information entry is destroyed. For example, distributed session tracking manager  may destroy the session information entry at the cached session information  at any load balancing units  that have the session information entry. Examples of such destroying and subsequent deleting are described further below especially with reference to .",{"@attributes":{"id":"p-0241","num":"0249"},"figref":"FIG. 22","b":["106","106","1","106","2","106","2202","1","2202","2","2202","2202","2202","2010","2202","1","2202","2","2202","2206","1","2206","2","2206","2206"],"i":["u","u","u","u"]},"DAM  is a distributed application or virtual service that manages session information  in a reliable and scalable manner so that traffic routing functionality  can use it to preserve session affinity. For example, traffic routing functionality  can access DAM  using an API (not specifically shown) to search or have searched DAMT . Function calls , operation of DAM , and other aspects of  are described further below after the description of .",{"@attributes":{"id":"p-0243","num":"0251"},"figref":["FIG. 23A","FIG. 20"],"b":["2014","2014","2302","1","2302","2","2302","2302","2002","2006","316","2302","2002","2006","316"],"i":"v"},"As described above, each session establishment notification (E) includes a session identifier and optionally an identifier of application . Each respective entry (), () . . . () in session table  includes respective fields of (i) session identifier (I), (I) . . . (I) and (ii) session type and\/or application (T), (T) . . . (T).","Session type and\/or application (T) may be \u201cTCP\u201d, \u201cIPSEC\u201d, \u201cTerminal Server,\u201d \u201cHTTP-cookie\u201d, an application type as noted above, and so forth. Session identifier (I) may be \u201c<source IP address, source TCP port, destination IP address, destination TCP port>\u201d, \u201cClient IP=172.30.189.122\u201d, \u201cUser=\u2018joe_user\u2019\u201d, \u201cCookie=\u2018{b7595cc9-e68b-4eb0-9bf1-bb717b31d447}\u2019\u201d, another e.g. application-specific identification for a session, and so forth. For TCP connection\/session types, session identifier (I) may alternatively be a canonical version of the TCP 4-tuple (for IPv4 or IPv6). Other values for the fields of session identifier (I) and application\/session type (T) may alternatively be used.",{"@attributes":{"id":"p-0246","num":"0254"},"figref":["FIG. 23B","FIG. 22"],"b":["2206","2206","2304","1","2304","2","2304","2304","2202","2008","2002","2304","2008","2002","2304","2206","2202","2204"],"i":"w"},"As described above, session up message (U) includes the session identifier, a host identifier, and optionally other information. Each respective session information entry (), () . . . () in DAM table  includes respective fields of (i) key (K), (K) . . . (K), (ii) data (D), (D) . . . (D), and (iii) metadata (M), (M) . . . (M). For example, values for key (K) fields may be alphanumeric strings, and values for data (D) fields may be binary bits. Values for key (K) may be binary bits, too.","Key (K) may correspond to the session identifier (I). Data (D) may correspond to the host identifier, such as a network address of the host  on which the session context exists. Metadata (M) may correspond to other, optional information. Examples of such metadata (M) include data that is used internally by DAM  to resolve atom collisions and to track atom aliveness (e.g., via a time-out mechanism). (This characterization of entries  as being atomic is described more fully in the following paragraph.) More specifically, metadata (M) includes, among other things, the identity of the entity (e.g., the instance of traffic routing functionality ) that added the session information entry  to the DAM table .","In a described implementation, each session information entry  is atomic in the sense that DAM  may add, delete, copy, etc. the entries  as a whole, but DAM  does not ordinarily modify a portion of any whole entry . Thus, atomic entries  are added, deleted, copied, otherwise manipulated, etc. across DAM tables  by DAM  in order to implement availability and scalability for a session affinity preservation implementation.","Function calls  (of ) are usable by DAM  to manipulate the atomic entries  of DAM table . Function calls  may be communicated from one load balancing unit  to one or more other load balancing units  in a point-to-point or a multicast manner. These function calls include add atom (A), delete atom (D), query atom (Q), and return atom (R).","Add atom (A) takes the form AddAtom(key, data) and is used to add an atomic entry  to one or more DAM tables . Hence, an add atom (A) function call may be formulated as AddAtom(<session identifier>, host IP address). Delete atom (D) takes the form DeleteAtom(key) and is used to delete an atomic entry  at one or more DAM tables . Delete atom (D) function calls may be directed at those DAM tables  known to have a copy of the session that is identified by the key (K) or may be multicast to all DAM tables  to ensure that any copies are deleted.","Query atom (Q) takes the form QueryAtom(key) and is used by a particular DAM portion  when a session identifier as referenced by an incoming connection request is not located in the particular local DAM table  of the particular DAM portion . Query atom (Q) function calls are sent to one or more (including possibly all) other DAM portions . In response, each other DAM portion  checks its local DAM table  for the key\/session identifier. If the key is located by another DAM portion , this other DAM portion  replies with a return atom (R).","Return atom (R) takes the form ReturnAtom(key, data) and is used to reply to a query atom (Q) function call. Return atom (R) function calls are used when a DAM portion  has a requested atomic entry  in its local DAM table  as identified by a key (K) specified in the query atom (Q) function call. Return atom (R) function calls may be directed back to the DAM portion  that issued the query atom (Q) function call.","Add atom (A) function calls are used in response to session up messages (U) and\/or to replicate an atomic entry  to one or more other DAM tables . Such replication may be for redundancy and\/or scalability.","Delete atom (D) function calls are used in response to session down messages (D) and may also be sent to one or more other DAM tables . After an atomic entry  is deleted, the atomic entry  may enter a \u201czombie\u201d state such that it remains with DAM , and optionally so that it is actually still stored with DAM table  with a zombie indication in the metadata (M) field of the atomic entry .","Thus, once an atomic entry  is deleted, it may stay on in DAM  and DAM table  in a zombie state so that packets for this (now dead and closed) session are directed to the host  of the session context for proper, protocol-specific treatment. For example, TCP packets received after a TCP connection has been torn down are directed to the host  that terminated the connection. This host  can respond appropriately\u2014perhaps by sending an RST or by resending a FIN-ACK. The time the atomic entry  spends in this zombie state matches (as closely as reasonably possible) the protocol-specific dead time of the reliable communication protocol that is employed.","A query atom (Q) function call is used to attain an atomic entry  when a first load balancing unit  receives an incoming connection request that references a session that is not stored in the local DAM table  of the DAM  of the first load balancing unit . It should be noted that other DAM portions  may be queried simultaneously in a broadcast query atom (Q) function call or sequentially until a positive return atom (R) function call is received.","A return atom (R) function call is used by a DAM portion  of a second load balancing unit  to provide an atomic entry  to the DAM portion  of the first load balancing unit , where the atomic entry  has a key (K) that is specified by the key\/session identifier in a query atom (Q) function call, which was previously issued by the DAM portion  of the first load balancing unit . It should be noted that other components, such as traffic routing functionality , may also be capable of calling functions , especially a query atom (Q) function call, in accordance with an API or similar.","DAM portions  and DAM tables  may be organized and managed in a myriad of manners. Exemplary manners relate to replication\/redundancy, local caching upon acquisition, hashing for location selection, and so forth. Zero, one, two, or more levels of replication up to full replication may be employed. With a zero level of replication, each atomic entry  is stored at the DAM  that receives a session up message (U) therefor without replication to other DAM portions .","With a first level of replication, each atomic entry  is stored at the DAM  that receives a session up message (U) therefor, and it is also added (copied) to one other DAM portion  using an add atom (A) function call. This handles one level of failure for a load balancing unit . Similarly, with a second level of replication, each atomic entry  is stored at the DAM  that receives a session up message (U) therefor, and it is also added to two other DAM portions . Generally, the one, two, etc. other DAM portions  to which a given DAM portion  copies atomic entries  is predetermined or selected at random. Third, fourth, etc. levels of replication may also be employed.","Furthermore, full replication may be employed by having each atomic entry  that is stored at the DAM  that receives a session up message (U) therefor also being added to every other DAM portion . Several factors are impacted by selection of the replication level: As the replication level increases, availability increases and latency decreases. On the other hand, network traffic and memory usage both increase as the replication level increases.","When full replication is not employed, local caching upon acquisition may be. For example, when a DAM portion  does not locate a referenced session identifier in its part of DAM table , the DAM portion  issues a query atom (Q) function call to attain the atomic entry  associated with the referenced session identifier via a return atom (R) function call. Instead of jettisoning the attained atomic entry  after use thereof, the DAM portion  caches the attained atomic entry  in its part of DAM table . This option offers a tradeoff between the above-enumerated factors.","As another option when full replication is not employed, hashing for location selection may be. The first atomic entry  for a session is stored at the DAM portion  that receives the session up message (U). Replicated copy or copies are sent via add atom (A) function calls to specific DAM portion(s)  using a hashing function. Of a total range of possible hash values, each DAM portion  is assigned a subset thereof. Each session identifier is hashed using some hashing function to arrive at a hashing value. This hashing value is mapped to the assigned DAM portion(s) . The DAM portion  that first added the atomic entry  then replicates the atomic entry  to the assigned DAM portion(s) .","With hashing for location selection, at least one DAM portion  that has a desired atomic entry  locally cached at its DAM table  is knowable from the session identifier. A query atom (Q) function call can therefore be directed to the known DAM portion(s) . This usually reduces network traffic and\/or latency.","This hashing for location selection may be used with one, two, three, or more levels of replication with each range of hashing values mapping to one, two, three, etc. different DAM portions , respectively. Additionally, hashing for location selection may be used with local caching upon acquisition.",{"@attributes":{"id":"p-0266","num":"0274"},"figref":["FIG. 24","FIGS. 1-3"],"b":["2400","2400","2402","2416","2400","19","20","22","23"]},"At block , an incoming connection request with a session reference is analyzed. For example, traffic routing functionality  may receive an incoming connection request that references a previously-opened\/established session of a particular type. At block , a local DAM table is searched using the session reference. For example, for a given load balancing unit  and traffic routing functionality , the DAM portion  thereof may search its corresponding DAM table  looking for the session reference.","At block , it is determined if the session reference matches a key of the local DAM table. For example, DAM portion  may search key fields (K) of multiple entries  of DAM table  to determine whether the session reference matches any values of the key fields (K). If so, flow diagram  continues at block .","If, on the other hand, the session reference does not match any key, flow diagram  continues at block . At block , a query atom function call is made. For example, DAM portion  may make a query atom (Q) function call that includes the session reference\/identifier as the key. The query atom (Q) function call may be sent to at least one other DAM portion . The number, selection, order, etc. of possible destination DAM portions  for query atom (Q) may depend on the options (e.g., replication level, hashing for location selection, local caching upon acquisition, point-to-point versus multicast, etc.) employed by DAM .","At block , a returned atom is received. For example, information from a returned atom (R) function call that is issued by another DAM portion  may be received. The other DAM portion  successfully located an atomic entry  in its corresponding DAM table , with the located atomic entry  having a key that matches the session reference. The information from the returned atom (R) function call includes values from key field (K) and data field (D) for the located atomic entry . These values correspond to the session identifier of the session and the network address of the host  that is affinitized to the session.","At block , an atomic entry is extracted. The atomic entry is extracted from the local DAM table if a match was found locally (at blocks  and ) or from the returned atom if a match was found elsewhere (at blocks  and ). For example, an atomic entry  may be extracted from DAM table  of the DAM portion  or from information received by a return atom (R) function call. The extracted atomic entry  may be cached at the local DAM table  if received as a result of the return atom (R) function call.","At block , the host having session affinity with the referenced session is ascertained from the atomic entry. For example, a value of the data field (D) of the extracted atomic entry  may be ascertained to thereby ascertain a network address of the affinitized host . At block , the incoming connection request is routed to the ascertained host. For example, traffic routing functionality  and\/or forwarding functionality may route the incoming connection request having the session reference to the ascertained and affinitized host . Exemplary classifying, request routing, and forwarding functionalities are described in the following section.","This section describes how traffic routing may be implemented for network load balancing, including with regard to high availability of such traffic routing functionality. Traffic routing functionality may include classifying and\/or requesting routing functionality, especially in conjunction with forwarding functionality. This section primarily references . It illuminates the functionality of a request router  (of ), an interrelationship between tracking sessions and utilizing health and load information when routing traffic, operational implementations for traffic routing interactions with session information and\/or health and load information, failover procedures for high availability of network load balancing infrastructure (including handling failures of classifying, forwarding, and\/or request routing components), additional network load balancing infrastructure configurations, and so forth.",{"@attributes":{"id":"p-0274","num":"0282"},"figref":["FIG. 25","FIG. 4","FIG. 25"],"b":["306","2012"]},"Request-level routing occurs at a higher level than that of packet-level routing. Generally, a request router  acts as a proxy for an application  running on a host . Request router  terminates TCP connections, parses (perhaps partially) each request from a client , and resubmits each request to host . Request router  may perform pre-processing on the connection, such as SSL decryption. Also, request router  may chose to absorb certain requests (e.g., the request router may maintain a cache of responses), and it may \u201carbitrarily\u201d modify requests before forwarding them to hosts .","Request routers  are usually application-specific, and they may be rather open-ended in what they are capable of doing. By way of example only, a single class of request routers \u2014HTTP\/SSL request routers (H\/S)\u2014are addressed in the following description. As illustrated, a client  having a network address C is communicating across network  with hosts () and () having network addresses H and H, respectively. The communications are effectuated via load balancing infrastructure that includes an HTTP\/SSL request router (H\/S).","HTTP\/SSL request router (H\/S) terminates HTTP and SSL traffic, decrypts SSL traffic, examines each HTTP request from client , applies application-specific rules to classify each request and to determine the \u201cbest\u201d endpoint for that request while taking into account application endpoint health and load information, and submits the request to the endpoint. The request submission to the endpoint uses a separate TCP connection than that of the one originated by client  (the latter connection is terminated at HTTP\/SSL request router (H\/S)). These actions may be considered as logically equivalent to the actions performed by a classifier , but a difference arises in that these actions in HTTP\/SSL request router (H\/S) are occurring at the logical request level for each request within the TCP connection. HTTP\/SSL request router (H\/S), and request routers  generally, can use the same (i) application health and load and (ii) session tracking infrastructure that is used by classifiers .","HTTP\/SSL request router (H\/S) is acting as an intermediary between client  and two hosts () and (). It is handling two requests from client  over a single TCP connection. In a described implementation, the resulting request routing involves a number of actions. First, client  establishes an http or https connection [] to HTTP\/SSL request router (H\/S) and sends a request # ().","Second, HTTP\/SSL request router (H\/S) terminates the SSL session (if the traffic is SSL encrypted), parses request # (), and examines the content of request # (). Taking into account application health and load as well as session information, HTTP\/SSL request router (H\/S) determines that host () is the \u201cbest\u201d host for this particular request # () in this example.","Third, HTTP\/SSL request router (H\/S) establishes a secondary TCP connection [] to host (). This secondary TCP connection is not sourced from a VIP address on network ; instead, it is sourced from an address (not shown in ) that is dedicated to request router (H\/S) to ensure that responses  from host(s)  reach the correct request router . (There may be multiple request routers  that are active even though one request router (H\/S) is shown in  for clarity.) It may alternatively use an existing connection [] to host (). HTTP\/SSL request router (H\/S) then sends an e.g. unencrypted version of request # () to host (). Fourth, host () replies with a response # (). Fifth, HTTP\/SSL request router (H\/S) encrypts this response # () and sends it back to client  on TCP connection [].","Sixth, client  sends another request, request # (). Request # () is handled similarly to the handling of request # (), except that HTTP\/SSL request router (H\/S) selects host (). The different selection may be because host () is now failing or more-heavily loaded, because request # () is directed to a different URL than request # (), and so forth. Regardless, HTTP\/SSL request router (H\/S) establishes another secondary TCP connection, but this secondary TCP connection [] is to host (). Unencrypted request # () is routed to host (), and a response # () is received therefrom as a result. An encrypted version of response # () is then sent to client  from HTTP\/SSL request router (H\/S).","Seventh, client  closes TCP connection [] with HTTP\/SSL request router (H\/S). HTTP\/SSL request router (H\/S) (at some future time) closes connections [] and [] that it made to hosts () and (), respectively, on behalf of client . TCP connection [] may alternatively be closed after HTTP\/SSL request router (H\/S) decides to open\/use TCP connection [] for request # ().","Because an HTTP\/SSL request router (H\/S) terminates the HTTP\/HTTPS connection, HTTP\/SSL request router (H\/S) can do more than route requests. For example, HTTP\/SSL request router (H\/S) can potentially maintain its own cache of responses (e.g., with an out-of-band mechanism to invalidate the cache). As noted in the above example, HTTP\/SSL request router (H\/S) can also potentially route different kinds of requests to different sets of hosts  based on e.g. the requested URL. Conversely, HTTP\/SSL request router (H\/S) can potentially aggregate requests from many short-lived client connections and send them over a few, long-standing TCP connections to hosts . Such connection aggregation can reduce the TCP connection processing overhead in hosts .","Request routers of other classes may correspond to other exemplary protocols besides HTTP. For example, a request router may be a SOAP request router. SOAP request routers function analogously to an HTTP\/SSL request router (H\/S). However, SOAP request routers specialize in routing SOAP traffic. SOAP request routers understand SOAP headers and make routing decisions based on the SOAP headers as well as application health and load.","Both packet-level classification and forwarding (or packet-level routing) and request-level routing can provide some form of layer- load balancing. Layer- load balancing is described further below in the section entitled \u201cExemplary Connection Migrating with Optional Tunneling and\/or Application-Level Load Balancing\u201d. Packet-level routing provides read-only access to the initial portion of a client's TCP connection data, and request-level routing provides read and modify access to an entire data stream.","Packet-level routing typically has several advantages over request-level routing. These advantages include transparency (client packets are delivered to hosts as-is, preserving source and destination IP addresses and port numbers), low processing overhead (generally, forwarding traffic involves a route lookup), low latency (individual packets are forwarded, and packets are not queued once the TCP connection destination has been determined), and high-availability (generally, a failure in a forwarder does not terminate the TCP connection). Request-level routing, on the other hand, typically has the following advantages over packet-level routing: an ability to examine an entire data stream flowing to and from the client; and an ability to transform a data stream, and even to split the data stream among multiple hosts or aggregate data streams from multiple clients.",{"@attributes":{"id":"p-0287","num":"0295"},"figref":["FIG. 26","FIGS. 1-3"],"b":["2600","2600","2602","2616","2600","12","18","20","22","23"]},"At block , an incoming packet is received. For example, a packet from a client  may be received at a forwarder  of a load balancing unit . At block , it is determined if the received packet is for a preexisting session. For example, forwarder  may consult a local DAM table ( ) to determine that the received packet is already part of a TCP\/IP session.","Additionally, forwarder  may consult the local DAM table ( ) and determine that the received packet is not already part of a TCP\/IP session. In this case, forwarder  provides the received packet to a classifier , which checks for a higher level session affinity for the received packet if it has a session reference. Examples for these actions are described above with particular reference to  and further below with particular reference to .","If the received packet is for a preexisting session (as determined at block ), then flow continues at block . At block , a host that is affinitized to the preexisting session is ascertained. For example, an affinitized host  may be ascertained from the local DAM ( ) and\/or the overall distributed DAM  by forwarder  or classifier .","At block , it is determined if the affinitized host is healthy. For example, classifier  may consult a consolidated health and load cache  to determine if the affinitized host  is healthy, especially for those received packets that are part of sessions that are of a higher logical level than TCP\/IP sessions. The action(s) of this block may be accomplished in conjunction with a health and load handler .","If the affinitized host is healthy (as determined at block ), then flow continues at block . At block , the received packet is routed to the affinitized host. For example, forwarder  (for TCP\/IP sessions) or classifier  (for higher-level sessions) may route the packet to the affinitized host . In an alternative implementation, classifier  may return the received packet to forwarder  for routing to the affinitized host  even for received packets that are part of higher-level sessions.","If, on the other hand, the affinitized host is not healthy (as determined at block ), then flow continues at block . Also, if on the other hand, the received packet is not for a preexisting session (as determined at block ), then flow continues at block . At block , a host is selected responsive to health and load information. For example, classifier  may select a host  from and\/or using a health and load-related application allotment (e.g., from a target application endpoint allotment response ) that is attained from health and load handler . Examples for these action(s) are described above with particular reference to  and further below with particular reference to .","At block , the received packet is routed to the selected host. For example, classifier  may route (optionally via forwarder ) the packet to the selected host . At block , a route for a connection path to the selected host is plumbed. For example, classifier  may add a session information entry to DAM table , especially at the DAM table ( ) that is local to the forwarder  that provided the received packet to the classifier . This session information entry may be replicated in accordance with the instituted redundancy policy for a DAM  (e.g., of a session tracker ).","The action(s) of block  and those of block  may be performed in the order specifically illustrated, with those of block  being performed prior to those of block , with the actions partially or fully overlapping in any order, and so forth. It should be noted that the actions performed by classifier  as described above may alternatively be performed by a request router  (or more generally traffic routing functionality ).","In addition to packet-level and request-level routing, traffic routing functionality as described herein (e.g., traffic routing functionality , a request router , a forwarder \/classifier  pair, etc.) can also be used to implement firewall functionality. Hence, a feature of the traffic routing functionality may include blocking traffic, instead of automatically routing traffic to the correct host . For example, a classifier  can inspect traffic and drop it if it is deemed unsafe.",{"@attributes":{"id":"p-0297","num":"0305"},"figref":"FIG. 27","b":["202","106","302","1","304","1","304","2","302","2"]},"With classifier () executing on the second device and forwarder () executing on the third device, each device may be specially tuned for its respective functions. For example, the hardware, software, firmware, some combination thereof, etc. of the second device and the third device may be adapted to support the desired functionality without excessive over provisioning. Thus, the third device that includes forwarder () may be akin to a switch and\/or router from a hardware capability perspective, and the second device that includes classifier () may be more akin to a server and\/or personal computer from a hardware capability perspective.","Although shown as three devices that are providing functionality across four components, alternative logical and\/or device-level configurations for forwarding and classifying functionality are applicable to the exemplary traffic routing flow that is described here for . Also, although the routing destinations are shown as hosts , the descriptions herein of routing implementations may alternatively be applied more generally to a next node destination for the packet and not necessarily a final node that consumes the packet.","A DAM  realization of session tracker  is used to implement DAM table . However, session affinity preservers  in general are also applicable to the exemplary traffic routing flow of . Forwarder () includes DAM table portion (), and forwarder () includes DAM table portion (). Incoming packets are routed to host () or host ().","In a described implementation, DAM  is a distributed, in-memory table of \u201catoms\u201d  (e.g., keyword-value pairs, with optional metadata) having session information. DAM  and DAM table  is described further above with particular reference to . Any node in the cluster of classifiers  may add, query, and delete atoms . DAM  maintains a highly available DAM table  that includes active (e.g., TCP\/IP level) routes as well as higher-level session information. Examples of higher level sessions include: a TLS\/SSL session, a PPTP session, an IPSec\/L2TP session, an ISA session, an HTTP cookie-based session, and so forth. Furthermore, DAM  may include session information entries in DAM table  that are directed to other non-TCP\/IP sessions, such as RTP, UDP, and so forth.","At (1), load-balancing-aware switches (LBA) direct an incoming packet to forwarder (). At (2), forwarder () consults its internal routing table, DAM table (). When forwarder () does not find an atomic entry  for this packet, it forwards the packet to its assigned and\/or associated classifier, classifier ().","At (3), classifier () recognizes that the packet in this example is a first packet of a new session (e.g., a SYN packet for a TCP connection). Classifier () therefore treats the packet as a start of a new TCP connection from a client . Using health and load information from a health and load handler  (not explicitly illustrated), classifier () determines that host () should receive this session.","Classifier () updates DAM table () that serves as the local routing table for forwarder (), and it also inserts an atomic entry  representing the route into the overall DAM . These may be separate operations, a single operation in which the TCP\/IP-level sessions of DAM table  are located at forwarders , and so forth. DAM  internally replicates this route to one or more other members of the cluster of classifiers  in accordance with its stipulated redundancy policy. Classifier () may optionally communicate with host () to confirm the creation of the new session before it updates DAM table () of forwarder () and the overall DAM \/DAM table .","At (4), forwarder () directly forwards subsequent packets for this connection to host () without interacting with classifier (). DAM  can be used to mask, at least in part, the failure of a forwarder , a classifier , or a forwarder\/classifier pair \/. DAM  can also be used, at least in part, to preserve client connectivity if load-balancing-aware switches (LBA) inadvertently start sending packets for an established connection to a different forwarder .",{"@attributes":{"id":"p-0306","num":"0314"},"figref":["FIG. 28","FIG. 27","FIG. 28","FIG. 27"],"b":["106","302","1","304","1","2202"]},"At (1), load-balancing-aware switches (LBA) detect the failure of forwarder () and start forwarding packets for the connection to some other forwarder  in the cluster. In this example, the other forwarder  is forwarder (). Although  illustrates a failure situation, load-balancing-aware switches (LBA) may also send this traffic to forwarder () even if forwarder () is still available. This non-failure-induced change of forwarders  may occur, for example, because load-balancing-aware switches (LBA) do not preserve the affinity of this traffic to forwarder (). Any of several factors can cause switches  to (mis)direct traffic to a different, non-affinitized forwarder . For example, traffic for the same higher-level session can arrive at switches  from a different source IP address or source port when the source is behind a farm of proxy servers. The actions of notations (2)-(5) apply to both the failure and the \u201cmisdirected traffic\u201d situations.","At (2), forwarder () consults its routing table, DAM table (). When it does not find a route for this packet, it forwards the packet to its classifier (). At (3), classifier () recognizes that this packet is a \u201cmid-session\u201d packet, and classifier () queries DAM  for the route for this packet. DAM  responds with the route for the connection from an atomic entry  that is associated therewith.","At (4), classifier () plumbs the route in forwarder (). An exemplary protocol for plumbing routes is described further below. At (5), subsequent packets for this connection that are directed to forwarder () are routed directly to the correct host, which is host () in this example, without consulting classifier ().","Generally, a route plumbing protocol for communications between classifiers  and forwarders  includes instructions to add and remove routes. More specifically, an add route instruction is sent from a classifier  to a forwarder  in order to plumb a route from the forwarder  to a destination host  for a given connection. By way of example, an add route instruction can be provided to forwarder () from classifier () as indicated at (4) in . The route (e.g., a key and corresponding value) is added to local DAM table () for quick access by forwarder () in the future. In this example, classifier () is a separate device from forwarder (), so the route plumbing protocol may be an inter-device protocol. However, the route plumbing protocol may also be utilized for intra-device communications.","In a described implementation, classifier () includes a connection inventory . With connection inventory , classifier () keeps track of the sessions of any forwarders  (such as forwarder ()) for which classifier () plumbs routes. To enable classifier () to keep track of the sessions, including cessations thereof, forwarder () forwards final packets for sessions (such as a TCP FIN packet) to classifier (). Classifier () then deletes an entry in connection inventory  that corresponds to the session and sends a delete route instruction to forwarder (). Upon receiving the delete route instruction, forwarder () removes the corresponding route in DAM table ().","In this manner, the classifying functionality in conjunction with session tracking functionality can control the route tables, and the routes thereof, that are used by the forwarding functionality. Consequently, forwarding functionality that is separated onto a different device may be effectuated using high-speed, but relatively simple, hardware. Alternatively, classifiers  may rely on communications with\/from hosts , rather than (or in addition to) intercepted session initiation (such as TCP SYN) and termination (such as TCP FIN) packets, to determine the lifetimes of sessions. In other words, classifiers  may alternatively or additionally receive and utilize session (up\/down) messages (U\/D) as described above in the section entitled \u201cExemplary Session Tracking\u201d.",{"@attributes":{"id":"p-0313","num":"0321"},"figref":"FIG. 29","b":["106","2902","2906","106","302","1","302","2","302","3","304","1","304","2"]},"In a described implementation, each of these five components (), (), (), (), and () corresponds to an individual device. However, similar failover procedures apply to environments in which different load balancing components share devices. Also, similar or analogous failover procedures may apply to environments having other numbers, combinations, scalings, etc. of components.","Initially at [], router\/switch(es)  direct an incoming packet that happens to be for a new connection to forwarder (). Because forwarder () does not have a route for this connection in its local routing table, it sends the packet to classifier () as indicated by the dashed double arrow at (1). Classifier () first checks session information with reference to session tracking  for a possible higher-level session affinity. In this example, the packet is not affinized to an existing session, so classifier () selects a host  with reference to health and load information with reference to health and load handling .","Specifically, classifier () selects host () in this example. Assuming the packet is for a TCP\/IP connection, this TCP\/IP session as linked to host () is added to DAM  using an add atom (A) function call by classifier (). The initial packet is forwarded to host () by classifier () or forwarder (). Classifier () also plumbs a route in the local routing table of forwarder (). Subsequent packets are forwarded to host () by forwarder () without further interaction with classifier ().","At some time during connection [], there is a failure  at forwarder (). With load-balancing-aware router\/switch(es) (LBA), this failure  is detected. As a result, at point , router\/switch(es)  direct later packets that would have been sent to forwarder () along connection [] to another forwarder , which is forwarder () in this example.","Forwarder () thus receives future packets along a connection []. Because forwarder () does not have an entry in its local routing table for the packets that were formerly directed to forwarder (), forwarder () sends the first received packet of connection [] to the classifier to which it is assigned\/associated. In this example, forwarder () is assigned to classifier () as indicated by the dashed double arrow at (2).","Classifier () uses a query atom (Q) function call to attain the atomic entry  (not explicitly shown) from DAM  that is associated with the existing TCP\/IP connection. This atomic entry  is provided through DAM  of session tracking  via a return atom (R) function call. Classifier () extracts the host () that is affinitized with this TCP\/IP connection from the returned atomic entry . Classifier () forwards the first received packet for connection [] to host () and also plumbs a route in the local routing table of forwarder (). Subsequent packets are forwarded to host () by forwarder () without further interaction with classifier ().","The above descriptions focus predominantly on failures of individual forwarder  components. However, classifier  components can also fail. For example, at some point, there is a failure  at classifier (). Forwarder () detects failure  when it attempts to consume classification services or through noticing a lack of some aliveness indication such as a heartbeat-type indicator. To handle failure , forwarder () is reassigned or re-associated with a different classifier , which is classifier () in this example. Future classification functionality is provided to forwarder () by classifier () as indicated by the dashed double arrow at (3).",{"@attributes":{"id":"p-0321","num":"0329"},"figref":"FIG. 30","b":["302","304","314","108","1","108","2","108","302","304","306","2012"],"i":"n"},"As illustrated, host () includes application endpoints IP, IP, and IP for application #, application #, and application #, respectively. Host () includes application endpoints IP and IP for application # and application #, respectively. Host () includes application endpoint IP for application #. These hosts (), () . . . () and application endpoints IP, IP, IP, IP, IP, and IP are monitored by health and load handler  (e.g., using health and load infrastructure , consolidated health and load cache , etc.).","In a described implementation, at (1) classifier  requests one or more application endpoint allotments (e.g., via at least one target application endpoint allotment request ) in an environment using a token allotment scheme . Health and load handler , in this example, responds by providing token allotments  (e.g., via at least one target application endpoint allotment response ).","Specifically, a token allotment for application # () and a token allotment for application # () are available to classifier . Token allotment for application # () initially provides 40 tokens for IP, 35 tokens for IP, and 25 tokens for IP. Token allotment for application # () provides 10 tokens for IP, 72 tokens for IP, and 18 tokens for IP. For each new connection that is allocated a routing to an application endpoint by classifier , a token is consumed by classifier .","At (2), forwarder  receives an initial incoming packet for a new connection. Because no routing for this new connection is present in local DAM table portion  of forwarder , forwarder  forwards the initial packet to classifier  at (3).","At (4), classifier  (e.g., after determining that the initial packet does not include a session reference for a higher-level session) selects an application endpoint (and thus a host ) responsive to health and load information. Specifically, for a new connection that is to be served by application #, classifier  can select any of IP, IP, and IP if a token for the respective endpoint still exists.","Classifier  can consume tokens in any of many possible manners. For example, classifier  may use a round-robin approach regardless of the number of tokens per endpoint. Alternatively, classifier  may simply start from IP and progress through IP while consuming all tokens for each endpoint before moving to the next endpoint in a linear approach. Also, classifier  may consume a token from the endpoint-defined-set of tokens that currently has the greatest number of tokens at any one moment. Using the latter approach, classifier  selects IP. Other approaches may also be employed.","As illustrated, classifier  consumes a token for application endpoint IP. Consequently, the token set for IP is reduced from 35 tokens to 34 tokens as a token is consumed. Also, the initial packet for the new connection is to be routed to application endpoint IP.","At (5A), the initial packet is forwarded from classifier  to application endpoint IP of host (). Before, during, or after this forwarding, classifier  at (5B) plumbs a route for this connection in local DAM table portion . Classifier  may also add an atomic entry  for this session into DAM table  for distribution and replication purposes. At (6), future packets for this connection\/session are forwarded from forwarder  to application endpoint IP of host () using the local routing table of forwarder  as realized by local DAM table portion  in .",{"@attributes":{"id":"p-0330","num":"0338"},"figref":"FIG. 31","b":["106","3104","3106","3108","106","106","302","304","306","308","314"]},"At (A), forwarder  undergoes a local failure. At (A), at least one load-balancing-aware switch detects the failure. To handle local failure (A), packets are redirected to other forwarder(s) at (A) by the load-balancing-aware switch. To recover from the failure of forwarder , routes that were stored locally at forwarder  are rebuilt at (A) at the forwarder(s) to which packets are redirected using a distributed session tracking manager and a table thereof such as a DAM and a DAM table thereof. The distributed session tracking manager may therefore include data redundancies of one or more levels.","At (B), classifier  undergoes a local failure. At (B), at least one forwarder detects the failure. To handle local failure (B), packets are redirected to other classifier(s) at (B) by the forwarder detecting the failure. To recover from the failure of classifier , session information that was stored locally at classifier  are rebuilt at (B) at the classifier(s) to which packets are redirected using DAM. This session information may be, for example, session information of a higher level than baseline TCP\/IP connections. Also, such session information may be considered as part of session tracking infrastructure that is resident on the same device as classifier .","At (C), request router  undergoes a local failure. At (C), at least one forwarder and\/or load-balancing-aware switch detect the failure. To handle local failure (C), packets are redirected to other request router(s) at (C) by the forwarder and\/or load-balancing-aware switch. Individual current logical requests on which request router  is working upon the occurrence of local failure (C) may be lost unless each such individual logical request is replicated while the request is being serviced. To recover from the failure of request router , session information and\/or routes that were stored locally at request router  are rebuilt at (C) at the request router(s) to which packets (and thus new logical requests) are redirected. The session information rebuilding may be effectuated using DAM. Again, such session information may be considered as part of session tracking infrastructure that is resident on the same device as request router .","At (D), session tracker  undergoes a local failure. At (D), at least one forwarder and\/or classifier detect the failure. For example, if session tracker  is resident on a same device as a classifier, then a forwarder or another classifier may detect the failure. If session tracker  is resident on a separate device, then a classifier may detect the failure. To handle local failure (D), data redundancy of one or more levels and distribution across multiple devices are instituted at (D) for the tracked session information. It should be noted that the redundancy and distribution are instituted prior to failure (D). To recover from the failure of session tracker , session information from the tables of the DAM may be redistributed and re-replicated at (D) across at least two devices (if not already so distributed and sufficiently replicated) in order to handle a second level of failure.","At (E), health and load handler  undergoes a local failure. At (E), at least one classifier and\/or request router detect the failure. For example, a component that is receiving health and load information from health and load handler  may detect a failure if health and load handler  becomes non-responsive, especially if health and load handler  is resident on a different device from that of the inquiring component. To handle local failure (E), cached health and load data redundancy and intrinsic failure handling are employed at (E) for the health and load information.","For example, each health and load handler  can include a consolidated health and load information cache  that duplicates information in health and load tables  on multiple hosts . Also, consumers of the health and load information  of a given health and load handler  may be located on a same device as health and load handler  so that failure of health and load handler  is intrinsically acceptable. Similarly, the authoritative version of a respective portion of health and load information  is located on a respective host  so that failure of the host  renders the loss of the respective portion of the health and load information acceptable.","To recover from the failure of health and load handler , a given network load balancing component that consumes health and load information may query a different health and load handler because each such health and load handler includes a consolidated cache of health and load handler information. Also, when health and load handler  is again accessible, message protocol  may be used at (E) to rebuild its consolidated cache of health and load information. Using these exemplary high availability mechanisms, failures of network load balancing infrastructure  components can be detected, handled, and recovered from in order to mask such failures from clients .","This section describes how connection manipulation, such as connection migration, may be utilized in network load balancing. This section primarily references  and illuminates connection migrating functionality such as that provided by connection migrator  (of ). As described above with reference to , each incoming connection at load balancing infrastructure  may be terminated thereat. Afterwards, the connection may be migrated to a host  such that the connection is then terminated at the host . Connection migrator  is capable of performing this connection migration and may be located partially at hosts  to effectuate the migration. Such connection migration may be performed in conjunction with application-level load balancing by a classifier  and\/or using tunneling via tunneler .",{"@attributes":{"id":"p-0339","num":"0347"},"figref":"FIG. 32","b":["7","106","304","310","108"]},"For application-level load balancing in a TCP-based environment generally, classifiers  peek at the initial portion of a client's TCP data when deciding where to forward the client's TCP connection. Thus, application-level logic examines the client's data and makes load balancing decisions based on that data. For example, if a connection is an (unencrypted) HTTP connection, a classifier  can take a peek at the HTTP header of the first HTTP request in the connection, and it can make routing decisions based on some portion of the content of the header (e.g., the URL, a cookie, etc.). Although application-level load balancing, connection migration, and tunneling are applicable to other protocols, TCP\/IP is used predominantly in the examples herein.","As illustrated, load balancing infrastructure  (not specifically indicated) includes a forwarder , a classifier , a tunneler , and a connection migrator  (and possibly e.g. load-balancing-aware router\/switches (LBA)). Forwarder  corresponds to the virtual IP address and forwards packets to hosts  in accordance with host selections by classifier . Although not specifically shown in  for clarity, hosts  also include connection migrator  functionality and tunneler  functionality.","In a described implementation, forwarder , classifier , and connection migrator  (at classifier  and on hosts ), along with TCP protocol software on classifier  and hosts , cooperate to provide connection migration. The connection migration illustrated in  is for a connection from client () that is initially terminated at classifier . After connection migration, the connection from client () is terminated at host (). Once the connection is terminated at host (), packets for the connection may be tunneled using tunneler  (at forwarder  and host ()).","At (1), client () sends a SYN packet to forwarder  to signal the start of a new TCP connection. At (2), forwarder  forwards this packet to classifier . At (3), classifier  accepts the TCP connection on behalf of a host  (whose identity is not yet known because the actual target host ( ) has yet to be selected). In TCP protocol terms, classifier  sends a SYN-ACK packet to client ().","At (4), client () begins sending data. (The initial SYN packet may also contain data.) The data is processed by classifier , which can consult application-specific logic. The application-specific logic can relate to which host  is capable of handling or best handling which types of requests or connections. Hence, classifier  uses the data, as well as application health and load information from health and load handler  and optionally application session information from session tracker , to determine a host  that is better or best suited to handle this connection from client (). In this example, host () is selected.","At (5), classifier  sends a \u201cbinary blob\u201d that represents the state of the TCP connection to host (). This connection state is aggregated with cooperation from a TCP stack on classifier  by connection migrator . The binary blob contains data from client () that has been acknowledged by classifier  and TCP parameters such as the TCP\/IP 4-tuple, initial sequence numbers, and so forth.","At (6), a connection migrator  component on host () (not explicitly shown in ) \u201cinjects\u201d this connection into a TCP stack on host () using the state of the TCP connection from the binary blob received from classifier . This connection state injection is performed in cooperation with the TCP stack on host (), making it appear to applications  on host () that this connection was originally accepted by host () itself. Client () and applications  on host () are unaware of the connection migration.","At (7), classifier , in cooperation with the TCP stack on classifier , cleans up the internal state maintained for this connection. This internal state cleanup at classifier  is performed silently such that client () is not notified that the connection state is being torn down. Classifier  also adds a route in a local routing table of forwarder  that indicates host () as the destination for packets of this connection.","At (8), subsequent packets for the connection are routed by forwarder  to host () without diversion to or through classifier . These packets may be treated the same by forwarder  as those packets for connections that are classified and routed without using connection migration. These subsequent packets may optionally be tunneled from forwarder  to host () using tunneler . Tunneler  is also illustrated (using dashed lines) at connection migrator  at classifier  because certain parameter(s) used by tunneler  may be determined during a connection migration and\/or associated with a connection being migrated. Exemplary implementations for tunneler  are described further below with particular reference to .",{"@attributes":{"id":"p-0349","num":"0357"},"figref":"FIG. 33","b":["3300","3300","3302","3314","32","34","37","310"]},"At block , a connection is accepted at a first device. For example, a first device may terminate an incoming connection in accordance with one or more protocols of a protocol stack portion of a network stack. At block , data is received for the connection at the first device. For example, this data may be received in an initial packet that requests the connection or in one or more packets that are received subsequent to an acceptance of the connection.","At block , a connection state for the accepted connection is aggregated from a protocol stack (or more generally from a network stack) at the first device. For example, a protocol state of the one or more protocols of the protocol stack may be compiled and aggregated with any received data that has been acknowledged. At block , the connection state is sent from the first device to a second device. For example, the aggregated information of the connection state may be sent using a reliable protocol to a second device.","At block , the connection state for the connection being migrated is received from the first device at the second device. At block , the connection state is injected into a protocol stack (or more generally into the network stack) of the second device. For example, the connection may be rehydrated using the protocols of the protocol stack of the second device such that programs above the protocol stack level are unaware that the connection is a migrated connection. More specifically, the protocol state may be infused into the protocol stack. The aggregated data of the connection state is also incorporated at the second device. At block , the connection is continued at the second device. For example, the connection may be continued at the second device as if the connection was not previously terminated elsewhere.",{"@attributes":{"id":"p-0353","num":"0361"},"figref":"FIG. 34","b":["3400","3400","310","3400","106","3400","304","302","306"]},"As illustrated, originating device  includes as parts of its network stack a physical network interface (PNI) , a PNI miniport , a protocol-hardware interface , a protocol stack , and a socket layer . Originating device  also includes load balancing functionality , such as a classifier  at an application level and connection migrator . Specifically, connection migrator  includes a migrator intermediate driver  and a migrator shim . Connection migrator  is capable of offloading a connection from originating device .","In a described implementation, physical network interface  may be a network interface card (NIC) (e.g., an Ethernet NIC), a wireless interface, and so forth. Although only one physical network interface  is shown, a given device may actually have multiple such physical network interfaces  (i.e., originating device  may be multi-homed). Each physical network interface  typically corresponds to one or more physical network addresses.","PNI miniport  is a software module that understands and interfaces with the specific hardware realization of physical network interface . Protocol-hardware interface  is a layer that includes one or more respective interfaces between one or more respective protocols and PNI miniport .","Protocol stack  includes one or more respective modules that are each directed to one or more respective protocols. Examples of such protocols are described further below with reference to . In a transient context, protocol stack  includes a protocol state  for each connection existing at originating device . A socket layer  lies between a program such as load balancing functionality  and protocol stack . Socket layer  provides APIs between load balancing functionality  and protocol stack , and it enables programs to register for connections, among other things.","Migrator intermediate driver , or more generally migrator driver , is located at protocol-hardware interface layer . Migrator shim  is located transparently between protocol stack  and socket layer .","When an initial packet (not shown) requesting a new connection is presented to originating device , the packet is directed upward from physical network interface , to PNI miniport , through protocol-hardware interface layer , and to protocol stack . As the packet traverses the one or more protocols of protocol stack , protocol state  is created thereat. Also, as a result of this initial packet or as a consequence of load balancing functionality  accepting the connection to take a peek at the request, data  arrives at originating device .","In operation, migrator intermediate driver  diverts a copy of data  to the logic of connection migrator . When load balancing functionality  issues a migrate connection function call, the migrate function call is passed to a topmost layer of protocol stack  so that connection state aggregation  may commence. Protocol state  is compiled from the one or more protocols of protocol stack . In a TCP\/IP implementation, protocol state  may include (i) destination and source TCP ports and IP addresses (e.g., a TCP\/IP 4-tuple), (ii) TCP window state, (iii) initial sequence numbers, (iv) timeout information, (v) IP fragment ID, (vi) routing information, and (vii) so forth.","Connection state aggregation  also aggregates data  that has been diverted to connection migrator  and that has already been acknowledged from originating device  (e.g., by load balancing functionality ). This aggregated connection state  includes protocol state  and data  (and optionally other connection-related information). Aggregated connection state  is then sent as a binary blob  away from originating device  toward a targeted device.","Binary blob  may be sent from originating device  toward a targeted device using a reliable protocol. \u201cReliable\u201d may imply, for example, that binary blob  is received intact at the targeted device even if individual packets that constitute binary blob  are lost or corrupted. This binary blob  may also be bundled with a flow identifier if the connection is to be tunneled subsequently with tunneler . Flow identifiers with tunneling are described further below with particular reference to .",{"@attributes":{"id":"p-0363","num":"0371"},"figref":"FIG. 35","b":["3500","3500","3400","310","316","3402","3500","108","310","3400"]},"In a described implementation, application  is the destination of the connection-initiating packet received at originating device . From originating device , target device  receives binary blob . Binary blob  includes the connection state associated with the connection being migrated to target device  and optionally a flow identifier. This connection state includes protocol state  and acknowledged data  (and possibly other connection-related information).","In operation, when binary blob  reaches protocol-hardware interface layer , migrator intermediate driver  recognizes it as a blob for connection migration and diverts it. The connection state is injected at  to create the appearance to application  that the connection was originally terminated at target device .","Specifically, protocol state  of injected connection state  is infused into protocol stack . In a described implementation, protocol state  is infused first at higher-level protocols and then at lower-level protocols of protocol stack . After protocol state  is infused into protocol stack , data  can be indicated up to application . This data  can be provided to application  as if it were part of a newly and locally terminated connection.","After connection state injection  is completed, the connection initiated by the packet received at originating device  is successfully migrated therefrom to target device . Subsequent packets for the connection may be forwarded directly to target device  without passing through originating device , or at least with only simple routing and no application-level analysis being applied thereto. Optionally, these packets may be tunneled such that migrator intermediate driver  effectively operates as a software-based virtual NIC that is bound to the virtual IP address. In other words, migrator intermediate driver  (of ) may comprise a virtual network adapter that is bound to the destination address of un-encapsulated packets.",{"@attributes":{"id":"p-0368","num":"0376"},"figref":"FIG. 36","b":["3600","3600","3400","3404","3404","3404","3404","3404"]},"By way of example, protocol-hardware interface layer  may be realized as a network driver interface specification (NDIS)-based layer in a Microsoft\u00ae Windows\u00ae operating system (OS) environment. Also, socket layer  may be realized as a Winsock\u2122 layer in a Microsoft\u00ae Windows\u00ae OS environment.","In a described implementation, migrator intermediate driver  includes protocol-hardware interfaces  at the junctions to ARP stack (A) and to PNI miniport . Migrator intermediate driver  serves as an offload target in migration offloading procedure . The offload target is a protocol-hardware interface  miniport as illustrated in this example. In a migration uploading procedure  (as in ), migrator intermediate driver  serves as an upload diverter.","More specifically, migrator intermediate driver  is bound to each physical network interface  through which a TCP connection may be migrated. Migrator intermediate driver  usually operates as a pass-through driver by passing packets upwards or downwards in the network stack without otherwise interacting with the packets. However, migrator intermediate driver  does interact with packets related to connection migration (optionally including subsequently tunneled packets).","Responsibilities of migrator intermediate driver  include: (i) the acceptance of migrate offload requests; (ii) the aggregation of the protocol state information that is related to the TCP connection being migrated as compiled from the specific protocol stacks ( ), along with acknowledged data to produce the connection state information; and (iii) the transmission of the aggregated connection state to a targeted device  for a migration uploading procedure . A reliable wire protocol for such transmission may be shared with that used by the session tracking components  and  to send and receive session information messages  (e.g., as described above with reference to ).","Another responsibility of migrator intermediate driver  (e.g., in a migration uploading procedure ) is to initiate the uploading of migrated connections that it receives from other devices and to buffer any incoming packets related to the migrating connection while it is in the process of being uploaded. To upload the connection, migrator intermediate driver  sends an upload request to migrator shim . Migrator shim  issues an inject call down into protocol stack  at TCP stack (A) to instantiate the connection in the protocol stack  portion of the network stack.","Migrator shim  exposes a transport layer client interface to TCP stack (T) and exposes a transport layer provider interface to socket layer . Migrator shim  has two roles: (i) to initiate connection migration offload procedure  on an originating device  and subsequently migration upload procedure  on a targeted device  and (ii) to mediate the classification process between a host application  program, a load-balancing classifier  program, and socket layer . Migrator shim  and migrator intermediate driver  are both further described below with reference to .","For an exemplary migration offloading procedure , the migration of a TCP connection is performed after classifier  classifies the incoming TCP connection using one, two, or more packets thereof. Migration offloading procedure  is described at points <1> through <7>.","At <1>, an initialization is performed prior to classification operations. Protocol stack  makes queries at protocol-hardware interface layer  to determine what offloading capabilities, if any, are available. Migrator intermediate driver  indicates that connection migration offloading is available and propagates the query down to PNI miniport . If a TCP chimney offload ability is provided by a physical network interface , PNI miniport  also so indicates. TCP chimney offload enables some TCP\/IP processing to be offloaded to the hardware of physical network interface  and involves some compiling of protocol state . Consequently, some compiling and aggregation logic may be shared between the two offloading mechanisms.","At <2>, once a TCP connection has been classified, classifier  initiates a TCP connection migration to a selected host . Specifically, a migration command indicating a targeted device  is issued via socket layer  to migrator shim .","At <3>, migrator shim  initiates TCP connection migration to compile the TCP protocol state. Specifically, migrator shim  invokes a TCP initiate migrate offload API (or more generally a migrate connection function call or migrate connection command). This routine compiles the relevant state for the specified TCP connection that is used to reinstate the connection on the targeted device . The compiled protocol state  includes state from the intermediate stack layers, including TCP stack (T), IP stack (I), and ARP stack (A).","At <4>, once protocol stack  has compiled protocol state  for the TCP connection being migrated, it invokes an initiate migrate offload API on the miniport to which it is bound; in this example, that miniport is migrator intermediate driver . However, in practice, there may be other intermediate drivers inserted between protocol stack  and migrator intermediate driver , such as IP QoS. If so, those IM drivers may participate in the migration, if relevant, by compiling\/aggregating their state to the connection state information for the connection being migrated. Intermediate drivers continue to propagate the initiate migrate offload call down the network stack, which eventually results in execution of a migrate offload handler at migrator intermediate driver . At this point, migrator intermediate driver  also aggregates any acknowledged data with the remaining connection state for transfer of the TCP connection to targeted device .","At <5>, after storing\/copying connection state information for the TCP connection being migrated, migrator intermediate driver  notifies the network stack that the migration is in its final stages by invoking an initiate migrate offload complete API. This initiate migrate offload complete API follows the reverse path up the network stack, through the same intermediate drivers (if any), and eventually to protocol stack . As each layer processes this call, state information that is associated with the migrated connection may be released. Until the processing of this call is complete, each layer may send updating notifications down the network stack to update any part of the connection state that has changed since the migration was initiated.","At <6>, when the initiate migrate offload complete routine reaches TCP stack (T), TCP silently (i.e., no reset is sent to client ) closes the connection, flushing all state associated with the migrated connection, and propagates the initiate migrate offload complete call to migrator shim . At this point, the network stack is free of any residual knowledge of the migrated TCP connection.","At <7>, when the initiate migrate offload complete call returns to migrator intermediate driver  (via the migrator shim  portion of connection migrator ), the migration of the TCP connection from originating device  to targeted device  may commence with the transfer of the connection state thereto. The connection state may be transferred asynchronously and reliably.","Once migration is initiated, originating device  is also responsible for ensuring that subsequent data from client  is forwarded to target device . Consequently, even after the connection is successfully migrated to the target, the originator retains some amount of state for the connection (e.g., a routing table entry) in order to properly route subsequent packets to the target. When the connection is terminated, the target notifies the originator to enable it to purge whatever residual state remains for the migrated connection.","Furthermore, as a consequence of the asynchronous nature of the connection migration, data packets for the migrating connection that are forwarded by originating device  (or a forwarder designated thereby if a separate device) may start arriving at targeted device  before targeted device  receives the migrated connection state. Migrator intermediate driver  at targeted device  is responsible for buffering those packets until the associated migrated connection is established on targeted device .",{"@attributes":{"id":"p-0385","num":"0393"},"figref":"FIG. 37","b":["3700","3700","3500"]},"When a migrated connection arrives at targeted device , it is relayed to migrator intermediate driver  for processing. After amalgamating and assimilating the migrated connection state, migrator intermediate driver , in conjunction with migrator shim , injects the migrated connection into the local network stack in a manner transparent to application . For an exemplary migration uploading procedure , the migration of a TCP connection at points <1> through <8> is described.","At <1>, as described above with reference to migration offloading procedure , an initialization is performed prior to application hosting operations. Specifically, protocol stack  makes queries regarding what offloading capabilities, if any, are available. Migrator intermediate driver  fills in the TCP connection migration support query to indicate that connection migration uploading is available and also propagates the query down to PNI miniport  for possible TCP chimney offload capabilities.","At <2>, when connection migration data arrives at target device , the connection migration information (e.g., a bundled binary blob ) is delivered to migrator intermediate driver . Migrator intermediate driver  reassembles the connection state, matches it up with any associated data that has arrived during the migration, and prepares for the upload onto the network stack. Any data from client  that arrives during the process of uploading the migrated connection is buffered by migrator intermediate driver . Upon successful completion of the migration, the data will be delivered to application .","At <3>, to initiate the upload of the migrated connection into the local network stack, migrator intermediate driver  notifies migrator shim  that a migrated connection request has arrived. Migrator intermediate driver  also delivers the connection state (or at least protocol state ) to migrator shim .","At <4>, migrator shim  initiates the upload of the migrated connection by invoking a TCP initiate inject routine (or more generally an infuse protocol state routine) and by providing the migrated protocol state  to TCP stack (T). At <5>, TCP\/IP recreates the migrated connection throughout protocol stack  using the provided protocol state . This protocol state  may include one or more of transport state (TCP), path state (IP), neighbor and next-hop state (ARP), and so forth.","At <6>, if the migrated connection is successfully reestablished on target device , TCP initiates a connect event to a client portion of migrator shim  to indicate that a new connection has been established. There are a multitude of possible reasons for failure, but common reasons may include the lack of a corresponding listener, routing failure, etc. In these cases where the network stack is unable to reestablish the migrated connection, no connect event is indicated and a failure status is specified in the initiate inject complete call. Connection migrator  is responsible for cleaning up the migration and for sending a reset notification back to client  to abandon the connection.","At <7>, migrator shim  acts as a provider to propagate the connect event to socket layer  so as to indicate to the listening application  that a new connection has been established. If the application  accepts the connection, it processes the requests and responds through normal read and write socket operations; application  can be unaware that the connection was migrated. If the connection is not accepted by the application , TCP terminates the connection but does not send a reset notification back to client . Again, a failure status is specified in the initiate inject complete call, and connection migrator  is responsible for cleaning up the migration and for sending a reset notification back to client  to abandon the connection.","A special situation arises when application  and classifier  are co-located on the same device: migrator shim  may referee between them. When both classes of programs reside on the same host , they may both be listening to the same IP address(es) and port(s). However, TCP typically has one listener per unique IP address and port. Consequently, migrator shim  can obscure a configuration where two programs are listening on the same IP address and port by multiplexing the two sockets into a single listener at the TCP layer.","In such a case, when connect events arrive at the client portion of migrator shim , migrator shim  as a provider determines on which listening socket to deliver the connect notification at socket layer . If there is only one socket listening to the corresponding IP address and port, then that socket receives the connect event. If there is more than one socket listening, then the recipient depends on the context in which the connect event is indicated. If the connect event is a brand new connection for a virtual IP address, then the connect event is delivered to classifier ; if the connect event is for a dedicated IP address (non-load-balanced IP address) or the result of uploading a migrated connection, then the connect event is delivered to the target application .","At <8>, once the injection of the migrated connection is complete, TCP notifies migrator shim  by invoking the provided initiate inject complete handler. A status code is provided to notify migrator shim  whether or not the connection was successfully uploaded. If uploading of the migrated connection fails, connection migrator  is responsible for cleaning up the migration and for notifying client  that the connection has been abandoned by sending it a reset. If the migrated connection was successfully injected into the local network stack, migrator intermediate driver  may begin delivering any buffered data from client  by passing the received packet(s) up through the packet receive path of protocol-hardware interface .","When a migrated connection is terminated (because uploading failed, because the migrated connection is subsequently closed through normal means, etc.), target device  notifies originating device . Originating device  uses these notifications to more efficiently and reliably clean out lingering state for migrated connections, including routing table entries. Therefore, to account for successfully migrated connections which terminate arbitrarily in the future, migrator shim  may monitor their activity and notify migrator intermediate driver  when the sockets therefor are closed.",{"@attributes":{"id":"p-0397","num":"0405"},"figref":"FIG. 38","b":["302","108","3808","302","108","3814","3806","3810","312","312","302","108","3814","3808"]},"As noted above with reference to , packets for a connection that arrive subsequent to a connection migration may be routed by forwarder  to host () using tunneling by a tunneler . At () (of ), forwarder  forwards such subsequent packets from forwarder  having a network address of \u201cF\u201d to host () having a network address of \u201cH\u201d. As described above with reference to , forwarder  may perform NAT, half-NAT, tunneling, etc. in order to route the incoming packets to host ().","Such incoming packets include a destination IP address of the virtual IP (\u201cVIP\u201d) address and a source IP address of \u201cC\u201d for packets arriving from client (). The packets being routed to host () have a destination IP address of H and a source address of C (for half-NAT) or \u201cF\u201d (for full NAT). This rewriting of the addresses can interfere with some protocols that expect both of client () and host () to have identical views of the source and destination addresses.","Furthermore, at least with respect to full NAT, return paths from host () to client () that do not run through forwarder  are prohibitive because host () does not know the address of client (). Direct paths from host () to client () are desirable in situations in which traffic from host () to client () is especially high and\/or significantly greater than traffic in the opposite direction (e.g., when host () provides streaming media to client ()).","Tunneling by tunnelers  as described herein can provide for identical views with respect to the source and destination addresses (and ports) for clients  and applications  on hosts . By way of example and with reference to , tunneler  in each of forwarder  and host  may operate as part of or in conjunction with a migrator intermediate driver  of a connection migrator .","In a described implementation for , connection migrator  provides an encapsulation mapping  between a flow identifier  and a TCP\/IP 4-tuple . Connection migrator  may be associated with a classifier , and connection migrator  (optionally along with such a classifier ) may be located on a same device as forwarder . Alternatively, connection migrator  (as well as the classifier ) may be located on a different device from forwarder . Encapsulation mapping  may alternatively be provided by or in conjunction with tunneler  functionality that is, for example, located at and\/or associated with a classifier .","By being mapped to a TCP\/IP 4-tuple  in encapsulation mapping , flow identifier  serves to identify a flow of encapsulated packets  for a particular connection. TCP\/IP 4-tuple  includes network addresses (and ports, etc.) for the source and destination for a particular connection in accordance with a TCP\/IP protocol, or any similar or analogous protocol. Flow identifier  is 32 bits in a described implementation because this allows the flow identifier to be encoded in the source and destination port fields of the TCP segment header in the tunneled packet, which enables the tunneled packet to be transmitted without any tunneling space overhead. At the destination, the TCP\/IP 4-tuple can be determined by looking up the 4-tuple that is linked to the flow identifier as extracted from the source and destination port fields. However, flow identifiers  of other lengths may alternatively be used, especially for other protocols such as internet RTP, etc.","Each flow identifier  can identify a unique connection from the device that is originating the tunneling (which is forwarder  in this example). Flow identifiers  may be generated using any appropriate mechanism, such as an incrementing connection counter. Alternatively, the TCP\/IP receiver Initial Sequence Number (ISN) generated by the connection migrator can serve as flow identifiers . Furthermore, TCP\/IP 4-tuple  is more generally a source\/destination pair. Each source value and destination value of an individual source\/destination pair may include a network node identifier (e.g., network address, port, some combination thereof, etc.) for the source and destination, respectively, of a given packet propagating on a particular connection.","Connection migrator  provides encapsulation mapping  to host . Tunneler (H) at host  stores encapsulation mapping  in encapsulation mapping table  as encapsulation mapping entry (). Tunneler (H) can thereafter use flow identifier  to map to and identify the particular connection corresponding to TCP\/IP 4-tuple . Encapsulation mapping  may optionally be provided to host  as part of a bundled binary blob  in a connection migration operation.","Forwarder  also includes a tunneler (F) component with an encapsulation mapping table . Encapsulation mapping table  stores an encapsulation mapping entry () that links\/maps TCP\/IP 4-tuple  for a particular connection to a flow identifier . Tunneler (F) also receives the mapping information for encapsulation mapping entry () from connection migrator  (e.g., as an encapsulation mapping ).","Although only one encapsulation mapping entry () and () is shown, each of encapsulation mapping table  and encapsulation mapping table  may have multiple such entries. These encapsulation mapping tables  and  may be combined with other information, such as tables for session information of session tracker .","When a transmitting device (such as forwarder ) and a receiving device (such as host ) of encapsulated packets  only tunnel between each other, the encapsulation mapping tables thereof likely have the same encapsulation mapping entries. Otherwise, encapsulation mapping table  and encapsulation mapping table  likely have a different total set of encapsulation mapping entries ( ) and encapsulation mapping entries ( ), respectively.","In operation, an incoming packet  for a particular connection is received at forwarder . The particular connection is associated with TCP\/IP 4-tuple . Incoming packet  includes TCP\/IP 4-tuple  with a source IP address (of a client ), a destination IP address (the virtual IP), a source TCP port (of the client ), and a destination TCP port.","Tunneler (F) accepts incoming packet  for tunneling to host . Using TCP\/IP 4-tuple , tunneler (F) accesses encapsulation mapping table  to locate encapsulation mapping entry (). Flow identifier  is extracted from encapsulation mapping entry () as being linked\/mapped to TCP\/IP 4-tuple .","To create encapsulated packet , tunneler (F) inserts flow identifier  into the source and destination port portions of the TCP\/IP 4-tuple header. These two TCP portions are 16 bits each, which allows a 32-bit flow identifier  to be inserted. Also, for the source IP address portion of the TCP\/IP 4-tuple header, tunneler (F) inserts the IP address \u201cF\u201d of forwarder . For the destination IP address portion of the TCP\/IP 4-tuple header, tunneler (F) inserts the IP address \u201cH\u201d of host .","Forwarder  routes\/transmits encapsulated packet  to host , and host  receives encapsulated packet  from forwarder . The tunneler (H) component at host  detects that encapsulated packet  is a tunneled packet that is to be de-encapsulated.","Flow identifier  is extracted from encapsulated packet  and used to look up the corresponding TCP\/IP 4-tuple  that is linked thereto in encapsulation mapping entry () of encapsulation mapping table . TCP\/IP 4-tuple  is used by tunneler (H) to recreate the TCP\/IP 4-tuple  header as originally received in incoming packet  at forwarder .","Specifically, the IP address F of forwarder  is replaced with the source IP address, and the IP address H of host  is replaced with the destination IP address. Furthermore, flow identifier  is replaced by the source TCP port and the destination TCP port. The de-encapsulated packet is then indicated up the network stack of host  to the targeted application .","More generally, a portion of a packet header, including a portion of a source\/destination pair, for a given packet that is not necessarily used for communicating the given packet may be used to carry a flow identifier . By pre-providing at least part of the source\/destination pair at host , a flow identifier  may be employed to tunnel (e.g., encapsulate and\/or de-encapsulate) packets without incurring an encapsulation overhead on each packet. Furthermore, packets that are full-size with respect to a given protocol may be tunneled without being fragmented.",{"@attributes":{"id":"p-0416","num":"0424"},"figref":"FIG. 39","b":["3900","3400","3500","106","108"]},"Flow diagram  includes twelve blocks -. Although the actions of flow diagram  may be performed in other environments and with a variety of software schemes, , , , , and  are used in particular to illustrate certain aspects and examples of the method.","At block , a mapping of a flow identifier-to-TCP\/IP 4-tuple is sent to a target device from an originating device. For example, originating device  may send an encapsulation mapping  that links a flow identifier  to a TCP\/IP 4-tuple . At block , the mapping of the flow identifier-to-the TCP\/IP 4-tuple is received at the target device from the originating device. For example, target device  receives encapsulation mapping  that links flow identifier  to TCP\/IP 4-tuple  from originating device .","Alternatively, target device  may receive encapsulation mapping  from another device. As indicated by dashed arrows  and , the actions of blocks - and blocks - can occur at some time after the actions of blocks  and , respectively.","At block , an incoming packet is received at the originating device from a client. For example, an incoming packet  having a header with TCP\/IP 4-tuple  may be received at originating device  from a client . At block , a flow identifier is looked up for a connection corresponding to the client's packet using the TPC\/IP 4-tuple of the incoming packet. For example, flow identifier  may be looked up for the connection with client  using TCP\/IP 4-tuple  that is mapped thereto in an encapsulation mapping entry () of an encapsulation mapping table .","At block , the source IP and destination IP of the incoming packet are replaced with an originating IP address of the originating device and a target IP address of the target device, respectively. For example, originating device  may replace the IP address portions of the TCP\/IP 4-tuple  portion of a header of incoming packet  with IP addresses of originating device  and target device .","At block , the source port and the destination port of the incoming packet are replaced with the flow identifier. For example, originating device  may replace source and destination TCP ports of the TCP\/IP 4-tuple  portion of the header of incoming packet  with flow identifier . At block , the encapsulated packet is sent from the originating device to the target device. For example, originating device  may send an encapsulated packet  to target device .","At block , the encapsulated packet is received at the target device from the originating device. For example, target device  may receive the encapsulated packet  from originating device . At block , the TCP\/IP 4-tuple is looked up for the connection corresponding to the packet received from the client using the flow identifier. For example, target device  may access an encapsulation mapping table  at an encapsulation mapping entry () that maps flow identifier  to TCP\/IP 4-tuple .","At block , the originating IP address and the target IP address are replaced with the source IP address and the destination IP address, respectively, using the looked-up TCP\/IP 4-tuple. For example, target device  may replace the IP addresses of originating device  and target device  in encapsulated packet  with the source IP address and the destination IP address from TCP\/IP 4-tuple  as attained from encapsulation mapping table .","At block , the flow identifier is replaced with the source port and the destination port of the incoming packet using the looked up TCP\/IP 4-tuple. For example, target device  may replace flow identifier  in encapsulated packet  with the source TCP port and the destination TCP port from TCP\/IP 4-tuple . At block , the client's packet is indicated up to an application at the target device. For example, a de-encapsulated version of encapsulated packet , or incoming packet , is indicated up to application  of target device .","The actions, aspects, features, components, etc. of  are illustrated in diagrams that are divided into multiple blocks. However, the order, interconnections, layout, etc. in which  are described and\/or shown is not intended to be construed as a limitation, and any number of the blocks can be combined, rearranged, augmented, omitted, etc. in any manner to implement one or more systems, methods, devices, procedures, media, APIs, apparatuses, arrangements, etc. for network load balancing. Furthermore, although the description herein includes references to specific implementations (and the exemplary operating environment of ), the illustrated and\/or described implementations can be implemented in any suitable hardware, software, firmware, or combination thereof and using any suitable network organization(s), transport\/communication protocols(s), application programming interface(s) (APIs), client-server architecture(s), and so forth.",{"@attributes":{"id":"p-0427","num":"0435"},"figref":"FIG. 40","b":["4000","4000"]},"Exemplary operating environment  is only one example of an environment and is not intended to suggest any limitation as to the scope of use or functionality of the applicable device (including computer, network node, entertainment device, mobile appliance, general electronic device, etc.) architectures. Neither should operating environment  (or the devices thereof) be interpreted as having any dependency or requirement relating to any one or to any combination of components as illustrated in .","Additionally, network load balancing may be implemented with numerous other general purpose or special purpose device (including computing system) environments or configurations. Examples of well known devices, systems, environments, and\/or configurations that may be suitable for use include, but are not limited to, personal computers, server computers, thin clients, thick clients, personal digital assistants (PDAs) or mobile telephones, watches, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set-top boxes, programmable consumer electronics, video game machines, game consoles, portable or handheld gaming units, network PCs, minicomputers, mainframe computers, network nodes, distributed or multi-processing computing environments that include any of the above systems or devices, some combination thereof, and so forth.","Implementations for network load balancing may be described in the general context of processor-executable instructions. Generally, processor-executable instructions include routines, programs, protocols, objects, interfaces, components, data structures, etc. that perform and\/or enable particular tasks and\/or implement particular abstract data types. Network load balancing, as described in certain implementations herein, may also be practiced in distributed processing environments where tasks are performed by remotely-linked processing devices that are connected through a communications link and\/or network. Especially in a distributed computing environment, processor-executable instructions may be located in separate storage media, executed by different processors, and\/or propagated over transmission media.","Exemplary operating environment  includes a general-purpose computing device in the form of a computer , which may comprise any (e.g., electronic) device with computing\/processing capabilities. The components of computer  may include, but are not limited to, one or more processors or processing units , a system memory , and a system bus  that couples various system components including processor  to system memory .","Processors  are not limited by the materials from which they are formed or the processing mechanisms employed therein. For example, processors  may be comprised of semiconductor(s) and\/or transistors (e.g., electronic integrated circuits (ICs)). In such a context, processor-executable instructions may be electronically-executable instructions. Alternatively, the mechanisms of or for processors , and thus of or for computer , may include, but are not limited to, quantum computing, optical computing, mechanical computing (e.g., using nanotechnology), and so forth.","System bus  represents one or more of any of many types of wired or wireless bus structures, including a memory bus or memory controller, a point-to-point connection, a switching fabric, a peripheral bus, an accelerated graphics port, and a processor or local bus using any of a variety of bus architectures. By way of example, such architectures may include an Industry Standard Architecture (ISA) bus, a Micro Channel Architecture (MCA) bus, an Enhanced ISA (EISA) bus, a Video Electronics Standards Association (VESA) local bus, a Peripheral Component Interconnects (PCI) bus also known as a Mezzanine bus, some combination thereof, and so forth.","Computer  typically includes a variety of processor-accessible media. Such media may be any available media that is accessible by computer  or another (e.g., electronic) device, and it includes both volatile and non-volatile media, removable and non-removable media, and storage and transmission media.","System memory  includes processor-accessible storage media in the form of volatile memory, such as random access memory (RAM) , and\/or non-volatile memory, such as read only memory (ROM) . A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules\/instructions that are immediately accessible to and\/or being presently operated on by processing unit .","Computer  may also include other removable\/non-removable and\/or volatile\/non-volatile storage media. By way of example,  illustrates a hard disk drive or disk drive array  for reading from and writing to a (typically) non-removable, non-volatile magnetic media (not separately shown); a magnetic disk drive  for reading from and writing to a (typically) removable, non-volatile magnetic disk  (e.g., a \u201cfloppy disk\u201d); and an optical disk drive  for reading from and\/or writing to a (typically) removable, non-volatile optical disk  such as a CD, DVD, or other optical media. Hard disk drive , magnetic disk drive , and optical disk drive  are each connected to system bus  by one or more storage media interfaces . Alternatively, hard disk drive , magnetic disk drive , and optical disk drive  may be connected to system bus  by one or more other separate or combined interfaces (not shown).","The disk drives and their associated processor-accessible media provide non-volatile storage of processor-executable instructions, such as data structures, program modules, and other data for computer . Although exemplary computer  illustrates a hard disk , a removable magnetic disk , and a removable optical disk , it is to be appreciated that other types of processor-accessible media may store instructions that are accessible by a device, such as magnetic cassettes or other magnetic storage devices, flash memory, compact disks (CDs), digital versatile disks (DVDs) or other optical storage, RAM, ROM, electrically-erasable programmable read-only memories (EEPROM), and so forth. Such media may also include so-called special purpose or hard-wired IC chips. In other words, any processor-accessible media may be utilized to realize the storage media of the exemplary operating environment .","Any number of program modules (or other units or sets of instructions\/code) may be stored on hard disk , magnetic disk , optical disk , ROM , and\/or RAM , including by way of general example, an operating system , one or more application programs , other program modules , and program data .","A user may enter commands and\/or information into computer  via input devices such as a keyboard  and a pointing device  (e.g., a \u201cmouse\u201d). Other input devices  (not shown specifically) may include a microphone, joystick, game pad, satellite dish, serial port, scanner, and\/or the like. These and other input devices are connected to processing unit  via input\/output interfaces  that are coupled to system bus . However, input devices and\/or output devices may instead be connected by other interface and bus structures, such as a parallel port, a game port, a universal serial bus (USB) port, an infrared port, an IEEE 1394 (\u201cFirewire\u201d) interface, an IEEE 802.11 wireless interface, a Bluetooth\u00ae wireless interface, and so forth.","A monitor\/view screen  or other type of display device may also be connected to system bus  via an interface, such as a video adapter . Video adapter  (or another component) may be or may include a graphics card for processing graphics-intensive calculations and for handling demanding display requirements. Typically, a graphics card includes a graphics processing unit (GPU), video RAM (VRAM), etc. to facilitate the expeditious display of graphics and performance of graphics operations. In addition to monitor , other output peripheral devices may include components such as speakers (not shown) and a printer , which may be connected to computer  via input\/output interfaces .","Computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computing device . By way of example, remote computing device  may be a personal computer, a portable computer (e.g., laptop computer, tablet computer, PDA, mobile station, etc.), a palm or pocket-sized computer, a watch, a gaming device, a server, a router, a network computer, a peer device, another network node, or another device type as listed above, and so forth. However, remote computing device  is illustrated as a portable computer that may include many or all of the elements and features described herein with respect to computer .","Logical connections between computer  and remote computer  are depicted as a local area network (LAN)  and a general wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, the Internet, fixed and mobile telephone networks, ad-hoc and infrastructure wireless networks, other wireless networks, gaming networks, some combination thereof, and so forth. Such networks and communications connections are examples of transmission media.","When implemented in a LAN networking environment, computer  is usually connected to LAN  via a network interface or adapter . When implemented in a WAN networking environment, computer  typically includes a modem  or other means for establishing communications over WAN . Modem , which may be internal or external to computer , may be connected to system bus  via input\/output interfaces  or any other appropriate mechanism(s). It is to be appreciated that the illustrated network connections are exemplary and that other means of establishing communication link(s) between computers  and  may be employed.","Furthermore, other hardware that is specifically designed for servers may be employed. For example, SSL acceleration cards can be used to offload SSL computations. Additionally, especially in a network load balancing operating environment, TCP offload hardware and\/or packet classifiers on network interfaces or adapters  (e.g., on network interface cards) may be installed and used at server devices.","In a networked environment, such as that illustrated with operating environment , program modules or other instructions that are depicted relative to computer , or portions thereof, may be fully or partially stored in a remote media storage device. By way of example, remote application programs  reside on a memory component of remote computer  but may be usable or otherwise accessible via computer . Also, for purposes of illustration, application programs  and other processor-executable instructions such as operating system  are illustrated herein as discrete blocks, but it is recognized that such programs, components, and other instructions reside at various times in different storage components of computing device  (and\/or remote computing device ) and are executed by processor(s)  of computer  (and\/or those of remote computing device ).","Although systems, media, devices, methods, procedures, apparatuses, techniques, schemes, approaches, procedures, arrangements, and other implementations have been described in language specific to structural, logical, algorithmic, and functional features and\/or diagrams, it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or diagrams described. Rather, the specific features and diagrams are disclosed as exemplary forms of implementing the claimed invention."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The same numbers are used throughout the drawings to reference like and\/or corresponding aspects, features, and components.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIGS. 8A and 8B"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIGS. 9A and 9B"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 13A","FIG. 12"]},{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 13B","FIG. 12"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 15","FIG. 12"]},{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 16","FIG. 12"]},{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIGS. 17A and 17B","FIG. 13A","FIG. 13B"]},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 23A","FIG. 20"]},{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 23B","FIG. 22"]},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 31"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 37"},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 38"},{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 39"},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 40"}]},"DETDESC":[{},{}]}
