---
title: System and method for collaboration summarization playback
abstract: A system for collaboration summarization playback includes a graphical user interface () for displaying summarization categories () associated with recording cues and clips of the multimedia conference. The categories may be arranged as a list or as thumbnails and typically includes a length of time for each category; a time during the conference when the associated clip was recorded; and a media type. The categories are clickable and allow the associated clip to be played or displayed as recorded. In addition, in certain embodiments, a voice recognition transcription of audio clips may be provided.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07545758&OS=07545758&RS=07545758
owner: Siemens Communications, Inc.
number: 07545758
owner_city: Boca Raton
owner_country: US
publication_date: 20021211
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF EMBODIMENTS OF THE INVENTION"],"p":["The present invention relates to telecommunications systems and, in particular, to an improved system and method for messaging collaboration summarization.","The development of various voice over IP protocols such as the H.323 Recommendation and the Session Initiation Protocol (SIP) has led to increased interest in multimedia conferencing. In such conferencing, typically, a more or less central server manages the conference and maintains the various communications paths. Parties to the conference are able to communicate via voice and\/or video through the server.","Instant messaging can provide an added dimension to multimedia conferences. In addition to allowing text chatting, instant messaging systems such as Microsoft Windows Messenger can allow for transfer of files, document sharing and collaboration, collaborative whiteboarding, and even voice and video.","As can be appreciated, a complete multimedia conference can involve multiple voice and video streams, the transfer of many files, and much marking-up of documents and whiteboarding. On occasion, an individual who is not a party to all or part of the conference may nevertheless find it necessary to review what was said. While a messaging server or individual clients may be able to record or store an entirety of such a conference, the reviewing party may not wish to replay the entire meeting, including all the irrelevant comments and dead ends typical in any multiparty collaboration.","As such, there is a need for a system and method for easily reviewing a multimedia conference. There is a further need for a system and method for accessing particular portions of a multimedia conference upon review.","These and other drawbacks in the prior art are overcome in large part by a system and method according to embodiments of the present invention.","A telecommunications system according to an embodiment of the present invention includes a network and a multimedia server operably coupled to the network. The multimedia server is adapted to manage a multimedia conference and includes a memory for storing selectable portions of the multimedia conference. The system further includes one or more client devices operably coupled to the network and adapted to set recording cues for choosing portions of said multimedia conference for playback. The multimedia server or clients may include a voice recognition system for transcribing audio portions of the conference. The voice recognition system may further be used to detect instances of the recording cues.","A method according to an embodiment of the present invention includes storing a plurality of recording cues adapted for marking a predetermined time period around which a portion of a multimedia conference is to be recorded; and capturing sequentially portions of the multimedia conference responsive to execution of the recording cues. The recording cues may be audio cues or may be whiteboard or document identifiers.","A telecommunications server according to an embodiment of the present invention is adapted to store or record a multimedia conference. In addition, the server may store a plurality of predetermined recording cues, settable by a user. The recording cues may include voice recording cues, recognizable by a voice recognition unit, or may include text or whiteboard identification recording cues. When the cues are identified, a predetermined amount of the conference is tagged or stored for summary play later. In addition, a percentage match when tags are identified may be assigned, such that the summary may be played back later based on the likelihood of a match.","A system for collaboration summarization playback according to an embodiment of the present invention includes a graphical user interface for displaying summarization categories associated with recording cues and clips of the multimedia conference. The categories may be arranged as a list or as thumbnails and typically includes a length of time for each category; a time during the conference when the associated clip was recorded; and a media type. The categories are clickable and allow the associated clip to be played or displayed as recorded. In addition, in certain embodiments, a voice recognition transcription of audio clips may be provided.","A method according to an embodiment of the present invention includes recording a multimedia conference and associating portions thereof with one or more categories derived from recording cues. The method further includes making the portions accessible for selective playback via a user interface. This can include identifying a media type and a time associated with each portion. Further, the method includes playing back the portions responsive to a selection in the original media type or by a text transcription.","A better understanding of these and other specific embodiments of the invention is obtained when the following detailed description is considered in conjunction with the following drawings.","Turning now to the drawings and, with particular attention to , a diagram of an exemplary telecommunications system  according to an embodiment of the present invention is shown. As shown, the telecommunications system  includes a local area network (LAN) . The LAN  may be implemented using a TCP\/IP network and may implement voice or multimedia over IP using, for example, the Session Initiation Protocol (SIP). Operably coupled to the local area network  is a server . The server  may include one or more controllers , which may be embodied as one or more microprocessors, and memory  for storing application programs and data. The controller  implements an instant messaging system . The instant messaging system may be embodied as Microsoft Windows Messenger or other instant messaging system. Thus, according to certain embodiments of the present invention, the instant messaging system  implements the Microsoft .Net environment  and Real Time Communications protocol (RTC) .","In addition, according to embodiments of the present invention, a collaboration system  may be provided, which may be part of an interactive suite of applications , run by controller , as will be described in greater detail below.","Also coupled to the LAN  is a gateway  which may be implemented as a gateway to a private branch exchange (PBX), the public switched telephone network (PSTN) , or any of a variety of other networks, such as a wireless or cellular network. In addition, one or more LAN telephones -and one or more computers -may be operably coupled to the LAN .","The computers -may be personal computers implementing the Windows XP operating system and thus, Windows Messenger. In addition, the computers -may include telephony and other multimedia messaging capability using, for example, peripheral cameras, microphones and speakers (not shown) or peripheral telephony handsets , such as the Optipoint handset, available from Siemens Corporation. In other embodiments, one or more of the computers may be implemented as wireless telephones, digital telephones, or personal digital assistants (PDAs). Thus, the figures are exemplary only. As shown with reference to computer , the computers may include one or more controllers , such as Pentium-type microprocessors, and storage  for applications and other programs.","Finally, the computers -may implement Interaction Services -according to embodiments of the present invention. As will be described in greater detail below, the Interaction Services -allow for interworking of phone, buddy list, instant messaging, presence, collaboration, calendar and other applications. In addition, according to embodiments of the present invention, the Interaction Services  allow access to the collaboration summarization module  of the server  and thus permit the user to access and manipulate conference summaries.","Turning now to , a functional model diagram illustrating collaboration system  is shown. More particularly,  is a logical diagram illustrating a particular embodiment of a collaboration server . The server  includes a plurality of application modules  and a communication broker module . One or more of the application modules and communication broker module  may include an inference engine, i.e., a rules based artificial intelligence engine for implementing functions according to the present invention, as will be described in greater detail below. In addition, the server  provides interfaces, such as APIs (application programming interfaces) to SIP phones  and gateways\/interworking units .","According to the embodiment illustrated, the broker module  includes a basic services module , an advanced services module , an automation module , and a toolkit module .","The basic services module  functions to implement, for example, phone support, PBX interfaces, call features and management, as well as Windows Messaging and RTC add-ins, when necessary. The phone support features allow maintenance of and access to buddy lists and provide presence status.","The advanced services module  implements function such as presence, multipoint control unit (MCU), recording, and the like. MCU functions are used for voice conferencing and support ad hoc and dynamic conference creation from a buddy list following the SIP conferencing model for ad hoc conferences. In certain embodiments, support for G.711 and G.723.1 codecs is provided. Further, in certain embodiments, the MCU can distribute media processing over multiple servers using the MEGACO protocol.","Presence features provide device context for both SIP registered devices and user-defined non-SIP devices. Various user contexts, such as In Meeting, On Vacation, In the Office, etc., can be provided for. In addition, voice, e-mail and instant messaging availability may be provided across the user's devices. The presence feature enables real time call control using presence information, e.g., to choose a destination based on the presence of a user's devices. In addition, various components have a central repository for presence information and for changing and querying presence information. In addition, the presence module provides a user interface for presenting the user with presence information.","In addition, the broker module  may include the ComResponse platform, available from Siemens Information and Communication Networks, Inc. ComResponse features include speech recognition, speech-to-text, and text-to-speech, and allow for creation of scripts for applications. The speech recognition and speech-to-text features may be used by the collaboration summarization unit , as will be discussed in greater detail below.","In addition, real time call control is provided by a SIP API  associated with the basic services module . That is, calls can be intercepted in progress and real time actions performed on them, including directing those calls to alternate destinations based on rules and or other stimuli. The SIP API  also provides call progress monitoring capabilities and for reporting status of such calls to interested applications. The SIP API  also provides for call control from the user interface.","According to the embodiment illustrated, the application modules include a collaboration module , an interaction center module , a mobility module , an interworking services module , and a collaboration summarization module .","The collaboration module  allows for creation, modification or deletion of a collaboration session for a group of users. The collaboration module  may further allow for invoking a voice conference from any client. In addition, the collaboration module  can launch a multi-media conferencing package, such as the WebEx package. It is noted that the multi-media conferencing can be handled by other products.","The interaction center  provides a telephony interface for both subscribers and guests. Subscriber access functions include calendar access and voicemail and e-mail access. The calendar access allows the subscriber to accept, decline, or modify appointments, as well as block out particular times. The voicemail and e-mail access allows the subscriber to access and sort messages.","Similarly, the guest access feature allows the guest access to voicemail for leaving messages and calendar functions for scheduling, canceling, and modifying appointments with subscribers. Further, the guest access feature allows a guest user to access specific data meant for them, e.g., receiving e-mail and fax back, etc.","The mobility module  provides for message forwarding and \u201cone number\u201d access across media, and message \u201cmorphing\u201d across media for the subscriber. Further, various applications can send notification messages to a variety of destinations, such as e-mails, instant messages, pagers, and the like. In addition, the subscriber can set rules that the mobility module  uses to define media handling, such as e-mail, voice and instant messaging handling. Such rules specify data and associated actions. For example, a rule could be defined to say \u201cIf I'm traveling, and I get a voicemail or e-mail marked Urgent, then page me.\u201d","Further, as will be explained in greater detail below, the collaboration summarization module  is used to identify or highlight portions of a multimedia conference and configure the portions sequentially for later playback. The portions may be stored or identified based on recording cues either preset or settable by one or more of the participants in the conference, such as a moderator. As will be explained in greater detail below, the recording cues may be based on vocalized keywords identified by the voice recognition unit of the ComResponse module, or may be invoked by special controls or video or whiteboarding or other identifiers.","Turning now to , a diagram of a graphical user interface  according to embodiments of the present invention is shown. In particular, shown are a variety of windows for invoking various functions. Such a graphical user interface  may be implemented on one or more of the network clients. Thus, the graphical user interface  interacts with the Interactive Services unit  to control collaboration sessions.","Shown are a collaboration interface , a phone interface , and a buddy list . It is noted that other functional interfaces may be provided. According to particular embodiments, certain of the interfaces may be based on, be similar to, or interwork with, those provided by Microsoft Windows Messenger or Outlook.","The buddy list  is used to set up instant messaging calls and\/or multimedia conferences. The phone interface  is used to make calls, e.g., by typing in a phone number, and also allows invocation of supplementary service functions such as transfer, forward, etc. The collaboration interface  allows for viewing the parties to a collaboration and the type of media involved. It is noted that, while illustrated in the context of personal computers , similar interfaces may be provided the telephones or cellular telephones or PDAs.","As noted above, an aspect of the present invention allows selective summarization based on recognition of recording cues.  is a diagram schematically illustrating collaboration summarization according to an embodiment of the present invention. More particularly, shown are a plurality of media streams representative of, for example, a multimedia conference between multiple parties. Shown are a whiteboard stream , an audio stream , a video stream , and an instant messaging stream . It is noted that, in practice, more or fewer of such data streams may be present. Thus, the figure is exemplary only.","Also shown in  is a time scale  showing a time T. The time T represents, for example, a duration of the conference and hence the period required to review the conference in its entirety once it has been recorded. According to the present invention, however, a participant in the conference, such as a designated moderator, can set and activate or invoke a recording cue, which causes the collaboration summarization system to either mark predetermined periods on the recorded conference or save predetermined periods as a separate summary file. As shown in , at a time Ta, a user activates a recording cue . A period  of the conference is then either marked or stored in memory  for later playback as part of a collaboration summary. Similarly, at time Tb, another recording cue is activated and a period  is then either marked or stored for later playback as part of a collaboration summary. As seen at , the result on playback is a summary of the multimedia conference of duration T.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 5A","FIG. 5B","FIG. 5C"],"b":["5000","5002","5004","5006","5000","128","122","114","104"]},"As shown in , a moderator may set recording cues or keywords for later use in a conference. At , the moderator speaks or otherwise enters the desired recording cue. For example, the moderator may set phrases such as \u201cAction Item,\u201d \u201cA decision has been reached,\u201d \u201cWe have a consensus,\u201d \u201cOur next meeting will be . . . \u201d and the like. The computer's sound system will receive the cue and display it at  on the graphical user interface of . In other embodiments, the user can type in a recording cue that will be recognized either from the speech unit of the ComResponse platform or from transcribed text. Alternatively, the user may define a particular entry into whiteboard or instant messaging windows as the recording cue. For example, the moderator may indicate that an R in the whiteboard window means that the contents should be recorded. Alternatively, an X through it should indicate it should not. The user than has an option of accepting or rejecting the cue, by selecting the buttons ,  (). If rejected, the user can re-try. If accepted, the collaboration summarization system  will then record the cue at (e.g., store it in a database in memory ) and monitor the conference for instances of the cue at , as will be explained in greater detail below. It is noted that an accept\/reject option may also be provided for video or other cues, as well.","In addition to, or instead of, the moderator setting the recording cues, in certain embodiments, the recording cues may be set by the individual users prior to beginning the conference. This may be particularly useful if, for example, a voice response system needs to learn the voices of various participants. As shown in , at step , the system may connect the conferees and enter a training mode. In the training mode, while the users may be connected to the server, they are not necessarily connected to one another. At step , the users may each set their cues, in a manner similar to that described above with reference to  and . The training mode may allow, for example, the users to each set various phrases as recording cues and may allow the system to establish a personalized summary of the conference, keyed to the person who made the cue. At step , the system stores the cues in memory  for use during the conference and then connects the users.","Signaling for exemplary system recording cue training is shown in . Shown are a server  and a client , which may represent the conference moderator or a participant. At , the client  requests and receives access to the server  for a media session. This can include, for example, a SIP INVITE, RINGING, OK sequence, for example. At , the server  and the client  open a media channel and the client  accesses the collaboration system . At , the client  uploads the recording cue. As discussed above, this can include a voice or video cue, or whiteboard, etc., markup. At , the collaboration system  downloads a confirmation of the recording cue and stores it. For example, it may convert the speech to text and download the text, or may store and analyze the cue and repeat it back, for confirmation. If the cue is appropriately confirmed, then at , the client  sends an acknowledge.",{"@attributes":{"id":"p-0065","num":"0064"},"figref":["FIG. 6A","FIG. 6B","FIG. 6A","FIG. 6B"],"b":["6000","6000","6000","6000","6002","6004","6006","6006"],"i":["a","b","c","a "]},"Turning now to , at , the conference begins, with the users all connected via the server, using various media. As noted above, such a conference can include various combinations of media such as voice, video, Instant Messaging, application sharing, whiteboarding, and the like. At , the collaboration system records the entirety of the multimedia conference, including all threads and media, by storing it in memory . Further, in certain embodiments, the collaboration system activates a speech-to-text unit, e.g., the ComResponse platform, to transcribe all speech from the voice and video channels, which is also stored in association with the conference in memory . The window  () may be used to display the transcription. At , the moderator or one of the users activates one of the recording cues. The recording cue may be activated, for example, by the user or moderator speaking it or by marking the whiteboard or other document being collaborated on. Alternatively, in certain embodiments, the recording cue may be activated by selecting a button or key associated with the client. For example, with reference to , the user may activate the button ; or may draw the X  in the whiteboarding window ; or may activate the Record button  of the chat\/shared application window . The invoking of the recording cue may occur by the moderator or party formally invoking it, or by the system \u201cpicking up\u201d the use of it during the conference.","In response, at  (), the collaboration summarization system  either marks the point on the master recording of the conference where the cue was invoked for later playback, or stores in a separate file the associated passage, also for later playback. In either case, the conference portion pertinent to the cue is designated for later playback. In certain embodiments, the summarization is stored or marked or categorized by the party who has invoked the cue. In such an embodiment, a moderator may maintain a master summarization record. In other embodiments, the summarization occurs on a singular basis\u2014i.e., only one summarization is performed, regardless of the invoking party. Finally, at step , a match or relevance probability is set in association with the marked or recorded summarization portion of the conference. Any of a variety of probability matching methods may be employed. In this manner, each part of the conference is captured, separated and marked with a probability of its relevance.",{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 6C","b":["122","122","122","6500","104","6502","6504","104","6506","6508","6510","122","122","104","6512","104","114","6514","114","114","6518"],"i":["a","b ","c","a","c "]},{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIG. 7A","FIG. 7B","FIG. 7A","FIG. 7B"],"b":"7000"},"As shown in , the interface includes a conference list  listing conferences that have been saved and summarized; one or more viewing windows ; a play button ; a relevance probability entry field ; and training buttons .","Turning now to , at step , the user desiring a summary will activate a summary function using his GUI , for example, by selecting the conference from the conference window  and selecting the play button . In certain embodiments, a default match percentage will be used to deliver the summary. In other embodiments, the user can designate a percentage match threshold using the match field \u2014for matches to the cue higher than the threshold, the system will play back a summary. As noted above, in certain embodiments, this can be embodied as playing back a single file containing all media above the threshold, or can be embodied as accessing a single broad summary file with relevant passages at the desired percent match marked. At , the system will access the stored conference and play back the summary according to the percent match.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 7C","b":["122","104","7500","122","104","7502","7504","7506","104","103"]},"As noted above, the system can be trained to recognize cues prior to the start of a conference.  illustrates another way of training the system. More particularly, a user can activate approval indicia, such as \u201cthumbs up\u201d or \u201cthumbs down\u201d (or good-bad) buttons when playing back his selected summary. That is, each time the user detects an inaccuracy on behalf of the system, he can select the \u201cthumbs down\u201d button and each time he is satisfied, he can push the \u201cthumbs up\u201d button. This is interpreted by the system and can be used when the same scenario occurs in the future. Such good-bad buttons  are illustrated in .","Operation of this training method is illustrated more particularly with reference to . In particular, at , the user elects to playback the selected summary. At , the user presses the \u201cthumbs up\u201d or \u201cthumbs down\u201d buttons to indicate approval or disapproval. At , the system stores the approval-disapproval after identifying the context. The knowledge can then be used on subsequent occasions when the context occurs again. That is, the collaboration system  can learn whether a cue was correctly detected as having been invoked. Thus, the next time a cue is determined to be invoked, the system can check both its database of \u201cuser-set\u201d cues and cross-reference its record of \u201clearned\u201d probabilities. Further, such training can be used by the collaboration summarization system  to search through and update other stored summarizations, if desired.","As noted above, the summarization can be stored by the system either as a completely separate file or as indices marking \u201cpoints\u201d on the complete conference recording. This is illustrated more particularly with reference to . Shown in  is a file representing the complete recorded conference. Also shown are files , representing one or more recorded summaries of the conference. In certain embodiments, each file represents a complete summary based on a particular user's automatic or deliberate invocation of recording cues. In certain embodiments, only one such file will be created (i.e., based on the moderator's cuing). Alternatively, each file can represent a complete summary based on a percent match with the recording cue.",{"@attributes":{"id":"p-0076","num":"0075"},"figref":"FIG. 9B","b":["900","902","1","902","2","902","3","902","4","900"],"i":["b ","b","b","b","b","b"]},"As noted above, an aspect of the present invention relates to providing an interface for accessing a collaboration summary. In one embodiment for accessing, the summarized portions of a conference can be stored according to summarization categories. In certain embodiments, the recording cues themselves may for the category indices.","Turning now to , a diagram of an exemplary graphical user interface  according to an embodiment of the present invention is shown. Typically, the graphical user interface  is generated in conjunction with the Interactive Services module  and Collaboration Summarization module . In the embodiment illustrated, the graphical user interface for playback  includes a plurality of category headings -, representative of, for example, Action Items, Decisions, Items on Hold, Summaries, and Open Items. It is noted that this list of categories is not comprehensive and is exemplary only. Associated with each of the categories -are one or more thumbnails -, respectively. Each of the thumbnails is representative of a portion or a clip from the multimedia conference. In certain embodiments, displayed with the thumbnails is an indication of the media type, size, and time of and associated with the clip. It is noted that, while in the embodiment illustrated the categories are displayed as thumbnails, the categories and associated information could be displayed, for example, as a scrollable or dropdown list, or other arrangement. Also, certain embodiments may include a timeline  to allow a visualization of where each of the associated clips occurs during the conference. Thus, as shown, time indicia for thumbnail clips  and  are displayed on the timeline. This allows the user to better distinguish among clips in the same category. In operation, as will be discussed in greater detail below, the user can click on one of the thumbnails to view the associated portion of the conference. The graphical user interface  may further include a relevance probability entry window . This allows the user to specify both a category and a relevance probability for summary viewing.","The category headings can be settable by a user and associated with one or more recording cues, also settable by the user. More particularly, shown in  are exemplary categories and associated recording cues. In particular, shown at  is a category \u201cAction Item,\u201d with associated cues  \u201cAction Item,\u201d \u201cNeed to Implement,\u201d \u201cProgress must be made,\u201d and \u201cOf utmost urgency.\u201d It is noted that these are exemplary only. Similarly, an exemplary category \u201cDecisions\u201d  is shown, with associated recording cues  \u201cWhen,\u201d \u201cHow Much.\u201d","In operation, the user can define the categories (or have default categories provided) and then set associated recording cues. Signaling for this is illustrated more particularly with reference to . Shown are a client  and server . At , the client logs in. This can include, for example, logging in via a Web page access portal. At , the server  provides a default list of categories. This may include, for example, the presentation of a Web page having a form using CGI-BIN script. At , the user can be provided with an option to change the categories, and transmit the changes to the server . At , the user can provide recording cues, in a manner similar to that discussed above, and also associate them with the appropriate categories. It is noted that providing the recording cues and providing the categories need not necessarily occur in the same session. Finally, at , the server  stores the category\/cue lists in memory  and can use them for the designated conference.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 13","b":["1302","104","1304","104","103","1306","104","114","1308","114","1310","114","1312","114"]},{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIG. 14","FIG. 14","FIG. 10"],"b":["122","104","1402","122","104","1404","104","1406","122","114","1408","104","1410","114"]},"As noted above, in certain embodiments, the user can enter a relevance probability in addition to a category when accessing a summary. This is illustrated more particularly with reference to the flowchart of . At step , the collaboration summarization module receives the category selection from the user. The collaboration summarization module  may then prompt the user for a relevance probability, which can be entered at step . For example, the probability can be entered using control  while the category can be selected by clicking on one of the categories. The collaboration summarization module  then searches in the category for all stored conference portions have that relevance probability or higher, and displays them at step .","An additional aspect of embodiments of the present invention makes use of the text to speech capabilities of the ComResponse platform. More particularly, the ComResponse module is able to convert the Web page interface  to speech and allow the user to hear categories as voice prompts in an IVR function. The conference summary can then be accessed remotely via voice telephone, if the requesting party does not have Web access. This is illustrated more particularly in flowchart form in  and .","Turning now to , in step , after the conference and after the recording summary has been made, the collaboration summarization module  generates the control web page interface  from the user input categories (if any) and the detected recording cues, as described above. In step , the user or a moderator can invoke the ComResponse platform to generate a speech-based menu from the Web page. In step , the user or a moderator can invoke the ComResponse feature to generate a speech-based menu from the Web page. The result is a stored \u201clisting\u201d of the category headings from the Web page . In certain embodiments, identifiers of the individual records can also be converted to speech. In step , the system then uses this listing to be associated with an IVR (interactive voice response) type menu, with the categories being a first layer of prompts and the individual summary portions underneath the headings being a next layer of prompts. Alternatively, only the main categories can be rendered as speech; accessing the IVR choices then would cause the system to \u201cread\u201d the record portions associated with the heading serially. It is noted that, while the ComResponse system employs one type of text to speech, any suitable one may be employed.",{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 17","b":["1702","1704","1706"]},"Accessing such a menu is illustrated with reference to the flowchart of . In step , the accessing party dials in to an access telephone number and enters any appropriate access codes, etc. Once the accessing party has obtained access to the system, he can select a conference for review, for example via an interactive voice menu. In step , the system delivers or presents to voice menu associated with the conference that has been rendered as discussed above. Finally, in step , the accessing party can access the desired summary portion or portions by selecting the category or otherwise navigating the IVR menu. In certain embodiments, the IVR menu may also give the user the option of keying in a relevance probability in a manner similar to that described above.",{"@attributes":{"id":"p-0088","num":"0087"},"figref":"FIG. 18","b":["104","116","118","118","1802","116","104","1804","1804","1806","104","116","1808","116","1810","104","1812","1814","1816","114","1818","104","1820","1822"]},"The invention described in the above detailed description is not intended to be limited to the specific form set forth herein, but is intended to cover such alternatives, modifications and equivalents as can reasonably be included within the spirit and scope of the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 5A","FIG. 5B"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5C"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5D"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 6C"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 7B"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 7C"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 9A","FIG. 9B"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 16A","FIG. 16B"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 18"}]},"DETDESC":[{},{}]}
