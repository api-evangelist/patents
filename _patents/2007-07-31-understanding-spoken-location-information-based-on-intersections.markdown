---
title: Understanding spoken location information based on intersections
abstract: In one embodiment, the present system recognizes a user's speech input using an automatically generated probabilistic context free grammar for street names that maps all pronunciation variations of a street name to a single canonical representation during recognition. A tokenizer expands the representation using position-dependent phonetic tokens and an intersection classifier classifies an intersection, despite the presence of recognition errors and incomplete street names.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07983913&OS=07983913&RS=07983913
owner: Microsoft Corporation
number: 07983913
owner_city: Redmond
owner_country: US
publication_date: 20070731
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["There are currently a wide variety of different types of geographic data and graphic software available. For instance, many people have access to digital maps, and mapping software, that facilitates the creation and use of digital maps.","The availability of such digital maps and mapping software has given rise to an industry devoted to location-based software and services. Such software and services provide functionality based on a specified geographic location. For instance, some examples of location-based software and services include route planning software, navigation software, and services that locate nearby businesses, such as restaurants, gas stations, etc.","Some location-based software and services, although they have conventionally been deployed on desktop computers, are being deployed on mobile devices and embedded computers (such as those found in automobiles). In these applications, it can be very important to provide the user with a way for easily inputting locations to the system.","Mobile devices and embedded computers often have very small screens and are used in environments in which it may be undesirable to have the user pay particularly close attention to the mobile device or embedded computer. For instance, some such computers are used while driving. Driving, of course, is a hands-busy\/eyes-busy environment, and it would be undesirable to require a user to use certain input modes on a computer (such as typing, mouse inputs, or stylus inputs) while driving.","Other types of input modes, however, are relatively safe. Speech, for instance, is a safe and natural input mode that can be used for inputting location information into such location-based software and services.","There are some difficulties, however, in specifying a location using speech. Locations can be conveyed by the user in several ways. For example, a business or point of interest can be used to indicate a location if the corresponding address is known. However, this only works for unique businesses or points of interest, and does not work for chain businesses or residences. For example, asking for directions to \u201cACME Coffee Company\u201d may be highly ambiguous, especially if AMCE Coffee Company is a chain establishment, having many stores. There may be many ACME Coffee Company stores in a given city, and often more than one on a single street.","Specifying a full street address on the other hand, nearly always corresponds to a unique location. Unfortunately, however, using the street address is difficult in practice because of recognition errors, especially when using a speech recognizer that only performs a single recognition pass. For example, when one considers that the state-of-the-art recognition accuracy for a five-digit number in noisy conditions (often found in driving) is approximately 90 percent, this means that one out of ten house numbers or zip codes will be misrecognized. In such cases, the disambiguation strategies used to correct these errors must often resort to tedious digit-by-digit confirmation.","The discussion above is merely provided for general background information and is not intended to be used as an aid in determining the scope of the claimed subject matter.","A user can specify an intersection as a way to convey an exact location to a spoken dialog system. Intersections have many advantages over conventional methods of location entry. They are quite natural and often used to convey location in human-to-human communication. In addition, it may be easier for a user to determine the nearest intersection than to determine the nearest valid street address, while driving. Similarly, because an intersection has two streets, there are a limited number of ways an intersection can be misrecognized. Either one of the two streets is misrecognized, or both are misrecognized. This makes disambiguation potentially much simpler compared to a street address. Further, if intersections can be recognized reliably, users can uniquely identify an otherwise ambiguous point of interest with a reference intersection, such as \u201cACME Coffee Company on the corner of Pine Street and Third.\u201d","Of course, recognizing intersections reliably is a challenging problem in itself. In major cities, there can be thousands of street names and many more intersections. For example, in the city of Seattle, there are over 3500 unique street names and over twenty thousand intersections. In addition, streets and intersections are often spoken informally with incomplete specifications using a variety of different pronunciations.","In one embodiment, the present system recognizes a user's speech input using an automatically generated, probabilistic, context free grammar for street names that maps all pronunciation variations of a street name to a single canonical representation during recognition. A tokenizer expands the representation using position-dependent phonetic tokens and an intersection classifier classifies an intersection, despite the presence of recognition errors and incomplete street names.","This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter. The claimed subject matter is not limited to implementations that solve any or all disadvantages noted in the background.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1","b":["100","100","102","102","102","104","102","104","102","106","108","110"]},"There is a high degree of variability in the way people refer to street names. For example, users may use a partial street name, either out of familiarity or convenience. One example of this is \u201cthe gas station on 148.\u201d Of course, the term \u201c148\u201d does not fully specify a street name but is only a partial street name. Similarly, a user may not know or remember the complete street name or the order of the terms in the street name. Examples of this include \u201c5Avenue South\u201d and \u201cSouth 5Avenue\u201d, \u201c5Avenue\u201d and even \u201c5\u201d.","Intersection understanding system  illustratively includes an automatic speech recognition system. In order to recognize the different variations in street name pronunciations robustly, a rich, probabilistic, context free grammar that captures the variety of ways people refer to streets is first automatically generated.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 2","FIG. 3","FIGS. 2-3"],"b":["120","120","122","124","126","128","130","132","120"]},"Geographic database  is illustratively a database that contains all street names and intersections in a given city. The street names follow conventional address abbreviations, such as standard street suffix (e.g., St., Ave, Ln.) and compass directions (e.g., N, S, NE, SW). Parsing component  extracts the individual street names and intersections from database  and parses each into a sequence of entities using regular expressions based on a set of rules. In one illustrative example, the set of rules are hand written rules used to perform the parsing. The parsing rules accessed by parsing component  are also illustrated at  in .","Table 1 shows a list of entities and a list of what examples for those entities might be. For instance, the entity \u201cInterstatePrefix\u201d may be \u201cI\u201d or \u201cUS\u201d. Similarly, the entity \u201cHighwayPrefix\u201d may be \u201cHwy\u201d, \u201cSR\u201d, \u201cRoute\u201d, etc. Parsing the street names into these entities is illustrated by block  in . The entities are shown at  in .",{"@attributes":{"id":"p-0027","num":"0026"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"91pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Street Entity","Examples"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"<InterstatePrefix>","I, US"]},{"entry":[{},"<HighwayPrefix>","Hwy, SR, Route"]},{"entry":[{},"<CardinalAlpha>","9A"]},{"entry":[{},"<AlphaCardinal>","A101"]},{"entry":[{},"<Cardinal>","101, 5, 90"]},{"entry":[{},"<Ordinal>","148, 3"]},{"entry":[{},"<Direction>","N, S, NE, SW"]},{"entry":[{},"<StreetType>","Ave, Ln, St, Ct"]},{"entry":[{},"<TextName>","Main, Ashbury"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"Once parsing component  has labeled each of the street names  with the entities, enumeration component  enumerates all possible variations of the full street name, in one embodiment using a graph-based representation.  shows one embodiment of a graph representation  for the term \u201c148Ave NE\u201d. The graph  is constructed such that all paths in the graph constitute a valid pronunciation of the street name. A valid street name may, for example, be required to include a cardinal, ordinal, alpha cardinal, cardinal alpha, or text name, while all other labels such as direction, street suffix, and highway prefix can be skipped. Using enumeration component  to generate the enumeration graph and enumerate all paths in the graph is indicated by block  in .","Once all of the graphs are enumerated, the utterance corresponding to each path through each graph is extracted, text normalized and added to the grammar. For each valid path, additional utterances are also illustratively generated by utterance generator . The additional utterances correspond to alternate pronunciations and common prefix substitutions for the given path. This frequently occurs for ordinal street names. For instance, \u201c140\u201d can be pronounced \u201cone hundred and fortieth\u201d, \u201cone fortieth\u201d, \u201ca hundred fortieth\u201d, etc. This also happens for highways, where a variety of prefixes such as \u201cI\u201d, \u201cInterstate\u201d, or \u201cHighway\u201d are common. An example of the various pronunciations generated for the path \u201c148Ave NE\u201d shown in  is illustrated in the right hand side of Table 2. The various utterances for each entity in the path, generated by utterance generator , are illustrated by  in , and extracting them is illustrated by block  in .",{"@attributes":{"id":"p-0030","num":"0029"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 2"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Semantic ID","Recognized Text"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"148Ave NE","one hundred and forty eighth avenue north east"]},{"entry":[{},{},"one hundred forty eighth avenue north east"]},{"entry":[{},{},"one forty eighth avenue north east"]},{"entry":[{},{},"a hundred and forty eighth avenue north east"]},{"entry":[{},{},"a hundred forty eighth avenue north east"]},{"entry":[{},"148Ave","one hundred and forty eighth avenue"]},{"entry":[{},{},"one hundred forty eighth avenue"]},{"entry":[{},{},"one forty eighth avenue"]},{"entry":[{},{},"a hundred and forty eighth avenue"]},{"entry":[{},{},"a hundred forty eighth avenue"]},{"entry":[{},"148NE","one hundred and forty eighth north east"]},{"entry":[{},{},"one hundred forty eighth north east"]},{"entry":[{},{},"one forty eighth north east"]},{"entry":[{},{},"a hundred and forty eighth north east"]},{"entry":[{},{},"a hundred forty eighth north east"]},{"entry":[{},"148","one hundred and forty eighth"]},{"entry":[{},{},"one hundred forty eighth"]},{"entry":[{},{},"one forty eighth"]},{"entry":[{},{},"a hundred and forty eighth"]},{"entry":[{},{},"a hundred forty eighth"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"Once all the utterance variations are generated, semantic mapper  maps each variation that correspond to a given path taken through the word graph to a common semantic identity. This is indicated by block  in . In one embodiment, the semantic identity is used as a semantic tag in a W3C standardized SRGS grammar. This is a known speech recognition grammar specification that is widely recognized. Of course, other standards could be employed as well. By mapping the various pronunciations to a semantic identity (or semantic tag) the recognition can be performed using a probabilistic context free grammar. This has advantages in that a large variety of possible street name pronunciations are collapsed down to a precise canonical representation.","The semantic identity for each of the various pronunciations shown in Table 2 are illustrated on the left column of Table 2. The pronunciations mapped to the semantic identities are represented by  in .","Because the grammar is quite large, adding prior probabilities to the entries in the grammar can significantly improve recognition accuracy over a simple uniform distribution. Therefore, prior probability generator  illustratively sets prior probabilities for streets based on the number of intersections of which the given street is a member. Therefore, long, busy streets will have many intersections, while smaller neighborhood streets will have significantly fewer. In order to assign the prior probabilities, once the grammar is generated, duplicate entries are counted and aggregated and their weights are combined. For example, both \u201c148Ave NE\u201d and \u201cNE 148PL\u201d will generate entries in the grammar as \u201c148\u201d so this entries weight is proportional to the sum of the weights of all streets with the root ordinal \u201c148\u201d. This increases the prior probability of a root ordinal which is shared across several street names. The result of this processing is the probabilistic context free street grammar  shown in . Generating the prior probabilities is indicated by block  in , and outputting the street grammar  for use in intersection understanding is indicated by block  in .","In order to recognize naturally spoken intersections, grammar  is embedded in another context free grammar  that captures typical ways of specifying an intersection, such as \u201cI am on the corner of <Street> and <Street>\u201d. This intersection CFG is then combined with a domain-independent N-gram filler model to generate a hybrid CFG\/N-gram grammar which is much more robust than a stand alone CFG, to variations in the grammar. In other words, the intersection CFG  models various ways of specifying an intersection, but leaves the street names as slots to be filled. The probabilistic street name CFG  is used to fill the street slots.","Also, in this way, the intersection grammar can be common to all cities or locations, and the appropriate street grammar can simply be loaded, as desired by the user.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIG. 4","FIG. 1","FIG. 4","FIG. 5","FIG. 4"],"b":["100","100","300","143","142","100","302","304","306","100"]},"In one embodiment, system  is deployed in a dialog system in which a dialog is conducted with the user. Therefore, prior to recognizing the location information, the dialog system first obtains city information from the user. The city information indicates a city of interest to the user. Obtaining the city information from the user is indicated by block  in .","Next, the speech recognition system  (or the dialog system) loads the street grammar (determined based on the city information received from the user) into the intersection grammar . This is indicated by block  in . It will be noted, of course, that a user may not know the exact boundary of a given city. Therefore, in one embodiment, a plurality of different street grammars, corresponding to the city denoted by the user, and other cities in close proximity to the denoted city, are also loaded into intersection grammar . For instance, in one embodiment, street grammars for all cities bordering the city specified by the user are located into intersection grammar . This is described in greater detail below.","In any case, once the appropriate street grammars  are loaded into intersection grammar , system  is ready to recognize a spoken intersection input  input by the user. Speech recognition system  is illustratively an automatic speech recognition system that receives and recognizes the user's input, or utterance, . This is indicated by block  in . Speech recognition system  uses the appropriate intersection grammar  with embedded street grammar  to recognize and parse the utterance to obtain a recognition hypothesis (and a corresponding semantic tag for that hypothesis) for each of the streets in the intersection. The recognition hypothesis with the semantic tags is indicated by block  in , and identifying the semantic identities (or tags) of the hypothesized streets is indicated by block  in .","However, it has been seen that there is a relatively high likelihood that the user uttered only a fragment of the complete street name. In addition, because of the high acoustic confusability among many street names, especially numeric streets, there is a relatively good chance that recognition errors may occur.","In one embodiment, in order to enable system  to recover from some misrecognitions, tokenization component  is used. Tokenization component  tokenizes numeric street names because it has been empirically observed that these are often the streets with the highest acoustic confusability.","Intersection database  contains a database of all the intersections, which are searched based on the tokenized recognition result from speech recognition system . Searching database  is described in greater detail below. However, for purposes of discussion of tokenization component , database , itself, is not discussed. Each numeric street name in database  is illustratively represented by a sequence of phonemes based on a standard speech recognition dictionary. In addition, each phoneme in the sequence is labeled with the digits position of its parent digit, where \u201c100\u201d marks the 100's place, \u201c10\u201d marks the 10's place, and \u201c1\u201d marks the 1's place. The phonemes of ordinal suffixes (st, rd, and th, etc.) are labeled with \u201c0\u201d. For example, the \u201c1\u201d in \u201c100\u201d is represented as follows: \u201cwahn\u201d, while \u201c8\u201d is transformed into \u201ceytth\u201d.","There are several advantages to this type of tokenization scheme. It enables the hypothesized numeric strings to be decomposed into a series of elements such that recognition errors remain local to the incorrect subword units. Also, by augmenting the phonemes with the position of the corresponding digit, sequence information is preserved, which allows downstream classification to separate digits which are acoustically identical, but semantically different, such as the 3 in \u201c300\u201d and the 3 in \u201c23\u201d. Table 3 compares the proposed position-dependent phonetic tokenization to two other common representations for three acoustically confusable entities \u201c30\u201d, \u201c38\u201d, and \u201c13\u201d.",{"@attributes":{"id":"p-0044","num":"0043"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"98pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 3"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":[{},{},"Position Dependent"]},{"entry":["Ordinal","Word","Phonemes"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["30","thirtieth","thertiyihth"]},{"entry":["38","thirty eighth","thertiyeytth"]},{"entry":["13","thirteenth","thertiynth"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"It can be seen that the phonetic similarity of the three entities is captured in the present tokenization scheme, but is missing from the ordinal and word-based representations. It can also be seen that the sequence information is retained, as the leading \u201cth\u201d is represented differently than the trailing \u201cth\u201d.","Prior to completing the discussion of tokenization component , a discussion of intersection search component (or classifier)  will now be undertaken for greater clarity. Suffice it to say, for now, that search component  receives a tokenized query from tokenization component  corresponding to a street name. Search component  then searches intersection database  to obtain intersections which include that street name.","In the embodiment discussed herein, intersection search component  is a street name classifier embodied as a vector space model (VSM). In some other current systems, a VSM is used for information retrieval of text documents. In such text information retrieval systems, the VSM will be first discussed in this context in order to enhance understanding of its use in the present system. Each document din a collection D is represented as a vector v, whose components represent the importance of particular terms in the document. The most commonly used values for the components in these vectors are based on Term Frequency-Inverse Document Frequency (TF-IDF), as follows:",{"@attributes":{"id":"p-0048","num":"0047"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["v","ij"]},"mo":"=","mrow":{"mrow":[{"msub":{"mi":["TF","ij"]},"mo":"\u00b7","mrow":{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["IDF","i"]}}}},{"mfrac":{"msub":[{"mi":["N","ij"]},{"mi":["N","j"]}]},"mo":"\u00b7","mrow":{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":"M","msub":{"mi":["M","i"]}}}}}],"mo":"="}}},{"mrow":{"mi":"Eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"1"}}]}}}},"br":{},"sub":["ij ","i ","j","j ","j","i ","i"]},"The TF-IDF score is composed of two terms, the term frequency (TF), which is the ratio of the number of occurrences of a word to the total number of words in the document, and inverse document frequency (IDF), which is the ratio of the total number of documents in a collection to the number of documents containing that word. Thus, for word win document d, TF-IDF is computed as:",{"@attributes":{"id":"p-0050","num":"0049"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","i"]},{"mi":["d","j"]}],"mo":","}}},{"mrow":{"mi":["cos","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"=","mfrac":{"mrow":[{"msub":[{"mi":["v","i"]},{"mi":["v","j"]}],"mo":"\u00b7"},{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mi":["v","i"]}},{"mo":["\uf605","\uf606"],"msub":{"mi":["v","j"]}}],"mo":"\u2062"}]}}],"mo":"="}},{"mrow":{"mi":"Eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"2"}}]}}}}},"If the two documents are identical, then S(di; dj)=1 and if the documents share no terms, then S(di; dj)=0. When a query q is made, it is treated as a document, and the appropriate vector vis created. Documents similar to the query can then be identified.","When the VSM is used as intersection search component  in the present system  (shown in ), streets can be thought of as documents, with words corresponding to the entities comprising a particular street's full name. For example, if the street names were used directly in the VSM, then \u201c148Ave NE\u201d would be represented by a vector with non-zero TF-IDF scores for the term \u201c148\u201d, \u201cAve\u201d, and \u201cNE\u201d. Therefore, using a VSM for intersection search component  helps to locate street names when only a partial street name is spoken by the user.","Returning now to the discussion of tokenization component , assume that the user's utterance is recognized and parsed, and the semantic identities, along with the recognition hypotheses of the two hypothesized streets or street fragments are generated as  in . Next, tokenization component  tokenizes the semantic tag for the first street entity s. This tokenization is performed according to the tokenization scheme used to generate intersection database , as discussed above. Tokenization of the semantic tag for the first street entity sgenerates a street query q( in ) corresponding to the first street in the hypothesis. The vector of TF-IDF scores is computed for query q(as set out in Eq. 1 above) and intersection search component  then compares the similarity of qto the first street of all intersections in database . This results in a ranked list of candidate intersections, based on the hypothesized first street s. The similarity is computed as set out in Eq. 2 above.","Tokenizing the semantic tag for street sto create query qis indicated by block  in , and executing the query to search for intersections with streets similar to sin them is indicated by block  in . Generating the ranked list of results (candidate intersections) based on the first street is indicated by block  in .","Tokenization component  then tokenizes the semantic tag of the second street sin the hypothesis, transforming it into a second query q. Intersection search component  is then used to calculate the TF-IDF vector scores for qand compute the similarity between sand all second streets in the previously generated list of candidate intersections (generated based on s). Performing the tokenization, generating the query, and generating the results based on the second query are indicated by blocks , and - in .","The overall score for each of the hypothesis intersections is then computed as the product of the VSM scores (generated by intersection search component ) of the two streets in the intersection. Thus, the score for intersection I is calculated as follows:\n\n()=()\u00b7()\u2003\u2003Eq. 3\n\nwhere the similarities S(q,d) and S(q,d) are computed using Eq. 2 above. Calculating the overall score for each intersection in the results is indicated by block  in .\n","In one embodiment, in order to reduce redundancy in intersection database , all intersections are represented once with an arbitrary street ordering. If a user refers to an intersection with the opposite ordering, it will not match an entry in the database. As a result, the above procedure for intersection search can be performed both with the original ordering and with the queries qand qswapped. Thus, the final hypothesized intersection can be identified by computing the scores as follows:",{"@attributes":{"id":"p-0058","num":"0057"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"I","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":[{"mi":"s","mn":"1"},{"mi":["d","i"]}],"mo":"="},{"msub":[{"mi":"s","mn":"2"},{"mi":["d","j"]}],"mo":"="}],"mo":","}}},{"munder":{"mrow":[{"mstyle":{"mtext":"arg"},"mo":"\u2062","mi":"max"},{"mi":["i","j"],"mo":","}]},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"mrow":[{"mrow":[{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"q","mn":"1"},{"mi":["d","i"]}],"mo":","}}},{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"q","mn":"2"},{"mi":["d","j"]}],"mo":","}}}],"mo":"\u00b7"},{"mrow":[{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"q","mn":"2"},{"mi":["d","i"]}],"mo":","}}},{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"q","mn":"1"},{"mi":["d","j"]}],"mo":","}}}],"mo":"\u00b7"}],"mo":","}}}],"mo":"="}},{"mrow":{"mi":"Eq","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"4"}}]}}}}},"The top scoring intersection, or a ranked list of candidate intersections, is then output as indicated by block  in , and the results themselves are indicated by block  in . Of course, as discussed above with respect to , the results can be returned to the user or output to another system (such as a navigation system, etc.) for further processing.","It has also been found that in densely populated areas, many users might believe themselves to be in one particular city when they are actually in a neighboring city. Therefore, in one embodiment, the intersections for all bordering cities are also searched in the intersection database . If an intersection is identified that is not in the city specified by the user, then a fixed penalty is applied to the VSM score generated by intersection search component , to reflect the fact that the intersection is outside the user's specified search area. The value of this penalty can be tuned using development data or it can be otherwise empirically set.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 6","FIG. 6"],"b":["600","200","602","604","100","606","608","610"]},"Memory  is implemented as non-volatile electronic memory such as random access memory (RAM) with a battery back-up module (not shown) such that information stored in memory  is not lost when the general power to mobile device  is shut down. A portion of memory  can be allocated as addressable memory for program execution, while another portion of memory  can be used for storage, such as to simulate storage on a disk drive.","Memory  includes an operating system , application programs  as well as an object store . During operation, operating system  is preferably executed by processor  from memory . Operating system  can illustratively be designed for mobile devices, and implements database features that can be utilized by applications  through a set of exposed application programming interfaces and methods. The location-based system (such as navigation systems, etc.) can be in application  for instance. The objects in object store  are maintained by applications  and operating system , at least partially in response to calls to the exposed application programming interfaces and methods.","Communication interface  represents numerous devices and technologies that allow mobile device  to send and receive information. The devices include wired and wireless modems, satellite receivers and broadcast tuners to name a few. In one embodiment, mobile device  can also be directly connected to a computer to exchange data therewith. In such cases, communication interface  can be an infrared transceiver or a serial or parallel communication connection, all of which are capable of transmitting streaming information.","Input\/output components  can include a variety of input devices such as a touch-sensitive screen, buttons, rollers, and a microphone as well as a variety of output devices including an audio generator, a vibrating device, and a display. The devices listed above are by way of example and need not all be present on mobile device . In addition, other input\/output devices may be attached to or found with mobile device .","Although the subject matter has been described in language specific to structural features and\/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 5","FIG. 4"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
