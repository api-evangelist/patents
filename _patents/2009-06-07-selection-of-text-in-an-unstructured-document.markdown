---
title: Selection of text in an unstructured document
abstract: Some embodiments provide a method for defining a selection of text in an unstructured document that includes a number of glyphs. The method identifies associated sets of glyphs and a reading order that specifies a flow of reading through the glyphs. The method displays the document. The method receives a start point and end point for a selection of text within the displayed document. The method defines a selection of text from the start point to the end point by using the identified sets of glyphs and intended flow of reading.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08352855&OS=08352855&RS=08352855
owner: Apple Inc.
number: 08352855
owner_city: Cupertino
owner_country: US
publication_date: 20090607
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CLAIM OF BENEFIT TO PRIOR APPLICATION","CROSS REFERENCE TO RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This application claims the benefit of U.S. Provisional Application 61\/142,329, entitled \u201cMethods and System for Document Reconstruction\u201d, filed Jan. 2, 2009, which is incorporated herein by reference.","This application is related to the following applications: U.S. patent application Ser. No. 12\/479,852, filed Jun. 7, 2009, now published as US 2010\/0174732; U.S. patent application Ser. No. 12\/479,843, filed Jun. 7, 2009, now issued as U.S. Pat. No. 8,261,186; U.S. patent application Ser. No. 12\/479,849, filed Jun. 7, 2009, now published as US 2010\/0174979; U.S. patent application Ser. No. 12\/479,850, filed Jun. 7, 2009, now published as US 2010\/0174980; U.S. patent application Ser. No. 12\/479,847, filed Jun. 7, 2009, now published as US 2010\/0174978; U.S. patent application Ser. No. 12\/455,866, filed Jun. 7, 2009, now published as US 2010\/0174985; U.S. patent application Ser. No. 12\/479,848, filed Jun. 7, 2009, now published as US 2010\/0174975; U.S. patent application Ser. No. 12\/479,842, filed Jun. 7, 2009, now published as US 2010\/0174976; and U.S. patent application Ser. No. 12\/479,844, filed Jun. 7, 2009, now published as US 2010\/0174982.","The invention is directed towards the selection of text in an unstructured document. Specifically, the invention is directed towards methods for defining a structured document from an unstructured document, for improving the efficiency of such processes, and for improving display of and interaction with structured documents.","Documents are often defined as nothing more than a collection of primitive elements that are drawn on a page at defined locations. For example, a PDF (portable document format) file might have no definition of structure and instead is nothing more than instructions to draw glyphs, shapes, and bitmaps at various locations.","A user can view such a document on a standard monitor and deduce the structure. However, because such a file is only a collection of primitive elements, a document viewing application has no knowledge of the intended structure of the document. For example, a table is displayed as a series of lines and\/or rectangles with text between the lines, which the human viewer recognizes as a table. However, the application displaying the document has no indication that the text groupings have relationships to each other based on the rows and columns because the document does not include such information. Similarly, the application has no indication of the flow of text through a page (e.g., the flow from one column to the next, or the flow around an embedded image), or various other important qualities that can be determined instantly by a human user.","This lack of knowledge about document structure will not always be a problem when a user is simply viewing the document on a standard monitor. However, it would often be of value to a reader to be able to access the file and edit it as though it were a document produced by a word processor, image-editing application, etc., that has structure and relationships between elements. Therefore, there is a need for methods that can reconstruct an unstructured document. Similarly, there is a need for methods that take advantage of such reconstructed document structure to idealize the display of the document (e.g., for small-screen devices where it is not realistic to display the entire document on the screen at once), or to enable intelligent selection of elements of the document.","In the modern world, more and more computing applications are moving to handheld devices (e.g., cell phones, media players, etc.). Accordingly, document reconstruction techniques must be viable on such devices, which generally have less computing power than a standard personal computer. However, document reconstruction often uses fairly computation and memory intensive procedures, such as cluster analysis, and the use of large chunks of memory. Therefore, there is further a need for techniques that allow for greater efficiency in document reconstruction generally, and cluster analysis specifically.","Different embodiments of the invention use different techniques for analyzing an unstructured document to define a structured document. In some embodiments, the unstructured document includes numerous primitive elements, but does not include structural elements that specify the structural relationship between the primitive elements and\/or structural attributes of the document based on these primitive elements. Accordingly, to define the structured document, some embodiments use the primitive elements of the unstructured document to identify various geometric attributes of the unstructured document, and then use the identified geometric attributes and other attributes of the primitive elements to define structural elements, such as associated primitive elements (e.g., words, paragraphs, joined graphs, etc.), tables, guides, gutters, etc., as well as to define the flow of reading through the primitive and structural elements.","As mentioned, some embodiments use primitive elements to identify various geometric attributes. For instance, some embodiments provide a method that identifies boundaries between sets of primitive elements and regions bounded by the boundaries. The method uses the identified regions to define structural elements for the document, and defines a structured document based on the primitive elements and the structural elements. In some embodiments, defining structural elements includes analyzing each region separately to create associations between sets of primitive elements in the particular region. In some embodiments, defining the structured document includes identifying hierarchical relationships between the identified regions.","Some embodiments provide a method that analyzes an unstructured document that includes numerous words, where each word is an associated set of glyphs and each glyph has location coordinates. The method identifies clusters of location values, where each location value is associated with one word, is a basis for word alignment, and is derived from the location coordinates of the glyphs of that word. Based on the identified clusters of location values, the method defines a set of boundary elements for the words that identify a set of alignment guides for the words. The method defines a structured document based on the glyphs and the defined boundary elements. Some embodiments also define at least one region of white space between a pair of boundary elements and further define the structured document based on the region of white space. Some embodiments identify the clusters of location values by using density clustering.","Some embodiments use the identified geometric attributes and other attributes of the primitive elements to define structural elements as well as to define the flow of reading through the primitive and structural elements. For instance, some embodiments provide a method that analyzes an unstructured document that includes numerous glyphs, each of which has a position in the unstructured document. Based on the positions of glyphs, the method creates associations between different sets of glyphs in order to identify different sets of glyphs as different words. The method creates associations between different sets of words in order to identify different sets of words as different paragraphs. The method defines associations between paragraphs that are not contiguous in order to define a reading order through the paragraphs. In order to create associations between different sets of words in order to identify different sets of words as different paragraphs, some embodiments create associations between different sets of words as different text lines, and create associations between different sets of text lines as different paragraphs.","Some embodiments provide a method that identifies boundaries between sets of glyphs and identifies that several of the boundaries form a table. The method defines a tabular structural element based on the table that includes several cells arranged in several rows and columns, where each cell includes an associated set of glyphs. Some embodiments identify that the boundaries form a table by identifying a set of boundaries that form a larger rectangular shape and several rectangular shapes contained within the larger rectangular shape. In some embodiments, at least some of the identified boundaries are inferred based on positions of the associated sets of glyphs that form the cells.","Some embodiments provide a method for analyzing an unstructured document that includes numerous primitive graphic elements, each of which is defined as a single object. The document has a drawing order that indicates the order in which the primitive graphic elements are drawn. The method identifies positional relationships between successive primitive graphic elements in the drawing order. Based on the positional relationships, the method defines a single structural graphic element from several primitive graphic elements. Some embodiments identify a positional relationship between a first and second primitive graphic element that are subsequent in the drawing order by calculating a size of a structural graphic element that includes the first and second primitive graphic elements.","Some embodiments provide methods to make geometric analysis and document reconstruction more effective. For instance, some embodiments provide a method that provides a default set of document reconstruction operations for defining a structured document that comprises a plurality of primitive elements. The method provides a hierarchical set of profiles, each profile including (i) a set of document reconstruction results and (ii) results for modifying the document reconstruction operations when intermediate document reconstruction results match the potential document reconstruction results for the profile. Instructions from a profile at a lower level in the hierarchy override instructions from a profile at a higher level. In some embodiments, the instructions for a particular profile include a subset of profiles at a lower level in the hierarchical set of profiles that should be tested when the intermediate document reconstruction results match the potential document reconstruction results for the profile.","Once a structured document is defined, some embodiments provide various techniques for idealizing user interaction with the structured document. For instance, some embodiments provide a method for displaying a structured document that includes a hierarchy of structural elements constructed by analyzing an unstructured document. The method displays the structured document on the device (e.g., a small-screen device). The method receives a position of interest in the document, and identifies a structural element within the hierarchy as a region of interest based on the position of interest. The method modifies the display of the document to highlight the identified region of interest. Some embodiments identify the structural element by identifying a structural element at the lowest level of the hierarchy that includes the position of interest, and identifying structural elements at higher levels of hierarchy that include the structural element identified at the lowest level until a structural element qualifying as a region of interest is reached. Some embodiments also receive an input to move from the region of interest and modify the display of the document to highlight a structurally related region of interest.","Some embodiments provide a method for defining a selection of text in an unstructured document that includes numerous glyphs. The method identifies associated sets of glyphs and a reading order that specifies a flow of reading through the glyphs. The method displays the document and receives a start point and end point for a selection of text within the displayed document. The method defines the selection of text from the start point to the end point by using the identified sets of glyphs and intended flow of reading. In some embodiments, the associated sets of glyphs are paragraphs and the reading order specifies a flow of reading from a first paragraph to a second paragraph that are not contiguous.","Some embodiments provide methods that enhance the efficiency of the geometric analysis and document reconstruction processes. Some embodiments use cluster analysis for geometric analysis and\/or document reconstruction, which can be a computing-intensive process. Accordingly, some embodiments provide a method that defines structure for an unstructured document that includes numerous primitive elements that are defined in terms of their position in the document. The method identifies a pairwise grouping of nearest primitive elements and sorts the pairwise primitive elements based on an order from the closest to the furthest pairs. The method stores a single value that identifies which of the pairwise primitive elements are sufficiently far apart to form a partition. The method uses the stored value to identify and analyze the partitions in order to define structural elements for the document.","Some embodiments also provide methods for making use of efficient data structures. For instance, some embodiments provide several different processes for analyzing and manipulating an unstructured document that includes numerous primitive elements. Some embodiments also provide a storage for data associated with the primitive elements. At least some of the data is stored in a separate memory space from the processes and is shared by at least two different processes. The processes access the data by use of references to the data. The data is not replicated by the processes.","In the following description, numerous details are set forth for purpose of explanation. However, one of ordinary skill in the art will realize that the invention may be practiced without the use of these specific details. For instance, in some cases, the techniques described below are described as taking place in a specific order. However, in some embodiments, the techniques are performed in an order different from that described. Furthermore, while the techniques are described for languages that are read left-to-right (e.g., English), one of ordinary skill will recognize that the techniques are easily adapted for right-to-left languages.","I. Overview","Some embodiments of the invention provide novel methods for defining a structured document from an unstructured document. In some embodiments, an unstructured document is a document defined to include only primitive elements such as shapes (e.g., vector graphics), images (e.g., bitmaps), and glyphs. In some embodiments, a glyph is a visual representation of a text character (e.g., a letter, a number, a punctuation mark, or other inline character), collection of characters, or portion of a character. In some embodiments, a glyph may be a pre-specified collection of scalable vector graphics including path definitions for the outline of the glyph. In some embodiments, a glyph may be a pre-specified raster image or collection of raster images optimized for various sizes. As an example, the character \u201ci\u201d could be represented by a single glyph that is a path with two sub-paths, one for the outline of the dot and one for the outline of the lower portion. As another example, the combination of three characters \u201cffi\u201d, when occurring in sequence, are sometimes represented by a single glyph called a ligature, drawn in a slightly different manner than the characters occurring individually. As a third example, accented characters such as \u201c\u00ea\u201d are sometimes represented by more than one glyph (e.g. one for the character and one for the accent) and are sometimes represented by a single glyph (combining accent with character).","The unstructured document of some embodiments does not specify any relationship or association between the primitive elements, while in other embodiments it specifies a minimum amount of such relationships and associations. In some embodiments, the unstructured document may have some amount of structure, but the structure is unrecognizable or not relied upon. In some embodiments the unstructured document has an unknown structure or is assumed to be unstructured.","Some embodiments generate, from the unstructured document, a structured document that includes associations and relationships between the primitive elements, groupings and orderings of the primitive elements, and properties of the groups of primitive elements. For instance, some embodiments use the primitive elements of the unstructured document to identify various geometric attributes of the unstructured document and use these identified geometric attributes (along with other attributes of the primitive elements) to define structural elements. Structural elements of some embodiments include associated primitive elements (e.g., words, paragraphs, joined graphs, etc.), guides, gutters, text flow, tables, etc. These structural elements are related in a hierarchical manner in some embodiments (e.g., a paragraph includes text lines, a text line includes words, and a word includes primitive glyphs). In some embodiments, the structured document serves two purposes\u2014it identifies associated elements (e.g., the elements making up a table) and it identifies a flow order through the primitive elements (i.e., the order in which a human would be expected to read through the primitive elements in the document).","Upon receiving an unstructured document, some embodiments first parse the document into its constituent elements (e.g., primitive elements and their associated information such as coordinate locations, drawing order, etc.). For instance, a large block of text might be defined in the unstructured document as a number of character glyphs, each having x- and y-coordinates at which their anchors are placed on a particular page along with a scale factor determining the size of each glyph (and any other linear transforms that are to be applied), each glyph to be drawn on the page in a particular order (relevant to the compositing operation performed when one glyph overlays another). Some embodiments then perform geometric analysis on the primitive elements to define geometric attributes of the document. For example, some embodiments analyze the primitive elements to identify boundaries between primitive elements and regions bordered by the boundaries.",{"@attributes":{"id":"p-0098","num":"0097"},"figref":"FIG. 1","b":["100","110","110"]},{"@attributes":{"id":"p-0099","num":"0098"},"figref":"FIG. 2","b":["200","205","110","240","245","250","200"],"sub":["1 ","2 "]},"In some embodiments, the boundaries identified by geometric analysis modules  also include alignment guides. In some embodiments, an alignment guide is a vertical edge formed by the beginning or end of words (e.g., at the left edge of a column of left-aligned text). Similarly, in some embodiments, the regions identified by geometric analysis include gaps of unfilled white space between groups of glyphs (e.g., between guides). These gaps are called gutters in some embodiments.","Analysis result  illustrates a left-alignment guide  at the left edge of the first column of text and a gutter  spanning the white space between the two columns of text (for simplicity, the other guides and the columns of text are not shown). As illustrated in , the output of the semantic analysis modules  of some embodiments is zones , guides , and gutters .","The data output from geometric analysis modules  is sent to document reconstruction modules . Document reconstruction modules  continue the process of analyzing the unstructured document to define a structured document. In some embodiments, document reconstruction modules  create associations between primitive elements in order to define contiguous structural elements such as text, tables, and shapes. Some embodiments also define a hierarchy of the structural elements and relationships between the structural elements.","For instance, in some embodiments, the document reconstruction modules  create associations between glyphs, sets of glyphs, sets of sets of glyphs, etc. Some embodiments associate individual glyphs into words, words into text lines, text lines into paragraphs, etc. Analysis result  illustrates that individual lines  and paragraphs  are identified within the first column of text.","The document reconstruction modules  also identify the layout of glyphs in order to define the text flow through the glyphs. Specifically, to define the text flow, some embodiments identify a reading order through the glyphs (or through the sets of glyphs), which represents the order in which a human would be expected to read through the glyphs on a page (e.g., from the bottom of a first column to the top of a second column, then skipping a separated text box in the center, etc.) Analysis result  illustrates that two columns are identified within the document  and that the reading flow  runs from the bottom of the first column to the top of the second column. In some embodiments, the identification and definition of layout and flow makes use of the zone results , the guide and gutter results , and the glyph association results .","The document reconstruction modules  also define other structural elements in a document that are associations between primitive elements other than glyphs or between structural elements. For instance, in some embodiments, document reconstruction modules  identify tables in a document as associations between regions identified by geometric analysis modules  as well as the glyphs and sets of glyphs within the regions. For example, some embodiments associate regions as cells of a table, and the glyphs inside each region as the table information. Analysis result  illustrates the identification of a table  with nine cells  in document  by document reconstruction modules . Some embodiments associate the primitive elements that form the table by defining a tabular structural element. Whereas in the initial document, what was viewed as a table was defined as an unassociated collection of primitive elements (lines and glyphs), after reconstruction the cells are identified in the tabular structural element as table cells and are individually or collectively editable. As further illustrated, in some embodiments, the table identification and reconstruction uses zone results , glyph association results , and layout and flow results .","Some embodiments also identify when two or more primitive graphic elements or graphic objects (e.g., shapes, images, photographs, bitmaps, etc.) in the document should be grouped as one structural graphic element. For instance, two objects that mostly overlap may be one element that is defined as two shapes or images in the unstructured document. The document reconstruction modules  join these two objects as one object. Analysis result  illustrates that the two primitive shapes (a star and a hexagon) from the initial document  have been joined as one graphic  by the document reconstruction modules .","As illustrated in , examples of the output of the document reconstruction modules  include semantic hierarchy data  (i.e., associations of glyphs), layout and flow data , table data , and joined graph data . Furthermore, in some embodiments, some of this information is also passed between the several document reconstruction modules .  illustrates that all of this information is used to define a structured document . Structured document  has the same appearance as unstructured document , but the structured document  includes information about the structural elements and the associations, relationships, and hierarchy of elements, thereby enabling editing, more intuitive display, etc.","The data from the document reconstruction modules  (as well as, in some embodiments, data from the geometric analysis modules ) is used by document display and interaction modules . Document display and interaction modules  enable a user to view, edit, scroll through, etc. a document. For example, sequence  illustrates a document displayed as two columns of text on a handheld device that is held upright. When the handheld device is rotated on its side, the text in the two columns is rearranged into three columns. This rearrangement cannot be done with an unstructured document, because it relies upon the associations between elements, especially the flow of text through glyphs that is not part of the unstructured document.","In some embodiments, document display and interaction modules  can also recognize a structural element (e.g., a paragraph, graphic object, etc.) that has been selected by a user and intelligently zoom to display the selected element. In some embodiments, the user selects a position of interest (i.e., a particular location in a displayed document), and the display and interaction modules  identify a qualifying structural element in the hierarchy of structural elements. Some embodiments define particular types of structural elements as qualifying structural elements. The qualifying structural element is used to define a region of interest that is highlighted in the display in some embodiments.","Sequence  illustrates a selection of a paragraph  (e.g., by a selection of a position of interest of interest within the paragraph) and the subsequent intelligent display of the paragraph and nearby text. Document display and interaction modules  also provide other features such as intelligent selection of text and graphic objects, intelligent scrolling through a document, etc.","Some embodiments use hierarchical profiling to modify how geometric analysis and document reconstruction are performed on the fly, using intermediate analysis and reconstruction results. Some embodiments check the intermediate results against profiles that indicate what type of content a document includes and alter the reconstruction processes accordingly. In some embodiments, the hierarchical profiles can instruct the analysis and reconstruction modules to perform more or less processes, perform processes differently, or re-perform processes. For instance, if intermediate analysis results indicate that a document is one page long, has one column of text, and no shapes or images, then some embodiments will only perform processes to associate the glyphs into words, lines, and paragraphs. Table identification, for instance, will not be performed.","Some embodiments employ various novel efficiency techniques for more efficient memory and processing usage. For instance, some embodiments perform some of the above described processes by using cluster analysis, which is a technique used to identify groups of elements that are closely spaced in some way relative to other elements. Some embodiments use cluster analysis to identify guides based on numerous words starting at, ending at, centered on or otherwise aligned with the same or nearly the same x-coordinate. Some embodiments use cluster analysis to recognize different size gaps between glyphs so as to identify gaps between words and gaps larger than those between words. Some embodiments also use cluster analysis to identify primitive graphics (e.g., shapes, images) that should be joined into single graphics.","Some embodiments perform cluster analysis efficiently by using ordered data (e.g., primitive element position data) that references unsorted data, and by storing partitions of the data using a single value. A partition, as this term is used in the present invention, divides a sequence, or linearly ordered set, into subsequences, which are subsets of the sequence with the same order relation. Furthermore, a partition has the properties that (i) every member of the original sequence is contained in exactly one of the partition's subsequences, and (ii) given two of the partition's subsequences S and T, either all the members of S are less than all the members of T or all the members of T are less than all the members of S, according to the order relation. Storing a partition as a single value enables various cluster analysis functions, such as examining multiple partitions, to be performed more efficiently in some embodiments.","Some embodiments also gain efficiency in the document reconstruction process by using an application programming interface (API) that minimizes the amount of copying of data while appearing to the user of the API (e.g., a programmer or a software application using the API) as though the data is freely modifiable. Some embodiments store data in a randomly ordered array, then define a sorted array of references to the data and share this sorted array among numerous collection objects (e.g. character sequence objects, which are collections of character data) to optimize the usage of memory and processing. Both of these efficiency enhancements, as well as others, are used in some embodiments to enable document reconstruction to be performed on a limited-resource device, such as a cell phone, media player, etc. (e.g., an iPhone\u00ae).","Although the above-described overview of some embodiments was provided by reference to the examples illustrated in , one of ordinary skill will realize that these examples were meant only as exemplary embodiments that introduced the features and operations of some embodiments of the invention. One of ordinary skill will realize that many embodiments have features and operations that are different than those illustrated in . For instance, although geometric analysis has been described as one set of modules , one of ordinary skill would recognize that some embodiments do not necessarily identify all geometric attributes at once. For example, some embodiments do a subset of geometric analysis first (e.g., region analysis to identify one or more zones in the document) and then guides and gutters are identified on a zone-by-zone basis.","More detailed examples of some embodiments will be described below. Section II describes the identification of regions (i.e., zones) of a document based on boundary primitive elements and the definition of a hierarchical structure (e.g., a document object model) that forms the framework of a structured document. Section III then describes the identification of boundary elements for glyphs (e.g., alignment guides) and particular empty spaces between alignment points (gutters). Next, Section IV details the creation of associations between glyphs and sets of glyphs to define structural elements such as words, text lines, paragraphs, columns, etc., as well as the definition of a flow order through these structural elements (as well as other elements such as graphics, tables, etc.).","Next, Section V details various aspects of using a structured document (e.g., a document defined by a document object model) to display the document on a small-screen device (e.g., a handheld phone or media player). Both the adaptation of the document display to the small screen and the display of an identified region of interest are discussed. Section VI describes the use of the structured document to define a selection of text (or other elements of the document) in response to user input.","Section VII then describes various methods for improving the efficiency of cluster analysis techniques, which (among other uses) are used for identification of alignment guides, words and glyph spacing, and compound graphics in the document reconstruction process. Next, Section VIII details methods and data structures that enable more efficient parsing and analysis of a document. These data structures illustrate one manner of creating associations between glyphs (e.g., to form words, text lines, paragraphs, etc.) that can be used in the document reconstruction process. However, one of ordinary skill in the art will recognize that many other ways of creating associations between primitive elements (e.g., glyphs, graphic elements, etc.) to define structural elements (e.g., paragraphs, tables, compound graphics, etc.) are possible, as is well known in the art. Next, Section IX describes the software architecture of a document reconstruction application of some embodiments, and Section X describes a computer system that implements some embodiments of the invention.","II. Zone Analysis","When there are multiple articles, sections or categories of information on a page, these are often delineated by lines, images or shapes. Although a human can easily identify the manner in which graphical cues are intended to indicate how the page is broken up into zones, this is a nontrivial problem for a computer (particularly in the presence of a mixture of graphic primitive elements, some of which are intended as page content while others are intended to delineate content zones).","Some embodiments of the invention provide methods for identifying boundaries and the regions bordered by those boundaries (e.g., zones) based on the primitive elements (e.g., the shapes and images) of an unstructured document. In some embodiments, the regions are used in subsequent reconstruction of the document as well as for compartmentalization of further reconstruction processes. Some embodiments generate a region graph (i.e., hierarchical structure such as a tree) that is populated with content and enables the association of content with the region in which the content is located. Some embodiments perform the region identification on a page-by-page basis.",{"@attributes":{"id":"p-0121","num":"0120"},"figref":["FIG. 3","FIG. 4","FIG. 4","FIG. 3"],"b":["300","300","400","430","300","305"]},"Next, the process identifies (at ) zones on the page. In some embodiments, the identification of zones includes identifying zone borders and intersections and then traversing the zone borders to identify the zones. Referring to the example of , process  identifies that page  includes five zones: zones A , B , C , D , and E .","After identifying the zones, process  generates (at ) a zone graph (i.e., hierarchical structure such as a tree) for the page. The zone graph illustrates the hierarchy of the zones. For instance, zone tree  illustrates that a zone for the page (node P) includes four zones A, B, C, and D. Furthermore, zone D includes zone E, as zone E is fully within zone D. In some embodiments, a first zone is the parent of a second zone when the second zone is wholly within the first zone. A parent and a child can share one or more borders in some embodiments.","After generating the zone graph, process  inserts (at ) the content of the page into the zone graph. The process then ends. In some embodiments, a page includes text, graphics, or other content. Each particular content grouping (e.g., an image, paragraph, column, etc.) is placed as a child of the smallest zone that fully contains the particular content grouping. In some embodiments, the insertion of content objects into the zone graph is performed later in the document reconstruction process, once the content has been further analyzed (e.g., grouping text into paragraphs, identifying tables, etc.). Furthermore, as document reconstruction is performed, some embodiments update the zone graph with content subtrees for each zone.","A. Terminology",{"@attributes":{"id":"p-0126","num":"0125"},"figref":"FIG. 5","b":["500","500","505","509"]},"Zone border graphics are graphic objects (e.g., shapes, images, lines) on a page that either are narrow rectangles or have an upright bounding box that is a narrow rectangle For instance, zone borders - are all lines with a particular (relatively narrow) thickness. In some embodiments, zone border graphics include relatively narrow objects, all or part of the rendering of which fills all or part of a zone border. In some embodiments, zone border graphics also include objects whose boundary contributes to a zone border (e.g., one side of a filled polygon can indicate all or part of a zone border even though the polygon itself is not narrow and does not fit in the border bounds).","Zone borders graphics, however, need not be perfectly straight lines or perfectly rectilinear. For instance,  illustrates a page  that includes zone border graphics . Zone border graphics  are not perfectly vertical strips: instead they are images of twigs that are aligned very close to vertically. Some embodiments will recognize the graphic as a zone border graphic, whereas some embodiments will not.","Page  of  also includes numerous zone border intersections, such as intersections  and . In some embodiments, a zone border intersection is a rectangular intersection of a horizontal zone border with a vertical zone border. As intersection  illustrates, a zone border intersection need not be at the end of a zone border. Zone border intersections in the middle of a zone border break the zone border into one or more zone border intervals, in some embodiments. For instance, the bottom zone border of page  is broken into zone border intervals , , , and .","A zone, therefore, is a closed region bounded by a collection of zone border intervals that form an upright rectilinear shape in some embodiments. Upright rectilinear shapes are any polygons that can be formed by horizontal and vertical line segments, including but not limited to upright rectangles, which are rectangles formed from horizontal and vertical line segments. Each zone has an upright rectilinear outer bound which is a shape, formed from the outer sides of its zone border bounding rectangles. Each zone also has an upright rectilinear inner bound, which is a shape formed from the inner sides of its zone border bounding rectangles.","Page  includes zones P  (the page bounds), A  (an arch-shaped zone that includes the thin strips on the left and right side as well as the area above zones C and D), B , C  (the left zone that shares borders with zone E), D  (the right zone that is a mirror image of zone C), E , and G . Zones have outer bounds and inner bounds in some embodiments, defined by the outer and inner sides of the zone borders.",{"@attributes":{"id":"p-0132","num":"0131"},"figref":"FIG. 7","b":["700","500"]},"B. Rotation Groups","Some embodiments define several rotation groups on a page and analyze the zones and content of each rotation group separately. In some embodiments, rotation groups are similar to zones except that they do not have any zone borders. Instead, a rotation group is defined to include all content that is rotated by the same angle (or nearly the same angle to within a particular threshold that is sufficiently small as to be difficult for a human viewer to distinguish).  conceptually illustrates a process  of some embodiments for defining rotation groups on a page. As shown, process  receives (at ) a page of a document. In some cases, the page is the only page of the document, whereas in other cases the page is one of multiple pages. Some embodiments perform rotation group analysis for a multi-page document (or a multi-page section) all at once, rather than page-by-page.","The process then determines (at ) the rotation angle of each object on a page. In some embodiments, irregularly-shaped images are assumed to have a rotation angle of zero. For instance, the image in zone E of page  is irregularly shaped, and would not be given a non-zero rotation angle. Horizontally-aligned text also has a rotation angle of zero, while text that is aligned off the x-axis is given a rotation angle. For example, the text in region F  of page  would have a rotation angle of approximately \u221245 degrees. Similarly, the text  (\u201cOrganic\u201d and \u201cPure\u201d) in page  would have its own rotation angle. In embodiments that also place graphic objects into rotation groups, the rectangular image  above text  would have the same rotation angle as text .","Next, process  orders (at ) the objects by rotation angle. The process then groups (at ) the objects into clusters with a spread in rotation angle that is below a particular threshold. In some embodiments, the spread that is compared to the particular threshold is the smallest rotation angle in the group subtracted from the largest rotation angle in the group. The use of a non-zero threshold allows the grouping to account for minor errors in the content definition in the initially received document (e.g., a line of text that is very slightly off of horizontal).","Process  then analyzes (at ) each rotation group separately. The process then ends. On most pages, most of the analysis will involve the upright (zero angle) group. Some embodiments do not perform zone analysis for groups other than the upright group, and instead simply classify the content of the rotated groups as children of the page as a whole. In some embodiments, each rotation group has a coordinate system in which its content appears upright. In such embodiments, each rotation group has its own zone tree with content that fits into the DOM for the document. Some embodiments define one rotation group for each distinguishable angle by which content on the page is rotated. The analysis on each group is described in detail below.","C. Identifying Zone Borders and Intersections",{"@attributes":{"id":"p-0139","num":"0138"},"figref":["FIG. 9","FIG. 10","FIG. 10"],"b":["900","900","1000"]},"As shown in , the process receives (at ) a rotation group and normalizes the group to an upright coordinate system. In some embodiments, normalizing the group to an upright coordinate system involves defining a coordinate system for the group such that all objects in the group are vertical or horizontal (e.g., text lines are horizontal in the coordinate system). The following discussion assumes that the rotation group is the upright (zero-angle) group. One of ordinary skill in the art would be able to apply the same techniques to rotation groups with non-zero angles in a coordinate system in which their content appears upright. Some embodiments remove content from other rotation groups before performing zone identification for a particular rotation group. For instance, some embodiments would remove text  and image  from page  in  before performing zone identification and analysis in the upright rectilinear coordinate system.","The process then identifies (at ) potential zone borders. Potential zone borders, in some embodiments, include any horizontal or vertical graphic object that is sufficiently narrow. The determination of whether a particular graphic object is sufficiently narrow uses an absolute measure (e.g., when the smaller dimension of the upright bounding rectangle of the graphic object is less than 1\/24 of inch) in some embodiments. In other embodiments, the determination uses a relative measure (e.g., the larger dimension of the upright bounding rectangle is eight times the size of the smaller dimension), or a combination of absolute and relative measures (e.g., the narrow dimension could be allowed to be up to 1\/12 of an inch, but the relative measure of 8:1 applies). Some embodiments adjust the threshold in relation to the size of the page. For instance, the above examples might apply to a standard 8.5\u00d711 inch page, whereas a much larger page could have larger potential zone borders.","Referring to , page  includes several lines that would be classified as potential zone borders: horizontal borders - and vertical borders (-). However, graphic object  would generally not be considered a potential zone border, because it is too thick in the x-direction.","Some embodiments also identify all upright rectilinear shapes that have at least a threshold size and use the sides of these shapes as potential zone borders. In some embodiments, the threshold size is a particular area, whereas in other embodiments a threshold width and a threshold height must be surpassed. For instance, object  might have an area large enough to qualify its edges as potential zone borders, but it is too narrow to be a separate zone. Star object , on the other hand, is not an upright rectilinear shape and as such its edges would not qualify as a zone border. As such, these objects would simply be classified as content (specifically, graphic objects) that are within one zone or another. Some embodiments set the bounds of each potential zone border identified as the side of an upright rectilinear shape as the upright rectangle bounding the side, including the stroke width if stroked. Some embodiments also include the page borders as zone borders if they are upright rectilinear in the coordinate system of the rotation group.","After identifying potential zone borders, process  removes (at ) borders or portions of borders that intersect with other objects on the page. For instance, potential border  is obscured by star object , and as such would be broken into two potential zone borders (the area above the star and the area below the star). Some embodiments also remove zone borders that intersect character bounding boxes. A character bounding box for a particular character, in some embodiments, is the smallest rectangle that completely encloses the character. For instance, potential zone border  crosses the characters \u201cLorem Ipsum\u201d. As such, some embodiments would remove potential zone border  from consideration.","Next, process  merges (at ) borders. Some embodiments merge borders that are parallel and either overlapping or close to overlapping. Borders overlap when their bounds intersect. For instance, when two very narrow rectangles of different width are drawn such that one completely envelops the other, the two potential zone borders would be merged. Some embodiments slightly expand the bounds (both in width and length of the potential zone borders to test for overlap. Accordingly, borders  and  in  would be merged into one zone border , with a thickness greater than that of borders  and .","Process  then determines (at ) whether any merged borders remain unprocessed. When no borders were merged, or all merged borders have been processed, the process proceeds to , described below. Otherwise, the process selects (at ) an unprocessed merged border. The process then determines (at ) whether the merged border is too thick or includes too many zone border graphics. A merged border is too thick, in some embodiments, when its width in the narrow direction is above a particular threshold. In some embodiments, the test for thickness is the same as whether a graphic object is narrow enough to be classified as a zone border initially. When the process determines that the border is not too thick, the process proceeds to  which is described above. Otherwise, when the merged border is too thick, the process removes (at ) the merged border from the potential zone border candidates and classifies it as a single graphic object, then proceeds to . For instance, this could happen when an image is drawn as a series of narrow rectangles or a bar graph is drawn with narrow and closely spaced bars.","Once all merged borders are examined, the process identifies (at ) zone border intersections. As discussed above, zone border intersections are identified wherever a horizontal border intersects a vertical border. Some embodiments also identify near-intersections and classify these as intersections. To find near-intersections, borders are extended a small amount and then tested for intersection. Some embodiments extend the borders a fixed amount (e.g., one-fourth of an inch), while other embodiments extend each borders an amount that is a percentage of the length of the particular zone border. When the lengthened borders intersect, the near-intersection is classified as an intersection and the two borders are extended to fully cross the thickness of the other. As an example, borders  and  in  do not quite intersect. However, they are close enough that they would be classified as intersecting and are extended such that they intersect.","The process then eliminates (at ) borders with less than two intersections. Once a border is removed, any borders that intersected the removed border must be retested to determine whether they still have at least two intersections. In the example page , border  and the two remaining portions of border  would be removed, as they have no zone border intersections. Once the zone borders and intersections are identified, the process trims (at ) the zone borders to remove any portions extending past the outermost intersections. For instance, the borders  and  extend past their intersection. These would be trimmed to extend only to the outermost bound of each other. After trimming the borders, the process stores (at ) the zone border and intersection information for future use (e.g., in identifying zones). The process then ends.","At this point, the zone border intervals and zone border intersections have all been determined.  illustrates vertical zone border intervals , , , , , , , and  as well as horizontal zone border intervals , , , , , , , and .  also illustrates zone border intersections , , , , , , , , , , , , , and .","D. Identifying Zones","Once the zone borders and zone border intersections are identified, the zones can be identified.  conceptually illustrates a process  of some embodiments for identifying zones. Process  will be described in conjunction with .  illustrate the application of process  to identify the zones of page . Each of the figures is illustrated as a sequence.  illustrates a sequence - to identify a first zone border. Arrows in  illustrate direction vectors and dashed lines illustrate a path taken through the zone border intervals to define a zone.  illustrates the zones identified by process .","As shown in , process  receives (at ) zone borders and intersections for a group or page. In some embodiments, the zone borders and intersections are the output of process  described above. The process then determines (at ) whether there are any zone border intervals. When there are none, the process ends. Otherwise, the process assigns (at ) two direction vectors to each zone border interval (i.e., horizontal intervals have vectors pointing right and left, and vertical intervals have vectors pointing up and down).  illustrates (at ) that each of the border intervals for page  starts with direction vectors in both directions.","Next, the process selects (at ) a border interval b, an intersection i, and a direction d. Some embodiments select the starting point randomly, whereas other embodiments use a heuristic such as the top- and left-most intersection in a particular direction.  illustrates (at ) a random selection of starting at intersection  moving upwards along interval . Process  then proceeds (at ) in the direction d from intersection i until arriving at the next intersection.","Once the intersection is reached, the process determines (at ) whether the intersection is the starting intersection selected at . When the intersection is the original starting intersection, the process proceeds to  which is described below. Otherwise, the process determines (at ) whether the path through the zone border intervals can turn clockwise at the intersection. When the path can turn clockwise, the path does so (at ). The process then proceeds to  which is described below. When the path cannot turn clockwise, the process determines (at ) whether the path can continue straight through the intersection. When the path can continue straight, then the path does so (at ). The process then proceeds to  which is described below. When the path cannot continue straight, the path turns (at ) counterclockwise to the next border interval. By the choices made in steps  and , the process  exhibits a preference for a clockwise turn at each border intersection. Some embodiments will instead exhibit a preference for counterclockwise turns, which gives the same results.","The process sets (at ) the new border interval as the current border interval b, and the new intersection as the current intersection i. The process then sets (at ) the direction d moving away from intersection i along border b. The process then proceeds to  which was described above.","Once the original intersection is reached, process  defines (at ) a zone Z as the set of border intervals traversed since operation . As noted above,  illustrates the traversal of a set of zone border intervals according to process . At , after selecting interval  moving up from intersection  to start (shown by the circle and short arrow in the figure), the path comes to intersection . Turning clockwise is an option, so the path turns (at ) to interval , then clockwise again at intersection  to interval . The path turns (at ) clockwise yet again at intersection  to interval , but then at intersection  cannot either turn clockwise or continue straight through. Instead, the path turns counterclockwise to interval , then again at intersection  to interval  to proceed towards intersection . At intersection , the path turns (at ) clockwise to interval , then clockwise again at intersection  to interval . Interval  returns to the path to the original intersection .",{"@attributes":{"id":"p-0157","num":"0156"},"figref":["FIG. 13","FIG. 13"],"b":["1325","1300","1115","1120","1155","1150","1145","1160","1175","1180","1200","1265","1270","1330","1000","1300"],"sub":"1 "},"Process  next removes (at ) all border intervals with no remaining direction vectors. This will not occur after the first zone is identified, but can happen after any of the further zones are identified. When the zone Z is an island (i.e., a zone that shares no borders with its parent), process  classifies (at ) the zone as such. In embodiments in which the preference is for clockwise turns, then a zone defined by traversing its center in a counterclockwise direction will be an island.","The process then determines (at ) whether any zone border intervals remain. When more zone border intervals remain, the process proceeds to  which was described above. Otherwise, once all zone border intervals are used in both directions, the process has defined all the zones for the page. The process then stores (at ) the zone information. The process then ends.",{"@attributes":{"id":"p-0160","num":"0159"},"figref":["FIG. 14","FIG. 14"],"b":["1200","1000","1113","1123","1133","1143","1435","1440","1192","1445","1450","1455"]},"E. Generating the Zone Tree","Once the zones have been identified, the zone graph (zone tree) can be generated. The zone tree is used, in some embodiments, in document reconstruction that is done on a zone-by-zone basis.  conceptually illustrates a process  of some embodiments for generating a zone tree. As shown, the process receives (at ) zones and content objects. In some embodiments, these zones have been identified by a process such as process . The process then sorts (at ) the zones by area. Some embodiments treat an island as larger than a non-island when their areas are equal for the purposes of sorting the zones.","Next, the process selects (at ) the smallest zone as z. The process then determines (at ) whether zone z has a node yet in the zone graph for the page. When z has a node, the process proceeds to  which is described below. Otherwise, when z does not yet have a node, the process  defines (at ) a node for zone z.","Next, the process selects (at ) the next smallest zone as zone p. The process then determines (at ) whether zone p contains zone z (i.e., whether the outer bounds of zone z are completely within the outer bounds of zone p). When zone p contains zone z, the process determines (at ) that zone z is a child of zone p. Based on this, the process defines (at ) a node for zone p in the node graph. The process then defines (at ) an edge from zone p to zone z. The process then proceeds to  which is described below.","When, at , the process determines that zone p does not contain zone z, the process determines (at ) whether there are any zones larger than the current zone p. When there are larger zones remaining, the process proceeds to  and selects the next smallest zone as zone p to test whether the new zone p is a parent of zone z. Otherwise, when there are no zones larger than zone p, the process determines (at ) that zone z has no parent zones.","Next, the process determines (at ) whether there are any zones larger than zone z. When there are larger zones, the process removes (at ) zone z from the set of zones from which to select and proceeds to  to select another zone for parent-child analysis.",{"@attributes":{"id":"p-0167","num":"0166"},"figref":["FIG. 16","FIG. 10"],"b":["1435","1440","1455","1450","1300","1445","1000","1600","1500","1600"]},"Once all zones have been analyzed, the process proceeds to  and determines whether there are any unprocessed content objects. When there are no content objects (i.e., the document is blank except for zone borders), or all content objects have been processed, the process proceeds to , described below. Otherwise, the process proceeds to  and selects a content object c. The process then defines (at ) a node for the object c. A content object, in some embodiments, is a primitive object (e.g., a glyph, shape or image). The process then determines (at ) the smallest zone x that contains content object c. Once the zone x containing content object c is determined, the process defines (at ) an edge in the zone graph from zone x to content object c. When all objects have been added, the process stores (at ) the zone graph. The process then ends.","In some embodiments, the content in each zone is further analyzed (e.g., grouping text into paragraphs, identifying tables, etc.). Furthermore, as document reconstruction is performed, some embodiments update the zone graph with content subtrees for each zone, where those content subtrees include structure nodes that represent the hierarchical grouping of the primitive objects of the zone. By performing zone analysis first, one ensures that content from different zones is not inappropriately grouped in the subsequent document reconstruction steps.","In some embodiments, the identification of geometric attributes such as boundaries and the regions bordered by those boundaries (e.g., zones) sets the stage for further document reconstruction. For example, profiles may depend on zone geometry and structure elements such as tables or text boxes may be recognized from the zone geometry.","F. Software Architecture","In some embodiments, the zone analysis processes described above are implemented as software running on a particular machine, such as a computer, a media player, a cell phone (e.g., an iPhone\u00ae), or other handheld or resource-limited devices (or stored in a computer readable medium).  conceptually illustrates the software architecture of a zone analysis application  of some embodiments for performing zone analysis on a document. In some embodiments, the application is a stand-alone application or is integrated into another application (e.g., a document reconstruction application), while in other embodiments the application might be implemented within an operating system.","Zone analysis application  includes a border identification module , an interval and intersection identification module , a zone identification module , and a zone graph builder , as well as zone information storage .",{"@attributes":{"id":"p-0174","num":"0173"},"figref":"FIG. 17","b":["1730","1705","1730","1705","1710","1725","1705","900"]},"The interval and intersection identification module  receives zone border information from the border identification module  and\/or the zone information storage . The interval and intersection identification module  identifies zone border intersections and zone border intervals based on the potential zone borders identified by module . The identified zone border intersections and zone border intervals are passed to the zone identification module  as well as storing in zone information storage . In some embodiments, interval and intersection module identification  performs some or all of process .","The zone identification module  receives zone border information from the border identification module , zone border intersection and zone border interval information from the interval and intersection identification module , and\/or information from the zone information storage . Zone identification module  identifies zones based on the information from modules  and . The identified zones are passed to the zone graph builder as well as storing in the zone information storage . In some embodiments, zone identification module  performs some or all of process .","The zone graph builder  module receives zone information from the zone identification module  and\/or the zone information storage , as well as content information from the document content . Zone graph builder  defines the zone graph for a document based on the zone information, and populates the zone graph with content information. In some embodiments, the zone graph builder  populates the zone graph as content information is identified by other reconstruction processes, such as those described in the Sections below. In some embodiments, zone graph builder  performs some or all of process .","In some embodiments, the results of the processes performed by the above-described modules or other modules are stored in an electronic storage (e.g., as part of a document object model). The document object model can then be used for displaying the document on an electronic display device (e.g., a handheld device, computer screen, etc.) such that a user can review and\/or interact with the document (e.g., via touchscreen, cursor control device, etc.).","III. Guide and Gutter Analysis","Some embodiments of the invention provide methods for identifying geometric attributes such as boundaries (e.g., alignment guides) and unfilled space (e.g., gaps of unfilled white space between groups of glyphs, called gutters) in a document or portion of a document. In some embodiments, a gutter is the white space between two alignment points (e.g., between a right-alignment point and a left-alignment point). Identification of guides and gutters is used in subsequent reconstruction procedures, such as column identification and splitting of text lines, in some embodiments. Some embodiments identify guides and gutters on a zone-by-zone or page-by-page basis.",{"@attributes":{"id":"p-0180","num":"0179"},"figref":["FIG. 18","FIG. 19","FIG. 18"],"b":["1800","1800","1900","1900","1800","1805"]},"The process then applies (at ) cluster analysis to determine guides of the received document portion. Cluster analysis enables the process to determine x-coordinates where the ends or beginnings of words are grouped together, making those x-coordinates likely alignment guides. As mentioned,  illustrates a page  with two columns of text. Page  includes as set of guides . Some embodiments determine bottom and top lines of columns as guides, whereas other embodiments only determine left- and right-alignment guides. Some embodiments also identify guides for other alignments, such as center alignment or the alignment of decimal points in listings of numbers. Cluster analysis and the guide determination process are described in further detail below.","Next, the process determines (at ) the gutters of the document portion. Some embodiments use information from operation  to determine the gutters.  illustrates a gutter  that is determined for page  between the right-alignment guide of column one and the left-alignment guide of column two. Some embodiments treat the page margins as gutters, while other embodiments do not. Once the guides and gutters are determined, the process  uses (at ) the guides and gutters for further reconstruction of the document. The process then ends.","A. Density Clustering","Some embodiments determine right- and left-alignment guides by searching for text lines that start or end at the same or nearly the same x-coordinate on a page and determining whether sufficient evidence exists that the x-coordinate is actually an alignment point. Some embodiments use a form of cluster analysis called density clustering to determine alignment guides. The density clustering of some embodiments takes advantage of the memory and processing efficiencies described below in Section VII so that it can be performed on a resource-limited device (e.g., an iPhone\u00ae).","Density clustering is often applicable to problems in which there is a substantial amount of \u201cnoise\u201d or random data mixed in with otherwise clearly visible clusters. When the data is a set of real numbers, the clusters are identified as subsets that optimally meet given density constraints. The constraints are generally designed to pick out subsets that are relatively denser than others. For instance, some embodiments use a minimum size of a cluster and a maximum spread of a cluster as constraints.",{"@attributes":{"id":"p-0186","num":"0185"},"figref":"FIG. 20","b":["2000","2005"]},"The process then sorts (at ) the set of input data. Some embodiments sort the data in ascending order, while other embodiments sort the data in descending order. For instance, in the case of using density clustering to determine alignment guides, the data (x-coordinate values) is sorted from lowest to highest x-coordinate value such that if two x-coordinate values are equal they are next to each other in the sorted data (unless there are other words with the same x-coordinate value that fall in-between the two). Some embodiments create a new array for the sorted data, while some embodiments use an indirectly sorted array of indices as described below in Section VII.","Next, process  determines (at ) whether the set has at least two pieces of data. If not, then the process ends, as there is nothing to cluster. Otherwise, the process proceeds to determine (at ) the set of differences between subsequent data in the sorted set. Such a set will have one less value than the set of input data. As an example, when there are three words on a page, the two values in the set of differences are the difference between the x-coordinate values of the first and second words and the difference between the x-coordinate values of the second and third words.","Next, the process sets (at ) a variable d to the largest unevaluated difference in the set of differences. For instance, when the differences for a set of words are 0.7 inches, 0.2 inches, 0.0 inches, and 0.4 inches, then the variable d would initially be set to 0.7 inches. The process then partitions (at ) the sorted data wherever the difference is greater than or equal to d to generate a set of subsets of the data. The first partition will always partition the sorted data only at differences equal to d, because d will be set to the largest difference. In the above example of five data values with differences of 0.7, 0.2, 0.0, and 0.4, the partitioning would generate two subsets (the first value in one subset and the other four in the other subset).","The process then determines (at ) the set S of subsets that satisfy particular constraints for the problem being solved. In some embodiments, the purpose of the constraints is to determine subsets that are relatively denser than the other subsets. Some embodiments use two density constraints: a minimum cluster size (i.e., the minimum number of values in the subset) and maximum cluster spread (i.e., the largest allowed difference between the largest and smallest values in the subset). In the case of using density clustering for determining alignment guides, some embodiments use a minimum cluster size that is a fraction of the total lines in the page or zone being evaluated, while other embodiments use a constant. Some embodiments use a maximum spread that is a fraction of the median font size of the first (for left-alignment) or last (for right-alignment) characters of words.","Once the set S of subsets that satisfy the constraints are determined, the process determines (at ) whether S is empty. When S is empty, the process proceeds to  which is described below. When S includes at least one subset, the process evaluates (at ) an optimization function for S. Some embodiments use an optimization function that looks for the set S that has the largest subset that meets the constraints. Other embodiments use an optimization function tries to maximize the sum of the squares of a particular value (e.g., the size of the subset minus the minimum cluster size) over all of the subsets that meet the constraints. Yet other embodiments use one of the above-mentioned optimization functions, and then use the other in case of a tie. Other optimization functions are used by other embodiments.","Next, the process determines (at ) whether the set S is the most optimal so far, based on the optimization function. When S is not the most optimal, the process proceeds to  which is described below. Otherwise, when S is the most optimal, the process stores (at ) S as the best set of clusters yet found. The first pass through (in which d is the largest difference) will always be the most optimal at that point, if S is not empty. On subsequent passes, the current S will be compared to the stored set of clusters.","The process then determines (at ) whether there are any unevaluated differences. Some embodiments test each possible partition to find the most optimal set of clusters. Some such embodiments use the efficiency techniques described below in Section VII to enable faster and more efficient processing. When the process determines that there are unevaluated differences, the process proceeds to  which was described above.","Otherwise, once all the differences have been evaluated, the process outputs (at ) the currently stored optimal set (or empty set if no clusters satisfying the constraints were found) as the final set of clusters. In the case of determining alignment guides, the final set of clusters would be groups of words with very close x-coordinates. The process then ends. One of ordinary skill will recognize that in addition to the density constraints and optimal measure, process  imposes a consistency constraint on the clusters; namely, that intra-cluster differences between successive values in a cluster will never equal or exceed inter-cluster differences, because the data is always partitioned at all differences that are equal to or greater than a specified gap minimum.","B. Determining Alignment Guides","As mentioned above, some embodiments determine right- and left-alignment guides by searching for associated sets of glyphs (e.g., words, text lines) that start or end at the same or nearly the same x-coordinate on a page and determining whether sufficient evidence exists that the x-coordinate is actually an alignment point. Some embodiments use similar but not identical processes to find left-alignment guides and right-alignment guides.",{"@attributes":{"id":"p-0197","num":"0196"},"figref":["FIG. 21","FIGS. 22-24","FIGS. 22-24","FIG. 21"],"b":["2100","2100","2200","2100","2105"]},"The process then determines (at ) desired cluster properties. In some embodiments, the cluster properties are the constraints for density clustering described above. Some embodiments use two density constraints: a minimum cluster size (i.e., the minimum number of values in the subset) and maximum cluster spread (i.e., the largest allowed difference between the largest and smallest values in the subset). In the case of using density clustering for determining alignment guides, some embodiments use a minimum cluster size that is a fraction of the total lines in the page or zone being evaluated, while other embodiments use a constant. Some embodiments use a maximum spread that is a fraction of the median font size of the first (for left-alignment) or last (for right-alignment) characters of words. One example of constraints are that the minimum cluster size is 5% of the total number of text lines in the region, and the maximum spread is 10% of the median font size.","Next, the process applies (at ) density clustering to the input data using the determined cluster properties to determine clusters of x-coordinate values that may be alignment guides. Some embodiments use process  as described above.","Process  then determines (at ) whether there are any unevaluated clusters. When there are no clusters, or all clusters are evaluated, the process ends. Otherwise, the process selects (at ) a cluster (i.e., one of the clusters output from the cluster analysis). The process then sets (at ) a left-alignment guide as a rectangle with the minimum and maximum x-coordinates as the smallest and largest values in the cluster and the minimum and maximum y-coordinates as the top and bottom of the page. In some cases, the minimum and maximum x-coordinate will be the same, as all the x-coordinates in the cluster will have the same value. In other cases, small aberrations or words that accidentally make it into the cluster will give the rectangle a non-zero width.",{"@attributes":{"id":"p-0201","num":"0200"},"figref":"FIG. 22","b":["2200","2205","2205","2215","2210","2210"]},"Process  then removes (at ) the rectangle at y-coordinates that do not satisfy constraints based on an analysis of words that start in the rectangle and words that cross the rectangle. The process then proceeds to , described above. Some embodiments remove a portion of the rectangle anywhere that a word starts left of the rectangle and crosses into the rectangle. The rectangle is also removed at any y-coordinate that is between two crossing words that do not have a sufficient number of border words between them. A border word is a word that starts in or at one of the edges of the rectangle. Some embodiments use a requirement that there be at least five border words between crossing words, and at least one of those five border words must be the leftmost on its text line or separated from the previous word on its text line by more than a normal word gap. Some embodiments use processes described in United States Publication No. 2007\/0250497, now issued as U.S. Pat. No. 7,603,351, entitled \u201cSemantic Reconstruction\u201d, by Mansfield, et al., which is incorporated herein by reference, to determine word gaps and larger gaps. Some embodiments use different requirements (e.g., fewer or greater than five border words between crossing words) to perform operation .",{"@attributes":{"id":"p-0203","num":"0202"},"figref":"FIG. 23","b":["2200","2205","2205","2340","2315","2210","2325","2340","2315","2330","2335"]},{"@attributes":{"id":"p-0204","num":"0203"},"figref":"FIG. 24","b":["2405","2410","2200","2200"]},"As mentioned above, some embodiments use a process similar to process  for determining right-alignment guides.  conceptually illustrates a process  of some embodiments for determining right-alignment guides. As shown, the process sets (at ) the input data for density clustering as the x-coordinates of the right edge of words in a region of a document. The region is a page or a zone of a page in some embodiments. In some embodiments, the right edge of a particular word is the x-coordinate of the anchor of the last glyph in the particular word plus the x-coordinate of the advance vector for the last glyph in the word, adjusted to the right alignment position expected for the glyph.","The process then determines (at ) desired cluster properties. In some embodiments, the cluster properties are the constraints for density clustering described above. Some embodiments use two density constraints: a minimum cluster size (i.e., the minimum number of values in the subset) and maximum cluster spread (i.e., the largest allowed difference between the largest and smallest values in the subset). In the case of using density clustering for determining alignment guides, some embodiments use a minimum cluster size that is a fraction of the total lines in the page or zone being evaluated, while other embodiments use a constant. Some embodiments use a maximum spread that is a fraction of the median font size of the first (for left-alignment) or last (for right-alignment) characters of words. One example of constraints are that the minimum cluster size is 5% of the total number of text lines in the region, and the maximum spread is 10% of the median font size.","Next, the process applies (at ) density clustering to the input data using the determined cluster properties to determine clusters of x-coordinate values that may be alignment guides. Some embodiments use process  as described above.","The process then determines (at ) whether there are any unprocessed clusters. When there are no clusters, or all clusters have been processed, the process ends. Otherwise, the process selects (at ) a cluster (i.e., one of the clusters output from the cluster analysis). The process then sets (at ) a right-alignment guide as a rectangle with the minimum and maximum x-coordinates as the smallest and largest values in the cluster and the minimum and maximum y-coordinates as the top and bottom of the page. In some cases, the minimum and maximum x-coordinate will be the same, as all the x-coordinates in the cluster will have the same value. In other cases, small aberrations or words that accidentally make it into the cluster will give the rectangle a non-zero width.","The process then removes (at ) the rectangle at y-coordinates that do not satisfy constraints based on an analysis of words that end in the rectangle and words that cross the rectangle. The process then proceeds to , described above. Some embodiments remove a portion of the rectangle anywhere that a word crosses or starts in the rectangle and ends right of the rectangle. The rectangle is also removed at any y-coordinate that is between two crossing words that do not have a sufficient number of border words between them. A border word is a word that ends in or at one of the edges of the rectangle. Some embodiments use a requirement that there be at least five border words between crossing words, and at least one of those five border words must be the rightmost on its text line or separated from the next word on its text line by more than a normal word gap. Some embodiments use processes described in the above-mentioned United States Publication No. 2007\/0250497 now issued as U.S. Pat. No. 7,603,351, to determine word gaps and larger gaps. Some embodiments use different requirements (e.g., fewer or greater than five border words between crossing words) to perform operation .","C. Determining Gutters","After determining the guides, some embodiments then determine gutters of the region (e.g., zone, page, etc.). Some embodiments use information from the guide determination process (e.g., processes  and ) to determine the groupings of unfilled white space between associated glyphs (e.g., gutters) of the region. Some embodiments also use other alignment points in addition to guides for determining gutters in a region.",{"@attributes":{"id":"p-0212","num":"0211"},"figref":["FIG. 26","FIGS. 27-29","FIGS. 27-29"],"b":["2600","2600","2700"]},"As shown in , the process receives (at ) alignment information. In some embodiments, this information is the guides determined by processes  and . Some embodiments include other alignment points as well as guides. For instance, in some embodiments, the end of text lines in left-aligned (not justified) text are treated as right-alignment points. This enables gutters to be identified in column gaps even if no guide is found at the right edge of the first column. Similarly, the left edge of right-aligned text, or both edges of centered text, are considered alignment points in some embodiments.","Process  then determines (at ) whether there are any unprocessed right-alignment points. When there are no right alignment points, or all have been processed, the process ends. Otherwise, the process selects (at ) a right-alignment point. In some embodiments, the process identifies the leftmost right-alignment point first, while in other embodiments it picks a random right-alignment point.","The process then determines (at ) whether a left-alignment point exists between the selected right-alignment point and the right edge of the region. When there are no left-alignment points, the process proceeds to , which was described above. Otherwise, when there is at least one left-alignment point between the right-alignment point and the region edge, the process identifies (at ) the next left-alignment point moving right across the region from the selected right-alignment point. It is the area between these two points that the process tests to determine if there is a gutter.","Once the right- and left-alignment points are identified, the process sets (at ) a gutter as a rectangle with the right-alignment point as the minimum x-coordinate and the left-alignment point as the maximum x-coordinate. The minimum and maximum y-coordinates of the rectangle are the top and bottom of the page.  illustrates the page  and a rectangle  that is to be tested as a possible gutter. The minimum x-coordinate is the right-alignment point at the right edge of the first column, and the maximum x-coordinate is the left-alignment point at the left edge of the second column.","Next, the process removes (at ) the gutter at y-coordinates that do not satisfy constraints based on an analysis of words that cross into the rectangle and border the rectangle. Some embodiments remove a portion of the rectangle anywhere that a word crosses into or starts in the rectangle. The rectangle is also removed at any y-coordinate that is between two crossing words that do not have a sufficient number of border words between them. A border word for a gutter is a word that ends at the left edge of the rectangle or starts at the right edge of the rectangle. Some embodiments use a requirement that there be at least five border words between crossing words, and at least one of those five border words must be either the leftmost on its text line or separated from the previous word on its text line by more than a normal word gap or the rightmost on its text line or separated from the next word on its text line by more than a normal word gap. Some embodiments use processes described in the above mentioned United States Publication No. 2007\/0250497, now issued as U.S. Pat. No. 7,603,351, to determine word gaps and larger gaps. Some embodiments use different requirements (e.g., fewer or greater than five border words between crossing words) to perform operation . The process then proceeds to , which was described above.",{"@attributes":{"id":"p-0218","num":"0217"},"figref":"FIG. 28","b":["2700","2705","2705","2810","2815","2820","2810","2815"]},{"@attributes":{"id":"p-0219","num":"0218"},"figref":"FIG. 29","b":["2905","2910","2700"]},"Some embodiments use the guides and gutters throughout the semantic reconstruction process. For example, gutters are used to split text lines and identify columns, processes that are described below in Section IV.","D. Software Architecture","In some embodiments, the guide and gutter analysis processes described above are implemented as software running on a particular machine, such as a computer, a media player, a cell phone (e.g., an iPhone\u00ae), or other handheld or resource-limited devices (or stored in a computer readable medium).  conceptually illustrates the software architecture of a guide and gutter analysis application  of some embodiments for identifying guides and gutters in a document. In some embodiments, the application is a stand-alone application or is integrated into another application (e.g., a document reconstruction application), while in other embodiments the application might be implemented within an operating system.","Guide and gutter analysis application  includes a guide identification module , a density clustering module , and a gutter identification module , as well as guide and gutter information storage .",{"@attributes":{"id":"p-0224","num":"0223"},"figref":"FIG. 30","b":["3025","3005","3025","3005","3015","3020","3025","3005","2100","2500"]},"The guide identification module  also passes information to, and receives information from, the density clustering module . Density clustering module  receives input data from the guide identification module  and\/or the guide and gutter information storage  and performs density clustering on the input data in order to determine potential guides. In some embodiments, density clustering module  performs some or all of process .","The gutter identification module  receives information from the guide identification module  and the document content . The gutter identification module analyzes the received information to identify gutters in the document. The identified gutters are passed to the guide and gutter information storage  and to the document content . In some embodiments, gutter identification module  performs some or all of process .","In some embodiments, the results of the processes performed by the above-described modules or other modules are stored in an electronic storage (e.g., as part of a document object model). The document object model can then be used for displaying the document on an electronic display device (e.g., a handheld device, computer screen, etc.) such that a user can review and\/or interact with the document (e.g., via touchscreen, cursor control device, etc.).","IV. Determining the Layout and Flow","Documents generally have an implicit structure and flow of content. Specifically, in some cases, ordered sequences of characters (and inline graphics) make up words, ordered sequences of words make up text lines (or span text lines with a hyphen), ordered sequences of text lines make up paragraphs, ordered sequences of paragraphs make up columns (or span columns), ordered sequences of columns make up layouts, and ordered sequences of layouts make up sections of a document. When this structure is not provided in the file format of an electronic document, the structure has previously been inaccessible to software. While merely viewing a document does not necessarily require document structure, applications for editing, importing, searching, styling, or otherwise repurposing a document do require knowledge of the document structure and flow in order to function properly.","Some embodiments of the invention provide methods for determining the layout and flow of a document or a region of a document. This includes determining the semantic hierarchy (e.g., the words, lines, and paragraphs of a document), as well as layout properties such as the columns and how the columns fit together for intended reading of the document. In some embodiments, the goal of the processes is to identify the order in which a human would read a document from start to finish.",{"@attributes":{"id":"p-0230","num":"0229"},"figref":["FIG. 31","FIG. 32","FIG. 32","FIG. 32","FIG. 31"],"b":["3100","3100","3200","3200","3100","3105"]},"The process then identifies (at ) lines of text in the received document. This includes identifying characters that share a common baseline and merging preliminary lines together when necessary (e.g., subscripts and superscripts).  illustrates the identification of lines  and . The line identification process of some embodiments is described in further detail below in subsection A.","Next, the process identifies (at ) words in the text. Some embodiments use difference clustering, as described in above mentioned United States Publication No. 2007\/0250497, now issued as U.S. Pat. No. 7,603,351, to identify words in the text.  illustrates the identification of words on page , including the word  (\u201cLorem\u201d) from line  and the word  (\u201camet\u201d) from line . The word identification process is also described in further detail below in subsection B.","The process then splits (at ) the lines of text where the text is discontinuous.  illustrates that line  is split into lines  and , and line  is split into lines  and . The line splitting process of some embodiments is described in further detail below in subsection C.","After splitting the lines, the process places (at ) the text lines into paragraphs.  illustrates paragraphs  and  identified on page . The paragraph identification process is described in further detail below in subsection D.","Lastly, the process places (at ) the paragraphs into columns and layouts.  illustrates columns  and  identified on page . The column and layout identification process is described in further detail below in subsection E.","Some embodiments do not perform all of the operations of process  at once. Instead, some perform other document reconstruction processes in between operations of process . For example, some embodiments determine lines of text and the words in the text, but then identify guides and gutters prior to splitting the lines of text.","A. Initial Line Identification","As mentioned above, in some embodiments lines of text have to be identified. Because every character in a particular line of text will not necessarily always share a common baseline, some embodiments attempt to merge lines together based on evidence that the characters in the two lines are intended to be read as part of the same line of text (e.g., superscripts and subscripts).",{"@attributes":{"id":"p-0239","num":"0238"},"figref":["FIG. 33","FIGS. 34 and 35","FIG. 34","FIG. 35"],"b":["3300","3300","3400","3405","3430"]},"As shown in , the process receives (at ) a portion of a document. In some embodiments, the portion is a page of a document, or a zone of a page, etc. The process then determines (at ) whether there are any characters in the document portion. When there are none, the process ends. Otherwise, the process associates (at ) as preliminary text lines characters that share a common baseline. Characters share a common baseline in some embodiments when they have the same y-coordinate anchor point. In general, associating characters that share a common baseline will group together lines of standard text. Some embodiments use a small threshold such that the y-coordinate anchor points in a preliminary text line need not be exactly equal, but must be within the small threshold of each other.","Next, the process identifies (at ) groups of text lines that vertically overlap. Two lines vertically overlap in some embodiments when the bounding rectangle of the first line overlaps in y-coordinate values with the bounding rectangle of the second line.  illustrates the page  with six groups of vertically overlapping text lines: lines  and , lines  and , lines  and , lines , , and , lines  and , and lines  and . Line  is associated in a group with line  because both overlap with line , even though they do not overlap each other. Even though there is no horizontal overlap, because lines  and  vertically overlap, they are initially grouped together in some embodiments.","The process then selects (at ) an unevaluated group and partitions (at ) the group into sections with no horizontal overlap between text lines of different sections. Two text lines horizontally overlap in some embodiments when the x-coordinates of the bounding box of the first text line overlap with the x-coordinates of the bounding box of the second text line. For instance, lines  and  are partitioned at this point because they do not horizontally overlap and thus would not be likely to be considered the same line. Some embodiments expand the measure of horizontal overlap a small distance (e.g., one half of a space character) at the beginning and end of the text lines, so that offset characters (e.g., subscripts and superscripts) at the beginning or end of a line are merged. For example, there is no horizontal overlap between lines  and , but they are not partitioned because the end of line  is close enough to the beginning of line .","After partitioning the selected group, the process selects (at ) an unevaluated section from the group and sorts (at ) the lines in the section from top to bottom. Thus, if the selected section with lines - is selected, the lines would be sorted with line  first, line  second, and line  third. Various embodiments sort the lines by ascent, descent, baseline, or other measure of the vertical position of a line.","The process then selects (at ) the top-most unevaluated line in the section. Next, the process selects (at ) the first (reading from the left for left-to-right languages) unevaluated character in the selected line. The process determines (at ) whether the selected character can be merged into the next line. Some embodiments allow a character to be merged into the next line when the selected character does not horizontally overlap significantly with any character in the next line. Some embodiments allow some small amount of horizontal overlap between characters. For left-to-right languages, some embodiments allow less overlap on the left of the character to be merged down than on the right of the character to be merged down, in order to account for common spacing adjustments for offset characters.","Furthermore, some embodiments allow any amount of overlap when the original insertion order of the overlapping characters is adjacent. The insertion order, in some embodiments, is the order in which the characters are drawn on the page. Often (though not always), characters are drawn in the order they are meant to be read, so when two vertically and horizontally overlapping characters are adjacent in the insertion order, it is likely they are intended to be read together.","When the process determines that the selected character can be merged into the next line, the process merges (at ) the selected character in to the next line. The process then proceeds to  which is described below. Otherwise, when the selected character cannot be merged, the process keeps (at ) the selected character in the selected line.","Next, the process determines (at ) whether the selected line includes more characters. When there are more characters in the currently selected line, the process proceeds to  to select the next unevaluated character in the line. Otherwise, when all characters in the line have been evaluated, the process determines (at ) whether the current section includes more lines. When there are more lines in the currently selected section, the process proceeds to  to select the next unevaluated line.","Otherwise, when all lines in the section have been evaluated, the process determines (at ) whether the selected group includes more sections. When there are more sections in the currently selected group, the process proceeds to  to select another section and merge lines in that section. Otherwise, when all the sections in the group have been evaluated, the process determines (at ) whether there are any more groups to evaluate in the document portion. When there are more groups, the process proceeds to  to select another group. Otherwise, when all groups have been evaluated, then line-merging is finished for the document portion and the process ends.",{"@attributes":{"id":"p-0249","num":"0248"},"figref":"FIG. 35","b":["3500","3506","3505","3505","3506","3506","3510","3511","3510","3511","3510","3511","3516","3515"]},"Lines - cannot be fully merged. The character \u201cb\u201d in line  is initially merged down into line . Then, the character \u201cA\u201d in line  is merged down into line  as it does not overlap with the character \u201cc\u201d. However, character \u201cb\u201d is not merged down into line  because it completely overlaps with character \u201cc\u201d. Thus, line  only includes \u201cb\u201d, line  includes \u201cA\u201d and \u201cc\u201d, and line  is empty. As described above, some embodiments will merge \u201cb\u201d into line  if\u201cb\u201d and \u201cc\u201d are adjacent in the insertion order.","Similarly, lines  and  are not merged. All of the characters in line  significantly overlap one or more characters in line , and therefore are not merged down into line . It is unlikely that the \u201cT\u201d in line  would be between the \u201ch\u201d and \u201cn\u201d of line  in the insertion order for page . Lastly, lines  and  are not merged because there is no horizontal overlap between the lines and thus they are partitioned at operation .","After the lines are identified and merged, words are identified in some embodiments. Some embodiments use difference clustering, as described in United States Publication No. 2007\/0250497, now issued as U.S. Pat. No. 7,603,351, to identify words based on spacing between letters within a word and between words. In some embodiments, the difference clustering also provides information about segment gaps, column gaps, etc. Some embodiments use the memory and processing efficiency techniques described below in Section VII to perform difference clustering.","B. Identifying Words and Gaps Using Difference Clustering",{"@attributes":{"id":"p-0254","num":"0253"},"figref":"FIG. 36","b":"3600"},"In some embodiments, cluster analysis is a set of techniques that can be applied to a collection of data points to group points into clusters that are closer to each other than to the points of another cluster. In some embodiments, cluster analysis is applied to data points that represent the horizontal and vertical gaps between objects such as glyphs, words, and text lines. For example, some embodiments use k-means cluster analysis, which will now be described. Starting with a collection of numbers (p, . . . , p) representing spatial gaps, and a known value for k (the number of clusters), the technique is used to partition the numbers into k clusters C, . . . , Cdefined by inequalities of the form C={p|a\u2266p<a+1} where a, . . . ais an increasing sequence. Before applying the k-means technique, the differences p\u2212pare sorted by size and the k\u22121 largest differences are taken to be the partition points. For example, if p\u2212pis one of the k\u22121 largest differences, then pis in a different cluster from p, and pis one of the successive values a. k-means cluster analysis is then applied to repeatedly refine the clusters. The k-means technique involves taking the mean of the numbers in each cluster, then re-distributing the pinto clusters by associating them with the closest calculated mean. This is performed repeatedly until it causes no change in the clusters or their means.","In some embodiments, a technique disclosed and referred to herein as \u201cdifference clustering\u201d is used to determine the number of levels of structural relationships that exist between content elements comprising a given source content and\/or one or more hierarchical relationships between such levels, as well as one or more characteristics that can be used to determine whether a content element is related to another content in each of the determined levels. In some embodiments, difference clustering utilizes the k-means technique together with other techniques. In the example shown in , differences between positions of content elements (spacing) are analyzed using difference clustering analysis. In some embodiments, by analyzing the spacing between content elements, the content elements can be grouped at least in part using the grouping data of the spacing. In some embodiments, each directional component of spacing is analyzed separately. For instance, difference clustering analysis on the horizontal component is used to distinguish between character spacing, word spacing, and column spacing. Difference clustering analysis on the vertical component can be used to distinguish line spacing, paragraph spacing, and text box spacing in some embodiments. Process  conceptually illustrates difference clustering analysis for a single directional component. The process may be used again to analyze one or more additional directional components. In some embodiments, the results of performing difference cluster analysis along one or more dimensions are combined together to determine the structural relationships between content elements at one or more levels.","As shown in , process  receives (at ) a portion of a document. The process then identifies (at ) the locations of elements in the document. In some embodiments, the elements include characters, glyphs, images, lines, drawings, boxes, cells, margins, and\/or various other content elements. In some embodiments, locations of the elements include determining and\/or assigning one or more location coordinate components to the elements. In some embodiments, the locations of the elements are organized in an order. For example when analyzing the horizontal spacing of characters, the characters are organized in increasing horizontal coordinate order for each line of characters. In some embodiments, the location coordinate values of the elements are desired to be associated with the spacing between the elements, and the location values are compensated for the width\/length of the element. For example, when determining a compensated horizontal coordinate (x-coordinate) value for an element in the n-th position of an organized order of elements, the following formula is used:",{"@attributes":{"id":"p-0258","num":"0257"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msubsup":{"mi":["X","n","\u2032"]},"mo":"=","mrow":{"msub":{"mi":["X","n"]},"mo":"-","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"i","mo":"=","mn":"1"},{"mi":"n","mo":"-","mn":"1"}]},"mo":"\u2062","msub":{"mi":["W","i"]}}}}}},"br":{},"sub":["n ","n ","i "]},"Next, the process determines (at ) the first-order differences between locations of adjacent elements. In some embodiments, an element is adjacent to another element when the two elements with at least one same location coordinate component value are ordered next to each other in at least one other location coordinate component value. For instance, two glyphs are adjacent to each other if both of the glyphs belong to the same text line and no other glyph exists between them. In some embodiments, two elements have at least one same location coordinate component when the difference between corresponding location coordinate component values of the elements is below a limit value or within a range value. In various embodiments, an element is adjacent to another element when the two elements are next to each other in an order and\/or organization associated with the identified locations of the elements. In some embodiments, the first order difference between the locations is the difference between the width\/length compensated location coordinate values. For instance, when determining the difference between compensated horizontal coordinate (x-coordinate) values for the adjacent elements in the nth and n+1 position of an organized order of compensated horizontal coordinates, in some embodiments the following formula is used.\n\n\n\nIn some embodiments, the first order difference is associated with the gap spacing between glyphs in the content.\n","Next, process  sorts (at ) the first order differences. In some embodiments, organizing the first order difference includes ordering the first order differences in an increasing order. In some embodiments, organizing the first order differences includes assigning a weight value to one or more of the first order differences and organizing the first order differences at least in part by using the weight value(s). For instance, in some embodiments, actual glyph spacing is divided by expected glyph spacing for each specific pair of glyphs given the font that is used and its font metrics including size, default letter spacing, and a table of kerning values stored with the font file. This ratio of actual to expected spacing is ordered by increasing value, and the values of this ratio are used in place of the first order differences throughout the remainder of the difference clustering method.","The process then determines (at ) second order differences between the sorted first order differences. For instance, when determining the second order difference between first order differences in an i-th and i+1 position of an organized order of first order differences, the following formula is used:\n\n\u0394\n\nwhere \u0394Xis the i-th second order difference, \u0394Xis the first order difference in the i-th position of the sorted first order differences, and \u0394Xis the first order difference in the i+1 position of the same sorted first order differences. In some embodiments, the second order differences are associated with differences between the spacing of glyphs.\n","Next, process  determines (at ) the number of cluster levels by analyzing the second order differences. In some embodiments, analyzing the second order differences includes organizing the determined second order differences. In some embodiments, organizing the second order difference includes ordering the second order differences in an increasing order and\/or plotting the second order differences in an order of increasing second order difference values. In some embodiments, organizing the second order difference includes assigning a weight value to one or more of the second order difference. In some embodiments, organizing the second order difference includes grouping the second order differences into one or more groups. In some embodiments, the second order differences are each categorized as either an inter-group difference or an intra-group difference.","Intra-group differences are associated with relatively smaller second order difference values and can represent second order differences of first order differences within the same clustering group. An example of an intra-group difference is the relatively small variation one would expect to find in the character-width compensated spacing between letters in the same word. Inter-group differences are associated with relatively larger difference values and can represent second order differences of first order differences between different clustering groups. An example of an inter-group difference is the relatively large difference between the space between two words, on the one hand, and the space between two letters in the same word, on the other.","In some embodiments, the categorization of second-order differences into intra-group and inter-group values is achieved by applying 2-means cluster analysis to the ordered second-order difference values; specifically, taking (p, . . . , p) to be {\u0394X, . . . , \u0394X} in increasing order. Similarly, any other technique of cluster analysis that is sufficient to distinguish two clusters of data values can be applied to the ordered second-order difference values. The intra-group differences are then in the first cluster C={p|a\u2266p<a}, and the inter-group differences are in the second cluster C={p|a\u2266p<a}, where a<a<a. In some embodiments, the number of levels into which content elements are determined to be organized, based on their spatial relationships analyzed as described above, is one more than the number of inter-group differences found through difference cluster analysis. For instance, when two inter-group differences exist, the number of structural levels is three. Taking a simple example, consider characters that form words comprising a single line of text. The first order differences in the spacing between characters in the x-x-direction would yield a second order difference between character spacing and word spacing (one inter-group difference), indicating two levels of structure (words and lines). When the text had been in two columns, a further second order difference (between word spacing and column spacing) would have been detected, for a total of two inter-group differences, indicating three structural levels in the x-direction (words, lines, and columns). Repeating the analysis in the y-direction and combining results would, when applicable to the particular content, identify in some embodiments any further structural levels (e.g., paragraphs, etc.) that are manifested in the spacing between characters and groups of characters.","The process then determines (at ) characteristics of each cluster level. The process then ends. In some embodiments, determining the characteristics includes determining which first order difference (and\/or what range of first order differences) is associated with which cluster level. In some embodiments, determining the characteristic includes computing a statistical value associated with the first order differences associated with a cluster level. For example, by determining the average, minimum, maximum of the portion of first order differences associated with a cluster level, the average, minimum, and maximum spacing between glyphs in the content can be determined.","Let L be the number of levels of clustering. In some embodiments, L is computed by counting the number of points in the second cluster of second-order differences and adding 1. Next, the groups of first-order differences corresponding to each level can be identified, and the clusters of compensated X\u2032 values can be identified at each level, for example, in one of the following two ways.","One possibility is to perform L-means cluster analysis on the first-order differences. The resulting L clusters are the groups of first-order differences corresponding to each level. Next the number Kof clusters of X\u2032 at level m are computed by adding the number of points in the (m+1)th, (m+2)th, . . . , and Lth clusters of first-order differences plus 1. Finally, perform K-means analysis on the compensated X\u2032 values to produce the Kclusters at level m.","A second possibility is, when originally computing each first-order difference \u0394X=X\u2032\u2212X\u2032, to store its value together with the index n that can be used to identify either one of the pair of successive X values that were subtracted to produce that difference. Store the value and the index reference in a single \u201cfirst-order difference\u201d data structure. Similarly, when originally computing each second-order difference, store its value together with an index reference that can be used to identify either one of the pair of successive \u201cfirst-order difference\u201d data whose values were subtracted to produce that difference. Now, for each second-order difference that is in the second cluster (i.e. for each inter-group difference), use its index reference to identify a partition point in the first-order differences. This means that the index identifies a pair of first-order difference values that are partitioned to be in separate clusters. Partitioning in this way produces L clusters of first-order differences corresponding to the L levels of clustering in the original data. Now, the clusters of X\u2032 values at level n are identified as follows: for each first-order difference data in the (m+1)th, (m+2)th, . . . , and Lth cluster of first-order differences, use its index reference as a partition point in the X\u2032 values.",{"@attributes":{"id":"p-0269","num":"0268"},"figref":["FIG. 37","FIG. 37","FIG. 36","FIG. 37"],"b":["3600","3705","3710","3715"]},"In the example shown, the data are associated with horizontal spacing between glyphs. By ordering the first order difference values, the example illustrates three groups of first order difference values , , and . First order difference value group  is associated with spacing between glyphs that compose words. First order difference value group  is associated with spacing between words. First order difference value group  is associated with spacing between columns. For each pair of adjacent first order difference values, a second order difference value (i.e., the difference between one first order difference and an adjacent first order difference) is determined and plotted in an increasing order on a line associated with second order difference values. Second order difference value group , , and  each include one or more points associated with the second order difference values. In some embodiments, point  is a member of a group of associated second order difference points comprising a second order difference value group.","In some embodiments, point  is a member of a group of associated second order difference points comprising a second order difference value group. In some embodiments,  is identified as one cluster and  together with  is identified as a second cluster. Second order difference values between the first order difference values within the same single first order difference value group (intra-group differences) are included in second order difference value group . In a text document, for example, typically the character-width compensated spacing between characters within a word, or in the spacing between different pairs of words, varies only slightly. The second order difference between inter-group adjacent points in group  and  is included in point . The second order difference between inter-group adjacent points in group  and  is included in point . Since there exists two inter-group second order difference values in the example, there are two plus one (three) grouping levels (in this example, words, sentences or parts thereof on a line of text within a column, and columns). By determining the minimum and maximum of the first order difference values in group , minimum and maximum spacing between glyphs that compose words can be determined, and similarly group  and  can be used to determine word spacing and column spacing respectively.","In some embodiments, the minimum and maximum spacing associated with each grouping level is used to group content elements (e.g., glyphs) accordingly, such as by identifying groups of characters that comprise words, group words into lines of text within a column, etc. By using data determined from cluster analysis, the glyphs are grouped into the determined levels of groupings. It is possible to perform the analysis quickly and automatically with respect to any arbitrary content, in part because it is not necessary to know in advance how many grouping levels there are in the structure of the content or other collection of elements being analyzed. Regardless of the number of grouping levels, the number of levels is determined in just two processing steps. By determining the average of the first order difference values in group , the average spacing between glyphs that compose words can be determined. Similarly, other statistical quantities can be determined for the glyphs that compose words. Similarly, an analysis of the first order difference values in group  and  can be used to determine statistical quantities relevant to word spacing and column spacing.","C. Splitting Lines","Some embodiments split text lines after word and segment break information is generated. Text lines are split, for example, where the text line spans more than one column, as the text in the two (or more) sections is probably not meant to be read together. Some embodiments use guide and gutter information derived from processes described above in Section III along with information from difference clustering (e.g., segment gaps, etc.) in order to split the text lines.",{"@attributes":{"id":"p-0275","num":"0274"},"figref":["FIG. 38","FIG. 39","FIG. 39","FIG. 38"],"b":["3800","3800","3900","3800","3805","3300","2100","2500","2600"]},"Next, the process sorts (at ) the received text lines based on the y-coordinate of their baselines. Starting at the bottom of the page, the process selects (at ) the bottom-most unevaluated text line and identifies (at ) potential splits in the selected line. Some embodiments define a potential split as any gap between two words in a line either (1) is a segment gap, as defined by difference clustering, or (2) has a guide or gutter passing through it. Other embodiments only use one or the other, or different definitions, for potential splits.","The process then determines (at ) whether any potential splits were identified. When none were identified, the process proceeds to , described below. Otherwise, the process selects (at ) a potential split from the currently selected text line. The process then determines (at ) whether the x-interval of the potential split overlaps with the x-interval of any potential split from the previous text line. The first text line evaluated will not have a previous text line, and therefore there will be no overlapping potential splits. When the x-interval of the currently selected potential split does not overlap with the x-interval of a potential split from the previous line, the process proceeds to  which was described above. Otherwise, the process associates (at ) the overlapping potential splits. The process then proceeds to  which was described above.","When there are no more unevaluated potential splits, the process determines (at ) whether there are more lines to evaluate. When more lines remain, the process proceeds to  to identify potential splits in the next line and test them for overlap.","When all lines have been evaluated, then all the potential splits in the document portion have been identified and associated. The process then performs several operations to eliminate false positives (i.e., potential splits that should not actually split a line of text). The process determines (at ) whether any groups of potential splits were identified. When none were identified, the process ends. Otherwise, the process selects (at ) a group of associated potential splits and defines (at ) a rectangular strip passing completely through the potential splits of the selected group. The strip, in some embodiments, has an x-interval that is the intersection of the x-intervals of all the potential splits in the selected group (i.e., the x-interval for a strip two of whose potential splits barely overlap will be very thin).",{"@attributes":{"id":"p-0280","num":"0279"},"figref":["FIG. 39","FIG. 39"],"b":["3900","3905","3910","3915","3920"]},"After defining the rectangular strip for the selected group, the process determines (at ) whether the strip spans fewer than a threshold number of text lines. Strips that span one or only a few text lines are not likely to represent an actual split in reading, but rather may be tabs within a line or other non-breaking gaps. Sometimes segment gaps are found by difference clustering where a gap between words is very large due to justified text. When the strip spans fewer than the threshold number of lines, the process removes (at ) the group from the list of potential splits and will not split the text lines at those locations. The process then proceeds to  which is described below. On page , the potential splits making up strips  and  are removed because they do not have enough splits to be a likely column break. More likely, the potential splits are tabs or large word gaps.","When the strip spans at least the threshold number of lines, the process determines (at ) whether the current strip is within a threshold distance of another strip. Some embodiments only look to prior strips that have been tested and not yet removed when determining whether another strip is within a threshold of the current strip. When the current strip is within the threshold distance of another strip, the process removes (at ) the group with a vertically shorter strip (in some cases, where the lines are all the same size, this is the strip that spans fewer text lines). The process then proceeds to  which is described below.","Strips  and  of page  both qualify as spanning enough text lines to pass operation . However, in some embodiments the strips are too close to each other to both be kept. Accordingly, the group of potential splits making up strip  is removed because  is the longer of the two strips. This process prevents list bullets or number from being split from the items they reference, in some embodiments, as well as other potentially problematic splits.","When the current strip is not too close to another strip, the process determines (at ) whether the strip includes a threshold number of subsequent potential splits in a row that are not segment gaps. In some embodiments, it is possible to identify a guide and\/or gutter where word edges accidentally align. This is especially likely if the text is displayed in a monospace font (e.g., Courier). When the strip includes at least this threshold number of subsequent non-segment gap potential splits, the process removes (at ) the group from the list of potential splits and will not split the text lines at those locations.","Next, the process determines (at ) whether there are more groups of potential splits that have not been tested against the various threshold requirements. When more groups remain, the process proceeds to  to select and evaluate the next group of potential splits. Otherwise, when all groups have been evaluated, the process splits (at ) the text lines using any of the splits that have not been removed. The process then ends. In the case illustrated for page , the only splits that would be used are those in the center separating the two columns of text.","While process  is illustrated using three specific tests (operations , , and ) to remove groups of potential splits, some embodiments employ only a subset of these, while other embodiments use other tests that are not shown in order to eliminate potential splits from consideration.","D. Paragraph Identification","In some embodiments, once lines of text have been merged and split, the lines are grouped into paragraphs.  conceptually illustrates a process  of some embodiments for grouping text lines into paragraphs. Portions of process  will be described in conjunction with .  illustrates the identification of paragraphs on a page  of a document. As shown in , process  receives (at ) text lines for a portion of a document. The text lines have already been merged (e.g., by process ) and split (e.g., by process ) in some embodiments before process  is performed. In some embodiments, the document portion is an entire document, a section of a document, a page, a zone, etc.","The process determines (at ) whether there are any lines in the document portion. When there are none, the process ends. Otherwise, beginning at the top of the received document portion, the process selects (at ) the first unevaluated text line in the document portion. The process then determines (at ) whether there is more than one text line below the selected line. In some embodiments, the lines must be within a particular vertical distance of each other for the lower line to be considered below the selected line for the purposes of operation . Some embodiments require at least three text lines to make judgments about whether the text lines belong to the same paragraph. In some embodiments, this requirement is imposed because two spacings (i.e., the spacing between the first and second text lines and between the second and third text lines) are necessary in order to make a comparison.","When there are two or more lines below the selected text line, the process proceeds to  which is described below. Otherwise, when fewer than two lines are below the selected text line, the process places (at ) the selected line in a paragraph by itself. The process then determines (at ) whether there are more lines in the document portion. When there are no more lines (e.g., when there is only one line of text in the document portion), the process ends. Otherwise, when there are more lines, the process proceeds to  and selects the next line of text.","When, at , there are two or more lines of text below the line selected at  (i.e., the first line in the current paragraph), the process identifies (at ) the next two lines below the selected text line. The process then determines (at ) whether the spacing and alignment is consistent between the three lines. In some embodiments, this determination involves examining whether the vertical distance from the first to second line is the same as the vertical distance from the second to third line. Some embodiments use the baselines of the text lines to determine the vertical spacing. Alignment differences, in some embodiments, are identified if one of the lines begins indented, or ends left of the other lines, thus signaling a likely beginning or end of a paragraph.","When the spacing and alignment is not consistent, the process applies (at ) heuristic rules to determine whether to add either of the identified lines to the paragraph with the selected first line. For instance, in some embodiments, when the first two lines are close together and the third line is further down, the first two lines are placed in one paragraph and the third line is the start of the next paragraph. Similarly, in some embodiments, when the first line is further from the second and third, the first paragraph is a one-line paragraph and the next paragraph starts at the second line. Similar rules are used in some embodiments for alignment differences between the lines. After applying the heuristic rules, the process proceeds to  to select the next unevaluated text line (i.e., the next line that is not yet assigned to a paragraph) and start a new paragraph.","When the spacing and alignment is consistent between the three lines, the process places (at ) all three lines in the same paragraph. Some embodiments identify spacing and alignment properties of the paragraph as well. For instance, some embodiments identify paragraphs as left-aligned, right-aligned, justified, centered, etc. Some embodiments leave open multiple possibilities (e.g., a paragraph with an indented first line, all three lines right-aligned or very close, and the lower two lines left-aligned could possibly be any of the three of left-aligned, right-aligned, or justified).","After the initial phase of identifying the start of a new paragraph, process  attempts to add lines to the paragraph. In some embodiments, the line addition is based on the spacing and alignment properties determined from the three lines making up the start of the paragraph. In other embodiments, as lines are added that do not conflict with the spacing and alignment properties for the paragraph, the spacing and alignment properties are refined based on any further evidence.","Next, the process determines (at ) whether there are any more lines in the document portion. When there are no more lines (i.e., the document portion has exactly three lines), the process ends. Otherwise, the process identifies (at ) the next text line in the document portion. The process then determines (at ) whether there is a spacing or alignment mismatch between the current paragraph and the identified next line. When there is a mismatch, the process ends the paragraph and proceeds to , which was described above. In such a case, the recently mismatched line will be the line selected at .","Otherwise, when the spacing and alignment line up, the process adds (at ) the line to the current paragraph. The process then proceeds to , which was described above. In some embodiments, an alignment mismatch is found when the identified next text line does not fit one of the properties (e.g., justified) of the paragraph. Similarly, if the spacing between the last line in the paragraph and the next line is increased as compared to that of the paragraph, then a spacing mismatch is found in some embodiments.","Some embodiments employ other stopping conditions (e.g., conditions resulting in the identified line not being added to the paragraph). For instance, some embodiments recognize if the first word on the identified line would fit into the white space at the end of the last line of a left-aligned paragraph. When this is the case, the new line is assumed to be part of the next paragraph because if it were part of the current paragraph, then the word would be in the white space at the end of the last line rather than starting a new line. Similarly, some embodiments recognize an indent as indicating a new paragraph. A third condition of some embodiments is if the identified line is uniformly styled (e.g., all bold, or of a larger font size) and different from the styling of any character on the previous line.","Once process  has completed, all of the paragraphs in the document portion are identified, and all lines of text are assigned to a paragraph. Some embodiments then use the paragraphs to identify columns and layouts.",{"@attributes":{"id":"p-0299","num":"0298"},"figref":"FIG. 41","b":["4100","4000","4105","4110","4115","4120","4125","4105","4110","4115","4115","4120"]},"E. Column and Layout Identification","Some embodiments place paragraphs into columns and layouts after identifying the paragraphs. In some embodiments, a column is a vertically ordered group of paragraphs in which the text reads coherently from the top to the bottom. A layout in some embodiments is a collection of non-overlapping columns and a linear layout in some embodiments is a horizontally ordered group of columns in which the text reads coherently from the top of the left-most column to the bottom of the right-most column. For example, some embodiments classify a simple page with unsegmented text lines and no headers or footers as a single linear layout with one column.",{"@attributes":{"id":"p-0302","num":"0301"},"figref":["FIG. 42","FIGS. 43-46","FIGS. 43 and 44","FIGS. 45 and 46"],"b":["4200","4200","4300","4400","4300","4400"]},"As shown in , process  receives (at ) information for paragraphs for the portion of the document. The document portion in some embodiments is an entire document, a section of a document, a page, a zone, etc. In some embodiments the paragraph information is determined using process  described above. The process then determines whether there are any paragraphs to select. When there are none, the process exits.","Otherwise, the process selects (at ) a paragraph. In some embodiments, the paragraphs in the document portion are selected in order, starting at the top-left, whereas in other embodiments the paragraphs are selected in a random order.","Next, the process calculates (at ) the in-order, out-order, left-order, and right-order, as well as sets of paragraphs that accompany each of these values. The out-order of a paragraph p is calculated in some embodiments by using a set B(p). The set B(p) is initially all paragraphs below paragraph p in the document portion that overlap p horizontally (i.e., that overlap x-coordinates). For instance,  illustrates a page  with eleven paragraphs including paragraph P . The set B(P) is initially {Q, R, S, T, U}. Next, the paragraph closest top is identified as q, and all paragraphs that overlap paragraph q horizontally are removed from the set B(P). In the case of paragraph P , paragraph Q  is the closest to paragraph P, and paragraphs R , S , T , and U  are removed from the set B(P). At this point, the set B(P) is {Q}.","Some embodiments then continue onto the next closest paragraph to p that was initially in the set B(p), and remove any paragraphs from B(p) that are below and horizontally overlap this next closest paragraph. Other embodiments continue to the next closest paragraph to p that remains in the set B(p), and remove any paragraphs from B(p) that horizontally overlap this paragraph. Either way, in the example of , the set B(P) for paragraph P  is {Q}. The out-order of p is then the cardinality (i.e., number of elements) of the set B(p). This is repeated for each paragraph in B(p). Thus, in this case the out-order of paragraph P  is 1. As an example of a paragraph with an out-order greater than 1, for paragraph R , the set B(R) is {S, X}, so that the out-order of paragraph R  is 2.","The in-order of a paragraph p is calculated similarly to the out-order in some embodiments by using a set A(p). The set A(p) is initially all of the paragraphs in the document portion above p that overlap p horizontally. The closest paragraph top is selected as paragraph q, and the paragraphs that overlap paragraph q horizontally are removed from A(p). This is then repeated for each of the paragraphs in A(p). In the example page , the set A(P) for paragraph P  is the empty set, while the set A(R) for paragraph R  is {Q, W}. The in-order of a paragraph p is the cardinality (i.e., number of elements) of the set A(p).","The left-order and right-order of a paragraph p are also calculated similarly in some embodiments, using a set L(p) (paragraphs left of p and vertically overlapping p, using the same removal rules) and a set R(p) (paragraphs right of p and vertically overlapping p, using the same removal rules). Some embodiments use L(p) and R(p) for flow graphs (see below) when it has been determined (e.g., by an external means) that the language direction is top-down. For page , the set R(P) for paragraph P  is {V}, while the set L(V) for paragraph V  is {P}. The sets L(R) and R(R) for paragraph R  are both empty.","Once the in-order, out-order, left-order, and right-order are calculated for the selected paragraph, the process  determines (at ) whether more paragraphs remain for which the various values must be calculated. If more paragraphs remain, the process proceeds to  to select another paragraph.","Otherwise, once the values are calculated for all paragraphs, the process generates (at ) a flow graph for the paragraphs. The flow graph of some embodiments is generated such that each paragraph in the document portion being evaluated is a node. A directed edge is drawn from the node for a paragraph p to each node for the paragraphs in the set A(p). This is the same, in some embodiments, as drawing a directed edge from each node for the paragraphs in the set B(p) to the node for the paragraph p.  illustrates an initial flow graph  for the page .","Next, process  identifies (at ) call-outs. In some embodiments, identified call-outs are removed from the flow graph. A call-out, in some embodiments, is a text element on a page that is meant to be read in an order independent from the rest of the text on the page. Some examples of call-outs include headers and footers, footnotes, margin notes, side-bars, and other blocks of text placed amongst other elements such as large-font quotes in a magazine article.","Some embodiments identify call-outs based on a combination of the geometry of the text element, its position on the page, its flow properties (in-order, out-order, left-order, and right-order), and the style properties of its elements. For instance, when a vertex v includes a one-line paragraph that is close to the top of a page, the distance from the one-line paragraph to any element in A(v) is more than one line height, L(v)\u22661, R(v)\u22661, and any vertices in L(v) and R(v) share these conditions, then some embodiments classify the paragraph as a header call-out. Requirements for a footer call-out are similar in some embodiments, except looking for the distance to the bottom of the page and to elements in B(v).","Some embodiments also identify sidebars that jut into columns (and are not in their own zone), randomly located text boxes, small bits of text with no obvious relationship to other text (e.g., figure captions), etc. as call-outs. Some embodiments make these determinations (as well as other determinations of flow properties) based on a purely textual analysis, whereas other embodiments incorporate images into the analysis (e.g., as further evidence for a figure caption). For example, in some embodiments, some embodiments identify single-line paragraphs distant from all elements in A(p) and B(p) as isolated small paragraphs. Captions are identified in some embodiments when a paragraph with a single text line is enclosed by the bounds of an image and is aligned in particular ways with the image bounds (e.g., centered near the bottom, centered near the top, etc.).","When the rectangular bounding boxes of two or more paragraphs intersect, some embodiments identify all but one of the paragraphs as intersection call-outs. For instance, suppose that two paragraphs p and q overlap and B(p)={q, r}. When r has an in-order of 1 or when q is in A(r), then q is an intersection call-out in some embodiments. Some embodiments classify as an intersection call-out any paragraph p whose style and\/or alignment properties are not consistent with the paragraphs in A(p) or B(p). When two paragraphs intersect, and none of the above rules applies, some embodiments classify the paragraph with smaller area as a call-out.","After generating the flow graph for the paragraphs in the document portion, the process  merges (at ) nodes of the flow graph into columns. Some embodiments merge nodes for paragraphs p and q if A(p)={q} and B(q)={p}. This indicates that paragraphs p and q are in the same column in some embodiments. In some embodiments, the new node pq will have A(pq)=A(q), B(pq)=B(p), L(pq)=L(p)+L(q), and R(pq)=R(p)+R(q). For example, in , the flow graph  is modified such that nodes S , T , and U  are merged into node STU  in modified flow graph . The other nodes are modified similarly.",{"@attributes":{"id":"p-0316","num":"0315"},"figref":["FIG. 46","FIG. 44"],"b":["4601","4400","4420","4620","4601"]},"Once call-outs have been identified (and, in some embodiments, removed from the flow graph), process  partitions (at ) the flow graph into layouts. Some embodiments define labels for expansion and reduction edges as part of the partitioning process. In some embodiments, if the out-order of a paragraph p is greater than 1, and the in-order of each paragraph q in the set B(p) is 1, then the edge from p to each q in B(p) is an expansion edge. Similarly, in some embodiments, if the in-order of a paragraph p is greater than 1, and the out-order of each paragraph q in the set A(p) is 1, then the edges from each q in A(p) to p is a reduction edge.  illustrates that the edges leading into node R  are both reduction edges, and the edges leading out of node R  are both expansion edges.","The partitioning of some embodiments examines each vertex v the edges of which are all labeled. When the in-order of v is greater than 1, some embodiments define a partition the elements of which are B(v) so long as A(p)={v} for each p in B(v). Similarly, when the out-order of v is greater than 1, some embodiments define a partition the elements of which are A(v) so long as B(p)={V} for each p in A(v). When both of these partitions are possible, the vertex v is defined as a partition by itself. Based on these rules, the flow graph  is partitioned into three partitions , , and .","Some embodiments place any remaining nodes into one or more partitions such that the smallest number of partitions is defined without any geometric overlap between the partitions. Due to complex page structure, some embodiments use more relaxed partitioning rules than those described above. For instance, when a partition could be created from a node v, except that the out-order of v is greater than 1, then elements of A(v) that are far from v and narrow relative to v are eliminated in some embodiments. When only one element remains in A(v), the edges from v to the removed vertices are removed, and partitioning is continued. Once partitioning is complete, the process  ends.","In some embodiments, each partition corresponds to a linear layout, and each of the final (merged) nodes corresponds to a column. Once partitions are defined, some embodiments calculate properties of the document portion such as gutter width, margins, in-line or floating images, etc.","Furthermore, layout and flow information (including word, line, paragraph, and column data) is used prominently in the display of the document and enabling more robust user interaction with the document, as described below in Sections V and VI. For instance, in some embodiments, a user might wish to view a complex document that includes several columns of text, images, call-outs, captions, etc., and be able to copy and paste the entire text of the document into a text editor. In order for this to be accomplished, a reading order is assigned to each of the elements in the document that attempts to identify the order in which a human would read through the elements of the document.","For instance, some embodiments assign reading orders to columns, such that the reading order follows the expected order in which a human would read the columns from the start to end of the document or page. Other embodiments assign reading orders to other structural elements (e.g., paragraphs, words, etc.). In some embodiments, when the user copies and pastes the entire text of such a document into another application, the text appears in the application in the order that a human would read it. This is in contrast to copying and pasting from a standard PDF file that orders all text in a strict top-down configuration.","Some embodiments also insert images and shapes into the reading order. For instance, some embodiments will identify a particular image as associated with a particular column of text and insert the image either before or after (depending on the evidence in the document) the column of text. As an example, some embodiments identify that an image is associated with the caption for the image and insert the image into the reading order immediately prior to its caption.","Some embodiments also define links between structural elements. For instance, some embodiments use the reading order to define links between a paragraph at the end of a column and a paragraph at the beginning of the next column that are actually one paragraph. In some embodiments, to maintain the hierarchy that has each paragraph assigned to one particular column, a separate paragraph bridging the columns is not defined. Instead, a link between the two paragraphs is defined indicating that they are, in fact, one paragraph. Some embodiments use tests similar to those for adding lines to a paragraph in order to determine whether the top paragraph from a second column is actually a continuation of the paragraph at the end of a first column (i.e., examining spacing, alignment, font stylings, etc.). The link can then be used, e.g., if a user performs a selection operation (e.g., a triple-click) intended to select a paragraph within either of the defined paragraphs, the entire actual paragraph will be selected based on the link.","Some embodiments also define links between layouts (e.g., linking across pages) or zones. For instance, some embodiments can recognize continuation text (e.g., text in a newspaper indicating that a story continues on a different page) and can link the text in the layout with the continuation text to the layout where the text continues. Some embodiments only attempt such linking when a profile has been matched indicating that linking should be performed. For instance, if a document has been identified as a newspaper, then some embodiments will search for continuation text.","E. Software Architecture","In some embodiments, the layout and flow analysis processes described above are implemented as software running on a particular machine, such as a computer, a media player, a cell phone (e.g., an iPhone\u00ae), or other handheld or resource-limited devices (or stored in a computer readable medium).  conceptually illustrates the software architecture of a layout and flow analysis application  of some embodiments for identifying layout and flow characteristics of a document. In some embodiments, the application is a stand-alone application or is integrated into another application (e.g., a document reconstruction application), while in other embodiments the application might be implemented within an operating system.","Layout and flow analysis application  includes a line identification module , a line-merging module , a word identification module , a difference clustering module , a line splitting module , a paragraph identification module , a column and layout identification module , and an order calculator .",{"@attributes":{"id":"p-0329","num":"0328"},"figref":"FIG. 47","b":["4745","4705","4730","4705","4710","4710","3300","4710","4705","4705","4745","4725"]},"Word identification module  also receives information from the document content . In some embodiments, this information is information about the position of characters in the document. The word identification module  identifies characters that should be grouped together as words. Word identification module  passes information to, and receives information from, the difference clustering module . Difference clustering module  performs difference clustering on the document characters to return different levels of gaps between characters (e.g., word gaps, segment gaps, etc.). The word identification module  uses the difference clustering results to identify the words. Word identification module  passes its results (as well as other difference clustering results such as segment gaps) to the document content , as well as to line splitting module .","Line splitting module  receives line information from the line identification module and gap information from the word identification module, as well as other information (e.g., gutter information) from the document content . Line splitting module  identifies where lines should be split and outputs new line information based on the splits. The new line information is passed to document content  as well as paragraph identification module . In some embodiments, line splitting module  performs some or all of process .","Paragraph identification module  receives line information from line splitting module  as well as other information (e.g., alignment information) from document content . Paragraph identification module  identifies which lines should be grouped into paragraphs and outputs the result information. The paragraph information is passed to document content  as well as to the column and layout identification module . In some embodiments, paragraph identification module  performs some or all of process .","Column and layout identification module  receives paragraph information from paragraph identification module , as well as other information (e.g., zone information) from document content . Column and layout identification module  groups paragraphs into columns and groups columns into layouts. Column and layout information module  passes information to, and receives information from, order calculator . The order calculator  receives paragraph information from the module , and calculates the in-order, out-order, left-order, and right-order (as well as the corresponding sets A, B, L, and R) for the paragraphs. This information is then returned to the module  for use in generating a flow graph. The results from column and layout identification module  are passed to the document content . In some embodiments, column and layout identification module  performs some or all of process  described above.","In some embodiments, the results of the processes performed by the above-described modules or other modules are stored in an electronic storage (e.g., as part of a document object model). The document object model can then be used for displaying the document on an electronic display device (e.g., a handheld device, computer screen, etc.) such that a user can review and\/or interact with the document (e.g., via touchscreen, cursor control device, etc.).","V. Identification and Selection of Regions of Interest, and Navigation and Display of Documents","Document viewing applications such as an e-book reader will often need to know how to best display a document and navigate within a document. This is especially important on small-screen devices that cannot legibly display entire pages of documents at once. For instance, in some cases, a document viewer should be able to recognize that an entry in the table of contents links to a particular section of the document, or that two sections of a document are related (e.g., that a call-out is part of a particular article, or that one column flows into the next).","Some embodiments of the invention use information gained from document reconstruction (i.e., paragraph and column information, table information, etc.) for display and navigation of a document. Specifically, some embodiments adapt display and navigation of semantically reconstructed documents for display and navigation on small-screen devices (e.g., media players, cell phones, etc.).","A. Identification and Selection of Regions of Interest","Some embodiments provide methods for identifying and selecting a region of interest in a semantically reconstructed document, and then modifying the display of the document based on the selection of the region of interest.  conceptually illustrates a process  for displaying a document based on an identification of a position of interest in some embodiments. Process  will be described in conjunction with .  illustrates a sequence  (-) on a small-screen device in which a position of interest is selected and the display is modified in accordance with some embodiments of the invention.","As shown in , process  receives (at ) an indication of a position of interest in a semantically reconstructed document. In some embodiments, the semantically reconstructed document includes a document object model that is the result of document reconstruction as described above in Sections II-IV as well as in the concurrently filed U.S. patent application Ser. No. 12\/479,850, now published as US 2010\/0174980, entitled \u201cIdentification of Regions of a Document\u201d, which is incorporated herein by reference. A document object model in some embodiments includes a zone graph as described above in Section II, after it has been populated with content information throughout the document reconstruction process. The document object model of some embodiments also indicates the reading order of the content (e.g., of the columns, paragraphs, images, etc.).","Some embodiments receive an indication of a position of interest as a selection of a point on a display. For instance, a selection can be made with a cursor control device (e.g., a mouse, touchpad, etc.). A position of interest can also be indicated on a touchscreen device by a user tapping the screen (e.g., a single-tap, double-tap, pinching motion, etc.). Referring to , sequence  shows (at ) a user  selecting a point on the display , which is displaying a portion of a document. Position of interest  is illustrated (at ) at the point in the display  where the user touched the screen to make the selection.","Next, process  identifies (at ) a region of interest in the semantically reconstructed document. Sequence  shows (at ) that the paragraph  has been identified as the region of interest based on selection of position of interest . Some embodiments identify a paragraph as the region of interest when the position of interest is within the bounding box of the paragraph, as is the case with position of interest .","After identifying the region of interest, process  applies (at ) required transformations to place the region of interest in the viewing area of the display device. In some embodiments, the transformations include a combination of rotations, zooms, and translations, as described below with respect to processes  and . Next, the process draws (at ) the document based on the applied transformations. The process then ends. Sequence  shows (at ) that paragraph  has been zoomed in and centered both vertically and horizontally, according to specified transformations. In some embodiments, the process displays the original (i.e., unstructured) document, but uses the knowledge of the positions of the structural elements (e.g., from the structured document) to pan and zoom the document.",{"@attributes":{"id":"p-0343","num":"0342"},"figref":"FIG. 50","b":["5000","5000","5005"]},"Based on the position of interest, the process then determines (at ) a selected object in a semantically reconstructed document based on a received position of interest. In some embodiments, a selected object can be a character, word, text line, image, etc. In some embodiments, the semantically reconstructed document includes a document object model (DOM) that is the result of document reconstruction as described above in Sections II-IV as well as in the concurrently filed U.S. patent application Ser. No. 12\/479,850, now published as US 2010\/0174980, entitled \u201cIdentification of Regions of a Document\u201d, which is incorporated herein by reference. A document object model in some embodiments includes a zone graph as described above in Section II, after it has been populated with content information throughout the document reconstruction process.","The process next moves up (at ) the document hierarchy until either a paragraph or graphic object is reached. In some embodiments, the document hierarchy is the zone graph populated with content information (i.e., the DOM). When the selected object is a word, in some embodiments the process moves up the hierarchy from the word to the text line including the word to the paragraph including the text line.","The process then determines (at ) whether the identified object is a paragraph. When the identified object is not a paragraph, it is a graphic object. In some embodiments, the graphic object can be any of a shape, image, or joined graph (i.e., a compound graphic object). When the identified object is a graphic object, the process defines (at ) a rectangle of interest (ROI) as the upright bounding box of the identified object. The process then zooms (at ) such that the width and height of the ROI are no larger than the width and height of the display area. The process then proceeds to , which is described below.","When the identified object is a paragraph, the process defines (at ) a rectangle with the width of the parent column of the paragraph and the height of the paragraph. The process then applies (at ) any rotation for the paragraph to the rectangle and defines the ROI as the upright bounding box of the rotated rectangle. A paragraph is rotated if it is in a rotation group in the document object model in some embodiments. Some embodiments define a rotation group as described above in Section II.","The process then determines (at ) whether the paragraph baselines (prior to rotation) are steeper than the diagonal of the display area. For instance, when the display area is a square, the determination is whether the baselines are steeper or less steep than 45 degrees. When the paragraph baselines are steeper than the diagonal of the display area, the process zooms (at ) such that the ROI is no larger than the height of the display area. The process then proceeds to  which is described below. On the other hand, when the paragraph baselines are not steeper than the diagonal of the display area, the process zooms (at ) such that the ROI is no larger than the width of the display area.","Next, process  determines (at ) whether the ROI (as defined in the operations above) fits in the display area horizontally. When the ROI fits horizontally, the process centers (at ) the ROI horizontally. The process then proceeds to  which is described below. Otherwise, the process centers (at ) the position of interest horizontally. The process then determines (at ) whether the ROI fits in the display area vertically. When the ROI fits vertically, the process centers (at ) the ROI vertically. The process then proceeds to  which is described below. Otherwise, the process centers (at ) the position of interest vertically.","Next, the process determines (at ) whether either the bottom or top edge of the page that includes the position of interest is in the display area. When so, the process moves (at ) the visible page edge to the corresponding (i.e., top or bottom) edge of the display area so that only one page is displayed and the entire display area is occupied vertically. The process then determines (at ) whether either the right or left edge of the page that includes the position of interest is in the display area. When so, the process moves (at ) the visible page edge to the corresponding (i.e., right or left) edge of the display area so that only one page is displayed and the entire display area is occupied vertically. Finally, the process redraws (at ) the display area with all of the above transformations applied. The process then ends.","Some embodiments use other combinations of transformations (e.g., zooms, translations, rotations, etc.) to display a selected region of interest. For instance, while process  determines how to zoom differently for a region of interest that is a paragraph as compared to a region of interest that is a graphic object, other embodiments define a region of interest such that the zoom is the same for all regions of interest. For instance, process , described below, zooms on a region of interest in this manner.",{"@attributes":{"id":"p-0352","num":"0351"},"figref":"FIG. 51","b":["5100","5100","5000","5000","5100","5100","5105"]},"Based on the position of interest, the process then determines (at ) a selected object in a semantically reconstructed document based on a received position of interest. In some embodiments, a selected object can be a character, word, text line, image, etc. In some embodiments, the semantically reconstructed document includes a document object model that is the result of document reconstruction as described above in Sections II-IV as well as in the concurrently filed U.S. patent application Ser. No. 12\/479,850, now published as US 2010\/0174980, entitled \u201cIdentification of Regions of a Document\u201d, which is incorporated herein by reference. A document object model in some embodiments includes a zone graph as described above in Section II, after it has been populated with content information throughout the document reconstruction process.","Process  next moves (at ) up the document hierarchy until either a paragraph or graphic object is reached. In some embodiments, the document hierarchy is the zone graph populated with content information. If the selected object is a word, then in some embodiments the process moves up the hierarchy from the word to the text line including the word to the paragraph including the text line.","The process then determines (at ) whether the identified object is a paragraph. If the identified object is not a paragraph, then it is a graphic object. In some embodiments, the graphic object can be any of a shape, image, or joined graph (i.e., a compound graphic object). When the identified object is a graphic object, the process defines (at ) a rectangle of interest (ROI) as the upright bounding box of the identified object, then proceeds to , which is described below.","When the identified object is a paragraph, the process defines (at ) a rectangle with the width of the parent column of the paragraph and the height of the paragraph. The process then applies (at ) any rotation for the paragraph to the rectangle. A paragraph is rotated if it is in a rotation group in the document object model in some embodiments. Some embodiments define a rotation group as described above in Section II.","The process then defines (at ) the ROI as the upright bounding box that includes a first particular number of lines above the position of interest and a second particular number of lines below the position of interest. This definition is based on the assumption that a user is interested in the position of interest and would want to see a certain number of lines of text below and above that position of interest.","With the ROI defined, process  then zooms (at ) such that the width and height of the ROI are no larger than the width and height of the viewing area.","Next, process  determines (at ) whether the ROI (as defined in the operations above) fits in the display area horizontally. When the ROI fits horizontally, the process centers (at ) the ROI horizontally. Otherwise, the process centers (at ) the position of interest horizontally. The process then determines (at ) whether the ROI fits in the display area vertically. When the ROI fits vertically, the process centers (at ) the ROI vertically. Otherwise, the process centers (at ) the position of interest vertically.","After centering the position and\/or region of interest, the process determines (at ) whether either the bottom or top edge of the page that includes the position of interest is in the display area. If so, the process moves (at ) the visible page edge to the corresponding (i.e., top or bottom) edge of the display area so that only one page is displayed and the entire display area is occupied vertically. The process then determines (at ) whether either the right or left edge of the page that includes the position of interest is in the display area. If so, the process moves (at ) the visible page edge to the corresponding (i.e., right or left) edge of the display area so that only one page is displayed and the entire display area is occupied vertically. Finally, the process redraws (at ) the display area with all of the above transformations applied, then ends.","B. Display and Navigation of Semantically Reconstructed Documents","Some embodiments provide various methods for optimizing display and navigation of semantically reconstructed documents. In some embodiments, the display and navigation is optimized for small-screen devices (e.g., media players, cell phones, etc.).",{"@attributes":{"id":"p-0363","num":"0362"},"figref":"FIG. 52","b":["5200","5205"]},"The process then divides (at ) the semantically reconstructed document into sections. In some embodiments, the division is based on information in the document object model for the document. In some embodiments, each section is an ordered sequence of words, associated graphic objects, and other, nested sections. For example, nesting can appear as a boxed example or note, or as cells of a table.","Process  next adapts the viewing of the reconstructed document to accommodate the natural flow through the sections. The process then ends. The adaptations can manifest themselves in multiple ways in some embodiments.  illustrates one such adaptation of some embodiments.  illustrates a device  that is initially displaying a portion of a semantically reconstructed document in two columns  and . In some instances, the document initially had two columns, while in other cases the document has already been adapted for viewing on the device .",{"@attributes":{"id":"p-0366","num":"0365"},"figref":"FIG. 53","b":["5305","90","5310","5315","5320","5330"]},{"@attributes":{"id":"p-0367","num":"0366"},"figref":"FIG. 54","b":["5400","5400","5405"]},"Process  receives (at ) input scrolling past the end of the displayed region. The end can be the bottom (scrolling down) or the top (scrolling up) of the region in some embodiments. For instance, when part of a column of text is displayed, the process receives input scrolling up to the top of the column or down to the end of the column.","The process then automatically moves (at ) the next region in the flow of the document into the display using the semantically reconstructed hierarchical model of the document (i.e., the document object model). As discussed above, using the document object model, the process can recognize a flow through the text and associated graphics in the document. To continue with the column example, when a user scrolls down past the end of a column, some embodiments jump to the top of the next column. Some embodiments instead append the text from the top of the second column to the bottom of the first column and continue scrolling as though the text is all one column.",{"@attributes":{"id":"p-0370","num":"0369"},"figref":"FIG. 55","b":["5500","5505"]},{"@attributes":{"id":"p-0371","num":"0370"},"figref":"FIG. 56","b":["5600","5600","5605"]},"Process  modifies (at ) the layout for viewing on a small-screen device while maintaining the flow of the document by using the hierarchical model of the document (i.e., document object model). The process displays (at ) at least a portion of the modified layout on a small-screen device. The process then ends.  illustrates a small-screen device  displaying the text  from the first column of page . However, the text has been adapted for ideal viewing on the small-screen device. Rather than display the text very small so that a user has to squint, the text size is increased and the number of words per line is decreased. Scrolling down would enable a user to continue reading the text in order in some embodiments.","In some embodiments, the document object model for a document includes suggestions regarding how to adaptively display layouts for a variety of situations, display area sizes, and display area aspect ratios. These suggestions can be generated during the document reconstruction process based on the results of the reconstruction, can be set as user preferences, or can be set by the initial author of the document in some embodiments. Some embodiments store the reconstructed document information (e.g., the document object model) with the document, and can store such user preferences with the reconstructed document. Some embodiments store the document information in XML format, or as metadata of a PDF (or similar format) document.","VI. Selection of Text Across Layouts","In addition to display and navigating through documents, the ability to select text may be of great import to a user. Complex pages with multiple different text flows (e.g., multiple articles) which are in turn broken into multiple layouts may create difficulties for an application attempting to intelligently select text in order. When selecting text (e.g., for copying and pasting), it is critical that the ordering of the characters, words, text lines, etc. be preserved. This includes not just selections within a column, but selections that span across multiple columns, layouts, zones, or pages.","Some embodiments provide methods for selecting text within a semantically reconstructed document. In some embodiments, the semantically reconstructed document includes a document object model that is the result of document reconstruction as described above in Sections II-IV as well as in the concurrently filed U.S. patent application Ser. No. 12\/479,850, now published as US 2010\/0174980, entitled \u201cIdentification of Regions of a Document\u201d, which is incorporated herein by reference. A document object model in some embodiments includes a zone graph as described above in Section II, after it has been populated with content information throughout the document reconstruction process. The document object model of some embodiments includes layout and flow information, such as reading order of columns within a layout, and flow from one layout to the next.",{"@attributes":{"id":"p-0376","num":"0375"},"figref":"FIG. 57","b":["5700","5700","5705"]},"The process then displays (at ) a portion of the document. In some embodiments, the document is displayed in its original viewing dimensions on a standard screen. Some embodiments, though, display the document in an adaptive manner using one of the processes described above in Section V (e.g., if displaying the document on a small-screen device).","Process  receives (at ) a start point of a selection. The process also receives (at ) an end point of the selection. Some embodiments receive start and end points through a cursor control device (e.g., a mouse), a keyboard, or a combination thereof. For example, a selection can be defined by a user clicking on a start point in the text with a mouse, holding the mouse button down, dragging to an end point in the text, and releasing the mouse button. Similar processes can be performed with other cursor control devices. Some embodiments allow other sorts of selections with cursor control devices as well\u2014e.g., double-clicking to select a word, or triple-clicking to select a line of text. A user can also, in some embodiments, use selection keys on a keyboard (e.g., shift and arrow keys) to select text in a semantically reconstructed document.","In the case of a drag selection, some embodiments define the start point as the point at which the mouse was first clicked and the end point as the current point of the cursor if the mouse button is held down or the release point of the mouse button if it has been released. For double- and triple-clicks, or other such selection mechanisms that select a structural element (e.g., a paragraph, column, etc.), some embodiments define the start point as the bottom left and the end point as the top right of the bounding box of the structural element. In some embodiments, the bounding box of the structural element is the bounding box of the union of its typographic bounds. In some embodiments, the typographic bounds for a character extend from its anchor point on the left to the anchor point plus the width (possibly adjusted by kerning with the following character) on the right and from the ascent above the anchor to the descent below the anchor.","The process then determines (at ) the selected section of text using the start point, end point, and layout and flow properties of the document. The process then ends. Various embodiments provide different detailed processes, some of which are described below, for determining exactly which text is selected from which layouts in a semantically reconstructed document given a start and end point in the document.",{"@attributes":{"id":"p-0381","num":"0380"},"figref":"FIG. 58","b":["5800","5801","5801","5805","5810","5815","5800","5820","5825","5830","5815","5815","5830"]},{"@attributes":{"id":"p-0382","num":"0381"},"figref":"FIG. 59","b":["5900","5900","5905"]},"Next, the process assigns (at ) a reading order to each column in the document. Some embodiments start at a reading order of zero on each page (i.e., the first column that would be read is assigned reading order zero). Some embodiments impose the requirement that within a particular layout, the reading order assigned to each column must be consistent with the order of the columns in the layout and no column outside a particular layout can have a reading order between those of the starting and ending columns of the particular layout. As for which layout comes first in the reading order, that decision is arbitrary in some embodiments. Other embodiments discern a reading order from layout to layout based on the design of the page.","The process then displays (at ) a portion of the document. In some embodiments, the document is displayed in its original viewing dimensions on a standard screen. Some embodiments, though, display the document in an adaptive manner using one of the processes described above in Section V (e.g., when displaying the document on a small-screen device).","The process then receives (at ) start and end points for a text selection. Some embodiments receive start and end points through a cursor control device (e.g., a mouse), a keyboard, or a combination thereof. For instance, a selection can be defined by a user clicking on a start point in the text with a mouse, holding the mouse button down, dragging to an end point in the text, and releasing the mouse button. Similar processes can be performed with other cursor control devices. Some embodiments allow other sorts of selections with cursor control devices as well\u2014e.g., double-clicking to select a word, or triple-clicking to select a line of text. A user can also, in some embodiments, use selection keys on a keyboard (e.g., shift and arrow keys) to select text in a semantically reconstructed document.","Next, the process determines (at ) whether the start and end points are in the same layout. When the start and end points are not in the same layout, the process determines (at ) a new end point in the same layout as the start point. Some embodiments move the end point to the same layout as the start point on the assumption that the user probably accidentally drifted the selection device into the second layout, and because selections can be determined more reliably within a single layout as opposed to across layouts. Some embodiments define a line from the start to the end point, and the location where the line leaves the layout of the start point is defined as the new end point. Other embodiments translate the end point horizontally or vertically into the layout of the start point.","The process then determines (at ) whether the start point is before the end point in reading order. In some embodiments, when the start and end point are in the same column, reading order is determined such that the higher (and if tied, left-most) of the two points is the earlier point in the reading order. When the start point is after the end point in the reading order, the process switches (at ) the start and end point of the selection, such that the start point is always earlier in the reading order than the end point.","Next, process  determines (at ) whether the start and end points are in the same column. When the two points are in the same column, the process selects (at ) text in the column from the start point to the end point. The process then ends. Otherwise, when the two points are not in the same column, the process selects (at ) text from the start point to the bottom of the column including the start point, from the top of the column including the end point to the end point, and all intervening columns. The process then ends. In some embodiments, the first selected character is the character either at or to the right of the start point, and the last selected character is the character either at or the left of the end point. In some embodiments, if the end point is between two lines, then all of the line above is selected and none of the line below is selected. Once the text is selected, the process ends.",{"@attributes":{"id":"p-0389","num":"0388"},"figref":["FIG. 60","FIG. 60","FIG. 61"],"b":["6000","6000","6005","6010","6015","6005","1","6010","2","6015","3","6020","6025","6030","6100","6020","6025","5900","6030","6015","5900","6100","6005","6015"]},{"@attributes":{"id":"p-0390","num":"0389"},"figref":["FIG. 62","FIG. 63","FIG. 63"],"b":["6000","6220","6225","6230","6300","6220","6225","5900","6225","6220","6220","6300","6225","6305"]},{"@attributes":{"id":"p-0391","num":"0390"},"figref":"FIG. 64","b":["6400","5900","6400","5900","6400"]},"As shown, process  receives (at ) zone and layout information for a document. In some embodiments, zone information includes a zone graph, populated with the content of the document, as described above in Section II. Layout information, in some embodiments, includes columns and layouts as described above in Section IV, as well as the flow of reading through the layouts and, between layouts.","Next, the process assigns (at ) a reading order to each column in the document. Some embodiments start at zero on each page. Some embodiments impose the requirement that within a particular layout, the reading order assigned to each column must be consistent with the order of the columns in the layout, and no column outside a particular layout can have a reading order between those of the starting and ending columns of the particular layout. As for which layout comes first in the reading order, that decision is arbitrary in some embodiments. Other embodiments attempt to discern a reading order from layout to layout based on the design of the page.","Process  then displays (at ) a portion of the document. In some embodiments, the document is displayed in its original viewing dimensions on a standard screen. Some embodiments, though, display the document in an adaptive manner using one of the processes described above in Section V (e.g., if displaying the document on a small-screen device).","The process then receives (at ) start and end points for a text selection. Some embodiments receive start and end points through a cursor control device (e.g., a mouse), a keyboard, or a combination thereof. For instance, a selection can be defined by a user clicking on a start point in the text with a mouse, holding the mouse button down, dragging to an end point in the text, and releasing the mouse button. Similar processes can be performed with other cursor control devices. Some embodiments allow other sorts of selections with cursor control devices as well\u2014e.g., double-clicking to select a word, or triple-clicking to select a line of text. A user can also, in some embodiments, use selection keys on a keyboard (e.g., shift and arrow keys) to select text in a semantically reconstructed document.","Process  then defines (at ) a line between the start and end point. If either the start or end point (or both) is not in a column (i.e., is in white space, a graphic, etc.), then the process defines (at ) a new start point or end point (or both) at the edge of the last column that the line passes through. Some embodiments define this point at the edge of the column where the line passes through the edge. Other embodiments translate the start or end point horizontally into the column to define the new start or end point.","The process then determines (at ) whether the start point is before the end point in reading order. In some embodiments, when the start and end point are in the same column, reading order is determined such that the higher (and if tied, left-most) of the two points is the earlier point in the reading order. When the start point is before the end point, the process proceeds to  which is described below. When the start point is after the end point in the reading order, the process switches (at ) the start and end point of the selection, such that the start point is always earlier in the reading order than the end point.","Next, the process selects (at ) text from the start point to the end of the column that includes the start point, from the start of the column that includes the end point to the end point, as well as all columns in between the starting and ending column in reading order. The process then ends. In some embodiments, the first selected character is the character either at or to the right of the start point, and the last selected character is the character either at or the left of the end point. In some embodiments, when the end point is between two lines, then all of the line above is selected and none of the line below is selected.",{"@attributes":{"id":"p-0399","num":"0398"},"figref":["FIG. 65","FIG. 60","FIG. 60","FIG. 66"],"b":["6500","6020","6025","6000","6400","6020","6025","6015","6015","6015","6010","6015","6015","6010"]},"Similarly,  illustrates a selection  defined by start and end points  and  (on page  of ) according to process . Because the end point  is in a layout different from the start point , the entire layout of the start point, including most of column  and all of column , is selected. In addition, text in box  is selected up to the end point .",{"@attributes":{"id":"p-0401","num":"0400"},"figref":["FIGS. 61 and 63","FIGS. 65 and 66"],"b":["5900","6400"]},"VII. Efficient Cluster Analysis","As noted in various sections above and in the concurrently filed U.S. patent application Ser. No. 12\/479,844, now published as US 2010\/0174982, entitled \u201cIdentification of Compound Graphic Elements in an Unstructured Document\u201d, which is incorporated herein by reference, some embodiments of the invention utilize cluster analysis to perform document reconstruction. For instance, alignment guides are identified with the use of density clustering, joined graphs are identified with the use of bounds clustering, and gaps between characters are used to identify words and segment gaps with the use of difference clustering. However, cluster analysis can be very memory-intensive, such that it can be difficult for a resource-limited device, such as a cell-phone or media player, to perform cluster analysis.","Accordingly, some embodiments of the invention provide methods for performing efficient cluster analysis. In some embodiments, the efficient cluster analysis allows cluster analysis to be performed on a resource-limited device (e.g., a handheld device). Resource-limited devices can be limited in terms of available memory, processing power, both, or other computing resources.","In some embodiments, the cluster analysis uses indirectly sorted arrays that stores indices of an unsorted array. Some embodiments use indirectly sorted arrays to partition data at multiple different distance scales concurrently, so as to more quickly find an optimal partition of the data, as opposed to repeating cluster analysis at each different distance scale and comparing the results.",{"@attributes":{"id":"p-0405","num":"0404"},"figref":"FIG. 67","b":["6700","6700","6705"]},"The process then performs (at ) efficient cluster analysis on the document data on the resource-limited device. For instance, some embodiments perform difference clustering to identify words and segment gaps, density clustering to identify alignment guides, and bounds clustering to identify compound graphics.","Finally, the process semantically reconstructs (at ) the document on the resource-limited device based on the results of the cluster analysis. The process then ends.  illustrates a sequence  of some embodiments by which a document  is semantically reconstructed on a resource-limited device . The document  is initially parsed (at ) into a set  of characters with coordinates. For instance, character  (\u201cr\u201d) has coordinates {X, Y). Some embodiments also parse graphic objects (e.g., images, shapes, etc.)","Next, efficient cluster analysis is applied (at ) to the document data. In some embodiments, this includes using difference clustering to identify words, density clustering to identify guides, and bounds clustering to identify graphs to join. Other reconstruction processes are also performed (at ). For instance, paragraphs and columns are identified in some embodiments. One of ordinary skill will recognize that in some embodiments, the cluster analysis processes and other reconstruction processes are not necessarily segregated as far as the order they are performed. The result of the efficient cluster analysis and other reconstruction processes is a semantically reconstructed document  that can be displayed, navigated, etc.","A. Cluster Analysis as a Set of Operators","Some embodiments perform cluster analysis (whether it be difference clustering, density clustering, or bounds clustering) based on several operators that are applied to sequences of real numbers (r, r, . . . , r). Some embodiments include the following operators:\n\n","Some embodiments of difference clustering are performed in terms of the above operators. Similarly, because bounds clustering uses difference clustering with spread values substituted for first-order differences, some embodiments of bounds clustering are performed in terms of the above operators.","For instance, some embodiments apply the sorting operator S to input data, followed by the difference operator D to generate first-order differences. S and D are then applied to the result data to generate second-order differences (the differences between the differences). The second-order differences are sorted with S, and the second-order differences are then split into two disjoint subsequences (the intra-level differences and the larger inter-level differences).","In some embodiments, the splitting includes further application of D to the second-order differences to obtain third-order differences, followed by S to order the third differences. The split in second-order differences generally occurs where there is one third-order difference substantially larger than the rest. Some embodiments evaluate domain-specific factors as well.","Once the split is established, some embodiments apply P using a gap minimum equal to the smallest inter-level second difference to partition the ordered first differences, such that each partition represents a level of clustering. Some embodiments apply C to this partition, while some may not. To partition the data into clusters at a particular level, some embodiments apply P to the (sorted) input data using a gap minimum equal to the smallest difference at the particular level. Some embodiments apply C at this point as well, though often with different criteria for coalescing the cluster partition than for the level partitions. Lastly, some embodiments apply F to disqualify some of the clusters.","Some embodiments of density clustering are also performed in terms of the above operators. For example, some embodiments apply S followed by D to the input data to generate first-order differences, and apply S to sort the differences. For each of the differences d, some embodiments partition the ordered input data with the operator P using a gap minimum d, then filter the partitions using density constraints. Each of the post-filtering partitions is measured by an optimization metric and the optimal partition is selected as the final clustering. Some embodiments loop through the first-order differences (as gap minimums) starting with the largest and moving to successively smaller values in the sorted sequence.","In some embodiments, the loop can be ended early for efficiency if there is enough information. Specifically, some embodiments recognize that each successive partition will be the previous partition with one of the clusters split into two clusters. Some embodiments also recognize that clusters that do not meet a minimum size density constraint will never meet such a constraint in the future, so these clusters can be discarded. Once all clusters in a partition have fallen below the minimum size, then the loop is ended prematurely in some embodiments.","B. Efficient Data Structures for Cluster Analysis","Some embodiments perform efficient cluster analysis by using efficient data structures that allow for memory and processing savings. For instance, when sorting data (e.g., applying the operator S to input data), rather than generating a new array for the data, some embodiments define an array of indices into the array of unsorted data, with the indices sorted in order of the values they reference. This is referred to as an indirectly sorted array in some embodiments. One of ordinary skill will understand that while the examples use arrays, any other suitable data structure may be used as well.",{"@attributes":{"id":"p-0419","num":"0423"},"figref":["FIG. 69","FIG. 70","FIG. 70","FIG. 69","FIG. 70"],"b":["6900","6900","6900","6905","7010","0","8"]},"Next, process  next defines and stores (at ) an array D(A) of first-order differences of the array A by comparing pairs of subsequent values of array A. In some embodiments, the array D(A) is generated by use of the operator D that is described above in subsection A.  illustrates the array D  that stores the first-order differences between the data. For instance, the value in index D[] is the value in index A[] subtracted from the value in index A [] of array A .","Next, the process defines and stores (at ) an indirectly sorted array S(D(A)) of the indices of D(A) by applying a sort function to the array D(A). In some embodiments, the sort function is the operator S that is described above in subsection A.  illustrates the indirectly sorted array S(D)  that sorts the values of array D . The first value in the array  (\u201c3\u201d) references index  of array D , which is the smallest of the first-order differences (\u201c1.14\u201d). The second value in the array  references index  of array D , which is the second smallest first-order difference, and so on.","The process then determines (at ) the minimum size of the gaps between clusters to be used in partitioning the data. In some embodiments, this is the gap minimum g for use with the partitioning operator P described above in subsection A. The minimum gap size is specified by a user in some embodiments, or is a value inherent to the problem being solved in others. Some embodiments use multiple partitions (e.g., in the case of density clustering) such that different gap minimums based on the data are used.","Next, process  partitions (at ) the data into clusters using consecutive indices stored in the array S(D(A)). The process then stores (at ) the partition. The process then ends. Some embodiments use the indices stored in the indirectly sorted array to partition the data. In some embodiments, the index stored in S(D(A)) corresponding to the smallest first-order difference that is larger than the gap minimum (i.e., the effective gap minimum) will correspond to the index in the sorted array of data after which the data should be split. All indices stored in the array S(D(A)) after the effective gap minimum will also indicate where to split the sorted data, because they represent gaps larger than the gap minimum.",{"@attributes":{"id":"p-0424","num":"0428"},"figref":"FIG. 70","b":["7","7015","7025","7","2","1","7025","7030","5","7020","5","7020"]},"The above process  enables multiple processing and memory efficiencies for cluster analysis. First, storing the indices (which are integers) rather than the decimal values of the actual data in the sorted array of differences saves memory space. Second, instead of actually storing the partition as multiple separate arrays, it is stored as a single integer value referencing an index of the indirectly sorted array, which can bring about substantial memory savings when there are numerous partitions being evaluated for large arrays of data. Third, the indices at which to partition the data can be read off quickly from the indirectly sorted array, which substantially saves processing time.","These efficiencies can be leveraged in numerous ways to perform cluster analysis.  conceptually illustrates a process  of some embodiments for performing cluster analysis at multiple distance scales concurrently. In some embodiments, process  takes advantage of the efficiencies offered by process . As shown, process  defines (at ) an indirectly sorted array of differences of data values to be clustered. This is an array such as array  of , and is arrived at in some embodiments by sorting the input data values, taking the first-order differences, and then sorting those.","Process  then partitions (at ) the data values at several different distance scales concurrently. In some embodiments, this means that multiple partitions are generated for the data using different gap minimums. For instance, in the case of density clustering, each possible partition is generated in some embodiments. In some embodiments, because the first-order differences are sorted with an indirectly sorted array, the partitioning locations for the data can be quickly read off as the indices stored in the indirectly sorted array.","Next, the process stores (at ) each partition as an integer value referring to an index of the indirectly sorted array. Integer value  of  is an example of storing a partition as a single integer value. The process then determines (at ) the optimal distance scale (and thus the optimal partition). For example, some embodiments use an optimization measure such as is described for density clustering above in Section III. Furthermore, some embodiments eliminate some of the clusters in a partition by using constraints before testing the partition against the optimization measure.","Finally, once the optimal distance scale is determined, the process stores (at ) the partition of data derived from the optimal distance scale as the set of clusters for the problem being solved. The process then ends. In some embodiments, the set of clusters is stored as a new array once it is determined that it is the optimal set.","While the above descriptions indicate the efficiencies gained for repeated use of the partitioning operator, the memory and processing efficiencies from indirectly sorted arrays and storing a partition as a single value are applicable to other aspects of cluster analysis as well. For instance, the coalescing operator can take advantage of the same efficiencies in some embodiments.","As noted above, the coalescing operator C of some embodiments joins neighboring clusters in a partition, possibly repeatedly. The joining of neighboring clusters can be represented as removing a split in a partition. Because each of these splits corresponds to one of the consecutive indices in an indirectly sorted array, coalescing clusters can be defined as disqualifying particular indices from the sequence. As such, the results of applying the coalescing operator to a partition can be a sequence (e.g., an array) of qualifying indices (i.e., indices at which the new partition is split). Storing such a subsequence is much faster in some embodiments than directly moving around the data in the clusters being coalesced.","Furthermore, coalescing clusters of differences (which is effectively a combination of levels of differences) does not adversely affect the efficiency with which the data clusters (as opposed to the difference clusters) can be quickly read off for a particular chosen level. Even after coalescing the clusters of differences, the indices in the L-th indirectly sorted cluster of differences and above are the split points for the data clusters at level L. The change due to coalescing is that there will be fewer indirectly sorted second differences that determine where each indirectly sorted first difference cluster starts.","Because the filtering operator (which eliminates clusters of data based on constraints) is only applied to clusters of data (not to clusters of differences), the data clusters have already been determined when the filtering operator is applied, and thus it does not interfere with the efficiencies gained through the above implementations of the partitioning and coalescing operators.","Efficiencies can also be gained in the splitting of second differences into intra-level and inter-level second differences that is performed in difference clustering, as described above in Section IV. In some embodiments, the conditions used to determine a split point may depend on the clustering of first differences and the data that would result. Thus, the evaluation of these conditions benefits directly from the efficiencies in determining partitions of differences (and thus partitions of data).","For instance, in the case of difference clustering as applied to document reconstruction, the splitting of second differences is used to determine word breaks and segment breaks (e.g., column, tab, etc. gaps) on a text line, which correspond to first order differences and greater than first order differences respectively. In some embodiments, the goal is to split the second differences such that the minimum of the second cluster of first differences is not much smaller than the expected space character width for the applicable font. Furthermore, a secondary goal would be that the data clusters (each of which is a word) have an average size typical for words in the applicable language. Potential split points can be assessed comparatively lower depending on how far the resulting clusters of first differences and the clusters of data would differ from these expectations. Such assessments can be combined in some embodiments with other measures applied directly to the second differences (e.g., the relative size of the split, the percentile of the split position, and the percentage increase at the split) in a formula that determines the optimal split point. The repeated testing of different splits in the second differences can be made significantly more efficient by the processes described above.","One of ordinary skill in the art will recognize that while cluster analysis and the specific efficiency techniques described above have primarily been described with respect to its use in document reconstruction, they are applicable to any problem in which there is a set, a distance function on pairs of elements of the set, and a need to identify subsets of elements separated by distances that are small in terms relative to the set. For instance, cluster analysis can be applied to analyzing user interaction with an application, web page, or video, by clustering position data acquired by measuring eye movements, mouse movements, or touch screen interactions. As another example, a raster image (i.e., bitmap) can be compressed by reducing the number of colors used to encode it. Cluster analysis can be used on the original set of colors to select a reduced set of colors, such that each cluster of colors is replaced by a single color (often equal to an average of its members). Still another example is that some image recognition techniques (e.g., biometrics, optical character recognition, currency validation, etc.) and vectorization of raster images depend on clustering of pixels in a metric space defined by spatial and color coordinate axes. As a final example, patterns in experimental data (e.g., scientific or business data) are often found by plotting data points in a space the axes of which are the parameters of interest. Cluster analysis can be applied to this data, noting that all points in a given cluster have approximately the same values of all parameters of interest.","C. Software Architecture","In some embodiments, the cluster analysis described above is implemented as software running on a particular machine, such as a computer, a media player, a cell phone (e.g., and iPhone\u00ae), or other handheld or resource-limited devices (or stored in a computer readable medium).  conceptually illustrates the software architecture of a cluster analysis application  of some embodiments for performing cluster analysis. In some embodiments, the application is a stand-alone application or is integrated into another application (e.g., a document reconstruction application), while in other embodiments the application might be implemented within an operating system.","Cluster analysis application  includes density clustering module , difference clustering module , and bounds clustering module . The application also includes sorting module , differencing module , partitioning module , coalescing module , and filtering module , as well as cluster analysis storage .",{"@attributes":{"id":"p-0440","num":"0444"},"figref":"FIG. 72","b":["7250","7200","7205","7210","7215","7250","7205","7220","7240","7210","7220","7240","7215","7220","7240","7205","7215","7250"]},"In some embodiments, the five modules - perform operations associated with the five operators described above in subsection A. The sorting module  of some embodiments receives data from one of the modules - and orders the data (e.g., from lowest value to highest value). The differencing module  of some embodiments receives data from one of the modules - and determines the differences between adjacent pieces of data. The partitioning module  of some embodiments receives data from one of the modules - and partitions the data into multiple subsets. The coalescing module  of some embodiments receives data as multiple subsets from one of the modules - and joins adjacent subsets according to various conditions. The filtering module  of some embodiments receives a partitioned sequence of data in some embodiments and filters out partitions based on various constraints.","The modules - store data in cluster analysis storage , as well as pass the data back to the modules -. In some embodiments, the sorting module  stores its results in cluster analysis storage  as a sorted array of indices (i.e., an indirectly sorted array). The partitioning module, in some embodiments, stores partitions in the cluster analysis storage  as a single integer value referencing an index of an indirectly sorted array.","VIII. Efficient Data Structures for Parsing and Analyzing a Document","Some embodiments of the invention provide novel methods and data structures that enable more efficient parsing and analysis of a document. Some embodiments provide an application programming interface (API) that minimizes redundant copies of data as the data is manipulated. An API, in some embodiments, is a set of functions, procedures, methods, classes, or protocols that an operating system, library, service, or framework provides to support requests made by computer programs. In some embodiments, the API is statically linked, while in other embodiments an API is dynamically linked.","Typically, APIs return copies of internal data or give read-only access to internal data which must then be copied before being manipulated in any way. This creates many layers of redundant data, which slows processing and consumes excess memory. Some embodiments solve this problem by decoupling objects from their data so that object APIs can be made optimal for a programmer at the same time that the data structures are made optimal with respect to performance and memory consumption. Some embodiments use such an API for reconstructing a document as described above in Sections II-VII as well as in the concurrently filed U.S. patent application Ser. No. 12\/479,850, now published as US 2010\/0174980, entitled \u201cIdentification of Regions of a Document\u201d, which is incorporated herein by reference. However, one of ordinary skill in the art will recognize that such an API can be used for any sort of analysis of parsed input data.","Some embodiments provide an API that appears to a user (e.g., a programmer or a software application using the API) as if the user has their own independent, modifiable copy of the class members of the API with no explicit restrictions. In other words, it appears to the user as though any object returned through the API is completely modifiable by the user. However, in some embodiments, the objects will actually only copy themselves when absolutely necessary, and in most cases will manage memory in such a way as to minimize the amount of memory actually used. The memory management of some embodiments is done by using a sorted array of pointers that has a shared memory object which keeps track of the use of the pointers by other objects. In some embodiments, numerous objects can all reference the same pointer array through the shared memory object, enabling substantial memory savings as compared to making copies of the data at every stage of analysis. One of ordinary skill in the art will recognize that while pointers are used to describe certain features below, any sort of referential data structure could be used.","A. Document Reconstruction with Shared Pointers","Some embodiments use an API such as is described above to reconstruct a document.  conceptually illustrates a process  of some embodiments for reconstructing a document efficiently. Process  will be described in conjunction with .  illustrates a sequence by which a document  is parsed and analyzed according to process .","As shown in , process  receives (at ) a portion of a document. In some embodiments, the document portion is a page, and the process operates on a page-by-page basis. In other embodiments, the document portion is an entire document, a section of a document, or a zone on a page. The process then parses (at ) the document to determine the characters in the document portion, and stores (at ) an array of characters for the parsed data.",{"@attributes":{"id":"p-0449","num":"0453"},"figref":"FIG. 74","b":["7400","7405","7405"]},"Process  defines (at ) a sorted array of pointer that orders the characters for the document portion. In some embodiments, the characters for a page are sorted with a primary sort of top to bottom and a secondary sort of left to right. Some embodiments that store multiple pages in a character array sort by page first.  illustrates an array of pointers  that is defined for the sorted characters. The first pointer  points to the letter \u201cL\u201d in the array , the second pointer  to the letter \u201co\u201d, and so on. Defining an array of pointers to the initial character array rather than defining and storing a separate new array saves memory in some embodiments.","The process next receives (at ) instructions to manipulate string objects. Some embodiments define a string object as a pointer to a location in the sorted array of pointers and a count of how many characters are in the string. For instance, a string object for the entire page would point to the first pointer in the sorted pointer array (the top-leftmost character), and give a count of the number of characters on the page.","In some embodiments, the instructions include splitting strings, joining strings, adding characters, removing characters, and re-ordering characters. These operations, in some embodiments, are invoked as part of the process of reconstructing a document and using the reconstructed document as described above in Sections II-VII as well as in the concurrently filed U.S. patent application Ser. No. 12\/479,850, now published as US 2010\/0174980, entitled \u201cIdentification of Regions of a Document\u201d, which is incorporated herein by reference. For instance, in some cases when lines are merged, the order of characters must be modified. When zones are defined, some embodiments define strings for each zone, which in many cases involves splitting strings, joining strings, or both.","After receiving the instructions, the process determines (at ) whether the instructions can be performed using only pointers that are already allocated (e.g., the sorted pointer array defined at ). In some embodiments, splitting strings involves only the use of pointers that are already allocated. In the case of document reconstruction, some processes only involve the splitting of strings (e.g., line identification, line splitting, etc.). Furthermore, joining strings that are next to each other in the sorted array of pointers will involve only the use of already-allocated pointers in some embodiments.",{"@attributes":{"id":"p-0454","num":"0458"},"figref":"FIG. 74","b":["7400","7415","7420","7410","7415","7411","7420","7413"]},"The same pointers  can then be used when words are identified. For example, string objects  and  define two of the words in document . These words point to the same start pointers as string objects  and , but have different counts because the words are shorter than the lines. However, no new pointers need to be allocated to define these words, only new string objects. For a full document, hundreds or thousands of different string objects may all reference the same pointer array (such as pointers ), introducing large memory savings over repeatedly allocating memory for new pointer arrays.","When the received instructions can be performed using only pointers that are already allocated, process  performs (at ) the instructions using the shared pointers that are already allocated in memory. The process then proceeds to , which is described below. Otherwise, the process determines (at ) whether the instructions can be performed using a new collection of pointers.","Some embodiments allocate new pointers when instructions cannot be performed with only pointers that are already allocated, but the instructions do not require direct data manipulation of the character array. In some embodiments, joining strings that are not next to each other in a shared array of pointers requires a new allocation of pointers, because a string object for the joined strings cannot be represented by pointing to one pointer in the sorted array and moving forward in that array. For instance, referring to , if an operation called for appending the first line to the end of the second line, then string object for the appended lines could not point to array . Instead, a new array of pointers would have to be allocated in the required order.","When the received instructions can be performed using a new allocation of pointers, the process performs (at ) the instructions by using a new allocation of pointers to the character array. The process then and proceeds to , which is described below. Otherwise, the process performs (at ) the instructions by using a new copy of a portion or the entire character array. Directly editing the document data (i.e., a user adding a word to the document) is an example of instructions that could not be performed without manipulating the actual array of characters in some embodiments. However, a user adding a word to the document would not require a completely new copy, but instead could be handled by adding characters to the array and then defining a new array of pointers to the characters. Similarly, merging text lines often requires a new array of pointers, because a character from one text line may be inserted into the next text line, thereby altering the order of the characters relative to each other.","Next, the process determines (at ) whether more instructions to manipulate the string objects have been received. When more instructions have been received, the process proceeds to , which is described above, to determine the most efficient way of performing the instructions. Otherwise, the process ends. This process illustrates the hierarchy of memory and processing savings that are introduced by using the shared data. The original data is shared among various pointer arrays, and each pointer array is shared among many string objects. For each set of instructions received (e.g., each call into an API), the most efficient way of performing the instructions is used. Ideally, the instructions will not require the creation of any new pointers, and only new string objects need be created. If this is not possible, then memory savings may still be gained by creating new pointers that share the original data as opposed to creating a new character array.","Although process  has been described with reference to string objects and specifically string objects for document reconstruction, one of ordinary skill in the art will recognize that the efficiencies gained by exhibiting a preference for using already-allocated pointers and then for allocating new pointers as opposed to copying data, are applicable to a wide range of problems where memory and processing time are at a premium.","B. Shared Memory Objects","In some embodiments, each array of pointers has a shared memory object that manages the use of the pointers in the array. In some embodiments, the shared memory object for a particular pointer array keeps track of the data objects (e.g., string objects) that reference the particular array. In some embodiments, the shared memory object also keeps track of where in memory the pointer array starts as well.",{"@attributes":{"id":"p-0463","num":"0467"},"figref":["FIG. 75","FIG. 75"],"b":["7505","7510","7515","7520","7505"]},"The sorted array of pointers  is an array of pointers to the data array . Each pointer points to a data item in the array  in some embodiments. The pointers are arranged in an order based upon a sort of the data. For instance, in the case of a document, the pointers are arranged in the reading order of the characters to which they point in some embodiments.","Each of the data objects  includes a reference to a location in the pointer array  and a count. The location in the pointer array  for a particular data object is the pointer that points to the first piece of data that the data object references. For instance, when the data object is a string object for the word \u201cArray\u201d, the data object would specify the location in the pointer array where the pointer that points to the \u201cA\u201d is found. The data object would also include a count of 5.",{"@attributes":{"id":"p-0466","num":"0470"},"figref":"FIG. 75","b":["7515","7510","7520","7515","7520","7510"]},"Some embodiments do not define the shared memory object  when a first data object (that points to the start of the array and has a count of the entire array) is defined. However, once a second data object points to the array, the array is now shared, and the shared memory object  is defined to keep track of how many data objects share the array and where the start of the array is, as each individual object does not have this information. Accordingly, in some embodiments, the data objects  can call a function to instantiate a shared memory object for a pointer array if none exists when the data object is set to point to the pointer array. When the number of objects  drops to zero, the shared memory object  deallocates the pointers  and is then itself removed from memory.","In some embodiments, each individual data object  sharing the pointer array  does not have any knowledge that other objects  are also using the pointers in array . Furthermore, the objects  do not have any knowledge of the start or end of array , merely referencing some point in the array . However, the shared memory object  of some embodiments knows where the start of the array is in memory.","C. Software Architecture","In some embodiments, the API described above are implemented as software running on a particular machine, such as a computer, a media player, a cell phone (e.g., an iPhone\u00ae), or other handheld or resource-limited devices (or stored in a computer readable medium).  conceptually illustrates an API  that performs document reconstruction processes while using the efficiency techniques described above in subsections A and B.","API  includes geometric analysis modules , document reconstruction modules , and display and interaction modules . The API  is, in some embodiments, the set of functions, procedures, methods, classes, and\/or protocols that is provided for use by external applications .","The API  receives requests (e.g., function calls) to the public methods by external applications . In some embodiments, there are numerous external applications. For instance, in the case where an API is provided on a handheld device (e.g., an iPhone\u00ae), the external applications might be a PDF viewer (e.g., an e-book reader), a word processor (e.g., Microsoft Word, Apple Pages, etc.), a web browser (e.g., Microsoft Internet Explorer, Apple Safari, Mozilla Firefox, etc.), etc.","The various public methods provided by API  call various private methods that perform the geometric analysis and document reconstruction, access the document object model, etc. The data (e.g., the primitive elements that are initially identified by a parser) is stored in the document reconstruction data . Although it may appear to the external applications that they can access the data (e.g., while manipulating characters to identify words, text lines, etc.), in fact the class members that are manipulated by the external applications through the API are divorced from the actual data by defining the class members to only store references to the data, as described above in subsections A and B.","VIII. Overall Software Architecture","In some embodiments, the processes described above are implemented as software running on a particular machine, such as a computer, a media player, a cell phone (e.g., an iPhone\u00ae), or other handheld or resource-limited devices (or stored in a computer readable medium).  conceptually illustrates the software architecture of an application  of some embodiments for reconstructing, displaying, and interacting with a document. In some embodiments, the application is a stand-alone application or is integrated into another application, while in other embodiments the application might be implemented within an operating system. In still other embodiments the modules illustrated in  are split among multiple applications. For instance, in some embodiments, one application generates the document object model, while another application displays the document and interacts with the document object model (see full description below).","Application  includes a parser , profiling modules , semantic reconstruction modules , cluster analysis modules , user interaction modules , and display adaptation modules . The application  also includes document data storage , profile storage , cluster analysis storage , and document object module storage .  also illustrates an operating system  that includes cursor controller driver , keyboard drive , and display module . In some embodiments, as illustrated, the cursor controller driver , keyboard driver , and\/or display module  are part of operating system  even when the compositing application is a stand-alone application separate from the operating system.","As shown, the parser  receives a document . In some embodiments, the document is an unformatted document that includes vector graphics (e.g., a PDF). The parser  parses the document information and stores the parsed data in the document data storage . In some embodiments, the parsed text data is stored as an array of characters as described in Section XI of the concurrently filed U.S. patent application Ser. No. 12\/479,842, now published as US 2010\/0174976, entitled \u201cEfficient Data Structures for Parsing and Analyzing a Document\u201d, which is incorporated herein by reference.","The semantic reconstruction modules  reconstruct the document to generate the document object model  from the document data . Semantic reconstruction modules  perform such processes as zone analysis, guide and gutter identification, layout and flow identification, table identification, and joined graph identification.","The output of the semantic reconstruction modules also is sent to the profiling modules . Profiling modules  include a profile matching engine that matches hierarchical profiles and inform the semantic reconstruction modules how to go about performing reconstruction, as described in Section VII of the concurrently filed U.S. patent application Ser. No. 12\/479,852, now published as US 2010\/0174732, entitled \u201cContent Profiling to Dynamically Configure Content Processing\u201d, which is incorporated herein by reference.","The semantic reconstruction modules  also pass information to the cluster analysis modules . Cluster analysis modules  perform density clustering for guide identification, difference clustering for word and segment gap information, and bounds clustering for identifying graphs that should be joined, in some embodiments. The cluster analysis modules use the cluster analysis storage  to store arrays and indices as described in Section VII. The results of the cluster analysis are then passed back to the semantic reconstruction modules .","Once the semantic reconstruction modules  have reconstructed the document, they store the document object model . Document object model  stores all information about the semantically reconstructed document, such as the zone graph populated with content that is described above in Section II.","Display adaptation modules  use the document object model  to determine how to display the document. For instance, display adaptation modules of some embodiments perform the processes described above in Section V for displaying the document on a small-screen device. Display adaptation modules  pass the display information to the display module , which governs the actual display on the screen.","User interaction modules  receive input information from the cursor controller driver  and keyboard driver . The input information directs the user interaction modules  to perform operations on the document, such as selections as described above in Section VI, as well as editing of the document. If the document is edited, then the document object model  must be modified to reflect the edits.","In some embodiments, the results of the processes performed by some of the above-described modules or other modules are stored in an electronic storage (e.g., as part of a document object model). The document object model can then be used for displaying the document on an electronic display device (e.g., a handheld device, computer screen, etc.) such that a user can review and\/or interact with the document (e.g., via touchscreen, cursor control device, etc.).",{"@attributes":{"id":"p-0484","num":"0488"},"figref":"FIG. 78","b":["7800","7700"]},"As shown, process  begins by defining (at ) geometric analysis modules, such as modules  of . The process then defines (at ) document reconstruction modules such as modules  of . In some embodiments, semantic reconstruction modules  of  include both geometric analysis modules and document reconstruction modules, though other embodiments only include one or the other.","Process  then defines (at ) a set of hierarchical profiles, such as profiles . Next, the process defines (at ) a set of modules for performing cluster analysis. The cluster analysis modules  are an example of such modules. The process then defines (at ) modules for adaptively displaying a document, such as display adaptation modules .","Next, process  defines (at ) modules for receiving user interactions with a document, such as modules . These modules, in some embodiments, include modules for interpreting text selections in a document that has associated sets of glyphs and a reading order that specifies a flow of reading through the glyphs. In some embodiments, the modules receive a start and end point for a selection of text within the displayed document and define a selection of text from the start point to the end point by using the identified sets of glyphs and intended flow of reading.","The process also defines (at ) other modules. For instance, some embodiments include modules for parsing an incoming document (e.g., a document received by the application) or for efficiently using memory and processing time when performing various document reconstruction operations.","Process  then stores (at ) the application on a computer readable storage medium. As mentioned above, in some embodiments the computer readable storage medium is a distributable CD-ROM. In some embodiments, the medium is one or more of a solid-state device, a hard disk, a CD-ROM, or other non-volatile computer readable storage medium. The medium may be firmware of a handheld device (e.g., an iPhone) in some embodiments.","One of ordinary skill in the art will recognize that the various elements defined by process  are not exhaustive of the modules, rules, and processes that could be defined and stored on a computer readable storage medium for an application incorporating some embodiments of the invention. Furthermore, it is equally possible that some embodiments will include only a subset of the elements defined by process  rather than all of them.","In addition, the process  is a conceptual process, and the actual implementations may vary. For example, different embodiments may define the various elements in a different order, may define several elements in one operation, may decompose the definition of a single element into multiple operations, etc. Furthermore, the process  may be implemented as several sub-processes or combined with other operations in a macro-process.","IX. Computer System","Many of the above-described features and applications are implemented as software processes that are specified as a set of instructions recorded on a computer readable storage medium (also referred to as computer readable medium). When these instructions are executed by one or more computational element(s) (such as processors or other computational elements like ASICs and FPGAs), they cause the computational element(s) to perform the actions indicated in the instructions. Computer is meant in its broadest sense, and can include any electronic device with a processor. Examples of computer readable media include, but are not limited to, CD-ROMs, flash drives, RAM chips, hard drives, EPROMs, etc. The computer readable media does not include carrier waves and electronic signals passing wirelessly or over wired connections.","In this specification, the term \u201csoftware\u201d is meant to include firmware residing in read-only memory or applications stored in magnetic storage which can be read into memory for processing by a processor. Also, in some embodiments, multiple software inventions can be implemented as sub-parts of a larger program while remaining distinct software inventions. In some embodiments, multiple software inventions can also be implemented as separate programs. Finally, any combination of separate programs that together implement a software invention described here is within the scope of the invention. In some embodiments, the software programs when installed to operate on one or more computer systems define one or more specific machine implementations that execute and perform the operations of the software programs.",{"@attributes":{"id":"p-0494","num":"0498"},"figref":"FIG. 79","b":["7900","7905","7910","7920","7925","7930","7935","7940","7945"]},"The bus  collectively represents all system, peripheral, and chipset buses that communicatively connect the numerous internal devices of the computer system . For instance, the bus  communicatively connects the processor  with the read-only memory , the GPU , the system memory , and the permanent storage device .","From these various memory units, the processor  retrieves instructions to execute and data to process in order to execute the processes of the invention. In some embodiments, the processor comprises a Field Programmable Gate Array (FPGA), an ASIC, or various other electronic components for executing instructions. Some instructions are passed to and executed by the GPU . The GPU  can offload various computations or complement the image processing provided by the processor . In some embodiments, such functionality can be provided using Corelmage's kernel shading language.","The read-only-memory (ROM)  stores static data and instructions that are needed by the processor  and other modules of the computer system. The permanent storage device , on the other hand, is a read-and-write memory device. This device is a non-volatile memory unit that stores instructions and data even when the computer system  is off. Some embodiments of the invention use a mass-storage device (such as a magnetic or optical disk and its corresponding disk drive) as the permanent storage device .","Other embodiments use a removable storage device (such as a floppy disk, flash drive, or ZIP\u00ae disk, and its corresponding disk drive) as the permanent storage device. Like the permanent storage device , the system memory  is a read-and-write memory device. However, unlike storage device , the system memory is a volatile read-and-write memory, such a random access memory. The system memory stores some of the instructions and data that the processor needs at runtime. In some embodiments, the invention's processes are stored in the system memory , the permanent storage device , and\/or the read-only memory . For example, the various memory units include instructions for processing multimedia items in accordance with some embodiments. From these various memory units, the processor  retrieves instructions to execute and data to process in order to execute the processes of some embodiments.","The bus  also connects to the input and output devices  and . The input devices enable the user to communicate information and select commands to the computer system. The input devices  include alphanumeric keyboards and pointing devices (also called \u201ccursor control devices\u201d). The output devices  display images generated by the computer system. The output devices include printers and display devices, such as cathode ray tubes (CRT) or liquid crystal displays (LCD).","Finally, as shown in , bus  also couples computer  to a network  through a network adapter (not shown). In this manner, the computer can be a part of a network of computers (such as a local area network (\u201cLAN\u201d), a wide area network (\u201cWAN\u201d), or an Intranet, or a network of networks, such as the internet. Any or all components of computer system  may be used in conjunction with the invention.","Some embodiments include electronic components, such as microprocessors, storage and memory that store computer program instructions in a machine-readable or computer-readable medium (alternatively referred to as computer-readable storage media, machine-readable media, or machine-readable storage media). Some examples of such computer-readable media include RAM, ROM, read-only compact discs (CD-ROM), recordable compact discs (CD-R), rewritable compact discs (CD-RW), read-only digital versatile discs (e.g., DVD-ROM, dual-layer DVD-ROM), a variety of recordable\/rewritable DVDs (e.g., DVD-RAM, DVD-RW, DVD+RW, etc.), flash memory (e.g., SD cards, mini-SD cards, micro-SD cards, etc.), magnetic and\/or solid state hard drives, read-only and recordable blu-ray discs, ultra density optical discs, any other optical or magnetic media, and floppy disks. The computer-readable media may store a computer program that is executable by at least one processor and includes sets of instructions for performing various operations. Examples of hardware devices configured to store and execute sets of instructions include, but are not limited to application specific integrated circuits (ASICs), field programmable gate arrays (FPGA), programmable logic devices (PLDs), ROM, and RAM devices. Examples of computer programs or computer code include machine code, such as is produced by a compiler, and files including higher-level code that are executed by a computer, an electronic component, or a microprocessor using an interpreter.","As used in this specification and any claims of this application, the terms \u201ccomputer\u201d, \u201cserver\u201d, \u201cprocessor\u201d, and \u201cmemory\u201d all refer to electronic or other technological devices. These terms exclude people or groups of people. For the purposes of the specification, the terms display or displaying means displaying on an electronic device. As used in this specification and any claims of this application, the terms \u201ccomputer readable medium\u201d and \u201ccomputer readable media\u201d are entirely restricted to tangible, physical objects that store information in a form that is readable by a computer. These terms exclude any wireless signals, wired download signals, and any other ephemeral signals.","While the invention has been described with reference to numerous specific details, one of ordinary skill in the art will recognize that the invention can be embodied in other specific forms without departing from the spirit of the invention. For example, some embodiments receive a document in which each page is defined as a single image. However, some embodiments can perform optical character recognition on the document to recognize glyphs, and in some cases shapes (e.g., lines, rectangles, etc.), after which point the document can be reconstructed. Also, some embodiments have been described above as performing particular geometric analysis and document reconstruction operations on particular primitive elements. However, one of ordinary skill would recognize that the operations could be applied to other sorts of primitive elements. For instance, guide identification is described as involving the use of density clustering to identify associations of (i.e., to associate, or to define associations of) glyphs forming a vertical boundary. However, similar operations could be applied to look for clusters of primitive shapes that form boundaries (e.g., dashed lines).","Furthermore, a number of the figures (including , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ) conceptually illustrate processes. The specific operations of these processes may not be performed in the exact order shown and described the specific operations may not be performed in one continuous series of operations, and different specific operations may be performed in different embodiments. Furthermore, the process could be implemented using several sub-processes, or as part of a larger macro process. Thus, one of ordinary skill in the art would understand that the invention is not to be limited by the foregoing illustrative details, but rather is to be defined by the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The novel features of the invention are set forth in the appended claims. However, for purpose of explanation, several embodiments of the invention are set forth in the following figures.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 7","FIG. 5"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 11","FIG. 10"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIGS. 13 and 14","FIG. 12","FIG. 10"]},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 16","FIG. 10"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIGS. 22-24"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIGS. 27-29"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 31"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 35","FIG. 34"]},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 37"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 38"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 39"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 40"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 41"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 42"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIGS. 43 and 44"},{"@attributes":{"id":"p-0059","num":"0058"},"figref":["FIGS. 45 and 46","FIGS. 43 and 44"]},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 47"},{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 48"},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 49"},{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 50"},{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 51"},{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 52"},{"@attributes":{"id":"p-0066","num":"0065"},"figref":["FIG. 53","FIG. 52"]},{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 54"},{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 55"},{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 56"},{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 57"},{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 58"},{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 59"},{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 60"},{"@attributes":{"id":"p-0074","num":"0073"},"figref":["FIG. 61","FIG. 60","FIG. 59"]},{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 62"},{"@attributes":{"id":"p-0076","num":"0075"},"figref":["FIG. 63","FIG. 62","FIG. 59"]},{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 64"},{"@attributes":{"id":"p-0078","num":"0077"},"figref":["FIG. 65","FIG. 60","FIG. 64"]},{"@attributes":{"id":"p-0079","num":"0078"},"figref":["FIG. 66","FIG. 62","FIG. 64"]},{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 67"},{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 68"},{"@attributes":{"id":"p-0082","num":"0081"},"figref":"FIG. 69"},{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 70"},{"@attributes":{"id":"p-0084","num":"0083"},"figref":"FIG. 71"},{"@attributes":{"id":"p-0085","num":"0084"},"figref":"FIG. 72"},{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 73"},{"@attributes":{"id":"p-0087","num":"0086"},"figref":["FIG. 74","FIG. 73"]},{"@attributes":{"id":"p-0088","num":"0087"},"figref":"FIG. 75"},{"@attributes":{"id":"p-0089","num":"0088"},"figref":"FIG. 76"},{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 77"},{"@attributes":{"id":"p-0091","num":"0090"},"figref":["FIG. 78","FIG. 77"]},{"@attributes":{"id":"p-0092","num":"0091"},"figref":"FIG. 79"}]},"DETDESC":[{},{}]}
