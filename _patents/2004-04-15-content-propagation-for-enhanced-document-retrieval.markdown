---
title: Content propagation for enhanced document retrieval
abstract: Systems and methods providing computer-implemented content propagation for enhanced document retrieval are described. In one aspect, reference information directed to one or more documents is identified. The reference information is identified from one or more sources of data that are independent of a data source that includes the one or more documents. Metadata that is proximally located to the reference information is extracted from the one or more sources of data. Relevance between respective features of the metadata to content of associated ones of the one or more documents is calculated. For each document of the one or more documents, associated portions of the metadata is indexed with the relevance of features from the respective portions into original content of the document. The indexing generates one or more enhanced documents.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07305389&OS=07305389&RS=07305389
owner: Microsoft Corporation
number: 07305389
owner_city: Redmond
owner_country: US
publication_date: 20040415
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Mining PS Document Links, IDs, Etc., from Multiple Data Sources","Feature Extraction and Importance Weighting","Enhanced KB Article Retrieval","Retrieved Document Relevance and Ranking Operations","Search Result Snippet Generation\/Highlighting","Appendix A","Clustering of Heterogeneous Objects"],"p":["This patent application is related to the following patent applications, each of which are commonly assigned to assignee of this application, and hereby incorporated by reference:","pending U.S. patent application Ser. No. 10\/826,159, titled \u201cReinforced Clustering of Multi-Type Data Objects for Search Term Suggestion\u201d, filed on Apr. 15, 2004; and","pending U.S. patent application Ser. No. 10\/427,548, titled \u201cObject Clustering Using Inter-Layer Links\u201d, filed on May 1, 2003.","Implementations of the invention pertain to data mining.","Today's high technology corporations typically provide some aspect of product support to ensure that consumers and partners receive the maximum value for their technology investments. For instance, a variety of consumer and business support offerings, and strategic IT consulting services may be provided to help meet the requirements of customers and partners. Support offerings may include phone, on-site, Web-based support, and so on. Unfortunately, product support services can become prohibitively expensive, not only in terms of financial costs, but also the amount of time that is required to find a solution. For instance, on-site consulting services are typically expensive, so expensive that most non-corporate consumers cannot afford to hire an individual product consultant or troubleshooter.","Additionally, when services are automated, for instance via online searches of a knowledge base comprising product \u201chow-to\u201d (help) and troubleshooting articles, the amount of time that it may take the consumer to identify an on-point set of articles may become prohibitive. One reason for this is because knowledge base product troubleshooting articles are typically generated by professional writers, vendors, and the like, not the everyday users of the products for which support is sought. In such a scenario, if the user does not form a search query using the terms adopted by knowledge base (KB) content producer(s), the user may find it very difficult and time consuming to locate any on-point knowledge base troubleshooting information.","Systems and methods providing computer-implemented content propagation for enhanced document retrieval are described. In one aspect, reference information directed to one or more documents is identified. The reference information is identified from one or more sources of data that are independent of a data source that includes the one or more documents. Metadata that is proximally located to the reference information is extracted from the one or more sources of data. Relevance between respective features of the metadata to content of associated ones of the one or more documents is calculated. For each document of the one or more documents, associated portions of the metadata is indexed with the relevance of features from the respective portions into original content of the document. The indexing generates one or more enhanced documents.","Overview","KB articles are created to assist customers in locating \u201chow-to\u201d (help) articles, to solve product problems (troubleshoot), and\/or otherwise research a product. Studies have shown that the easier it is for an end-user to search for and obtain an on-point KB article that directly addresses the customer's inquiry, the greater is the customer's satisfaction with the product and its related support infrastructure. In view of this, the following described systems and methods provide content propagation and enhanced document retrieval by analyzing information stored across a variety of data sources to locate KB article related information (KBARI). Such data sources include, for example, service request storage repositories, online product and developer support group newsgroup postings, search query click-thru logs, and\/or the like.","KBARI includes, for example, substantially unique PS document (e.g., KB article) IDs, hypertext links to specific PS article(s), Universal Resource Identifier(s) (URI(s)) to specific PS article(s), document titles, etc. When KBARI is found among product service request(s) and\/or postings from a product developer support newsgroup, it is probable that text in proximity to the KBARI includes information that is semantically and\/or contextually valuable to the PS\/troubleshooting article(s) referenced by the KBARI. Moreover, such text was likely generated by an end-user and\/or product support service (PSS) engineer(s) during real problem resolution scenarios\u2014not solely by a professional writer or vendor tasked with documenting a product.","For example, a service request (SR) in a PSS log of service request(s) is an archived document (e.g., one or more associated e-mails) that includes information initially submitted by an end-user to a PSS engineer. That is, the SR directs a product related question such as a troubleshooting scenario to the PSS engineer. The PSS engineer generally responds to the SR. Before the SR is closed, the PSS engineer generates a SR summary to clearly identify some combination of the following information: the product, the problem addressed, the problem's symptoms (e.g., action and result), causes, and\/or resolution. As a result, an SR includes data that is likely to contain substantially valuable references to KB articles  and\/or product related information generated by end-user(s) and PSS engineer(s) in real problem resolution scenarios.","With respect to newsgroup postings, entities and corporations commonly host product and\/or developer related newsgroups to provide end-users with opportunities to discuss product development and troubleshooting issues online. For instance, if an end-user encounters a problem with a particular product, the user may post a corresponding article to the server that identifies the problem and requests assistance. In such a scenario, newsgroup readers, which may include votaries and\/or service professionals associated with the product, may post an answer to the request. As with a service request, a newsgroup posting may include content (e.g., a link, reference, etc.) that is directly or contextually related to one or more KB articles. When a posting references a KB article, the posting provides potentially useful metadata for the KB article.","With respect to query log(s), end-users often submit search queries to search engine(s), e.g., via a Web site, seeking KB article(s) relevant to particular product(s), troubleshooting product behavior, and so on. A server, such as the one hosting the search engine and\/or the KB database, records the end-user queries as well as any subsequent end-user click-thru action(s). If a query is highly-frequently associated to a KB article, then this query is most likely to be good meta-data for the KB article.","To leverage such semantically and\/or contextually related information from multiple data sources, the systems and methods extract text in proximity to (e.g., surrounding) the located KBARI. The extracted text is analyzed to generate feature (keyword) importance weighting value(s) with respect to associated PS article(s). (Extracted text is associated with PS article(s) as indicated by KBARI to which the text is in proximity). The extracted text (hereinafter often referred to as \u201cmetadata\u201d) and corresponding feature importance weighting value(s) are indexed with original content of the associated PS article(s) to generate new or enhanced PS article(s). In this implementation, there is a one-to-one correspondence between original and enhanced PS articles. For instance, for each enhanced PS article there is a corresponding non-enhanced or original PS article. In another implementation, there is not such a one-to-one correspondence, and an original PS article may be replaced with an enhanced PS article.","Responsive to receiving a search query from an end-user, the systems and methods providing content propagation for enhanced document retrieval retrieve any PS article(s) (original and\/or enhanced) that include term(s) of the search query. Relevance of the retrieved original and\/or enhanced PS articles are then determined in view of query term proximity and popularity criteria. The search results are then ranked in view of these relevance scores. Snippet descriptions are generated from the search results to clearly indicate to the end-user the relevance of a returned document. The ranked results, along with the snippet descriptions, are communicated to the end-user.","In one implementation, the systems and methods providing content propagation for enhanced document retrieval also facilitate identification of new PS content for automatic PS article generation. These and other aspects of the systems and methods providing content propagation for enhanced document retrieval are now described in greater detail.","An Exemplary System","Turning to the drawings, wherein like reference numerals refer to like elements, the systems and methods are described and shown as being implemented in a suitable computing environment. Although not required, the systems and methods are described in the general context of computer-executable instructions, such as program modules, being executed by a personal computer. Program modules generally include routines, programs, objects, components, data structures, etc., that perform particular tasks or implement particular abstract data types. While the systems and methods are described in the foregoing context, acts and operations described hereinafter may also be implemented in hardware.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 1","b":["100","100","102","104","106","108","114","116","104","102","108","114","118","120","108","114","108","110","112","114","102","122","116","118","120","122","116"]},"More particularly, metadata extraction  of KB hosting server(s)  mine information stored across data sources - to identify information related to respective ones of KB articles . For purposes of discussion and illustration, this identified information is referred to as KB article related information (KBARI) . KBARI  includes, for example, substantially unique KB article IDs (e.g., a GUID), hypertext links to specific KB article(s), Universal Resource Identifier(s) (URI(s)) to specific KB article(s), and\/or the like. When metadata extraction  locates KBARI  in service request(s)  from a PSS and\/or newsgroup postings  from a product developer support newsgroup, it is very probable that text in proximity to the KBARI  includes information that is semantically and\/or contextually valuable to the original KB article(s)  referenced by the KBARI . For instance such text may include article titles, article keywords, product problem description and resolution data, etc. Moreover, such text was likely generated by an end-user and\/or PSS engineer(s) during real problem resolution scenarios\u2014not solely by a professional writer or vendor tasked with documenting a product.","To leverage semantically and\/or contextually related KB article information from data source(s) -, metadata extraction  extracts text in proximity (e.g., surrounding) to located KBARI . For purposes of discussion, such extracted text is shown as metadata . To provide an end-user with KB article(s)  that are substantially most pertinent to terms of search query , metadata extraction  analyzes metadata  to generate feature importance (relevance) weighting value(s) with respect to associated ones of KB article(s) . (Extracted metadata  is associated with KB article(s)  as indicated by corresponding KBARI ).","More particularly, metadata extraction  utilizes full text searching techniques to assign different relevance weights to features of metadata . In this implementation and with respect to service requests , greater weight is assigned to titles and symptoms as compared to weights assigned to other service request information, for example, a problem resolution. This is because a user will more likely formulate a search query with problem symptom(s), rather than with problem resolution information. Feature weighting may also reflect the number of times that a particular KB article reference (i.e., a respective piece of KBARI ) is identified within its context, be a function of reference ages, etc. Such feature weighting is also applied to newsgroup posting(s) .","With respect to metadata  extracted from query log(s) , metadata extraction  performs feature analysis and weighting first by identifying some combination of the following information: (a) search queries frequently generated by end-users to search KB articles , (b) subsequently selected KB articles , and\/or (c) any other KB articles  related to the selected articles. Metadata extraction  then addresses sparse click-thru data associated with (a), (b), and\/or (c) by generating clusters of similar queries (query clusters) and clusters of related KB articles  (i.e., article clusters). Sparse click-thru data typically results if a user selects (i.e., clicks-thru) a small number (e.g., one or more) of documents returned from a search engine. For purposes of illustration, query cluster(s) and article cluster(s) are also represented as respective portion(s) of \u201cother data\u201d . An exemplary clustering technique for formulating clusters for similar queries and related KB articles is described in greater detail below in Appendix A, which is titled \u201cExemplary Clustering of Heterogeneous Objects.\u201d","To persist and manage the weighted features of metadata , metadata extraction and analysis module  indexes metadata  and corresponding feature importance weighting value(s) with original content of the associated original KB article(s)  to generate new or enhanced KB article(s) . (Recall that metadata  includes data mined from one or more data sources - that has been determined to be complementary to one or more respective KB article(s) ). In this implementation, the weighted features of metadata  are tagged so that markup languages such as XML may be utilized to reference and retrieve content of the index. In one implementation, metadata  is indexed in an enhanced KB article  as an inverted index. In this implementation, there is a one-to-one correspondence between enhanced KB articles  and original KB articles . For instance, for each enhanced KB article  there is a corresponding non-enhanced or original KB article . This one-to-one correspondence means that at least a subset of the original KB articles  will have a corresponding enhanced KB article . In another implementation, there is not such a one-to-one correspondence. For example, an original KB article  may be replaced with an enhanced KB article .","Search provider  receives a KB related search query  from an end-user of client computing device . Term(s) of search query  are pertinent to a product research or troubleshooting inquiry. In one implementation, search query  includes information specified in Extended Markup Language (XML). The end-user uses any of a number of different possible application(s)  to send search query  over network  to KB hosting server(s) . Application(s)  include, for example, a Web browser, word processor, e-mail, and\/or other types of computer-program application(s).","In this implementation, search provider  provides a remote application entry point to KB hosting server  and search engine functionalities. The entry point allows communications between KB server  and any of the various possible architectural implementations of application(s) . For example, in one implementation, the entry point supports Hypertext Transfer Protocol (HTTP) commands communicated from an application  implemented as a Web browser. In another implementation, the entry point supports XML-based messaging protocols such as Simple Object Access Protocol (SOAP). Other entry point implementations are also possible as a function of the particular type of communication support desired between application(s)  and search provider .","Responsive to receiving search query , search provider  parses and enforces the data format of search query  in view of a schema, which is shown as a respective portion of \u201cother data\u201d . In one implementation, the schema is uploaded to KB hosting server , for instance, by client computing device . Next, search provider  performs a full-text search on KB articles  to identify and retrieve related\/pertinent original KB article(s)  and\/or enhanced KB article(s) . For purposes of illustration and discussion, such retrieved documents are shown as a respective portion of \u201cother data\u201d .","Relevance of the retrieved documents are then determined in view of query term proximity and popularity criteria. With respect to term proximity, the length of search query  to search for a KB article  may be longer than other types of queries (e.g., a query modeled for a general Web search). This is because more words\/terms are generally used to describe product troubleshooting and\/or research questions. In light of this, and to locate a KB article  that covers as many query term fragments as possible in queries that may include more terms, search provider  uses term proximity to weight the terms in search query . A proximity value is transformed by a curve into a weighting factor for similarity values output by full-text retrieval module as follows:",{"@attributes":{"id":"p-0040","num":"0039"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"Sim","mo":"=","mrow":{"msub":{"mi":["Sim","orig"]},"mo":"*","mi":"proximity"}},{"mi":"proximity","mo":"=","mfrac":{"mrow":[{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"+","mrow":{"mi":"\u03b1","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":["\u03b2","Hit"],"mo":"*"},{"mrow":[{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"\u03b2"}},{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"EditDistance"}}],"mo":"*"}],"mo":"+"}}}}}},{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"+","mi":"\u03b1"}}}]}}],"mo":[",","\u2062",","],"mstyle":{"mtext":{}}}}},"br":{},"b":["122","122","122","130"]},"Search provider  ranks the retrieved documents in view of the query term proximity based relevance scores, and also in view of popularity of the identified document(s). In one implementation, this is accomplished by determining the age of the identified KB articles , and assigning greater weight to a more recent article  as being \u201cmore popular\u201d than an older KB article. . In another implementation, wherein the popularity of a KB article  is substantially difficult to determine popularity of the identified KB article(s)  is determined as a function of the number of times the article(s) is\/are referenced across service request(s)  and\/or newsgroup posting(s) . The greater the number of times that an article is referenced, the greater the articles popularity and the higher it is ranked compared to an article that has not been referenced as many times. With respect to newsgroup posting(s) , KB article  popularity is a function of frequency of article reference and\/or some determination of newsgroup poster prevalence in the newsgroup-the more articles posted by a particular user, the greater the user's prevalence.","A relatively new KB article  in view of a small frequency of reference would indicate a small relative popularity. Yet, the new article may be of significant value to the end-user. Accordingly, in one implementation, search provider  combines the factors of frequency of reference and age, and normalizes the popularity for KB articles with different age as follows:",{"@attributes":{"id":"p-0043","num":"0042"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"popularity","mo":"=","mrow":{"mfrac":{"mrow":[{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"+","mrow":{"mi":"\u03b1","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"\u03b2","mo":"*","msub":{"mi":["I","ref"]}},{"mrow":[{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"\u03b2"}},{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msub":{"mi":["I","age"]}}}],"mo":"*"}],"mo":"+"}}}}}},{"mi":"log","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"+","mi":"\u03b1"}}}]},"mo":"."}}}},"br":{},"sub":["ref ","age "],"b":"106"},{"@attributes":{"id":"p-0044","num":"0043"},"maths":[{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["I","ref"]},"mo":"=","mrow":{"mn":"0.5","mo":"+","mrow":{"mn":"0.5","mo":["\u2062","\u2062","\u2062"],"mrow":[{"mrow":{"mi":"freq","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"ref"}},"mo":"\/","mi":"max"},{"mi":"freq","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"ref"}}],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}}}}},{"@attributes":{"id":"MATH-US-00003-2","num":"00003.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["I","age"]},"mo":"=","mrow":{"mfrac":{"mn":"1","mrow":{"mn":"1","mo":"+","msup":{"mi":["\u2147","age"]}}},"mo":"."}}}}],"br":{},"b":["106","122","130"]},"In one implementation, and to substantially maximize query-related information presented to end-users, search provider  generates snippet descriptions for one or more of the top ranked retrieved documents to clearly indicate to the end-user the relevance of a retrieved document (i.e., a clear indication to the end-user of how the identified material (article(s)) is related to term(s) of search query . For purposes of illustration, snippet description(s) is\/are represented with respective portion(s) of \u201cother data\u201d . To generate a snippet description, search provider  locates one or more blocks from a retrieved KB article  determined to be relevant to search query  for the snippet description, and then highlights any terms of the search query  in the one or more blocks. Search provider  identifies the one or more blocks with a sliding window of configurable size that is applied to portions of the retrieved document. In one implementation, the size of the sliding window is a function of UI space available for snippet description display on client computing device .","For each application of the sliding window to a portion of a retrieved KB article , search provider  measures the amount of query-related information carried by text delineated by the sliding window. This measure is represented with a respective portion of \u201cother data\u201d . The measure includes values based on quantitative criteria such as word frequency, word proximity to an enhanced query term, word position, etc. Search provider  utilizes a trained classifier model (see, \u201cother data\u201d ) to combine these different criteria to get the most informative block for the snippet description. In this manner, a snippet description clearly illustrates to the end-user a relevance of the identified KB article .","The trained classifier model is trained by linear regression, which is a classic learning method in statistics. Linear regression attempts to explain the relationship of a vector x and a value y with a straight line fit to the data. The linear regression model postulates that:",{"@attributes":{"id":"p-0048","num":"0047"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"y","mo":"=","mrow":{"msub":{"mi":"b","mn":"0"},"mo":["+","+"],"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"p"},"mo":"\u2062","mrow":{"msub":[{"mi":["b","j"]},{"mi":["x","j"]}],"mo":"\u2062"}},"mi":"e"}}}},"br":{},"sub":["j ","j "]},"Search provider  encapsulates at least a subset of the top-ranked retrieved document(s) along with corresponding snippet descriptions into query response . Search provider  communicates query response  to client computing device  for presentation and use by the end-user to solve product research and\/or troubleshooting inquiries.","An Exemplary Procedure",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 2","FIG. 1","FIG. 1"],"b":["200","202","124","126","106","108","114","204","124","202","206","124","128","106","208","124","106","120"]},"At block , search provider , responsive to receiving search query , retrieves original KB articles  and\/or enhanced KB articles  that include term(s) of search query . At block , search provider  ranks the retrieved documents\/articles based on relevance scores of search query  term(s) to respective ones of the documents\/articles. At block , search provider  generates snippet descriptions for the retrieved knowledge base articles . At block , search provider  communicates the ranked results and snippet descriptions to the end-user.","An Exemplary Operating Environment",{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIG. 3","FIG. 1","FIG. 2","FIG. 3"],"b":["300","100","300","300","300","300"]},"The methods and systems described herein are operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use include, but are not limited to, personal computers, server computers, multiprocessor systems, microprocessor-based systems, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and so on. Compact or subset versions of the framework may also be implemented in clients of limited resources, such as handheld computers, or other computing devices. The invention is practiced in a distributed computing environment where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote memory storage devices.","With reference to , an exemplary system providing content propagation for enhanced document retrieval includes a general purpose computing device in the form of a computer . The following described aspects of computer  are exemplary implementations of client computing device  () and\/or KB hosting server  (). Components of computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","A computer  typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer .","Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.","System memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules , and program data . In one implementation, referring in combination to , computer  is a KB hosting server . In this scenario, application programs  comprise program modules  of , and program data  comprises KB article related information (KBARI) , metadata , and\/or \u201cother data\u201d  of .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in , provide storage of computer readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that they are at least different copies.","A user may enter commands and information into the computer  through input devices such as a keyboard  and pointing device , commonly referred to as a mouse, trackball or touch pad. Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus , but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB).","A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . In addition to the monitor, computers may also include other peripheral output devices such as speakers  and printer , which may be connected through an output peripheral interface .","The computer  operates in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on memory device . The network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Conclusion","Although the systems and methods providing content propagation for enhanced document retrieval have been described in language specific to structural features and\/or methodological operations or actions, it is understood that the implementations defined in the appended claims are not necessarily limited to the specific features or actions described. For example, although system  of  has been described in terms of data source content propagation for enhanced KB article  retrieval, the described systems and methods can be used to propagate metadata mined from one or more independent data sources to referenced documents of any type, not only to KB or product support articles. For instance, system  may be used to provide content propagation for enhanced document retrieval across data sources that include links, references, titles, document IDs, and so on, with respect to other types of documents. Accordingly, the specific features and actions of the written description are disclosed as exemplary forms of implementing the claimed subject matter.","Background for Exemplary Clustering Systems and Methods","Clustering involves grouping of multiple objects, and is used in such applications as search engines and information mining. Clustering algorithms group objects based on the similarities of the objects. For instance, Web page objects are clustered based on their content, link structure, or their user access logs. The clustering of users is based on the items they have selected. User objects are clustered based on their access history. Clustering of items associated with the users is traditionally based on the users who selected those items. A variety of clustering algorithms are known. Prior-art clustering algorithms include partitioning-based clustering, hierarchical clustering, and density-based clustering.","The content of users' accessed Web pages or access patterns are often used to build user profiles to cluster Web users. Traditional clustering techniques are then employed. In collaborative filtering, clustering is also used to group users or items for better recommendation\/prediction.","Use of these prior clustering algorithms, in general, has certain limitations. Traditional clustering techniques can face the problem of data sparseness in which the number of objects, or the number of links between heterogeneous objects, are too sparse to achieve effective clustering of objects. With homogenous clustering, the data set being analyzed contains the same type of objects. For example, if the homogenous clustering is based on a Web page and a user, then the Web page objects and the user objects will each be clustered separately. If the homogenous clustering is based on an item and a user, then the item objects and the user objects will each be clustered separately. In such homogenous clustering embodiments, those objects of the same type are clustered together without consideration of other types of objects.","Prior-art heterogeneous object clustering cluster the object sets separately. The heterogeneous object clustering uses the links only as flat features representing each object node. In prior art heterogeneous clustering, the overall link structure inside and between the layers is not considered, or alternatively simply treated as separated features","Exemplary Clustering Systems and Methods","One embodiment of computer environment  (that is a general purpose computer) that can benefit by the use of clustering is shown in . The computer environment  includes a memory , a processor , a clustering portion , and support circuits . The support circuits include such devices as a display and an input\/output circuit portion that allow the distinct components of the computer environment  to transfer information (i.e., data objects).","Clustering is performed within the clustering portion . The clustering portion  can be integrated within the memory  and the processor  portions of the computer environment. For example, the processor  processes the clustering algorithm (which is retrieved from memory) that clusters the different objects. The memory  (such as databases) is responsible for storing the clustered objects and the associated programs and clustering algorithms so that the clustered objects can be retrieved (and stored) as necessary. The computer environment  may be configured as a stand-alone computer, a networked computer system, a mainframe, or any of the variety of computer systems that are known. Certain embodiments disclosed herein describe a computer environment application (a computer downloading Web pages from the Internet). It is envisioned that the concepts described herein are applicable to any known type of computer environment .","This written description provides a clustering mechanism by which the percentage of the returned results that are considered reliable (i.e., are applicable to the user's query) is increased. Clustering can be applied to such technical areas as search tools, information mining, data mining, collaborative filtering, etc. Search tools have received attention because of their capabilities to serve different information needs and achieve improved retrieval performance. Search tools are associated with such computer aspects as Web pages, users, queries, etc.","The present written description describes a variety of clustering algorithm embodiments for clustering data objects. Clustering of data objects is a technique by which large sets of data objects are grouped into a larger number of sets or clusters of data objects (with each of the larger number of clusters of data objects having fewer data objects). Each data object contained within a clustered group of data objects has some similarity. One aspect of clustering therefore can be considered as grouping of multiple data objects.","One clustering mechanism described in this written description relates to a framework graph , one embodiment of the framework graph is illustrated in . Certain embodiments of a unified clustering mechanism are provided in which different types of objects are clustered between different levels or node sets P and U as shown in the framework graph  of . It is also envisioned that the concepts described in this written description can be applied to three or more layers, instead of the two layers as described in the written description. Each node set P and U may also be considered a layer. In this written description, the term \u201cunified\u201d clustering applies to a technique for clustering heterogeneous data. The node set P includes a plurality of data objects p, p, p, . . . , pthat are each of a similar data type. The node set U includes a plurality of data objects u, u, u, . . . , uthat are each of a similar data type. The data type of the objects clustered on each node set (P or U) is identical, and therefore the data objects in each node set (P or U) are homogenous. The type of the data objects p, p, p, . . . , pthat are in the node set P are different from the types of the data objects u, u, u, . . . , uthat are in the node set U. As such, the types of data objects that are in different ones of the node sets P and U are different, or heterogeneous. Certain aspects of this written description provide for clustering using inputs (based on links) from homogenous and heterogeneous data types of objects.","Links are illustrated in this written description by lines extending between a pair of data objects. Links represent the relationships between pairs of data objects in clustering. In one instance, a link may extend from a Web page object to a user object, and represent the user selecting certain Web pages. In another instance, a link may extend from a Web page object to another Web page object, and represent relations between different Web pages. In certain embodiments of clustering, the \u201clinks\u201d are referred to as \u201cedges\u201d. The generalized term \u201clink\u201d is used in this written description to describe links, edges, or any connector of one object to another object that describes a relationship between the objects.","There are a variety of different types of links (as described in this written description) that relate to clustering different types of objects that associate different ones of the objects as set forth in the framework graph . The links can be classified as either inter-layer link or intra-layer link. An intra-layer link  or  is one embodiment of link within the framework graph  that describes relationships between different objects of the same type. An inter-layer link  is one embodiment of link within the framework graph  that describes relationships between objects of different types. As shown in , there are a plurality of intra-layer links  extending between certain one of the data objects u, u, u, . . . , u. In the embodiment shown in , there are also a plurality of intra-layer links  extending between certain ones of the data objects p, p, p, . . . , p. In the embodiment shown in , there are also a plurality of inter-layer links  extending between certain ones of the data objects u, u, u, . . . , uin the node set P and certain ones of the data objects p, p, p, . . . , pin the node set U. Using inter-layer links recognizes that clustering of one type of object may be affected by another type of object. For instance, clustering of web page objects may be affected by user object configurations, state, and characteristics.","The link direction (as provided by the arrowheads for the links , , or  in , and also in ) are illustrated as bi-directional since the relationships between the data objects may be directed in either direction. The links are considered illustrative and not limiting in scope. Certain links in the graph in the framework graph  may be more appropriately directed in one direction, the direction of the arrowhead typically does not affect the framework's operation. The framework graph  is composed of node set P, node set U, and link set L. With the framework graph , pand urepresent two types of data objects, in which p\u03b5P (i=1, . . . , I) and u\u03b5U (j=1, . . . , J). I and J are cardinalities of the node sets P and U, respectively.","Links (p, u)\u03b5L are inter-layer links (which are configured as 2-tuples) that are illustrated by reference character  between different types of objects. Links (p, p)\u03b5L and (u, u)\u03b5L , that are referenced by  and , respectively, are intra-layer links that extend between the same type of object. For simplicity, different reference characters are applied for inter-layer link sets () and intra-layer link sets (, ).","Using unified clustering, links are more fully utilized among objects to improve clustering. The clustering of the different types of objects in the different layers is reinforced by effective clustering. If objects are clustered correctly then clustering results should be more reasonable. Clustering can provide structuralized information that is useful in analyzing data.","The framework graph  illustrates clustering of multiple types of objects in which each type of objects is substantially identical (e.g., one type pertains to a group of web pages, a group of users, or a group of documents, etc.). The type of each group of objects generally differs from the type of other groups of the objects within the framework graph .","The disclosed clustering technique considers and receives input from different (heterogeneous) object types when clustering. One aspect of this written description is based on an intrinsic mutual relation in which the objects being clustered is provided with links to other objects. Certain ones of the links (and the objects to which those links connect) that connect to each object can be weighted with different importance to reflect their relevance to that object. For example, objects of the same types as those being clustered can be provided with greater importance than objects of a different type. This written description provides a mechanism by which varying levels of importance can be assigned to different objects or different types of objects. This assigning of different levels of importance to different objects (or different types of objects) is referred to herein","as clustering with importance. The varying levels of importance of the different often results in improved clustering results and effectiveness.","In the embodiment of the framework graph  for clustering heterogeneous objects as shown in , the different node sets P or U represent different layers each containing different object types. The multiple node sets (P and U are illustrated) of the framework graph  provide a basis for clustering. The two-layered directed graph  contains a set of data objects to be clustered. Objects of each type of object types (that are to be clustered according to the clustering algorithm) can be considered as the instance of a \u201clatent\u201d class. The links , , or  that extend between certain ones of the object nodes reflect inherent relations among the object nodes that are provided by the clustering. An iterative projecting technique for clustering, several embodiments of which are described in this written description, enables separate clustering of objects that have separate data types to contribute to the clustering process.","The heterogeneous types of objects (and their associated links) are reinforced by using the iterative clustering techniques as described herein. The iterative clustering projection technique relies on obtaining clustering information from separate types of objects that are arranged in separate layers, with each layer containing a homogenous type of object. The node information in combination with the link information is used to iteratively project and propagate the clustered results (the clustering algorithm is provided between layers) until the clustering converges. Iteratively clustering results of one type of object into the clustering results of another type of object can reduce clustering challenges associated with data sparseness. With this iterative projecting, the similarity measure in one layer clustering is calculated on clusters instead of individual groups of clusters of another type.","Each type of the different kinds of nodes and links are examined to obtain structural information that can be used for clustering. Structural information, for example, can be obtained considering the type of links connecting different data objects (e.g., whether a link is an inter-layer link or an intra-layer link). The type of each object is indicated by its node set P or U, as indicated in .","The generalized framework graph  of  can be applied to a particular clustering application. Namely, the framework graph  can illustrate a group of Web pages on the Internet relative to a group of users. The Web page layer is grouped as the node set P. The user layer of objects is grouped as the node set U. The framework graph  integrates the plurality of Web page objects and the plurality of user objects in the representation of the two-layer framework graph . The framework graph  uses link (e.g., edge) relations , ,  to facilitate the clustering of the different type of objects (as outlined by the generalized  framework graph). The link structure of the whole data set is examined during the clustering procedure to learn the different importance level of nodes. The nodes are weighted based on their importance in the clustering procedure to ensure that important nodes are clustered more reasonably.","In certain embodiments of the present written description, the links , , and  among clusters in the links are reserved. Reserved links are those links that extend between clusters of objects instead of the objects themselves. For example, one reserved link extends between a web-page cluster and a user cluster (instead of between a web page object and a user object as with the original links). In certain embodiments, the reserved links are maintained for a variety of future applications, such as a recommendation in the framework graph . E.g., the clustering result of Web page\/user clustering with reserved links could be shown as a summary graph of user hits behaviors, which provides the prediction of user's hits.","The content of the respective nodes pand uare denoted by the respective vectors fand g(not shown in ). Depending on the application, each individual node pand umay have (or may not have any) content features. Prior-art clustering techniques cluster the nodes pindependently from the nodes u. In contrast, in the clustering framework  described in this written description the nodes pand the nodes uare clustered dependently based on their relative importance. The clustering algorithm described herein uses a similarity function to measure distance between objects for each cluster type to produce the clustering. The cosine-similarity function as set forth in (1) can be used for clustering:",{"@attributes":{"id":"p-0087","num":"0086"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["s","c"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["f","x"]},{"mi":["f","y"]}],"mo":","}}},"mo":"=","mfrac":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"kx"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["f","x"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"ky"},"mo":"\u2062","mrow":{"msub":{"mi":["f","y"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"j"}}}],"mo":"\u00b7"}},{"msqrt":[{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"kx"},"mo":"\u2062","mrow":{"msubsup":{"mi":["f","x"],"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}},{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"ky"},"mo":"\u2062","mrow":{"msubsup":{"mi":["f","y"],"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"j"}}}}],"mo":"\u00b7"}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"1"}}]},{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["s","c"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":[{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["f","x"]},{"mi":["f","y"]}],"mo":","}}},{"mfrac":[{"mrow":[{"msub":[{"mi":["f","x"]},{"mi":["f","y"]}],"mo":"\u00b7"},{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mi":["f","x"]}},{"mo":["\uf605","\uf606"],"msub":{"mi":["f","y"]}}],"mo":"\u2062"}]},{"mrow":[{"munder":{"mo":"\u2211","mrow":{"mi":"k","mo":",","mrow":{"mrow":[{"msub":{"mi":["f","x"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["f","y"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"="}}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["f","x"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["f","y"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"\u2062"}},{"msqrt":[{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"kx"},"mo":"\u2062","mrow":{"msubsup":{"mi":["f","x"],"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}}},{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"ky"},"mo":"\u2062","mrow":{"msubsup":{"mi":["f","y"],"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"j"}}}}],"mo":"\u00b7"}]}],"mo":"="}],"mo":"="}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}]}}},"br":{},"sub":["x","y ","c ","x","y","x ","y","x","y"]},"In this written description, the node set P is used as an example to illustrate the inter-layer link  and the intra-layer links  and  of the nodes. All data is assumed to comprise a sequence of node pairs, for intra-layer node pairs (p, p), (p, p), . . . [where pand pare the same as p, and the pairs (p, p), (p, p), both stands for a node in the homogeneous layer] such as connected by links  or ; and for inter-layer pairs (p, u), (p, u), . . . such as connected by links . Thus a link between a pair of nodes (p, p) or (p, u) represents one or more occurrence of identical pairs in the data series. The weight of the link relates to its occurrence frequency.","In this written description, two separate vectors represent features of the inter-layer links  and the intra-layer links ,  for each particular node. For example, the intra-layer link ,  features are represented using a vector whose components correspond to other nodes in the same layer. By comparison the inter-layer link  feature is represented using a vector whose components correspond to nodes in another layer. Each component could be a numeric value representing the weight of link from (or to) the corresponding node. For example, the inter-layer link  feature of nodes pand p(as shown in ) can be represented as [1, 0, 0, . . . 0]and [1, 1, 1, . . . , 0], respectively.","Thus, the corresponding similarity function could be defined as cosine-similarity as above. The similarity function s(x,y) for intra-layer link ,  features determines the similarity between nodes pand pis applied is described in (3) as follows:",{"@attributes":{"id":"p-0091","num":"0090"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"s","msub":{"mi":"l","mn":"1"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["l","x"]},{"mi":["l","y"]}],"mo":"\u00b7"}}},"mo":"=","mfrac":{"mrow":[{"msub":[{"mi":["l","x"]},{"mi":["l","y"]}],"mo":"\u00b7"},{"mrow":[{"mo":["\uf605","\uf606"],"msub":{"mi":["l","x"]}},{"mo":["\uf605","\uf606"],"msub":{"mi":["l","y"]}}],"mo":"\u2062"}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}},"br":[{},{},{}],"sub":["lx","1 ","2 ","l2","x","y","l1 ","l2 ","x ","y ","x ","y "],"b":"504","in-line-formulae":[{},{}],"i":["s","x, y","h",", h"]},"Other representations of link features and other similarity measures could be used, such as representing links of each node as a set and applying a Jaccard coefficient. There are multiple advantages of the embodiments described herein. One advantage is that certain ones of the embodiments of clustering algorithms accommodate weighted links. Moreover, such clustering algorithms, as the k-means clustering algorithm, facilitate the calculation of the centroid of the clustering. The centroid is useful in further calculations to indicate a generalized value or characteristic of the clustered object.","The overall similarity function of node x and node y can be defined as the weighted sum of the three similarities including the three weighted values \u03b1, \u03b2, and \u03b3 as set forth in (5). There are two disclosed techniques to assign the three weighted values: heuristically and by training. If, for example, there is no tuning data, the weights are assigned manually to some desired value (e.g. alpha=0.5, beta=0.25, and gamma=0.25). If there is some extra tuning data, by comparison, then the weights can be calculated using a greedy algorithm, a hill-climbing algorithm, or some other type of either local or global improvement or optimizing program. A greedy algorithm refers to a type of optimization algorithm that seeks to improve each factor in each step, so that eventually an improved (and optimized in certain embodiments) solution can be reached.\n\n()=\u03b1()+\u03b2()+\u03b3()\u2003\u2003(5)\n\nwhere \u03b1+\u03b2+\u03b3=1.\n","Using these calculations, the content of the nodes, and the similarity of the nodes, are determined. Depending on the application, the three variables can be modified to provide different information values for the clustering algorithm. These contents and similarities of the nodes can thereupon be used as a basis for retrieval.","Many heterogeneous clustering problems often share the same property that the nodes are not equally important. Examples of heterogeneous clustering include Web page\/user clustering, item\/user clustering for collaborative filtering, etc. For these applications, important objects play an important role in getting more reasonable clustering results. In this written description, the link structure of the whole dataset is used to learn the importance of nodes. For each node in the node set P and U, for example pand u, importance weights ip, and iuare calculated by the link structure and are used in clustering procedure.","One clustering aspect relates a link analysis algorithm, multiple embodiments of which are provided in this written description. In one embodiment of the link analysis algorithm, a hybrid net model  as shown in  is constructed. Using the hybrid net model , the users and the Web pages are used as two illustrative types of nodes. The  embodiment of hybrid net model involving Web page and user types of objects is particularly directed to types of clustering involving the Internet, intranets, or other networks. The links include Web page hyperlinks\/interactions as shown by link , user-to-Web page hyperlinks\/interactions as shown by link , and user-to-user hyperlinks\/interactions as shown by link . The hybrid net model  of  explicates these hyperlinks\/relations by indicating the relations in and between users and Web pages that are illustrated by links , , and .","Given a certain group of users  that are contained within a user set , all Web pages that any of the nodes from the user set  have visited form the Web page set . The Web page set  is determined by sending the root Web page set to search engines and obtain a base Web page set. Three kinds of links represented by the arrows in  have different meanings. Those links represented by the arrows  that are contained within the Web page set  indicate hyperlinks between Web pages. Those links represented by arrows  that are contained within the user set  indicate social relations among users. Those links represented by arrows  that extend between the users set  and the Web page set  indicate the user's visiting actions toward Web pages. The links represented by arrows  indicate the user's evaluation of each particular Web page, so the authority\/hub score of a Web page will be more credible. Since the different types of links , , and  represent different relations. Each link can be weighted with a different importance depending, for example, on how often the link is accessed or how each pair of nodes that are connected by the link are associated.",{"@attributes":{"id":"p-0098","num":"0097"},"figref":"FIG. 7","b":["400","750","752","754","756","758","760","400","762","758","780","756","750","760"]},"The modeling module  includes a prior formalization portion , a webpage extraction portion , and a user extraction portion . Portions , , and  are configured to provide and\/or track data that has been previously formalized , is extracted from a Web page, or is extracted from the user . The embodiment of computer environment as illustrated in  is configured to provide a link analysis algorithm, one embodiment of which is described in this written description.","One embodiment of clustering algorithm can analyze a Web graph by looking for two types of pages: hubs, authorities, and users. Hubs are pages that link to a number of other pages that provide useful relevant information on a particular topic. Authority pages are considered as pages that are relevant to many hubs. Users access each one of authorities and hubs. Each pair of hubs, authorities, and users thereby exhibits a mutually reinforcing relationship. The clustering algorithm relies on three vectors that are used in certain embodiments of the present link analysis algorithm: the web page authority weight vector a, the hub weight vector h, and the user vector u. Certain aspects of these vectors are described in this written description.","Several of the following terms relating to the following weight calculations are not illustrated in the figures such as , and instead relate to the calculations. In one embodiment, for a given user i, the user weight udenotes his\/her knowledge level. For a Web page j, respective terms aand hindicate the authority weight and the hub weight. In one embodiment, each one of the three vectors (representing the user weight u, the web page authority weight a, and the hub weight h) are each respectively initialized at some value (such as 1). All three vectors h, a, and u are then iteratively updated based on the Internet usage considering the following calculations as set forth respectively in (6), (7), and (8):",{"@attributes":{"id":"p-0102","num":"0101"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"\u2003","mrow":{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":"a","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"p"}},{"mrow":[{"munder":{"mo":"\u2211","mrow":{"mi":["q","p"],"mo":"->"}},"mo":"\u2062","mrow":{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"q"}}},{"munder":{"mo":"\u2211","mrow":{"mi":["r","p"],"mo":"->"}},"mo":"\u2062","mrow":{"mi":"u","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}}],"mo":"+"}],"mo":"="}},{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"21.1em","height":"21.1ex"}}},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"6"}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"p"}},{"mrow":[{"munder":{"mo":"\u2211","mrow":{"mi":["p","q"],"mo":"->"}},"mo":"\u2062","mrow":{"mi":"a","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"q"}}},{"munder":{"mo":"\u2211","mrow":{"mi":["r","p"],"mo":"->"}},"mo":"\u2062","mrow":{"mi":"u","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}}],"mo":"+"}],"mo":"="}},{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"21.4em","height":"21.4ex"}}},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"7"}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"u","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}},{"mrow":[{"munder":{"mo":"\u2211","mrow":{"mi":["r","p"],"mo":"->"}},"mo":"\u2062","mrow":{"mi":"a","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"p"}}},{"munder":{"mo":"\u2211","mrow":{"mi":["r","q"],"mo":"->"}},"mo":"\u2062","mrow":{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"q"}}}],"mo":"+"}],"mo":"="}},{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"21.4em","height":"21.4ex"}}},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"8"}}}]}]}}}}},"br":{},"sub":["ij","ij","ij","ij","ij","ij"]},{"@attributes":{"id":"p-0103","num":"0102"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"\u2003","mrow":{"mo":"{","mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"a","mo":"=","mrow":{"mrow":[{"msup":{"mi":["A","T"]},"mo":"\u2062","mi":"h"},{"msup":{"mi":["V","T"]},"mo":"\u2062","mi":"u"}],"mo":"+"}}},{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"26.7em","height":"26.7ex"}}},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"9"}}}]},{"mtd":[{"mrow":{"mi":"h","mo":"=","mrow":{"mi":"Aa","mo":"+","mrow":{"msup":{"mi":["V","T"]},"mo":"\u2062","mi":"u"}}}},{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"26.9em","height":"26.9ex"}}},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"10"}}}]},{"mtd":[{"mrow":{"mi":"u","mo":"=","mrow":{"mi":"V","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["a","h"],"mo":"+"}}}}},{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"26.9em","height":"26.9ex"}}},"mo":"\u2062","mrow":{"mo":["(",")"],"mn":"11"}}}]}]}}}}}},"In one embodiment, the calculation for vectors a, h, u as set forth in (9), (10), and (11) go through several iterations to provide meaningful results. Prior to the iterations in certain embodiments, a random value is assigned to each one of the vectors a, h, and u. Following each iteration, the values of a, h, u will be changed and normalized to provide a basis for the next iteration. Following each iteration, the iterative values of a, h, and u each tend to converge to a certain respective value. The users with high user weight ui and Web pages with high authority weight aand\/or hub weight hcan be reported. In a preferred embodiment, certain respective user or web-page objects can be assigned with higher values than other respective user or web-page objects. The higher the value is, the more importance is assigned to that object.","The embodiment of link analysis algorithm as described in this written description that can cluster thereby relies on iterative input from both Web pages and users. As such, weighted input from the user is applied to the clustering algorithm of the Web page. Using the weighted user input for the clustering improves the precision of the search results, and the speed at which the clustering algorithm can be performed.","While the link analysis algorithm described herein is applied to clustering algorithms for clustering Web pages based on users, it is envisioned that the link analysis algorithm can be applied to any heterogeneous clustering algorithm. This weighting partially provides for the clustering with importance as described herein.","A variety of embodiments of a clustering algorithm that can be used to cluster object types are described. Clustering algorithms attempt to find natural groups of data objects based on some similarity between the data objects to be clustered. As such, clustering algorithms perform a clustering action on the data objects. Certain embodiments of clustering algorithm also finds the centroid of a group of data sets, which represents a point whose parameter values are the mean of the parameter values of all the points in the clusters. To determine cluster membership, most clustering algorithms evaluate the distance between a point and the cluster centroid. The output from a clustering algorithm is basically a statistical description of the cluster centroids with the number of components in each cluster.","Multiple embodiments of cluster algorithms are described in this written description. The two-ways k-means cluster algorithm is based on the mutual reinforcement of clustering process. The two-ways k-means cluster algorithm is an iterative clustering algorithm. In the two-ways k-means cluster algorithm, the object importance is first calculated by (6)-(8) or (9)-(11), and the result is then applied in the followed iterative clustering procedure. The clustering algorithm clusters objects in each layer based on the defined similarity function. Although a great deal of clustering algorithms, such as k-means, k-medoids, and agglomerative hierarchical methods could be used, this written description describes the application of the k-means clustering algorithm.","There are several techniques to apply the calculated importance score of nodes. One technique involves modifying the basic k-means clustering algorithm to a \u2018weighted\u2019 k-means algorithm. In the modified k-means algorithm, the centroid of the given cluster is calculated using the weighted sum of the features with the weight setting determining the importance score. The nodes having a higher importance or weighting are thereby given more emphasis in forming the cluster centroid for both the content and the link features. Another embodiment involves modifying the nodes' link weight by their importance score, and then using the weighted link feature in the similarity function. In this way, the importance of the nodes is only reflected in the link feature in clustering process.","One embodiment of the input\/output of the clustering algorithm is shown in . The input to the clustering algorithm includes a two-layered framework graph  (including the content features fand gof the nodes). The output to the clustering algorithm includes a new framework graph  that reflects the clustering. In certain embodiments of the new framework graph, the variations of each old node that has changed into its new node position can be illustrated.","One embodiment of a flow chart illustrating one embodiment of the clustering algorithm  is shown in . The clustering algorithm  includes  in which the original framework graph (prior to each clustering iteration) is input. In , the importance of each node being considered is determined or calculated using (6)-(8) or (9)-(11). In , an arbitrary layer is selected for clustering. Nodes in the selected layer are clustered in an appropriate fashion (e.g., according to content features) in . In certain embodiments, the nodes can be filtered using a desired filtering algorithm (not shown) to improve the clustering. In , the nodes of each cluster are merged into one node. For instance, if two candidate nodes exist following the filtering, the closest two candidate nodes can be merged by, e.g., averaging the vector values of the two candidate nodes. This merging allows individual nodes to be combined to reduce the number of nodes that have to be considered. As such, the merging operation can be used to reduce the occurrence of duplicates and near-duplicates.","The corresponding links are updated based on the merging in . In , the clustering algorithm switches to a second layer (from the arbitrarily selected layer) for clustering. In , the nodes of the second layer are clustered according to their content features and updated link features. In , the nodes of each cluster are merged into one node.","In , the original link structure and the original nodes of the other layer are restored. In , the nodes of each cluster of the second layer are merged, and the corresponding links are updated. In , this iterative clustering process is continued within the computer environment. In , a revised version of the framework graph  is output.","In the initial clustering pass, only the content features are utilized. Because in most cases the link feature are too sparse in the beginning to be useful for clustering. In subsequent clustering passes, content features and link features are combined to enhance the effectiveness of the clustering. By combining the content features and the link features, the weights are specified with different values and the results can be compared, and clustering having an improved accuracy can be provided.","The clustering algorithm as described relative to  can be applied to many clustering embodiments. More particularly, one embodiment of clustering of Web pages based on how the Web pages are accessed by users is now described. In those types of link extends between a node of the user layer to a node of the Web page layer, a user uhas visited a Web page pbefore if there is one link from uto p. The weight of the link means the probability that the user uwill visit the page pat a specific time, denoted as Pr(p|u). It can be simply calculated by counting the numbers within the observed data, as shown in (12).",{"@attributes":{"id":"p-0116","num":"0115"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["p","i"]},{"mi":["u","j"]}],"mo":"\u2758"}}},"mo":"=","mfrac":{"mrow":[{"mi":"C","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["p","i"]},{"mi":["u","j"]}],"mo":","}}},{"munder":{"mo":"\u2211","mrow":{"mi":"t","mo":"\u2208","mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["u","j"]}}}}},"mo":"\u2062","mrow":{"mi":"C","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["p","t"]},{"mi":["u","j"]}],"mo":","}}}}]}}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}},"br":{},"sub":["j","j ","i","j","j ","i "]},"One embodiment of clustering algorithm, as shown in the embodiment of framework graph  of , involves a concept layer or hidden layer. In , for simplicity, the intra-layer link  and  that are shown in the framework graph of  are hidden. It is envisioned, however, that the embodiment of framework graph  as shown in  can rely on any combination of intra-layer links and inter-layer links and still remain within the concepts of the present written description.","The hidden layer  (in the embodiment of framework graph  as displayed in ) lies between web-page layer and user layer. The hidden layer  provides an additional layer of abstraction (from which links extend to each of the node sets P and U) that permit modeling with improved realism compared to extending links between the original node sets P and U. One of the inter-layer links  of the embodiment of framework graph  such as shown in  (that does not have a hidden layer) may be modeled as a pair of hidden inter-layer links of the embodiment of framework graph  such as shown in . One of the hidden inter-layer links extends between the web-page layer containing the node set P and the hidden layer , and one of the hidden inter-layer links extends between the user layer and the hidden layer . The direction of the arrows on each hidden inter-layer link shown in  is arbitrary, as is the particular web pages and users in the respective node sets P and U that are connected by a hidden inter-layer link to a node in the hidden layer.","Links (i.e., hidden inter-layer links) that extend between the web-page layer containing the node set P and the hidden layer  indicate how likely a web-page p, petc. belongs to a particular concept node P(c), P(c), etc. in the hidden layer . Links (i.e., hidden inter-layer links) that extend between the user layer and the hidden layer  indicate how likely a user node u, u, etc. has interest in a particular concept node P(c), P(c), etc. within the hidden layer .","The links that extend between the web-page layer and the concept layer therefore each stand for the probability that a Web page pis classified into a concept category c, denoted as Pr(p|c). This model embodied by the framework graph shares the assumption used by Na\u00efve Bayesian classification, in which different words are considered conditionally independent. So the concept ccan be represented as a normal distribution, i.e. a vector {right arrow over (\u03bc)}for expectation and a {right arrow over (\u03c3)}vector for covariance. The value Pr(p|c) can be derived as per (13).",{"@attributes":{"id":"p-0121","num":"0120"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mi":"E","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["p","i"]},{"mi":["c","k"]}],"mo":"\u2758"}}}}},"mo":"=","mfrac":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["p","i"]},{"mi":["c","k"]}],"mo":"\u2758"}}},{"munder":{"mo":"\u2211","mi":"t"},"mo":"\u2062","mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["p","t"]},{"mi":["c","k"]}],"mo":"\u2758"}}}}]}}}},{"mtd":{"mrow":{"mo":"=","mfrac":{"mrow":[{"munder":{"mo":"\u220f","mi":"l"},"mo":"\u2062","mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"w","mrow":{"mi":["l","i"],"mo":","}},{"mi":["c","k"]}],"mo":"\u2758"}}}},{"munder":{"mo":"\u2211","mi":"t"},"mo":"\u2062","mrow":{"munder":{"mo":"\u220f","mi":"l"},"mo":"\u2062","mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"w","mrow":{"mi":["l","t"],"mo":","}},{"mi":["c","k"]}],"mo":"\u2758"}}}}}]}}}},{"mtd":{"mrow":{"mrow":{"mo":"=","mfrac":{"msup":{"mi":"\u2147","mrow":{"mo":"-","mrow":{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"mfrac":{"mn":"1","mrow":{"mn":"2","mo":"\u2062","msub":{"mi":"\u03c3","mrow":{"mi":["l","k"],"mo":","}}}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"w","mrow":{"mi":["l","i"],"mo":","}},{"mi":"\u03bc","mrow":{"mi":["l","k"],"mo":","}}],"mo":"-"}},"mn":"2"}}}}},"mrow":{"munder":{"mo":"\u2211","mi":"t"},"mo":"\u2062","msup":{"mi":"\u2147","mrow":{"mo":"-","mrow":{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"mfrac":{"mn":"1","mrow":{"mn":"2","mo":"\u2062","msub":{"mi":"\u03c3","mrow":{"mi":["l","k"],"mo":","}}}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"w","mrow":{"mi":["l","k"],"mo":","}},{"mi":"\u03bc","mrow":{"mi":["l","k"],"mo":","}}],"mo":"-"}},"mn":"2"}}}}}}}},"mo":","}}}]}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}}}},"br":{},"sub":["l,i ","i "]},"Those links (denoted as Pr(c|u)) that extend between a node in the user layer and a node in the hidden layer reflect the interest of the user in the category reflected by the concept. Thus, one vector (I, I, . . . , I), I=Pr(c|u) corresponds to each user, in which n is the number of the hidden concept. The links shown in  can be considered as the vector models of the user. The vector is constrained by the user's usage data as set forth in (14).",{"@attributes":{"id":"p-0123","num":"0122"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["p","i"]},{"mi":["u","j"]}],"mo":"|"}}},{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":[{"mi":["p","i"]},{"mi":["c","l"]}],"mo":"|"},"mo":",","msub":{"mi":["u","j"]}}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["c","l"]},{"mi":["u","j"]}],"mo":"|"}}}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":"="}}},{"mtd":{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"5.8em","height":"5.8ex"}}},"mo":"\u2062","mrow":{"mo":"\u2248","mrow":{"munder":{"mo":"\u2211","mi":"l"},"mo":"\u2062","mrow":{"mrow":[{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["p","i"]},{"mi":["c","l"]}],"mo":"|"}}},{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["c","l"]},{"mi":["u","j"]}],"mo":"|"}}}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}}}}]}},{"mrow":{"mo":["(",")"],"mn":"14"}}]}}}},"br":{},"sub":["k","j"]},"To simplify, Pr(p|u)=R, Pr(p|c)=S, and Pr(c|u)=T. The user j can be considered separately as set forth in (15).",{"@attributes":{"id":"p-0125","num":"0124"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":"R","mrow":{"mn":"1","mo":",","mi":"j"}}}},{"mtd":{"msub":{"mi":"R","mrow":{"mn":"2","mo":",","mi":"j"}}}},{"mtd":{"mi":"\u2026"}},{"mtd":{"msub":{"mi":"R","mrow":{"mrow":{"mo":["\uf603","\uf604"],"mi":"Page"},"mo":",","mi":"j"}}}}]}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"msub":{"mi":"S","mrow":{"mn":["1","1"],"mo":","}}},{"msub":{"mi":"S","mrow":{"mn":["1","2"],"mo":","}}},{"mi":"\u2026"},{"msub":{"mi":"S","mrow":{"mn":"1","mo":",","mrow":{"mo":["\uf603","\uf604"],"mi":"Concept"}}}}]},{"mtd":[{"msub":{"mi":"S","mrow":{"mn":["2","1"],"mo":","}}},{"msub":{"mi":"S","mrow":{"mn":["2","2"],"mo":","}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":"\u2026"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"msub":{"mi":"S","mrow":{"mrow":{"mo":["\uf603","\uf604"],"mi":"Page"},"mo":",","mn":"1"}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":"\u2026"},{"msub":{"mi":"S","mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mi":"Page"},{"mo":["\uf603","\uf604"],"mi":"Concept"}],"mo":","}}}]}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":"T","mrow":{"mn":"1","mo":",","mi":"j"}}}},{"mtd":{"msub":{"mi":"T","mrow":{"mn":"2","mo":",","mi":"j"}}}},{"mtd":{"mi":"\u2026"}},{"mtd":{"msub":{"mi":"T","mrow":{"mrow":{"mo":["\uf603","\uf604"],"mi":"Concept"},"mo":",","mi":"j"}}}}]}}],"mo":"\u00d7"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"15"}}]}}}},"br":{},"sub":"k,j "},{"@attributes":{"id":"p-0126","num":"0125"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mrow":{"mo":["[","]"],"mtable":{"mtr":{"mtd":[{"msub":{"mi":"R","mrow":{"mi":"i","mo":",","mn":"1"}}},{"msub":{"mi":"R","mrow":{"mi":"i","mo":",","mn":"2"}}},{"mi":"\u2026"},{"msub":{"mi":"R","mrow":{"mi":"i","mo":",","mrow":{"mo":["\uf603","\uf604"],"mi":"User"}}}}]}}},"mo":"="},"mo":"\u2062","mstyle":{"mspace":{"@attributes":{"width":"25.3em","height":"25.3ex"}}}}}},{"mtd":{"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":{"mtd":[{"msub":{"mi":"S","mrow":{"mi":"i","mo":",","mn":"1"}}},{"msub":{"mi":"S","mrow":{"mi":"i","mo":",","mn":"2"}}},{"mi":"\u2026"},{"msub":{"mi":"S","mrow":{"mi":"i","mo":",","mrow":{"mo":["\uf603","\uf604"],"mi":"Concept"}}}}]}}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"msub":{"mi":"T","mrow":{"mn":["1","1"],"mo":","}}},{"msub":{"mi":"T","mrow":{"mn":["1","2"],"mo":","}}},{"mi":"\u2026"},{"msub":{"mi":"T","mrow":{"mn":"1","mo":",","mrow":{"mo":["\uf603","\uf604"],"mi":"User"}}}}]},{"mtd":[{"msub":{"mi":"T","mrow":{"mn":["2","1"],"mo":","}}},{"msub":{"mi":"T","mrow":{"mn":["2","2"],"mo":","}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mi":"\u2026"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mi":"\u2026"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"msub":{"mi":"T","mrow":{"mrow":{"mo":["\uf603","\uf604"],"mi":"Concept"},"mo":",","mn":"1"}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"msub":{"mi":"T","mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mi":"Concept"},{"mo":["\uf603","\uf604"],"mi":"User"}],"mo":","}}}]}]}}],"mo":"\u00d7"}}}]}},{"mrow":{"mo":["(",")"],"mn":"16"}}]}}}},"br":{}},"Since |User|>>|Concept|, we can also give a least square solution of Sas set forth in (17).",{"@attributes":{"id":"p-0128","num":"0127"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mover":{"mi":"\u03bc","mo":"->"},"mi":"j"},"mo":"=","mrow":{"mrow":[{"munder":{"mo":"\u2211","mi":"t"},"mo":"\u2062","mrow":{"msub":{"mover":{"mi":"P","mo":"->"},"mi":"t"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"Pr","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["p","t"]},{"mi":["c","k"]}],"mo":"|"}}}}},{"munder":{"mo":"\u2211","mi":"k"},"mo":"\u2062","mrow":{"msub":[{"mi":"S","mrow":{"mi":["t","k"],"mo":","}},{"mover":{"mi":"P","mo":"->"},"mi":"t"}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}],"mo":"="}}},{"mrow":{"mo":["(",")"],"mn":"17"}}]}}}}},"After the vector for expectation {right arrow over (\u03bc)}is obtained, a new vector for covariance {right arrow over (\u03c3)}. can be calculated. While the embodiment of framework graph  that is illustrated in  extends between the node set P and the node set U, it is envisioned that the particular contents of the node sets are illustrative in nature, and can be applied to any set of node sets.","One embodiment of the clustering algorithm in which Web page objects are clustered based on user objects can be outlined as follows as described relative to one embodiment of Web page clustering algorithm shown as  in :\n\n"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["In the figures, the left-most digit of a component reference number identifies the particular figure in which the component first appears.",{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
