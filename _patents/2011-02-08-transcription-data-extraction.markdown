---
title: Transcription data extraction
abstract: A computer program product, for performing data determination from medical record transcriptions, resides on a computer-readable medium and includes computer-readable instructions for causing a computer to obtain a medical transcription of a dictation, the dictation being from medical personnel and concerning a patient, analyze the transcription for an indicating phrase associated with a type of data desired to be determined from the transcription, the type of desired data being relevant to medical records, determine whether data indicated by text disposed proximately to the indicating phrase is of the desired type, and store an indication of the data if the data is of the desired type.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08280735&OS=08280735&RS=08280735
owner: eScription Inc.
number: 08280735
owner_city: Needham
owner_country: US
publication_date: 20110208
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS"],"p":["This Application claims the benefit under 35 U.S.C. \u00a7120 and is a continuation (CON) of U.S. application Ser. No. 12\/587,297 entitled \u201cTRANSCRIPTION DATA EXTRACTION\u201d filed on Oct. 5, 2009, which claims the benefit under 35 U.S.C. \u00a7120 and is a continuation (CON) of U.S. application Ser. No. 11\/080,689, entitled \u201cTRANSCRIPTION DATA EXTRACTION\u201d filed on Mar. 14, 2005, each of which is herein incorporated by reference in its entirety.","Healthcare costs in the United States account for a significant share of the GNP. The affordability of healthcare is of great concern to many Americans. Technological innovations offer an important leverage to reduce healthcare costs.","Many Healthcare institutions require doctors to keep accurate and detailed records concerning diagnosis and treatment of patients. Motivation for keeping such records include government regulations (such as Medicare and Medicaid regulations), desire for the best outcome for the patient, and mitigation of liability. The records include patient notes that reflect information that a doctor or other person adds to a patient record after a given diagnosis, patient interaction, lab test or the like.","Record keeping can be a time-consuming task, and the physician's time is valuable. The time required for a physician to hand-write or type patient notes can represent a significant expense. Verbal dictation of patient notes offers significant timesavings to physicians, and is becoming increasingly prevalent in modern healthcare organizations.","Over time, a significant industry has evolved around the transcription of medical dictation. Several companies produce special-purpose voice mailbox systems for storing medical dictation. These centralized systems hold voice mailboxes for a large number of physicians, each of whom can access a voice mailbox by dialing a phone number and putting in his or her identification code. These dictation voice mailbox systems are typically purchased or shared by healthcare institutions. Prices can be over $100,000 per voice mailbox system. Even at these prices, these centralized systems save healthcare institutions vast sums of money over the cost of maintaining records in a more distributed fashion.","Using today's voice mailbox medical dictation systems, when a doctor completes an interaction with a patient, the doctor calls a dictation voice mailbox, and dictates the records of the interaction with the patient. The voice mailbox is later accessed by a medical transcriptionist who listens to the audio and transcribes the audio into a text record. The playback of the audio data from the voice mailbox may be controlled by the transcriptionist through a set of foot pedals that mimic the action of the \u201cforward\u201d, \u201cplay\u201d, and \u201crewind\u201d buttons on a tape player. Should a transcriptionist hear an unfamiliar word, the standard practice is to stop the audio playback and look up the word in a printed dictionary.","Some medical transcriptionists may specialize in one area of medicine, or may deal primarily with a specific group of doctors. The level of familiarity with the doctors' voices and with the subject matter can increase the transcriptionist accuracy and efficiency over time.","The medical transcriptionist's time is less costly for the hospital than the doctor's time, and the medical transcriptionist is typically much more familiar with the computerized record-keeping systems than the doctor is, so this system offers a significant overall cost saving to the hospital.","To reduce costs further, health care organizations have deployed speech recognition technology, such as the AutoScript\u2122 product (made by eScription\u2122 of Needham, Mass.), to automatically transcribe medical dictations. Automatically transcribed medical records documents usually require editing by the transcriptionist. While speech recognition may accurately capture the literal word string spoken by the provider, the resulting document is generally not presented in a desired format.","Many new medical record documents could be or should be structured in tabular format with data values filled in to appropriate fields in the table. For example, laboratory reports, pathology reports, radiology reports and cardiac stress tests often can or should be wholly or partially formatted in tables with data filled in to the appropriate fields of the table.","In an exemplary scenario, a physician may dictate:\n\n","It may be desired for the resulting portion of the document to appear as:",{"@attributes":{"id":"p-0014","num":"0014"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003","************************"]},{"entry":[{},{},"Sex: Male"]},{"entry":[{},{},"DOB: 01\/05\/1953"]},{"entry":[{},{},"REASON FOR VISIT: Routine Physical."]},{"entry":[{},{},"PHYSICAL EXAMINATION:"]},{"entry":[{},{},"General: Well-appearing"]},{"entry":[{},{},"Pulse:"]},{"entry":[{},{},"BP: 120\/85"]},{"entry":[{},{},"Weight: 182"]},{"entry":[{},{},"Height:"]},{"entry":[{},{},"******************************************"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"At least one automatic speech recognition system currently exists for formatting dictated data into tabular form. This existing system is an interactive speech recognition system where the medical care provider sees the data table on the screen and, therefore, knows what data is expected to be dictated and in what order. The speaker using this system must verbally indicate that the speaker is moving to the next tabular field (for example, by saying \u201cnext blank\u201d) before speaking the required data of the next field. Without interaction with the speaker, there is nothing to constrain the speaker to a particular sequence of dictating the desired information. Nor is there any way to guarantee that all required fields are available in the dictation when using the non-interactive system.","In general, in an aspect, the invention provides a computer program product for performing data determination from medical record transcriptions, the computer program product residing on a computer-readable medium and including computer-readable instructions for causing a computer to obtain a medical transcription of a dictation, the dictation being from medical personnel and concerning a patient, analyze the transcription for an indicating phrase associated with a type of data desired to be determined from the transcription, the type of desired data being relevant to medical records, determine whether data indicated by text disposed proximately to the indicating phrase is of the desired type, and store an indication of the data if the data is of the desired type.","Implementations of the invention may include one or more of the following features. The computer program product further includes instructions for causing the computer to alter a format of the transcription based upon whether the data indicated by the text disposed proximately to the indicating phrase is of the desired type. The computer program product further includes instructions for causing the computer to obtain a set of indicia of desired data types to be determined, and store data type indicators, and corresponding indicia of data from the transcription determined to be of desired types, in the transcription indicative of a table format such that if the transcription is displayed, the data indicia are displayed in association with corresponding data type indicators. The instructions allow for the determination of data corresponding to less than all of the desired data types indicated by the set of indicia, whereby the computer program product provides for sparse data extraction. The instructions for causing the computer to obtain the set of indicia cause the computer to retrieve the set in accordance with a worktype associated with the transcription.","Implementations of the invention may also include one or more of the following features. The data indicated by the text disposed proximately to the indicating phrase is determined to be of the desired type only if a probability of the proximately-disposed data being of the desired type exceeds a threshold probability. The data indicated by the text disposed proximately to the indicating phrase is determined to be of a first data type if a first probability that the proximately-disposed data is of the first data type exceeds a second probability that the proximately-disposed data is of a second data type. The computer program product further includes instructions for causing the computer to analyze information associated with patient to determine which type of data the indicated data are based on known relationships between values of different data types and patient information. The computer program product further includes instructions for causing the computer to obtain the information associated with the patient from the transcription.","Implementations of the invention may also include one or more of the following features. The computer program product further includes instructions for causing the computer to analyze the indicated data to determine which type of data the indicated data are based on known values of data associated with different data types. The computer program product further includes instructions for causing the computer to remove from the transcription, if it is determined that data indicated by text disposed proximately to the indicating phrase is of a desired type, the proximately-disposed text and the indicating phrase. The computer program product further includes instructions for causing the computer to modify the indicating phrase associated with the data type desired to be determined from the transcription. The instructions for causing the computer to determine if data indicated by text disposed proximately to the indicating phrase is of the desired type is capable of determining substantive data content of the text despite different phrases potentially forming the text.","In general, in another aspect, the invention provides a language processor module for processing a medical dictation transcription, the module being configured to compare words of the transcription with a plurality of natural language trigger phrases associated with desired types of data, make a probabilistic determination that the transcription includes first data of a first type if a first trigger phrase associated with the first type of data is found in the transcription, and alter the transcription, to produce an altered transcription, by at least one of removing the first trigger phrase from the transcription, and reformatting the transcription such that if the transcription is displayed the first data will be displayed in association with an indication of the first data type.","Implementations of the invention may include one or more of the following features. To make the probabilistic determination, the module is configured to compare the first data to at least one value associated with the particular data type. The module is configured to select the at least one value dependent upon patient information associated with a patient corresponding to the transcription. To alter the transcription the module is configured to produce a table including indicia of data types and the first data associated with the indication of the first data type. The module is configured to store the first data in a database field independent of the transcription. The trigger phrase comprises a natural language phrase. At least a portion of the transcription is normalized and the trigger phrase comprises a normalized language phrase. The module is configured to remove the first trigger phrase and indicia of the first data from the transcription. To make a probabilistic determination the module is configured to analyze a first probability that the first data represents the desired data type and a second probability that the first data represents another data type. To make a probabilistic determination the module is configured to determine that a probability that the first data represents the first data type exceeds a probability threshold.","Various aspects of the invention may provide one or more of the following capabilities. Time and cost of editing automatically-generated medical transcription documents can be reduced. Transcriptionist fatigue in editing transcribed documents can be reduced. Data can be extracted from a document dictated in a natural manner and entered as a by-product of current dictation work flow into tabular form and\/or into individually specific data fields. Costs associated with entering data into an electronic medical record can be reduced. Medical records can be used to better track patient progress and\/or can be more easily searched to assist in medical treatment outcome research. Data from medical record transcriptions can be extracted and used without substantially interfering with normal work flow of the providers of medical care providing the medical records dictations. Medical record documents can be provided with an improved appearance. The creation of fully electronic medical records can be facilitated.","These and other capabilities of the invention, along with the invention itself, will be more fully understood after a review of the following figures, detailed description, and claims.","Embodiments of the invention provide techniques for extracting specific data elements as a result of automated speech recognition of medical dictations. For example, an automatic speech recognition (ASR) system is supplemented by natural language processing, constrained by one or more tables of data elements for locating relevant information in the dictation. The natural language processing analyzes the dictation and extracts data according to the desired table, preferably without interaction with the speaker and preferably without the speaker dictating the data for the table in any particular sequence. The extracted data may be presented along with original audio, to a medical transcriptionist (MT) for editing. Other embodiments are within the scope of the invention.","Referring to , a system  for transcribing audio and editing transcribed audio includes a speaker\/person , a communications network , a voice mailbox system , an administrative console , an editing device , a communications network , a database server , a communications network , a model builder\/modifier , and an automatic transcription device . Here, the network  is preferably a public switched telephone network (PSTN) although other networks, including packet-switched networks could be used, e.g., if the speaker  uses an Internet phone for dictation. The network  is preferably a packet-switched network such as the global packet-switched network known as the Internet. The network  is preferably a packet-switched, local area network (LAN). Other types of networks may be used, however, for the networks , , , or any or all of the networks , ,  may be eliminated, e.g., if items shown in  are combined or eliminated. As discussed below, the model builder\/modifier  is configured to build and\/or modify models (e.g., trigger models, content models, order models) used to accurately extract the requested data fields from the transcription.","Preferably, the voice mailbox system , the administrative console , and the editing device  are situated \u201coff site\u201d from the database server  and the automatic transcription device . These systems\/devices , , , however, could be located \u201con site,\u201d and communications between them may take place, e.g., over a local area network. Similarly, it is possible to locate the automatic transcription device  off-site, and have the device  communicate with the database server  over the network .","The network  is configured to convey dictation from the speaker  to the voice mailbox system . Preferably, the speaker  dictates into an audio transducer such as a telephone, and the transduced audio is transmitted over the telephone network  into the voice mailbox system , such as the Intelliscript\u2122 product made by eScription\u2122 of Needham, Mass. The speaker  may, however, use means other than a standard telephone for creating the digital audio file for each dictation. For example, the speaker  may dictate into a handheld PDA device that includes its own digitization mechanism for storing the audio file. Or, the speaker  may use a standard \u201cdictation station,\u201d such as those provided by many vendors. Still other devices may be used by the speaker  for dictating, and possibly digitizing the dictation, and sending it to the voice mailbox system .","The voice mailbox system  is configured to digitize audio from the speaker  to produce a digital audio file of the dictation. For example, the system  may use the Intelliscript\u2122 product made by eScription.","The voice mailbox system  is further configured to prompt the speaker  to enter an identification code and a worktype code. The speaker  can enter the codes, e.g., by pressing buttons on a telephone to send DTMF tones, or by speaking the codes into the telephone. The system  may provide speech recognition to convert the spoken codes into a digital identification code and a digital worktype code. The mailbox system  is further configured to store the identifying code and the worktype code in association with the dictation. The identification code can associate the dictation with a particular speaker and\/or an entity associated with the speaker (e.g., the speaker's employer or affiliate hospital, etc.). Speakers with multiple affiliations (e.g., to different entities such as hospitals) preferably have multiple identification codes, with each identification code corresponding to a respective one of the affiliated entities. The system  preferably prompts the speaker  to provide the worktype code at least for each dictation related to the medical field. The worktype code designates a category of work to which the dictation pertains, e.g., for medical applications this could include Office Note, Consultation, Operative Note, Discharge Summary, Radiology report, etc. The worktype code may be used to define settings such as database fields and\/or to refine settings, such that settings may be specific not only to speaker-transcriptionist pairings, but further to worktype of dictations provided by the speaker, and\/or to other parameters or indicia.","The voice mailbox system  is further configured to transmit the digital audio file and speaker identification code and worktype code over the network  to the database server  for storage. This transmission is accomplished by the system  product using standard network transmission protocols communicating with the database server .","The database server  is configured to store the incoming data from the voice mailbox system , as well as from other sources, in a database . The database server  may include the EditScript\u2122 database product from eScription. Software of the database server is configured to produce a database record for the dictation, including a file pointer to the digital audio data, and a field containing the identification code for the speaker . If the audio and identifying data are stored on a PDA, the PDA may be connected to a computer running the HandiScript\u2122 software product made by eScription that will perform the data transfer and communication with the database server  to enable a database record to be produced for the dictation.","The database  stores a variety of information regarding transcriptions. The database  stores the incoming data from the voice mailbox system , the database record produced by the database software, data fields associated with transcriptions, etc. The data fields are stored in a tabular data fields section , of the database , that includes sets of data fields associated with particular transcriptions. These fields may be accessed by the automatic transcription device , e.g., for storing data in the fields, or the administration console , e.g., for searching the fields for particular information.","Preferably, all communication with the database server  is intermediated by a \u201cservlet\u201d application  that includes an in-memory cached representation of recent database entries. The servlet  is configured to service requests from the voice mailbox system , the automatic transcription device, the editing device , and the administrative console , reading from the database  when the servlet's cache does not contain the required information. The servlet  includes a separate software module that helps ensure that the servlet's cache is synchronized with the contents of the database . This helps allow the database  to be off-loaded of much of the real-time data-communication and to grow to be much larger than otherwise possible. For simplicity, however, the below discussion does not refer to the servlet, but all database access activities may be realized using the servlet application  as an intermediary.","The automatic transcription device  may access the database in the database server  over the data network  for transcribing the stored dictation. The automatic transcription device  uses an automatic speech recognition (ASR) device (e.g., software) to produce a draft transcription for the dictation. An example of ASR technology is the AutoScript\u2122 product made by eScription, that also uses the speaker identifying information to access speaker-dependent ASR models with which to perform the transcription. The device  transmits the draft transcription over the data network  to the database server  for storage in the database and to be accessed, along with the digital audio file, by the editing device .","The editing device  is configured to be used by a transcriptionist to access and edit the draft transcription stored in the database of the database server . The editing device  includes a computer (e.g., display, keyboard, mouse, monitor, memory, and a processor, etc.), an attached foot-pedal, and appropriate software such as the EditScript Client\u2122 software product made by eScription. The transcriptionist can request a dictation job by, e.g., clicking an on-screen icon. The request is serviced by the database server , which finds the dictation for the transcriptionist, and transmits the corresponding audio file and the draft transcription text file, as stored in the database.","The transcriptionist edits the draft using the editing device  and sends the edited transcript back to the database server . For example, to end the editing session the transcriptionist can click an on-screen icon button to instruct the editing device  to send the final edited document to the database server  via the network , along with a unique identifier for the transcriptionist.","With the data sent from the editing device , the database in the server  contains, for each dictation: a speaker identifier, a transcriptionist identifier, the digital audio signal, and the edited text document.","The edited text document can be transmitted directly to a customer's medical record system or accessed over the data network  from the database by the administrative console . The console  may include an administrative console software product such as Emon\u2122 made by eScription.","The raw and edited versions of a transcription may be used by the model builder\/modifier  to models for data extraction. The raw and edited versions of transcriptions associated with their respective speakers are stored in the database . The model builder\/modifier  uses the transcriptions for each speaker to build or modify models for the speaker (and\/or speaker and worktype) for extracting data from transcriptions. These models are stored in the database  so that they may be accessed and used by the automatic transcription device  to extract data from transcriptions.","Referring also to , the automatic transcription device  includes an ASR module , a memory , and a natural language processing module (NLP) . The NLP module  includes memory and a processor for reading software code stored in the memory and for executing instructions associated with this code for performing functions described below. The NLP module  is configured to analyze raw transcribed speech data from the automatic transcription device  to extract data elements from the transcribed text, and possibly use the extracted data to fill in a table or database fields. The memory  includes a raw\/modified text section , a table section , and a trigger section . The raw\/modified text section  includes the stored raw text of the speech-recognized transcription and the corresponding text as modified by the NLP module . The table section  includes stored tables that may be desired to be filled in with data extracted from various transcriptions. The trigger section  includes triggers corresponding to particular types of data desired to be extracted from the transcriptions in accordance with the tables stored in the table section . Trigger models may be built and\/or modified by the model builder\/modifier  ().","Referring to , an exemplary database  of tabular data stored in the tabular data fields section  of the database  () associated with corresponding transcriptions includes data sets  with dictation identifications  and several data fields, here data fields , , , , , . The dictation identification is uniquely associated with a corresponding dictation and the data fields are preferably in sets corresponding to the type of transcription, e.g., here being for medical record transcriptions. Thus, in this example, the database  includes data sets  each with data in an age data field , a gender data field , a date of birth (DOB) data field , a resting respiration data field , a resting pulse data field , and a resting blood pressure data field . The data fields , , , , ,  are searchable, e.g., using known database search techniques on the database . The data sets  each correspond to a separate transcription and the corresponding data fields are populated with the data extracted from the associated transcription. Information stored in the data fields , , , , ,  may be extracted from transcriptions and\/or entered independently (e.g., through the administration console  shown in ).","Referring again to , the NLP module  is configured to access a table to be filled in with data extracted from a transcription. For example, the NLP module  can access a particular table from the table section  in accordance with the worktype code entered by the speaker. Other techniques, however, may be used to determine which table to access to be filled in with data extracted from the transcription. For example, one or more tables may be associated with a particular speaker through the identification code, or tables may be accessed in accordance with a combination of identification code and worktype code, or worktype code alone, etc.","Fields of the table(s) accessed by the NLP module  are associated with corresponding \u201ctrigger\u201d phrases stored in the trigger section . A trigger phrase provides context for data and may include a single word or character (e.g., a symbol such as a number sign (#), the symbol for feet (\u2032), or the symbol for inches (\u2033)), multiple or characters, or combinations of one or more words and one or more characters. A trigger phrase indicates that the transcription likely contains desired data in the vicinity of the trigger phrase. The trigger phrases may be stored in sets that are associated with corresponding ones of the tables in the table section , or may be stored individually and associated with any table that includes a field corresponding with the particular trigger phrase, etc. The trigger phrases may be predictive, (e.g., \u201cthe blood pressure is _\u201d), retroactive (e.g.,  beats per minute\u201d), or both (e.g., \u201ctemperature is  degrees orally\u201d). Several passes can be made over the transcribed text by the NLP module  to refine the search for table data, especially if the NLP module  is operating as a background ASR, and is therefore not operating as a real-time interactive processing module. The NLP module  may assess the tabular data fields to be filled in or data otherwise to be extracted from the transcription based on various probabilities that the data corresponds to desired table or other data to be extracted, potentially both of the data field in question as well as other data fields.","The NLP module  may use the trigger phrases in a variety of manners in order to extract data from the transcription, preferably to help improve the accuracy with which data are extracted from the transcription. For example, the triggers may be probabilistically weighted based on various parameters such as speaker-specific or speaker-independent textual data. For example, a different trigger phrase may be associated with a number of different table items potentially, with different likelihoods associated with the different potential table items. The different probabilities associated with the different data items may be speaker independent or speaker dependent. For example, given the existence of a trigger phrase in the transcription of \u201cthe patient is,\u201d the subsequent data may be the age with 80% probability, or height with 15% probability, or appearance with 5% probability. These probabilities are exemplary, and may be different in practice, especially for different speakers. Further, the NLP module  may train trigger phrases using natural ASR raw data output so that the trigger phrases can incorporate or accommodate typical errors. Usually, such a trigger model would be a speaker-specific model. Additionally, the NLP module  may use a single trigger phrase to extract data for multiple data fields. For example, a medical care provider may dictate \u201cvital signs one hundred over sixty, eighty-two and regular.\u201d The NLP Module  may analyze the use of the trigger phrase \u201cvital signs\u201d as an indicator of both blood pressure and pulse.","The NLP module  is further configured to analyze the transcription in view of a content model to help modify transcribed text into common formats, taking account of different manners in which different speakers may say the same thing. The NLP  can thus make the format of various types of data be presented consistently despite inconsistent manners in which the data is spoken. For example, one speaker may say \u201cThe patient's temperature was one hundred and one point three degrees\u201d while another speaker may say \u201cThe patient's temperature was one oh one three.\u201d The data, the patient's temperature of 101.3\u00b0 F. is the same, but the text is different in these two examples. The NLP module  applying a content model built and\/or modified by the model builder\/modifier  can analyze these two different texts and modify the transcription to produce a consistent edited text, e.g., of 101.3\u00b0 F. Examples of different styles of speech for conveying similar information that the NLP module  can preferably make consistent are:","1) Body Temperature\n\n","2) Date\n\n","Content models provided by the model builder\/modifier  can be based on allowable grammars. Per-speaker probabilities can be assigned to \u201cpaths\u201d through a grammar based on how the speaker dictates each data type. The model builder\/modifier  can compute these probabilities and build\/modify the content models using these probabilities, preferably offline.","The NLP module  may also apply syntax constraints to the ASR output associated with particular types of data. Applying these constraints can help resolve ambiguity when the same trigger phrase is potentially used to indicate different types of data. For example, if a trigger phrase could be used to indicate either a pulse or a respiratory rate, then the NLP module  prefers pulse if the transcription contained a numeric quantity greater than 30 and a respiratory rate otherwise. Thus, the NLP module  applies constraints based on known characteristics and\/or likely values (e.g., ranges) of the various parameters or data types that the data may be in order to select which data type corresponds to particular data in a transcription. Further, the syntax constraints may lead to content models not employing non-absolute probabilities (i.e., probabilities greater than 0% and less than 100%) for some or all instances associated with the models. For example, to evaluate a transcription for a blood pressure value, if the transcription does not contain text in the form of a first number, followed by the word \u201cover,\u201d followed by a second number that is smaller than the first, then the model would not assign a value to a blood pressure variable. This may, however, be viewed as a 0% probability and thus an implementation of probabilities. If the first number \u201cover\u201d second number syntax is found, then the value for blood pressure would be hypothesized, with the probability of this being true being computed from the trigger model and order model (discussed below).","Further, the NLP module  is configured to use information about the subject of the transcription (e.g., a patient) available from the transcription or otherwise to constrain the search for given data types. For example, the transcription may indicate, or it may be otherwise known that (e.g., independently entered or determined that), the patient is a 47-year old male. In this case, certain values for the patient's weight and height would be deemed more likely to be correct if they comport with values for these data types typically associated with a 47-year old male. For example, a value of higher than 60 inches may be deemed to be more likely to be indicative of the patient's height and a value of 120 or more may be deemed to be more likely to be associated with the patient's weight. Additionally, the data search process performed by the NLP module  could be supplemented by providing access by the NLP module  to the patient's historical data from medical records, e.g., stored in the database . This information could be obtained either by having the speaker enter a patient-identifying code (such as the patient's medical record number (MRN)) with each dictation or by extracting this information from the spoken dictation, etc. Once the patient identification is obtained, the NLP module  may query the patient's historical medical data, and use this data to limit or constrain searches for valid content words (i.e., the words indicative of data values). For example, the search for blood pressure, cholesterol values, birth date, height, weight, etc. could benefit from constrained searches based upon information about the patient.","The NLP module  may further employ a model when analyzing the transcription in accordance with the order in which the speaker dictates the table fields and expected orders for such dictations. For example, the NLP module  may employ an n-gram formulation to analyze the n previous data fields that were extracted and determine a probability for the next data field being any of various potential data fields. Thus, the NLP module  employing a 3-gram formulation can determine the likelihood that the speaker is about to dictate the blood pressure field conditioned on the preceding two fields dictated being the patient's pulse and respiratory rate. This model may be deterministic and thus require a specific sequence of data fields or may be non-deterministic\/probabilistic, not requiring a particular sequence of data fields. Such a model assists the search by attributing a probability to each possible dictation sequence to increase the likelihood that particular data in the transcription is accurately extracted from the transcription, e.g., and stored in an appropriate data field and\/or table entry.","The model builder\/modifier  may produce custom trigger models for use in analyzing the transcription. For example, the database  may contain the history of text documents produced from the speaker's dictations, as well as the automatic transcriptions of the speaker's dictations provided by the automatic transcription device . The trigger phrases and content word syntax for each data type dictated by the speaker can be derived by correlating the final documents with the raw transcriptions, in effect reversing the decoding process to determine trigger phrases from the content words used by the speaker. The trigger models used by the NLP module  can be updated, e.g., periodically, as more dictations are gathered for the speaker over time. In this way, the models can track changes in the speaker's speaking style. The NLP module  preferably uses the updated model for the next transcription to be analyzed from the particular speaker. The NLP module , however, could re-evaluate a transcription from the speaker that was the last transcription analyzed before the trigger model was updated (e.g., the transcription that induced the update in the trigger model). Further, the model builder\/modifier  may weight more recent transcriptions from the speaker more heavily than earlier transcriptions to help account for changes in the speaker's style.","Further, the NLP module  may not fill all of the data fields desired to be extracted (e.g., associated with a particular table at issue), as the speaker may not dictate data corresponding to all of the data fields and\/or may not dictate the data with sufficient confidence that the NLP module  fills all the data fields. For example, the NLP module  may not fill a data field associated with a table if data from the transcription has an undesirably low probability of being associated with a particular data field. Thus, the NLP module  may leave the raw text of the transcription in tact and not fill a data field if the highest probability of data in the transcription being associated with that data field does not meet or exceed a threshold probability value. In this case, the \u201cfree text\u201d form of the transcription may be left alone such that the MT can choose to move data from the text into a particular data field (e.g., in a table) as appropriate. The NLP module  thus can provide a sparse data extraction process where the speaker may not dictate all desired data items or may not dictate all desired data items with sufficient confidence for the NLP module  to associate the dictated data with particular data fields.","Referring also to , the table structure may be encoded or stored as a combination of literal text and data-type tags, e.g., tags - as shown. The data-type tags - may be limited in any variety of manners, e.g., with underscores on either side of the tags - as shown in  to separate the tags - from the literal text.  illustrates a portion  of an exemplary encoded table and is not limiting of the invention.","The NLP module  attempts to replace all of the data-type tags - in the table portion  with appropriate data items extracted from the transcription. The NLP module  further attempts to exclude the raw text associated with these items from which the data for the corresponding data fields is drawn. The transcription is thus edited to remove the text indicative of the data, and the table portion  is updated with the data extracted from the raw text.","The table portion  illustrates the generality of potential table data fields. The table fields need not be restricted to numeric data. For example, descriptive data may be appropriate for some of the fields (e.g., the _s1_s2_STATUS field  may have a value of \u201cnormal\u201d). Other fields may be filled with other text including full paragraphs (e.g., the _CONCLUSION_field  may have a value of \u201cThis is a problematic test. The patient should be considered for cardiac angiography in the next few days.\u201d).","Referring to , with further reference to , a process  of performing sparse data extraction using system , and in particular the NLP module , includes the stages shown. The process , however, is exemplary only and not limiting. The process  can be altered, e.g., by having stages added, removed, or rearranged.","At stage , dictation is obtained and transcribed. The speaker  dictates text that is conveyed through the network  to, and stored in, the voice mailbox . The dictation is conveyed through the network , the database server , and the LAN  to the automatic transcription device . The device  transcribes the stored dictation and provides the transcribed text to the memory  where it is stored in the raw\/edited text section .","At stage , the NLP module  determines the desired data for extraction. For example, if the data to be extracted corresponds to a table, then the NLP module  accesses the appropriate table from the table section  of the database . The NLP module  accesses the appropriate table, e.g., by searching for a table corresponding to the worktype code and\/or the identification code entered by the speaker  or transcribed from the dictation from the speaker . The table that is accessed provides indicia of the data fields to be extracted from the transcription for filling in the table, with the data fields being associated with corresponding trigger phrases.","At stage , the NLP module  searches for triggers in the raw transcription corresponding to the data desired to be extracted and extracts the data. For each data type desired by the table, the raw text transcription is searched by the NLP module  for potential triggers, and the adjacent content words are assigned likelihoods for being one or more of the desired data fields based on the posterior trigger probability and the syntax likelihood of the content words. Multiple possible parses of the raw text transcription are scored and preferably the best fit between the table structure and the trigger and content words is found. For each data type accounted for in the best-fit parse, the corresponding table fields are filled in and the corresponding trigger and content words are removed from the raw text transcription. The best-fit may be a table-wide best fit, a partial-table best fit, or may be the best fit for each individual data field.","The following example is provided to illustrate multiple potential parses being applied to a portion of transcribed text for determining data fields. A portion of an exemplary raw text transcription may read:\n\n","Two exemplary potential parses for this transcription fragment are as follows:\n\n","In these parses, where a trigger phrase or data type is hypothesized, the underlying raw text words appearing in the transcription raw text (either the trigger phrase or content words) are subsumed, so that they do not appear in the document as hypothesized. Also, each trigger phrase and data type in the parses has an associated probability, so that standard search techniques, such as Viterbi decode, may be applied to the entire sequence to try to find the parse with the higher\/highest overall probability. If the first parse is chosen as the more likely parse by the search, then the corresponding section of the output might appear as follows:",{"@attributes":{"id":"p-0070","num":"0077"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"CARDIAC STRESS TEST REPORT"]},{"entry":[{},"Patient Age: 46 Patient Gender: _____ Patient DOB: _____ "]},{"entry":[{},"Time of Test: 11:00 a.m. Duration of Test: _____ "]},{"entry":[{},"Resting Pulse Rate: 87 Peak Pulse Rate: 145"]},{"entry":[{},"Resting Respirations: _____ Peak Respirations: --------- "]},{"entry":[{},"Resting Blood Pressure: 150\/85 Peak Blood Pressure: _____ "]},{"entry":[{},"S1\/S2: Normal.\u2003\u2003\u2003\u2003\u2003\u2003\u2003S3\/S4: _____ "]},{"entry":[{},"----------------------------------------------"]},{"entry":[{},"This is a cardiac stress test on John Doe which lasted 37 minutes."]},{"entry":[{},"Male."]},{"entry":[{},"I don't have the date of birth available at this time."]},{"entry":[{},"After twenty minutes,"]},{"entry":[{},"The other heart sounds were normal."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"The text below the dash line is fragmented because trigger phrases and content words have been removed. This text can be used by the transcriptionist to potentially ease the task of filling in any data fields not filled in automatically by the NLP module . Alternatively, the text below the dashed line could be deleted, with the MT filling in the remaining fields that have been dictated by the speaker using the audio played to the MT. Alternatively still, some of the text may be deleted while other portions of the text may be provided to the MT. For example, the phrase \u201cafter twenty minutes\u201d may possibly be removed as this text portion is a sentence fragment.","The draft transcription at this point is a modified (from the raw text), partially-structured, transcription ready for uploading. The modified transcription includes a structured document, to the extent it has been filled in by the NLP module , and the remaining raw text, to the extent that it has been deemed worth including in the draft. Subsequent formatting steps can be applied to the remaining raw text, that may include text that does not contribute to the structured part of the document. The draft in this stage is preferably uploaded to the database .","At stage , the draft transcription is edited by the medical transcriptionist. The MT retrieves the draft transcription stored in the database  via the network . The MT edits the draft transcription using the editing device . This editing includes modifying data that was extracted from the transcribed text, e.g., including modifying data entries for a table. Further, the editing may include adding information that was not extracted from the text, including adding data to the table where data was not dictated corresponding to one or more data fields.","At stage , the extracted and\/or edited and\/or added data is stored in the appropriate database fields. The extracted or otherwise provided data from the editing device  is stored in corresponding database fields in the tabular data field section  of the database . For example, age, gender, date of birth, resting respiration, resting pulse and\/or resting blood pressure is stored in the corresponding database fields , , , ,  in an appropriate entry  of the database . The database fields and the data in these fields may be accessed separately, including independently of the NLP Module .","At stage , trigger phrases are customized by the model builder\/modifier . The edited transcription can be compared by the NLP module  with the draft transcription provided by the NLP module  to determine whether data determined by the NLP module  corresponding with a particular data field was changed by the medical transcriptionist. Using this information, the NLP module  can modify the trigger phrases and\/or models used to associate the extracted data with the corresponding data fields. Thus, trigger phrases and\/or trigger models can be modified to accommodate changes in style of speakers and\/or trigger phrases used by the speaker, or multiple speakers associated with a common entity, etc. The NLP module  would then apply the modified trigger phrases and\/or trigger models and\/or other models provided\/modified by the model builder\/modifier  (or otherwise provided, e.g., stored in the memory ) to future analyses of transcriptions to perform sparse data extraction on the transcriptions.","The process  can be modified and, as such, the process illustrated in  as described above is illustrative only. For example, the extracted data may be stored before the transcription is edited by the medical transcriptionist and the data modified, if at all, by the medical transcriptionist and re-stored subsequent to the transcription editing.","Referring to  and with further reference to , process  of searching for data associated with desired data types using the system  includes the stages shown. The process , however, is exemplary only in not limiting. The process  can be altered, e.g, by having stages added, removed or rearranged.","At stage , a request for a data search is received. A user can enter a data search request through the administration console . For example, a healthcare provider might use a software application that queries the database  for all of the patient's peak pulse values for cardiac stress tests taken over a period of time. Alternatively, healthcare researchers may ask for the blood pressure values of numerous patients so that the researcher might judge the efficacy of a certain treatment regimen. The data request is forwarded through the network  to the database server  to be performed on the information stored on the database .","At stage , an inquiry is made as to whether data of the data types to be searched for are stored in separate data fields separate from transcriptions stored in the database . In particular, the database server  can determine whether database fields corresponding to the data types to be searched are stored in the database . If not, then the process  proceeds to stage  described below and otherwise proceeds to stage .","At stage , the database server  searches the stored database fields for data corresponding to the search request. The server  searches through stored data, e.g, the database  for data corresponding to data types indicated by the search request. For example, the server  may search for data corresponding to age, gender, and blood pressure corresponding to specific worktype codes entered or otherwise provided by the speaker when producing the dictation leading to a transcription.","At stage , the database server  searches stored transcriptions for the desired data corresponding to the indicated data type to be searched. The database server  may search the stored transcriptions as edited by a medical transcriptionist using the editing device . In this case, the server may employ the NLP module  to search through the stored transcriptions using appropriate trigger phrases and\/or trigger models. The transcriptions are normalized by having portions formatted in structured tables, although the tables may differ. In this case, the trigger phrases and\/or trigger models may be adapted to a search for text associated with structured tables of data, with the text associated with the structured tables potentially being different than trigger phrases that may be used in transcription. For example, in dictations, the speaker may say something like, \u201cThe patient is a 47-year-old male.\u201d The trigger phrase searched for in raw text may be a phrase such as \u201cthe patient is a,\u201d because this is a typical spoken lead-in to an age description, while a trigger phrase for searching in a normalized transcription may be more succinct, such as \u201cage\u201d or \u201cgender\u201d or \u201csex\u201d as these are more likely to appear in a table.","Other embodiments are within the scope and spirit of the appended claims. For example, due to the nature of software, functions described above can be implemented using software, hardware, firmware, hardwiring, or combinations of any of these. Features implementing functions may also be physically located at various positions, including being distributed such that portions of functions are implemented at different physical locations. For example, the NLP module  may be disposed wholly or partially elsewhere (i.e., other than at the automatic transcription device ), such as at the database server .","In other embodiments, for example, the NLP processing may take place after the MT has edited the original raw text transcription produced by the ASR device . Thus, referring to , the editing stage  may be performed before the NLP processing stage . In this instance, the MT may make no attempt to fill in the table format. This table may not be available to the MT at all. Instead, the MT corrects the raw speech recognition as usual and instructs the edited transcription to be stored. The stored edited transcription is analyzed by the NLP module  to perform the NLP processing stage . The trigger phrase and content models may be much more restrictive than in cases where the raw text is used as an input since the edited text is presumably more error free than the raw text transcription.","In other embodiments, a combination of techniques discussed above can be used. For example, a process may proceed according to stages ,  and  shown in . In the editing stage, however, the medical transcriptionist may correct speech recognition and formatting errors but not move data into table fields or edit the tables fields and may not delete any of the transcribed text. The NLP module  may be applied to analyze the edited transcription with the further constraint that already filled-in table fields should not be located. Thus, the NLP module  would search over the remaining, non-table raw text for a subset of the original table fields that were neither filled in by the original analysis by the NLP module  nor filled in during the editing performed by the medical transcriptionist.","While the description above focused on medical transcriptions, the invention is not limited to medical transcriptions. The invention may be applied to data extraction for non-medical applications such as legal dictations (e.g., for billing), student evaluations (e.g., situations involving ratings and\/or test scores including psychological evaluations), etc.","Further, while the discussion above refers to \u201cthe invention,\u201d more than one invention may be disclosed."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE FIGURES","p":[{"@attributes":{"id":"p-0024","num":"0024"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0025","num":"0025"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0026","num":"0026"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0027","num":"0027"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0028","num":"0028"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0029","num":"0029"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
