---
title: Mapping visual display screen to portable touch screen
abstract: A content player transmits a screen image to a display. The screen image includes an active region, which may be a portion that may be manipulated. The player determines active region information for the active region and transmits such to a portable device. The portable device receives the active region information as well as information regarding any inactive regions, which may be portions that may not be manipulated. The portable device utilizes the information to present a simulated version of the screen image on a touch screen. The portable device may then receive manipulation information via the touch screen and transmit such to the player. In response, the player may generate and present an updated version of the screen image, determine updated information, and transmit such to the portable device. The portable device may utilize the updated information to present a simulated updated version of the screen image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09525905&OS=09525905&RS=09525905
owner: Echostar UK Holdings Limited
number: 09525905
owner_city: Milton Keynes
owner_country: GB
publication_date: 20111214
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","SUMMARY","DETAILED DESCRIPTION OF THE EMBODIMENTS"],"p":["This disclosure relates generally to touch screen interfaces, and more specifically to mapping visual display screens to touch screens.","The present disclosure discloses systems and methods for mapping visual display screens to touch screens. A content player may present a screen image including one or more active regions by transmitting the screen image to an associated display device. Active regions may be portions of the screen image that are operable to be manipulated by a user. The content player may determine active region information for the active region, which may include position information, color information, interactive information, and other such information regarding the active region. The content player may then transmit such information to a portable touch screen device.","The portable touch screen device may receive the active region information from the content player as well as information regarding one or more inactive regions. Inactive regions may be portions of the screen image that may not be manipulated by a user. The portable touch screen device may utilize the information for active and\/or inactive regions to present a simulated version of the screen image on one or more touch screens of the portable touch screen device.","Subsequently, the portable touch screen device may receive manipulation information for one or more of the active regions via the touch screen. The portable touch screen device may transmit such information to the content player. In response, the content player may generate and present an updated version of the screen image via the associated display device. The content player may also determine updated active region information based on the manipulation information and transmit such updated information to the portable touch screen device, which may utilize the updated information to present a simulated updated version of the screen image on the touch screen.","In some implementations, the information regarding the active and\/or inactive regions and\/or update information may fully describe how to present such regions. In other implementations, one or more screen templates may be modified to generate active and\/or inactive regions and\/or update such regions and the information and\/or update information may specify the screen template utilized and indicate modifications. In still other implementations, the information regarding the active and\/or inactive regions may fully describe how to present such regions whereas update information may only include information regarding changes. In yet other implementations, one or more screen templates may be modified to generate active and\/or inactive regions, information regarding such regions may specify the screen template utilized and indicate modifications, and update information may include only information regarding changes.","In various implementations, active regions and\/or inactive regions may be generated by one or more software applications being executed by the content player. The software application may generate the region by calling one or more graphical APIs (application programming interfaces) provided by one or more operating systems of the content player and the graphical API may generate the region. As part of generating the region, the graphical API may be also be configured to provide information regarding the region. The content player may then determine the information for that region by receiving the information for that region from the graphical API and may combine such information with information regarding other regions before transmitting the combined information to the portable touch screen device.","In one or more implementations, the simulated version of the screen image may not be precisely identical to the screen image. In some cases, the simulated version of the screen image may differ dimensionally from the screen image. In other cases, the simulated version of the screen image may include less information and\/or detail than the actual screen image. Regardless, the simulated version of the screen image may resemble the actual screen image enough that users may visually understand the mapping relationship between the two images.","It is to be understood that both the foregoing general description and the following detailed description are for purposes of example and explanation and do not necessarily limit the present disclosure. The accompanying drawings, which are incorporated in and constitute a part of the specification, illustrate subject matter of the disclosure. Together, the descriptions and the drawings serve to explain the principles of the disclosure.","The description that follows includes sample systems, methods, and computer program products that embody various elements of the present disclosure. However, it should be understood that the described disclosure may be practiced in a variety of forms in addition to those described herein.","Content players (such as set top boxes, television receivers, digital video recorders, television tuners, digital music players, desktop computers, laptop computers, cellular telephones, smart phones, mobile computing devices, and so on) may present content via one or more presentation devices (such as computer monitors, televisions, cathode ray tube displays, liquid crystal displays, speakers, printers, and\/or other such devices for presenting content). The content that such content players may present may be stored by the content player and\/or may be received from one or more content providers (such as one or more television programming providers, video on demand providers, pay per view movie providers, digital music providers, and so on) via one or more communication links (such as one or more satellite communication links, coaxial cable communication links, WiFi communication links, Internet protocol communication links, and so on). The operations of such content players may be controlled via one or more control interfaces which may be separate from the content player (such as one or more keyboards, mice, remote control devices, and\/or other selection devices) and\/or integrated into the content player (such as one or more buttons, keys, and\/or other selection elements).","As content players incorporate increasingly complex functions, such as Internet browsing, traditional remote control devices become increasingly difficult and complex for users to utilize in directing the operations of the content player. Other traditional control interfaces, such as keyboards or mice, provide more intuitive options for users to control content players, but even such traditional control interfaces may be increasingly difficult and complex for users to utilize as content players perform increasingly complex functions. Further, control interfaces such as remotes, keyboards, and mice may not be as intuitive for users when interfacing with the increasingly graphical interactive user interfaces that may be provided by content players.","Touch screen interfaces may enable users to more intuitively interact with such interactive displays. As users may directly touch and manipulate the interactive user interface displayed by the screen, users may not have to perform the additional mental processing inherent in translating between selection elements of a control interface and the displayed interactive user interface. This may result in less user confusion than other control interfaces and may generally improve the user's experience in utilizing the content player.","However, many content players display such interactive user interfaces on displays which are not located within reach of a user. For example, set top boxes, television receivers, digital video recorders, television tuners, and\/or other content players may display interactive user interfaces on display devices that may be typically located several feet or more away from a user when utilized. In such cases, even if one or more display screens of such display devices are configured as touch screens, users may not be able to utilize the touch screen without physically approaching the display device every time they wish to control the content player. In order to allow users to control content players in such situations without having to physically move to the display device, non-touch screen control interfaces such as remote controls, keyboards, mice, and so on may be utilized. As such, the intuitive features of displaying the interactive user interfaces via a touch screen may be lost.","The present disclosure discloses systems and methods for mapping visual display screens to touch screens. A content player may present a screen image that includes one or more active regions (portions of the screen image that are operable to be manipulated by a user) by transmitting the screen image to an associated display device. The content player may determine active region information for the active region, which may include position information, color information, interactive information (i.e., ways that a user may manipulate the active region), and other such information regarding the active region. The content player may then transmit such information to a portable touch screen device. The portable touch screen device may receive the active region information from the content player (as well as information regarding one or more inactive regions, or regions that may not be manipulated by a user) and utilize such information to present a simulated version of the screen image on one or more touch screens of the portable touch screen device.","Subsequently, the portable touch screen device may receive manipulation information for the active region (i.e., one or more actions that a user has performed on the active region) via the touch screen. The portable touch screen device may transmit such information to the content player and, in response, the content player may generate and present an updated version of the screen image via the associated display device. The content player may also determine updated active region information based on the manipulation information and transmit such updated information to the portable touch screen device. Upon receiving such updated information, the portable touch screen device may utilize the updated information to present a simulated updated version of the screen image on the touch screen.","In this way, interactive user interfaces displayed via the associated display device may be mapped to the touch screen of the portable touch screen device. Though users may not be located within sufficient proximity to touch the associated display device, as the simulated screen image approximates the screen image (though it may not be precisely identical), the users may still be able to interact with any displayed interactive user interfaces without having perform the additional mental processing inherent in translating between selection elements of a control interface and the displayed interactive user interface. As such, controlling the content player may be more intuitive for users than other control interfaces.",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1","b":["100","100","101","102","103","103"]},"The content player  may include one or more processing units , one or more non-transitory storage media  (which may take the form of, but is not limited to, a magnetic storage medium; optical storage medium; magneto-optical storage medium; read only memory; random access memory; erasable programmable memory; flash memory; and so on), one or more communication components , and\/or one or more output components . The processing unit  may execute instructions stored in the non-transitory storage medium  to present content on the presentation device  utilizing the output component.","The processing unit  may also execute instructions stored in the non-transitory storage medium  to present one or more screen images including one or more active regions on the presentation device  via the output component . When presenting such a screen image, the processing unit  may determine information for one or more active regions and\/or inactive regions (which may themselves each include one or more active or inactive sub regions) included in the screen image. A region may be an active region if is configured to be manipulated by a user and may be an inactive region if it is configured to not be manipulated by a user. Such information may include position information (such as absolute dimensions and\/or position coordinates in the screen image, dimensions and\/or position coordinates relative to other portions of the screen image and\/or the screen image itself, center point and\/or absolute radius\/diameter information, center point and\/or radius\/diameter information relative to other portions of the screen image and\/or the screen image itself, and\/or any other information specifying dimensions and\/or position of the region), color information (such as hue information for one or more portions of the region, brightness information for one or more portions of the region, saturation information for one or more portions of the region, and\/or any other information specifying one or more color aspects of one or more potions of the region), interaction information (such as whether the region may be selected, selected and dragged, expanded, resized, deleted, accept text input via a presented virtual keyboard, and\/or any other action that may be performed and\/or not performed in relation to the region), and\/or any other such information regarding the active and\/or inactive regions. The processing unit  may transmit such information to the portable touch screen device  via the communication component .","The portable touch screen device  may include one or more processing units , one or more non-transitory storage media , one or more communication components , and\/or one or more touch screens . The processing unit  may receive the information regarding one or more active regions and\/or inactive regions via the communication component  and execute instructions stored in the non-transitory storage medium  to present a simulated version of the screen image displayed on the presentation device  via the touch screen  utilizing the received positional information, color information, interaction information, or other such information.","In some cases, the information regarding one or more active regions and\/or inactive regions may fully describe how to present the simulated version of the screen image. In other cases, the screen image may be created by modifying one or more screen templates stored in the non-transitory medium . As such, the information may specify the screen template utilized and any modifications performed. In still other cases a combination of these approaches may be utilized.","Such a simulated version of the screen image may not be precisely identical to the screen image. By way of a first example, the dimensions of the touch screen  may not be the same as the presentation device . As such, the dimensions of the active and\/or inactive regions included in the simulated version of the screen image may differ from the actual screen image. By way of another example, active and\/or inactive regions included in the simulated version of the screen image may include less information and\/or detail (whether in arrangement, color, and\/or other such information and\/or detail) than the actual screen image. However, even though the simulated version of the screen image may not be precisely identical to the actual screen image, the simulated version of the screen image may resemble the actual screen image enough that users may visually understand the mapping relationship between the two images.","The processing unit  of the portable touch screen device  may also execute instructions stored in the non-transitory storage medium  to receive manipulation information regarding one or more of the active regions (such as whether a region is selected, selected and dragged, expanded, resized, deleted, receives text input via a presented virtual keyboard, and\/or any other action that is performed in relation to the region) via the touch screen . Such information may be received as a result of one or more users manipulating one or more of the active regions included in the simulated version of the screen image displayed by the touch screen . When receiving such manipulation information, the processing unit  may restrict manipulation that is received to manipulations that comply with interaction information received from content player  specifying how the respective region can be manipulated. The processing unit  may transmit such manipulation information to the content player  via the communication component .","The processing unit  of the content player  may receive the manipulation information via the communication component , utilize such information to generate an updated version of the screen image, and present the updated screen image on the presentation device  via the output component . The processing unit  may also determine updated information for one or more active and\/or inactive regions included (and\/or not included if the manipulation information corresponds to removal of the respective region) in the updated screen image and transmit such updated information to the portable touch screen device  via the communication component . Additionally, the processing unit  may perform one or more content player  operations in response to the manipulation information such as presenting content, switching content that is presented, and\/or any other operation that the content player  is configured to perform as controlled by the portable touch screen device .","The processing unit  of the portable touch screen device  may receive such update information via the communication component  and may utilize such to present a simulated updated version of the screen image on the touch screen . In some cases, such update information may fully describe how to present the simulated updated version of the screen image. In other cases, such update information may only specify changes from the simulated version of the screen image. In still other cases a combination of these approaches may be utilized.","Although the above discusses updating the screen image and the corresponding simulated screen image, in some cases processing unit  of the content player  may generate one or more additional screen images in response to the manipulation information that may be unrelated to the original screen image (i.e., display a different screen). As such, the updated screen image may be a completely different screen image. Further, although the above describes a single round of presentation of a screen image, manipulation, and updating of the screen image, multiple iterations of such operations may be performed without departing from the scope of the present disclosure.",{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 2","FIG. 1"],"b":["200","200","101","201","202","203","104","104","204","202","101"]},"At block , after the processing unit  determines to generate a screen image, the processing unit  generates the screen image. The screen image may include one or more active regions and\/or one or more inactive regions (which may themselves include one or more active or inactive sub regions). The flow then proceeds to block  where the processing unit  determines information for one or more active regions and\/or inactive regions included in the screen image. Next, the flow proceeds to block  where the processing unit  transmits the screen image to the presentation device  via the output component . The flow then proceeds to block  where the processing unit  transmits the information regarding the active and\/or inactive regions to the portable touch screen device  via the communication component .","Next, the flow proceeds to block  where the processing unit  determines whether or not manipulation information for the screen image is received from the portable touch screen device  via the communication component . If so, the flow proceeds to block . Otherwise, the flow proceeds to block .","At block , after the processing unit  determines that manipulation information is received, the processing unit  updates the screen image utilizing the manipulation information. The flow then proceeds to block  where the processing unit  determines update information for the screen image based at least one the manipulation information. Next, the flow proceeds to block  where the processing unit  transmits the updated screen image to the presentation device  via the output component . The flow then proceeds to block  where the processing unit  transmits the update information to the portable touch screen device  via the communication component  before the flow returns to block  and the processing unit  determines whether or not additional manipulation information for the updated screen image is received.","At block , after the processing unit  determines that manipulation information is not received, the processing unit  determines whether or not to generate a new screen image. The processing unit  may determine to generate the new screen image as part of performing other operations and\/or in response to received input. If so, the flow returns to block  where the processing unit  generates the new screen image. Otherwise, the flow returns to block  where the content player  continues to operate.","Although the method  is illustrated and described above as including particular operations configured in a particular arrangement, other arrangements of different operations are possible without departing from the scope of the present disclosure. For example, the method  describes transmitting the screen image to the presentation device before transmitting the information regarding the active and\/or inactive regions to the portable touch screen device . However, in other implementations such operations may be performed in a reverse order and\/or simultaneously.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 3","FIG. 1"],"b":["300","300","102","301","302","102","303","108","304","302","102"]},"At block , after the processing unit  determines whether or not information for active and\/or inactive regions of a screen image is received, the processing unit  utilizes the information to present a simulated version of the screen image via the touch screen  before the flow proceeds to block .","At block  the processing unit  determines whether or not manipulation information for one or more of the active regions of the simulated version of the screen image is received via the touch screen . If so, the flow proceeds to block . Otherwise, the flow returns to block  where the processing unit determines whether or not information for active and\/or inactive regions of another screen image is received.","At block , after the processing unit  determines manipulation information is received, the processing unit  transmits the manipulation information to the content player  via the communication component  and the flow proceeds to block . At block , the processing unit  receives update information from the content player  via the communication component . Next, the flow proceeds to block  where the processing unit  utilizes the update information to present a simulated updated version of the screen image via the touch screen .","The flow then returns to block  where the processing unit  determines whether or not manipulation information for one or more of the active regions of the simulated updated version of the screen image is received via the touch screen .","Although the method  is illustrated and described above as including particular operations configured in a particular arrangement, other arrangements of different operations are possible without departing from the scope of the present disclosure. For example, the method  describes receiving update information after transmitting manipulation information. However, in other implementations, update information may not be received after transmitting manipulation information and the processing unit  may respond by retransmitting the manipulation information.","Returning to , in some implementations, one or more active regions and\/or inactive regions generated by the processing unit  as part of generating a screen image may be generated by one or more software applications (such as one or more social networking applications, Internet browser applications, office applications, and\/or any other software application) being executed by the processing unit . The software application may generate the region by calling one or more graphical APIs provided by one or more operating systems being executed by the processing unit . The graphical API may then generate the region according to the call from the software application.","As part of generating the region, the graphical API may be also be configured to transmit information regarding the region (such as positional information of the region and\/or sub regions, color information for the region and\/or sub regions, interaction information for the region and\/or sub regions) to the processing unit . The processing unit  may then determine the information for that region by receiving the information for that region from the graphical API and may combine such information received from the graphical API with information regarding other regions before transmitting the combined information to the portable touch screen device via the communication component .",{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIGS. 4A-4C","FIG. 1","FIG. 4A"],"b":["403","400","404","404","405","405","401","404","1","406","2","407","3","408","1","2","3"],"i":["a","c ","a","c","a "]},"The television  may generate information for active regions and\/inactive regions in the interactive menu . In this example, the screen elements - for the three movies are active elements and the portion of the screen around the screen elements - for the three movies is an inactive region. The television  may generate positional information and color information for the active and inactive information as well as interaction information for the active regions (i.e., how the screen elements - for the three movies can be manipulated to reorder the download queue). The television  may transmit this information to a tablet computing device  being utilized by the user , as illustrated in .","As illustrated in , the tablet computing device  utilizes the information to present a simulated version of the interactive menu that includes screen elements  (corresponding to screen element  of the interactive menu ),  (corresponding to screen element  of the interactive menu ), and  (corresponding to screen element  of the interactive menu ). In this example, the simulated version of the interactive menu does not precisely mirror the interactive menu . Instead, the simulated version of the interactive menu is a simplified version of the interactive menu where text information included in the interactive menu has been omitted. However, the simulated version of the interactive menu may resemble the interactive menu closely enough that the user  may mentally treat the simulated version of the interactive menu as if it were the interactive menu ","In this example, the user  may utilize the touch screen of the tablet computing device  to manipulate the screen elements - of the simulated version of the interactive menu by touching the touch screen in order to reorder the download queue. The user  may touch and drag the screen element  to movie it above the screen element . The tablet computing device  may receive this manipulation information and transmit such to the television . As illustrated in , in response the television  may reorder the download queue accordingly, update the interactive menu , and transmit corresponding update information to the mobile computing device  which may then present the simulated version of the interactive menu ","As shown in , the screen element  corresponding to Movie  is now at the top of the download queue in the interactive menu , followed by the screen element  corresponding to Movie  and the screen element  corresponding to movie . Further, the screen element  of the simulated version of the interactive menu , the screen element  of the simulated version of the interactive menu , and the screen element  of the simulated version of the interactive menu are rearranged similarly to their respective corresponding screen elements - of the interactive menu . As such, the television  may download Movie  first, then Movie , and then Movie .","In the present disclosure, the methods disclosed may be implemented as sets of instructions or software readable by a device. Further, it is understood that the specific order or hierarchy of steps in the methods disclosed are examples of sample approaches. In other embodiments, the specific order or hierarchy of steps in the method can be rearranged while remaining within the disclosed subject matter. The accompanying method claims present elements of the various steps in a sample order, and are not necessarily meant to be limited to the specific order or hierarchy presented.","The described disclosure may be provided as a computer program product, or software, that may include a non-transitory machine-readable medium having stored thereon instructions, which may be used to program a computer system (or other electronic devices) to perform a process according to the present disclosure. A non-transitory machine-readable medium includes any mechanism for storing information in a form (e.g., software, processing application) readable by a machine (e.g., a computer). The non-transitory machine-readable medium may take the form of, but is not limited to, a magnetic storage medium (e.g., floppy diskette, video cassette, and so on); optical storage medium (e.g., CD-ROM); magneto-optical storage medium; read only memory (ROM); random access memory (RAM); erasable programmable memory (e.g., EPROM and EEPROM); flash memory; and so on.","It is believed that the present disclosure and many of its attendant advantages will be understood by the foregoing description, and it will be apparent that various changes may be made in the form, construction and arrangement of the components without departing from the disclosed subject matter or without sacrificing all of its material advantages. The form described is merely explanatory, and it is the intention of the following claims to encompass and include such changes.","While the present disclosure has been described with reference to various embodiments, it will be understood that these embodiments are illustrative and that the scope of the disclosure is not limited to them. Many variations, modifications, additions, and improvements are possible. More generally, embodiments in accordance with the present disclosure have been described in the context or particular embodiments. Functionality may be separated or combined in blocks differently in various embodiments of the disclosure or described with different terminology. These and other variations, modifications, additions, and improvements may fall within the scope of the disclosure as defined in the claims that follow."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIGS. 4A-4C","FIG. 1"]}]},"DETDESC":[{},{}]}
