---
title: Systems and methods to build and utilize a search infrastructure
abstract: Methods and systems to build and utilize a search infrastructure are described. The system generates index information components in real-time based on a database that is time-stamped. The system updates index information at a plurality of query node servers based on the index information components. A query engine receives a search query from a client machine and identifies search results based on the query and the index information. The system communicates the search results, over the network, to the client machine.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09607049&OS=09607049&RS=09607049
owner: eBay Inc.
number: 09607049
owner_city: San Jose
owner_country: US
publication_date: 20121228
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","RELATED ART","DETAILED DESCRIPTION"],"p":["This application claims priority to U.S. Provisional Application No. 61\/675,793, filed on Jul. 25, 2012, and entitled, \u201cSYSTEMS AND METHODS TO BUILD AND UTILIZE A SEARCH INFRASTRUCTURE,\u201d which is hereby incorporated by reference in its entirety.","This disclosure relates to the technical field of data storage and retrieval. More particularly, systems and methods to build and utilize a search infrastructure.","A search infrastructure supports the storage of data items in one or more databases and the retrieval of the data items from the one or more databases. Building and utilizing the search infrastructure may present many technical challenges. In particular the performance, manageability, and quality of service in storing and retrieving the data items may present many opportunities for innovation.","In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of some example embodiments. It will be evident, however, to one of ordinary skill in the art that embodiments of the present disclosure may be practiced without these specific details.","As described further below, according to various example embodiments of the disclosed subject matter described and claimed herein, systems and methods to build and utilize a search infrastructure are provided. Various embodiments are described below in connection with the figures provided herein.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 1","b":["10","10","11","12","33"]},"Illustrated on the top left is an operation A that describes a first user operating the client machine  to interact with an application server  to store or update a document  in a database ; illustrated in the middle are operations B, C, D, E that describe retrieving and transforming the contents of the database , storing the transformed contents in a database  that is time-stamped, retrieving the contents from the database  to generate a full-index  and a set of mini-indexes  which are utilized to generate and continually update the index information  in the database  to be consumed and served by the query node servers ; and illustrated on the top right is an operation F that describes a second user who operates a client machine  to enter a query that is received by one or more query node servers  that, in turn, apply the query to the index information  to identify and return search results that reference the document . The above operations to continually rebuild the index information  are performed in real-time and without interruption to service that is provided to the first and second users who continue to interact with the system .","The index information  may include an inverted index  and document information . An inverted index (e.g., inverted index ), as is well known in the art, is an index data structure storing a mapping from content (e.g., content contained by the document ), such as words or numbers, to its locations in a database file, or in a document (e.g., document ) or a set of documents. The documents  (e.g., document data, column group data) and\/or information contained by the documents  may be stored in the document information .","Merely for example a \u201cdocument X\u201d may include the words \u201capple,\u201d \u201corange,\u201d and \u201cbanana;\u201d a \u201cdocument Y\u201d may include the words \u201capple\u201d and \u201corange; and, a \u201cdocument Z\u201d may include the word \u201capple.\u201d An inverted index for the words in documents X, Y, and Z may be generated as follows:",{"@attributes":{"id":"p-0044","num":"0043"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Word","Document"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"apple","X(1), Y(1), Z(1)"]},{"entry":[{},"orange","X(2), Y(2)"]},{"entry":[{},"banana","X(3)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"The above inverted index may be utilized to identify the word \u201capple\u201d as being positioned in the first word of documents X, Y, and Z; the word \u201corange\u201d as being positioned in the second word of the documents X and Y; and the word \u201cbanana\u201d as being positioned as the third word of the document X. Accordingly, the above inverted index may be utilized to map a keyword \u201capple\u201d contained in a query that is received from a client computer to the documents X, Y, and Z that are further referenced in search results that are returned to the client computer. It is appreciated by one skilled in the art that the inverted index  corresponds to the underlying database that it describes. Accordingly, any update to the underlying database is reflected in a corresponding update to the inverted index . Updates to the database  may include the addition and deletion of documents  in the document information  as well as the update of any of the contents contained by the documents  in the document information . In the present embodiment, the index information  may be updated in real time to respond to a query in real time with accurate search results that include the most recent document information . To this end, the operations A-F are now further described.","The information storage and retrieval platform  includes multiple components including the application servers  that may execute on one or more application server machines (not shown), the database , a database , an Hadoop distributed file system , the database , the query node servers  that operate on query node server machines (not shown), an HBase\/Hadoop Cluster  comprised of one or more HBase\/Hadoop machines (not shown) including an HBase Hadoop Node  (e.g, HBase\/Hadoop machine), an index distribution module  executing on HBase\/Hadoop machine, search front-end servers  that executes on search machines (not shown), and search back-end servers  that execute on search machines (not shown) as being communicatively coupled together. For example, the multiple components may be communicatively coupled with any combination of a wide area network, local area network, wireless network, or any other type of network utilizing various networking technologies.","At operation A, the document , or one or more elements of the document , may be communicated from the client machine  to the application servers  and stored in the database  (e.g., Oracle database). The document  may include multiple elements including elements a, b, c, d, e, and f that may include strings of text, numeric information, scores, or other discrete quantum of information that are positioned in different sections or fields of the document (e.g., item information).","At operation B, at the application servers , event manager modules  may identify updates to the database , generate events that correspond to the respective updates, prioritize the events according to the quality of the data in the event and communicate the prioritized events into event queues  that are consumed by consumer modules  that service the respective event queues . According to an embodiment, the event manager modules  and the consumer modules  may utilize three event queues  to process and prioritize event types. For example, the update of the \u201celement a\u201d in the document  in the database  may be a price change to item information describing an item for sale that causes the generation of a corresponding event that is associated with a high priority that, in turn, is communicated into in a first event queue associated with high priority that, in turn, is received by a consumer module . Similarly, the update of the \u201celement b\u201d in document  in the database  may be a change to a title of the item that causes the generation of an event that is associated with a medium priority that, in turn, is communicated into a second event queue associated with the medium priority that, in turn, is received by a consumer module . Finally, the update of the \u201celement c\u201d in document  in the database  may be a change to a description of the item that causes the generation of an event that is communicated into a third event queue associated with a low priority that, in turn, is received by a consumer module . Accordingly, the three event queues  may be utilized to communicate events in high, medium, and low priorities to facilitate a preference for the update of high priority events (e.g., price) over medium priority events (e.g., title) over low priority events (e.g. description). In some embodiments the priority for the respective event types may be configured. Other embodiments may include fewer or more event queues .","At operation C, the consumer modules  may transform the data in the events and communicate the transformed data via an HBase application programming interface to an HBase master server  in an HBase\/Hadoop cluster  that, in turn, stores the transformed data in one or more tables including an items table  in the database  (e.g., HBase). The transformed data may be stored according to regions that are managed by region server processes . According to an embodiment, the database  may be embodied as an open source non-relational, distributed database (e.g., HBase) that runs on a Hadoop Distributed Filesystem (HDFS) . HDFS  is an open source software framework that supports data-intensive distributed applications, known by those skilled in the art. The HBase\/Hadoop cluster  may further includes the HBase master server  that is utilized to manage the HBase\/HDFS environment, a scheduler module , and an HBase\/Hadoop node  that includes multiple region server processes  and a map-reduce job module . Each region server process  may further be associated with a column (not shown) that corresponds to a range of documents (e.g., or items corresponding to item information in the items table ) and may be utilized to manage one or more regions (not shown) that respectively correspond to a range of the documents . For example, the documents  may be uniquely identified with document identifiers (e.g., item identifiers) that are numbered from  to X where each column and region are dedicated to respective overlapping predetermined ranges of documents (e.g., documents (- and documents (-), as described further in this document. According to one embodiment, the number of region server processes  may be in the hundreds but scaling is not limited to any fixed number. HBase is a technology that provides a fault-tolerant way of storing large quantities of sparse data featuring compression, in-memory operation, and a space-efficient probabilistic data structure (e.g., Bloom filters) on a per-column basis as outlined in the original BigTable paper, as is known by those skilled in the art. An items table  in the database  (e.g. HBase) may serve as the input and output for one or more map-reduce jobs that are scheduled by the map-reduce job module . The map-reduce jobs may be embodied as a map jobs and reduce jobs that runs in HDFS. The items table  in the database  may further be accessed through the Java Application Programming Interface (API) but also through representational state transfer (REST) architecture and other APIs.","At operation D, the scheduler module , executing in the HBase\/Hadoop cluster , may schedule two index generating sub-operations that process in parallel to generate indexes that are subsequently distributed to the query node servers . The sub-operations may execute for the generating of a full-index  and the generating of the mini-indexes . The sub-operations may further execute for the distribution of the indexes to the query node servers . The full-index  may be a snapshot of the contents of items table  in the database  and the mini-indexes  may respectively correspond to a series of consecutive snapshots where each snapshot captures one or more updates to the items table  in the database  that occurred within an associated time period of time. The distribution of the full-indexes  and the mini-indexes  to the query node servers  may be over a network utilizing an index distribution module  based on Bit Torrent, a peer to peer file sharing protocol. In one embodiment, the scheduler module  may schedule the generation of the full-index  twice in a twenty-four hour period and the generation of mini-indexes  every five minutes. The scheduler module  may generate a full-index  that is associated with a start-time by scheduling a map-reduce job module . The map-reduce job module  may initiate a map step that divides the job into smaller sub-jobs (e.g., map tasks) and multiple reduce steps that consume the output from the sub-jobs and aggregates results to generate the index information . Similarly, the scheduler module  may generate a mini-index  by scheduling a map-reduce job module  for execution on the HBase\/Hadoop Node . The generation of the mini-index  may include a map step but not, according to one embodiment, a reduce step. Accordingly, each mini-index  may be associated with events that arrive from the event queues  during a particular period of time and is associated with one or more full-indexes . Each index ,  (e.g., full and mini) may include a bill of material (BOM) information which describes the content of the index ,  including the index information . The full-index  may include full-index BOM information  and the mini-index  may include mini-index BOM information . The index information  may include the inverted index  and document information , as previously described.","At operation E, each of the query node servers  may receive the full-index  and the associated mini-indexes . The query node servers  may be comprised of a search grid that is arranged in columns of query node servers , as described later in this document. Each column of query node servers  may be utilized to manage a range of the documents , as previously mentioned. The index information  may be stored in memory of the query node servers  and in the database  connected to the query node servers . The index information  may be updated with the full-index  responsive to its arrival at the query node servers . Further, the index information  may be updated with the mini-index  responsive to its arrival at the query node servers . The index information  is generally updated in sequential order. For example, the index information  are generally updated at the query node server  in the order in which the full-index  and the mini-indexes  are generated. To this end, the full-index  may be associated with full-index BOM information  the mini-index  may be associated with mini-index BOM information  that are utilized by the query node server  to manage the update of the index information . In one embodiment a map-reduce job module  may include sub-jobs that execute on the HBase\/Hadoop node  to generate inverted indices in the form of region sub-indices (not shown) for part of the region associated with the region server (HBase). The sub-jobs may further merge or stitch the multiple region sub-indices together for the region.","At operation F, a second user who operates the client machine  may enter a query that may be communicated over a network (e.g., Internet) via front-end servers  and back-end servers  to be received by the query node servers  which may be divided into two layers. The two layers may include an aggregation layer and a query execution layer. The aggregation layer may include a query node server  that includes a query engine  (e.g. query module) that receives the query that, in turn, communicates the query to multiple query engines  that respectively execute in the execution layer in multiple query node servers  that correspond to the columns. The query engines  in the query execution layer may, in turn, respectively apply the same query, in parallel, against respective the index information  that were generated for a range of document identifiers (e.g., column) to identify search results (e.g., document ) in parallel. Finally, the query engines , at each query node server  in the query execution layer, may communicate their respective partial search results to the query engine  in the aggregation layer which aggregates the multiple sets of partial search results to form a search result for the entire index information  and to communicate the search result over the network to the second user.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 2A","FIG. 1"],"b":["21","21","20","21","80","80","80","81","81","80"]},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 2B","b":["80","80","82","84","86","88","80","21","81","81"]},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 3A","b":["21","90","1","21","90","90","80","21","21","90","26","90","49","90","26","90","49","90","90"],"i":"s "},{"@attributes":{"id":"p-0056","num":"0055"},"figref":["FIG. 3B","FIG. 3B"],"b":["90","98","94","92","30","92","30","94","96","92","26","30","90","80","21","90","1","98","1","94","98","80","21","92","30","94","92","98","94","96","96","94","21","21"]},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 4","b":["100","22","24","100","22","24"]},"Full-Index Generation","Callout  corresponds to a full snapshot () of the items table  and callout  corresponds to a full deployment of the full snapshot (). The full snapshot may capture the entire contents of the items table  at an instant in time. Further, callout  corresponds to a full snapshot () that occurs later in time and callout  corresponds to a full deployment of the full snapshot (). The full snapshot () and the full snapshot () may be utilized to respectively generate the full-index  () and the full-index  ()","Mini-Index Generation","Callout  corresponds to a start-time of a delta snapshot () of the items table  and callout  corresponds to an end-time of the delta snapshot (). The delta snapshot may capture the changes to the items table  that are subsequent to the previous delta snapshot. For example, subsequent to a prior delta snapshot, an entry of item information  may be added to the items table, an entry of item information  may be removed from the items table  or an existing item information  entry may be modified. These changes are capture with the delta snapshot. Sequential delta snapshots are illustrated including callout  which corresponds to a start-time of a delta snapshot () of the items table  and callout  which corresponds to an end-time of the delta snapshot (). The successive delta snapshots may be may be utilized to generate the mini-indexes  (e.g., mini-index  (), mini-index  (), mini-index  (), etc.)","Update of Index Information with Full Snapshots and Delta Snapshots","The index information  at the query node servers  may be updated with the full-indexes  and the mini-indexes  in an order that is sequential. For example, the index information  may be updated based on the order in which the full-index  and the mini-indexes  are generated and communicated to the query node servers . Further, the mini-indexes  may arrive out of sequence at the query node servers . Accordingly, each of the query node servers  may utilize current BOM information  at the query node servers , a full-index BOM information  associated with the full-index , and the mini-index BOM information  associated with the mini-index  to ensure the update is performed in sequential order. In some embodiments a delta snapshot may be skipped if explicitly identified. Further, it will be appreciated that the same index information  at the query node server  may be generated by combining different full and delta snapshots. For example, the index information  may be generated based on the full snapshot associated with the full-index  () and the delta snapshots respectively associated with the mini-indexes  (-) or the full-index  () and the delta snapshots respectively associated with the mini-indexes  (-). Other equivalent combinations may be formed. For example, the index information  may be generated based on the full snapshot associated with the full-index  () and the delta snapshots respectively associated with the mini-indexes  (-) or the full snapshot associated with the full-index  () and the delta snapshots respectively associated with the mini-indexes  (-), etc.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 5A","b":["120","120","22","24"]},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 5B","b":["22","22","80","21","88","22","54","121","121","122","26","128","26","32","34","80","21","88","122","98","98","32","98","34","80","98","32","34","80","122","122","128","22"]},{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 5C","b":["24","24","80","21","88","24","54","121","121","22","130","34","80","21","88","32","34","130","80","24"]},{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 6A","b":["64","64","30","26","22","24","64","150","22","152","24","154","24","30","26","30","26","30","24","162","24","30","150","22","156","1","152","22","24","154","24","2","3","4","24","30","24","1","26","24","162","1","24","162","1","2","3","4"]},{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 6B","b":["54","54","156","54","158","54","156","156","1","158","0","01"]},{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 6C","b":["160","160","162","24","164","24","166","22","24","168","24","24","170","24","162","162","6","164","0","02","156","1","2","1","2","3","4","5","6","170","5","26","30","24","6","26","22","1","2","26","30","24","6","26","24","162","5","170","24","5"]},{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 7","b":["300","300","302","11","12","42","80","21","80","82","84","86","11","80","82","84","86","21"]},"At operation , the HBase\/Hadoop Cluster  may include a scheduler module  that periodically generates\/builds the index information components  including the full-index  or the mini-index . The scheduler module  may periodically generate the index information component  by scheduling a map-reduce job module  that initiates jobs that execute in a map-reduce framework. The map-reduce job module  may schedule one set of jobs to generate the full-index  and another set of jobs to generate the mini-index . The building of the full-index  and the mini-index  may be in real time while the information search and retrieval platform  remains operational and in parallel. For example, the scheduler module  may schedule the generation of the full-index  twice in a twenty-four hour period and the generation of mini-indexes  every five minutes. The scheduling and execution of jobs is described more fully in method  of .","At operation , the index distribution module  may communicate the index information component  to the appropriate query node servers . For example, the index distribution module  may communicate the full-index  to the appropriate column  of query node servers  in the grid  of query node servers  responsive to the build of the full-index  being completed. Also for example, the index distribution module  may communicate the mini-index  to the appropriate column  of query node servers  in the grid  of query node servers  responsive to the build of the mini-index  being completed.","At operation , the query node servers  in the query node column  may update the index information  responsive to receipt of the index information component . The query node server  may update the index information  with the full-index  by restarting the query node server , as described more fully in method  of . Also for example, the query node server  may update the index information  with the mini-index  as described more fully in method  of .","At operation , the information storage and retrieval platform  may receive a search query, over a network, from a client machine  and utilize the index information  in the grid  of query node servers  to identify search results that are communicated back to the client machine .",{"@attributes":{"id":"p-0072","num":"0071"},"figref":["FIG. 8A","FIG. 9A"],"b":["400","120","400","400","402","48","50","404","50","22","22","50","406","408","410","412","22","94","30","92","30","550"]},"At decision operation , the map-reduce job module  may identify whether a mini-index  is scheduled for generation\/build. If a mini-index  is scheduled for generation\/build then the map-reduce job module  may sequentially execute the mini-index section job (operation ) and the transport packing job (operation ). The transport packing job may communicate the mini-index  to the appropriate query node column  of query node servers  in the grid  of query node servers . The execution of jobs is described more fully in a data flow  of .",{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 8B","b":["450","26","30","22","453","62","30","22","454","62","22","22","54","156","158","62","156","150","22","62","158","22","158","22","456","456","62","150","64","156","54","458","62","30","26","30","22","30","156","54","22"]},{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 8C","b":["470","26","30","24","472","62","30","24","474","62","24","62","162","152","24","24","26","62","164","24","164","62","166","156","150","24","24","22","26","30"]},"At decision operation , the query engine  may identify whether the received mini-index  is identified with a mini-index identifier  that identifies the next expected mini-index . For example, the query engine  may identify whether the mini-index identifier  in the mini-index BOM information  is equal to the current mini-index identifier  plus 1. If the received mini-index  is the next in sequence then processing continues at operation . Otherwise processing continues at operation . At operation , the query engine  may identify whether mini-indexes  may be skipped. For example, the query engine may read the skip-information  in the mini-index BOM information  included in the mini-index . At operation , the query engine  may identify whether any mini-indexes  have been stored as mini-index storage information . At decision operation , the query engine  may determine whether the update of the index information  in the query node server  may be performed based on the skip information  and the identified stored mini-indexes . If the update may be performed then processing continues at operation . Otherwise processing continues at operation . At operation , the query engine  may store the mini-index  that was most recently received as mini-index storage information . At operation , the query engine  may update in sequential order the index information  in the query node server  with the mini-indexes  that were identified. For example, the query engine  may sequentially update the index information  with the one or more mini-indexes  identified as stored as mini-index storage information  and the mini-index  that was most recently received while skipping any mini-indexes that were identified in the skip information .",{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 9A","b":["550","22","550","48","48","50","550","202","204","206","208","202","204"]},"The full-index section job  may initiate map tasks  (e.g., M, M, M, MN), one for each of the regions  of the items table , as previously described. The map tasks  may take full snapshots of the item information  corresponding to item identifiers  in the associated region . To this end, the map tasks  may read item information  (e.g., describing items) from the items table , according to regions , and generate token information  and other information both being utilized to generate the section information . The other information may be communicated directly to the reducers  (e.g., \u201cR,\u201d \u201cR,\u201d \u201cR,\u201d \u201cRN\u201d). The token information  may be communicated to a partitioned  which, in turn, partitions the token information  for consumption by reducers  (e.g., \u201cR,\u201d \u201cR,\u201d \u201cR,\u201d \u201cRN\u201d). The partitioner  may partition the token information  (not shown) based on the contents of the token information  including a token element  (not shown), an item identifier , and the column identifier. For example, token information  may be embodied as follows:","\u201c\u2018cat,\u2019 item , column .\u201d","Responsive to receiving the token information , the partitioner  may identify a particular reducer  (e.g., \u201cR,\u201d \u201cR,\u201d \u201cR,\u201d \u201cRN\u201d) based on a hash value that is generated from the token element  and the column identifier and send the token information  to the identified reducer . The merger jobs  may initiate the reducers  and map tasks  to process the token information  and other information to generate the full-index . The reducers  and map tasks  may execute on the HBase\/Hadoop nodes . It will be appreciated that processing time to produce the full-index  may be minimized by increasing the number of map tasks , reducers , map tasks  and HBase\/Hadoop nodes . Further, resources may be economized by decreasing the same. Each of the reducers  may segregate the received token information  according to columns  (e.g., \u201cCOLUMN ,\u201d \u201cCOLUMN ,\u201d \u201cCOLUMN ,\u201d COLUMN N). For example, the token information  and other information for \u201cColumn \u201d may be segregated as output  for \u201cCOLUMN .\u201d Other output  may be segregated for other columns  in a similar manner. Recall that the columns  may correspond to a query node column  of query node servers  in a grid  of query node servers  (not shown)) that utilize the full-index , once generated, to process a query. The reducers  may organize the token information  and other information into output  according to columns  based on column identifiers and distributes the output  in accordance with the columns  to the map tasks . For example,  illustrates the reducer  identified as \u201cR\u201d as receiving the token information  for all columns , generating output  that is organized according to the columns \u201cC,\u201d \u201cC,\u201d \u201cC,\u201d \u201cCN\u201d and distributing the output  for \u201cC\u201d to the map task  \u201cM.\u201d For clarity sake the other output  (e.g., \u201cC,\u201d \u201cC,\u201d and \u201cCN\u201d) is not illustrated as being distributed to the other map tasks  (e.g., \u201cM,\u201d \u201cM,\u201d \u201cM,\u201d and \u201cMN\u201d). Further, the remaining reducers  (e.g., \u201cR,\u201d \u201cR,\u201d and \u201cRN\u201d) are also illustrated as distributing the output  for \u201cC\u201d to the map task  \u201cR\u201d but again, for clarity sake, the full data flow is not illustrated. Broadly, each reducer  may generate output  for all columns  and distributes the output  to the map tasks, according to columns .","The map task  may receive the output  for a single column . The map task  may utilize the output  and the other information to generate the section information  (e.g., \u201cS,\u201d \u201cS,\u201d \u201cS,\u201d and \u201cSN\u201d) for the particular column .","The index packing job  may execute to generate the full index . The index packing job  may generate the full index  by packing the sections of the section information  together, generating the full-index BOM information , and packing the full-index . The index packing job  may pack the full-index by packing the section information , the full-index BOM information  and the index properties information  into the full-index .","Finally, the transport job  may execute to distribute the full-indexes , according to columns , to the grid  of query node servers . For example, the transport job  may execute to transport the full-index  for column  to each of the query node servers  in column  of the grid . In one embodiment, the distribution of the full-indexes  to the query node servers  may be over a network utilizing the index distribution module  based on Bit Torrent, a peer to peer file sharing protocol.",{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 9B","b":["570","24","250","48","50","252","208","252"]},"The mini-index section job  may initiate map tasks  (e.g., \u201cM,\u201d \u201cM,\u201d \u201cM,\u201d and \u201cMN\u201d), one for each column . The map tasks  may further correspond to two regions  of the items table , according to an embodiment. Other embodiments may utilize a different ratio of regions  to columns  to map tasks . The map tasks  may take a snapshot of changes to the items table  that have occurred between a start-time and an end-time. For example, the snapshot may record an addition of item information  (e.g., new item), a deletion of item information , and a modification to existing item information  (e.g., field addition, field addition, field modification). The map tasks  may further generate the mini-index . The map tasks  may generate the mini-index  by packing the sections of the section information  together, generating the mini-index BOM information , and packing the mini-index . The map tasks  may pack the mini-index  by packing the section information , the mini-index BOM information  and the index properties information  into the mini-index .","The transport job  may execute to distribute the mini-indexes , according to columns , to the query node column  in the grid  of query node servers . For example, the transport job  may execute to transport the mini-index  for column  to the query node servers  (not shown) in column  of the grid  (not shown). In one embodiment, the distribution of the mini-indexes  to the query node servers  may be over a network utilizing the index distribution module  based on Bit Torrent, a peer to peer file sharing protocol.",{"@attributes":{"id":"p-0086","num":"0085"},"figref":["FIG. 10A","FIG. 1"],"b":["600","602","600","10","600","33","11","11","11","33","606","604","602","604","622","624","625","33","625","625","625","625","625","622","625","625","624","622","625","62","625","622","624","600"]},"At operation A, the information storage and retrieval platform  may utilize search front-end servers  to receive the query  from the client machine . For example, the query may include the keywords \u201cBLACK IPOD NANO ACCESSORIES.\u201d The search front-end servers  may parse the query  to generate query information  and store the query information  in a query container . The query container  may contain multiple entries of query information , some being parsed from the same query  \u201cBLACK IPOD NANO ACCESSORIES\u201d and others being parsed from other queries (not shown). The query information  that is illustrated is for the query expression  \u201cAND (IPOD, NANO)\u201d being parsed from the example query, \u201cBLACK IPOD NANO ACCESSORIES.\u201d Other query information  is not illustrated. The query information  may include the query expression , output field information , sort field information  and a primary input table . The query expression , as described above, may be comprised of keywords that are parsed by the front-end server  from the query  that is received and operators that either appear in the query  or are implied as being in the query . The output field information  may identify output fields to be included the search results. For example, the output field information  may identify one or more fields of records (e.g., items, documents) that are included in the search results. The sort field information  may identify the one or more field(s) utilized to sort the search results and whether to sort in ascending or descending order. The primary input table  may identify an input table from which data is retrieved based on the query expression . At least a portion of the data may be returned to the client machine  as search results.","At operation B, the search front-end servers  may communicate the query container  to the search back-end servers . The search back-end servers  may process the query information  in the query container , as described later in this document.","At operation C, the search back-end servers  may communicate the query container  to a query node server  in an aggregation layer  of query node servers . The query node server  may respond to receipt of the query container  by invoking a query engine  (not shown) to generate a query expression tree  based on the query expression  and store the query expression tree  in the query container . Further, the query engine  may identify a single query node server  in each of the query node columns  of the grid  of query node servers  and communicate the query container  to the identified query node servers . Further, recall that each of the query node columns  is dedicated to a particular range of documents (e.g., items) in the index information . Accordingly, the query node server  in the aggregation layer  communicates the query container  to one query node server  in each of the query node columns  in the grid  to retrieve search results for the entire index information .","At operation D, the query node servers  in respective query node columns  may receive the query container  and process the query information  entries in the query container . For example, the query node server  may process each query information  entry to build (e.g. generate) and execute a query plan . To this end, one query engine  from each query node column  invokes a query plan builder  to build the query plan  and further executes the query plan . The query plan  may include a cursor expression tree  that include expression nodes (not shown) that correspond to cursor objects of the query expression tree  (not shown). The query plan builder  may invoke expansion generators (not shown) that read the expression nodes of the query expression tree  to generate the cursor objects of the cursor expression tree . The expansion generators may include a generic expansion generator (not shown) that executes in the execution layer  to generate cursor objects and multiple specific expansion generators (not shown) that execute in the storage layer to generate storage cursor objects. The expression nodes directly correspond to the cursor objects (e.g., one-to-one correspondence).","The query engine  executes the query plan . For example, the query engine  may execute cursor objects (not shown) and storage cursor objects (not shown) in the query plan . The query engine  may execute the storage cursor objects to retrieve data from a particular storage device . The query node server  may store the data that was retrieved in a table container  that may subsequently be communicated as search results via the aggregation layer  to the search back-end servers  to the search front-end servers  to the client machine . Accordingly, operations that are unique to a particular storage device  are hidden within a storage layer that is accessible via an execution layer that is exposed to query processing clients (e.g., query engine ) resulting in a unified storage interface.",{"@attributes":{"id":"p-0092","num":"0091"},"figref":["FIG. 10B","FIG. 10A"],"b":["60","60","650","652","650","606","58","606","652","650","606","652","652","604","606","608","608","652","608","80","80","652","652","80","620","620","620","58","33","620","620","80","620","80","620"]},{"@attributes":{"id":"p-0093","num":"0092"},"figref":"FIG. 10C","b":["30","30","62","654","626","626","30","26","30","28","662","28","26","656","658","660","656","654","614","604","658","660","662","658","664","30","658","28","660","28","658","662","660","662"]},{"@attributes":{"id":"p-0094","num":"0093"},"figref":"FIG. 10D","b":["618","618","680","684","680","608","684","608"]},{"@attributes":{"id":"p-0095","num":"0094"},"figref":"FIG. 10E","b":["628","628","62","625","628","686","688","686","680","618","688","684","618"]},{"@attributes":{"id":"p-0096","num":"0095"},"figref":"FIG. 10F","b":["690","690","622","624","622","692","628","692","686","680","618","624","694","625","694","694","696","688","628","696","684","618"]},{"@attributes":{"id":"p-0097","num":"0096"},"figref":"FIG. 10G","b":["698","698","614","604","694","696","694"]},{"@attributes":{"id":"p-0098","num":"0097"},"figref":"FIG. 10H","b":["688","688","688"]},{"@attributes":{"id":"p-0099","num":"0098"},"figref":"FIG. 10I","b":["700","700","702","58","11","33","58","604","604","606","604","608","608","58","606","60","604","606","606","30","616","30"]},"In one embodiment, the transformer  may perform an expansion function for the query information  in the query container . For example, the query expression  \u201cAND (IPOD, NANO)\u201d may be expanded to capture plural forms, synonyms, idioms, etc. In one embodiment, the transformer  may further perform a scatter\/gather function by iterating the search of the query expression  and blending the results. The transformer  may generate the desired search result by initiating two searches in parallel. The transformer  may initiate the first search by communicating the query container  to a first query node server  in the aggregation layer  of query node servers  to request item information  for items that are offered for sale with an auction process and the second search by communicating the query container  to a second query node server  in the aggregation layer  of query node servers  to request item information  for items that are offered for sale with a purchase process, as previously described. The search results may be blended into a single search result, as previously described.","At operation , the query node server  in the aggregation layer may utilize the query engine  to generate a query expression tree  for each query information  entry in the query container . For example, the query engine  may generate the query expression tree  based on the query expression  in the query information  and store the query expression tree  in the query container . The query expression tree  may include nodes representing expressions in the query expression  that are logically connected with edges. For example, the query expression tree  for the query expression \u201cAND (IPOD, NANO)\u201d may include an operator expression node  for \u201cAND,\u201d a term expression node  \u201cIPOD\u201d and a term expression node  for \u201cNANO\u201d where two edges lead away from the \u201cAND\u201d operator expression node , one leading to the \u201cIPOD\u201d term expression node  and the other leading to the \u201cNANO\u201d term expression node . Further, the query engine  may identify a single query node server  in each of the query node columns  of a grid  of query node servers  and communicate the query container  to the identified query node servers .","At operation , the query node servers  in respective query node columns  may receive the query container  and invoke the query engine  to invoke the query plan builder . The query plan builder  may process each query information  entry in the query container  to build (e.g., generate) an associated query plan . The query plan builder  may build the query plan  to include a cursor expression tree  that includes cursor objects that correspond to expression nodes in the query expression tree , as described more fully in method  on .","At operation , the query engine  may execute the cursor expression tree  to retrieve data from a storage device . For example, the query engine  may execute a method in the storage cursor object  for \u201cNANO\u201d to retrieve records (e.g., item information ) that include the string \u201cNANO\u201d from a storage device  (e.g., relational storage). Further, the query engine  may execute a method in the storage cursor object  for \u201cIPOD\u201d to retrieve records (e.g., item information ) that include the string \u201cIPOD\u201d from a storage device  (e.g., relational storage). Finally, the query engine  may execute a method in the cursor object  for \u201cAND\u201d to \u201cAND\u201d the two sets of retrieved records and store the combined set in a table container  as results.","At operation , the query node server  may communicate table container  via the aggregation layer  to the search back-end servers  that, in turn, communicate the table container  to the search front-end servers  that, in turn, extract the search results from the table container  and communicate the search results to the client machine .",{"@attributes":{"id":"p-0105","num":"0104"},"figref":"FIG. 10J","b":["750","628","752","654","30","618","754","654","654","692","622","760","756","756","654","696","614","604","654","698","614","604","694","696","758","654","692","688","696","624","688","762","654","628","764","654","618","618","752"]},{"@attributes":{"id":"p-0106","num":"0105"},"figref":["FIG. 11","FIG. 1","FIG. 11"],"b":["800","800","10","812","814","816","820","818","822","833","811","833"]},"An Application Program Interface (API) server  and a web server  are coupled to, and provide programmatic and web interfaces respectively to, one or more application servers . The application servers  host one or more marketplace applications  and payment applications . The application servers  are, in turn, shown to be coupled to one or more database servers  that facilitate access to one or more databases ","The marketplace applications  may provide a number of marketplace functions and services to users that access the network-based marketplace . The payment applications  may likewise provide a number of payment services and functions to users. The payment applications  may allow users to accumulate value in accounts and then to later redeem the accumulated value for products (e.g., goods or services) that are made available via the marketplace applications . The value may be accumulated in a commercial currency, such as the U.S. dollar, or a proprietary currency, such as \u201cpoints.\u201d While the marketplace applications  and payment applications  are shown in  to both form part of the network-based marketplace , it will be appreciated that, in alternative embodiments, the payment applications  may form part of a payment service that is separate and distinct from the network-based marketplace .","Further, while the networked system  shown in  employs client-server architecture, embodiments of the present disclosure are of course not limited to such an architecture and could equally well find application in a distributed, or peer-to-peer, architecture system, for example. The various marketplace applications  and payment applications  could also be implemented as standalone software programs, which do not necessarily have networking capabilities.","The web client  and mobile web client  access the various marketplace applications  and payment applications  via the web interface supported by the web server . Similarly, the programmatic client  accesses the various services and functions provided by the marketplace applications  and payment applications  via the programmatic interface provided by the API server . The programmatic client  may, for example, be a seller application (e.g., the TurboLister application developed by eBay Inc., of San Jose, Calif.) to enable sellers to author and manage listings on the network-based marketplace  in an off-line manner, and to perform batch-mode communications between the programmatic client  and the network-based marketplace .",{"@attributes":{"id":"p-0111","num":"0110"},"figref":"FIG. 11","b":["829","831","800","824"]},"The mobile device  may be embodied as a mobile phone, a personal digital assistant (PDA), a cell phone, or any other wireless device that is capable of communicating with the network-based marketplace . For example, the mobile device  may be embodied as an iPhone mobile phone manufactured by Apple, Inc. of Cupertino, Calif. or, as previously mentioned, a Blackberry\u2122 mobile phone manufactured by Research In Motion of Waterloo, Ontario.","Marketplace and Payment Applications",{"@attributes":{"id":"p-0113","num":"0112"},"figref":["FIG. 12","FIG. 11","FIG. 11","FIG. 11"],"b":["830","832","800","830","832","836","834"]},"The network-based marketplace  of  may provide a number of publishing, listing and price-setting mechanisms whereby a seller may list (or publish information concerning) goods or services for sale; a buyer can express interest in or indicate a desire to purchase such goods or services; and a price can be set for a transaction pertaining to the goods or services. To this end, the marketplace applications  are shown to include at least one publication application  and one or more auction applications  which support auction-format listing and price setting mechanisms (e.g., English, Dutch, Vickrey, Chinese, Double, Reverse auctions, etc.). The various auction applications  may also provide a number of features in support of such auction-format listings, such as a reserve price feature whereby a seller may specify a reserve price in connection with a listing and a proxy-bidding feature whereby a bidder may invoke automated proxy bidding.","A number of fixed-price applications  support fixed-price listing formats (e.g., the traditional classified advertisement-type listing or a catalogue listing) and buyout-type listings. Specifically, buyout-type listings (e.g., including the Buy-It-Now (BIN) technology developed by eBay Inc., of San Jose, Calif.) may be offered in conjunction with auction-format listings and may allow a buyer to purchase goods or services, which are also being offered for sale via an auction, for a fixed-price that is typically higher than the starting price of the auction.","Store application(s)  allows a seller to group listings within a \u201cvirtual\u201d store, which may be branded and otherwise personalized by and for the seller. Such a virtual store may also offer promotions, incentives and features that are specific and personalized to a relevant seller.","Reputation applications  allow users that transact, utilizing the network-based marketplace , to establish, build and maintain reputations, which may be made available and published to potential trading partners. Consider that where, for example, the network-based marketplace  supports person-to-person trading, users may otherwise have no history or other reference information whereby the trustworthiness and credibility of potential trading partners may be assessed. The reputation applications  allow a user to establish a reputation within the network-based marketplace  over time, for example, through feedback provided by other transaction partners and by the computation of a feedback score based on the feedback. For example, the feedback score may be publicly displayed by the network-based marketplace . Other potential trading partners may then reference such a feedback score for the purposes of assessing credibility and trustworthiness.","Personalization applications  allow users of the network-based marketplace  to personalize various aspects of their interactions with the network-based marketplace . For example, a user may, utilizing an appropriate personalization application , create a personalized reference page at which information regarding transactions to which the user is (or has been) a party may be viewed. Further, a personalization application  may enable a user to personalize listings and other aspects of their interactions with the networked system  and other parties.","The networked system  may support a number of marketplaces that are customized, for example, for specific geographic regions. A version of the networked system  may be customized for the United Kingdom, whereas another version of the networked system  may be customized for the United States. Some of these versions may operate as an independent marketplace, or may be customized (or internationalized) presentations of a common underlying marketplace. The networked system  may accordingly include a number of internationalization applications  that customize information (and\/or the presentation of information) by the networked system  according to predetermined criteria (e.g., geographic, demographic or marketplace criteria). For example, the internationalization applications  may be used to support the customization of information for a number of regional websites that are operated by the networked system  and that are accessible via respective servers  and  both of .","Navigation of the network-based marketplace  may be facilitated by one or more navigation applications . Merely for example, the navigation applications  may receive search information in the form of a query to search for items on the network-based marketplace and return search results responsive to the request. A browse application may allow users to browse various category, catalogue, or inventory data structures according to which listings may be classified within the networked system . Various other navigation applications may be provided to supplement the search and browsing applications. For example, the navigation applications  may include the event manager module , the scheduler module , the map-reduce job module , included in the system  to build and utilize a search infrastructure. Further, the navigation applications  may include other modules in the system  that are not presently mentioned. In order to make listings available via the networked system  as visually informing and attractive as possible, the marketplace applications  may include one or more imaging applications  with which users may upload images for inclusion within listings. An imaging application  also operates to incorporate images within viewed listings. The imaging applications  may also support one or more promotional features, such as image galleries that are presented to potential buyers. For example, sellers may pay an additional fee to have an image included within a gallery of images for promoted items.","Listing creation applications  allow sellers to conveniently author listings pertaining to goods or services that they wish to transact via the network-based marketplace , while the listing management applications  allow sellers to manage such listings. Specifically, where a particular seller has authored and\/or published a large number of listings, the management of such listings may present a challenge. The listing creation applications may further include a processing module, communication module, and listing module that facilitate a buyer watching for specific types of listings. The listing management applications  provide a number of features (e.g., auto-relisting, inventory level monitors, etc.) to assist the seller in managing such listings.","One or more post-listing management applications  may also assist sellers with a number of activities that may typically occur post-listing. For example, upon completion of an auction facilitated by one or more auction applications , a seller may wish to leave feedback regarding a particular buyer. To this end, a post-listing management application  may provide an interface to one or more reputation applications , so as to allow the seller conveniently to provide feedback regarding multiple buyers to the reputation applications .","Dispute resolution applications  provide mechanisms whereby disputes arising between transacting parties may be resolved. For example, the dispute resolution applications  may provide guided procedures whereby the parties are guided through a number of steps in an attempt to settle a dispute. In the event that the dispute cannot be settled via the guided procedures, the dispute may be escalated to a third party mediator or arbitrator.","A number of fraud prevention applications  implement fraud detection and prevention mechanisms to reduce the occurrence of fraud within the network-based marketplace .","Messaging applications  are responsible for the generation and delivery of messages to users of the network-based marketplace , with such messages, for example, advising users regarding the status of listings at the network-based marketplace  (e.g. providing \u201coutbid\u201d notices to bidders during an auction process or to providing promotional and merchandising information to users). Respective messaging applications  may utilize any one of a number of message delivery networks and platforms to deliver messages to users. For example, messaging applications  may deliver electronic mail (e-mail), instant message (IM), Short Message Service (SMS), text, facsimile, or voice (e.g., Voice over IP (VoIP)) messages via the wired (e.g., the Internet), Plain Old Telephone Service (POTS), or wireless (e.g., mobile, cellular, WiFi (e.g., IEEE 802.11 technologies including 802.11n, 802.11b, 802.11g, and 802.11a)), Worldwide Interoperability for Microwave Access (e.g. WiMAX\u2014IEEE 802.16) networks.","Merchandising applications  support various merchandising functions that are made available to sellers to enable sellers to increase sales via the network-based marketplace . The merchandising applications  also operate the various merchandising features that may be invoked by sellers and may monitor and track the success of merchandising strategies employed by sellers. The transaction incentivizing applications  operate to provide incentives for buyers and sellers to enter into and complete transactions.","Data Structures",{"@attributes":{"id":"p-0127","num":"0126"},"figref":["FIG. 13","FIG. 11","FIG. 12","FIG. 11"],"b":["880","836","830","832","882","812","812","812"]},"The tables  also include an items table  in which item records are maintained for goods and services that are available to be, or have been, transacted via the network-based marketplace . Item records within the items table  may furthermore be linked to one or more user records within the user table , so as to associate a seller and one or more actual or potential buyers with an item record.","A transaction table  contains a record for each transaction (e.g., a purchase or sale transaction or auction) pertaining to items for which records exist within the items table .","An order table  is populated with order records, with each order record being associated with an order. Each order, in turn, may be associated with one or more transactions for which records exist within the transaction table .","Bid records within a bids table  relate to a bid received at the network-based marketplace  in connection with an auction-format listing supported by an auction application  of . A feedback table  is utilized by one or more reputation applications  of , in one example embodiment, to construct and maintain reputation information concerning users in the form of a feedback score. A history table  maintains a history of transactions to which a user has been a party. One or more attributes tables  record attribute information pertaining to items for which records exist within the items table . Considering only a single example of such an attribute, the attributes tables  may indicate a currency attribute associated with a particular item, with the currency attribute identifying the currency of a price for the relevant item as specified in by a seller.","Search storage structures  may store information that is utilized to search the items table  and other tables. For example, the search storage structures  may be utilized by the system , as illustrated n , to build and utilize a search infrastructure, according to an embodiment. A customization table  may store customization records that may be utilized to customize the operation of the network-based marketplace .",{"@attributes":{"id":"p-0133","num":"0132"},"figref":"FIG. 14","b":"900"},"The example computer system  includes a processor  (e.g., a central processing unit (CPU), a graphics processing unit (GPU), or both), a main memory  and a static memory , which communicate with each other via a bus . The computer system  may further include a video display unit  (e.g. a liquid crystal display (LCD) or a cathode ray tube (CRT)). The computer system  also includes an input device  (e.g., a keyboard), a cursor control device  (e.g., a mouse), a disk drive unit , a signal generation device  (e.g., a speaker) and a network interface device .","The disk drive unit  includes a machine-readable medium  on which is stored one or more sets of instructions (e.g., software ) embodying any one or more of the methodologies or functions described herein. The instructions (e.g., software ) may also reside, completely or at least partially, within the main memory , the static memory , and\/or within the processor  during execution thereof by the computer system . The main memory  and the processor  also may constitute machine-readable media. The instructions  may further be transmitted or received over a network  via the network interface device .","Applications that may include the apparatus and systems of various embodiments broadly include a variety of electronic and computer systems. Some embodiments implement functions in two or more specific interconnected hardware modules or devices with related control and data signals communicated between and through the modules, or as portions of an application-specific integrated circuit. Thus, the example system is applicable to software, firmware, and hardware implementations. In example embodiments, a computer system (e.g., a standalone, client or server computer system) configured by an application may constitute a \u201cmodule\u201d that is configured and operates to perform certain operations as described herein. In other embodiments, the \u201cmodule\u201d may be implemented mechanically or electronically. For example, a module may comprise dedicated circuitry or logic that is permanently configured (e.g., within a special-purpose processor) to perform certain operations. A module may also comprise programmable logic or circuitry (e.g., as encompassed within a general-purpose processor or other programmable processor) that is temporarily configured by software to perform certain operations. It will be appreciated that the decision to implement a module mechanically, in the dedicated and permanently configured circuitry, or in temporarily configured circuitry (e.g. configured by software) may be driven by cost and time considerations. Accordingly, the term \u201cmodule\u201d should be understood to encompass a tangible entity, be that an entity that is physically constructed, permanently configured (e.g., hardwired) or temporarily configured (e.g., programmed) to operate in a certain manner and\/or to perform certain operations described herein.","While the machine-readable medium  is shown in an example embodiment to be a single medium, the term \u201cmachine-readable medium\u201d should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and\/or associated caches and servers) that store the one or more sets of instructions. The term \u201cmachine-readable medium\u201d shall also be taken to include any medium that is capable of storing, encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present description. The term \u201cmachine-readable medium\u201d shall accordingly be taken to include, but not be limited to, solid-state memories, optical media and magnetic media. As noted, the software may be transmitted over a network using a transmission medium. The term \u201ctransmission medium\u201d shall be taken to include any medium that is capable of storing, encoding or carrying instructions for transmission to and execution by the machine, and includes digital or analogue communications signal or other intangible medium to facilitate transmission and communication of such software.","The illustrations of embodiments described herein are intended to provide a general understanding of the structure of various embodiments, and they are not intended to serve as a complete description of all the elements and features of apparatus and systems that might make use of the structures described herein. Many other embodiments will be apparent to those of ordinary skill in the art upon reviewing the above description. Other embodiments may be utilized and derived therefrom, such that structural and logical substitutions and changes may be made without departing from the scope of this disclosure. The figures provided herein are merely representational and may not be drawn to scale. Certain proportions thereof may be exaggerated, while others may be minimized. Accordingly, the specification and drawings are to be regarded in an illustrative rather than a restrictive sense.","Software","In some embodiments, the methods described herein may be implemented in a distributed or non-distributed software application designed under a three-tier architecture paradigm, whereby the various components of computer code that implement this method may be categorized as belonging to one or more of these three tiers. Some embodiments may include a first tier as an interface (e.g., an interface tier) that is relatively free of application processing. Further, a second tier may be a logic tier that performs application processing in the form of logical\/mathematical manipulations of data inputted through the interface level and communicates the results of these logical\/mathematical manipulations to the interface tier and\/or to a backend, or storage, tier. These logical\/mathematical manipulations may relate to certain business rules or processes that govern the software application as a whole. A third, storage tier may be a persistent storage medium or non-persistent storage medium. In some cases, one or more of these tiers may be collapsed into another, resulting in a two-tier architecture, or even a one-tier architecture. For example, the interface and logic tiers may be consolidated, or the logic and storage tiers may be consolidated, as in the case of a software application with an embedded database. This three-tier architecture may be implemented using one technology, or, as will be discussed below, a variety of technologies. This three-tier architecture, and the technologies through which it is implemented, may be executed on two or more computer systems organized in a server-client, peer-to-peer, or so some other suitable configuration. Further, these three tiers may be distributed between multiple computer systems as various software components.","Some example embodiments may include the above illustrated tiers, and processes or operations that make them up, as being written as one or more software components. Common to many of these components is the ability to generate, use, and manipulate data. These components, and the functionality associated with each, may be used by client, server, or peer computer systems. These various components may be implemented by a computer system on an as-needed basis. These components may be written in an object-oriented computer language such that a component oriented, or object-oriented programming technique can be implemented using a Visual Component Library (VCL), Component Library for Cross Platform (CLX), Java Beans (JB), Java Enterprise Beans (EJB), Component Object Model (COM), Distributed Component Object Model (DCOM), or other suitable technique. These components may be linked to other components via various APIs, and then compiled into one complete server, client, and\/or peer software application. Further, these APIs may be able to communicate through various distributed programming protocols as distributed computing components.","Some example embodiments may include remote procedure calls being used to implement one or more of the above illustrated components across a distributed programming environment as distributed computing components. For example, an interface component (e.g., an interface tier) may reside on a first computer system that is remotely located from a second computer system containing a logic component (e.g., a logic tier). These first and second computer systems may be configured in a server-client, peer-to-peer, or some other suitable configuration. These various components may be written using the above illustrated object-oriented programming techniques, and can be written in the same programming language, or a different programming language. Various protocols may be implemented to enable these various components to communicate regardless of the programming language used to write these components. For example, a component written in C++ may be able to communicate with another component written in the Java programming language by using a distributed computing protocol such as a Common Object Request Broker Architecture (CORBA), a Simple Object Access Protocol (SOAP), or some other suitable protocol. Some embodiments may include the use of one or more of these protocols with the various protocols outlined in the Open Systems Interconnection (OSI) model, or Transport Control Protocol\/Internet Protocol (TCP\/IP) protocol stack model for defining the protocols used by a network to transmit data.","Some embodiments may utilize the OSI model or TCP\/IP protocol stack model for defining the protocols used by a network to transmit data. In applying these models, a system of data transmission between a server and client, or between peer computer systems, is illustrated as a series of roughly five layers comprising: an application layer, a transport layer, a network layer, a data link layer, and a physical layer. In the case of software having a three-tier architecture, the various tiers (e.g., the interface, logic, and storage tiers) reside on the application layer of the TCP\/IP protocol stack. In an example implementation using the TCP\/IP protocol stack model, data from an application residing at the application layer is loaded into the data load field of a TCP segment residing at the transport layer. This TCP segment also contains port information for a recipient software application residing remotely. This TCP segment is loaded into the data load field of an IP datagram residing at the network layer. Next, this IP datagram is loaded into a frame residing at the data link layer. This frame is then encoded at the physical layer, and the data transmitted over a network such as an internet, Local Area Network (LAN). WAN, or some other suitable network. In some cases, internet refers to a network of networks. These networks may use a variety of protocols for the exchange of data, including the aforementioned TCP\/IP, and additionally ATM, SNA, SDI, or some other suitable protocol. These networks may be organized within a variety of topologies (e.g., a star topology) or structures.","The illustrations of embodiments described herein are intended to provide a general understanding of the structure of various embodiments, and they are not intended to serve as a complete description of all the elements and features of apparatus and systems that might make use of the structures described herein. Many other embodiments will be apparent to those of ordinary skill in the art upon reviewing the above description. Other embodiments may be utilized and derived therefrom, such that structural and logical substitutions and changes may be made without departing from the scope of this disclosure. The figures provided herein are merely representational and may not be drawn to scale. Certain proportions thereof may be exaggerated, while others may be minimized. Accordingly, the specification and drawings are to be regarded in an illustrative rather than a restrictive sense.","Thus, systems and methods to build and utilize a search infrastructure are disclosed. While the present disclosure has been described in terms of several example embodiments, those of ordinary skill in the art will recognize that the present disclosure is not limited to the embodiments described, but may be practiced with modification and alteration within the spirit and scope of the appended claims. The description herein is thus to be regarded as illustrative instead of limiting."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Embodiments illustrated, by way of example and not limitation, in the figures of the accompanying drawings, in which:",{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 2B"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 5C"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6C"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 8B"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8C"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 9A"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 9B"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 10A"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 10B"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 10C"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 10D"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 10E"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 10F"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 10G"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 10H"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 10I"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 10J"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 14"}]},"DETDESC":[{},{}]}
