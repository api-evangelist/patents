---
title: Simplified thread control block design
abstract: A data structure is disclosed. Such a data structure includes a thread control block and a message. The thread control block is described by a first data structure and the message is described by a second data structure. Additionally, the first data structure includes the second data structure. Thus, a data structure according to the present invention combines a thread control block structure and a message structure to provide the various benefits described herein. The first data structure may be configured, for example, to store information used to control execution of a thread, with the second data structure configured to store a message.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06865579&OS=06865579&RS=06865579
owner: Sun Microsystems, Inc.
number: 06865579
owner_city: Santa Clara
owner_country: US
publication_date: 20000828
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCES TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This application is related to Patent Application No. 10\/322,382 entitled \u201cAN OPERATING SYSTEM ARCHITECTURE EMPLOYING SYNCHRONOUS TASKS,\u201d filed herewith and having N. Shaylor as inventor; Patent Application No. 09\/650,370 entitled \u201cA GENERAL DATA STRUCTURE FOR DESCRIBING LOGICAL DATA SPACES,\u201d filed herewith and having N. Shaylor as inventor; patent application Ser. No. 09\/498,606, entitled \u201cA SIMPLIFIED MICROKERNEL APPLICATION PROGRAMMING INTERFACE,\u201d filed Feb. 7, 2000, and having N. Shaylor as inventor; Patent Application No. 09\/649,130 entitled \u201cA MICROKERNEL APPLICATION PROGRAMMING INTERFACE EMPLOYING HYBRID DIRECTIVES,\u201d filed herewith and having N. Shaylor as inventor; and Patent Application No. 09\/649,199 entitled \u201cA NON-PREEMPTIBLE MICROKERNEL,\u201d filed herewith and having N. Shaylor as inventor. These applications are assigned to Sun Microsystems, Inc., the assignee of the present invention, and are hereby incorporated by reference, in their entirety and for all purposes.","1. Field of the Invention","The present invention relates to operating systems, and, more particularly, to a combined thread control block and inter-task messaging structure.","2. Description of the Related Art","An operating system is an organized collection of programs and data that is specifically designed to manage the resources of computer system and to facilitate the creation of computer programs and control their execution on that system. The use of an operating system obviates the need to provide individual and unique access to the hardware of a computer for each user wishing to run a program on that computer. This simplifies the user's task of writing of a program because the user is relieved of having to write routines to interface the program to the computer's hardware. Instead, the user accesses such functionality using standard system calls, which are generally referred to in the aggregate as an application programming interface (API).","A current trend in the design of operating systems is toward smaller operating systems. In particular, operating systems known as microkernels are becoming increasingly prevalent. In certain microkernel operating system architectures, some of the functions normally associated with the operating system, accessed via calls to the operating system's API, are moved into the user space and executed as user tasks. Microkernels thus tend to be faster and simpler than more complex operating systems.","These advantages are of particular benefit in specialized applications that do not require the range of functionalities provided by a standard operating system. For example, a microkernel-based system is particularly well suited to embedded applications. Embedded applications include information appliances (personal digital assistance (PDAs), network computers, cellular phones, and other such devices), household appliances (e.g., televisions, electronic games, kitchen appliances, and the like), and other such applications. The modularity provided by a microkernel allows only the necessary functions (modules) to be used. Thus, the code required to operate such a device can be kept to a minimum by starting with the microkernel and adding only those modules required for the device's operation. The simplicity afforded by the use of a microkernel also makes programming such devices simpler.","Performance is often an important design consideration when creating a microkernel. In real-time applications, particularly in embedded real-time applications, the speed provided by a microkernel-based operating system architecture can be of great benefit. By making the operating system's operation more efficient, the need for improved performance in real-time applications may be met. This is of particular importance when writing software for mission-critical systems. In addition to efficiency, mission-critical systems must be made as robust as possible. Thus, designers of mission-critical systems strive to avoid system crashes caused, for example, by memory leaks and out-of-memory conditions.","Embodiments of the present invention address the need to improve operating system efficiency and simplicity. The inventor determined that these objectives could be achieved by combining the data structure used to control input\/output transactions (referred to herein as a message) and the data structure used to control threads (referred to herein as a thread control block or TCB).","By combing a TCB's data structure and a message's data structure, an operating system employing an embodiment of the present invention can be constructed more simply and so operate more efficiently. An operating system incorporating an embodiment of the present invention is simplified because of simplified error handling, reduced indirection, fewer initial allocations and reduced allocation\/de-allocation operations, among other such advantages. Error handling routines in such an operating system are simplified as a result of the pre-allocation of TCB\/message structures, which obviates the need to handle errors caused by failures in the allocation of such structures at a later time. Because such a combined structure allows access to information regarding both thread control and message information, less indirection is encountered in accessing such information (e.g., the indirection necessary to access a message structure via a thread control structure is avoided). Not only does this simplify such an operating system's design, a combined TCB\/message structure thus allows more efficient management of such structures. Only half the number of allocations of such separate structures need be performed in comparison to the allocations performed using a combines TCB\/message structure. And because each TCB\/message structure is pre-allocated, the allocation\/de-allocation normally associated with such structures is also avoided. This is of particular importance in operating systems that employ message passing as their primary (or only) method of inter-task communication, because operations entailing the management of such TCB\/message structures are performed so frequently.","Such an operating system's efficiency is also improved by the ability of a combined TCB\/message structure to control both thread execution and message passing. For example, upon the receipt of a TCB\/message structure, a task has all the control information necessary to perform information transfer and thread control. The TCB\/message structure provides the task with the control information needed to access the information associated with the message. The TCB\/message structure also provides the task with thread control information, allowing the task to start (or re-start) execution of the given thread at the appropriate time. For example, the thread control information held in the TCB\/message structure can be used to cause execution of the thread to begin only after the message passing operation has completed. Thus, the task need only access one structure to acquire all the information necessary to both complete the message passing operation and control the thread associated therewith.","Moreover, because such combined structures are pre-allocated in an operating system according to the present invention, failure due to allocation errors is avoided. In other words, if there will not be enough memory to create a thread control block, that fact will become apparent when the pre-allocation is performed. As noted, this is of particular importance in a mission-critical system because the occurrence of such a dynamic failure during a dynamic allocation would likely cause an operating system to fail, and because such failures are non-deterministic in nature (and so cannot be predicted with any accuracy), they are especially dangerous in mission-critical systems.","In one embodiment of the present invention, a data structure is disclosed. Such a data structure includes a thread control block and a message. The thread control block is described by a first data structure and the message is described by a second data structure. Additionally, the first data structure includes the second data structure. Thus, a data structure according to the present invention combines a thread control block structure and a message structure to provide the various benefits described herein. The first data structure may be configured, for example, to store information used to control execution of a thread, with the second data structure configured to store a message. The first data structure may include, for example, a process control block pointer, processor information and stack information. Such a process control block pointer is used to point to a process control block.","In one embodiment of the present invention, a method of inter-task communication is disclosed. The method includes sending a message between a first task and a second task by performing a send operation (performed by the first task) and causing the second task to perform a receive operation. The send operation employs a thread control block\/message structure. In terms of architecture, the first task may act as a client task, with the second task acting as a server task.","In one aspect of the embodiment, the thread control block\/message structure may include, for example, a thread control block and a message. The thread control block can be described by a first data structure, with the message described by a second data structure and the first data structure included in the second data structure.","In another aspect of the embodiment, the thread control block\/message structure supports control of a thread within the second task. Additionally, the method further includes determining if the thread is queued to a thread queue of the second task and transferring the message from the first task and the second task. The transferring the message may include, for example, passing the message between the first task and the second task by performing a fast-path message copy if the thread is queued to the thread queue, and passing the message between the first task and the second task by performing a message copy (e.g., if the thread is not queued to the thread queue). Such a fast-path message copy may include, for example, copying the message from a memory space of the first task to a memory space of the second task. Such a message copy may include, for example, copying the message from the first task to the thread control block\/message structure, waiting for the thread to be queued to the thread queue, and copying the message from the thread control block\/message structure to the second task.","The foregoing is a summary and thus contains, by necessity, simplifications, generalizations and omissions of detail; consequently, those skilled in the art will appreciate that the summary is illustrative only and is not intended to be in any way limiting. Other aspects, inventive features, and advantages of the present invention, as defined solely by the claims, will become apparent in the non-limiting detailed description set forth below.","The following is intended to provide a detailed description of an example of the invention and should not be taken to be limiting of the invention itself. Rather, any number of variations may fall within the scope of the invention which is defined in the claims following the description.","Introduction","By combining a TCB's data structure and a message's data structure, an operating system employing an embodiment of the present invention can be constructed more simply and so operate more efficiently. An operating system incorporating an embodiment of the present invention is simplified because of simplified error handling, reduced indirection, fewer initial allocations and reduced allocation\/de-allocation operations, among other advantages, as explained previously.","Such an operating system's efficiency is also improved by the ability of a combined TCB\/message structure to control both thread execution and message passing. For example, upon the receipt of a TCB\/message structure, a task has all the control information necessary to perform information transfer and thread control. In one configuration, for example, queuing a TCB\/message structure to an I\/O channel (as described subsequently herein) of a task not only provides the task's thread with the requisite information, but also provides thread control information to the task, obviating the need for the task or operating system to coordinate message information with task information. The TCB\/message structure provides the task with the control information needed to access the information associated with the message. The TCB\/message structure also provides the task with thread control information, allowing the task to start (or re-start) execution of the given thread at the appropriate time. For example, the thread control information held in the TCB\/message structure can be used to cause execution of the thread to begin only after the message passing operation has completed. Thus, the task need only access one structure to acquire all the information necessary to both complete the message passing operation and control the thread associated therewith.","Moreover, because such combined structures are pre-allocated in an operating system according to the present invention, failure due to allocation errors is avoided. In other words, if there will not be enough memory to create a thread control block, that fact will become apparent when the pre-allocation is performed. As noted, this is of particular importance in a mission-critical system because the occurrence of such a dynamic failure during a dynamic allocation would likely cause an operating system to fail, and because such failures are non-deterministic in nature (and so cannot be predicted with any accuracy), they are especially dangerous in mission-critical systems. This aspect also avoids the operating system becoming deadlocked during I\/O operations, waiting for the allocation of a message that cannot be allocated due to a lack of memory space.","Such a structure does have its limitations, however. While the size of a combined TCB\/message structure may be slightly smaller than that of the two structures taken separately (depending on the implementation), the use of a combined TCB\/message structure will often consume more total memory, on average, than the use of separate structures. This is due to the pre-allocation (and concomitant lack of de-allocation) performed when using such a combined structure. As noted, if the preceding approach is taken to TCB allocation, the space occupied by the combined structure is not de-allocated.",{"@attributes":{"id":"P-00047","num":"00047"},"figref":["FIG. 1","FIG. 1","FIG. 1"],"b":["100","100","110","1","100","100"]},"It will be noted that the variable identifier \u201cN\u201d, as well as other such identifiers, are used in several instances in FIG.  and elsewhere to more simply designate the final element (e.g., task (N) and so on) of a series of related or similar elements (e.g., tasks ()-(N) and so on). The repeated use of such a variable identifier is not meant to imply a correlation between the sizes of such series of elements. The use of such a variable identifier does not require that each series of elements has the same number of elements as another series delimited by the same variable identifier. Rather, in each instance of use, the variable identified by \u201cN\u201d (or other variable identifier) may hold the same or a different value than other instances of the same variable identifier.",{"@attributes":{"id":"P-00049","num":"00049"},"figref":["FIG. 2","FIG. 2","FIG. 2"],"b":["210","220","230","240","100","250","260","100","270","280","290","100"]},"In an operating system architecture such as that shown in , drivers and other system components are not part of the microkernel. As a result, input\/output (I\/O) requests are passed to the drivers using a message passing system. The sender of the request calls the microkernel and the microkernel copies the request into the driver (or other task) and then switches user mode execution to that task to process the request. When processing of the request is complete, the microkernel copies any results back to the sender task and the user mode context is switched back to the sender task. The use of such a message passing system therefore enables drivers (e.g., disk driver ) to be moved from the microkernel to a task in user-space.","A microkernel such as microkernel  is simpler than traditional operating systems and even traditional microkernels because a substantial portion of the functionality normally associated with the operating system is moved into the user space. Microkernel  provides a shorter path through the kernel when executing kernel functions, and contains fewer kernel functions. As a result, the API of microkernel  is significantly simpler than comparable operating systems. Because microkernel  is smaller in size and provides shorter paths through the kernel, microkernel  is generally faster than a similar operating systems. This means, for example, that context switches can be performed more quickly, because there are fewer instructions to execute in a given execution path through the microkernel and so fewer instructions to execute to perform a context switch. In effect, there is less \u201cclutter\u201d for the executing thread to wade through.","Moreover, microkernel  is highly modular as a result of the use of user tasks to perform actions previously handled by modules within the operating system. This provides at least two benefits. First, functionality can easily be added (or removed) by simply executing (or not executing) the user-level task associated with that function. This allows for the customization of the system's architecture, an important benefit in embedded applications, for example. Another advantage of microkernel  is robustness. Because most of the system's components (software modules) are protected from each other, a fault in any one of the components cannot directly cause other components to fail. By this statement, it is meant that an operating system component cannot cause the failure of another such component, but such a failure may prevent the other component from operating (or operating properly). In a traditional operating system, a fault in any one system component is likely to cause the operating system to cease functioning, or at least to cease functioning correctly. As the quantity of system code continues to grow, the frequency of such events increases. Another reason for the robustness of microkernel  is that the construction of a component of microkernel  is often simpler than that of a traditional operating system. This characteristic is treated with particular importance in microkernel , and the effect is to allow subsystems that heretofore had been difficult to understand and maintain, to be coded in a clear and straightforward manner. Closely coupled with this characteristic is that the interfaces between the components are standardized in a way that allows them to be easily reconfigured.","Exemplary Directives","Directives defined in microkernel  may include, for example, a create thread directive (Create), a destroy thread directive (Destroy), a send message directive (Send), a receive message directive (Receive), a fetch data directive (Fetch), a store data directive (Store), and a reply directive (Reply). These directives allow for the manipulation of threads, the passing of messages, and the transfer of data.","The Create directive causes microkernel  to create a new thread of execution in the process of the calling thread. In one embodiment, the Create command clones all the qualities of the calling thread into the thread being created. Table 1 illustrates input parameters for the Create directive, while Table 2 illustrates output parameters for the Create directive (wherein \u201cipn\u201d indicates input parameter n, and \u201crpn\u201d indicates output parameter n).",{"@attributes":{"id":"P-d0e1760","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Input parameters for the Create directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Input Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["ip0","T_CREATE"]},{"entry":["ip1","Zero"]},{"entry":["ip2","A true\/false flag for running the new thread first"]},{"entry":["ip3","Initial execution address for new thread"]},{"entry":["ip4","Initial stack pointer for new thread"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-d0e1902","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Output parameters for the Create directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Result Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["rp1","The result code"]},{"entry":["rp2","The thread ID of the new thread"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The Destroy directive causes microkernel  to destroy the calling thread. Table 3 illustrates input parameters for the Destroy directive, while Table 4 illustrates output parameters for the Destroy directive.",{"@attributes":{"id":"P-d0e2016","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Input parameters for the Destroy directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"133pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Input Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["ip0","T_DESTROY"]},{"entry":["ip1","Zero"]},{"entry":["ip2","Zero"]},{"entry":["ip3","Zero"]},{"entry":["ip4","Zero"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-d0e2158","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 4"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Output parameters for the Destroy directive"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"133pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Result Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["rp1","The result code"]},{"entry":["rp2","Undefined"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"It will be noted that the output parameters for the Destroy directive are only returned if the Destroy directive fails (otherwise, if the Destroy directive is successful, the calling thread is destroyed and there is no thread to which results (or control) may be returned from the Destroy call).","The Send directive causes microkernel  to suspend the execution of the calling thread, initiate an input\/output (I\/O) operation and restart the calling thread once the I\/O operation has completed. In this manner, a message is sent by the calling thread. The calling thread sends the message (or causes a message to be sent (e.g., DMA, interrupt, or similar situations) to the intended thread, which then replies as to the outcome of the communication using a Reply directive. Table 5 illustrates Input parameters for the Send directive, while Table 6 illustrates output parameters for the Send directive.",{"@attributes":{"id":"P-d0e2277","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 5"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Input parameters for the Send directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Input Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["ip0","T_SEND"]},{"entry":["ip1","A pointer to an I\/O command structure (message)"]},{"entry":["ip2","Zero"]},{"entry":["ip3","Zero"]},{"entry":["ip4","Zero"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-d0e2419","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 6"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Output parameters for the Send directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"133pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Result Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["rp1","The result code"]},{"entry":["rp2","Undefined"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The Receive directive causes microkernel  to suspend the execution of the calling thread until an incoming I\/O operation is presented to one of the calling thread's process's I\/O channels (the abstraction that allows a task to receive messages from other tasks and other sources). By waiting for a thread control block to be queued to on of the calling thread's process's I\/O channels, a message is received by the calling thread. Table 7 illustrates input parameters for the Receive directive, while Table 8 illustrates output parameters for the Receive directive.",{"@attributes":{"id":"P-d0e2533","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 7"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Input parameters for the Receive directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Input Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["ip0","T_RECEIVE"]},{"entry":["ip1","A pointer to an I\/O command structure (message)"]},{"entry":["ip2","The input channel number"]},{"entry":["ip3","Zero"]},{"entry":["ip4","Zero"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-d0e2675","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 8"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Output parameters for the Receive directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"133pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Result Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["rp1","The result code"]},{"entry":["rp2","Undefined"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The Fetch directive causes microkernel  (or a stand-alone copy process, discussed subsequently) to copy any data sent to the receiver into a buffer in the caller's address space. Table 9 illustrates input parameters for the Fetch directive, while Table 10 illustrates output parameters for the Fetch directive.",{"@attributes":{"id":"P-d0e2789","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 9"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Input parameters for the Fetch directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Input Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["ip0","T_FETCH"]},{"entry":["ip1","A pointer to an I\/O command structure (message)"]},{"entry":["ip2","Zero"]},{"entry":["ip3","A buffer descriptor"]},{"entry":["ip4","Zero"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-d0e2931","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 10"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Output parameters for the Fetch directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Result Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["rp1","The result code"]},{"entry":["rp2","The length of the data copied to the Buffer descriptor"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The Store directive causes microkernel  (or a stand-alone copy process, discussed subsequently) to copy data to the I\/O sender's address space. Table 11 illustrates input parameters for the Store directive, while Table 12 illustrates output parameters for the Store directive.",{"@attributes":{"id":"P-d0e3045","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 11"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Input parameters for the Store directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Input Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["ip0","T_STORE"]},{"entry":["ip1","A pointer to an I\/O command structure (message)"]},{"entry":["ip2","Zero"]},{"entry":["ip3","Zero"]},{"entry":["ip4","A buffer descriptor pointer for the Store directive"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-d0e3187","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 12"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Output parameters for the Store directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Result Parameter","Description"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"rp1","The result code"]},{"entry":[{},"rp2","The length of the data copied to the buffer"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"The Reply directive causes microkernel  to pass reply status to the sender of a message. The calling thread is not blocked, and the sending thread is released for execution. Table 13 illustrates input parameters for the Reply directive, while Table 14 illustrates output parameters for the Reply directive.",{"@attributes":{"id":"P-d0e3313","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00013","num":"00013"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 13"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Input parameters for the Reply directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Input Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["ip0","T_REPLY"]},{"entry":["ip1","A pointer to an I\/O command structure (message)"]},{"entry":["ip2","Zero"]},{"entry":["ip3","Zero"]},{"entry":["ip4","Zero"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"P-d0e3455","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00014","num":"00014"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 14"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Output parameters for the Reply directive."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"133pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Result Parameter","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["rp1","The result code"]},{"entry":["rp2","Undefined"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The preceding directives allow tasks to effectively and efficiently transfer data, and manage threads and messages. The use of messages for inter-task communications and in supporting common operating system functionality are now described.","Message Passing Architecture",{"@attributes":{"id":"P-00065","num":"00065"},"figref":"FIG. 3","b":["300","300","100","100","300","100","300","305","310","315","320","325","330","305","310","315","320","325","330","320","325","320","325"]},{"@attributes":{"id":"P-00066","num":"00066"},"figref":"FIG. 4","b":["330","330","400","410","420","430","440","450","460","470","410","330","420","330","470","420","470","100"]},"For example, because optional in-line data  is of some fixed size (as is control data area ), the amount of data to be copied when sending or receiving a message is well known. If multiple word lengths are used, buffers used in the transfer are word-aligned and do not overlap. Thus, the copy operation devolves to simply copying a given number of words. This operation can be highly optimized, and so the time to move small messages can be made very short. The efficiency and speed of this operation can be further enhanced by copying the data directly from the sending task to the receiving task, where possible. These operations are discussed subsequently. In contrast, a larger amount of data would prove cumbersome (or even impossible) to transfer using optional in-line buffer , and so is preferably transferred using one of the data structures described with regard to ,  and .","Context field  is reserved for system use and indicates the operating system context in which DDR  exists. In the case where data is not stored in-line (i.e., within the data structure of DDR ), information with regard to the location of the data is required. This information is provided in base address field , offset field , and length field . The information within these fields depends upon the data structure being used to store the data being transferred. Various possible data structures are shown in , , and . Data stored in-line in DDR  is stored in optional in-line buffer . Optional in-line buffer  can be of any size appropriate to the processor and hardware architecture employed. The possible sizes of optional in-line buffer  are governed by environmental factors such as word size, memory page size and other such environmental factors. For example, optional in-line buffer  may be defined as having zero bytes, 32 bytes, 64 bytes, or 96 bytes of in-line data. Obviously, the buffer size of zero bytes would be used when simply passing commands or when using alternative data structures to transfer data, as previously noted. As will be apparent to one of skill in the art, some limit to the amount of data that optional in-line buffer  can hold should be provided because optional in-line buffer  must be made to fit into a thread control block (itself being of definite extent). Thus, optional in-line buffer  can be smaller than a given amount, but no larger, in order to predictably fit into a thread control block. This maximum is preferably on the order of tens of bytes.",{"@attributes":{"id":"P-00069","num":"00069"},"figref":"FIG. 4","b":["330","470","470","420","420","470","420","470","420","305","330","310","315","320","325","400","410","420","470","470","420"]},"In-line data field can also be configured to support multiple values, and so indicate the number of blocks of in-line data employed (e.g., 32, 34, 64, or 96 bytes, as represented by 1, 2, or 3, respectively, in the manner described previously). In the case of in-line data, base address field  and offset field  need not be used, as the location of the data is known (i.e., the data being in optional in-line buffer ). The value held in length field  represents the logical length of the data being transferred, and is normally used to indicate the extent of \u201clive\u201d (actual) data stored in optional in-line buffer  or elsewhere. Thus, length field  can be used in multiple circumstances when defining the storage of data associated with message .",{"@attributes":{"id":"P-00071","num":"00071"},"figref":["FIGS. 5","FIG. 5"],"b":["6","7","300","500","510","500","420","510","440","510","450","510","510","440","460","510","440","450","460","510","510","510"]},{"@attributes":{"id":"P-00072","num":"00072"},"figref":"FIG. 6","b":["600","610","610","620","1","630","1","420","440","610","630","1","640","1","440","610","640","1","630","1","620","1","640","1","630","1","450","640","1","640","1","630","1","460","640","1","640","1"]},{"@attributes":{"id":"P-00073","num":"00073"},"figref":"FIG. 7","b":["700","700","710","720","1","720","710","720","1","740","1","420","440","720","1","710","710","450","740","1","740","1","460","740","1"]},"Exemplary Operations Using A Message Passing Architecture",{"@attributes":{"id":"P-00075","num":"00075"},"figref":["FIG. 8A","FIG. 8A"],"b":["100","810","820","810","820","830","100","820","840","830","100","830","840","830","820","830","830","810","820"]},{"@attributes":{"id":"P-00076","num":"00076"},"figref":"FIG. 8B","b":["840","850","840","850","852","850","840","854","840","850","850","840"]},{"@attributes":{"id":"P-00077","num":"00077"},"figref":"FIG. 8C","b":["860","870","880"]},{"@attributes":{"id":"P-d0e4934","num":"00002"},"tables":{"@attributes":{"id":"TABLE-US-00015","num":"00015"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"\/*------------------------------------------------------------"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"The MSG and DDR structures"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"------------------------------------------------------------*\/"},{"entry":"#define DDRINLINEBUFSIZE \u200296"},{"entry":"#define DDR2INLINEBUFSIZE 64"},{"entry":"#define DDR1INLINEBUFSIZE 32"},{"entry":"#define DDR0INLINEBUFSIZE 0"},{"entry":"typedef struct mrb_t {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"short","r_fidOrMid;"]},{"entry":[{},"uchar","r_op;"]},{"entry":[{},"uchar","r_ctl;"]},{"entry":[{},"int","r_result;"]},{"entry":[{},"union {"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"49pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["*\/","int","x_arg;","\/* 1 32 bit args"]},{"entry":["*\/","int","x_args[2];","\/* 2 32 bit args"]},{"entry":["*\/","short","x_shortargs[4];","\/* 4 16 bit args"]},{"entry":["*\/","longlong","x_bigarg;","\/* 1 64 bit arg"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"} u;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"{ MRB;"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["#define r_arg","u.x_arg"]},{"entry":["#define r_args","u.x_args"]},{"entry":["#define r_bigarg","u.x_bigarg"]},{"entry":["#define r_shortargs","u.x_shortargs"]},{"entry":["#define MSGMAIN","\\"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"MRB","m_mrb;","\/* Input and Output"]},{"entry":[{},{},{},"parameters"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["*\/",{}]},{"entry":["#define m_fidOrMid","m_mrb.r_fidOrMid"]},{"entry":["#define m_op","m_mrb.r_op"]},{"entry":["#define m_ctl","m mrb.r_ctl"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/*--------------------------------------------*\/"},{"entry":"\/*\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003Macros\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003*\/"},{"entry":"\/*--------------------------------------------*\/"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["#define m_fid","m_fidOrMid"]},{"entry":["#define m_mid","m_fidOrMid"]},{"entry":["#define m_result","m_mrb.r_result"]},{"entry":["#define m_cid","m_mrb.r_result"]},{"entry":["#define m_args","m_mrb.r_args"]},{"entry":["#define m_arg","m_mrb.r_arg"]},{"entry":["#define m_bigarg","m_mrb.r_bigarg"]},{"entry":["#define m_shortargs","m_mrb.r_shortargs"]},{"entry":["#define m_type","m_ddr.d_type"]},{"entry":["#define m_inline","m_ddr.d_inline"]},{"entry":["#define m_pid","m_ddr.d_pid"]},{"entry":["#define m_base","m_ddr.d_base"]},{"entry":["#define m_offset","m_ddr.d_offset"]},{"entry":["#define m_length","m_ddr.d_length"]},{"entry":["#define m_inlinebuf","m_ddr.d_inlinebuf"]},{"entry":["#define DDRMAIN","\\"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"14pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"char","d_type;","\/* Type of DDR DT_XXXX","*\/"]},{"entry":"\\"},{"entry":[{},"char","d_inline;","\/* 0, 1, 2, or 3 groups of 32 bytes","*\/"]},{"entry":"\\"},{"entry":[{},"short","d_ctx;","\/* Context of DDR ** SYSTEM","*\/"]},{"entry":[{},{},{},"FIELD **"]},{"entry":"\\"},{"entry":[{},"void","*d_base;","\/* Ignored if d_inline != 0","*"]},{"entry":"\\"},{"entry":[{},"int","d_offset;","\/* Unused for inline or","*\/"]},{"entry":[{},{},{},"DT_VADDRESS"]},{"entry":"\\"},{"entry":[{},"int","d_length;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/*---------------------------------------------*\/"},{"entry":"\/* DDR and MSG with 96 bytes of inline data \u2003*\/"},{"entry":"\/*---------------------------------------------*\/"},{"entry":"typedef struct ddr_t3 {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DDRMAIN"]},{"entry":[{},"char \u2003d_inlinebuf[DDRINLINEBUFSIZE];"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} DDR, DDR3;"},{"entry":"typedef struct msg_t3 {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"MSGMAIN"]},{"entry":[{},"DDR \u2003m_ddr;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["} MSG3,","MSG;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/*---------------------------------------------*\/"},{"entry":"\/* DDR and MSG with 64 bytes of inline data \u2003*\/"},{"entry":"\/*---------------------------------------------*\/"},{"entry":"typedef struct ddr_t2 {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DDRMAIN"]},{"entry":[{},"char \u2003d_inlinebuf[DDR2INLINEBUFSIZE];"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} DDR2;"},{"entry":"typedef struct msg_t2 {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"MSGMAIN"]},{"entry":[{},"DDR2 \u2003m_ddr;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} MSG2;"},{"entry":"\/*---------------------------------------------*\/"},{"entry":"\/* DDR and MSG with 32 bytes of inline data \u2003*\/"},{"entry":"\/*---------------------------------------------*\/"},{"entry":"typedef struct ddr_t1 {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DDRMAIN"]},{"entry":[{},"char \u2003d_inlinebuf[DDR1INLINEBUFSIZE];"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} DDR1;"},{"entry":"typedef struct msg_t1 {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"MSGMAIN"]},{"entry":[{},"DDR1 \u2003\u2003m_ddr;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} MSG1;"},{"entry":"\/*---------------------------------------------*\/"},{"entry":"\/* DDR and MSG with 0 bytes of inline data \u2002\u2003*\/"},{"entry":"\/*---------------------------------------------*\/"},{"entry":"typedef struct ddr_t0 {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DDRMAIN"]},{"entry":[{},"char \u2003d_inlinebuf[DDR2INLINEBUFSIZE];"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} DDR0;"},{"entry":"typedef struct msg_t0 {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"MSGMAIN"]},{"entry":[{},"DDR0 \u2003\u2003m_ddr;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} MSG0;"},{"entry":"\/*---------------------------------------------------------------"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"TCB Structure"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"---------------------------------------------------------------*\/"},{"entry":"typedef struct tcb_t {"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"LEB","t_list;"]},{"entry":[{},"int","t_index;"]},{"entry":[{},"int","t_type;"]},{"entry":[{},"int","t_inputP3;"]},{"entry":[{},"struct cpu_t","*t_copyTaskCpu;"]},{"entry":[{},"struct cpu_t","*t_cpu;"]},{"entry":[{},"struct pcb_t","*t_pcb;"]},{"entry":[{},"struct pcb_t","*t_queuedTo;"]},{"entry":[{},"int","t_state;"]},{"entry":[{},"int","t_dirtyRegs;"]},{"entry":[{},"int","t_priority;"]},{"entry":[{},"int","t_lastPrioritySetting;"]},{"entry":[{},"int","t_semaphore;"]},{"entry":[{},"boolean","t_hasLockedRegs;"]},{"entry":[{},"CLK","t_clockBlock;"]},{"entry":[{},"boolean","t_swappingWasEnabled;"]},{"entry":[{},"int","t_handler;"]},{"entry":[{},"MSG","t_message;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"char","t_stackEnd[KERNELSTACKSIZE-"]},{"entry":[{},{},"sizeof(TRP)];"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"TRP","t_trapframe;"]},{"entry":[{},"int","t_kstackStart;"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"} TCB;"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"As can be seen in the structure definitions above, a message structure (of type MSG) is included as part of each thread control block structure (of type TCB). As can also be seen in the structure definitions above, a combined TCB\/message structure according to an embodiment of the present invention includes both thread information and message information. Access to both thread information and message information is simplified because a level of indirection is avoided through the use of a combined TCB\/message structure. The thread information relates mostly to the control of the particular thread in question, and includes information such as information regarding the process and CPU on which the thread is running, the thread's state, the thread's environment, register information, FPU information, and stack frame and trap frame information. The message information relates mostly to the transfer of data to or from the particular thread in question, and includes information such as type information (indicating the data structured used to transfer data to the receiving task), in-line data information (as to whether the data being transferred (if any) is in-line, and optionally the size of the data field used), context information, base address information, offset information and length information. Other information and structures can be supported by a combined TCB\/message structure according to embodiments of the present invention, as evidenced by the above program listing. As will be apparent to one of skill in the art, the actual structure definition of the message could be included in the thread control block structure (i.e., the code listing could be structured such that the thread control block's definition includes the message structure's definition), but this would make reading the listing of the thread control block's structure definition unnecessarily complicated. By integrating the message structure into the thread control block structure, an operating system benefits from the advantages of a combined TCB\/message structure according to an embodiment of the present invention previously enumerated.",{"@attributes":{"id":"P-00079","num":"00079"},"figref":["FIG. 9","FIGS. 3-7"],"b":["900","910","920","900","300","910"]},"Often, several largely independent tasks must be performed that do not need to be serialized (i.e., they do not need to be executed seriatim, and so can be executed concurrently). For instance, a database server may process numerous unrelated client requests. Because these requests need not be serviced in a particular order, they may be treated as independent execution units, which in principle could be executed in parallel. Such an application would perform better if the processing system provided mechanisms for concurrent execution of the sub-tasks.","Traditional systems often implement such programs using multiple processes. For example, most server applications have a listener thread that waits for client requests. When a request arrives, the listener forks a new process to service the request. Since servicing of the request often involves I\/O operations that may block the process, this approach can yield some concurrency benefits even on uniprocessor systems.","Using multiple processes in an application presents certain disadvantages. Creating all these processes adds substantial overhead, since forking a new process is usually an expensive system call. Additional work is required to dispatch processes to different machines or processors, pass information between these processes, wait for their completion, and gather the results. Finally, such systems often have no appropriate frameworks for sharing certain resources, e.g., network connections. Such a model is justified only if the benefits of concurrency offset the cost of creating and managing multiple processes.","These examples serve primarily to underscore the inadequacies of the process abstraction and the need for better facilities for concurrent computation. The concept of a fairly independent computational unit that is part of the total processing work of an application is thus of some importance. These units have relatively few interactions with one another and hence low synchronization requirements. An application may contain one or more such units. The thread abstraction represents such a single computational unit.","Thus, by using the thread abstraction, a process becomes a compound entity that an be divided into two components\u2014a set of threads and a collection of resources. The thread is a dynamic object that represents a control point in the process and that executes a sequence of instructions. The resources, which include an address space, open files, user credentials, quotas, and so on, may be shared by all threads in the process, or may be defined on a thread-by-thread basis, or a combination thereof. In addition, each thread may have its private objects, such as a program counter, a stack, and a register context. The traditional process has a single thread of execution. Multithreaded systems extend this concept by allowing more than one thread of execution in each process. Several different types of threads, each having different properties and uses, may be defined. Types of threads include kernel threads and user threads.","A kernel thread need not be associated with a user process, and is created and destroyed as needed by the kernel. A kernel thread is normally responsible for executing a specific function. Each kernel thread shares the kernel code (also referred to as kernel text) and global data, and has its own kernel stack. Kernel threads can be independently scheduled and can use standard synchronization mechanisms of the kernel. As an example, kernel threads are useful for performing operations such as asynchronous I\/O. In such a scenario, the kernel can simply create a new thread to handle each such request instead of providing special asynchronous I\/O mechanisms. The request is handled synchronously by the thread, but appears asynchronous to the rest of the kernel. Kernel threads may also be used to handle interrupts.","Kernel threads are relatively inexpensive to create and use in an operating system according to the present invention. (Often, in other operating systems such kernel threads are very expensive to create.) The only resources they use are the kernel stack and an area to save the register context when not running (a data structure to hold scheduling and synchronization information is also normally required). Context switching between kernel threads is also quick, since the memory mapping does not have to be altered.","It is also possible to provide the thread abstraction at the user level. This may be accomplished, for example, through the implementation of user libraries or via support by the operating system. Such libraries normally provide various directives for creating, synchronizing, scheduling, and managing threads without special assistance from the kernel. The implementation of user threads using a user library is possible because the user-level context of a thread can be saved and restored without kernel intervention. Each user thread may have, for example, its own user stack, an area to save user-level register context, and other state information. The library schedules and switches context between user threads by saving the current thread's stack and registers, then loading those of the newly scheduled one. The kernel retains the responsibility for process switching, because it alone has the privilege to modify the memory management registers.","Alternatively, support for user threads may be provided by the kernel. In that case, the directives are supported as calls to the operating system (as described herein, a microkernel). The number and variety of thread-related system calls (directives) can vary, but in a microkernel according to one embodiment of the present invention, thread manipulation directives are preferably limited to the Create directive and the Destroy directive. By so limiting the thread manipulation directives, microkernel  is simplified and its size minimized, providing the aforementioned benefits.","Threads have several benefits. For example, the use of threads provides a more natural way of programming many applications (e.g., windowing systems). Threads can also provide a synchronous programming paradigm by hiding the complexities of asynchronous operations in the threads library or operating system. The greatest advantage of threads is the improvement in performance such a paradigm provides. Threads are extremely lightweight and consume little or no kernel resources, requiring much less time for creation, destruction, and synchronization in an operating system according to the present invention.",{"@attributes":{"id":"P-00090","num":"00090"},"figref":["FIG. 10","FIG. 9","FIG. 10"],"b":["900","810","820","900","910","920","820","920","910","820","910","820","1010","1","820","1010","1","820","810"]},"Also illustrated in  are server thread queues ()-(N) which allow the queuing of threads that are to be executed as part of the operation of server . In the situation depicted in , there are no threads queued to server thread queues ()-(N), and so no threads are available to consume message  carried by a thread control block in . Thread control block  thus waits on I\/O channel () for a thread to be queued to server thread queue (). It will be noted that each of I\/O channels ()-(N) preferably correspond to one of server thread queues ()-(N), the simplest scenario (used herein) being a one-for-one correspondence (i.e., I\/O channel () corresponding to server thread queue () and so on).",{"@attributes":{"id":"P-00092","num":"00092"},"figref":"FIG. 11","b":["1100","1020","1","1100","1100","1100","100","910","1010","1","1100","1020","1"]},{"@attributes":{"id":"P-00093","num":"00093"},"figref":"FIG. 12A","b":["900","810","820","100","1100","920","910","820","1200","1200","1100","1200","1200","1210","810","820","810","1210","910","1210","810","810"]},{"@attributes":{"id":"P-00094","num":"00094"},"figref":"FIG. 12B","b":["1250","810","820","1260","810","820","1250","810","820","1270","100","1270","1260","810","820","1270","820","1270","1010","1","1280","1020","1","1270","1010","1","1270","1250","810","820","820","1260","1260","1290","810","820","810","1290","1270","810","1290","810"]},{"@attributes":{"id":"P-00095","num":"00095"},"figref":["FIG. 13","FIGS. 8-11","FIGS. 12A and 12B"],"b":["810","820"]},"The process of transferring one or more messages between client  and server  begins with the client performing a Send operation (step ). Among the actions performed in such an operation is the creation of a message in the client task. This corresponds to the situation depicted in , wherein the creation of message  is depicted. Also, the message is copied into the thread control block of the client task, which is assumed to have been created prior to this operation. This corresponds to the copying of message  into thread control block , resulting in message  within thread control block . The thread control block is then queued to one of the input\/output (I\/O) channels of the intended server task. This corresponds to the situation depicted in , wherein thread control block  (including message ) is queued to one of I\/O channels ()-(N) (as shown in , thread control block  is queued to the first of I\/O channels ()-(N), I\/O channel ()).","It must then be determined whether a thread is queued to the server thread queue corresponding to the I\/O channel to which the thread control block has been queued (step ). If no thread is queued to the corresponding server thread queue, the thread control block must wait for the requisite thread to be queued to the corresponding server thread queue. At this point, the message is copied into a thread control block to await the queuing of the requisite thread (step ). The message and thread control block then await the queuing of the requisite thread (step ). Once the requisite thread is queued, the message is copied from the thread control block to the server process (step ). This is the situation depicted in , and mandates the operations just described. Such a situation is also depicted by , wherein thread control block  must wait for a thread to be queued to a corresponding one of server thread queues ()(N). The queuing of a thread to the corresponding server thread queue is depicted in  by the queuing of thread  to the first of server thread queues ( (N) (i.e., server thread queue ()).","While it can be seen that I\/O channel () and server thread queue () correspond to one another and are depicted as having only a single thread control block and a single thread queued thereto, respectively, one of skill in the art will realize that multiple threads and thread control blocks can be queued to one of the server thread queues and I\/O channels, respectively. In such a scenario, the server task controls the matching of one or more of the queued (or to be queued) thread control blocks to one or more of the queued (or to be queued) threads. Alternatively, the control of the matching of thread control blocks and threads can be handled by the microkernel, or by some other mechanism.","Alternatively, the requisite thread control block may already be queued to the corresponding I\/O channel. If such is the case, the message may be copied directly from the client's memory space to the server's memory space (step ). This situation is illustrated in , where message  is copied from the memory space of client  to the memory space of server , appearing as message . It will be noted that the thread (e.g., thread  (or thread )) need not block waiting for a message (e.g., thread control block  (or thread control block )) in such a scenario. Included in these operations is the recognition of the thread control block by the server thread. As is also illustrated in , thread control block  and thread  are caused by server  to recognize one another.","Once the recognition has been performed and the thread unblocked (i.e., started, as depicted by step ), the message held in the thread control block is copied into the server task. This is depicted in  by the copying of message  from thread control block  into server  as message . This is depicted in  by the copying of message  from client  into server  as message . The server task then processes the information in the received message (step ). In response to the processing of the information in the received message, the server task sends a reply to the client sending the original message (i.e., client ; step ). This corresponds in  to the passing of reply  from server  to client , and in  to the passing of reply  from server  to client . Once the server task has replied to the client task, the message-passing operation is complete.","It will be understood that the processes illustrated in , B and  may also be employed based on whether or not both tasks (client  and server ) are in memory (assuming that some sort of swapping is implemented by microkernel ). The question of whether both tasks are in memory actually focuses on the task receiving the message, because the task sending the message must be in memory to be able to send the message. Because the fast-path message copy process of  is faster than that of , it is preferable to use the fast-path message copy process, if possible. If the receiving task is not in memory, it is normally not possible to use the fast-path message copy process. Moreover, if the data cannot be copied using the fast-path message copy process due to the amount of data, the method described in , employing a copy process, may be used. It will be noted that the decision to use one or the other of these methods can be made dynamically, based on the current status of the tasks involved.","As noted,  depicts a flow diagram of the operation of a method for passing a message from a client task to a server task in an operating system architecture according to an embodiment of the present invention. It is appreciated that operations discussed herein may consist of directly entered commands by a computer system user or by steps executed by application specific hardware modules, but the preferred embodiment includes steps executed by software modules. The functionality of steps referred to herein may correspond to the functionality of modules or portions of modules.","The operations referred to herein may be modules or portions of modules (e.g., software, firmware or hardware modules). For example, although the described embodiment includes software modules and\/or includes manually entered user commands, the various exemplary modules may be application specific hardware modules. The software modules discussed herein may include script, batch or other executable files, or combinations and\/or portions of such files. The software modules may include a computer program or subroutines thereof encoded on computer-readable media.","Additionally, those skilled in the art will recognize that the boundaries between modules are merely illustrative and alternative embodiments may merge modules or impose an alternative decomposition of functionality of modules. For example, the modules discussed herein may be decomposed into submodules to be executed as multiple computer processes. Moreover, alternative embodiments may combine multiple instances of a particular module or submodule. Furthermore, those skilled in the art will recognize that the operations described in exemplary embodiment are for illustration only. Operations may be combined or the functionality of the operations may be distributed in additional operations in accordance with the invention.","Each of the blocks of  may be executed by a module (e.g., a software module) or a portion of a module or a computer system user. Thus, the above described method, the operations thereof and modules therefor may be executed on a computer system configured to execute the operations of the method and\/or may be executed from computer-readable media. The method may be embodied in a machine-readable and\/or computer-readable medium for configuring a computer system to execute the method. Thus, the software modules may be stored within and\/or transmitted to a computer system memory to configure the computer system to perform the functions of the module. The preceding discussion is equally applicable to the other flow diagrams described herein.","The software modules described herein may be received by a computer system, for example, from computer readable media. The computer readable media may be permanently, removably or remotely coupled to the computer system. The computer readable media may non-exclusively include, for example, any number of the following: magnetic storage media including disk and tape storage media; optical storage media such as compact disk media (e.g., CD-ROM, CD-R, and the like) and digital video disk storage media; nonvolatile memory storage memory including semiconductor-based memory units such as FLASH memory, EEPROM, EPROM, ROM or application specific integrated circuits; volatile storage media including registers, buffers or caches, main memory, RAM, and the like; and data transmission media including computer network, point-to-point telecommunication, and carrier wave transmission media In a UNIX-based embodiment, the software modules may be embodied in a file which may be a device, a terminal, a local or remote file, a socket, a network connection, a signal, or other expedient of communication or state change. Other new and various types of computer-readable media may be used to store and\/or transmit the software modules discussed herein.",{"@attributes":{"id":"P-00107","num":"00107"},"figref":["FIG. 14A","FIG. 14A"],"b":["1400","100","1410","1010","1","1410","1420","1400","1430","1440","1020","1","1020","1","1410","1440","1020","1","100","1430","1430","820","1410","1420","1010","1","1440","1020","1","1430","100","820"]},"As noted, a thread control block is reserved especially for the given interrupt. In fact, thread control blocks are normally pre-allocated (i.e., pre-reserved) for all I\/O operations. This prevents operations requiring the use of a control block from failing due to a lack of memory and also allows the allocation size of control block space to be fixed. Moreover, I\/O operations can be performed as real time operations because the resources needed for I\/O are allocated at the time of thread creation. Alternatively, thread control block  need not actually exist. Thread control block  and dummy message  are therefore shown in dashed lines in FIG. A. In such a scenario, thread  is simply notified of the availability of message , once interrupt  is received and processed by microkernel . What is desired is that thread  react to the interrupt. Thus, thread  is simply unblocked, without need for the creation of thread control block .",{"@attributes":{"id":"P-00109","num":"00109"},"figref":["FIG. 14B","FIG. 14A. A","FIG. 14A","FIG. 14A"],"b":["1410","1420","1450","1410","1020","1","1460","1470","100"]},"Once a thread is queued to a corresponding one of the server thread queues (thread  of , which is queued to the first of server thread queues () (N)), the server task causes the recognition of the queued thread control block by the now-queued thread (step ). This corresponds to the recognition of thread control block  by thread  under the control of server . Unlike the process depicted in , the process of  now copies a message indicating the receipt of an interrupt (e.g., interrupt ) from the microkernel into the server task's memory space (step ). This corresponds to the copying of interrupt information from microkernel  to message  in the memory space of server . As before, once the message is received by the server task, the server task processes the message's information (step ).",{"@attributes":{"id":"P-00111","num":"00111"},"figref":["FIG. 15","FIG. 15","FIGS. 9-13"],"b":["810","820","470","1500","810","820","100","1505","820","1510","820","1515","1520","810","820","1530","1500","810","820","820","810","100","1520","1530","1535"]},"As can be seen, the process of fetching data from a client to a server is similar to that of simply sending a message with in-line data. However, because the message in the thread control block carries no data, only information on how to access the data, the process of accessing the data (e.g., either copying the data into the server task's memory space or simply accessing the data in-place) differs slightly. Because a large amount of data may be transferred using such techniques, alternative methods for transferring the data may also be required.","Should the amount of data to be transferred from buffer  to buffer  be greater than an amount determined to be appropriate for transfers using the facilities of microkernel , a copy process  is enlisted to offload the data transfer responsibilities for this transfer from microkernel . The provision of a task such as copy process  to facilitate such transfers is important to the efficient operation of microkernel . Because microkernel  is preferably non-preemptible (for reasons of efficiency and simplicity), long data transfers made by microkernel  can interfere with the servicing of other threads, the servicing of interrupts and other such processes. Long data transfers can interfere with such processes because, if microkernel  is non-preemptible, copying by microkernel  is also non-preemptible. Thus, all other processes must wait for copying to complete before they can expect to be run. By offloading the data transfer responsibilities for a long transfer from microkernel  to copy process , which is preemptible, copying a large amount of data does not necessarily appropriate long, unbroken stretches of processing time. This allows for the recognition of system events, execution of other processes, and the like.",{"@attributes":{"id":"P-00114","num":"00114"},"figref":["FIG. 16","FIGS. 9-13","FIG. 16","FIG. 16"],"b":["470","810","1600","820","1605","820","1610","820","810","1620","1600","1621","1630","1625","100","1620","1630","1540","100","100","100","100"]},"If supported by the given embodiment of the present invention, the process of storing data from a server to a client is similar to that of simply sending a message with in-line data. However, because the message in the thread control block carries no data, only information on how to provide the data, the process of accessing the data (e.g., either copying the data into the client task's memory space or simply allowing in-place access to the data) differs slightly. As noted, alternative methods for transferring the data (e.g., the use of a copy process) may also be required due to the need to transfer large amounts of data",{"@attributes":{"id":"P-00116","num":"00116"},"figref":["FIG. 17","FIG. 17"],"b":["1700","810","820","820","1710","1700","810","820","1700","810","820","1715","820","820","1720","820","1740","1720","1700","1725","810","15","16","1720","810","1720","820"]},"Again, the process of storing data from a peripheral to a client and fetching data from a client to a peripheral are similar to that of simply sending a message with in-line data. However, because the data is coming from\/going to a peripheral, the process of accessing the data differs slightly. Instead of copy the data from\/to a server task, the data is copied from\/to the peripheral. As noted, alternative methods for transferring the data (e.g., the use of a copy process) may also be required due to the need to transfer large amounts of data.","While the invention has been described with reference to various embodiments, it will be understood that these embodiments are illustrative and that the scope of the invention is not limited to them. Many variations, modifications, additions, and improvements of the embodiments described are possible.","For example, an operating system according to the present invention may support several different hardware configurations. Such an operating system may be run on a uniprocessor system, by executing microkernel  and tasks ()-(N) on a single processor. Alternatively, in a symmetrical multi-processor (SMP) environment, certain of tasks ()-(N) may be executed on other of the SMP processors. These tasks can be bound to a given one of the processors, or may be migrated from one processor to another. In such a scenario, messages can be sent from a task on one processor to a task on another processor.","Carrying the concept a step further, microkernel  can act as a network operating system, residing on a computer connected to a network. One or more of tasks ()-(N) can then be executed on other of the computers connected to the network. In this case, messages are passed from one task to another task over the network, under the control of the network operating system (i.e., microkernel ). In like fashion, data transfers between tasks also occur over the network. The ability of microkernel to easily scale from a uniprocessor system, to an SMP system, to a number of networked computers demonstrates the flexibility of such an approach.","While particular embodiments of the present invention have been shown and described, it will be obvious to those skilled in the art that, based upon the teachings herein, changes and modifications may be made without departing from this invention and its broader aspects and, therefore, the appended claims are to encompass within their scope all such changes and modifications as are within the true spirit and scope of this invention. Furthermore, it is to be understood that the invention is solely defined by the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention may be better understood, and its numerous objects, features, and advantages made apparent to those skilled in the art by referencing the accompanying drawings.",{"@attributes":{"id":"P-00020","num":"00020"},"figref":"FIG. 1"},{"@attributes":{"id":"P-00021","num":"00021"},"figref":"FIG. 2"},{"@attributes":{"id":"P-00022","num":"00022"},"figref":"FIG. 3"},{"@attributes":{"id":"P-00023","num":"00023"},"figref":"FIG. 4"},{"@attributes":{"id":"P-00024","num":"00024"},"figref":"FIG. 5"},{"@attributes":{"id":"P-00025","num":"00025"},"figref":"FIG. 6"},{"@attributes":{"id":"P-00026","num":"00026"},"figref":"FIG. 7"},{"@attributes":{"id":"P-00027","num":"00027"},"figref":"FIG. 8A"},{"@attributes":{"id":"P-00028","num":"00028"},"figref":"FIG. 8B"},{"@attributes":{"id":"P-00029","num":"00029"},"figref":"FIG. 8C"},{"@attributes":{"id":"P-00030","num":"00030"},"figref":"FIG. 9","b":"8"},{"@attributes":{"id":"P-00031","num":"00031"},"figref":"FIG. 10","b":"8"},{"@attributes":{"id":"P-00032","num":"00032"},"figref":"FIG. 11","b":"8"},{"@attributes":{"id":"P-00033","num":"00033"},"figref":"FIG. 12A","b":"8"},{"@attributes":{"id":"P-00034","num":"00034"},"figref":"FIG. 12B"},{"@attributes":{"id":"P-00035","num":"00035"},"figref":["FIG. 13","FIGS. 12A and 12B"]},{"@attributes":{"id":"P-00036","num":"00036"},"figref":"FIG. 14A"},{"@attributes":{"id":"P-00037","num":"00037"},"figref":"FIG. 14B"},{"@attributes":{"id":"P-00038","num":"00038"},"figref":"FIG. 15"},{"@attributes":{"id":"P-00039","num":"00039"},"figref":"FIG. 16"},{"@attributes":{"id":"P-00040","num":"00040"},"figref":"FIG. 17"}]},"DETDESC":[{},{}]}
