---
title: Product setup sharing for multiple inspection systems
abstract: An inspection tool includes a camera for obtaining images of a wafer and a controller configured for performing light source flat field correction, optical image warping correction, and optical image scale correction of the images. In operation, separate inspection tools are calibrated separately to obtain a characteristic response with respect to imaging and/or illumination for each such inspection tool. A standard target is then imaged by each inspection tool and the response of each of the inspection tools is normalized to ensure uniformity of the output of each inspection tool with respect to the other inspection tools.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08045788&OS=08045788&RS=08045788
owner: August Technology Corp.
number: 08045788
owner_city: Bloomington
owner_country: US
publication_date: 20040714
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application claims the benefit of U.S. Provisional Application Ser. No. 60\/487,152, filed Jul. 14, 2003.","1. Technical Field","The present invention relates to product setup sharing prior to and during inspection.","2. Background Information","Over the past several decades, the semiconductor has exponentially grown in use and popularity. The semiconductor has in effect revolutionized society by introducing computers, electronic advances, and generally revolutionizing many previously difficult, expensive and\/or time consuming mechanical processes into simplistic and quick electronic processes. This boom in semiconductors has been fueled by an insatiable desire by business and individuals for computers and electronics, and more particularly, faster, more advanced computers and electronics whether it be on an assembly line, on test equipment in a lab, on the personal computer at one's desk, or in the home electronics and toys.","The manufacturers of semiconductors have made vast improvements in end product quality, speed and performance as well as in manufacturing process quality, speed and performance. However, there continues to be demand for faster, more reliable and higher performing semiconductors.","Users of inspection equipment continue to demand better defect data thereby requiring better camera and illumination matching. This is further the case from system to system thereby assuring better correlation between inspection systems, such that the correlation in inspection results is very high.","It is known that cameras that are installed on inspection equipment are pre-set with vendor default settings for camera gain and offset. However, this often results in large variations between systems. In addition, light sources, whether halogen or strobe, can have large variations in light output (photons) for a given applied voltage. Furthermore, optics in each system have unique distortions and light transmission efficiencies that are field of view dependent. The result is that tool to tool correlation is in many cases unacceptable to the user.","As a result, inspection system users desire that all inspection systems produce the same image in regards to contrast, scale, warp, histogram, sharpness, etc. for a sample placed on two or more systems. This will best occur using product setup sharing.","One embodiment of the present invention provides an inspection tool. The inspection tool comprises a camera for obtaining images of a wafer and a controller configured for performing light source flat field correction, optical image warping correction, and optical image scale correction of the images.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 1","b":["100","100","102","104","106","108","112","110","114","116","118","120","122","124","100"]},"Camera  is used for visual inputting of good die during training and for visual inspection of other unknown quality die during inspection. The camera may be any type of camera capable of high resolution inspection. An example of such a camera is a charge-coupled device (CCD) inspection camera used to capture die or other images during defect analysis. In one embodiment, camera  is a high resolution CCD camera that provides high resolution gray scale images for inspection.","Robot  provides a wafer to test plate  for inspection. Wafer alignment device  aligns each and every wafer at the same x, y, and \u03b8 location or x, y, z, and \u03b8 location. Camera  is focused on wafer test plate  for inspecting wafers.","Computer controlled illumination, including inspection light source , is integrated into and with inspection camera  and optics to complete the wafer imaging process. Alternatively, the illumination system may be coupled to camera  and optics so long as the illumination system works in conjunction with camera . In a strobing environment, the illumination must occur simultaneously or substantially simultaneously with camera  shuttering, which is in one example a high speed electronic shuttering mechanism. Alternatively, in a non-strobing environment, the illumination is typically continuous or as needed. Illumination may be by any known illumination means such as high intensity lights, lasers, florescent lights, arc discharge lamps, incandescent lamps, etc.","Parameter input device  is for inputting parameters and other constraints or information. These parameters, constraints, and information include sensitivity parameters, geometry, die sizes, die shape, die pitch, number of rows, number of columns, etc. It is contemplated that any form of input device will suffice, including a keyboard, mouse, scanner, infrared or radio frequency transmitter and receiver, etc.","Display  is for displaying the view being seen by camera  presently or at any previously saved period. The display is preferably a color monitor or other device for displaying a color display format of the image being viewed by camera  for the user's viewing, or alternatively viewing an image saved in memory. In addition, the system parameters display  is also available for displaying other information as desired by the user, such as system parameters.","Computer system or controller  or other computer device having processing and memory capabilities is for saving the inputted good die, developing a model therefrom, and comparing or analyzing other die in comparison to the model based upon defect filtering and sensitivity parameters to determine if defects exist. Computer system  also saves flat field correction data, optical image warping correction data, and optical image scale correction data, which are described below. In addition, computer system  is used to perform all other mathematical and statistical functions as well as all operations. In one embodiment, computer system  is of a parallel processing DSP environment.","Semiconductor inspection system , according to one embodiment, is camera and illumination matched, such that semiconductor inspection systems that are camera and illumination matched to semiconductor inspection system  provide substantially the same camera output in response to substantially the same camera input and inspection light source setting. Camera and illumination matching involves matching camera gain and offset settings and illumination light source settings of multiple semiconductor inspection systems. Camera and illumination matching is described in further detail in U.S. patent application Ser. No. 10\/890,862 entitled \u201cCAMERA AND ILLUMINATION MATCHING FOR INSPECTION SYSTEM\u201d filed Jul. 14, 2004, which is incorporated herein by reference.","In addition, semiconductor inspection system , according to one embodiment, is light source flat field corrected, optical image warping corrected, and optical image scale corrected, such that semiconductor inspection systems that have also been light source flat field corrected, optical image warping corrected, and optical image scale corrected provide substantially the same inspection image in response to substantially the same inspection target. By performing light source flat field correction, optical image warping correction, and optical image scale correction, a first semiconductor inspection system can be trained for inspecting a product and the training information can be loaded onto a second semiconductor inspection system for inspecting the product without having to train the second semiconductor inspection system. This sharing of training information by two or more corrected inspection systems is termed product setup sharing.","The product setup sharing method of one embodiment of the present invention occurs via the use of mathematical techniques or algorithms used to reduce differences in digital images such as those acquired by semiconductor inspection system . In general, the method according to one embodiment is as follows: Two or more semiconductor inspection systems are calibrated for camera response and illumination matching. Then, for light source flat field correction, a target of uniform reflectance is placed in each semiconductor inspection system, such as semiconductor inspection system . Each semiconductor inspection system locates the target in the x, y, and z directions. At the desired illumination setting of the light source, such as light source , the average gray value of the charge-coupled device (CCD) array or other sensor array of the camera, such as camera , is computed. At each pixel location of the sensor array, a floating-point factor (normalizing factor) is computed by dividing the average gray value of the sensor array by the gray value at that pixel. The normalizing factor computed at each pixel is then multiplied to each image being inspected at the proper pixel location. Normalized pixel gain and offset values can also be supplied by the camera matching equipment to correct for individual CCD array pixels. The above method corrects for non-uniformity in the light source, such as light source .","The following steps measure and correct for optical scale and optical distortion (warping): (1) A target with objects of known size and location are placed in semiconductor inspection system ; (2) semiconductor inspection system  locates the target in the x, y, and z directions and finds the location of each object on the target; (3) the optical image center, which is the center of the optical distortion field, is found; (4) using the found object locations on the target and real world locations of the objects on the target, the optical scale and optical distortion are measured; and (5) interpolation regions are defined for the found objects on the target, the image distortion is corrected, and the image is scaled to a desired value.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 2","b":["170","170","100","100","170","120","104","106","174","108","120","106","180","104","182","174","108","104","106","174","120","176","106","180","106"]},"Light  reflected from target  impinges on the CCD array or other sensor array of camera . Controller  receives the image data from camera  through communication link , including the gray values of the individual pixels of the CCD array of camera . Controller  computes the average gray value for the CCD array of camera  from the gray values of the individual pixels of the CCD array of camera .","In one embodiment, controller  includes a memory  for storing a flat field correction algorithm , a warping algorithm , a scaling algorithm , normalizing factors , and warping and scale parameters . To best understand the algorithms, the following definitions are used. Optical Image Center or Image Center (IC) is the center of the optical system that can and most the time is different than the center of the camera CCD array. The center of the optical system is defined as the x, y pixel location that minimizes nonlinear distortion to a least squares error fit. The center of the optical system is used as the origin of image scale adjustments and image warping corrections.","Optical Image Warping (OIW) is defined as a nonlinear optical distortion, which most of the time is located in the corners of an image. OIW is an error that is localized and may affect only portions of an image that may or may not be used in the inspection.","Optical Image Scale (OIS) is defined as the ratio of pixels to real world dimensions, such as microns. The OIS is a function of the CCD array and optics and a typical ratio might be 5 microns\/pixel for a 1.25 magnification objective. OIS affects the complete image across its field of view.","Light Flat Fielding (FF) is defined as the amount of non-uniform light response across the field of view and can be a function of the light source (i.e., bulb) optics, and CCD array response. FF is an error that is localized and may affect only portions of an image that may or may not be used in the inspection.","Laplacian of Gaussian Filter (LOG) is a 2nd derivative edge detection filter that uses its zero crossing property to find the edge location.","Zero Cross Detect (ZCD) is a filter that finds the zero crossings in the LOG filter output, which are the edge locations.","Calibration Grid Target (CGT) is a plate of glass fabricated with two different regions of light reflectivity. One region of reflectivity contains objects, such as circles or squares, that have known feature sizes and locations. The CGT is used to measure OIS and OIW. In one embodiment, a grid region of squares can be measured so it is National Institute of Standards and Technology (NIST) traceable.","Since the product setup operation for an inspection system may be time consuming, customers with multiple systems could benefit from being able to train one semiconductor inspection system on a certain product setup then store that information to a network. Other semiconductor inspection systems could then use that product setup located on the network. At the present time, system-to-system variations can cause large errors that result in product setups not being able to be shared between semiconductor inspection tools.","Possible sources of system-to-system error have been identified and include OIS, OIW, and FF. One embodiment of the present invention measures and corrects for OIS, OIW, and FF errors. Below is a description of the mathematical models used to characterize OIS, OIW, and FF along with the techniques used to correct for each.","A number of images are collected on different semiconductor inspection tools and the images are stored on a shared drive on a network. Thereafter, the errors for OIS, OIW, and FF on the relevant images are characterized, and then corrections for OIS, OIW, and FF errors are applied independently so that the effect of each correction can be measured. The magnitude of errors before corrections for OIS, OIW, and FF along with the magnitude of errors after corrections are often reviewed. In one embodiment, multiple images are taken of the same wafer on one system with a small jog in x, a small jog in y, and a small rotation to have a baseline of what the error is after displacement and angle registration on images from the same system.","In one embodiment, the measurement and correction techniques for OIS, OIW, and FF described herein are implemented in code. A WIN32 Application Programming Interface (API) User Interface (UI) or the like accesses the routines so as to quickly take images from different systems and investigate the errors before and after corrections.","In one embodiment, the images are corrected for FF first and then corrected for OIW and OIS at the same time.","Light Source Flat Field (FF)",{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 3A","b":["200","104","100","200","208","206","204","104","210","210","202","200","104","106"]},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 3B","b":["200","104","100","200","208","206","204","104","210","104","202"]},"For FF, it is known that for a number of reasons, the light profile across a field of view of the camera can vary from system to system or within a system after a bulb has been changed or possibly after the bulb has aged. The steps for correcting this problem according to one embodiment are listed below. The effect of the flat fielding error is a gradual drop off from the brightest location in the image.","Step 1 involves acquiring and saving to disk images of an illumination wafer (i.e., a wafer of substantially uniform reflectance) at different light source power settings for each objective during illumination calibration. Frame averaging can be used to help reduce gaussian system noise. The images are filtered to remove noise from defects and contamination. In one embodiment, a histogram type filter or other type of filter may be used. The filter size may be of any size; however, one size that is suggested in one embodiment is a filter size of around 20 pixels by 20 pixels that is used on a histogram of that region of interest (ROI). The center value is replaced with the histogram bin that contains the highest number of pixels. The physical basis for this filter lies in the fact that the probability is that the highest pixels in that ROI have the same reflectivity. One technique is an edge detect filter (LOG\/ZCD\/Gradient) that defines the boundaries of the defect then a distance transform to replace the defect with its nearest valid neighbor value.","Step 2 occurs after a product setup is loaded where an image corresponding to that power is loaded in the inspection system. If an image has not been saved at that power level, then an interpolated image is created from images of power levels above and below that level. Since multiple mirrors are used to calibrate an objective, images need to be from the same objective.","Step 3 occurs once an image is available on which the average gray value may be found. A floating ratio matrix is created, which is the ratio of the average gray value to the gray value at each pixel. In one embodiment, on average, the light can fall off from the high point to low point by 10%. For example, if the average CCD array gray value is 200 with the low at 190 and the high at 210, then at the low pixel value the ratio is 200\/190=1.0526 and the ratio at the high value location is 200\/210=0.952. The ratio buffer is then downloaded to controller  after a product setup has been loaded and multiplied at run time against the inspection ROI.","In one embodiment, rather than just acquiring images from one region of the illumination wafer and then fitting the data to a third order polynomial to interpolate the images at any power level setting, one embodiment of the present invention also allows for the saving of the filtered illumination wafer images to disk and then loading them when loading a product setup.","It is noted that the ratio matrix for flat fielding may also contain a correction of gain errors in cameras that have digital gain settings. Furthermore, if desirable, an individual pixel gain may be added and offset with data acquired from the camera matching equipment.","Since the light flat field profile can change from replacing a light bulb, this calibration is preferably performed at least as often as a bulb is changed. It most likely will need to be run each time the illumination calibration changes a lookup value for a bulb or each time the illumination calibration is run.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 4","FIG. 2"],"b":["250","100","252","106","254","106","174","256","104","104","178","174","258","120","104","104"]},"At , controller  determines a normalizing factor for each pixel of the sensor array of camera  to compensate for the difference between the actual pixel gray value and the average gray value of the sensor array. At , controller  stores the normalizing factors for each pixel of the sensor array of camera  for the current inspection light source  setting. At , controller  determines whether each light source setting of the plurality of light source settings has been completed and a normalizing factor has been found for each pixel at that light source setting.","If controller  determines that each light source setting of the plurality of light source settings has not been set, control returns to block  where the inspection light source setting is adjusted to the next light source setting of the plurality of light source settings and the process repeats. If controller  determines that all light source settings of the plurality of light source settings have been completed, light source flat field correction is complete at .","Optical Image Scaling (OIS) and Optical Image Warping (OIW)",{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 5","b":["300","100","300","302","308","300","302","308","300"]},{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 6A","b":["310","300","310","312","310","314","320","322","328","314","312","316","320","314","320","322","328","302","308","300","322","328"],"sub":["OIC","OIC"]},{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 6B","b":["310","300","310","314","320","322","328","310","314","320"]},{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 6C","b":["310","300","310","322","328","322","328","302","308","300","310","300"]},{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 7A","b":["350","300","350","352","350","354","360","362","368","360","352","354","358","354","360","362","368","302","308","300","362","368"],"sub":["OIC","OIC"]},{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 7B","b":["350","300","350","354","360","362","368","350","354","360"]},{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 7C","b":["350","300","350","362","368","362","368","302","308","300","350","300"]},"Since the first semiconductor inspection system and the second semiconductor inspection system have been corrected to provide substantially equivalent images of target  as illustrated in , respectively, one of the first semiconductor inspection system and the second semiconductor inspection system can be trained on a product and both the first semiconductor inspection system and the second semiconductor inspection system can use that training to inspect the product.","In the past, the measurement of OIS and OIW have traditionally been done by the steps below: (1) Fabrication of target with objects of known distances; (2) find the center of each object using image processing techniques; (3) fit the found data to a least squares linear regression on an equation that takes into account scale, rotation, and warping; and (4) by using the coefficients from the least squares fit, optical scale and warping can be adjusted and\/or corrected. The embodiment of the solution provided herein uses a hybrid solution between a least squares approach and grid interpolation that uses the strong points of each method.","For step 1 above, a target containing grid patterns of circles, squares, or other shapes is used. In one embodiment, five patterns of circles have diameters and spacing set up to be used with multiple objectives of a semiconductor inspection system. In some cases, the user may not be sure of the true position accuracy on center to center spacing, but an estimate may be used. In some cases, only targets with patterns of squares can be measured or verified with calibrated equipment so as to make the targets NIST traceable. Image processing sub-pixel techniques used on edges appear to work much better on straight lines than on curved lines of a circle, so using targets made from squares is preferred.","For step 2, a blob technique is used along with an edge detect technique. The edge detect technique uses a LOG filter with ZCD and then a linear regression on the equation of an ellipse. Different sub-pixel techniques are used on the edges of the ellipse along with an error checking routine that removes points from the ellipse fit until the average error in the ellipse fit is not reduced. The advantage of the edge detect is that one can measure the sub-pixel error in the fit that allows for error checking. Small defects in the target can cause errors in its center position estimate that cannot be detected with a blob routine. The same type of edge detect error checking can be applied to square, rectangle, or any other suitable model based target. Error checking is extremely important for optical measurements. It is recommended, in one embodiment, that the user use many more objects on the target than required so damaged or contaminated objects can be dropped out or not used.","For step 3, one embodiment of the invention uses equations of the form given in Equations I-II below to determine the optical image center used to model the optical scale, grid rotation, grid offset and optical warping.\n\n01233435565\u2003\u2003Equation I\n\n","The procedure is to use the above linear regression and locate the optical image center. The image center is located at the X, Y pixel location that gives a minimum overall error in the fit. This is termed \u201cgoodness of fit.\u201d","Once the image center is found, the warp error at each location can be used to set up an interpolation grid. A simulation showed extremely small errors resulted from an interpolation grid. The warp errors at each calibration point can be used with bilinear interpolation to compute a warp error at each pixel location that is termed \u201cdifference matrices for x and y.\u201d Once the two difference floating point matrices are computed, scale adjustments can be added to the matrices. The above matrices are then downloaded to controller  when the inspection system program starts up. In one embodiment, the size of the matrices (2 of them) are 1024\u00d71024 and are floating point.","In one embodiment, the DSP code for controller  includes a loop to correct for any image warping errors along with any scaling change. The software loop consists of: (1) using the offset buffers to find which pixels in the original images should be used for interpolation; and (2) performing a bilinear interpolation to arrive at a new gray value in the corrected\/scaled image.","Controller , in one embodiment, performs scale adjustment only, warp correction only, and scale and warp correction at the same time. The error between images is reduced more by performing both scale and warping at the same time, because only one bilinear interpolation is performed.","The optics scale and warping should not change over time. The image center may change over time, because of mechanical issues. So the frequency of calibration would not have to be high, which means the number of targets purchased by the customer may be lower than the illumination wafer.",{"@attributes":{"id":"p-0084","num":"0103"},"figref":["FIG. 8","FIG. 2"],"b":["400","100","402","106","174","174","404","100","104","174","406","100","104","174"]},"At , controller  determines the optical image center of the image from camera . At , controller  determines the optical image warping of the image from camera . At , controller  corrects the image to correct for the optical image warping. At , controller  determines the optical image scale of the image from camera . At , controller  corrects the image to correct for optical image scale based on the determined optical image scale and the actual dimensions and locations of the objects on target . At , controller  saves the optical image warping and optical image scale correction data to memory for use during inspections.",{"@attributes":{"id":"p-0086","num":"0105"},"figref":"FIG. 9","b":["500","500","502","508","510","502","504","502","508","510","506"]},"In one embodiment, the invention provides for an ability to share product setups between semiconductor inspection tools and achieve defect correlation without operator intervention where the following steps occur: (1) train a product on first inspection tool ; (2) upload the product setup data  to computer system ; (3) download the product setup data  from computer system  to second inspection tool ; (4) inspect the product on first inspection tool  and second inspection tool ; and (5) verify defect correlation greater than 99.997% on a known standard.","The obstacles of the prior art overcome using this method include: camera issues including gain and offsets, illumination issues, including light degradation, light levels between semiconductor inspection tools and flat fielding, and optics issues including magnification between objectives and optical distortions between objectives.","This occurs because the method of one embodiment of the present invention provides image matching, which transforms the images from machine #1 and machine #2 to a \u201cStandard\u201d image. This involves flat fielding, image warping, and scaling.","Accordingly, the invention as described above and understood by one of skill in the art is simplified, provides an effective, safe, inexpensive, and efficient device, system and process that achieves all the enumerated objectives, provides for eliminating difficulties encountered with prior devices, systems and processes, and solves problems and obtains new results in the art.","In the foregoing description, certain terms have been used for brevity, clearness and understanding; but no unnecessary limitations are to be implied therefrom beyond the requirement of the prior art, because such terms are used for descriptive purposes and are intended to be broadly construed.","Moreover, the invention's description and illustration is by way of example, and the invention's scope is not limited to the exact details shown or described.","Having now described the features, discoveries and principles of the invention, the manner in which it is constructed and used, the characteristics of the construction, and the advantageous, new and useful results obtained; the new and useful structures, devices, elements, arrangements, parts and combinations, are set forth in the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Preferred embodiments of the invention, illustrative of the best mode in which Applicant has contemplated applying the principles are set forth in the following description and are shown in the drawings and are particularly and distinctly pointed out and set forth in the appended claims.",{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6C"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 7B"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 7C"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9"},"Similar numerals refer to similar parts throughout the drawings."]},"DETDESC":[{},{}]}
