---
title: Database optimization apparatus and method
abstract: A database optimizer collects statistics regarding which types of applications are accessing the database, and makes one or more changes to the database schema to optimize performance according to the collected statistics. In a first embodiment, the optimizer detects when a certain type of application accesses the database a percentage of time that exceeds a predefined threshold level, and if the data in the database is stored in a less-than-optimal format for the application, the data type of one or more columns in the database is changed to a more optimal format for the application. This means that the database optimizer must recognize when a different type of application requests data from any changed column, and must potentially perform a conversion from the new data type to the old data type before returning the requested data. In a second embodiment, the optimizer detects when one type of application accesses a column a percentage of time that exceeds a first predefined threshold level and that accesses the column a percentage of time that is less than a second predefined threshold level. In this case, a new column is created in the database so the data is present in both formats, thereby optimizing the performance of both old and new applications that access the data. The database optimizer looks at what type of application requested data, and returns the data in the format optimized for that type of application.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07089260&OS=07089260&RS=07089260
owner: International Business Machines Corporation
number: 07089260
owner_city: Armonk
owner_country: US
publication_date: 20020214
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","DISCLOSURE OF INVENTION","BEST MODE FOR CARRYING OUT THE INVENTION","Known Databases and Database Queries"],"p":["1. Technical Field","This invention generally relates to computer systems, and more specifically relates to apparatus and methods for accessing data in a computer database.","2. Background Art","Since the dawn of the computer age, computers have evolved and become more and more powerful. In our present day, computers have become indispensable in many fields of human endeavor including engineering design, machine and process control, information storage and retrieval, and office computing. One of the primary uses of computers is for information storage and retrieval.","Database systems have been developed that allow a computer to store a large amount of information in a way that allows a user to search for and retrieve specific information in the database. For example, an insurance company may have a database that includes all of its policy holders and their current account information, including payment history, premium amount, policy number, policy type, exclusions to coverage, etc. A database system allows the insurance company to retrieve the account information for a single policy holder among the thousands and perhaps millions of policy holders in its database.","Many databases include data that has existed for decades, often outliving the software applications that originally created the data. New applications are often developed that need to access the data. The way that data is stored in a database affects the performance of applications that access the data. If the data is stored as a particular data type, but an application requires a different data type, the data must typically be read, then converted to the desired data type. This problem arises, for example, when data that was originally created by legacy applications in one data type now needs to be accessed by new languages and APIs that expect a different data type.","Legacy applications often store integer data in fields that are in a format known as PACKED DECIMAL, which is one way to represent numeric data. Like the PACKED DECIMAL data type, the data types SMALLINT, INTEGER, and BIGINT are other alternative ways to represent numeric data. In a Java and JDBC programming paradigm, it is widely recognized that retrieval of data from database columns that have a type of SMALLINT, INTEGER, or BIGINT will perform significantly better than retrieval of data from a column that has a type PACKED DECIMAL. The format of the data stored in the database results in performance penalties for any application that needs to access the data, but could run faster if the data were of a different type. Changing the data type to accommodate the new applications is generally not an acceptable option, because changing the data type would require significant manual rework. This problem is especially apparent as companies with existing applications and databases become internet-enabled, which is commonly done using Java to access data in existing databases. Using Java to access data in less-than-optimal data types in older databases results in performance penalties that are significant. Without an apparatus and method that allows a database to dynamically evolve according to the applications accessing its data, the computer industry will continue to suffer from excessive overhead in porting existing data to new applications, such as web-enabled applications.","According to the preferred embodiments, a database optimizer collects statistics regarding which types of applications are accessing the database, and makes one or more changes to the database schema to optimize performance according to the collected statistics. In a first embodiment, the optimizer detects when a certain type of application accesses the database a percentage of time that exceeds a predefined threshold level, and if the data in the database is stored in a less-than-optimal format for the application, the data type of one or more columns in the database is changed to a more optimal format for the application. This means that the database optimizer must recognize when a different type of application requests data from any changed column, and must potentially perform a conversion from the new data type to the old data type before returning the requested data. In a second embodiment, the optimizer detects when one type of application accesses a column a percentage of time that exceeds a first predefined threshold level and that accesses the column a percentage of time that is less than a second predefined threshold level. In this case, a new column is created in the database so the data is present in both formats, thereby optimizing the performance of both old and new applications that access the data. The database optimizer looks at what type of application requested data, and returns the data in the format optimized for that type of application.","The foregoing and other features and advantages of the invention will be apparent from the following more particular description of preferred embodiments of the invention, as illustrated in the accompanying drawings.","1.0 Overview","The present invention relates to optimizing the performance of accessing data in a database. For those not familiar with databases, this Overview section will provide background information that will help to understand the present invention.","There are many different types of databases known in the art. The most common is known as a relational database (RDB), which organizes data in tables that have rows that represent individual entries or records in the database, and columns that define what is stored in each entry or record.","To be useful, the data stored in databases must be able to be efficiently retrieved. The most common way to retrieve data from a database is to generate a database query. A database query is an expression that is evaluated by a database manager. The expression may contain one or more predicate expressions that are used to retrieve data from a database. For example, lets assume there is a database for a company that includes a table of employees, with columns in the table that represent the employee's name, address, phone number, gender, and salary. With data stored in this format, a query could be formulated that would retrieve the records for all female employees that have a salary greater than $40,000. Similarly, a query could be formulated that would retrieve the records for all employees that have a particular area code or telephone prefix.","One popular way to define a query uses Structured Query Language (SQL). SQL defines a syntax for generating and processing queries that is independent of the actual structure and format of the database. One sample SQL query is shown in . The \u201cselect*\u201d statement tells the database query processor to select all columns, the \u201cfrom Table\u201d statement identifies which database table to search, and the \u201cwhere\u201d clause specifies one or more expressions that must be satisfied for a record to be retrieved. Note that the query of  is expressed in terms of columns C, C and C. Information about the internal storage of the data is not required as long as the query is written in terms of expressions that relate to values in columns from tables.","For the query of , the \u201cwhere\u201d clause specifies that the first column has a value equal to four (C=4) logically ANDed with the expression that the second column is greater than six OR the third column is not equal to eight. In the prior art, much effort has been expended to optimize queries so they may be executed faster, which increases system performance. However, no known efforts have been made to dynamically change a database's schema according to the type of applications accessing the database, the frequency with which the application access data in the database, and the location of the data in the database accessed by the applications.","2.0 Detailed Description","The preferred embodiments provide a way to dynamically tune a database to provide data in a format optimized for the type of application that most frequently accesses the data.","Referring to , a computer system  is one suitable implementation of an apparatus in accordance with the preferred embodiments of the invention. Computer system  is an IBM iSeries computer system. However, those skilled in the art will appreciate that the mechanisms and apparatus of the present invention apply equally to any computer system, regardless of whether the computer system is a complicated multi-user computing apparatus, a single user workstation, or an embedded control system. As shown in , computer system  comprises a processor , a main memory , a mass storage interface , a display interface , and a network interface . These system components are interconnected through the use of a system bus . Mass storage interface  is used to connect mass storage devices (such as a direct access storage device ) to computer system . One specific type of direct access storage device  is a readable and writable CD ROM drive, which may store data to and read data from a CD ROM .","Main memory  in accordance with the preferred embodiments contains data , an operating system , a database , a database manager , data access rules , and run-time statistics . Data  represents any data that serves as input to or output from any program in computer system . Operating system  is a multitasking operating system known in the industry as OS\/400; however, those skilled in the art will appreciate that the spirit and scope of the present invention is not limited to any one operating system. Database  is any suitable database, whether currently known or developed in the future. Database  comprises any suitable table or collection of tables defined by database schema . Database manager  suitably includes one or more database APIs  and a database optimizer . Database APIs  are the application programming interfaces (APIs) that applications may use to access data stored within database . In the preferred embodiments, each type of programming paradigm includes its own set of APIs for accessing data in the database . Data access rules  correlate a programming paradigm (such as COBOL or Java) to its preferred data types. Run-time statistics  contain statistics that indicate the relative frequency with which each programming paradigm accesses data in a particular portion of the database  (such as a selected column or columns). Database optimizer  monitors the data access rules  and the run-time statistics , and makes one or more changes to the database schema  to optimize the access of data in the database according to the run-time statistics . In some cases, the database optimizer  changes the data type of one or more columns in the database . In other cases, the database optimizer  adds reflective columns to the database  so that data within the database  is present in multiple data types at the same time. The database optimizer  then monitors which type of application requests access to the data (by determining which database API  is invoked), and retrieves data from a column in the database, if one exists, that stores the data in a data type that is optimized for the type of requesting application. Note that run-time statistics  may be collected by the database manager  within the scope of the preferred embodiments, or may be separately collected yet used by the database manager .","Computer system  utilizes well known virtual addressing mechanisms that allow the programs of computer system  to behave as if they only have access to a large, single storage entity instead of access to multiple, smaller storage entities such as main memory  and DASD device . Therefore, while data , operating system , database , database manager , data access rules , and run-time statistics  are shown to reside in main memory , those skilled in the art will recognize that these items are not necessarily all completely contained in main memory  at the same time. It should also be noted that the term \u201cmemory\u201d is used herein to generically refer to the entire virtual memory of computer system , and may include the virtual memory of other computer systems coupled to computer system .","Processor  may be constructed from one or more microprocessors and\/or integrated circuits. Processor  executes program instructions stored in main memory . Main memory  stores programs and data that processor  may access. When computer system  starts up, processor  initially executes the program instructions that make up operating system . Operating system  is a sophisticated program that manages the resources of computer system . Some of these resources are processor , main memory , mass storage interface , display interface , network interface , and system bus .","Although computer system  is shown to contain only a single processor and a single system bus, those skilled in the art will appreciate that the present invention may be practiced using a computer system that has multiple processors and\/or multiple buses. In addition, the interfaces that are used in the preferred embodiment each include separate, fully programmed microprocessors that are used to off-load compute-intensive processing from processor . However, those skilled in the art will appreciate that the present invention applies equally to computer systems that simply use I\/O adapters to perform similar functions.","Display interface  is used to directly connect one or more displays  to computer system . These displays , which may be non-intelligent (i.e., dumb) terminals or fully programmable workstations, are used to allow system administrators and users to communicate with computer system . Note, however, that while display interface  is provided to support communication with one or more displays , computer system  does not necessarily require a display , because all needed interaction with users and other processes may occur via network interface .","Network interface  is used to connect other computer systems and\/or workstations (e.g.,  in ) to computer system  across a network . The present invention applies equally no matter how computer system  may be connected to other computer systems and\/or workstations, regardless of whether the network connection  is made using present-day analog and\/or digital techniques or via some networking mechanism of the future. In addition, many different network protocols can be used to implement a network. These protocols are specialized computer programs that allow computers to communicate across network . TCP\/IP (Transmission Control Protocol\/Internet Protocol) is an example of a suitable network protocol.","At this point, it is important to note that while the present invention has been and will continue to be described in the context of a fully functional computer system, those skilled in the art will appreciate that the present invention is capable of being distributed as a program product in a variety of forms, and that the present invention applies equally regardless of the particular type of computer-readable signal bearing media used to actually carry out the distribution. Examples of suitable computer-readable signal bearing media include: recordable type media such as floppy disks and CD ROM (e.g.,  of ), and transmission type media such as digital and analog communications links.","The remainder of this specification describes the detailed function of the database optimizer  shown in . Referring now to , a block diagram shows the relationship between the database , the database manager , and applications  that require access to data stored in the database . Database  is defined by a database schema  that specifies the details for each table  in the database , including the number of columns in the table, the width of each column, and the data type of each column. Note that the database schema  includes a definition for each and every type of table  stored in the database .","Database manager  is a layer of code that runs between the applications  that need to access data in the database  and the database  itself. Database manager  includes the database optimizer  shown in , and includes database APIs  that provide interfaces for applications  to access data in the database . In , examples of suitable APIs are shown to include one or more COBOL APIs , one or more Java APIs , and one or more RPG APIs . COBOL APIs  are application programming interfaces that provide an interface for COBOL applications to access data stored in database . Java APIs  are application programming interfaces that provide an interface for Java applications to access data stored in database . RPG APIs  are application programming interfaces that provide an interface for RPG applications to access data stored in database . Of course, these specific APIs ,  and  in  are shown by way of example, and the preferred embodiments expressly extend to any suitable API or other type of interface that allows an application to access data stored within database .","Applications  include all applications that may access data within the database . From the specific APIs ,  and  shown in , we assume that applications  would include COBOL applications, Java applications, and RPG applications. In the preferred embodiment, each type of application will have its own set of APIs that is uses to access data in the database . Note, however, that an application of a particular type may access data in the database  using an API intended for a different application, so long as the application itself includes the logic to perform any needed conversion between the data returned by the API.","Referring now to , a method  in accordance with the preferred embodiments shows how the database optimizer  may dynamically make changes to a database to tune the performance of the database according to the type of applications that are accessing its data. First, the run-time statistics for the database are read (step ). Note that the run-time statistics are preferably collected by the database optimizer , but may also be collected by a separate software tool or application as well. Method  determines from the statistics if the percentage of accesses by a particular type of application that would benefit a change of data type exceeds a first threshold (step ). If not (step =NO), no change is made to the database (step ). If so (step =YES), method  checks to see if the percentage of accesses by a particular type of application that would benefit from a change of data type exceeds a second threshold (step ). If not (step =NO), one or more new reflective columns are created in the database (step ). If so (step =YES), the data type of one or more columns in the database is changed (step ). In this manner, method  makes appropriate changes to the database in steps  and  that will make accesses to the data stored in the database perform better according to the percentage of accesses by different types of applications. Note that the changes are determined by the first and second thresholds levels, which may be fixed, but are preferably variable and can be set by the database administrator.","Note that the changes to the database performed by the database optimizer  in method  of  are changes to data types for columns in the database (in step ), and the addition of columns in the database (step ). Note also that the database optimizer  may also delete reflective columns once they are no longer needed. These types of changes to the database are describe herein in two different ways. First, these are describe as changes to the database (as in ). Alternatively, these changes are described as changes to the database schema (as in the claims). Note that these are different ways of saying the same thing, since the database schema dictates the physical structure and organization of the database. Columns can only be added to a table by changing the schema for the table. The data type of a column can only be changed by changing the schema that specifies the data type for the column. For this reason, the terms \u201cchanging the database\u201d and \u201cchanging the database schema\u201d are considered equivalent, and no difference between these terms exists for the purposes of describing the preferred embodiments or claims herein.","In the preferred embodiments, the database administrator has the ability to dictate how the database optimizer  functions. Referring to , a menu display window  allows the database administrator to select whether the database optimizer is turned off, is put in an \u201cadvise only\u201d mode, or is enabled to make changes to the database automatically. If turned off, the database optimizer  does not perform any of the optimization functions described herein as part of the preferred embodiments. If in \u201cadvise only\u201d mode, the database optimizer  shows to the database administrator what changes the database optimizer  would have made to optimize performance of the database if automatic changes were enabled. If automatic changes are enabled (as shown by the check in the box in ), the database optimizer  automatically makes the changes to the database to optimize its performance according to the applications accessing its data, as shown by method  in . In addition to setting the database optimizer  to \u201coff\u201d, \u201cadvise only\u201d, or \u201cautomatic changes\u201d as shown in , the database administrator may also select the lower and upper threshold levels that control how the database optimizer  performs its functions, as shown in . The lower threshold determines when the database optimizer  can first take action to optimize the database for accesses by a particular type of application. The upper threshold determines when the accesses by a particular type of application become so dominant that it justifies changing the data type of one or more columns in the database to accommodate the dominant type of application. For the specific example of , the lower threshold is set to 20%, while the upper threshold is set to 80%. The fact that these two threshold levels in  sum to 100% is coincidental; any suitable values may be independently selected for the first and second threshold values so long as the upper threshold value is equal to or greater than the lower threshold value.","Once a type of application that would benefit from a change of data type exceeds 20% of the accesses to data within a particular column, the database optimizer may take action to optimize the database. If the type of application has a number of accesses between the lower and upper thresholds (between 20% and 80% for the example in ), reflective columns will be added to the database to provide data in multiple data types for multiple application types. Once the number of accesses for a particular application type exceeds the upper threshold, the data type of the columns in the database are changed to be optimized for the particular application. Note that the data access rules  in  correlate a type of application to its preferred data types that will optimize performance for that particular type of application.","It is important to note what happens when data is stored in a less-than-optimal format in the database, and no reflective columns are present to provide an alternative data type for the data. This happens when the number of accesses by an application type is lower than the lower threshold, or is greater than the upper threshold. When an application type has a percentage of accesses lower than the lower threshold, the database optimizer  will not perform optimizations to the database . Note, however, that the database manager  will still return data in a format expected by a requesting application by detecting which database API  was invoked, and by either returning the data (if already of the desired data type), or automatically converting the data to the desired data type before returning the data to the requesting application. Note that the correlation between a particular type of application and its preferred data types is stored in the data access rules . When an application type has a percentage of accesses greater than the upper threshold, the data type of one or more columns in the database will be changed to the preferred data types for that type of application. Other types of applications that now request data from these columns expect a different data type. Again, the database manager  accounts for this mismatch between data types, and performs a conversion between data types before returning the data to the requesting application. In this manner, the data type preferred by the type of requesting application is always returned, and when no conversion is necessary, the performance of the API returning the data is significantly increased. Note that the data conversion may be performed by the database optimizer , or may be performed by a different portion of code within the database manager .","Note that the lower and upper thresholds discussed herein can be either inclusive or exclusive of their boundary limits within the scope of the preferred embodiments. Thus, we discuss the function of the database optimizer  in method  of  as taking certain actions based on whether the percentage of accesses exceeds a first threshold (step ) or exceeds a second threshold (step ). Note that these steps could have alternatively been specified to evaluate whether the percentage of accesses is greater than or equal to the first and second thresholds. There is no specific importance regarding where the lines are drawn and whether the conditions are true when the percentage of accesses is equal to the set threshold levels. The preferred embodiments expressly extends to any manner of defining a lower threshold and an upper threshold, and for taking appropriate steps according to those defined threshold levels, regardless of whether the boundary limits defined by the threshold levels are included or excluded in the ranges.","A very simple example is now presented to illustrate the function of the database optimizer . Referring to , a table  is a very simple database table referred to as an Employee table that stores the name of a company's employees and their corresponding employee identification numbers. The employee table  includes a first column  that has a data type of char() and a label of \u201cname\u201d, and a second column  that has a data type of packed decimal (,) and a label of \u201cid\u201d. These data types are the preferred data types for a COBOL application, and we assume that table  was originally created using a COBOL application. Now, let's assume that the company wants to make the employee and identification numbers available to Java applications as well as COBOL applications. In the prior art, when a Java application accesses the data in table , the database manager  would convert the data from its stored data type to data types that Java expects. In the preferred embodiments, the database manager  also performs the conversion between data types by knowing what kind of application is requesting the data by determining which database API  was invoked, and by looking at the data access rules  that correlate a type of application to its preferred data types. With this information, the database manager  returns the preferred data type to the requesting application. It has been shown by extensive experience that Java processes unicode much more efficiently than character text, and processes integers much more efficiently than packed decimals. We therefore assume that the data access rules  list char and packed decimal as preferred data types for COBOL applications, while unicode and int are preferred data types for Java applications. We assume for this example that the lower and upper threshold levels are set at 20% and 80%, respectively, as shown in . For these threshold levels, for any percentage of accesses to a column by Java applications that are less than 20%, the database manager simply retrieves the data as stored in the table of , and performs the conversion between the retrieved data types and the preferred data types for Java (namely, unicode and int). For the table  of , a COBOL application requests access to the \u201cname\u201d column in table  by invoking a COBOL API (e.g., COBOL API  of ). The database manager  detects that a COBOL API was invoked, and looks at the data access rules  to determine that the preferred data type for text is char. The database manager  then looks at the database schema  to determine if a column in table  has the \u201cname\u201d information in \u201cchar\u201d format. Column  has the \u201cname\u201d information in \u201cchar\u201d format, so data from column  is returned. In similar fashion, a Java application requests access to the \u201cname\u201d column in table  by invoking a Java API (e.g., Java API  of ). The database manager  detects that a Java API was invoked, and looks at the data access rules  to determine that the preferred data type for text is unicode. The database manager  then looks at the database schema  to determine if a column in table  has the \u201cname\u201d information in \u201cunicode\u201d format. There is no column in table  that has the \u201cname\u201d information in \u201cunicode\u201d format, so the database manager  retrieves the char() data from column , converts the char() data to unicode() data, and returns the unicode() data to the requesting Java application. In this manner, the database manager  automatically converts from a stored data type to data type desired by the requesting application, when needed. However, the most significant advantage of the preferred embodiments is the reduction in the percentage of times a conversion is needed by changing the database schema to store data in one or more formats compatible with the type of applications that access the data most frequently.","Referring back to , once the percentage of accesses for a particular type of application that would benefit from a change in data type exceeds a first threshold (e.g., the lower threshold of 20%), the database optimizer  may take action to optimize the database by changing the database. If the percentage of accesses for the type of application lies between the first and second threshold levels (e.g., between the lower threshold of 20% and the upper threshold of 80%), reflective columns are created in the database (step  of ). Once the percentage of accesses for the type of application exceeds the second threshold (e.g., is greater than 80%), some of the reflective columns are deleted, leaving only the columns that contain the data type for the dominant type of application accessing the data.","Let's say that the percentage of accesses for Java applications for both the name and id columns in table  is 30%. This lies between the lower threshold of 20% and the upper threshold of 80%, so the database optimizer  creates reflective columns (step  in ), as shown in table A of . Note that the first two columns are the same columns  and  in . However, two new columns  and  are added that have different names and data types. Column  of table A has a data type of unicode(), and has a label of \u201cname_ref\u201d. The data in column  is represented by asterisks \u201c*\u201d to indicate that the data in this column is identical to the data in the \u201cname\u201d column , only it is stored in unicode() format rather than char() format. Similarly, the fourth column  of table A has a data type of int, and has a label of \u201cid_ref\u201d. The data in column  is represented by plus signs \u201c+\u201d to indicate that the data in this column is identical to the data in the \u201cid\u201d column, only it is stored in int format rather than packed decimal (,) format. Note that columns  and  are said to be \u201creflective\u201d columns because they reflect the same data in different data types (or formats). Similarly, columns  and  are reflective columns.","A COBOL application requests access to the \u201cname\u201d column in table A by invoking a COBOL API (e.g., COBOL API  of ). The database manager  detects that a COBOL API was invoked, and looks at the data access rules  to determine that the preferred data type for text is char. The database manager  then looks at the database schema  to determine which column in table A has the \u201cname\u201d information in \u201cchar\u201d format. Column  is the appropriate column, so data from column  is returned. In similar fashion, a Java application requests access to the \u201cname\u201d column in table A by invoking a Java API (e.g., Java API  of ). The database manager  detects that a Java API was invoked, and looks at the data access rules  to determine that the preferred data type for text is unicode. The database manager  then looks at the database schema  to determine which column in table A has the \u201cname\u201d information in \u201cunicode\u201d format. Column  is the appropriate column, so data from column  is returned. In this manner, data may be stored in multiple data types (or formats) in the preferred embodiments to allow efficiently returning data in a format that the requesting application expects.","We now assume for our example that the percentage of accesses by Java applications to one or more columns in table A of  rises above the upper threshold level of 80%. In this case, the database manager deletes the original columns  and  from table A, and renames the columns  and  to the names of the original columns (i. e., \u201cname\u201d and \u201cid\u201d), as shown in table B in . Now, when a COBOL application requests access to the \u201cname\u201d column in table  by invoking a COBOL API (e.g., COBOL API  of ), the database manager  detects that a COBOL API was invoked, and looks at the data access rules  to determine that the preferred data type for text is char. The database manager  then looks at the database schema  to determine if a column in table B has the \u201cname\u201d information in \u201cchar\u201d format. There is no column in table  that has the \u201cname\u201d information in \u201cchar\u201d format, so the database manager  retrieves the unicode() data from column , converts the unicode() data to char() data, and returns the char() data to the requesting COBOL application. In similar fashion, a Java application requests access to the \u201cname\u201d column in table B by invoking a Java API (e.g., Java API  of ). The database manager  detects that a Java API was invoked, and looks at the data access rules  to determine that the preferred data type for text for a Java request is unicode. The database manager  then looks at the database schema  to determine if a column in table B has the \u201cname\u201d information in \u201cunicode\u201d format. Column  has the \u201cname\u201d information in \u201cunicode\u201d format, so data from column  is returned. In this manner, the database optimizer  causes the database  to automatically evolve according to the types of applications requesting data from the database. Note that the data optimizer  may operate on the column level, which means that accesses may be tracked to particular columns, and appropriate changes as described in method  of  may be performed on individual columns in a table without affecting other columns in the table. This allows the optimizer  to only build a reflective column if the run-time statistics  indicate a percentage of accesses to that particular column exceeds the first threshold level.","One significant advantage of the preferred embodiments is the definition of different levels of metadata. In the prior art, the database administrator may review metadata that shows how data is stored in the database. The metadata is representative of the database schema. In the prior art, metadata for a database is typically stored in two tables, one to track the tables in the database, and another to track columns in the tables. Referring to , table  is table that shows a very simplified representation of metadata for tables in a simple database. Each entry in table  represents a different table in the database. The SchemaName column references the schema for that particular table. The TableName column contains the name of the table. The TableOwner column identifies who the owner is for the table. The ColumnCount column indicates how many columns are in the table. For the simple table  in , two tables are shown, the first being the Employee table  of , and the second being a table called Table. Of course, other tables can also exist within the database represented by the metadata in table . The Employee table is assumed to have a schema labeled \u201cEmpSchema\u201d, and its owner is specified by the user profile of the owner. As shown in table  of , the Employee table has two columns.","Referring now to , a table  represents a table of columns that shows metadata for the columns in the Employee table, but could also include metadata for columns in other tables as well. As shown in , the \u201cname\u201d column in the Employee table  has a data type of char and a size of . The \u201cid\u201d column in the Employee table  has a data type of packed decimal and a size of (,). The table of tables  in  and the table of columns  in  together make up metadata as known in the prior art that describes the employee table of .","In the preferred embodiments, the metadata is changed to accommodate the possibility of adding reflective columns. For table  of , the preferred embodiments have a table of tables  shown in  and a table of columns  shown in . The table of tables  includes an additional column  when compared to the prior art table of tables  in  that contains a flag to indicate whether or not the table contains reflective columns. Table  of  does not contain reflective columns, so this flag is set to FALSE for the Employee table. The table of columns  in  contains three new columns ,  and . Column  contains a flag that indicates whether the column is a reflective column. Column  contains the name of the column for which this column is reflective, or contains \u201cnull\u201d if the column is not a reflective column. Column  contains the name of a paradigm for which this column is optimized. Because table  in  was created by a COBOL application that prefers char() and packed decimal(,) format, the column was optimized for the COBOL programming paradigm. Note that for both the name and id columns in table  of , the metadata in the table of columns  of  specifies that neither of these columns is reflective, and that they are optimized for COBOL.","Now we examine how the metadata changes when reflective columns are added. Table A in  contains reflective columns. The table of tables  in  and the table of columns  in  represent metadata that describes the table A in . Thus, column  in the table of tables  of  is set to TRUE for the Employee table to indicate that the Employee table includes reflective columns. Now we analyze the differences in the metadata in the table of columns  shown in , which represents table A of . Because the \u201cname\u201d and \u201cid\u201d columns both have reflective columns \u201cname_ref\u201d and \u201cid_ref\u201d, respectively, column  in table  of  are true for all columns in the Employee table. Column  specifies which column in the table is the reflective column, and column  specifies which paradigm the column is optimized for. Note that the names \u201cname_ref\u201d and \u201cid_ref\u201d are shown herein as examples of suitable names that would easily correlate reflective columns by the addition of a \u201c_ref\u201d suffix. However, the actual names of reflective columns would preferably be assigned by the database optimizer  in a way that would minimize the likelihood that such a name would be explicitly created by a user. For example, a suffix of \u201c##$##\u201d could be assigned by the database optimizer for reflective columns, which would minimize the likelihood of a user creating a column of this name. By providing metadata as shown in the table of tables  and table of columns , the database optimizer  may easily keep track of when reflective columns are present in a table, and which columns contain data in which data types. This allows the database optimizer to return the data type that matches the requesting application, when possible, when reflective columns exist.","The table of tables  in  and the table of columns  in  represent metadata that describes the table B in . Note that in table B the original columns  and  have been deleted, and the newer, Java-optimized columns  and  have been renamed to the names of the original columns. These changes are reflected in the metadata for this table. First, column  in table  that corresponds to the Employee table is set to False to indicate that no reflective columns are present in the Employee table. Next, the two entries in the table of columns  relating to the COBOL data types have been deleted, and the column name of the remaining Java data types have been renamed to the original column names. Column  for each of the remaining columns is False because there are no longer reflective columns in the table. Column  for each of the remaining columns is Null, and column  specifies that these columns are optimized for the Java programing paradigm.","The simple example presented herein that shows the evolution of table  in  to table A of  to table B of , along with the associated metadata and its changes in , shows how the database optimizer  may cause a database to dynamically evolve according to which applications are accessing columns in the database and with what frequency. A database table optimized for COBOL (e.g., table  in ) may be transformed to include reflective columns that provide increased performance for Java applications that need to access data in the table. Note that this increase in performance comes at the expense of additional storage space in the database. This is another feature that is subject to potential customization by a database administrator. For example, the database administrator could specify a maximum database size, or percent of database growth, that could be used for reflective columns. The database optimizer  could then create reflective columns so long as the maximum is not exceeded. In the case that creating additional reflective columns would exceed the specified maximum, the database optimizer  could also include heuristics to determine whether the current optimization of potentially adding reflective columns outweighs the benefits of reflective columns that currently exist, and can therefore delete some current reflective columns to make room for new reflective columns.","Once the percentage of accesses by Java applications exceeds a second threshold level, it is deemed that the benefit of the reflective columns is outweighed by the cost of the additional required storage, so the original columns are deleted, and the remaining columns are renamed to the names of the original columns. Now Java applications can directly access the data in the format they prefer, while COBOL applications will suffer the performance penalty of having the database manager perform the conversion between the Java-optimized data types and the COBOL-optimized data types. Note also that this evolution can work in both directions. If the database table evolves from table  in  to table A to  to table B in , this is not necessarily the end of the evolution. Let's assume that there are more COBOL applications added that access the data. In the alternative, let's assume that fewer Java applications access the data, perhaps because the data is available in a different table. Whatever the reason, if the percentage of accesses by COBOL applications exceeds the first threshold level (e.g., of 20%), reflective columns can be added to the table, and if the percentage of accesses by COBOL applications exceeds the second threshold level, the reflective columns could be deleted and the table would devolve back to its original state, as shown in table  in . The database optimizer of the preferred embodiments thus provides a way to dynamically tune a database according to the applications accessing data in the database.","The presence of reflective columns in a database table presents some interesting issues. First of all, reflective columns give rise to two different levels of metadata not know in the prior art. In the prior art, a database user is able to view metadata for a database that shows the user the structure of the database. The present invention includes the concept of multiple layers of metadata. The two levels of metadata that may be viewed according to the preferred embodiments are referred to herein as \u201capplication view\u201d and \u201csystem view\u201d. The system view metadata shows all of the data stored in the database, similar to the display of metadata known in the prior art. However, a new level of metadata referred to herein as \u201capplication view metadata\u201d is a presentation of metadata from the point of view of a particular type of application. As discussed in detail above, the database optimizer  may add reflective columns to a database to improve the performance of applications that access data in the database. The presence of the reflective columns may not be terribly important to an application developer, because it represents changes made to the database by the database manager  to enhance the performance of accessing data in the database, but does not affect the logic within the application. When the application developer requests to see metadata for the database, the metadata he or she may really be interested in may be the metadata that applies to the application view. In other words, the metadata that is specific to the type of application may be displayed, while the metadata that is specific to other types of applications may be hidden from view. In the preferred embodiments, a database administrator may determine whether the application view metadata or the system view metadata is displayed when the user requests the display of metadata for the database by specifying a customization setting. One example of such a customization setting is shown in the menu display window  of , which gives the database administrator the ability to check either the \u201cApplication View\u201d box or the \u201cSystem View\u201d box. With the \u201cSystem View\u201d box checked as shown in , the system view metadata is displayed to the database administrator when the function to display the metadata is invoked. If the \u201cApplication View\u201d box is checked, only the metadata relating to a specific type of application is displayed, and any reflective columns for other types of applications will remain hidden.","Another interesting issue that arises due to the presence of reflective columns is the issue of data coherency between reflective columns. How can we assure that the data in two reflective columns are in sync? There are many ways to assure the data coherency between reflective columns. The first is to simply perform a write to both reflective columns when data in either is changed. Because read operations in a database typically far outnumber write operations, the performance penalty for having to write to two columns instead of one will be small. Another way to assure data coherency is to allow for one column to be marginally out of date while a background process copies the data from one reflective column to the other. Another way to assure data coherency is to define a \u201cmaster column\u201d, which would ensure that one column would always be up to date, while the other could be marginally out of date. This is really a combination of the first two methods discussed above. If a write to the database changes a column that is not the master column, an immediate write to the master column will be performed to keep the master column up to date. If a write to the database changes the master column, other reflective column(s) may be marginally out of date and updated by a background process. Finally, another way to assure data coherency between reflective columns is to flag a column as dirty if its data is out of date. This allows for only a single update to happen immediately to one column, and the update to the reflective column may be done separately. However, if an application reads a column that has its dirty flag set (indicating it is out of date with the other column), the column will be immediately updated and the dirty bit cleared before doing the read. Of course, there are other methods that could also be used to assure data coherency between reflective columns in a database. The preferred embodiments expressly extend to any and all methods for maintaining data coherency between reflective columns in a database.","One significant advantage of the preferred embodiments is that the database manager  returns data from the database in a format (i.e., of a data type) that matches the type of the requesting application, as determined by the API invoked to access the data, without performing as many conversions between data types as is required by the prior art. In the prior art, conversion between different data types is required whenever the data is stored in a format that is different than the format preferred by the requesting application. Referring to , a method  in accordance with the preferred embodiments begins when access to data is requested by an application (step ). The database manager then determines the type of data preferred by the requesting application (step ). In one suitable implementation, this step is broken down into the steps of determining which API was invoked, and referring to the data access rules  to determine which data type is preferred for the type of API that was invoked. Once the preferred data type is determined in step , the requested data is retrieved from the database (step ). If the retrieved data is in the preferred format (step =YES), the data is returned to the requesting application without modification (step ). If the retrieved data is not in the preferred format (step =NO), the data is converted to the preferred format (step ), and is returned to the requesting application (step ). A significant advantage of the preferred embodiments is to decrease the number of times conversion between data types is needed by changing the database to store data in a format optimized for the type of application that most frequently accesses the data. Thus, using the apparatus and method of the preferred embodiments, the performance of a database is increased by changing the database to reduce the number of times conversion is required between data types (e.g., in step  of ).","The database optimizer  has been described extensively above. Many of its features may be summarized by the block diagram shown in . Database optimizer  includes a data access mechanism  that performs the function of method  of , which allows a database to evolve according to the type of applications that access it. Data access mechanism  includes a database modification mechanism  that modifies the database schema to provide better performance. Database optimizer  also writes metadata  (as shown in ) that includes reflective column fields  that account for reflective columns, when present. Database optimizer  also includes customization settings  that allow a system administrator to customize the function of the database optimizer . Several examples of suitable customization are described above, including those illustrated in , , and . Data coherency mechanism  is a mechanism that maintains coherency of data between reflective columns, as explained in detail above. Data type conversion mechanism  is a mechanism that performs required conversions between data types before delivering data to the requesting applications, as described in method  of . Run-time statistics gathering mechanism  is a mechanism that tracks the frequency of accesses to columns in a database by different types of applications, and stores this information in run-time statistics  in . The block diagram of  shows that the database optimizer of the preferred embodiments includes many features not known in the prior art that provide significant performance advantages when compared to prior art techniques for accessing data in a database.","The preferred embodiments described herein allow a database to dynamically change over time to accommodate the applications accessing it. As shown by the simple example presented in , a database table may be created with columns that are of data types that are optimized for a COBOL application. When other applications, such as Java applications, access a column, the data in the COBOL-optimized data type is converted to data in the Java-optimized data type before returning the data to the requesting Java application. This allows the Java applications to know they will receive data of the proper type, relieving the application of the chore of performing conversion between data types. As the number of accesses by Java applications passes a first threshold level, the database schema may be changed to add reflective columns that provide data in multiple data types. At the point in time when the number of accesses by Java applications exceeds a second threshold level, the original columns that contain the COBOL-optimized data types may be deleted from the database, and only the columns with the Java-optimized data type. When COBOL applications access a column in this evolved database, the data in the Java-optimized data type is converted to data in the COBOL-optimized data type before returning the data to the requesting COBOL application. The first and second threshold may be set at variable levels according to the needs of the database customer. In this manner, the database may be dynamically tuned to optimize the performance of applications that access the database most frequently. By changing the first and second threshold levels, the database designer may trade off the performance penalty of converting data between data types with the space required to store reflective columns in the database.","One skilled in the art will appreciate that many variations are possible within the scope of the present invention. Thus, while the invention has been particularly shown and described with reference to preferred embodiments thereof, it will be understood by those skilled in the art that these and other changes in form and details may be made therein without departing from the spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF DRAWINGS","p":["The preferred embodiments of the present invention will hereinafter be described in conjunction with the appended drawings, where like designations denote like elements, and:",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 8","FIG. 7","FIG. 7"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 9","FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 10","FIG. 7"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 11","FIG. 7"]},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIGS. 12 and 13","FIG. 7"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIGS. 14 and 15","FIG. 8"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIGS. 16 and 17","FIG. 9"]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 20","FIG. 1"]}]},"DETDESC":[{},{}]}
