---
title: Super-resolution overlay in multi-projector displays
abstract: A technique, associated system and computer executable program code, for projecting a superimposed image onto a target display surface under observation of one or more cameras. A projective relationship between each projector being used and the target display surface is determined using a suitable calibration technique. A component image for each projector is then estimated using the information from the calibration, and represented in the frequency domain. Each component image is estimated by: Using the projective relationship, determine a set of sub-sampled, regionally shifted images, represented in the frequency domain; each component image is then composed of a respective set of the sub-sampled, regionally shifted images. In an optimization step, the difference between a sum of the component images and a frequency domain representation of a target image is minimized to produce a second, or subsequent, component image for each projector.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07097311&OS=07097311&RS=07097311
owner: University of Kentucky Research Foundation
number: 07097311
owner_city: Lexington
owner_country: US
publication_date: 20040419
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["This application claims the benefit of pending U.S. provisional patent application No. 60\/464,218 filed 19 Apr. 2003 for the applicants on behalf of the assignee hereof.","The invention disclosed herein was made with United States government support awarded by the following agency: National Science Foundation, under contract number NSF-4-65204. Accordingly, the U.S. Government has certain rights in this invention.","In general, the present invention relates to light projector systems used for displaying information on a target surface\u2014in the form of a superimposed image of images being projected from multiple projectors\u2014that is under observation of at least one camera. Traditional super-resolution (SR) reconstruction is the process of combining low resolution (LR) images projected from a multiple of front-projection devices in an attempt to recover a higher resolution image. More-particularly, the invention is directed to a technique and system for projecting a superimposed image onto a target display surface under observation of one or more cameras. First, a projective relationship between each projector being used and the target display surface is determined using a suitable calibration technique; aspects of the auto-calibration technique described by one of the applicants hereof in pending U.S. patent application Ser. No. 10\/727,953 \u201cMonitoring and Correction of Geometric Distortion in Projected Displays\u201d may be employed. A component image for each projector is then estimated, as represented in the frequency domain",{"@attributes":{"id":"p-0005","num":"0004"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msubsup":{"mi":["F","\u0394","p"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"r","mo":"=","mn":"0"},"mi":"N"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":"F","mrow":{"mi":["\u0394","r"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}},"mo":"."}}],"mo":"="}}},"br":{},"sub":["\u0394r","T"]},"The instant invention may be utilized in a wide variety of multi-projector display environments, especially those where higher resolution images are desired. By employing two or more projectors of traditional resolution capabilities, according to the invention, without increasing display size, one can achieve high resolution images. Such images are useful in displays used by the news media, for teleconferencing, for entertainment, as medical aides for surgery, for distributed rendering systems and high-resolution defense system displays, and so on. Other areas where decomposition of a higher-resolution image into its subpixel shifted components is useful include image decomposition for layered multichannel transmission and encoding, and visual cryptography. Further applications that benefit from higher resolution images include Infrared Imaging Systems, satellite imagery analysis, video forensics, medical and weather imaging and deep space photography where the increased spatial accuracy provides the ability to resolve small anomalies in the data.","Digital Projection: General Background Information. Digital Projection is Dominated by two technologies: liquid crystal display (LCD) and digital light processors (DLP). LCD projectors, as the name implies, use small transmissive LCD displays to create digital images. Transmittive projectors shine light through the image-forming element (CRT tube, LCD panel). Projectors using LCD typically have a projection lamp that provides a white light source. Light is split into three primary colors (red, green, and blue), and each color is then projected through a LCD display which allows the appropriate portion of light for the desired image to pass through. The 3 filtered colors are then optically recombined and projected for display. This technology appears in many of the portable projectors on the market today. Digital light processors reflect light off the image-forming element. The filtering device is an XY grid of digitally controlled micro-mirrors, constructed with micro-electro mechanical (MEMs) semiconductor technology. Each mirror can be independently tilted under digital control in only 15 millionths of a second. The frequency at which the bitstreamed image code directs each mirror to switch on and off determines the intensity reflected. For a RGB signal, the white light generated by the lamp passes through a color wheel that filters the light into red, green, and blue, from which colors are generated. The on and off states of each micromirror are coordinated with these three basic building blocks of color. Human eyes then blend these rapidly alternating flashes to see the intended hue in a projected image. Today, DLPs are proving highly scalable in resolution, but are limited by being more expensive than polysilicon panels. Since multiple images of different colors are projected in sequence, images can appear to break up into different colors, appearing with a red-green-blue rainbow flash around high-contrast edges.","One of the applicants hereof filed U.S. patent application Ser. No. 10\/727,953 entitled Monitoring and Correction of Geometric Distortion in Projected Displays on 3 Dec. 2003; subject matter of application Ser. No. 10\/727,953 and that of the instant application, as well as the pending provisional application to which this application claims benefit, was all commonly-owned by the assignee hereof at the time of invention. U.S. patent application Ser. No. 10\/727,953 is hereby fully incorporated by reference, and sections are set forth herein, for purposes of supporting one suitable technique of calibrating each projector p(or, also written as P) and camera cto recover homographies, H, thus providing a way to calculate an initial set of component image estimates.","The unique calibration technique for an immersive display produced using at least one camera and multiple projectors in application Ser. No. 10\/727,953 is used to continuously, automatically monitor and correct disparities in an environment under observation by at least one camera; the technique can detect and correct transient display artifacts and correct for miscalibration due to motion in the underlying devices, i.e., a rectification of arbitrary off-axis distortions that does not require user monitoring\/interaction to continuously monitor the state of calibration. The (one or more) camera(s) automatically detects when the projector's orientation has changed. The method runs in concert with interactive display applications and has minimal impact on frame-rate. An initial rectifying transform is recovered automatically by projecting target \u2018points\u2019, or fiducials\/targets of a selected intensity\/brightness distribution, and observing them within a camera. The display is then warped and passively monitored for calibration error and motion of the projector. A consistency\/correlation\/similarity score is calculated (and optimized) by, first, generating a predicted view based on the current framebuffer contents and correlating this prediction with the camera's captured, or observed, image. Aspects of that calibration technique, as well as the rigorous mathematical and engineering analyses performed in support thereof, are discussed in Robert M. {Matt} Steele, and Jaynes, Christopher O., \u201c,\u201d pgs. 1\u20138, Central European Conference on Computer Graphics and Computer Vision, 4\u20138 (Feb. 2002).","Building an immersive tiled display involves selection of a projector style, type of screen and supports, choice of display interface(s) and software, and method of interaction with the display. Importantly, a technique for integrating the image tiles into a seamless whole must be employed. Tile alignment, image overlap blending, intensity falloff correction, and color gamut matching and distortion correction, are a few of the areas of focus in developing tiled displays. Although prior virtual display designs have attempted to overcome super-resolution (SR) issues encountered when employing multiple projector displays in various configurations, the resolution limitation of projectors has hindered the rendering of truly reliable realistic virtual scenes. These prior displays are limited with respect to spatial resolution of the human visual system.","Rather than using partially overlapping projected images to achieve a wide-area display, as is conventionally often done to create tiled displays, projected images may be completely overlapped on top of one other to achieve the addition of light and color in an \u201coptical composition buffer.\u201d One hybrid projector-based rendering and display technique, called Computer Graphics Optique, was introduced by A. Majumder and G. Welch, \u201cComputer Graphics Optique: Optical Superposition of Projected Computer Graphics\u201d, , Stuttgart, Germany, Springer-Verlag, (May 2001) who used overlapping projectors to replace the analytical computation required for particular computer graphics rendering tasks.","The technique of \u201cstacking\u201d, or superimposing, multiple projector images on top of each other creates a region of a display surface illuminated by more than one projector, herein is referred to as \u201cOptical Framebuffer\u201d, or \u201cFramebuffer Optique\u201d. While a potential for intensity and contrast enhancement, as well as cooperative rendering of linear computer graphics operations of the Framebuffer Optique was noted by Majumder et al. (May 2001), applicants have taken a much different approach. Herein according to the invention, as one will appreciate, the Optical Framebuffer is uniquely utilized to produce high-resolution images from a composite of low-resolution components.","Traditional SR reconstruction addresses the problem of restoring a single SR image from a LR sample given other assumptions and constraints such as noise modeling and error energy. SR images can also be reconstructed from a sequence of LR frames whose relative displacements are known. The given LR input images are assumed to be noisy, down-sampled versions of an unknown SR image that is to be estimated. A common way of inverting the downsampling process is to write down the reconstruction constraints and then solve them, often adding noise prior to regularizing the solution. The first step is to register the images; i.e. compute the motion of pixels from one image to the others. The second step is a \u2018fusing\u2019 of the LR images into a super-resolution image. This fusion process is typically based on the constraints that the super-resolution image, and when appropriately warped and down-sampled to model the image formation process, should yield the low resolution inputs. Much of the narrow focus of traditional SR is toward producing SR still images from a video sequence\u2014several LR frames are combined to produce a single SR frame.","Traditional SR approaches typically have focused on the problem of producing SR still images from a video sequence\u2014wherein several LR frames are combined to produce a single SR frame. One traditional SR reconstruction attempts to compute an HR, noise-free image from a set of lower-resolution, potentially noisy images that are shifted with respect to one another. See, for example, FIG. 1 from M. Elad and A. Feuer, \u201cRestoration of a Single Superresolution Image from Several Blurred, Noisy, and Undersampled Measured Images,\u201d IEEE Transactions on Image Processing, Vol. 6, No. 12, (December 1997): which briefly describes certain aspects of four methods for superresolution restoration (pg. 1652) IBP method, a \u2018frequency domain approach\u2019, the POCS approach, and the MAP approach. Although research into multi-projector display systems remains healthy, there has been little work related to exploiting projector overlap. In contrast to earlier efforts by others, applicants utilize advantages of overlapping regions, the Framebuffer Optique, rather than seeking to remove or attenuate their effects\u2014to produce HR image overlay(s).","As mentioned, the inverse super-resolution (ISR) reconstruction technique of the invention uniquely comprises deriving low-resolution (LR) components of a given high-resolution target image, which when superimposed on the display surface (i.e., the LR components make up the Framebuffer Optique), produce an image that quite closely resembles a given target image. The resolution of the target image surpasses that of the component projectors. The multiprojector display is first calibrated and the general projective relationships between the rendering elements are derived and then converted to 2D shift matrices. The target image is then decomposed into appropriate LR components for each projector by downsampling and shifting using the corresponding 2D disparity derived from calibrating the display. Thus, as one will readily appreciate in connection with the instant technical disclosure, there are many fundamental distinguishing features of the instant invention\u2014the decomposition of a HR target image into its LR components\u2014from traditional SR.","It is a primary object of this invention to provide a technique, and associated system and computer executable program code on a computer readable storage medium, for projecting a superimposed image onto a target display surface that is of higher-resolution than the individual resolution capabilities of the projectors used to project the image. The technique of the invention may be employed in a myriad of front-projected display environments, whether single or multiple projectors and more than one camera is used; associated features of the system and program code will be accordingly adapted to additional projectors and cameras. While discussion herein focuses, by way of example for simplicity, on a two-projector one-camera pairing, more may be employed according to the invention.","As shown and supported, the invention includes a method, associated system and program code, for projecting a superimposed image onto a target display surface under observation of one or more cameras. First, a projective relationship between each projector being used and the target display surface is determined using a suitable calibration technique. A component image for each projector is then estimated using the information from the calibration, as represented in the frequency domain by:",{"@attributes":{"id":"p-0018","num":"0017"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msubsup":{"mi":["F","\u0394","p"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"r","mo":"=","mn":"0"},"mi":"N"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":"F","mrow":{"mi":["\u0394","r"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}},"mo":"."}}],"mo":"="}}},"br":{},"sub":["\u0394r","T"]},"There are numerous further patentably distinguishing features of the technique, system and program code of the invention. The step of determining a projective relationship can include: (a) observing the target display surface with camera, c; (b) recovering a homography between each projector, pi, and the camera, H, and (c) using this homography, H, determine the projective relationship, H, wherein b represents a reference frame for the target display surface. The step to determine the sub-sampled, regionally shifted images, can further include: (a) decomposing each projective relationship, H, into a linear shift matrix representing offsets between a respective of the projectors pi, and reference frame b; wherein (b) this linear shift matrix is used to determine the set of sub-sampled, regionally shifted images associated with a respective projector, pi. The step to minimize the difference between the sum of estimated components and the frequency domain representation of a target image, F[u, v], can be performed by:\n\n",{"@attributes":{"id":"p-0020","num":"0020"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"msup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mrow":[{"msub":{"mi":["F","T"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}},{"mo":["(",")"],"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"k"},"mo":"\u2062","mrow":{"msubsup":{"mi":["F","\u0394","i"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}}}}],"mo":"-"}},"mn":"2"}}},"ul":{"@attributes":{"id":"ul0003","list-style":"none"},"li":{"@attributes":{"id":"ul0003-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0004","list-style":"none"},"li":"\u2003wherein k represents the total number of projectors employed to project component images\u2014making up the superimposed image\u2014and the component image for each projector is represented by"}}}},{"@attributes":{"id":"p-0021","num":"0022"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"msubsup":{"mi":["F","\u0394","p"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"r","mo":"=","mn":"0"},"mi":"N"},"mo":"\u2062","mrow":{"msub":{"mi":"F","mrow":{"mi":["\u0394","r"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}}}],"mo":"="},"mo":","}}},"ul":{"@attributes":{"id":"ul0005","list-style":"none"},"li":{"@attributes":{"id":"ul0005-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0006","list-style":"none"},"li":["\u2003and the sub-sampled, regionally shifted images represented in the frequency domain are represented by F[u, v], to identify a second set of frequency domain coefficients for use in producing a frequency domain representation of the second component image for a respective one of the projectors; and","(b) taking the inverse Fourier transform of this frequency domain representation of the second component image, thus converting to spatial signal which can be fed into the projector for display."]}}}},"As can be appreciated, certain of the many unique features, as well as the further-unique combinations thereof, supported and contemplated hereby within the spirit and scope of this disclosure, may provide a variety of advantages. The advantages of these new features and combinations, as disclosed, will be better appreciated by perusing the instant technical discussion, including drawings, claims, and abstract, in light of drawbacks to traditional techniques identified throughout, or as may be uncovered. The unique technique and associated system and program code, provides design options and versatility to accommodate a wide variety of applications. Thus, it is noted that:","(a) Ease of operability\u2014An ability to utilize familiar, off-the-shelf multi-projector camera equipment for producing front-projected superimposed displays of sufficient resolution to carry out aspects of the invention, is provided.","(b) Flexibility of design and use\u2014The technique of the invention can be tailored for use with a wide variety of front-projected display equipment to display a myriad of different still-, motional-, video-, and so on, target images\/image functions.","(c) Manufacturability\u2014The unique technique and system of the invention can be tailored to current, as well as those under development or yet-to-be-developed, single and multi-projector-camera projection systems, providing a cost-effective means by which systems can be upgraded, or sold initially as a complete package.","In connection with discussing the features in , occasional reference will be made back-and-forth to other of the figures, all of which collectively detail core, as well as further unique and distinguishing features of technique of the invention at  and \u2014and further providing a pictorial demonstration of the flexibility of design of this invention. As one can appreciate, the configuration of the simplified projector-camera pair system  in  is suitable for a wide variety of display shapes and environments.",{"@attributes":{"id":"p-0034","num":"0037"},"figref":["FIG. 1","FIG. 2","FIG. 1"],"b":["10","22","24","28","50","24","1","6","8"]},"The technique requires at least two overlapping projectors Pand Pwhose view frustums illuminate a display surface-as shown in , \u2013,  by way of example, the display surface may be planar. During an initial calibration phase, a camera is used to recover a homography between each projector and a base projector frame (boxes , , , of  and box ,  of ). A base projector frame is aligned with the high-resolution space and only differs in its resolution. Sub-pixel overlap defines pixels in the high-resolution target frame\u2014for reference, see , \u2013, . Because each projector is related to the target frame via a general homography, the relative 2-D shift and sampling rate will change across the display. The component homographies are approximated by a set of 2-D sub-pixel shifts (referred to herein as a linear shift matrix) that represents the sub-pixel disparity of one projector with respect to the target image reference frame, for a given image sub-region (boxes , ,  and box , ). Although sampling rates change across the display, one may presume they are fixed as the mean pixel-sampling rate from each projector to the target frame. In practice, sampling rates change slowly for most configurations (i.e. projector optic axis somewhat orthogonal to the display), and do not govern the appearance of a component image. Component images are estimated in the frequency domain where the target image is sub-sampled and phase shifted according to the sampling rate and shift matrix for each component (at , ,  of  and boxes , , , . The resulting amplitudes and phase values are then optimized according to a cost function that measures the difference between the target image and the image that results from adding the multiple sub-sampled, shifted components together (box ,  and box , ). Component images are projected onto the display surface, resulting in a super-resolution image that more closely approximates the target than is possible with a single lower-resolution projector (box ,  and box , ).","Calibration. In order to compute the sub-pixel disparity between projectors and a target frame, pixel correspondences between any two projectors must be known to sub-pixel accuracy (for general reference, see , \u2013, ). The epipolar relationship between pairs of projectors and a known surface model is sufficient to compute pixel correspondences for every pixel in the Framebuffer. By way of example here, the display surface is constrained to be planar, so that the full projective relationship between any two devices, i and j can be modeled as a 3\u00d73 homography matrix that maps pixels in projector j directly to pixels in projector i, through the display plane. The homography can be automatically computed given a sufficient set of matchpoints between the two projectors in question. Matchpoints are first computed between a camera that observes the display surface, and each projector in the display. For each projector, a set of Gaussian target fiducials centered at randomly selected framebuffer pixels are iteratively displayed. The target is captured in the camera and a match-point pair is stored. The subpixel location of the target in the camera is computed through an optimization routine that estimates the parameters of homography, taking into account surface warp and the known Gaussian shape. See also,  and associated discussion, below.","Given a sufficient number of correspondences (, for example), a homography between each projector pi and the camera c, H, is then computed using linear least squares estimation (refer to , , ; boxes ,  of ; and boxes , ,  of ). These projector-to-camera matrices are then converted into a homography between each projector and the target image reference frame. An arbitrary projector framebuffer is selected as the base projector reference frame. Although the target frame and base projector framebuffer are of different resolutions (the target is presumed significantly higher), this projector defines the target space up to an unknown scale by assuming that the base framebuffer is axis-aligned with, and shares the origin of the target image space. Therefore, the relationship between any projector (i) and this target image frame (b) can be written as a composite homography, or H, from the projector (i) to the camera (c), and then to the base projector frame (b)\u2014see the and  schematic representations, boxes ,  of , and box , FIG. :\n\n=(H)\n","Multiple projectors overlap on the display surface and are each shifted with respect to the base frame. Shifted overlapping pixels give rise to the higher resolution space where sub-pixel shifts define integer pixels in the high-resolution target frame. By way of example only, in connection with any results shown here, it was assumed the sub-pixel calibration accuracy up to \u2155th of a pixel resulting in resolutions in the target frame that are 5-times those of component projectors.","For purposes of explanation, the low-resolution component images are modeled as sub-sampled versions of the image target with a uniform 2-D shift and sampling rate with respect to the target frame of reference. Since each projector is related to the target frame via a general homography, the relative 2-D shift and sampling rate will change across the display. The component homographies are approximated by a set of 2-D sub-pixel shifts (referred to as the linear shift matrix) that represents the sub-pixel disparity of one projector with respect to the target image reference frame, for a given image sub-region.","A projective warp between two projectors describes a more general displacement than uniform shift. To derive an appropriate component image, without the undue computation associated with a per-pixel solution, the homography is approximated by a set of 2-D shift vectors between a projector and the target display reference frame. Therefore, the homography between projector i and the base frame is decomposed into a linear shift matrix that represents 2-D offsets between the projector and the base reference frame. Each entry in the shift matrix corresponds to a region in the target reference frame for which the 2-D offset is assumed to be constant. Once computed, the shift matrix replaces the more general homography and regions in the component frame are related to the target frame through a constant, 2-D offset. Refer generally, to boxes , ,  of  and boxes , , and  of .","The 2-D disparity, \u0394, between a component projector reference frame pi and target frame b is written as the difference between the locations of a pixel in frame pi the same pixel in frame b (given by the known homography):\n\n\u0394=\n","The disparity in x and y directions (\u0394, \u0394) is independently given by:",{"@attributes":{"id":"p-0043","num":"0046"},"maths":[{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["\u0394","x"]},"mo":"=","mrow":{"msub":{"mi":["p","x"]},"mo":"-","mfrac":{"mrow":[{"msub":[{"mi":"H","mn":"1"},{"mi":["p","x"]}],"mo":"\u2062"},{"msub":[{"mi":"H","mn":"3"},{"mi":["p","x"]}],"mo":"\u2062"}]}}}}},{"@attributes":{"id":"MATH-US-00005-2","num":"00005.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["\u0394","y"]},"mo":"=","mrow":{"msub":{"mi":["p","y"]},"mo":"-","mfrac":{"mrow":[{"msub":[{"mi":"H","mn":"2"},{"mi":["p","y"]}],"mo":"\u2062"},{"msub":[{"mi":"H","mn":"3"},{"mi":["p","y"]}],"mo":"\u2062"}]}}}}}],"br":{},"sub":["k ","pi","x ","y "],"sup":["th ","b"]},"As x ranges from zero in the component projector to x, the resolution of projector in the x direction, the disparity values will vary in accordance with the line equation given above. This line is divided into k equal regions such that the disparity values in the region are all within \u03b5of one another. Conceptually, these k regions are columns in the component image that will use the same approximate x-shift values, \u02dc\u0394, for the purposes of deriving the component image corresponding to pixels contained in that column. Given the line equation for independent disparities in the y direction (above), a similar process divides the component frame into rows of uniform y-disparity with error tolerance \u03b5. These regions are combined to produce regions in the component image containing approximate values for 2-D shifts that are within \u03b5\u2266\u221a{square root over (\u03b5+\u03b5)} of the values represented in the actual homography. Therefore, for a given error tolerance E (by way of example, one may select as 0.2 pixels), the homography can be decomposed into areas of uniform disparity. These region-based 2-D approximate shifts, (\u02dc\u0394, \u02dc\u0394), and the corresponding offset of the region itself, (O, O), are used to derive the component image for a respective projector.  depicts ten regions  corresponding to a 5\u00d72 shift matrix, computed from the homography between a respective projector to the base frame for a two-projector setup. Given a fixed error tolerance, for example, the number of regions computed by this process is related to the amount of projective (off-axis) distortion induced by the viewing geometry.","Component Image Estimation. Component image estimation is performed in the frequency domain where initial images are first estimated (box ,  and box , ) and then optimized (box ,  and box , ). Component images are not constructed in the spatial domain because overlapping pixel intensities and the constraints they represent are difficult to characterize. Rather, a given target image is first converted to the resolution of the Framebuffer Optique, defined by the sub-pixel shift pattern recovered in the calibration phase. This target image I(x,y) is converted to a corresponding discrete Fourier transform (DFT) F(u, v)\u2014box ,  and box , .","Referencing also the high-level flow diagram in , at , a component image for a particular projector is estimated in two phases. First, sub-components for the n regions of uniform disparity are derived (see also, ). Following that, sub-components are combined to form a single component image for the projector. The target image DFT is sub-sampled at a rate of Rand Rbased on mean sampling-rate derived from the calibration phase for a particular component projector with respect to the target frame. The DFT of the target image F(u, v), and the sampled component image, F(u, v), are related via aliasing:",{"@attributes":{"id":"p-0047","num":"0050"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["F","S"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}},{"mi":"\u03b1","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"p","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"q","mo":"=","mn":"0"},{"mi":"M","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"msub":{"mi":["F","T"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mfrac":{"mi":"k","msub":{"mi":["MR","x"]}},"mo":"+","msub":{"mi":["pf","sx"]}},{"mfrac":{"mi":"l","msub":{"mi":["NR","y"]}},"mo":"+","msub":{"mi":["qf","sy"]}}],"mo":","}}}}}}],"mo":"="}}},"br":[{},{},{}],"sub":["sx","x ","sy","y ","x","y","x","y","x","x","y","y","\u0394r","s","\u0394r "],"sup":["r","r","r","r","r","r","r","r","j2\u03c0((\u02dc\u0394",{"sub2":"x"},{"sup2":"r"},"+O",{"sub2":"x"},{"sup2":"r"},")u+(\u02dc\u0394",{"sub2":"y"},{"sup2":"r"},"+O",{"sub2":"y"},{"sup2":"r"},")v)"],"in-line-formulae":[{},{}],"i":["F","[u,v]=e","F","u,v"]},{"@attributes":{"id":"p-0048","num":"0051"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msubsup":{"mi":["F","\u0394","p"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"r","mo":"=","mn":"0"},"mi":"N"},"mo":"\u2062","mrow":{"msub":{"mi":"F","mrow":{"mi":["\u0394","r"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}}}],"mo":"="}}}},"Optimization. Component images, computed for each overlapping projector, are derived independently. These initial components do not take the additive nature of the superposition process into account and are, thus, adjusted in an optimization phase. Each derived component image for each of the k projectors, F, is treated as the initial estimate for an optimization phase that seeks to minimize the difference between the sum of the different components and the image target. The superposition process is modeled on the display surface as additive, and the following expression is minimized:",{"@attributes":{"id":"p-0050","num":"0053"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"msup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mrow":[{"msub":{"mi":["F","T"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}},{"mo":["(",")"],"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"0"},"mi":"k"},"mo":"\u2062","mrow":{"msubsup":{"mi":["F","\u0394","i"]},"mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mi":["u","v"],"mo":","}}}}}],"mo":"-"}},"mn":"2"}}},"br":{},"figref":["FIGS. 1 and 2","FIG. 7"],"b":["20","60"]},"Optimization is key to producing super-positioned images that more closely resemble the target image function. A more accurate initial estimate of the component projector images prior to optimization, to more-efficiently utilize computing resources. The optimization step yields a new set of component DFT coefficients for each projector. The frequency domain representation is then converted to a spatial signal via the inverse Fourier transform that can then be placed directly into the Framebuffer of each component projector for display on surface . Please refer to  at ,  and  and .","The inverse of the sub-sampled and shifted Fourier series yields the image H(x,y) to be rendered by the component projector p.\n\n()=()\n\nThe inverse DFT of an image signal (IDFT) is defined by:\n",{"@attributes":{"id":"p-0053","num":"0056"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mrow":[{"msub":{"mi":["H","p"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mfrac":{"mn":"1","mrow":{"mi":["M","N"],"mo":"*"}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"u","mo":"=","mn":"0"},{"mi":"M","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"v","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mrow":{"msubsup":{"mi":["F","\u0394","p"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["u","v"],"mo":","}}},"mo":"\u2062","msup":{"mi":"\u2147","mrow":{"mi":"j2\u03a0","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":[{"mi":["ux","M"]},{"mi":["vy","N"]}],"mo":"+"}}}}}}}}}],"mo":"="},{"mi":"x","mo":"=","mn":"0"},{"mi":"M","mo":"-","mn":"1"},{"mi":"y","mo":"=","mn":"0"},{"mrow":{"mi":["\u2026","N"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},"mo":"-","mn":"1"}],"mo":[",","\u2062",",",",",",","\u2062",",",",",",",",",","],"mstyle":[{"mtext":{}},{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}}],"mn":["1","2","1","2"],"mi":"\u2026"}}},"br":{}},{"@attributes":{"id":"p-0054","num":"0057"},"maths":[{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["\u0394","x"]},"mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"99.6"},{"mn":"99.24"},{"mn":"98.7"},{"mn":"98"}]},{"mtd":[{"mn":"99.8"},{"mn":"98.84"},{"mn":"98.3"},{"mn":"97.5"}]},{"mtd":[{"mn":"100.28"},{"mn":"99"},{"mn":"98.24"},{"mn":"97"}]},{"mtd":[{"mn":"100.54"},{"mn":"99.78"},{"mn":"99"},{"mn":"96.4"}]}]}}}}},{"@attributes":{"id":"MATH-US-00010-2","num":"00010.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["\u0394","y"]},"mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"39.4"},{"mn":"39.24"},{"mn":"38.7"},{"mn":"38"}]},{"mtd":[{"mn":"39.6"},{"mn":"38.84"},{"mn":"38.3"},{"mn":"37.2"}]},{"mtd":[{"mn":"40.26"},{"mn":"40.42"},{"mn":"39.2"},{"mn":"37.7"}]},{"mtd":[{"mn":"40.5"},{"mn":"39.78"},{"mn":"39"},{"mn":"35.9"}]}]}}}}}]},"TABLE 1, below, lists different types of high-resolution satellite imagery and the number of 1024\u00d7768 projectors at about 15 feet from the display wall employed to render these images effectively at original resolution, by way of example only.",{"@attributes":{"id":"p-0056","num":"0059"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"84pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"High-","No. of Projectors","Display Surface"]},{"entry":[{},"Resolution","required","area in ft."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"49pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Satellite","Satellite","ISR","Traditional","ISR","Traditional"]},{"entry":["Information","Images","approach","tiled display","approach","tiled display"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["Geostationary","2291 \u00d7 2500","4","12","8 \u00d7 6","18 \u00d7 20"]},{"entry":"Meteorological"},{"entry":"Satellite"},{"entry":["Galilean Satellites","5748 \u00d7 2874","6","24","8 \u00d7 6","36 \u00d7 20"]},{"entry":["Voyager","5760 \u00d7 2880","6","18","8 \u00d7 6","36 \u00d7 20"]},{"entry":["Galileo-Voyager","4137 \u00d7 2069","5","15","8 \u00d7 6","30 \u00d7 15"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}]}}},"Notice, here, that the number of projectors required in typical tiled rendering approaches is a multiple of that needed using the ISR technique according to the invention. The display surface area is measured in a front-projector display setup with projectors about 15 feet away from the wall and almost orthogonal to it. A single projector 15 feet away from the display surface typically covers about 6\u00d75 ft. Hence a constant display area, determined by the display setup, is specified. By way of further example, only: High-resolution image files of digital library collections such as the \u201cElectronic Beowulf\u201d are 2320 by 3072 pixels in size, occupying 20\u201325 MB of memory. Employing the ISR technique of the invention can reproduce an approximation of high resolution images using four projectors of resolution 1024\u00d7768 by dividing the high resolution imagery amongst them. Traditional tiled display wall applications would require twelve 1024\u00d7768 projectors to render the same.","Now turning specifically to : It is a system schematic similar to that labeled as  in calibration technique patent application Ser. No. 10\/727,953 (having a common applicant hereto). Schematically depicted at , data\/information flow in connection with a multi-projector system (framebuffers are identified , , and  and associated with a respective projector and each camera  and ). Preferably, at least one camera is able to observe the screen surface at all times for which the process of detecting is engaged. For example, the placement of the cameras in the display environment might be: mounting overhead to minimize the chance of occlusion by the user.","Calibration of each device within the system engaged in producing the display is critical to detection and a resulting corrective adjustment. Initially, changes due to unexpected radiometric artifacts on the display surface are detected. Predicted imagery is constructed for a specific camera position and color transfer function and compared to captured images. Predicted images ,  are constructed using the identified position of the camera with respect to each projector as well as a unique color (transfer function) calibration phase applied in a straightforward manner. Given a camera-projector pair, geometric calibration comprises the transformation from pixels in the camera plane (shown within box defined at  and box defined at ) to their corresponding positions in the projectors' frame buffers (depicted within dashed box  are three framebuffers identified as \u2013). Given this transform, regions in shadow, observed in a camera, can then be correctly adjusted in the projected imagery. Once the homography between each projector and the camera has been recovered (boxes , , A and boxes , , B), a composition homography can be constructed to relate projector pixels to one another. Each projector projects a grid pattern that is parallel the axes of its own framebuffer. Given the known calibration, a coherent grid can be drawn by all projectors in the respective reference frame of a single projector.","Provided, next, for reference only in connection with calibration () to identify homographies between the camera and each projector, the auto-calibration technique in U.S. patent application Ser. No. 10\/727,953 entitled Monitoring and Correction of Geometric Distortion in Projected Displays, describes the operation of that technique, as follows:\n\n","In connection with step 3. outlined above, note that a \u201cpoint\u201d target is projected at some preselected location of the projector's framebuffer. Preferably according to the invention, the target\/fiducial takes the form of a projected white, filled-in circle, or Guassian distribution of light intensities, comprising a white center that fades into darker shades of gray the further one moves from the white center, until the surrounding region is solid black (resulting in a blurred, filled-in circle)\u2014the intensity (brightness, or whiteness) of this fiducial being governed by the following expression:\n\n()=\n\nThis expression defines circularly symmetric two-dimensional Gaussians\u2014or, blurred circles\u2014of a preselected size, where \u201csigma\u201d, the variance, is a value set such that the blurred circular targets are of the selected size (by way of example only, sigma can be set between \u02dc5 and 15 pixels).\n","Referring to step ., an alternative to that outlined above, includes the following: While a rectangle (bounding box) can be computed around the identified conglomeration (blob) of white pixels, the center of which, (c, c) is used as an estimate of where the camera saw the \u201cpoint\u201d projected, such a bounding box can also be constructed for the largest conglomeration (blob) of white pixels in the projector framebuffer. For this bounding box, let's say that its top is at p+sigma, it's bottom is at p\u2212sigma, its left edge is at p\u2212sigma, and it's right edge is at p+sigma. Note that the projector bounding box has four corners, as does the bounding box drawn\/calculated for the blob in the camera. One can then list four correspondences, consisting of: [(upper-left corner of projector's bounding box), (upper-left corner of camera's bounding box)]; [(upper-right corner of projector's bounding box), (upper-right corner of camera's bounding box)]; and so on. These four correspondences can be used to compute a homography matrix, call it H. Next, for example, one can evaluate a normalized cross correlation\u2014an image \u201csimilarity\/correlation score\u201d that is well-known in image processing and computer vision\u2014on those pixels that fall inside the bounding box computed for the camera. This similarity score, as a function of H, is maximized: Hhas 8 parameters (here, one can take advantage of the radial symmetry of the Gaussian pattern selected to reduce Hto 7 parameters, to speed up computation); using an iterative multidimensional optimization technique such as MINPACK's lmdif( ) searcher or Numerical Recipes in C API (\u201capplication programming interface\u201d)\u2014both of which are currently distributed, find the Hthat maximizes the similgarity score. From this H(using the H output by the search technique), take (c, c)=H(p, P). One can then output the [(P, p), (c, c)], which is the correspondence sought (step  above).",{"@attributes":{"id":"p-0063","num":"0078"},"figref":["FIGS. 4","FIG. 5","FIG. 5"],"b":["5","5","6","110","1","2"],"i":["a","b","a","a"],"sub":["1 ","2"]},"Theoretically, the optimization technique can be broken down another way as follows:","Given\n\n","Derive the contents of all c such that the difference between the composition of c and T is minimized. That is,",{"@attributes":{"id":"p-0067","num":"0085"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"msup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"c","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","msub":{"mrow":{"msubsup":{"mi":["P","c","T"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},"mi":"c"}},"mo":"-","msub":{"mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}},"mi":"T"}}},"mn":"2"}}},"br":[{},{}]},{"@attributes":{"id":"p-0068","num":"0086"},"figref":"FIG. 5","i":"b ","sub":["1 ","1 ","2"],"b":["2","1"]},"An example experimental setup is shown in  at . The projectors, P and P, with frustums, S and S, overlap and form the Framebuffer Optique (R) whose pixels are defined by the overlap and the relative shift of the component projectors Hand Hare the planar projective transforms between each projector and a camera C obtained during a calibration phase. One of the projectors can be selected as the reference projector. The other rendering elements are related to this reference frame via a general planar projective relation derived during calibration. This projective relationship between the display elements can be written as a 3\u00d73 homography. After the decomposition process, the component images are rendered by P and P and superimposed to achieve the superimposed image. Thus, as shown and labeled here by way of example, in deriving a set of component images, each projector, P, is calibrated to the reference frame, R, to determine the relative sub-pixel shift.","One again as mentioned,  is a high-level depiction in flow-diagram format of a technique  of the invention. As mentioned, the focus of image reconstruction according to the invention is deriving an appropriate component image for each projector's framebuffer to be projected: The target image is decomposed into the shifted and sub-sampled image components. Component images are then manipulated so as to minimize the difference between the sum of the components and the target image. These primary steps are summarized below:\n\n",{"@attributes":{"id":"p-0071","num":"0092"},"figref":"FIG. 8"},"While certain representative embodiments, examples, and details have been shown merely for the purpose of illustrating the technique and an associated system and program code of the invention, those skilled in the art will readily appreciate that various modifications, whether specifically or expressly identified herein, may be made to any of the representative embodiments without departing from the novel teachings or scope of this technical disclosure. Accordingly, all such modifications are contemplated and intended to be included within the scope of the claims. Although the commonly employed preamble phrase \u201ccomprising the steps of\u201d may be used herein in a method claim, applicants do not intend to invoke 35 U.S.C. \u00a7112 \u00b66. Furthermore, in any claim that is filed herewith or hereafter, any means-plus-function clauses used, or later found to be present, are intended to cover at least all structure(s) described herein as performing the recited function and not only structural equivalents but also equivalent structures."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","Field of the Invention","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF EMBODIMENTS DEPICTED IN DRAWINGS"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["For purposes of illustrating the innovative nature plus the flexibility of design and versatility of the preferred system and technique disclosed hereby, the invention will be better appreciated by reviewing the accompanying drawings (in which like numerals, if included, designate like parts). One can appreciate the many features that distinguish the instant invention from known, attempted SR projection techniques. The drawings have been included to communicate the features of the innovative platform structure and associated technique of the invention by way of example, only, and are in no way intended to unduly limit the disclosure hereof.",{"@attributes":{"id":"p-0027","num":"0030"},"figref":"FIG. 1","b":["10","24"]},{"@attributes":{"id":"p-0028","num":"0031"},"figref":["FIG. 2","FIG. 1"],"b":["50","24","1","6","8"]},{"@attributes":{"id":"p-0029","num":"0032"},"figref":["FIG. 3","FIG. 2"],"b":["120","1","2","3","1","2"]},{"@attributes":{"id":"p-0030","num":"0033"},"figref":"FIGS. 4","b":["5","5","6"],"i":["a","b"],"sub":["1 ","2"]},{"@attributes":{"id":"p-0031","num":"0034"},"figref":"FIG. 7","b":"70"},{"@attributes":{"id":"p-0032","num":"0035"},"figref":"FIG. 8","b":"10"}]},"DETDESC":[{},{}]}
