---
title: Enabling streaming to a media player without native streaming support
abstract: A method for enabling streaming to a media player without native streaming support is disclosed. Step (A) of the method may author a media file based on a content signal. The media file may have an indexed format compatible with the media player. The content signal may (i) be received from a remote server through a network, (ii) use a transfer protocol and format at least one of which is incompatible with the media player and (iii) convey both video data and audio data representative of a scene. Step (B) may generate a local signal carrying the media file. The local signal generally has a transfer protocol compatible with the media player. Step (C) may transfer the local signal to the media player while the content signal is being received. The media player generally recreates the video data as a visual depiction on a display based on the local signal.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08719437&OS=08719437&RS=08719437
owner: Avvasi Inc.
number: 08719437
owner_city: Kitchener, Ontario
owner_country: CA
publication_date: 20090813
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["The present invention relates to streaming video generally and, more particularly, to a method and\/or architecture for enabling streaming to a media player without native streaming support.","Many conventional media-capable platforms and media players support only a subclass of available content delivery protocols. The delivery subclass is usually limited to the Hypertext Transport Protocol (HTTP), commonly referred to as a progressive download (PD) protocol. In such environments, a client media player requests a file from a web server. The web server responds to the request by delivering the file via HTTP\/TCP (Transmission Control Protocol).","The file is typically organized in an indexed format that is similar or related to the International Organization for Standardization (ISO) base media file format. In the ISO base media file format, an index or metadata is used to seek and decode the content samples of the file. The index is usually found in a single section of the file. The index is typically stored at the start or at the end of the file. Such file formats infer an MPEG-4 systems-like environment.","Encoding\/authoring of content in an indexed format relies on the knowledge of the size of the media samples because the metadata contains a complete table of contents with size\/position information for all samples in all tracks for the entire clip. Therefore, a size of all compressed audio and video frames must be set before the authoring is finalized, and cannot be changed afterwards.","Streaming formats, such as Real-time Transport Protocol (RTP), Flash Video (FLV) format and MPEG-2 Transport Stream (TS) format, do not have an index and are not interoperable with the MPEG-4 systems-like environments. Many platform\/media players either have no support or very poor (i.e., unstable) support for such formats. Other conventional platforms\/players are limited in terms of the mix of formats and transport protocols supported. For example, some platforms\/players lack RTP\/TCP support and only provide unreliable RTP\/UDP (User Datagram Protocol). Other conventional platforms\/players have a limited ability to buffer data received at an input.","The limitations cause several disadvantages, such as unbounded content, unknown size content, incompatible content and unreliable networks. For example, live content or content in the process of being encoded is unbounded. However, authoring of unbounded content cannot be finished and therefore cannot be accessed until after the encoding has completed. As such, any stored content having a size that changes dynamically during the act of delivery is difficult to process. For example, transcoding of content during delivery to compensate for varying network conditions can alter the size of the content. Availability of the content on a platform\/device can be hindered by format incompatibilities or complicated by managing multiple formats. Content providers are either locked out of certain platforms\/media players or forced to make content available in many formats. Limiting delivery of the content to a few supported formats can be less reliable and\/or efficient than non-supported formats for a given application or service. For example, using TCP can provide more robust transmission and playback during lossy network conditions than UDP. Furthermore, some supported formats are unable to monitor or control the amount of data in the client buffer resulting in transmission problems during dynamic network conditions.","The present invention concerns a method for enabling streaming to a media player without native streaming support. Step (A) of the method may author a media file based on a content signal. The media file may have an indexed format compatible with the media player. The content signal may (i) be received from a remote server through a network, (ii) use a transfer protocol and format at least one of which is incompatible with the media player and (iii) convey both video data and audio data representative of a scene. Step (B) may generate a local signal carrying the media file. The local signal generally has a transfer protocol compatible with the media player. Step (C) may transfer the local signal to the media player while the content signal is being received. The media player generally recreates the video data as a visual depiction on a display based on the local signal.","The objects, features and advantages of the present invention include providing a method and\/or architecture for enabling streaming to a media player without native streaming support that may (i) leverage native player efficiencies, (ii) optimize battery life, (iii) optimize user experience, (iv) optimize playback quality, (v) remove non-causality of indexed file formats for transmission, (vi) enable unbounded content with minimal to no latency, (vii) permit dynamic and continuous adaptation to unbounded size content, (viii) leverage formats not normally supported by the native players, (ix) increase content ubiquity\/accessibility by bringing previously unsupported formats to a platform and\/or (x) increase flexibility of protocol mix for applications\/services to optimize resources.","Some embodiments of the present invention may enable interoperability between non-native media player compliant formats available from a variety of remote streaming servers and MPEG-4 systems-like environments of media players that are native to media-capable platforms and\/or devices. The platforms\/devices may include, but are not limited to cellular telephones, personal digital assistants, portable video players, personal computers and the like. Hereafter, the media-capable platforms and devices may be generically referred to as apparatuses or devices. The term \u201cformat\u201d generally refers to how data is arranged. The term \u201cprotocol\u201d generally refers to how data is transferred. The term \u201cmedia\u201d may refer to video, audio, images or a combination of some or all (e.g., movies).","Referring to , a block diagram of a system  is shown in accordance with a preferred embodiment of the present invention. The system generally comprises a server (or computer) , a network  and an apparatus (or device) . The server  and the apparatus  may represent modules and\/or blocks that may be implemented as hardware, software, a combination of hardware and software, or other implementations.","The apparatus  generally comprises a media-capable device. In some embodiments, the apparatus  may be implemented as a computer, an entertainment system, video-game console and the like. User interaction with the apparatus  may be through dedicates controls, a keyboard, a mouse, a touchscreen, a hand-held remote control device and the like. In other embodiments, the apparatus  may have a sufficiently compact size and light weight to be easily carried by a user with a single hand. A layout of the apparatus  may allow the user to operate the apparatus  with a single hand while holding the apparatus  in the same hand.","The network  may be implemented as a wired network and\/or a wireless network. The server  and the apparatus  are generally physically remote and separate from each other. As such, the server  may be referred to as a remote server.","A bi-directional signal (e.g., NNMPC) may be exchanged between the server  and the apparatus  through the network . The apparatus  may receive a signal (e.g., INPUT) from a user. An optical signal (e.g., PICTURES) may be generated by the apparatus  and presented to the user. The apparatus  may also generate an audio signal (e.g., SOUND) that is presented to the user. In some embodiments, the signal SOUND may comprise an electrical signal.","The apparatus  generally comprises a circuit (or module) , a circuit (or module) , a circuit (or module) , a circuit (or module)  and a circuit (or module) . The circuits  to  may represent modules and\/or blocks that may be implemented as hardware, software, a combination of hardware and software, or other implementations. In some embodiments, the apparatus  may be powered through a cord plugged into a wall socket. In other embodiments, the apparatus  may be battery powered to allow for ease of mobility.","The signal NNMPC may be both received into and presented from the circuit . As received into the circuit , a format of the signal NNMPC may be Non-Native Media Player Compliant. A signal (e.g., DATA) may be exchanged between the circuit  and the circuit . The signal INPUT may be received by the circuit . A signal (e.g., CMD) may be generated by the circuit  and presented to the circuit . A signal (e.g., VIDEO) may be generated by the circuit  and transferred to the circuit . The circuit  may generate a signal (e.g., AUDIO) that is presented to the circuit . The circuit  may generate and present the signal PICTURES. The signal SOUND may be generated and presented by the circuit .","The circuit  may be implemented as a processor circuit. The circuit  is generally operational to execute software programs to change the content received in the signal NNMPC into the signal VIDEO and the signal AUDIO. Selection of the content and control of the playback may be governed by the signal CMD.","The circuit  generally implements a memory circuit. The circuit  may be operational to store the software programs executed by the circuit . The circuit  may also act as temporary storage for information generated and consumed during the requesting and playback of the content received from the server .","The circuit  may implement a user interface circuit. The circuit  is generally operational to generate the signal CMD based on instructions received from the user via the signal INPUT. The circuit  may be implemented as switches, buttons, touch sensitive screens, keyboards, computer mice and the like.","The circuit  generally implements a video display screen. The circuit  may be operational to convert the video content received in the signal VIDEO into a sequence of visible pictures represented by the signal PICTURE. The visible pictures may be viewable by the user.","The circuit  may implement one or more speakers and\/or a headphone jack. The circuit  is generally operational to convert the audio data received in the signal AUDIO into the signal SOUND. In some embodiments where the circuit  comprises one or more speakers, the signal SOUND may be an audible sound that the user hears. In other embodiments where the circuit  comprises an audio jack, the signal SOUND may be an electronic signal suitable for driving a set of headphones.","The circuit  generally comprises a module (or block) , a module (or block)  and a module (or block) . The modules  to  may represent circuits and\/or blocks that may be implemented as hardware, software, a combination of hardware and software, or other implementations. In some embodiments, the modules  to  may be implemented as software modules (or code) stored in the circuit  and executed by the circuit .","The module  may send to and receive signal communications from the server  via the signal NNMPC. The module  and the module  may communicate with each other via a signal (e.g., A). The module  and the module  may communicate with each other through a signal (e.g., B). The module  may communicate with the circuit  through the signal CMD. The module  may generate the signals VIDEO and AUDIO.","The module  may implement a network interface module. The module  is generally operational to communicate with the server  through the network  to request and receive media content. A particular content being requested may be identified by the module  to the module  using data in the signal A. The content received from the server  may be parsed into video data and audio data and presented back to the module  in the signal A.","In an example case, a Real Time Streaming Protocol (RTSP) conversation may be initiated between the module  and the server . The server  may deliver the individual media tracks from a source audio\/video clip in related RTP streams. Where converting from RTP to an MPEG-4 Part 14 (MP4) container format, non-causal header data may be generated for the MP4 container. The data generally includes sequence level information such as audio sampling rate and video frame size and video frame rate. The information may be readily derived from the various content access or transport protocols discussed above, for example from a Session Description Protocol (SDP) in a prior RTSP conversation. The data may also include complete sample size and position information. If the data is local to a client and not being transmitted over the network , the sample sizes may be defined as maximum in a worst-case sense for the given stream.","The module  generally implements a converter module. The module  may be operational to convert the video data and the audio data received from the module  to a native media player compliant format intended for the module . The module  may subsequently arrange the non-compliant format received data into one or more final formats that are compatible with the module .","The module  may implement a media player. The module  is generally operational to convert the content received in the signal B into the signal VIDEO and the signal AUDIO. In some embodiments, the module  may be native (e.g., built-in) to the apparatus . In other embodiments, the module  may be added (e.g., downloaded) into the apparatus . The module  may be configured to minimize resource use, such as battery consumption, processor use and\/or memory use.","Most implementations of the module  may support indexed formats. However, some implementations may have minimal support for streaming (or non-indexed) formats. Some of the modules  may be invoked sequentially and served blocks of memory containing non-overlapping clips while maintaining a smooth playback. Some modules  may be invoked via a Uniform Resource Identifier (URI), in which case a single instance is executed by the circuit . Therefore, the entire media clip may be provided to the module  to allow a smooth playback.","The module  generally commands the module  to obtain particular content from the server . The content may be received by the module  via an interconnect through the network . The content may be parsed into queues conveyed to the module  via the signal A. The module  may generate appropriately formatted data in the signal B from the queued data. The data, or consumable portions of the data, may be transferred to the module  for normal processing. The data is generally sent to the module  with a protocol supported by the module .","Content may be accessed from the server  using one or more protocols. For example, the module  may use RTSP or HTTP to request transmission of a particular content from the server . The content may be delivered by the server  to the apparatus  using one or more formats and\/or protocols. In some situations, the format may be a streamable or a streaming format, such as the Real-time Transport Protocol (RTP) format, Flash Video (FLV) format, MPEG-2 Transport Stream (TS) format, fragmented MP4 format and the like. The streaming formats generally allow representations of streams of unknown\/unbounded length as well as known\/finite length streams. For example, a live broadcast may be represented by an unbounded length stream. An example of a known or finite length stream may be a broadcast of a pre-recorded program.","The server  may also generate the signal NNMPC carrying indexed formats. The indexed formats may include, but are not limited to the MP4 format, QuickTime MOV format (QuickTime\u00ae is a trademark of Apple Inc., Cupertino, Calif.), and Third Generation Partnership (3GP) format for non-native media player compliant applications. Proprietary indexed formats may be used in non-native media player compliant applications. Other indexed formats may be implemented to meet the criteria of a particular application.","The formats may also be categorized as streaming or streamable formats that may include, but are not limited to, the RTP format, FLV format, fragmented MP4 format and MPEG-2 transport stream format. The above formats may be used in non-native media player compliant applications. Other proprietary formats may also be used in non-native media player compliant applications to meet the criteria of a particular application.","In an example case of a fragmented MP4 format, subsections of clips may be authored incrementally. Each subsection may have a corresponding duration ranging from several milliseconds to several seconds. Metadata may be created only for the particular subsection being authored. In an example case of a proprietary MP4-like format, the metadata, sample data or some combination of the two, may not comply with a known standard. An example of non-compliant sample data may have each sample include a non-compliant field expressing a number of real sample bytes\/words (or conversely the number of padding bytes\/words) within a padded sample.","Delivery of the content streams to the apparatus  may be achieved, at least in part, through a wireless channel in the network . Example wireless networks may include, but are not limited to, a wireless Ethernet network, a WiFi network, a 2G network, a 3G network and the like. The network  may include, at least in part, a wired channel. Transport through the network may be controlled by the Transmission Control Protocol (TCP), User Datagram protocol (UDP) and the like.","One or more methods may be used to move the content through the network . For example, servers may send the content using the RTP format interleaved with an RTSP\/TCP flow. The interleaving technique may be referred to as RTP\/RTSP over TCP and\/or interleaved RTP. Furthermore, an RTP\/RTSP over UDP approach may comprise RTSP in a TCP flow and\/or RTP in UDP flows.","Servers may provide the content through either a progressive download or a stream. For example, web servers may deliver the content as a linked object (e.g., a file) over HTTP (e.g., a progressive download case). The term \u201cweb server\u201d generally refers to servers that support progressive downloads. In another example, a streaming server may deliver content through a streaming protocol. An example of a streaming server is a server that delivers the content via RTP. Other types of servers may be implemented to meet the criteria of a particular application.","The server  may receive the content from one or more local and\/or remote sources. In some embodiments, the content may be stored local to the server  in the media (e.g., file descriptors). In other embodiments, the content source may be accessed by the server  over Serial Advanced Technology Attachment (SATA) interface, an Integrated Device Electronics (IDE) interface, a Peripheral Component Interconnect (PCI) interface, a Universal Serial Bus (USB) interface, an IEEE 1394 bus interface and the like. The content may also be available via network stored media (e.g., sockets). Furthermore, the content may be provided live to the server  through audio\/video interfaces in real-time. The live content may be raw data of scenes as captured by cameras and microphones. The live content may be encoded prior to or after reaching the server .","Referring to , a detailed block diagram of the module  and the module  is shown. The module  generally comprises a module (or block)  and a module (or block) . The module  generally comprises a module (or block)  and a module (or block) . The module  generally comprises a module (or block)  and a module (or block) . The modules  to  may represent circuits and\/or blocks that may be implemented as hardware, software, a combination of hardware and software, or other implementations.","The signal NNMPC may be exchanged between (i) the server  and the module  and (ii) the server  and the module . The signal A may be exchanged between (i) the module  and the module  and (ii) the module  and the module . A signal (e.g., CMP) may be exchanged between the module  and the module . The module  may exchange the signal B with the module .","The module  may be implemented as a client circuit or client software. In some embodiments, the module  may implement an RTSP\/RTP client. The module  is generally operational to communicate with the server  to request the intended content as selected by the user and to manage the full session life cycle.","Requests for the content may include, but are not limited to, file access requests, HTTP requests, RTSP requests and the like. Network requests typically involve a streaming format-specific conversation (e.g., an AppleTalk Transaction Protocol conversation or an RTSP conversation. AppleTalk\u00ae is a trademark of Apple Inc., Cupertino, Calif.). Communication of the requests may be via an interconnect, examples of which are generally provided below.","Typical commands that the module  sends to the server  during an RTSP conversation generally include a DESCRIBE command, a SETUP command, a PLAY command, a PAUSE command and a TEARDOWN command. Other commands may be implemented to meet the criteria of a particular application.","The module  may implement a transport input circuit. The module  is generally operational to receive the content in the signal NNMPC via the interconnect. For example, incoming RTP packets received after the PLAY command is executed may be processed by the module .","The server  may reply to a DESCRIBE command with a response that contains SDP data. The following pieces of information may be extracted from the SDP by the module  that may be useful to create an indexed format file: (i) audio clocks per second, (ii) video clocks per second, (iii) frame rate, (iv) number of audio channels and (v) codec specific information.","The module  may also stitch received packets into complete units (e.g., audio and video frames). For audio packets, some initial bytes may be stripped from the payload to form an audio unit. Such bytes generally provide a variable length encode of a number of audio bytes and may be part of standard Advanced Audio Coding (AAC) over RTP. In addition, video packets may be stitched together, as appropriate, to form complete video units. The video (e.g., Network Abstraction Layer (NAL)) units may be processed and extra information such as H.264 Supplemental Enhancement Information (SEI), Sequence Parameter Set (SPS) and Picture Parameter Set (PPS) NALs may be removed. The audio units and the video units parsed from the signal NNMPC by the module  may be placed into queues upon arrival. Two queues may be created, the audio queue  for storing the audio data and the video queue  for storing the video data.","The module  generally implements an indexed format file generator circuit. The module  may be operational to convert the video data and audio data from the signal A into an indexed format. The data may be presented from the module  to the module  in the signal CMP. Many possible indexed formats may be available (e.g., MP4, MOV, 3GP and the like). Classification and further examples of several indexed formats are enumerated below. Additional processing of the data may be applied by the module  to generate information suitable for consumption by the module .","The worst-case audio and video sample sizes may be strictly enforced by the server  (for example, by dropping, transcoding or recoding the violating samples) and may be statically configured or negotiated per session between the module  and the server . Furthermore, the media tracks may be interleaved in the signal CMP, in which case patterns of alternating audio\/video frames are generally deduced from the source audio\/video frame rates. External events, such as packet drops and frame rate changes may be supported.","The MPEG-4 specification, ISO\/IEC 14496-14:2003, generally defines the MP4 format. The MP4 format may comprise discrete units of data called \u201cboxes\u201d or \u201catoms\u201d. A box and\/or atom may be defined as a simple building block. For example, a \u201cmoov\u201d box may be a parent box with no content except other boxes. A \u201ctrak\u201d box may contain other boxes that describe track information. A \u201cmdia\u201d box may contain other boxes that describe the media. A \u201cminf\u201d box generally contains media information, such as codec type. A \u201cstbl\u201d box may define a sample table that may contain stco and stsz boxes. A \u201cstco\u201d box of a media track generally lists offsets for various chunks of information that comprise the media track. A \u201cstsz\u201d box may contain sample size information.","In order for an RTSP\/RTP streaming format to be converted into a progressive MP4 (e.g., indexed format) that may start playing immediately, video and audio samples (e.g., frames) of fixed size may be used. The fixed size of samples may be referred to as buckets. Each bucket generally contains the original video or the original audio received in the signal NNMPC, along with player compliant padding. With fixed bucket sizes and a fixed number of buckets, a table of contents (e.g., moov box) may be generated without having to know the sizes of samples a priori. As samples arrive, the samples may be placed in an appropriate bucket and padded accordingly.","The module  may generate a complete table of contents (e.g., a moov box) from the parameters extracted from the SDP by the module . The audio\/video sampling frequencies in combination with the video frame rate may be used to generate the appropriate number of audio\/video samples per second in an MP4 file.","By way of example, the following SDP attribute (e.g., \u201ca\u201d) lines may have been parsed from the content:\n\n=rtpmap:96 MP4A-LATM\/32000\/2\n\n=rtpmap:97 H264\/90000\n\n=framerate:24\n\nThe audio\/video clocks per second and video frames per second may be extracted as follows:\n\naudioClocksPerSec=32000\n\nvideoClocksPerSec=90000\n\nframerate=24.0\n\nHeader variables may be calculated using the following formulas:\n\naudio_samples_per_sec=audio_clocks_per_sec\/audio_samples_per_clock\n\nvideo_samples_per_sec=framerate\n\nratio=audio_samples_per_sec\/video_samples_per_sec\n\nvideo_buckets=server determined value\n\naudio buckets=video_buckets\u00d7ratio\n\nApplication of the example parameters produces:\n\naudio_samples_per_sec=31.25\n\nvideo_samples_per_sec=24.0\n\naudio buckets=13020\n\nvideo buckets=10000\n\nAs illustrated in the above example, thousands (e.g., 23020) of buckets (e.g., 13020 buckets for audio and 10000 buckets for video) may be allocated for an MP4 file. Each of the buckets is generally indexed from 0 to N (e.g., 0 to 23019). The buckets may be dispersed evenly throughout the MP4 file. The module  may keep track of whether each given bucket should be filled with audio data or video data.\n","Since the buckets may be of fixed size, only the bucket offsets in the MP4 file are generally specified in a stco atom (e.g., moov->trak->mdia->minf->stbl->stco) of each respective track (e.g., audio track and video track) in the table of contents (e.g., moov atom). Sample size data (e.g., stsz atom) may be fixed per track for all samples available.","The module  may also provide a padding function so that the audio units and the video units extracted from the RTP stream may be expanded to fill respective padded MP4 buckets of fixed size. Different padding techniques may be used, depending on the hardware capabilities of the apparatus . For powerful apparatuses , the padding may be fully compliant with the module . For slower apparatuses , a lower complexity padding that may be decoded by the module  is generally employed.","The module  may implement a local server. In some embodiments, the module  may implement an indexed file server. The module  is generally operational to serve the incrementally generated format file created by the module  to the module  using a protocol accepted by the module . The formatted data may be received from the module  through the signal CMP. Subsequently, the data may be presented from the module  to the module  in the signal B. As such, the signal B may be referred to as a local signal. Depending on the platform Software Development Kit (SDK) and the Application Programming Interface (API) of the module , one or more of the following server types may be employed: (i) a web server, (ii) a read server and\/or (iii) a short duration server.","Referring to , a block diagram of an example data organization involved in a web server implementation is shown. In the web server implementation, packets  received in the signal NNMPC may be converted into an indexed format file . The indexed format file  may be delivered to the module  via responses to standard HTTP GET requests. The module  may submit multiple requests in parallel for data within the signal B for different parts of the indexed format file. The requests may be made with the Byte Range functionality of HTTP. The requested portions -of the indexed format file may be delivered from the module  via the signal B to the module . A caching functionality of the module  should be disabled while receiving the file from the module .","Referring to , a block diagram of an example data organization involved in a read server implementation is shown. In a read server implementation, the module  may request the indexed format file a single block at a time. The block requests may be incremental and continuous. Each of the requested blocks -may be delivered sequentially in the signal B (e.g., not pipelined) and may not overlap. The read server implementation is generally possible where the API of the module  may be provided a read( ) call back method to get portions of the source file.","Referring to , a block diagram of an example data organization involved in a short duration server implementation is shown. The web server implementation and the read server implementation may be applied where the module  is capable of playing the media file starting once enough data is available to do so (e.g., progressive download). However where the module  is capable of playing a media file only after the file is fully downloaded, the incoming clip may be broken into multiple independent clips (e.g., MP4 files) -that may be played seamlessly back to back. Each of the clips -may have a similar structure to the indexed format file  of . Thus, the module  may be referred to as the \u201cshort duration server\u201d, where short clips are played sequentially by one or more instantiations of the module . In some embodiments, the module  may provide sequential requests to the module , similar to the read server implementation. The module  may respond by sending the requested blocks -(or -) from a current clip (or ). In other embodiments, the module  may request entire clips -be sent as single units. The module  may respond by sending the requested clips -in the appropriate sequence. Note that most to all of the audio\/video samples may remain unpadded in the short duration server implementation.","Referring to , a flow diagram of an example method  of enabling streaming media delivery to a progressive download native media player is shown. The method (or process) generally comprises a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block) , a step (or block)  and a step (or block) . The method  may be implemented in the apparatus , the network  and the server .","In the step , the circuit  may receive one or more inputs from a user to obtain and play a particular content. The circuit  may generate one or more commands in the signal CMD based on the received inputs in the step . The signal CMD may inform the module  of the identity of the particular content being requested and a location of the content.","The module  may use the identity and the location of the requested content to generate a Universal Resource Identifier (URI). The URI may be passed from the module  to the module  or the module  in the step . The module  or  may pass the URI to the module  as part of step . The module  may respond to the request by contacting the server  via the network  in the step .","Upon receipt of the request for the particular content, the server  may locate and transfer the content in the signal NNMPC. The module  may receive the content in the step . As the content is delivered to the apparatus , the module  may parse the data into the queues  and  in the step . In the step , the module  may extract the various parameters from the content stream. The parameters are generally made available to the module .","Header data corresponding to one or more media files (e.g., MP4 files) may be created from the parameters in the step  by the module . The number of headers created generally depends on the configuration of the modules  and  (e.g., web server, read server or short duration server configurations). In the step , the module  may pad the video buckets and the audio buckets of the media files as appropriate.","To play the media file, the module  may issue one or more requests to the module  in the step . The number and sequencing of the requests generally depends on the configuration of the modules  and  (e.g., web server, read server or short duration server configurations). The module  may respond to the requests from the module  by reading the video data and the audio data of the media file via the signal CMP, serving the data as one or more clips in an indexed format (e.g., progressive download) and then sequentially load the data into the signal B in the step .","Upon receipt of each clip from the module , the module  may convert the video content into a display format in the signal VIDEO in the step . The circuit  may convert the signal VIDEO into a sequence of pictures (e.g., frames or fields) in the signal PICTURES in the step . As the module  is processing the video content, the audio content may be converted in the step  into an audio format in the signal AUDIO. Where the circuit  implements a speaker, the signal AUDIO may be converted into the acoustic signal SOUND in the step . Where the circuit  implements a microphone jack, the signal AUDIO may be amplified and passed to a headphone in the electrical signal SOUND. Presentation of the signal PICTURES and\/or the signal SOUND may occur while the video data and the audio data are still being received by the module .","An overriding criteria guiding behavior across all platforms may be to maximize user quality of experience subject to two constraints. A first constraint may be to minimize system resource requirements (e.g., CPU, network stack, memory, battery, etc.). A second constraint may be to adhere to the API of a particular platform and the module .","The module  may have several responsibilities. For example, the module  may be responsible for invoking and\/or serving multiple instances of the module . Invoking multiple instances may be performed where supported by the platform and the API. Moreover, multiple instances may be used where (i) similar resource usage with a single instance is impractical and (ii) seamless sequential playback between multiple instances is possible. In the context of multiple instances of module , seamless sequential playback generally means that multiple independent clips may be delivered one after another to alternating instances without creating audio\/video artifacts at the clip boundaries. An advantage of using multiple instances may be smaller clips due to the absence of padding. Each clip may be authored for a window of time for which all appropriate data has been received by the module  and therefore the indexing is fully determined.","The format of the clips is generally based on the platform and API of the module . In general, self-contained clips may be generated and delivered in a sequential seamless manner, as described above. The sample data from the source may be buffered by the module  for a fixed interval (e.g., one or more seconds). Therefore, the associated metadata may be fully determined and may be authored without use of padding for the interval. Once the resulting self-contained clip is delivered to the module , the module  may begin to author the self-contained clip for one or more following intervals. Generation of the clips may be performed in a pipelined fashion.","The module  may also be responsible for communicating with the module  via a published API and ultimately delivering content from the module  to the module . Communications between the module  and the module  may have several forms. In some embodiments, the module  may use a URI. In such a case, the module  generally includes a simple web server that \u201chosts\u201d the player-compliant clips, buffers locally and responds to one or more HTTP requests from the module . In other embodiments, the module  may issue one or more startup commands followed by one or more play commands, with associated clips\/buffers for each command. Each additional play command is generally associated with an additional clip or buffer, which is a continuation of the previous clip or buffer.","The module  may have several (e.g., four) modes of behavior. The modes of behavior generally represent how responsibilities are realized by the module . The modes may arise from the criteria to maximize Quality of Experience (QoE) subject to the two constraints, minimizing system resource consumption and adherence to the API of the module . Not all modes may be realizable on all platforms (e.g., apparatus ). For a given platform, a preferred mode that is realizable may be selected as the only or a dominant mode of operation. However, other realizable modes may also be employed.","A first mode of behavior generally involves seamless sequential playback without padding via a single instance of the module . The platform and API should support multiple inputs, either in parallel (e.g., via concurrent HTTP requests) or serially (e.g., via multiple clips or buffers). The module  may generate multiple, non-padded, self-contained clips from the input received in the signal A, as described above. To force the module  to generate concurrent HTTP requests, clip metadata and sample data should be separated within the media file. When the module  receives the initial metadata from an initial HTTP request, the module  may see that the sample data is further within the media file and issue another HTTP request for data starting prior to the desired samples. Therefore, metadata may be authored progressively and padding may be avoided. As a result, a response to the initial HTTP request is throttled, serving metadata only as generated from the module . Where multiple clips or buffers are provided by the module , the API of the module  may notify the application when ready for a new clip or buffer. The application may then invoke the appropriate API with the new clip or buffer.","A second mode of behavior may be used where (i) achieving a seamless sequential playback, without using padding and using a single instance of the module  is difficult and (ii) the platform and API support multiple instances of the module . In the second mode, the platform and API may support seamless sequential playback (e.g., no audio\/video artifacts may be created at the clip boundaries). Operation of the module  may be similar to that described above for generating sequential, non-overlapping clips. The module  may deliver the generated clips in ping-pong fashion to alternate instances of the module , thereby hiding any per-clip startup processing or latencies.","A third mode of behavior may maintain seamless playback using padding. The third mode may be applied to situations involving a single instance of the module . For example, the platform may have no support for multiple player instances or may not maintain seamless sequential playback between multiple player instances. Moreover, the platform may not support multiple inputs to a single instance of the module .","A fourth mode of behavior may result in non-seamless sequential playback. The module  may support either single or multiple instances in the fourth mode. The module  may generate multiple clips and switch between clips at inter-clip boundaries. Switching between the clips may be visible to the user as the transitions may be non-seamless.","In a first example implementation of the system , the server  may be a remote streaming server that supports RTSP\/RTP. The server  may communicate with mobile devices, such as an iPhone (iPhone\u2122 is a trademark of Apple Inc., Cupertino, Calif.), over a reliable transport protocol such as TCP or Reliable UDP. The module  may be a simple RTP\/RTSP client on the circuit . The module  generally issues and responds to RTSP messages. Once a session is established, the remote server  may stream RTP to the apparatus . The incoming packets may be retrieved as a continuous stream by the module  through APIs (e.g., sockets) of the module . The module  generally delivers the depacketized stream to the module . The module  may convert from the RTP format to the MP4 format.","The module  generally comprises a local server that hosts the MP4 clips and responds to HTTP requests from the module . Although the metadata in the signal CMP may be authored a priori and the response to the HTTP requests are not throttled (e.g., metadata is delivered to module  as fast as the module  will read), the sample data should be delivered in a throttled manner as the samples may only be embedded in the MP4 file sample data positions once received from the RTP stream.","In a second example implementation of the system , the server  may be a remote streaming server that supports RTSP\/RTP and communicates with a device over a reliable transport protocol, such as TCP or Reliable UDP. The module  may be a simple RTP\/RTSP client on the circuit . The module  generally issues and responds to RTSP messages. Once a session is established, the server  may stream RTP to the apparatus . Packets conveyed by the stream may be retrieved as a continuous stream by the module  through network APIs (e.g., sockets). The module  generally delivers the depacketized stream to the module  for further processing. The module  may convert the content from the RTP format to the MP4 format. In the example, the apparatus  and API of the module  generally supports seamless sequential playback to multiple instances. Communication between the module  and the module  may be via a series of commands.","The functions performed by the diagrams of  may be implemented using one or more of a conventional general purpose processor, digital computer, microprocessor, microcontroller, RISC (reduced instruction set computer) processor, CISC (complex instruction set computer) processor, SIMD (single instruction multiple data) processor, signal processor, central processing unit (CPU), arithmetic logic unit (ALU), video digital signal processor (VDSP) and\/or similar computational machines, programmed according to the teachings of the present specification, as will be apparent to those skilled in the relevant art(s). Appropriate software, firmware, coding, routines, instructions, opcodes, microcode, and\/or program modules may readily be prepared by skilled programmers based on the teachings of the present disclosure, as will also be apparent to those skilled in the relevant art(s). The software is generally executed from a medium or several media by one or more of the processors of the machine implementation.","The present invention may also be implemented by the preparation of ASICs (application specific integrated circuits), Platform ASICs, FPGAs (field programmable gate arrays), PLDs (programmable logic devices), CPLDs (complex programmable logic device), sea-of-gates, RFICs (radio frequency integrated circuits), ASSPs (application specific standard products) or by interconnecting an appropriate network of conventional component circuits, as is described herein, modifications of which will be readily apparent to those skilled in the art(s).","The present invention thus may also include a computer product which may be a storage medium or media and\/or a transmission medium or media including instructions which may be used to program a machine to perform one or more processes or methods in accordance with the present invention. Execution of instructions contained in the computer product by the machine, along with operations of surrounding circuitry, may transform input data into one or more files on the storage medium and\/or one or more output signals representative of a physical object or substance, such as an audio and\/or visual depiction. The storage medium may include, but is not limited to, any type of disk including floppy disk, hard drive, magnetic disk, optical disk, CD-ROM, DVD and magneto-optical disks and circuits such as ROMs (read-only memories), RAMs (random access memories), EPROMs (electronically programmable ROMs), EEPROMs (electronically erasable ROMs), UVPROM (ultra-violet erasable ROMs), Flash memory, magnetic cards, optical cards, and\/or any type of media suitable for storing electronic instructions.","The elements of the invention may form part or all of one or more devices, units, components, systems, machines and\/or apparatuses. The devices may include, but are not limited to, servers, workstations, storage array controllers, storage systems, personal computers, laptop computers, notebook computers, netbook computers, tablet computers, palm computers, personal digital assistants, portable electronic devices, battery powered devices, set-top boxes, encoders, decoders, transcoders, compressors, decompressors, pre-processors, post-processors, transmitters, receivers, transceivers, cipher circuits, cellular telephones, digital cameras, positioning and\/or navigation systems, medical equipment, heads-up displays, wireless devices, audio recording, storage and\/or playback devices, video recording, storage and\/or playback devices, game platforms, peripherals and\/or multi-chip modules. Those skilled in the relevant art(s) would understand that the elements of the invention may be implemented in other types of devices to meet the criteria of a particular application.","While the invention has been particularly shown and described with reference to the preferred embodiments thereof, it will be understood by those skilled in the art that various changes in form and details may be made without departing from the spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["These and other objects, features and advantages of the present invention will be apparent from the following detailed description and the appended claims and drawings in which:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
