---
title: Word training interface
abstract: A method for exposing speech engine features to one or more independent applications wherein the features relate to word training and/or wherein the method optionally exposes the speech engine features without invoking a user interface. A word training interface to expose speech engine features to one or more independent applications wherein the interface is optionally an application programming interface.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07587317&OS=07587317&RS=07587317
owner: Microsoft Corporation
number: 07587317
owner_city: Redmond
owner_country: US
publication_date: 20020215
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","Conclusion"],"p":["Exemplary systems and methods described herein relate to speech recognition systems. More particularly, the described systems and methods relate to a word training interface.","Speech recognition systems have been incorporated into many useful applications so that users may utilize the applications without having to manually operate an input device, such as a mouse or a keyboard. Personal computer systems (desktop, laptop, handheld, etc.) and automobile systems are only two examples of systems, or platforms, which may include integrated speech recognition functions.","A single platform may have several applications executing at a given time. For example, in an automobile computer system that utilizes speech recognition software, there may be speech recognition applications for radio operation, navigational tools, climate controls, mail, etc. Personal computers may include word processors, spreadsheets, databases and\/or other programs that utilize speech recognition. Each speech recognition application has a grammar associated with it that is a set of commands that the application is attempting to detect at any one time.","As the number of speech recognition applications and grammars has increased, it has become increasingly problematic to run multiple speech recognition application a single platform. When a speech recognition system receives such a command, it must be able to determine which application the speaker directed the command to and which application should respond to the user. Similarly, a speech recognition system should be able to handle training interactions between multiple applications and at least one speech recognition engine. For example, if a word in one application requires training, a system should allow for training of that word and optionally association of that word with a particular grammar or grammars. If so desired, such a system should also allow for training in a \u201cuser interfaceless\u201d fashion, i.e., without requiring an application to implement an additional user interface and\/or to alter an existing user interface.","A method for exposing speech engine features to one or more independent applications wherein the features optionally relate to word training and\/or wherein the method optionally exposes the speech engine features without invoking a user interface. A word training interface to expose speech engine features to one or more independent applications wherein the interface is optionally an application programming interface.","The methods, interfaces and\/or systems optionally operate to a train word without having to invoke a user interface that is not associated with the application. Thus, such methods, interfaces, and\/or systems allow an application to control user experiences. Such methods, interfaces, and\/or systems are optionally suitable for use in environments having a plurality of independent user applications and one or more speech engines. According to various exemplary methods, interfaces, and\/or systems described herein, a speech server and\/or a speech application programming interface are also implemented. Further, as described below, a word training interface optionally includes a word trainer API.","The exemplary methods and\/or systems concern training in a speech recognition system that is able to manage interactions from multiple applications that require use of at least one speech recognition engine. As described herein methods include procedures, processes, and\/or equivalents thereof. Aspects of various exemplary methods and\/or systems are optionally applicable to a variety of speech recognition systems, e.g., discreet, connected, continuous, etc.","Furthermore, exemplary methods and\/or systems described herein are optionally implemented as (or in) an automobile speech recognition system or systems. Of course, non-automobile environment implementations are also possible and within the scope of various exemplary methods and\/or systems. Reference may be made to one or more of such environments. Those skilled in the art will recognize the multitude of environments in which the exemplary methods and\/or systems, and structural and\/or functional equivalents thereof, may be implemented.","General Terms","Following is a brief description of some of the terms used herein. Some of the terms are terms of art, while others have a more particular meaning when used to describe various exemplary methods and\/or systems. Describing such terms initially helps to provide proper context for the discussion that follows, although the descriptions are not meant to limit the scope of the terms in the event that one or more of the descriptions conflict with how the terms are used in the discussion.","Grammars","As previously stated, each speech recognition application likely has its own specific grammar that a speech recognition system must recognize. There are a variety of different things that applications will want to do with their grammars, such as constructing new grammars, using static grammars, enable\/disable rules or entire grammars, persist grammars, make the grammars continually available, etc. The speech recognition system described herein exposes methods to accomplish these things and more.","Different grammars can have different attributes. A static grammar is one that will not change after being loaded and committed. A dynamic grammar, to the contrary, is a grammar that may change after a commit. Whether a grammar is static or dynamic must be known when the grammar is created or registered with the speech recognition system. Rules may also be static or dynamic. A static rule cannot be changed after it is committed, while a dynamic rule may be changed after it is committed. A static rule can include a dynamic rule as a part of the static rule.","A grammar may, at any time, be an enabled grammar or a disabled grammar. A disabled grammar is still within the speech recognition system, but is not being listened for by the system. An enabled grammar may also be called an active grammar; a disabled grammar may also be referred to as an inactive grammar.","Interaction","The term \u201cinteraction\u201d is typically used herein to refer to a complete exchange between a speech recognition application and a user. An interaction is a context of communication that unitizes one or more elements of a dialogue exchange. For example, an application developer may want to program a speech recognition application to alert a user with a tone, ask the user a question, and await a response from the user. The developer would likely want these three events to occur sequentially, without interruption from another application in order for the sequence to make sense to the user. In other words, the developer would not want the alert tone sounded and the question asked only to be interrupted at that point with a communication from another application. The user may then not know how or when to respond to the question. Therefore, with the present invention, the developer may include the three actions in one interaction that is submitted to a speech recognition system for sequential execution. Only in special circumstances will an interaction be interrupted. Interactions will be discussed in greater detail below.","Conversation","A series of related interactions may be referred to herein as a \u201cconversation.\u201d A conversation is intended to execute with minimal interruptions.","Computer-Executable Instructions\/Modules","The exemplary methods and\/or systems illustrated in the drawings are typically shown as being implemented in a suitable computing environment. Although not required, various methods and\/or systems are described in the general context of computer-executable instructions, such as program modules or blocks, to be executed by a computing device, such as a personal computer or a hand-held computer or electronic device. Generally, program modules or blocks include routines, programs, objects, components, data structures, etc., that perform particular tasks or implement particular abstract data types. Moreover, those skilled in the art will appreciate that various methods and\/or systems may be practiced with other computer system configurations, including multi-processor systems, microprocessor-based or programmable consumer electronics, network PCs, minicomputers, mainframe computers, and the like. Various methods and\/or systems may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote memory storage devices.","Exemplary Speech Recognition System",{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 1","FIG. 1"],"b":["100","102","104","100","106","108","110","112","114","116","100","100"]},"The speech recognition system  includes a speech engine  having a text-to-speech (TTS) converter  and a speech recognizer (SR) . The TTS converter  and the speech recognizer  are components typically found in speech recognition systems. The speech recognizer  is configured to receive speech input from the microphone  and other audio sources, and the TTS converter  is configured to receive electronic data and convert the data into recognizable speech that is output, for example, by the speaker .","The speech recognition system  also includes a speech server  that communicates with the speech engine  by way of a speech application programming interface (SAPI) . The SAPI  is a software layer used by the speech applications - and the speech server  to communicate with the speech engine . The SAPI  controls a number of aspects of the speech recognition system , such as: controlling audio input, loading grammar files, sharing recognitions across multiple applications, returning results and other information back to the applications, preventing applications from calling the speech engine  with invalid parameters, dealing with applications hanging and crashing, etc.","Although various exemplary methods and\/or systems discussed herein may be implemented without the SAPI , use of the SAPI  can prevent speech server  users from having to implement code for each speech engine  that may be used in the speech recognition system . By implementing the SAPI  to separate the speech engine  from the speech server , the speech server  can operate with any number of vendor-specific speech engines.","Also shown in  is a word trainer application programming interface  (at times referred to herein as a \u201cword trainer API\u201d). The word trainer API  is a software layer used directly and\/or indirectly by the speech applications - and\/or the speech server  to communicate with the speech engine . For example, the speech applications - and\/or the speech server  may use the word trainer API  indirectly via the SAPI  to communicate with the speech engine . Various exemplary word training interfaces and\/or word trainer APIs are described in more detail below.","Referring again to , a plurality of applications may be stored in the memory , including application_ , application_  and application_n . Depending on the components that make up the computer system , virtually any practical number of applications may be stored in the memory  for execution on the speech server . As shown in , each application - includes an associated grammar: Application_  includes grammar_ ; application_  includes grammar_ ; and application_n utilizes grammar_n . In the exemplary system , each of the applications - also includes a proxy that is used to communicate with the speech server . Application_  uses proxy_ ; application_  uses proxy_ ; and application_n  uses proxy_n .","As shown in , the speech server  includes an interaction object  and a stub object . The interaction object  is utilized to receive interactions from the applications - for processing. The stub object  is called by the applications -, which in turn calls the interaction object . The stub object  is generally used with the proxies - to provide fault tolerance for the speech recognition system . Although exemplary methods and\/or system may be implemented without utilizing proxies and a stub object, use of proxies and a stub object may provide the system  with enhanced stability, for example, making it less prone to errors.","In the exemplary system  of , the applications - are configured to call several controls which generally exist in a process space of an application. Controls are typically designed to provide application developers a robust, reliable set of user-interface tools with which to build applications. In general, controls are code modules that perform recurring functions desired by application developers. As such, controls decrease the programming effort required by an original equipment manufacturer or an independent vendor to create a rich application user interface.","For example, a question control gives an application developer an easy way to create various modal, system-initiated interactions, or dialogues. An announcement control provides a developer a simple way to deliver verbal feedback to users, including short notices and long passages of text-to-speech. A command control provides a way for applications to specify what grammar it is interested in listening to, and communicates to the applications if and when a recognition occurs. A word trainer control optionally provides an easy way to implement a speech-oriented work-training interaction with a user.","Speech recognitions systems typically include a vocabulary, for example, an entire set of speech commands recognizable by a speech recognition system (e.g., the speech recognition system ). A vocabulary is optionally maintained by a SAPI (e.g., SAPI ) and\/or a speech engine (e.g., speech engine ). Speech recognition systems typically include a master grammar table, which contains information about grammars. In general, a master grammar table does not include actual grammars, but rather it includes information about grammars (e.g., grammars , , ).","The speech server  of the exemplary system  includes a priority manager . As shown in , the priority manager  maintains a list  of one or more interactions (interaction_ , interaction_ , interaction_ , interaction_n ) from one or more applications in a particular order for processing by the speech server . As previously discussed, an interaction is, in one sense, a logical context used by an application to communicate with a user. To avoid conflicts, at any given time, there is generally only one active interaction between the user and an application. Other interactions may exist between internal components of the exemplary system which do not necessarily communicate with a user.","According to the exemplary system , the priority manager  processes the interactions - in a priority-based order. In general, interactions can be inserted at the front of the list , i.e., before interaction_ , or at the end of the list . If an interaction (not shown) is inserted at the front of the list , an interrupt occurs to interrupt the processing of interaction_ . A user interaction (e.g., input) initiated via a user interface, associated with an application (e.g., the applications , , ), generally has further effect through subsequent interaction with the SAPI  (e.g., calls to the SAPI ), the word trainer API  (e.g., calls to the word trainer API ), and\/or the speech engine  (e.g., calls to the speech engine ). In an exemplary process, an interaction (e.g., interaction , , , or ) in queue on the speech server  does not necessarily have to interact with the SAPI  or the word trainer API, for example, it may interact directly with the speech engine . However, for word training, an interaction (e.g., interaction , , , or ) in queue on the speech server  generally interacts with the word trainer API  because, as described below, the word trainer API  (or alternative word training interfaces) provide features, typically functional features, that facilitate and\/or enable word training procedures. As described in more detail below, in various exemplary systems, a word training interface may optionally alleviate the need to use a user interface, for example, a user interface associated with a speech engine or even the word training interface. Instead, for example, an application can create its own user interface for word training, wherein that user interface can issue calls to a word training interface (e.g., typically via a speech server when an environment has a plurality of speech recognition applications).","The priority manager  is also configured to notify the applications   of the following exemplary non-limiting transitions so that the applications - may modify the state or content of an interaction as it is processed in the list : interaction activated, interaction interrupted, interaction self-destructed, interaction re-activated, and interaction completed. As a result, the applications - can be aware of the state of the exemplary speech recognition system  at all times.","As previously noted, an interaction contains one or more elements that represent a \u201cturn\u201d of communication. A turn is a single action taken by either the system or the user during an interaction. For example, the system may announce \u201cFast or scenic route?\u201d during a turn, which is the system's turn. In response, the user may answer \u201cFast,\u201d which is the user's turn.","Exemplary Interactions",{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 2","FIG. 2"],"i":"a ","b":["200","200","200","202","202","102","204","206","200","102"]},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 2","i":"b ","b":["220","222","224","226","220"]},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 2","i":"c ","b":["230","232","234","230","102"]},"There is another type of element (not shown) that may be inserted into an interaction to cause a delay, or time out, before the system processes subsequent elements. This type of element is referred to as a NULL element. A NULL element would be inserted into an interaction to allow additional time for the interaction to be processed.","Referring again to , the priority manager  provides for the ordering of interactions, including the elements (EC, TTS, WT, NULL, SR) discussed above. This prevents, for example, more than one application from addressing the user simultaneously. The priority manager  processes the interactions - in the list  in the order in which the interactions are submitted to the priority manager  (i.e., on a first-in-first-out basis). An exception to this particular process may occur when an application is provided with the ability to submit an interaction directly to the beginning of the list , for example, in situations where the application considers the interaction a high priority or when an interaction is a part of a continuing conversation.","Word Training Interface (e.g., a Word Trainer API)","A training procedure generally involves having a user speak a word or a series of words to provide a speech recognition engine with the acoustic data it needs to recognize a grammar word or phrase that it may not have previously contained within its lexicon. As discussed below, a word training interface (e.g., the word trainer API  of ) optionally operates as an engine extension object.","Note that the exemplary word training interface can function without implementing or invoking a user interface. Thus, an application relying on such a word training interface can access speech engine functionality while retaining control over the user experience. Further, depending on the particular user application, a UI-less word training API has advantages in that an application has control over user experiences. Of course, exemplary word training interfaces described herein are not limited to UI-less word training interfaces.","As already mentioned, an exemplary word training interface does not define user experiences, but rather, allows an application to define user experiences. Consider a notification to a user that lets the user know when to commence speaking. This notification is optionally through use of an EC that executes prior to a call to a word training interface feature or method for commencing recording (e.g., see StartRecording below). In an alternative, an application may cause a flashing button or other object to appear on a user interface to notify a user as to when to commence speaking. This notification may appear prior to a call to a word training interface feature or method for commencing recording (e.g., see StartRecording below). Thus, various exemplary word training interfaces allow for development of a variety of applications having any of a variety of user experiences.","Referring to , a block diagram of an exemplary word trainer API  is shown. The exemplary word trainer API  operates as a word training interface and shares various features with the word trainer API  as described with reference to . As described above, this exemplary word trainer API  is optionally implemented as an SAPI engine extension interface. As shown in , the word trainer API  includes the following exemplary features as methods or blocks: a BeginTraining block , a StartRecording block , a GetAudio block , an Acknowledge block , a Commit block , a Cancel block , a RemoveWord block , a get_numUtt block , and a IsWordTrained block . These methods optionally include one or more parameters. The word trainer API  can optionally parse a call to retrieve such parameters and\/or pass such parameters to a speech engine, a speech server, an application, a SAPI, etc.","The BeginTraining block  can initiate a training process and optionally indicate which string requires training. For example, a call to an exemplary BeginTraining block  can include a string as a parameter. Upon receipt of the call, the word trainer API  can then parse the call to retrieve the string. The word trainer API  may then pass the string as desired. The BeginTraining block  may also initiate loading and\/or activation of an appropriate word training grammar. According to the exemplary word trainer API , a string may be an item in the lexicon (e.g., \u201cmom\u201d) and\/or an item to be treated more as a token (e.g., \u201cRadioPresetl\u201d for an automotive radio having a plurality of preset radio stations). In the instance that the string is an item in the lexicon, then word training generally results in replacement of the lexicon item. In the instance that the item is not in the lexicon, then word training generally results in addition of a new lexicon item. Of course, other alternative treatments are possible depending on the needs of the particular user application and\/or features of the speech recognition engine.","In general, calls to the BeginTraining block  are processed one at a time. A call to the Commit block  and\/or Cancel block  typically terminates a word training procedure initiated by the BeginTraining block . Thus, only after one word training procedure terminates can a call to the BeginTraining block  initiate another word training procedure. The BeginTraining block  may also strictly limit the scope of speech recognition to the precise item being trained.","The StartRecording block  can initiate a recording process upon a trigger, such as, but not limited to, sensed user speech (e.g., detectable audio). In general, the StartRecording block  returns a status message that indicates the quality of the recording process and\/or the recording. For example, a parameter may include a status message that optionally indicates a time out (e.g., no trigger after a set time period), an error, a good quality recording, and\/or a poor quality recording. Of course, the StartRecording block  may form part of a loop to allow an opportunity or opportunities to enhance quality (e.g., optionally dictated by the speech recognition engine); however, after a set time period, a global timeout typically occurs. Alternatively, another process or thread may interrupt execution of the StartRecording block  (e.g., through a call to the Cancel block ).","The GetAudio block  retrieves and\/or saves audio data; a word training procedure typically calls the GetAudio block  after execution of the StartRecording block , for example, after the StartRecording block  obtains a recording. The GetAudio block  optionally includes a parameter to indicate whether to save or discard (e.g., overwrite) a recording, which is optionally set upon execution of another block (e.g., a block executed prior to a call to the StartRecording block ).","A word training procedure calls the Acknowledge block  to acknowledge and\/or accept a recording. The Acknowledge block  optionally includes a parameter to indicate whether the speech recognition engine should save or discard (e.g., overwrite) a recording and a parameter to indicate whether training of the particular word was adequate, for example, wherein further recordings are unwarranted for a particular word training procedure. In general, a word training procedure holds audio data on a temporary basis only, for example, during the period between a call to the StartRecording block  and a call to the Acknowledge block . If storage of such data is desirable, the GetAudio block  and\/or other blocks may save audio data and\/or other information related to a word training procedure. Determinations of whether to save audio data are optionally made during execution of a word training procedure in, for example, the StartRecording block  and\/or other blocks.","The Commit block  commits the result of a word training procedure. In general, a call to the Commit block  completes a word training procedure. In addition, execution of the Commit block  can release all resources from training and\/or discard information pertaining to prior related trainings.","A call to the Cancel block  can interrupt execution of any block (potentially including blocks not listed in ). Upon execution, the Cancel block  typically returns a speech recognition engine to a state equivalent to its state prior to initiation of the current word training procedure (e.g., prior to a call to the BeginTraining block ).","The RemoveWord block  removes a training result (or other result) for a specified string (e.g., wherein the string corresponds to a word lexicon item and\/or a word token item). Upon execution the get_NumUtt block  provides the number of utterances needed to train any particular word. If a speech recognition engine does not track such information a call to the get_NumUtt block  returns a null or other suitable value. Execution of the IsWordTrained block  typically returns a Boolean value that indicates whether a particular string is trained.","Exemplary Word Training Procedure","Referring to , a block diagram of an exemplary word training procedure  is shown. This exemplary word training procedure  is implemented as a word training interface, for example, as a word trainer API such as, but not limited to, the word trainer API  of  and\/or the word trainer API  of . In general, the various functional blocks of  share features with the blocks - described with reference to .","As shown in , the exemplary word training procedure  commences with a call to a BeginTraining block  for initiating training wherein the call contains a string wherein the string corresponds to an item in the lexicon. Following the BeginTraining block , a call to a StartRecording block  occurs. According to the exemplary procedure , a user speaks during execution of the StartRecording block  to allow for acquisition of audio data. Once the user has finished speaking, the StartRecording block  returns. Next, a decision block  determines whether to preserve the audio data that was acquired during execution of the StartRecording block . This decision block  is optionally included within another block, such as, but not limited to, the StartRecording block . If the decision block  determines that the audio data should be preserved, a call to a GetAudio block  follows wherein execution of the GetAudio block  saves the audio data. If the decision block  determines that the audio data should not be preserved, then a call to an Acknowledge block  follows. A call to the Acknowledge block  also follows the GetAudio block .","Execution of the Acknowledge block  acknowledges the recording (e.g., acquisition of audio data). Another decision block  follows acknowledgement of the recording wherein a determination occurs as to whether additional utterances (or recordings) are warranted. For example, a particular speech recognition engine may require a plurality of recordings to get a representative sampling of how a user says a word or a phrase, or to verify a training result. Of course, the number of utterances is optionally provided in an earlier block, for example, the BeginTraining block  wherein the number of recordings is known a priori. According to the exemplary procedure , one of the blocks optionally calls a get_NumUtt block (e.g., the get_NumUtt block  of ) to get the number of recordings required by the speech recognition engine; the procedure  can then use this number to loop between the StartRecording block  and the decision block  until acquisition of a final recording. The decision block  is optionally part of or called during execution of the Acknowledge block . As such, a system relying on a plurality of utterances may start with a call to a BeginTraining block  and then loop through the StartRecording block  and the Acknowledge block . As shown in , following the decision block  (e.g., a final recording or utterance), a call to a Commit block  occurs. The Commit block  commits the speech recognition training performed during the exemplary word training procedure . In general, execution of the Commit block  completes the exemplary word training procedure .","A word training interface may also cause a speech recognition engine to disable grammars during a training procedure. For example, upon a call to a BeginTraining block, no recognitions occur until a call to a Commit block or a Cancel block occurs. Further, according to an exemplary word training interface executing an exemplary word training procedure, blocks such as an IsWordTrained block and a RemoveWord block are callable at any point, except between a call to a BeginTraining block and a Commit block or a Cancel block.","According to various exemplary training procedures, a call to a Commit block replaces any prior occurrence or training of a word with the result of the training procedure. In this manner, execution of such a training procedure acts to replace rather than to enhance a lexical item. For example, if the word \u201cmother\u201d is trained to \u201cmama\u201d, in all cases where \u201cmother\u201d was accepted, the only alternative should be \u201cmama\u201d, which is applied across grammars.","Exemplary Application-Interface-Engine Arrangements","While the various exemplary word training procedures and word training interfaces described above include particular features, other exemplary procedures and\/or interfaces may include other and\/or additional features. In general, a word training interface includes a plurality of features to allow an application developer to adequately include word training procedure options within an application that depends, at least in part, on speech recognition. Such word training interface features are typically callable methods and\/or other functional elements that relate to speech recognition and, in particular, word training. In essence, a word training interface can expose speech engine features (e.g., speech engine functionalities) either directly or indirectly to a plurality of applications. To do so, a word training interface generally includes a plurality of features to allow for exploitation of speech engine capabilities. In addition, a word training interface may optionally include features for use with one or more speech engines. In general, a judicious selection of features can ensure that a word training interface will provide adequate flexibility in a computing environment that relies on speech recognition.","Referring to , an exemplary word training interface  is shown within an exemplary computing environment . As shown in , the computing environment  includes applications APP_A , APP_B  and APP_C , a word training interface  and speech engines ENG_A  and ENG_B . According to this exemplary environment , instructions issues by the applications APP_A , APP_B  and APP_C , the word training interface  and\/or the speech engines ENG_A  and ENG_B  are optionally receivable directly and\/or indirectly by these and\/or other elements of the computing environment . Note that while not shown, the computing environment  optionally includes software, hardware and\/or other items shown in the computer system  of . For example, the applications , , , optionally operate in conjunction with a speech server (e.g., the speech server ) and\/or a speech API (e.g., the speech API ). As such, instructions issued from the applications APP_A , APP_B  and APP_C , the word training interface  and\/or the speech engines ENG_A  and ENG_B  are optionally receivable by a speech server and\/or a speech API.","As shown in , each of the applications , ,  includes features which are optionally related to word training. For example, the application  includes application features  (AFA_ ) through N (AFA_N ), where \u201cN\u201d represents any integer number, which may be unique for the application APP_A . Likewise, the application  includes application features  (AFB_ ) through N (AFB_N ) where \u201cN\u201d represents any integer number, which may be unique for application APP_B , and the application  includes application features  (AFC_ ) through N (AFC_N ) where \u201cN\u201d represents any integer number, which may be unique for application APP_C . In general, the features are related to word training for applications that offer speech recognition and\/or text-to-speech options.","The word training interface , which is optionally a word trainer API, includes features  (IF_ ) through N (IF_N ), where \u201cN\u201d represents any integer number, which may be unique for the word training interface . The features IF_ , IF_ , IF_N  optionally include features represented in the functional blocks of . In general, the features are useful for implementing word training in applications that offer speech recognition and\/or text-to-speech options.","The computing environment  also includes two speech engines: ENG_A  and ENG_B . Each of these engines , , includes a variety of features which are optionally useful for word training. For example, the engine ENG_A  includes features  (EFA_ ) through N (EFA_N ), where \u201cN\u201d represents any integer number, which may be unique for the engine ENG_A , and the ENG_B  includes features  (EFB_ ) through N (EFB_N ), where \u201cN\u201d represents any integer number, which may be unique for the engine ENG_B . In general, the features are useful for implementing word training in applications that offer speech recognition and\/or text-to-speech options.","According to the exemplary computing environment , the word training interface  allows for implementation of features of the applications , ,  through use of features of at least one of the speech engines ,  (e.g., functionality related to word training procedures). Hence, the word training interface  allows an application to execute features related to a word training procedure or procedures. Of course, the exemplary computing environment  may optionally rely on more than one word training interface to effectively achieve similar functionality.","Additional Exemplary Word Training Procedure","Referring to , a block diagram of an exemplary word training procedure  is shown. This exemplary procedure  is suitable for use with the exemplary word training interface  and\/or computing environment  shown in . In an identification block , an application (e.g., the applications , ,  of ) identifies a word that needs training. Next, in a communication block , the application communicates the word, typically as a parameter (e.g., string parameter), directly and\/or indirectly to a word training interface (e.g., the word training interface  of ). An alert block  follows wherein the word training interface implements an alert feature to alert a speech engine that training and\/or recording is requested. For example, consider the BeginTraining block  of the word trainer API  shown in .","Referring again to , in a record block , the speech engine implements a record feature to acquire audio data associated with the identified word. For example, a record feature that corresponds to the StartRecording block  of the word trainer API  shown in . According to the exemplary procedure , a train block  follows the record block , wherein the speech engine implements a training feature to train the identified word on the basis of the acquired audio data to thereby produce a training, which is typically a new training for the identified word. Finally, in a replacement block , a replacement feature replaces any prior training associated with the identified word with the new training. Of course, the exemplary procedure may also include quality check blocks, a speech server block, a prioritization block, a speech application programming interface block, and\/or other functional blocks. Such blocks optionally aid in exposing speech engine features to a plurality of independent applications (e.g., see applications , ,  of , which are optionally independent applications).","In another exemplary procedure, a speech engine optionally uses a default phonetic parsing rather than, for example, an existing training. In such an exemplary procedure, the \u201cnew training\u201d replaces the default information or adds more specific information about how to recognize the trained word. Overall, default information and\/or a prior training may be considered old information; a new training typically replaces and\/or supercedes the old information.","Exemplary Computer Environment","The various exemplary methods and\/or systems described herein, including associated components and\/or functionality, are implemented with any of a number of individual computers.  shows components of typical example of such a computer, referred by to reference numeral . The components shown in  are only examples, and are not intended to suggest any limitation as to the scope of the functionality of the invention; the invention is not necessarily dependent on the features shown in .","Generally, various different general purpose or special purpose computing system configurations can be used. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like.","The functionality of the computers is embodied in many cases by computer-executable instructions, such as program modules, that are executed by the computers. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Tasks might also be performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media.","The instructions and\/or program modules are stored at different times in the various computer-readable media that are either part of the computer or that can be read by the computer. Programs are typically distributed, for example, on floppy disks, CD-ROMs, DVD, or some form of communication media such as a modulated signal. From there, they are installed or loaded into the secondary memory of a computer. At execution, they are loaded at least partially into the computer's primary electronic memory. The invention described herein includes these and other various types of computer-readable media when such media contain instructions programs, and\/or modules for implementing the steps described below in conjunction with a microprocessor or other data processors. The invention also includes the computer itself when programmed according to the methods and techniques described below.","For purposes of illustration, programs and other executable program components such as the operating system are illustrated herein as discrete blocks, although it is recognized that such programs and components reside at various times in different storage components of the computer, and are executed by the data processor(s) of the computer.","With reference to , the components of computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISAA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as the Mezzanine bus.","Computer environment  typically includes a variety of computer-readable media. Computer-readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media. \u201cComputer storage media\u201d includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules, or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer . Communication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more if its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules , and program data .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface.","The drives and their associated computer storage media discussed above and illustrated in  provide storage of computer-readable instructions, data structures, program modules, and other data for computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer  through input devices such as a keyboard  and pointing device , commonly referred to as a mouse, trackball, or touch pad. Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus , but may be connected by other interface and bus structures, such as a parallel port, game port, or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . In addition to the monitor, computers may also include other peripheral output devices such as speakers and printer , which may be connected through an output peripheral interface .","The computer may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to computer . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) such as the Internet , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet .","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over a WAN, such as the Internet . The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on remote computing device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Although details of specific exemplary methods, interfaces, and\/or systems are described above, such details are intended to satisfy statutory disclosure obligations rather than to limit the scope of the following claims. Thus, the methods, interfaces, and\/or systems, etc. as defined by the claims are not limited to the specific features described above."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["A more complete understanding of exemplary methods and arrangements described herein may be had by reference to the following detailed description when taken in conjunction with the accompanying drawings wherein:",{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":["FIG. 2","FIG. 1"],"i":"a "},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIG. 2","FIG. 1"],"i":"b "},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 2","FIG. 1"],"i":"c "},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
