---
title: Application program interface for programmable graphics pipeline
abstract: Systems and methods that optimize GPU processing by front loading activities from a set time/binding time to creation time via enhancements to an API that configures the GPU. Such enhancements to the API include: implementing layering arrangements, employing state objects and view components for data objects; incorporating a pipeline stage linkage/signature, employing a detection mechanism to mitigate error conditions. Such an arrangement enables front loading of the work and reduction of associated API calls.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07659901&OS=07659901&RS=07659901
owner: Microsoft Corporation
number: 07659901
owner_city: Redmond
owner_country: US
publication_date: 20061130
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application claims the benefit of U.S. Provisional Application No. 60\/820,218 filed on Jul. 24, 2006 entitled \u201cAPPLICATION PROGRAM INTERFACE\u201d, the entirety of this application is hereby incorporated by reference.","Advancement of technology in the world of communications and computing has significantly advanced entertainment systems and enhanced user experiences. In general, entertainment systems strive to realistically recast an environment in which an event or game action occurs. Such trend can also involve recreating the environment based on a user's expectations or desires. Moreover, recent advancements in processing power and transmission capability have made it possible to recreate a realistic setting in relatively small computer enabled systems.","Typically, the entertainment industry offers a variety of passive and interactive forms of settings for amusements, which often are tailored depending on target audience. For example, different video games and television events or programs are specifically marketed to specific life styles, target age groups, and the like. Similarly, head mounted computer displays enable users to experience a graphical environment, wherein a user can enjoy an illusion of presence in the displayed environment. In general, such software for generating virtual reality environments have typically been employed for training and entertaining of personnel, wherein relatively inexpensive computing devices enable 3D virtual reality user interfaces. These 3D virtual reality worlds allow a user to explore a simulated environment. Such environments can further include views from an ordinary street scene with walkways, roads, and buildings to a completely fictitious landscape of an outer space planet. In general, the end goal with virtual reality interfaces still remains to provide the user the most realistic experience possible.","Rendering and displaying 3-D graphics typically involves a plurality of calculations and computations. For example, to render a 3-D object, a set of coordinate points or vertices that define an object to be rendered is initially formed, wherein vertices are subsequently joined to form polygons and define surfaces. Once such defining vertices are formed, a transformation from an object or model frame of reference to a world frame of reference and subsequently to 2-D coordinate is completed. Throughout such procedure, vertices can be rotated, scaled, eliminated or clipped (if they fall outside of a viewable area) lit by various lighting schemes and sources, colorized, and the like. Such processes for rendering and displaying a 3-D object can be computationally intensive and can involve a large number of operations for each vertex.","For example, complexities can arise within the shading process that describes appearance of a material at any point of a 1-D, 2-D or 3-D space, via a function (e.g., procedural shader) in a shading parameter space. In general, the object is \u201cimmersed\u201d in the original 1-D, 2-D or 3-D space and the values of shading parameters at a given point of surface are defined as a result of procedural shading function at such point. For instance, procedural shaders that approximate appearance of wood, marble or other natural materials have been developed. Moreover, by passing source code designed to work with a shader into an application, a shader becomes an object that the application can create\/utilize in order to facilitate the efficient drawing of complex video graphics\u2014for example, as vertex shaders, geometry shaders, and\/or pixel shaders.","Such Vertex, geometry and\/or pixel shaders can commonly be implemented wholly as software code, and\/or as a combination of more rigid pieces of hardware with software for controlling the hardware. (GPU), which can run on the host CPU. These implementations frequently are contained in a CPU or emulated via employing a system's CPU. For example, hardware implementations can directly integrate a CPU chip, to perform the processing functionality required of shading tasks. Moreover, pixel and vertex shaders can be implemented as specialized and programmable hardware components. Such vertex and pixel shader chips are highly specialized and typically do not behave as prior CPU hardware implementations. Also, GPUs are increasing speed at a faster rate when compared to advancements in CPUs. Accordingly, GPU performance is desired to be decoupled from CPU performance.","The following presents a simplified summary in order to provide a basic understanding of some aspects described herein. This summary is not an extensive overview of the claimed subject matter. It is intended to neither identify key or critical elements of the claimed subject matter nor delineate the scope thereof. Its sole purpose is to present some concepts in a simplified form as a prelude to the more detailed description that is presented later.","The subject innovation provides for systems and methods that optimize GPU processing by front loading activities from a set time (or binding time) to creation time, via enhancements to an API that configures the GPU. Such enhancements to the API include: implementing layering arrangements, employing state objects and view components for data objects; and incorporating a pipeline stage linkage\/signature. Accordingly, an application can designate system resources at creation time (as opposed to at bind time), wherein activities (such as state\/parameter validation, creating texture headers, creation points mapping to hardware state registers and the like) are moved to a less frequent path in processing, wherein actual set can be performed rapidly.","The view component supplies a description of how data is laid in memory and how such data can be interpreted by the graphics hardware, (e.g. what format data takes such as integer, floating point; where it is intended to be bound to the pipeline, and the like). In a related aspect, a state object component can create objects upfront (as opposed to manipulating state of the GPU and\/or API via a piece meal approach that risks obtaining invalid configurations). Moreover, performance costs associated with operation of computational units within a pipeline are reduced via a linking component that supplies a predefined order (e.g., bind by position\u2014as opposed to a bind by name such as a sort, wherein set of functions describe each parameter at set time on the driver via the CPU and declared at the API.) The linking component can encode a string (e.g., signatures) for each parameter, which can further be validated via a de-bug layer as part of a layering arrangement. In addition, an efficient detection mechanism can be supplied to mitigate error conditions (e.g., reducing number of potentially invalid states that occurs within the pipeline) by assigning a monotonically increasing value for a resource, which is incremented every time such resource is bound as an output.","According to a further aspect of the subject innovation a layered run-time can be provided wherein API calls can move through various layers, which provide additional functionality (e.g., linkage validation, traversing strings to ensure that adjacent shaders are passing values expected by the application, and the like.) As such, a de-bug layer can be supplied that in general does not affect the actual behavior of the API, to obtain layer specific interfaces.","The following description and the annexed drawings set forth in detail certain illustrative aspects of the claimed subject matter. These aspects are indicative, however, of but a few of the various ways in which the principles of such matter may be employed and the claimed subject matter is intended to include all such aspects and their equivalents. Other advantages and novel features will become apparent from the following detailed description when considered in conjunction with the drawings.","The various aspects of the subject innovation are now described with reference to the annexed drawings, wherein like numerals refer to like or corresponding elements throughout. It should be understood, however, that the drawings and detailed description relating thereto are not intended to limit the claimed subject matter to the particular form disclosed. Rather, the intention is to cover all modifications, equivalents and alternatives falling within the spirit and scope of the claimed subject matter.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 1","b":["100","120","130","135","110","120","110","120","120","135","130"]},"In general, the GPU processing  can include a plurality of computational units , ,  that are positioned within the pipeline to enable operation at various granularity levels (e.g. pixel granularity, vertex granularity, and the like), wherein such computational units can consume data; produce data pass data therebetween. For example and as described in detail infra, data can be passed between shader stages (e.g., from an input assembler to the first shader stage)\u2014such that adjacent stages effectively share a register array. The upstream stage can write data to specific locations in the register array and the downstream stage in generally must read from the same locations. Put differently, the API component  can reduce performance costs associated with operation of computational units , ,  within the pipeline for GPU processing , via front loading activities from the set time (or binding time)  to the creation time .",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 2","b":["206","208","208","208"]},"Likewise, such view component  can function as lightweight wrappers for data objects, to facilitate a rapidly perform set operation. Accordingly, the view component  can function as a mechanism for structural sub-setting of data objects\u2014e.g., given a 2D mipmapped texture data object, a view of a single mipmap level (which is set of arrays representing the same image at progressively lower resolutions) can be created for setting as a shader input resource\u2014while another view of a different mipmap level can be employed as a render target in a same draw call. In addition, such view component  can express other resource types as a Texture2Darray-equivalent, in order to enable render target and depth\/stencil access to such resources. For example, rendering to a cube map can occur as if it were a 2D texture array of length 6 or less. Moreover, the view component  can provide type information for data objects with typeless elements. Such can further enable a single data object to be interpreted with more than one type of the same element size (such as 4 Float 32s or 4 Int32s). In addition, a need for parameter validation can be mitigated during performance of associated functions. It is to be appreciated that any number of views can simultaneously exist for a single data object.","The view component  facilitates configuration of the GPU processing , which includes a plurality of computational units; such as the geometry shader component  that operates on a primitive representing a plurality of vertices data inputs. For example, such primitive can be a simple geometric element (e.g., a point, line, triangle, adjacencies and the like) that forms the building block of more complex geometric structures. The generated primitives can subsequently be sent to a rasterizer  for display of associated graphics. Moreover, states for a rasterizer  (e.g., rendering states) can be grouped into an object that can be authorized at time of creation (as opposed to at run time), as described in detail infra. Accordingly, a plurality of parameters can be formed as a structure\/object that is called at runtime (as opposed to setting individual states for each parameter). Such can mitigate problems associated with overhead and supply an optimized solution. For example, the subject innovation can efficiently configure a pipeline of the GPU processing , to provide bind by position wherein linkage and inputs\/outputs are defined via locations and\/or positions of registers\/register banks; (as opposed to bind by name, wherein shaders inputs and outputs are defined by names and a comparison of names is typically required across shader units, to determine how data is to be passed in the hardware.)","An exemplary syntax for a view creation associated with the view component  can include;",{"@attributes":{"id":"p-0031","num":"0030"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"typedef enum D3D10_SRV_DIMENSION"]},{"entry":[{},"{"]},{"entry":[{},"\u2003D3D10_SRV_DIMENSION_UNKNOWN = 0,"]},{"entry":[{},"\u2003D3D10_SRV_DIMENSION_BUFFER = 1,"]},{"entry":[{},"\u2003D3D10_SRV_DIMENSION_TEXTURE1D = 2,"]},{"entry":[{},"\u2003D3D10_SRV_DIMENSION_TEXTURE1DARRAY = 3,"]},{"entry":[{},"\u2003D3D10_SRV_DIMENSION_TEXTURE2D = 4,"]},{"entry":[{},"\u2003D3D10_SRV_DIMENSION_TEXTURE2DARRAY = 5,"]},{"entry":[{},"\u2003D3D10_SRV_DIMENSION_TEXTURE2DMS = 6,"]},{"entry":[{},"\u2003D3D10_SRV_DIMENSION_TEXTURE2DMSARRAY = 7,"]},{"entry":[{},"\u2003D3D10_SRV_DIMENSION_TEXTURE3D = 8,"]},{"entry":[{},"\u2003D3D10_SRV_DIMENSION_TEXTURECUBE = 9,"]},{"entry":[{},"} D3D10_SRV_DIMENSION;"]},{"entry":[{},"typedef struct D3D10_BUFFER_SRV"]},{"entry":[{},"{"]},{"entry":[{},"\u2003SIZE_T ElementOffset;"]},{"entry":[{},"\u2003SIZE_T ElementWidth;"]},{"entry":[{},"} D3D10_BUFFER_SRV;"]},{"entry":[{},"typedef struct D3D10_TEX1D_SRV"]},{"entry":[{},"{"]},{"entry":[{},"\u2003UINT MostDetailedMip;"]},{"entry":[{},"\u2003UINT MipLevels;"]},{"entry":[{},"\u2003UINT FirstArraySlice;"]},{"entry":[{},"\u2003UINT ArraySize;"]},{"entry":[{},"} D3D10_TEX1D_SRV;"]},{"entry":[{},"typedef struct D3D10_TEX2D_SRV"]},{"entry":[{},"{"]},{"entry":[{},"\u2003UINT MostDetailedMip;"]},{"entry":[{},"\u2003UINT MipLevels;"]},{"entry":[{},"\u2003UINT FirstArraySlice;"]},{"entry":[{},"\u2003UINT ArraySize;"]},{"entry":[{},"} D3D10_TEX2D_SRV;"]},{"entry":[{},"typedef struct D3D10_TEX3D_SRV"]},{"entry":[{},"{"]},{"entry":[{},"\u2003UINT MostDetailedMip;"]},{"entry":[{},"\u2003UINT MipLevels;"]},{"entry":[{},"} D3D10_TEX3D_SRV;"]},{"entry":[{},"typedef struct D3D10_TEXCUBE_SRV"]},{"entry":[{},"{"]},{"entry":[{},"\u2003UINT MostDetailedMip;"]},{"entry":[{},"\u2003UINT MipLevels;"]},{"entry":[{},"} D3D10_TEXCUBE_SRV;"]},{"entry":[{},"typedef struct D3D10_SHADER_RESOURCE_VIEW_DESC"]},{"entry":[{},"{"]},{"entry":[{},"\u2003DXGI_FORMAT Format;"]},{"entry":[{},"\u2003D3D10_RESOURCE ResourceType;"]},{"entry":[{},"\u2003union"]},{"entry":[{},"\u2003{"]},{"entry":[{},"\u2003\u2003D3D10_BUFFER_SRV Buffer;"]},{"entry":[{},"\u2003\u2003D3D10_TEX1D_SRV Texture1D;"]},{"entry":[{},"\u2003\u2003D3D10_TEX2D_SRV Texture2D;"]},{"entry":[{},"\u2003\u2003D3D10_TEX3D_SRV Texture3D;"]},{"entry":[{},"\u2003\u2003D3D10_TEXCUBE_SRV TextureCube;"]},{"entry":[{},"};"]},{"entry":[{},"} D3D10_SHADER_RESOURCE_VIEW_DESC;"]},{"entry":[{},"HRESULT ID3D10Device::CreateShaderResourceView("]},{"entry":[{},"\u2003[ in ] ID3D10Resource* pResource,"]},{"entry":[{},"\u2003[ in ] CONST D3D10_SHADER_RESOURCE_VIEW_DESC*"]},{"entry":[{},"\u2003pDesc,"]},{"entry":[{},"\u2003[ out ] ID3D10ShaderResourceView** ppSRView );"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 3","b":["306","308","311","306","312","311","308","311"]},"An exemplary syntax for object creation can include:",{"@attributes":{"id":"p-0034","num":"0033"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"CreateInputLayout"},{"entry":"HRESULT CreateInputLayout("},{"entry":"\u2003[ in, size_is(NumElements) ] D3D10_INPUT_ELEMENT_DESC*"},{"entry":"pInputElementDescs,"},{"entry":"\u2003[ in ] UINT NumElements,"},{"entry":"\u2003[ in ] const void* pShaderBytecodeWithInputSignature,"},{"entry":"\u2003[ out ] ID3D10InputLayout** ppInputLayout"},{"entry":");"},{"entry":"typedef enum D3D10_INPUT_CLASSIFICATION"},{"entry":"{"},{"entry":"\u2003D3D10_INPUT_PER_VERTEX_DATA,"},{"entry":"\u2003D3D10_INPUT_PER_INSTANCE_DATA"},{"entry":"} D3D10_INPUT_CLASSIFICATION;"},{"entry":"const UINT D3D10_APPEND_ALIGNED_ELEMENT = 0xffffffff;"},{"entry":"typedef struct D3D10_INPUT_ELEMENT_DESC"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"91pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["\u2003LPCSTR","SemanticName;"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u2003UINT","SemanticIndex;"]},{"entry":["\u2003DXGI_FORMAT","Format;"]},{"entry":["\u2003UINT","InputSlot;"]},{"entry":["\u2003UINT","AlignedByteOffset;"]},{"entry":["\u2003D3D10_INPUT_CLASSIFICATION","InputSlotClass;"]},{"entry":["\u2003UINT","InstanceDataStepRate;"]},{"entry":"} D3D10_INPUT_ELEMENT_DESC;"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}},"br":{}},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 4","b":["406","408","408","406","412","414","416"]},"In general such computational units , ,  are positioned within the pipeline to enable operation at various granularity levels (e.g., pixel granularity, vertex granularity, and the like), wherein such computational units can consume data; produce data pass data therebetween. For example, data can be passed between shader stages (e.g., from an input assembler to the first shader stage)\u2014such that adjacent stages effectively share a register array. The upstream stage can write data to specific locations in the register array and the downstream stage in generally must read from the same locations. The linking component  can encode a string for each parameter that can be validated via a de-bug layer as part of a layering arrangement, as described in detail infra. For example, the API mechanism for the upstream stage and downstream stage can share a common understanding of the linkage register locations (e.g., a \u2018signature\u2019.) Accordingly, configuration speed can be enhanced and a fix up requirement for corresponding input\/out puts for computational units of the pipeline is reduced.",{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 5","b":["508","510","511","510","508"]},"Signatures can be created during high-level shader language (HLSL) compilation based on the shader declaration, such as the specific names used in the HLSL code for the element names, for example. For connection points that are input-to or output-from a shader, the signature can be embedded in the shader object. Moreover for non-shader connection points (e.g., input assembler, stream output, and render target output) applications can either explicitly create a signature or extract a signature from a shader to use at such points.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 6","b":["606","608","608"]},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 7","b":["710","712","714","716","718"]},"In general, the core layer  can be incorporated for high-frequency calls, to perform a thin mapping between the API and the user-mode DDI. Put differently, such core layer  supplies a thin mapping to the API. Additional optional layers  support supplementary validation and other developer aids and tools. In general, layers can be requested at device create time, or in the case of developer tools can be controlled by external means (control panel, registry) and bound at device create time. Typically, and unless a layer specifically introduces behavior changes, the API component  behaves identically as layers are added and removed. For example, additional validation performed in the debug layer  can find and report issues via a separate error reporting mechanism, and will not alter any function behavior (including return results), for example. The debug layer  enables moving validation from run-time to development time and identifies application errors. Conceptually, the ordering of layers can be defined to maximize compatibility and utility between such layers. For example, the thread-safe layer can be positioned near the application, to provide thread-safety for other active layers in use.","In a related aspect, within the multi layering arrangement of the subject innovation, a query can be provided to turn \u201con\u201d and \u201coff\u201d the thread safety layer . Accordingly, thread safety can be employed for a predetermined period (e.g., for multiple threads to load data), and yet turned \u201coff\u201d at runtime when actual rendering occurs (wherein, safety is not required, as rendering can occur from a same thread, for example.) Hence, a balance can be maintained between performance and multithreaded safety, wherein thread safety support can be implemented in an optional layer wrapped around the core API. In general, such layer can be enabled by default, and if not active has no performance impact on single-thread accessed devices.","According to a particular example, a layered run-time can be provided wherein API call can move through various layers, to provide additional functionality (e.g., linkage validation, traversing strings to ensure that adjacent shaders are passing values expected by the application, and the like.) As such, a de-bug layer can be supplied that in general does not affect the actual behavior of the API, to obtain layer specific interfaces.","In a related aspect, handles or pointers for identification of data (which the API communicates to the driver), can be assigned at run-time and\/or API assigned\u2014as opposed to handles being driver assigned\u2014wherein the driver can inform how large a region of memory the handle should point to. In general, handles are pointers that are wrapped with a strong type to identify the object being operated on. The value of such pointer can be provided by the runtime. Accordingly, a control of memory allocation can be supplied (e.g., positioning data next to driver data), to enhance memory coherence (as access patterns indicate that this data will be accessed and thus improve performance.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 8","b":["810","820","830","840"]},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 9","b":["910","920","930","940"]},"As used in herein, the terms \u201ccomponent,\u201d \u201csystem\u201d, \u201carrangement\u201d and the like are intended to refer to a computer-related entity, either hardware, a combination of hardware and software, software or software in execution. For example, a component can be, but is not limited to being, a process running on a processor, a processor, an object, an instance, an executable, a thread of execution, a program and\/or a computer. By way of illustration, both an application running on a computer and the computer can be a component. One or more components may reside within a process and\/or thread of execution and a component may be localized on one computer and\/or distributed between two or more computers.","The word \u201cexemplary\u201d is used herein to mean serving as an example, instance or illustration. Any aspect or design described herein as \u201cexemplary\u201d is not necessarily to be construed as preferred or advantageous over other aspects or designs. Similarly, examples are provided herein solely for purposes of clarity and understanding and are not meant to limit the subject innovation or portion thereof in any manner. It is to be appreciated that a myriad of additional or alternate examples could have been presented, but have been omitted for purposes of brevity.","Furthermore, all or portions of the subject innovation can be implemented as a system, method, apparatus, or article of manufacture using standard programming and\/or engineering techniques to produce software, firmware, hardware or any combination thereof to control a computer to implement the disclosed innovation. For example, computer readable media can include but are not limited to magnetic storage devices (e.g., hard disk, floppy disk, magnetic strips . . . ), optical disks (e.g., compact disk (CD), digital versatile disk (DVD) . . . ), smart cards, and flash memory devices (e.g., card, stick, key drive . . . ). Additionally it should be appreciated that a carrier wave can be employed to carry computer-readable electronic data such as those used in transmitting and receiving electronic mail or in accessing a network such as the Internet or a local area network (LAN). Of course, those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.","In order to provide a context for the various aspects of the disclosed subject matter,  as well as the following discussion are intended to provide a brief, general description of a suitable environment in which the various aspects of the disclosed subject matter may be implemented. While the subject matter has been described above in the general context of computer-executable instructions of a computer program that runs on a computer and\/or computers, those skilled in the art will recognize that the innovation also may be implemented in combination with other program modules. Generally, program modules include routines, programs, components, data structures, etc. that perform particular tasks and\/or implement particular abstract data types. Moreover, those skilled in the art will appreciate that the innovative methods can be practiced with other computer system configurations, including single-processor or multiprocessor computer systems, mini-computing devices, mainframe computers, as well as personal computers, hand-held computing devices (e.g., personal digital assistant (PDA), phone, watch . . . ), microprocessor-based or programmable consumer or industrial electronics, and the like. The illustrated aspects may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. However, some, if not all aspects of the innovation can be practiced on stand-alone computers. In a distributed computing environment, program modules may be located in both local and remote memory storage devices.","With reference to , an exemplary environment  for implementing various aspects of the subject innovation is described that includes a computer . The computer  includes a processing unit , a system memory , and a system bus . The system bus  couples system components including, but not limited to, the system memory  to the processing unit . The processing unit  can be any of various available processors. Dual microprocessors and other multiprocessor architectures also can be employed as the processing unit .","The system bus  can be any of several types of bus structure(s) including the memory bus or memory controller, a peripheral bus or external bus, and\/or a local bus using any variety of available bus architectures including, but not limited to, 11-bit bus, Industrial Standard Architecture (ISA), Micro-Channel Architecture (MSA), Extended ISA (EISA), Intelligent Drive Electronics (IDE), VESA Local Bus (VLB), Peripheral Component Interconnect (PCI), Universal Serial Bus (USB), Advanced Graphics Port (AGP), Personal Computer Memory Card International Association bus (PCMCIA), and Small Computer Systems Interface (SCSI).","The system memory  includes volatile memory  and nonvolatile memory . The basic input\/output system (BIOS), containing the basic routines to transfer information between elements within the computer , such as during start-up, is stored in nonvolatile memory . By way of illustration, and not limitation, nonvolatile memory  can include read only memory (ROM), programmable ROM (PROM), electrically programmable ROM (EPROM), electrically erasable ROM (EEPROM), or flash memory. Volatile memory  includes random access memory (RAM), which acts as external cache memory. By way of illustration and not limitation, RAM is available in many forms such as synchronous RAM (SRAM), dynamic RAM (DRAM), synchronous DRAM (SDRAM), double data rate SDRAM (DDR SDRAM), enhanced SDRAM (ESDRAM), Synchlink DRAM (SLDRAM), and direct Rambus RAM (DRRAM).","Computer  also includes removable\/non-removable, volatile\/non-volatile computer storage media.  illustrates, for example a disk storage . Disk storage  includes, but is not limited to, devices like a magnetic disk drive, floppy disk drive, tape drive, Jaz drive, Zip drive, LS-60 drive, flash memory card, or memory stick. In addition, disk storage  can include storage media separately or in combination with other storage media including, but not limited to, an optical disk drive such as a compact disk ROM device (CD-ROM), CD recordable drive (CD-R Drive), CD rewritable drive (CD-RW Drive) or a digital versatile disk ROM drive (DVD-ROM). To facilitate connection of the disk storage devices  to the system bus , a removable or non-removable interface is typically used such as interface .","It is to be appreciated that  describes software that acts as an intermediary between users and the basic computer resources described in suitable operating environment . Such software includes an operating system . Operating system , which can be stored on disk storage , acts to control and allocate resources of the computer system . System applications  take advantage of the management of resources by operating system  through program modules  and program data  stored either in system memory  or on disk storage . It is to be appreciated that various components described herein can be implemented with various operating systems or combinations of operating systems.","A user enters commands or information into the computer  through input device(s) . Input devices  include, but are not limited to, a pointing device such as a mouse, trackball, stylus, touch pad, keyboard, microphone, joystick, game pad, satellite dish, scanner, TV tuner card, digital camera, digital video camera, web camera, and the like. These and other input devices connect to the processing unit  through the system bus  via interface port(s) . Interface port(s)  include, for example, a serial port, a parallel port, a game port, and a universal serial bus (USB). Output device(s)  use some of the same type of ports as input device(s) . Thus, for example, a USB port may be used to provide input to computer , and to output information from computer  to an output device . Output adapter  is provided to illustrate that there are some output devices  like monitors, speakers, and printers, among other output devices  that require special adapters. The output adapters  include, by way of illustration and not limitation, video and sound cards that provide a means of connection between the output device  and the system bus . It should be noted that other devices and\/or systems of devices provide both input and output capabilities such as remote computer(s) .","Computer  can operate in a networked environment using logical connections to one or more remote computers, such as remote computer(s) . The remote computer(s)  can be a personal computer, a server, a router, a network PC, a workstation, a microprocessor based appliance, a peer device or other common network node and the like, and typically includes many or all of the elements described relative to computer . For purposes of brevity, only a memory storage device  is illustrated with remote computer(s) . Remote computer(s)  is logically connected to computer  through a network interface  and then physically connected via communication connection . Network interface  encompasses communication networks such as local-area networks (LAN) and wide-area networks (WAN). LAN technologies include Fiber Distributed Data Interface (FDDI), Copper Distributed Data Interface (CDDI), Ethernet\/IEEE 802.3, Token Ring\/IEEE 802.5 and the like. WAN technologies include, but are not limited to, point-to-point links, circuit switching networks like Integrated Services Digital Networks (ISDN) and variations thereon, packet switching networks, and Digital Subscriber Lines (DSL).","Communication connection(s)  refers to the hardware\/software employed to connect the network interface  to the bus . While communication connection  is shown for illustrative clarity inside computer , it can also be external to computer . The hardware\/software necessary for connection to the network interface  includes, for exemplary purposes only, internal and external technologies such as, modems including regular telephone grade modems, cable modems and DSL modems, ISDN adapters, and Ethernet cards.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 11","b":["1100","1100","1110","1110","1100","1130","1130","1130","1110","1130","1100","1150","1110","1130","1110","1160","1110","1130","1140","1130"]},"What has been described above includes various exemplary aspects. It is, of course, not possible to describe every conceivable combination of components or methodologies for purposes of describing these aspects, but one of ordinary skill in the art may recognize that many further combinations and permutations are possible. Accordingly, the aspects described herein are intended to embrace all such alterations, modifications and variations that fall within the spirit and scope of the appended claims.","Furthermore, to the extent that the term \u201cincludes\u201d is used in either the detailed description or the claims, such term is intended to be inclusive in a manner similar to the term \u201ccomprising\u201d as \u201ccomprising\u201d is interpreted when employed as a transitional word in a claim."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
