---
title: Reproducing apparatus, reproducing method, reproducing program, and recording medium
abstract: A reproducing apparatus for reproducing contents data recorded on a disc-shaped recording medium is disclosed, the apparatus comprising inputting means for inputting a non-real time stream and a real time stream reproduced from the recording medium, storing means for storing the program code that has been input by the inputting means; image data storing means for storing the image data that has been input by the inputting means; first combining means for combining decoded moving picture data and decoded subtitle data; and second combining means for combining the decoded image data and the combined data of the decoded moving picture and the decoded subtitle data in accordance with the program code stored in the code storing means.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08620140&OS=08620140&RS=08620140
owner: Sony Corporation
number: 08620140
owner_city: Tokyo
owner_country: JP
publication_date: 20050128
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","OBJECTS AND SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["1. Field of the Invention","The present invention relates to a reproducing apparatus, a reproducing method, a reproducing program, and a recording medium that allow a user to interactively operate a program recorded on a large capacity recording medium such as a blu-ray disc.","2. Description of the Related Art","In recent years, as a standard for a recordable disc type recording medium that is detachable from a recording and reproducing apparatus, blu-ray disc standard has been proposed. The blu-ray disc standard prescribes a disc that has a recording medium having a diameter of 12 cm and a cover layer having a thickness of 0.1 mm. The blu-ray disc standard uses a bluish-purple laser having a wavelength of 405 nm and an objective lens having a numerical aperture of 0.85. The blu-ray disc standard accomplishes a recording capacity of 27 GB (Giga bytes) maximum. As a result, a program of a broadcasting satellite (BS) digital high-vision broadcast available in Japan can be recorded for two hours or longer without deterioration of picture quality.","As sources (supply sources) of audio\/video (AV) signals recorded on the recordable optical disc, an analog signal of for example a conventional analog television broadcast and a digital signal of for example a digital television broadcast such as a BS digital broadcast will be used. The blu-ray disc standard has established a method for recording AV signals of such broadcasts.","On the other hand, as a derivative standard of the current blu-ray disc standard, a reproduction-only recording medium on which a movie, music, or the like is prerecorded is being developed. As a disc-shaped recording medium on which a movie or music is prerecorded, a digital versatile disc (DVD) has been widely used. The reproduction-only optical disc in accordance with the blu-ray disc standard is largely different from and superior to the conventional DVD in a large recording capacity and a high speed transfer speed that allow a high-vision picture to be recoded for two hours or longer in high quality.","On the other hand, the current blu-ray disc standard prescribes neither a method for displaying a list of video contents of a disc on a screen nor a user interface function for allowing a user to move a cursor on the list and select a video content that he or she wants to reproduce from the list. These functions are accomplished by a recording and reproducing apparatus main unit that records and reproduces video contents to and from the blu-ray disc. Thus, even if a video content is reproduced from the same recording medium, the layout of the contents list screen depends on the recording and reproducing apparatus for use, and so does the user interface. Thus, the user cannot easily use the blu-ray disc. Consequently, it is necessary to allow the reproduction-only disc to display a menu screen and so forth that the disc (contents) producer has designed, not depend on the reproducing apparatus.","In addition, a multiple story function of which a selection screen is displayed while a video content is being reproduced is generally called an interactive function. To accomplish the interactive function, it is necessary for the disc producer to create a scenario that he or she has designated a reproduction order and branches of the video content, describe the scenario using a program language, a script language, or the like, and record the described scenario on a disc. The reproducing apparatus side reads and executes the scenario. As a result, the reproducing apparatus reproduces a video content and displays selection screens that allow the user to select branches of the video content that the producer has designated.","Thus, the current blu-ray disc standard (blu-ray disc rewritable format ver 1.0) prescribes neither a method for composing a menu screen and a branch selection screen that a contents producer has designated, nor a method for describing a process for a user input. Consequent, to date, it is difficult to reproduce a video content from the blu-ray disc in accordance with a scenario that the producer has designated with compatibility irrespective of manufactures and models of reproducing apparatuses.","For a reproduction-only disc on which a movie has been recorded, a function for displaying subtitles is essential. However, the current blu-ray disc standard does not prescribe the function for describing subtitles.","On the other hand, the foregoing interactive function has been already accomplished in for example the DVD (Digital Versatile Disc) standard. For example, in the DVD video, while a moving picture is being reproduced, a menu screen is called using a remote control commander. For example, by selecting a button displayed on a menu screen, the user can perform a process for changing the current scene that is being reproduced. The DVD standard also prescribes a function for displaying subtitles. That function allows the user to switch Japanese subtitles to English subtitles or vice versa that have been prepared.","In the case of the DVD, a menu screen is composed of a fixed sub picture. When the menu screen is called, it is displayed in such a manner that the sub picture is combined with a moving picture. Japanese Patent Laid-Open Publication No. HEI 10-308924 (hereinafter referred to as the patent document 1) describes a structure for combining sub picture data with moving picture data and recording the combined data on a recordable DVD.","Next, an example of a menu screen according to the related art reference will be described in brief. Before a movie main part is reproduced from a DVD by a reproducing apparatus, a menu screen is displayed. Generally, a plurality of buttons are disposed on the menu screen. Each button is assigned a predetermined operation. When the user selects a button and causes the operation of the selected button to be executed, the operation assigned to the selected button is executed. For example, when the user selects a button \u201cmovie main part\u201d and causes the operation of the selected button to be executed, the operation assigned to the button is executed. As a result, the movie main part is reproduced from the DVD.","The user operates keys (direction keys) assigned to up, down, left, and right directions with for example the remote control commander (hereinafter referred to as remote controller) so as to select one button displayed on the menu screen. Thereafter, with an OK key, the user causes the operation assigned to the selected button to be executed. In addition, each button has three states that are a normal state (non-selection state), a selection state, and an execution state. To allow the user to easily distinguish them, they have different images and colors. Generally, there is only one button that is placed in the selection state or the execution state.","For example, in the DVD video, each button is displayed with two types of data called sub picture and highlight.  shows an example of a DVD menu screen  according to a related art reference. The menu screen  is referred to as \u201ctitle menu\u201d. The menu screen  has three buttons A, B, and C that represent \u201cmove main part play\u201d, \u201cbonus picture\u201d, and \u201csound setting\u201d, respectively. In the example shown in , the color of an outer frame of the \u201cmovie main part play\u201d button A has been changed from the original color. That describes that the \u201cmovie main part play\u201d button A has been placed in the selection state.","In such a state, when the user operates the direction keys on the remote controller, for example as shown in , , and , he or she can cause another button to be placed in the selection state. Like the case shown in , the color of the outer frame of the button that has been selected is different from the colors of the outer frames of the other buttons that have not been selected (non-selected buttons). For example, in the state shown in , when the user operates an OK button disposed on the remote controller, as shown in , the color of the \u201cmovie main part play\u201d button A is changed to a color that represents the execution state. Thereafter, the menu screen  is cleared and the movie main part is reproduced. The foregoing is a basic operation of buttons of the DVD video.","The menu screen  as shown in  is composed of three types of data that are a background picture , a sub picture , and a highlight  that are shown in , , and , respectively. The background picture  is a still picture, a moving picture of a content main part prerecorded on the DVD, or the like.","As shown in , the sub picture  has one bit map picture, four-color information (A, B, C, and D), and coordinates (X, Y). The bit map picture is represented with information of two bits per pixel. The coordinates (X, Y) represent the display start position of the sub picture . Each of the color information A, B, C, and D is one-color information data composed of one set of R (Red), G (Green), and B (Blue) data. Each of colors R, G, and B has information of eight bits. The bit map picture has information of two bits per pixel. With two bits, one is selected from the foregoing four-color information (A, B, C, D) for each pixel. Color information also has transparency data. The sub picture  may have a region in which the background picture  is transparent. The display position of the upper left corner of the sub picture  is represented with coordinates (X, Y) relative to the background picture .","In addition, the sub picture  may have information that represents a display start time and a display end time and commands that cause visual effects such as fade-in and fade-out to be applied to the sub picture .","In the DVD video, a plurality of bit map pictures cannot be displayed at the same time. Thus, the menu screen  on which the plurality of buttons as shown in  are placed is displayed with one large bit map picture that has three button images as shown in . In the bit map picture of the sub picture  shown in , when a region outside the buttons A, B, and C is designated as a transparent region and the sub picture  is combined with the background picture , the background picture  becomes transparent outside the display regions of the buttons A, B, and C.","The highlight  is information used to change four colors used for the sub picture  to other four colors. As shown in , as color information, the highlight  has color information (A, B, C, D) of a selection state and color information (A, B, C, D) of an execution state. These color information is four-color information represented with RGB of eight bits each like the foregoing sub picture .","The highlight  has a set of coordinates of regions in which colors are changed. The range of which colors are changed is not limited to all the sub picture , but a part of the sub picture  as a square region. The number of square regions in the sub picture  of which colors are changed by the highlight  corresponds to the number of buttons that the user can select. The display position of each square region is represented by coordinates (X, Y) of the positions of the upper left corner and the lower left corner thereof. For example, the position of the highlight A corresponding to the button A is represented by coordinates (X, Y) and (X\u2032, Y\u2032). That applies to the highlights B and C corresponding to the buttons B and C, respectively.","For example, in the highlight A, color information (A, B, C, D) of a region represented by coordinates (X, Y) and (X\u2032, Y\u2032) of the background picture  is changed to color information (A, B, C, D) designated as a color of a selection state. At this point, the color information A of the background picture  is changed to color information A of the highlight A. Likewise, the color information B of the background picture  is changed to the color information B. The color information C is changed to the color information C. The color information D is changed to the color information D.","Next, an example of a color change of the highlight  will be described corresponding to a change of a state of the button A on the menu screen  shown in , , , , and . It is assumed that when the button A is in the non-selection state, the frame, front surface, and characters of the button A are displayed with the color information B, the color information C, and the color information D, respectively. When the button A is placed in the selection state, the frame color B of the button A is changed to the color information B corresponding to the selection state of the highlight A. At this point, the front surface color C and the character color D are not changed. Thereafter, when the button A is placed in the execution state, the front surface color C of the button A, which is the color of the selection state, is changed to the color information C. At this point, the frame color B and the character color D, which are the colors of the selection state, are not changed.","When a picture of the DVD video is normally reproduced, a picture corresponding to the background picture  is displayed. On the other hand, when a movie that has subtitles is reproduced, the background picture  of which the movie main part is reproduced and the sub picture  of which the subtitles are displayed are combined and displayed.","However, in the DVD video, the sub picture , the highlight  that represents the selection state, and the highlight  that represents the execution state can use only up to four colors each. Thus, as a problem of the related art, a sub picture having many colors cannot be displayed.","In addition, the highlight  only changes the color of the sub picture . Thus, characters of a button cannot be changed in for example the selection state and the execution state. In addition, an effect of which the shape of a button is changed cannot be accomplished. Thus, the related art cannot accomplish an enriched user interface.","In addition, conventionally, subtitles and buttons are displayed with the same scheme using the sub picture . Thus, the subtitles and the buttons cannot be independently controlled and displayed. In addition, a combining process for setting and combining transparencies of the subtitles and buttons and displaying the combined picture cannot be performed.","In addition, in the DVD video, when the menu screen is called, moving picture data reproduced in the background thereof is stopped. Thus, conventionally, even if such an interactive function were accomplished, the flexibility of the user interface that accomplishes the function would be low.","In the DVD video, a scheme for generating an effect sound in synchronization with subtitles displayed and changed has not been prescribed in the standard. Thus, an effect sound cannot be generated in synchronization with for example subtitles as a problem of the related art.","In addition, the standard does not prescribe a scheme for generating effect sounds for buttons such as an effect sound that is generated when the user places a button in the selection state and a click sound that is generated when the user operates an OK key in the selection state of a button. Thus, it is difficult to accomplish an enriched user interface as a problem of the related art.","In the foregoing, the effect sound is not sound data that is reproduced in synchronization with a moving picture or a still picture displayed on the moving picture plane (for example, sound that is recoded as a pair of a movie picture), but audio data reproduced by or in synchronization with a display control of subtitles and buttons.","Therefore, an object of the present invention is to provide a reproducing apparatus, a reproducing method, a reproducing program, and a recording medium that allow a user interface with high flexibility for a large capacity reproduction-only optical disc to be accomplished.","Another object of the present invention is to provide a reproducing apparatus, a reproducing method, a reproducing program, and a recording medium that allow an enriched user interface for a large capacity reproduction-only optical disc to be accomplished.","A first aspect of the present invention is a reproducing apparatus for reproducing contents data recorded on a disc-shaped recording medium, the apparatus comprising inputting means for inputting a non-real time stream and a real time stream reproduced from the recording medium, the non-real time stream containing a file storing as a set of at least a program code, image data composing an operation screen prompting a user to perform an operation, and a plurality of pieces of sound data with which effects sounds are reproduced, the real time stream containing at least moving picture data and subtitle data; storing means for storing the program code that has been input by the inputting means; image data storing means for storing the image data that has been input by the inputting means; first combining means for combining decoded moving picture data of which the moving picture data that had been input by the inputting means has been decoded and decoded subtitle data of which the subtitle data that had been input by the inputting means has been decoded; and second combining means for combining the decoded image data that has been stored in the image data storing means and the combined data of the decoded moving picture and the decoded subtitle data combined by the first combining means in accordance with the program code stored in the code storing means.","A second aspect of the present invention is a reproducing method for reproducing contents data recorded on a disc-shaped recording medium, the method comprising the steps of inputting a non-real time stream and a real time stream reproduced from the recording medium, the non-real time stream containing a file storing as a set of at least a program code, image data composing an operation screen prompting a user to perform an operation, and a plurality of pieces of sound data with which effects sounds are reproduced, the real time stream containing at least moving picture data and subtitle data; storing the program code that has been input at the inputting step; storing the image data that has been input at the inputting step; combining decoded moving picture data of which the moving picture data that had been input at the inputting step has been decoded and decoded subtitle data of which the subtitle data that had been input at the inputting step has been decoded; and combining the decoded image data that has been stored at the second storing step and the combined data of the decoded moving picture and the decoded subtitle data combined at the first combining step in accordance with the program code stored at the first storing step.","A third aspect of the present invention is a reproducing program for causing a computer device to execute a reproducing method for reproducing contents data recorded on a disc-shaped recording medium, the method comprising the steps of inputting a non-real time stream and a real time stream reproduced from the recording medium, the non-real time stream containing a file storing as a set of at least a program code, image data composing an operation screen prompting a user to perform an operation, and a plurality of pieces of sound data with which effects sounds are reproduced, the real time stream containing at least moving picture data and subtitle data; storing the program code that has been input at the inputting step; storing the image data that has been input at the inputting step; combining decoded moving picture data of which the moving picture data that had been input at the inputting step has been decoded and decoded subtitle data of which the subtitle data that had been input at the inputting step has been decoded; and combining the decoded image data that has been stored at the second storing step and the combined data of the decoded moving picture and the decoded subtitle data combined at the first combining step in accordance with the program code stored at the first storing step.","A fourth aspect of the present invention is a recording medium from which a computer device can read a reproducing program that causes the computer device to execute a reproducing method for reproducing contents data recorded on a disc-shaped recording medium, the method comprising the steps of inputting a non-real time stream and a real time stream reproduced from the recording medium, the non-real time stream containing a file storing as a set of at least a program code, image data composing an operation screen prompting a user to perform an operation, and a plurality of pieces of sound data with which effects sounds are reproduced, the real time stream containing at least moving picture data and subtitle data; storing the program code that has been input at the inputting step; storing the image data that has been input at the inputting step; combining decoded moving picture data of which the moving picture data that had been input at the inputting step has been decoded and decoded subtitle data of which the subtitle data that had been input at the inputting step has been decoded; and combining the decoded image data that has been stored at the second storing step and the combined data of the decoded moving picture and the decoded subtitle data combined at the first combining step in accordance with the program code stored at the first storing step.","A fifth aspect of the present invention is a disc-shaped recording medium on which contents data is recorded, a non-real time stream that contains at least a program code and image data that composes an operation screen that prompts a user to perform an operation, a real time stream that contains at least moving picture data and subtitle data, and a file that stores as a set of a plurality of pieces of sound data with which effects sounds being recorded, decoded image data that has been stored and combined data of decoded moving picture and decoded subtitle data that have been combined being combined in accordance with the program code.","A sixth aspect of the present invention is a recording apparatus for recording contents data on a disc-shaped recording medium, the apparatus comprising; recording means for recording a non-real time stream and a real time stream, the non-real time stream containing a file storing as a set of at least a program code, image data composing an operation screen prompting a user to perform an operation, and a plurality of pieces of sound data with which effects sounds, the real time stream containing at least moving picture data and subtitle data; wherein the program code is to execute a combining decoded image data obtained by decoding the image data which is recorded by the recording means and combined data which is comprising of decoded moving picture data of the real-time stream and decoded subtitle data of which the subtitle data of the real-time stream.","As described above, according to the first to fourth aspect of the present invention, a non-real time stream and a real time stream that have been reproduced from the recording medium are input. The non-real time stream contains a file that stores as a set of at least a program code, image data that composes an operation screen prompting a user to perform an operation, and a plurality of pieces of sound data with which effects sounds are reproduced. The real time stream contains at least moving picture data and subtitle data. The program code is stored in code storing means. The image data is stored in image data storing means. Decoded moving picture data of which the moving picture data that had been input has been decoded and decoded subtitle data of which the subtitle data that had been input has been decoded are combined and combined data of the decoded moving picture and the decoded subtitle data is obtained. The decoded image data that has been stored in the image data storing means and the combined data of the decoded moving picture and the decoded subtitle data are combined in accordance with the program code stored in the code storing means. Thus, when contents data is reproduced, the operation screen using the same image data can be easily displayed at different timings. In addition, effect sounds that prompt the user to operate on the operation screen can be reproduced.","According to the fifth aspect of the present invention, a non-real time stream that contains at least a program code and image data that composes an operation screen that prompts a user to perform an operation, a real time stream that contains at least moving picture data and subtitle data, and a file that stores as a set of a plurality of pieces of sound data with which effects sounds being recorded are recorded. Decoded image data that has been stored and combined data of decoded moving picture and decoded subtitle data that have been combined being combined in accordance with the program code. Thus, when contents data is reproduced, the operation screen using the same image data can be easily displayed at different timings. In addition, effect sounds that prompt the user to operate on the operation screen can be reproduced.","According to the sixth aspect of the present invention, a non-real time stream that contains at least a program code and image data that composes an operation screen that prompts a user to perform an operation, a real time stream that contains at least moving picture data and subtitle data, and a file that stores as a set of a plurality of pieces of sound data with which effects sounds being recorded are recorded in recording medium. Decoded image data that has been stored and combined data of decoded moving picture and decoded subtitle data that have been combined being combined in accordance with the program code which is recorded in recording medium. Thus, when contents data in recording medium is reproduced, the operation screen using the same image data can be easily displayed at different timings. In addition, effect sounds that prompt the user to operate on the operation screen can be reproduced.","As described above, a prerecorded large capacity disc according to the present invention has three independent planes that are a moving picture plane for a moving picture, a subtitle plane for subtitles, and a graphics plane for a screen having an interruptive function such as a menu screen. These planes are combined and displayed. Thus, as an effect of the present invention, a moving picture can be displayed on the moving picture plane, while a menu screen and so forth are displayed on the graphics plane with a background of the moving picture.","In addition, according to the present invention, since a buffer that stores image data to be displayed on the graphics plane is disposed, the same image data can be repeatedly displayed on the graphics plane. Thus, as an effect of the present invention, a menu screen and so forth can be structured with higher flexibility than before.","In addition, according to the present invention, a display control for graphics displayed on a graphic plane is described using display control commands. Thus, as an effect of the present invention, an interactive function can be accomplished with a screen displayed on the graphics plane.","In addition, a prerecorded large capacity disc according to the present invention has three independent planes that are a moving picture plane for a moving picture, a subtitle plane for subtitles, and a graphics plane for a screen having an interruptive function such as a menu screen. These planes are combined and displayed. A common graphics object as a format of an object displayed on the subtitle plane and the graphics plane is defined. A decoder model, display control commands, and an operation model are defined. As a result, as an effect of the present invention, subtitles and buttons can be displayed in synchronization with a moving picture.","In addition, a simple animation of which subtitles and buttons are scrolled and moved and enriched buttons of which the contents of an image are varied corresponding to a user's input can be accomplished.","In addition, according to the present invention, a decoder model of which sound data is contained in a graphics object and of which the sound data is reproduced while a button image contained in the graphics object is displayed is defined. Thus, sound data can be easily reproduced in synchronization with a graphics object that is displayed.","In addition, according to the present invention, a command that causes sound data to be reproduced is defined against a display control command for a graphics object. In addition, sound data can be assigned to image data contained in a graphics object against a display control command for an object. Thus, as an effect of the present invention, sound data such as an effect sound can be reproduced at any time and subtitles and buttons that have effect sounds can be accomplished.","In addition, according to the present invention, a scheme for generating effect sound such as click sound when the user has selected a button on a menu screen displayed by a graphical user interface (GUI) or he or she has operated an OK button after a button has been selected is provided. Thus, in a reproducing apparatus, a reproducing method, a reproducing program, and a recording medium that allows the user to interactively operate a program prerecorded on a large capacity recording medium such as the blu-ray disc, an enriched user interface can be accomplished.","These and other objects, features and advantages of the present invention will become more apparent in light of the following detailed description of a best mode embodiment thereof, as illustrated in the accompanying drawings.","Next, the present invention will be described in the following order.\n\n","First of all, for easy understanding of the present invention, a management structure as prescribed in \u201cBlu-ray Disc Rewritable Format Ver 1.0 part 3 Audio Visual Specification) for contents namely AV (Audio\/Video) data prerecorded on the blu-ray disc will be described. In the following description, the management structure is referred to as BDAV format.","A bit stream that has been encoded in accordance with an encoding system such as MPEG (Moving Pictures Experts Group) video or MPEG audio and multiplexed in accordance with MPEG-2 system is referred to as clip AV stream (or simply AV stream). The clip AV stream is recorded as a file on a disc by a file system defined in \u201cBlu-ray Disc Rewritable Format Ver 1.0 part 2\u201d for the blu-ray disc. This file is referred to as clip AV stream file (or simply AV stream).","A clip AV stream file is a management unit on the file system. Thus, it cannot be said that a clip AV stream file is a management unit that the user can easily understand. From a view point of user's convenience, it is necessary to record a scheme necessary for combining a video content that has been divided into a plurality of clip AV stream files and reproducing the combined video content, a scheme necessary for reproducing only a part of a clip AV stream file, information necessary for smoothly performing a special reproduction and a search reproduction, and so forth as a database. \u201cBlu-ray Disc Rewritable Format Ver. 1.0 part 3\u201d as a standard for the blu-ray disc prescribes such a database.",{"@attributes":{"id":"p-0149","num":"0177"},"figref":["FIG. 6","FIG. 6"]},"The simplest structure of a play list is one AV stream file obtained after recording of a content is started until the recording is stopped. Unless the AV stream file is edited, it becomes one play list.","A play list is composed of information that represents an AV stream file to be reproduced and sets of reproduction start points and reproduction stop points that designate reproduction start positions and reproduction stop positions of the AV stream file. A pair of information of a reproduction start point and information of a reproduction stop point is referred to as play item (PlayItem). A play list is composed of a set of play items. When a play item is reproduced, a part of the AV stream file referred from the play item is reproduced.","As described above, a clip AV stream is a bit stream of which video data and audio data have been multiplexed in the format of an MPEG2 TS (Transport Stream). Information about the clip AV stream is recorded as clip information to a file.","A set of a clip AV stream file and a clip information file that has corresponding clip information is treated as one object and referred to as clip. A clip is one object that is composed of a clip AV stream and clip information.","A file is generally treated as a sequence of bytes. A content of a clip AV stream file is expanded on the time base. An entry point in a clip is regularly designated on the time base. When a time stamp of an access point to a predetermined clip is given, a clip information file can be used to find information of an address from which data is read in a clip AV stream file.","All play lists and clips recorded on one disc are managed with volume information.",{"@attributes":{"id":"p-0156","num":"0184"},"figref":"FIG. 7"},"In addition, as shown in , the same clip can be referenced from a plurality of play lists. In the example shown in , a clip  is referenced from two play lists  and . In , the horizontal direction of the clip  represents the time base. The play list  references regions a to f of the clip  that include commercial message regions b and c and a scene e. On the other hand, the play list  references regions d to g of the clip  that include a scene e. When the play list  is designated, the regions a to f of the clip  can be reproduced. When the play list  is designated, the regions d to g of the clip  can be reproduced.","Next, with reference to , a management structure for files recorded on a recording medium prescribed in \u201cBlu-ray Disc Rewritable Format Ver 1.0 part 3\u201d will be described. Files are hierarchically managed in a directory structure. One directory (a root directory in the example shown in ) is created on the recording medium. Under the directory, files are managed by one recording and reproducing system.","Under the root directory, a directory BDAV is placed. As shown in , a plurality of directories such as directories BDAV, BDAV, BDAV, . . . , BDAVn can be placed. In the following description, the plurality of directories BDAV, BDAV, BDAV . . . , and BDAVn are represented by the directory BDAV. Only the representative directory BDAV will be described.","Under the directory BDAV, the following six types of files are placed.\n\n","In the files \u201c#####.rpls\u201d and \u201c#####.vpls\u201d categorized as (4), \u201c#####\u201d represents any number. Likewise, in the file \u201c%%%%%.clpi\u201d categorized as (5), \u201c%%%%%\u201d represents any number. In the file \u201c*****.m2ts\u201d categorized as (6), \u201c*****\u201d represents a number of which a file \u201c*****.m2ts\u201d corresponds to a file \u201c%%%%%.clpi\u201d with the relation of one to one. For example, a number \u201c*****\u201d can be the same as a number \u201c%%%%%\u201d.","The file \u201cinfo.bdav\u201d categorized as (1) is a file that has information of all the directory BDAV. The files \u201cmenu.tidx\u201d and \u201cmark.tidx\u201d categorized as (2) are files that have information of thumbnail pictures. The files \u201cmenu.tdt1\u201d, \u201cmenu.tdt2\u201d, \u201cmark.tdt1\u201d, and \u201cmark.tdt2\u201d categorized as (3) are files that have thumbnail pictures. The extensions \u201ctdt1\u201d and \u201ctdt2\u201d of those files represent whether or not data of thumbnail pictures in those files have been encrypted.","The files \u201c#####.rpls\u201d and \u201c#####.vpls\u201d categorized as (4) are files that have information of play lists. The files \u201c#####.rpls\u201d and \u201c#####.vpls\u201d are placed under the directory PLAYLIST, which is placed under the directory BDAV.","The file \u201c%%%%%.clpi\u201d categorized as (5) is a file that has clip information. The file \u201c%%%%%.CLP\u201d is placed under the directory CLIPINF, which is placed under the directory BDAV. The file \u201c*****.m2ts\u201d categorized as (6) is a clip AV stream file that has a clip AV stream. A clip AV stream file is correlated with one clip information file \u201c%%%%%.clpi\u201d with a file name number \u201c*****\u201d. The file \u201c*****.m2ts\u201d is placed under the directory STREAM, which is placed under the directory BDAV.","Next, each file will be described in detail. The file \u201cinfo.bda\u201d categorized as (1) is only one file placed under the directory BDAV.  shows syntax that describes an example of a structure of the file \u201cinfo.bdav\u201d. In this example, the syntax is represented by a descriptive method of C language, which is used as a program descriptive language for computer devices. This applies to drawings that show other syntax.","In , the file \u201cinfo.bdav\u201d is divided into blocks corresponding to functions. A field type_indicator describes a character string \u201cBDAV\u201d that describes that the file is \u201cinfo.bdav\u201d. A field version_number describes a version of the file \u201cinfo.bdav\u201d. A block UIAppInfoBDAV( ) describes information about files placed under the directory DBAV. A block TableOfPlayList( ) describes information about the arrangement of the play list. A block MakersPrivateData( ) describes unique information of the maker of the recording and reproducing apparatus.","Addresses that represent the beginnings of individual blocks are described at the beginning of the file \u201cinfo.bdav\u201d. For example, a field TableOfPlayLists_Start_address represents the start position of the block \u201cTableOfPlayLists( )\u201d with the relative number of bytes in the file.",{"@attributes":{"id":"p-0168","num":"0202"},"figref":"FIG. 11"},"A flag BDAV_protect_flag describes whether or not the user is unconditionally permitted to watch a content placed under the directory BDAV. When the flag has been set to \u201c1\u201d and the user has input a correct personal identification number (PIN), he or she is permitted to watch a content placed under the directory BDAV. In contrast, when the flag BDAV_protect_flag has been set to \u201c0\u201d, even if the user does not input his or her PIN, he or she is permitted to watch a content placed under the directory BDAV.","The personal identification number PIN is described in a field PIN. The personal identification number PIN is composed of for example a four-digit number, each digit ranging from 0 to 9. The personal identification number PIN represents a personal identification number that is required when the reproduction control is validated. Digits of the personal identification number PIN are encoded in accordance with for example International Organization for Standardization (ISO)\/International Electrotechnical Commission (IEC) 646 standard.","With the foregoing information described in the block UIAppInfoBDAV( ), the reproduction restriction for the directory BDAV is prescribed. As will be described later, the reproduction restriction for each play list is prescribed with a flag playback_control_flag defined in the block UIAppInfoPlayList( ) described in the files \u201c#####.rpls\u201d and \u201c#####.vpls\u201d.","In the example, to resume reproducing a content placed under the directory BDAV, a resume function can be used. The resume function allows a play list of a content to be reproduced in priority to be designated. It is assumed that the resume function is used when the user wants to resume reproducing a content from the last stop position.","In , a flag resume_valid_flag describes whether the resume function is valid\/invalid. When the value of the flag has been set to \u201c0\u201d, the resume function is invalid. When the value of the flag has been set to \u201c1\u201d, the resume function is valid. At this point, a play list designated by a field resume_PlayList_file_name is treated as a play list to be reproduced in priority.","A field ref_to_menu_thumbnail_index is a region that describes a thumbnail number that identifies a thumbnail picture that typifies the directory BDAV. In the blu-ray disc standard, a still picture that typifies the directory BDAV is referred to as menu thumbnail. A thumbnail picture that has an index thumbnail_index described in the field ref_to_menu_thumbnail_index is the menu thumbnail of the directory BDAV.","A field BDAV_name_length describes the byte length of the name of the directory BDAV described in a field BDAV_name. The number of bytes described in the field BDAV_name_length is valid for the character string of the field BDAV_name that describes the name of the directory BDAV. The rest of the byte sequence after the valid character string described in the field BDAV_name_length may have any value.",{"@attributes":{"id":"p-0176","num":"0210"},"figref":"FIG. 12"},"As described above, the files \u201c#####.rpls\u201d and \u201c#####.vpls\u201d are placed under the directory PLAYLIST. These files correspond to individual play lists in the relation of one to one.",{"@attributes":{"id":"p-0178","num":"0212"},"figref":["FIG. 13","FIG. 13"]},"A block UIAppInfoPlayList( ) describes attribute information of the play list. A block PlayList( ) describes information about play items that compose the play list. A block PlayListMark( ) describes information about a mark added to the play list. A block MakersPrivateData( ) describes maker's unique information of the apparatus that has recorded the play list file. Fields PlayList_start_address, PlayListMark_start_address and MakersPrivateData_start_address are placed at the beginning of each of the files \u201c#####.rpls\u201d and \u201c#####.vpls\u201d. These fields describe the start addresses of the corresponding blocks as address information of 32 bits.","Since the start address of each block is described at the beginning of each of the files \u201c#####.rpls\u201d and \u201c#####.vpls\u201d, data padding_word of any length can be placed before each block and\/or after each block. However, the start position of the block UIAppInfoPlayList( ), which is the first block of each of the files \u201c#####.rpls\u201d and \u201c#####.vpls\u201d, is fixed at the 320-th byte from the beginning of each of these files.",{"@attributes":{"id":"p-0181","num":"0215"},"figref":"FIG. 14"},"A flag playback_control_flag describes whether or not display of information and reproduction of a play list are restricted in accordance with a personal identification number PIN. When the value of the flag playback_control_flag is for example \u201c1\u201d, unless the user inputs a correct personal identification number PIN, information such as a thumbnail picture of a play list cannot be displayed and the play list cannot be reproduced. A flag write_protect_flag is an erase prohibition flag. It is necessary to structure the user interface so that when the value of the flag write_protect_flag is \u201c1\u201d, the user cannot easily erase the play list. A flag is_played_flag describes that the play list has been reproduced. A flag is_edited_flag describes that the play list has been edited.","A field time_zone describes a tine zone of which the play list was recorded. A field record_time_and_date describes the date and time on and at which the play list was recorded. A field PlayList_duration describes the reproduction duration of the play list.","Fields maker_ID and maker_model_code describe information that identifies a maker and a model of the recording apparatus that last updated the play list. The fields maker_ID and maker_model_code are for example numbers. A field channel_number describes a channel number of a recorded clip AV stream. A field channel_name describes a channel name. A field channel_name length describes the length of the channel name described in the field channel_name. In the field channel_name, a character string having the length described in the field channel_name_length is valid. A field PlayList_name describes a play list name having an effective length of a value described in the field PlayList_name_length. A field PlayList_detail describes detailed information of the play list having an effective length of a value described in the field PlayList_detail_length.",{"@attributes":{"id":"p-0185","num":"0219"},"figref":"FIG. 15"},"A block PlayItem( ) describes information of a play item. A block SubPlayItem( ) describes information of a sub play item.",{"@attributes":{"id":"p-0187","num":"0221"},"figref":"FIG. 16"},"A field Clip_codec_identifier describes an encoding system of a clip that the play item references. In the example, the field Clip_codec_Identifier is fixed to a value \u201cM2TS\u201d. A field connection_condition describes information of how this play item is connected to the next play item. In other words, the field connection_condition describes whether or not play items can be seamlessly reproduced.","A field ref_to_STC_id describes a sequence STC_sequence of a clip that the play item references. The sequence STC_sequence is a unique structure of the blu-ray disc standard. The structure represents a range of which a program clock reference (PCR) that is a reference of an MPEG2 TS (Transport Stream) is continuous on the time base. A number STC_id that is unique in the clip is assigned to the sequence STC_sequence. In the sequence STC_sequence, since a continuous time base can be defined, the start time and end time of a play item can be uniquely designated. The start point and end point of each play item should exist in the same sequence STC_sequence. A field ref_to_STC_id describes a sequence STC_sequence with a number STC_id.","Fields IN_time and OUT_time describe time stamps pts (presentation_time_stamp) of the start point and end point of the play item in the sequence STC_sequence, respectively.","A block BridgeSequenceInfo( ) describes information about a bridge clip (Bridge_Clip). As shown in , a bridge clip is a bit stream that is created when a function for seamlessly reproducing play items is accomplished. By reproducing a bridge clip instead of an original bit stream at a boundary of the preceding play item and the current play item, the two play items can be seamlessly reproduced. Since the function of the bridge clip does not closely relate to the present invention, the description of the function will be omitted.",{"@attributes":{"id":"p-0192","num":"0226"},"figref":"FIG. 18"},"A field length describes the length of bytes immediately after the field length until the end of the block PlayListmark( ). A field number_of_PlayList_marks describes the number of marks in the play list. One loop of a \u201cfor\u201d statement represents information of one mark. A flag mark_invalid_flag describes whether or not the mark is valid. When the value of the flag mark_invalid_flag is \u201c0\u201d, it describes that the mark is valid. When the value of the flag mark_invalid_flag is \u201c1\u201d, it describes that although information of the mark exists in the database, the mark is an invalid mark that is transparent to the user.","A field mark_type describes the type of the mark. There are a mark that represents the position of a picture as a thumbnail picture (representative picture) of the play list, a resume mark that represents a position from which reproduction is resumed, a chapter mark that represents a search point, a skip mark that represents a region to be skipped and reproduced, a mark that represents read start timing of a graphics image, a mark that represents display start timing of a graphics image, a mark that represents display stop timing of a graphics image, and so forth.","A field mark_name_length describes a data length of a field mark_name (that will be described later). A field maker_ID describes a maker of a recording apparatus that created the mark. The field maker_ID is used to identify a mark unique to a maker. A field ref_to_PlayItem_id describes what play item has time designated by the mark. A field mark_time_stamp describes time designated by the mark.","A field entry_ES_PID describes to what elementary stream the mark was added (namely, whether the mark was added to a stream of which picture data and\/or sound data was encoded). A field ref_to_menu_thumbnail_index and a field ref_to_mark_thumbnail_index describe thumbnail pictures that visually represent marks. A thumbnail picture is for example a still picture that was extracted at time designated by the mark.","A field duration is used when a mark has a length on the time base. When a skip mark is used, the field duration describes for what duration the skip is performed.","A field makers_information is a region that describes information unique to the maker. A field mark_name is a region that describes a name that is assigned to a mark. The size of a mark is described in the field mark_name_length.",{"@attributes":{"id":"p-0199","num":"0233"},"figref":"FIG. 19"},"A block ClipInfo( ) describes information about a clip. A block SequenceInfo( ) describes information about an incontinuous point of PCR that represents a time reference of a transport stream of the MPEG2 system. A block ProgramInfo( ) describes information about a program of the MPEG2 system. A block CPI( ) describes information about characteristic point information CPI that represents a characteristic portion in an AV stream. A block ClipMark( ) describes mark information that represents a search index point added to a clip and commercial start and\/or end points. A block MakersPrivateData( ) describes information unique to a maker of a recording apparatus.","Address information that represents the beginning of each block in the file \u201c%%%%%.clpi\u201d is described as fields SequenceInfo_start_address, ProgramInfo_start_address, CPI_start_address, ClipMark_start_address, and MakersPrivateData_start_address. Since the function of the clip file \u201c%%%%%.clpi\u201d does not closely relate to the present invention, the description of the file will be omitted.","Since the BDAV format has the foregoing data structure, with a play list composed of play items that describe sets of start points and end points of portions to be reproduced in a clip AV stream, contents recorded on the disc can be managed in a reproduction unit that the user can recognize.","2. First Mode of Present Invention","Next, the first mode of the present invention will be described. According to the present invention, the foregoing BDAV format is extended. With moving picture data and subtitle data corresponding to the real time decoding system and picture data corresponding to stored type decoding system that are independently provided, these data are combined and displayed. As a result, a user interface having a higher flexibility than the related art can be accomplished.","In addition, the BDAV format is extended so that it can have compatibility with play lists prescribed in \u201cBlu-ray Disc Rewritable Format Ver 1.0 part 3\u201d. As a result, the extension of the interactive function is accomplished. Hereinafter, the extended BDAV format is referred to as BDMV format. The BDMV format is suitable for reproduction-only discs (blu-ray disc-read only memory: BD-ROM).","2-1. About Planes","According to the first mode of the present invention, a plane structure as shown in  is used. A moving picture plane  is displayed on the rearmost side (bottom). The moving picture plane  deals with a picture (mainly, moving picture data) designated by a play list. A subtitle plane  is displayed above the moving picture plane . The subtitle plane  deals with subtitle data displayed while a moving picture is being reproduced. A graphics plane  is displayed on the most front. The graphics plane  deals with character data for a menu screen and graphics data such as bit map data for buttons. One display screen is composed of these three planes.","The difference between the present invention and the conventional DVD video is in that sub pictures for subtitles, a menu screen, buttons, and so forth are separated into the subtitle plane  and the graphics plane  so that the subtitles and buttons are independently controlled. As described above, in the conventional DVD video, graphics such as a menu screen and buttons and subtitles are controlled by the same scheme. They are displayed on the same plane. The number of bit map pictures that can be displayed at the same time is limited to one. Thus, in the DVD video, a plurality of bit map pictures cannot be displayed at the same time. In contrast, according to the present invention, since the subtitle plane  and the graphics plane  are independently disposed for subtitles and graphics, respectively, the foregoing problem of the DVD can be solved.","It can be thought that the subtitle plane  and the graphics plane  are an extension portion of \u201cBlu-ray Disc Rewritable Format Ver 1.0 part 3\u201d.","The moving picture plane , the subtitle plane , and the graphics plane  can be independently displayed. The moving picture plane , the subtitle plane , and the graphics plane  have resolutions and display colors as shown in . The moving picture plane  has a resolution of 1920 pixels\u00d71080 lines, a data length of 16 bits per pixel, a color system of YCbCr (4:2:2), where Y represents a luminance signal and Cb and Cr represent color difference signals. YCbCr (4:2:2) is a color system having a luminance signal Y of eight bits per pixel and color difference signals Cb and Cr of eight bits each. With two horizontal pixels of the color difference signals Cb and Cr, data of one color data is composed.","The graphics plane  has a resolution of 1920 pixels\u00d71080 lines, a sampling depth of eight bits per pixel, and a color system that is selectable from YCbCr (4:4:4) and RGB (4:4:4) of which R (red): G (green): B (blue)=4:4:4). The subtitle plane  has a resolution of 1920 pixels\u00d71080 lines, a sampling depth of eight bits per pixel, and a color system having eight-bit color map addresses using a palette of 256 colors.","The graphics plane  and the subtitle plane  can be alpha-blended in 256 levels. When the graphics plane  and the subtitle plane  are combined with another plane, the intransparency can be set in 256 levels. The intransparency can be set for each pixel. In the following description, the intransparency \u03b1 is represented in the range of (0\u2266\u03b1\u22661) where intransparency \u03b1=0 represents perfect transparent; intransparency \u03b1=1 represents perfect intransparent.","The subtitle plane  deals with picture data of for example PNG (Portable Network Graphics) format. Likewise, the graphics plane  can deal with picture data of the PNG format. In the PNG format, the sampling depth of one pixel is in the range from one bit to 16 bits. When the sampling depth is eight bits or 16 bits, an alpha channel, namely intransparency information (referred to as alpha data) of each pixel component can be added. When the sampling depth is eight bits, intransparency can be designated in 256 levels. With the intransparency information of the alpha channel, alpha-blending is performed. A palette image of up to 256 colors can be used. An element (index) of the prepared palette can be represented with an index number.","In addition, picture data dealt with the subtitle plane  and the graphics plane  is not limited to the PNG format. Alternatively, picture data that has been compression-encoded in accordance with for example JPEG system, picture data that has been run-length-compressed, or bit map data that has not been compression-encoded may be used.",{"@attributes":{"id":"p-0213","num":"0247"},"figref":["FIG. 22","FIG. 20","FIG. 21"],"b":["10","20","20","21"]},"Picture data of the subtitle plane  is input to a palette . The palette  outputs picture data of RGB (4:4:4). When intransparency of alpha-blending has been designated for the picture data, designated intransparency \u03b11 (0\u2266\u03b11\u22661) is output from the palette .",{"@attributes":{"id":"p-0215","num":"0249"},"figref":"FIG. 23","b":["22","22","22","22"]},{"@attributes":{"id":"p-0216","num":"0250"},"figref":"FIG. 24","b":["22","22"]},"The RGB data that is output from the palette  is supplied to an RGB\/YCbCr converting circuit . The RGB\/YCbCr converting circuit  converts the RGB data into a luminance signal Y and color difference signals Cb and Cr of eight bits each (hereinafter, they together are referred to as YCbCr data). This is because data of planes should be combined in the common data format. Data is unified to YCbCr data that is the data format of moving picture data.","The YCbCr data and the intransparency data \u03b11 that are output from the RGB\/YCbCr converting circuit  are input to a multiplying device . The multiplying device  multiplies the input YCbCr data by the intransparency data \u03b11. The multiplied result is input to one input terminal of an adding device . The multiplying device  multiplies each of the luminance signal Y and the color difference signals Cb and Cr of the YCbCr data by the intransparency data \u03b11. A complement (1\u2212\u03b11) of the intransparency data \u03b11 is supplied to the multiplying device .","The multiplying device  multiplies the moving picture data that is input from the 422\/444 converting circuit  by the complement (1\u2212\u03b11) of the intransparency data \u03b11. The multiplied result is input to the other input terminal of the adding device . The adding device  adds the multiplied results of the multiplying device  and the multiplying device . As the result, the moving picture plane  and the subtitle plane  are combined. The added result of the adding device  is input to a multiplying device .","Picture data of the graphics plane  is input to an RGB\/YCbCr converting circuit . When the color system of picture data of the graphics plane  is RGB (4:4:4), it is converted into YCbCr (4:4:4) and output from an RGB\/YCbCr converting circuit . The YCbCr data that is output from the RGB\/YCbCr converting circuit  is input to a multiplying device .","Picture data used on the graphics plane  is of the PNG format, intransparency data \u03b12 (0\u2266\u03b12\u22661) can be set for each pixel of the picture data. The intransparency data \u03b12 is supplied to the multiplying device . The multiplying device  multiplies each of the luminance signal Y and the color difference signals Cb and Cr of the YCbCr data that is input from the RGB\/YCbCr converting circuit  by the intransparency data \u03b12. The multiplied result of the multiplying device  is input to one input terminal of an adding device . A complement (1\u2212\u03b12) of the intransparency data \u03b12 is supplied to the multiplying device .","The multiplying device  multiplies the added result of the adding device  by the complement (1\u2212\u03b12) of the intransparency data \u03b12. The multiplied result of the multiplying device  is input to the other input terminal of the adding device . The adding device  adds the multiplied results of the multiplying device  and the multiplying device . As a result, the graphics plane  and the combined result of the moving picture plane  and the subtitle plane  are combined.","When the intransparency \u03b1 of a non-picture region of the subtitle plane  and the graphics plane  is set to 0 (a=0), a plane below those planes  and  becomes transparent. As a result, for example, moving picture data on the moving picture plane  can be displayed as a background of the subtitle plane  and the graphics plane .","The structure shown in  can be accomplished by any one of hardware and software.","2-2. Menu Screen","A screen that prompts the user to perform an operation, for example, a menu screen, can be displayed on the graphics plane .  shows an example of a menu screen  displayed on the graphics plane . On the menu screen , characters and images are displayed at particular positions. With characters and images, the menu screen  provides the user with a graphical user interface (GUI) that allows him or her to select a new operation.","A \u201clink\u201d describes an access method to a predetermined file with a character string or image data. When the user designates the character string or image data on a screen with for example a pointing device, he or she can access the predetermined file in accordance with the access method designated with the character string or image data. A \u201cbutton\u201d has for example three types of image data that represent a normal state, a selection state, and a pressed state for a \u201clink\u201d. When the user designates one button image, the image data is changed in accordance with the state that he or she has operated so that he or she can easily recognize the current state of the button.","When the user designates a \u201clink\u201d or a \u201cbutton\u201d, he or she moves a cursor on the screen with for example a mouse and clicks a mouse button (presses the mouse button several times) on a character string or an image on the \u201clink\u201d or an image on a \u201cbutton\u201d. The same operation can be performed with another pointing device other than the mouse. Alternatively, with a remote control commander or a key operation of a keyboard, the user can designate a \u201clink\u201d or a \u201cbutton\u201d. At this point, the user selects his or her desired \u201clink\u201d or \u201cbutton\u201d with a predetermined key such as a direction key and designates the selected \u201clink\u201d or \u201cbutton\u201d with an OK key or the like.","In the example shown in , a title  as image data is displayed at an upper portion of the menu screen  that is displayed on the graphics plane . The title  is followed by selection items A, B, C, and D as links. When the user selects and designates one of the selection items A, B, C, and D with a key operation of for example the remote control commander, a file linked to the designated selection item is accessed.","AT lower positions of the menu screen , buttons  and  are displayed. With the buttons  and , subtitles can be displayed and a language of output sound can be selected from for example English and Japanese. When the buttons  and  are operated in the foregoing manner, files used to display their setup screens are accessed and the predetermined screens are displayed.","In addition, at a lower left portion of the menu screen , a character string  that describes a method for selecting an item is displayed. The character string  is displayed on the graphics plane .","To display for example a screen shown in , any descriptive language for describing a screen display method, link information, and so forth is required. According to the first mode of the present invention, as the descriptive language, hyper text markup language (HTML), which has been widespread in the world wide web (WWW) on the Internet, is used.","As well known, an HTML document describes a document structure with tags. A tag is composed of one pair of symbols that represent the beginning and end of a range. A tag is embedded in a text so as to designate any range. For example, a start tag that represents the beginning of a range is described by surrounding an element defined as a character string with symbols \u201c<\u201d and \u201c>\u201d. Likewise, an end tag that represents the end of a range is described by surrounding the same character string described in that start tag with symbols \u201c<\/\u201d and \u201c>\u201d. An attribute of an element represented by a tag can be described therein. The end tag can be omitted. In addition, some elements do not need to describe their end tags.","A document described in the HTML is placed in a web server connected to the Internet and published by the web server to the Internet. The document is browsed by browser software installed in a computer apparatus such as a personal computer connected to the Internet. According to the first mode of the present invention, the HTML's standard is originally extended so that a menu screen for the blu-ray disc can be displayed.","For example, on the WWW, with link information described in an HTML document, browser software can link and read another HTML file designated by the link information. On the other hand, it is expected that on the menu screen  for the blu-ray disc, a table of play lists is displayed with image data, character strings, buttons, and so forth. In addition, it is expected that by designating a play list, the designated play list is read and reproduced from the disc.","This extension to the HTML is equivalent to for example a new function that is defined in a programming language or a new application programming interface (API) that is defined.","2-3. About Scenarios","In the example shown in , a table of play lists is displayed on the menu screen . In reality, images and sound of the menu screen  and those that are generated in accordance with an item selected on the menu screen  are composed of a plurality of play lists. When a plurality of play lists that compose one menu item are correlated, a scheme of which a story is branched can be accomplished. When a story is branched, a multiple story function that causes the contents of the story to vary in accordance with the user's selection and a parental function that causes scenes to be changed in accordance with the age of the user can be accomplished.","Although those functions are especially effective for recoded discs, but they are not prescribed in the current blu-ray disc standard, which mainly aims to record\/reproduce television broadcasts.","Information displayed on the screen may be described in accordance with not only the HTML, but for example XHTML (extensible HTML), which is a later version of HTML 4.0. In addition, information on the screen can be described with another markup language.","In the following description, the structure of which a plurality of play lists are arranged is referred to as scenario.  shows an example of an internal structure of a scenario . The scenario  has a plurality of play lists A to M. In addition, the scenario  has two portions (screens A and B) on which branch selection screens are displayed with the graphics plane . For example, the screen A has graphics data A and a play list C with which a branch selection screen is displayed. Likewise, the screen B has a graphics data B and a play list J with which a branch selection screen is displayed.","A scenario designates both an arrangement of play lists and display timing at which they are displayed on the graphics plane . The display timing of the play lists on the graphics plane  can be designated with marks on the play lists. Definitions of event handles  and  in the scenario  will be described later.","In the example shown in , a selection item on the menu screen  (for example, the selection item A) corresponds to the play list A represented by \u201centry\u201d in the scenario . In other words, when the selection item A is designated on the menu screen , the play list A of the scenario  is reproduced. After the play list A has been completely reproduced, the play list B is successively reproduced. After the play list B has been completely reproduced, the play list C is reproduced. Thereafter, the graphics data A is read. As a result, the screen A that prompts the user to select a story is displayed.","After the screen A is displayed, the story is branched in accordance with a user's selection. In the example shown in , when a first selection is performed, the screen A is displayed. Thereafter, the play lists D, E, and F are reproduced in succession. As a result, the reproduction of the scenario  is completed. After the play list F has been completely reproduced, the main menu screen (for example, the menu screen ) may be displayed again.","When a second selection is performed on the screen A, after the screen A is displayed, the play list G is reproduced. A mark is set in the play list G for example at predetermined timing. When the play list B is reproduced, the play list G may be branched at the position of the mark or fully reproduced in accordance with the setting of the reproducing apparatus, user's another scenario, or a selection on the branch selection screen. When all the play list G is reproduced, after the play list G is reproduced, the play lists M and I are reproduced in succession. Thereafter, the play list J is reproduced.","When the play list G is branched at the position of the mark, the play lists K and L are reproduced in succession. After the play list L has been completely reproduced, the reproduction is resumed from the position of the mark that has been set in the play list I.","In the play list J, the graphics data B is read. The screen B that prompts the user to select a branch of the story is displayed. In the first selection on the screen B, the play list F is reproduced. In the second selection of the screen B, the play list K is reproduced from the position of the mark that has been set in the play list K.","A mark, a user's input, and an operation change of the player are detected in accordance with an event driven model. In other words, when reproduction of a play list is started, reproduction of a play list is completed, a mark is detected while a play list is being reproduced, or a user inputs data by a key operation of the remote control commander, an event takes place. When a program has an event handler that is executed upon occurrence of an event, an operation expected for the event is executed by the player.","The scenario  shown in  has two event handlers  and . In these, the event handler  is a global event handler that describes an event handler that is effective all the scenario .","Even if any of the play lists A to M of the scenario  is being reproduced, when a menu button of the remote control commander is pressed, the menu screen  for a table of scenarios is displayed. In other words, an operation that performs a reproducing process for a play list for the menu screen  will be described. In this case, as an event handler that corresponds to an event that takes place when the menu button of the remote control commander is pressed (menu button press event), a command that causes a play list for the menu screen  to be reproduced is described as the global event handler .","The event handler  is a local event handler that is executed only while a predetermined play list is being reproduced or a predetermined user input screen is being displayed. For example, when the user designates a link displayed on the screen A as a branch selection screen, an operation for reproducing another play list is accomplished by describing a command that causes the play list to be reproduced against an event of which the link is designated as a local event handler.","In the first mode of the present invention, as a script language that defines the foregoing event handler, ECMA script is used. The ECMA script is a cross-platform script language in accordance with JavaScript (registered trademark). The ECMA script is prescribed by European Computer Manufacturers Association (ECMA). The ECMA script has a high affinity with an HTML document and allows a unique object to be defined. Thus, the ECMA script is suitable for the first mode of the present invention.","2-4. About Virtual Player Model","Next, a model of a reproducing apparatus that is provided with the graphics plane  and that operates in the BDAV format extended with the HTML and ECMA script will be considered. The modeled reproducing apparatus is referred to as BD (blu-ray disc) virtual player. The definition of the structure of the BD virtual player is referred to as BD virtual player model.","Next, with reference to , the BD virtual player model will be described. The BD virtual player  reproduces data from the blu-ray disc (hereinafter referred to as disc). The BD virtual player  is an object in a computer environment such as a personal computer. The computer environment is not limited to a general-purpose personal computer. Instead, the computer environment includes a software environment installed in a dedicated reproducing apparatus and\/or recording and reproducing apparatus that reproduces data from for example the blu-ray disc or the like.","The BD virtual player  roughly has two states A and B. In the state A, the BD virtual player  reproduces a play list and graphics. In the state B, the BD virtual player  stops reproducing a play list and graphics. A state change from one state to another state and a designation of the next operation in one state are performed by commands to an object of the BD virtual player .","The state A has a plurality of operations. As operations in the state A, there would be a high speed reproduction, a variable speed reproduction such as a reverse reproduction, and a special reproduction such as a jumping reproduction that starts from any time of a disc. When data of the graphics plane  is displayed, the variable speed reproduction and the special reproduction of the BD virtual player  would be restricted.","A play back control (PBC) program  corresponds to a scenario recorded on the disc. As will be described later, a scenario describes a reproducing method for a play list recorded on the disc and a displaying method for a menu screen. The PBC program  and the BD virtual player  exchange methods through an application programming interface (API)  so as to reproduce a play list recorded on the disc.","In more reality, when the state of the BD virtual player  changes, the PBC program  causes necessary information to be transferred to common parameters  defined as a dedicated memory of the BD virtual player  through the API . Values of the common parameters  are set directly with player commands  as methods exchanged between the PBC program  and the BD virtual player  through the API .","According to the first mode of the present invention, as described above, the BD virtual player  is controlled under an event driven model. While the BD virtual player  is operating, various events take place. Events are generated by hardware\/OS (Operating System)  for example when the user performs a key input or operates the remote control commander or a timer interrupt takes place. The events are sent to the BD virtual player . Alternatively, events may be generated when a mark is detected in a reproduced play list. Furthermore, events may be generated by the BD virtual player  itself for example the state of which the operation of the player is changed is detected. Events are processed with a concept of event bubbles.","The types of events that take place are defined in the BD virtual player model. When an event takes place, if an event handler as a script program has been described, the event handler is executed. If an event handler has not been described, a default event handler is executed and an operation prescribed in the standard for the player is executed.","When a method for a player operation is executed, the result of whether or not the player operation has been normally started is represented with a return value against the method. On the other hand, the end time at which a command was completed can be obtained with only the fact of which an event took place. Thus, when a method that starts reproducing the end of a scenario is described in a script program, it is preferred that the method should be described along with an event handler that receives an event representing the end of the scenario and that executes it.","An event handler can be different in each scenario for the same event.","Interrupt events of the BD virtual player  are roughly categorized as (1) an event that takes place in a content that is being reproduced, (2) an event that takes place with an interrupt by the user, and (3) an event that takes place due to a state change of the player.","The event (1), which takes place in a content that is being reproduced, is a predetermined interrupt. Whenever the content is reproduced, the event (1) takes place at the same timing. While the BD virtual player  is reproducing a play list, when time designated by a mark described in the play list has elapsed on the disc, a mark detection interrupt takes place in the BD virtual player . When a timer is designated by a script, a timer interrupt event takes place at the designated time or 10 seconds after the timer setup time designated by the script.","The event (2), which is a user's interrupt, is an event whose occurrence and occurrence timing cannot be predicted. When the user operates a key of the remote control commander, the interrupt event takes place. In this case, since it is uncertain when the user performs a key operation, the timing cannot be obtained in advance.","The event (3), which takes place due to a state change of the BD virtual player , is an event that causes a change of a stream of sound or subtitles to be informed. This event takes place when the state of the player changes from the reproduction state to the stop state or vice versa for a content. An event due to the state change of the player may take place in association with the event (1), which takes place in a content that is being reproduced, or the event (2), which takes place due to a user's interrupt event. As an example of an event that causes a change of a stream of sound or subtitles to be informed, when an interrupt event of a user's key operation of the remote control commander takes place, a stream of sound or subtitles is changed. As a result, since the state of the BD virtual player  changes, the event that causes the state change to be informed takes place.","In the first mode of the present invention, the display control using the graphics plane  is described as an HTML (Hyper Text Markup Language) 4.01 document or an XHTML (extensible HTML) document. As events for a display screen of the graphics plane , HTML 4.0 build-in events are used. If events other than the HTML 4.0 built-in events are required, they can be described using the ECMA script.","When the HTML format and the ECMA script are used in combination, if an event takes place, a process that is performed depends on whether an event handler designated with an attribute of an element of the event exists in the document. When an event handler exists, it is executed. When an event handler does not exist, it is determined whether or not a global event handler exists in the document. As a result, if a global event handler exists in the document, the event handler is executed. When the document does not describe an event handler in the script language, the BD virtual player  performs a default event process prepared for the event.","An event handler can be described as an attribute of an element of an HTML document or a method captureEvents of the ECMA script.","Next, the method for describing an event handler using an HTML document will be described. For example, an event onload, an event onunload, an event onclick, and an event onkeypress of built-in events prescribed in the HTML 4.0 can be used. Each of these events is described as an attribute in an element of a tag.","The event onload takes place when the user agent ends one window or all frames defined with a pair of tags <FRAMESET> <\/FRAMESET>. When a menu screen is displayed, the event onload takes place.","A window is a unit in which a browser application displays an HTML file in accordance with the prescription of the HTML. A frame is used to display a plurality of HTML files on divided regions of one window. HTML files in a frame and a frame itself are referred to as frame. The event onload attribute can be used with the element BODY and the element FRAMESET.","The event onunload takes place when the user agent removes one HTML document from one window or one frame. The event onunload attribute can be used with the element BODY and the element FRAMESET.","The event onclick takes place when an element is pointed with the pointing device or the like. For example, when a click operation of a mouse button is performed, the event onclick takes place. The event onclick attribute can be used with almost any element of the HTML 4.0.","The event onkeypress takes place when a key is pressed or released on or from an element. For example, when a predetermined key is pressed on the keyboard or a key of the remote control commander is pressed in a region defined with a particular element on the screen and placed in the selection state, the event onkeypress takes place. The event onkeypress attribute can be used with almost any element of the HTML 4.0.","Since the operation of the BD virtual player  cannot be sufficiently controlled with events of the foregoing HTML, in the first mode of the present invention, it is necessary to define original events.  shows examples of original events defined in the BD virtual player . The events are described in an HTML document using the ECMA script. As an attribute name that designates an event handler, \u201con\u201d is added to the beginning of an event name.","An event TimerFired takes place when the value of a countdown timer becomes \u201c0\u201d or when the value of a count up timer becomes a predetermined value. An event PlayStopped and an event PlayStilled take place when reproduction is stopped or paused. An event StillReleased takes place when the pause state is released. An event PlayPaused and an event PauseReleased take place when the user temporarily stops the reproduction and when the user releases the pause state of the reproduction. An event PlayStarted takes place when the reproduction is started. An event PlayRepeated takes place when the beginning of a region to be repeatedly reproduced is detected.","An event SPDisplayStatusChanged takes place when the display\/non-display state of a sub picture (subtitle) stream is changed. An event SelectedAudioChanged and an event VideoStopped take place when an audio stream and a video stream to be reproduced is changed, respectively.","An event ScenarioStarted and an event ScenarioEnded take place when the beginning and end of a scenario are detected, respectively. An event PlayListStarted and an event PlayListEnded take place when the beginning and end of a play list are detected, respectively. An event PlayItemStarted and an event PlayItemEnded take place when the beginning and end of a play item are detected, respectively.","An event MarkEncountered takes place when a mark is detected while a play list is being reproduced. This event is used when image data is displayed on for example the graphics plane . The type and number of a detected mark are described in the common parameters .","An event ButtonPressed takes place when a button placed on a screen is pressed. For example, when a button placed on the graphics plane  is virtually pressed by a key operation or a click operation of the mouse, the event ButtonPressed takes place.","An event ValidPeriodStarted takes place when a valid period starts. This event can be used when a valid period for which a link can be selected is designated. An event ValidPeriodEnded takes place when the valid period ended. This event can be used when a link is forcedly executed.","An event KeyPressed takes place when a key of the remote control commander is pressed. The type of a pressed key is identified with a \u201cswitch\u201d statement or the like of an event handler.","2-5. About Methods",{"@attributes":{"id":"p-0282","num":"0316"},"figref":["FIG. 29A","FIG. 29B","FIG. 30A","FIG. 30B","FIG. 30C","FIG. 30D","FIG. 31A","FIG. 31B","FIG. 31C","FIG. 31D"],"b":["30","30","11","32","12"]},"When these methods are used in a PBC program, the operations of the BD virtual player  can be controlled. These methods are built in the API  shown in . These methods are called in accordance with the description of the PBC program  through the API . The reproduction for the disc of the BD virtual player  is controlled in accordance with these methods. A real example of the PBC program  will be described later.","Next, methods for player operations will be described. A method playscenario (scenarioNumber, [scenarioTime]) causes a scenario designated by \u201cscenarioNumber\u201d to be reproduced. \u201cscenarioNumber\u201d is a URI (Universal Resource Identifier) that represents the location of a file that describes a scenario structure. A method playPlayList (playListNumber) causes a play list designated by \u201cplayListNumber\u201d to be reproduced. A method playChapterMark (playListNumber, chapterNumber) causes a play list designated by \u201cplayListNumber\u201d to be reproduced from a chapter designated by \u201cchapterNumber\u201d. A method playPlayItem (playListNumber, playItemNumber) causes a play list designated by \u201cplayListNumber\u201d from a play item designated by \u201cplayItemNumber\u201d. \u201cplayItemNumber\u201d is \u201cplayItem_id\u201d. When a value \u201c0\u201d is designated to \u201cplayItem_id\u201d, a play list to which the play item belongs is reproduced from the beginning.","A method play (position) (object) causes the current position to be moved to an adjacent play list or play item. A parameter \u201cposition\u201d is any one of \u201cprev\u201d, \u201cnext\u201d, \u201ctop\u201d, \u201cgoUp\u201d, and \u201ctail\u201d. A parameter \u201cobject\u201d describes a moving method to a moving object (a play list, a play item, or a chapter).","A method stop( ) causes the reproduction of a scenario to be stopped. In this case, the value of the standard register is not held. A method resume( ) causes the reproduction to be resumed from the last stop position. A method playSoundEffect( ) causes a selected effect sound to be reproduced.","Next, methods for player states will be described. In , ,  and , a method getMenuDescriptionLanguage( ) causes a language of a menu that is displayed to be obtained. A method getScenarioNumber( ), a method getPlayListNumber( ), and a method getChapterNumber( ) cause a scenario number, a play list number, and a chapter number that are being reproduced to be obtained, respectively.","Next, methods for video streams will be described. A method setVideoStreamNumber( ) describes a video stream to be decoded. A method getVideoStreamNumber( ), a method getVideoStreamStatus( ), and a method getVideoStreamAttr( ) cause a video stream number, a state, and an attribute of a video stream that is being reproduced to be obtained, respectively. Attributes of a video stream are for example an encoding system, a resolution, an aspect ratio, a display mode in the case that the aspect ratio is 4:3, and presence\/absence of a closed caption. A method setAngleNumber( ) describes an angle number. A method getAngleNumber( ) causes an angle number that has been selected to be obtained. A method getMaxVideoStream( ) causes a maximum number of video streams to be obtained.","Next, methods for audio streams will be described. A method getAudioStreamAvailability( ) causes information that describes whether or not a designated audio stream is contained to be obtained. A method getAudioStreamLanguage( ) causes information about a language of a designated audio stream to be obtained. A method setAudioStreamStatus( ) causes a state of a designated audio stream to be obtained. A method setAudioStreamStatus( ) causes a state of a designated audio stream to be designated. States of an audio stream are for example whether or not it is reproduced. A method getAudioStreamAttribute( ) causes an attribute of a designated audio stream to be obtained.","Next, methods for sub picture streams (subtitle data) will be described. A method getSPStreamAvailability( ) causes information that describes whether or not a designated sub picture stream is contained to be obtained. A method getSPStreamLanguage( ) causes a language used in a designated sub picture stream to be obtained. A method getSPDisplayStatus( ) causes a display state of a sub picture stream to be obtained. A method setSPDisplayStatus( ) describes a display state of a sub picture stream. Display states of a sub picture stream are for example whether or not the sub picture stream is displayed. A method getSpStreamAttribute( ) causes an attribute of a designated sub picture stream to be obtained. Attributes of a sub picture stream are for example whether the sub picture stream is displayed with an aspect ratio of 4:3 or with a wide screen.","Next, methods for the common parameters  will be described. In , ,  and , methods for the common parameters  are represented as methods for register read\/write. A method clearReg( ) causes all registers of a memory region of the BD virtual player  to be initialized. A method setReg( ) causes a value to be set to a designated register. A method getReg( ) causes a value to be read from a designated register.","Next, methods for timers will be described. A method sleep( ) causes a process to be stopped at designated time. A method setTimeout( ) causes a function or a process to be executed after designated time has elapsed. A method setInterval( ) causes a process to be executed at intervals of designated time. Methods for timers can be designated in the unit of a millisecond. A method clearTimer( ) causes a process that has a designated registration timer to be stopped. A method pauseTimer( ) causes a timer that has a designated registration ID to be temporarily stopped. A method resumeTimer( ) causes a timer that has a designated registration timer ID to be resumed from the pause state.","As a method for a key input, a method getPressedKey( ) causes the type of a key that has been input (pressed) to be obtained.","Next, methods for graphics will be described. A method loadGraphics (htmlfile, ID) causes a file designated by \u201chtmlfile\u201d to be read and the file to be expanded to the graphics plane  in a non-display state. An \u201cID\u201d is assigned to an expanded graphics image and referenced with a method that will be described later. A method showGraphics (ID) causes an image expanded on the graphics plane  by the foregoing method load Graphics (htmlfile, ID) to be displayed. A method hideGraphics (ID) causes an image designated by \u201cID\u201d to be hidden.","Next, other methods will be described. A method random (input Number num) causes a random number from 1 to \u201cnum\u201d to be generated. Random numbers are generated by a unique definition. A method catchEvent (eventname, eventhandler) causes a function designated by \u201ceventhandler\u201d to be executed when an event designated by \u201ceventname\u201d takes place.","2-6. About Execution of Commands","Next, a PBC program  will be practically described. In the first mode of the present invention, one script file is created for one scenario. When the menu screen  is displayed on the graphics plane , one HTML file is created for one screen. A script file and an HTML file have extensions \u201cjs\u201d and \u201chtml\u201d, respectively. These extensions distinguish these two types of files. A file of a script program that is initially executed when a disc is loaded into a drive device has a fixed file name for example \u201cstartup.js\u201d.","Next, as an example, a disc having a scenario structure shown in  will be considered. This disc has two scenarios Scenario and Scenario. The scenario Scenario causes a menu screen  that has a link button to the scenario Scenario to be displayed. When the disc is loaded into the reproducing apparatus, the menu screen  is displayed. When a button  on the menu screen  is clicked, the scenario Scenario is reproduced. After the scenario Scenario has been reproduced, the menu screen  is displayed again.",{"@attributes":{"id":"p-0298","num":"0332"},"figref":["FIG. 33","FIG. 32"],"b":["000","001"]},"Among those files, the file \u201cscenario.js\u201d is a script file that describes structural information of the scenario Scenario. The file \u201cscenario.js\u201d describes structural information of the menu screen , namely a scenario list screen. The file \u201c000.html\u201d is an HTML file that describes layout information of the menu screen . The file \u201c00000.rpls\u201d is a play list file that is displayed as a background of the menu screen . The file \u201cscenario.js\u201d is a script file that describes structural information of the scenario Scenario. The file \u201c00001.rpls\u201d is a play list file that describes information of a play list reproduced in accordance with the scenario Scenario.","In , contents files (a clip information file \u201c%%%%%.clip\u201d and an AV stream file \u201c*****.m2ts\u201d) that are reproduced in accordance with the play list files \u201c00000.rpls\u201d and \u201c00001.rpls\u201d are omitted.","Each file shown in  is recorded on a disc in accordance with a directory structure as shown in .",{"@attributes":{"id":"p-0302","num":"0336"},"figref":["FIG. 35 to 38","FIG. 35"],"b":["000","000","000","000","91"]},{"@attributes":{"id":"p-0303","num":"0337"},"figref":["FIG. 36","FIG. 28","FIG. 36"],"b":["000","91","91","12"]},"In other words, the file \u201cscenario.js\u201d causes a moving picture of the play list \u201c00000.rpls\u201d to be displayed on the moving picture plane . In addition, the file \u201cscenario.js\u201d causes the menu screen  to be displayed on the graphics plane  at timing of a mark detected while the play list \u201c00000.rpls\u201d is being reproduced.",{"@attributes":{"id":"p-0305","num":"0339"},"figref":["FIG. 37","FIG. 37"],"b":["91","000"]},"In a portion surrounded by tags <script type=\u201ctext\/javascript\u201d> and <\/script>, event handlers for mouse operations onMoverhandler (f), onMounthandler (f), and onMclickhandler (f) are defined. In the example shown in , image data \u201c201.png\u201d, \u201c200.png\u201d, and \u201c202.png\u201d as button images are correlated with the event handlers onMovehandler (f) onMouthandler (f), and onMclickhandler (f). In addition, the event handler onMclickhandler (f) causes the scenario file \u201cscenario.js\u201d to be reproduced.","In a portion surrounded by tags <body> and <\/body>, image data displayed on the graphics plane  of the menu screen  is described. File names (\u201c100.png\u201d and \u201c200.png\u201d) of image data corresponding to image names described in the portion surrounded by the tags <style type=\u201ctext\/css\u201d> and <\/style> are described. When events onMouseover, onMouseout, and onclick take place for the image data referenced by the image name \u201cscenario\u201d in accordance with an operation of a pointing device such as a mouse, event handlers onMoverhandler (f), onMouthandler (f), and onMclinckhandler (f) are executed, respectively.","The event onMouseover is an event that takes place when the cursor is placed at a designated region. The event onMouseout is an event that takes place when the cursor is left from a designated region. The event onclick is an event that takes place when a predetermined operation for example a clicking operation of the pointing device for example the mouse is performed while the cursor is placed in a designated region.",{"@attributes":{"id":"p-0309","num":"0343"},"figref":"FIG. 38","b":["001","001","000","91","001","000","91","001","00001"]},"Next, operations shown in  to  will be described. When the disc is loaded into the reproducing apparatus, the file \u201cstartup.js\u201d is read from the disc. The file \u201cscenario.js\u201d is called from the file \u201cstartup.js\u201d. When the scenario \u201cscenario\u201d described in the file \u201cscenario.js\u201d is executed, a moving picture of the play list \u201c00000.rpls\u201d is displayed on the moving picture plane  in accordance with the description shown in .","The file \u201c000.html\u201d is called at timing corresponding to a mark described in the play list \u201c00000.rpls\u201d. The menu screen  that displays a table of scenarios is expanded on the graphics plane  and displayed in accordance with the description of the file \u201c000.html\u201d. The menu screen  is also composed of one scenario, which is the scenario \u201cscenario\u201d.","On the menu screen , the image file \u201c100.png\u201d of a character string for example \u201cMenu\u201d and the image file \u201c200.png\u201d of a character string for example \u201cScenario\u201d are placed. These image files are placed on the graphics plane  and these character strings are displayed. On the moving picture plane  displayed as a background of the graphics plane , a moving picture of the play list \u201c00000.rpls\u201d is displayed. The moving picture of the play list \u201c00000.rpls\u201d on the moving picture plane  and the menu screen  of the file \u201c000.html\u201d on the graphics plane  are superimposed and displayed on the same screen. As a result, the menu screen  is displayed with a background of the moving picture.","At this point, predetermined intransparency is designated to a screen (the menu screen ) on the graphics plane . The menu screen  can be transparently displayed on the moving picture on the moving picture plane . In this example, marks are described at the beginning and the end of the play list \u201c00000.rpls\u201d. When the play list \u201c00000.rpls\u201d is reproduced, the menu screen  is displayed. After the play list \u201c00000.rpls\u201d has been reproduced, the menu screen  is cleared.","On the menu screen , a cursor that can be moved by user's key operations of the remote controller is displayed. When the cursor is superimposed with the image file \u201c200.png\u201d, the event Mouseover defined in the file \u201c000.html\u201d takes place. When the event Mouseover takes place, the event handler onMovehandler( ) corresponding to the event onMouseover is executed so as to represent the state that the image file \u201c200.pn\u201d is focused. When the event handler onMoverhandler( ) is executed, the image file \u201c200.png\u201d is replaced with the image file \u201c201.png\u201d. The image file \u201c201.png\u201d is a button image or the like whose color is different from the image file \u201c200.png\u201d.","When the cursor is placed on the image file \u201c201.png\u201d, if the user performs a clocking operation by a predetermined key of the remote control commander, the event handler onMclickhandler( ) corresponding to the event onclick is executed. As a result, the image file \u201c201.png\u201d is replaced with the image file \u201c202.png\u201d that represents the state that the image file \u201c201.png\u201d has been selected. The image file \u201c202.png\u201d is a button image that virtually represents the state that a button was pressed.","When event handlers corresponding to events \u201cfocused\u201d and \u201cclicked\u201d are described in the file \u201c000.html\u201d, a menu screen that has an interactive function that responds to a user's input is accomplished.","When a button image of \u201cScenario\u201d is clicked on the menu screen , a reproducing process for the scenario \u201cScenario\u201d is performed. When the file \u201cscenario.js\u201d is executed, the scenario \u201cScenario\u201d is reproduced. As shown in , a method playPlayList (\u201c0001.rpls\u201d) described in the file \u201cscenario.js\u201d is called. As a result, the play list \u201c00001.rpls\u201d is reproduced.","After the play list \u201c00001.rpls\u201d has been reproduced, a play list reproduction end event PlayListEnded( ) takes place. The event handler playScenario (\u201cscenario.js\u201d) corresponding to the event causes the scenario \u201cScenari.js\u201d to be reproduced. In this example, after the scenario \u201cScenario\u201d has been reproduced, the menu screen  is displayed again.","While the scenario \u201cScenario\u201d is being reproduced, even if a key designated by \u201ckeyID\u201d is operated, the scenario \u201cScenario.js\u201d is reproduced and the menu screen  is displayed.","The descriptions of the HTML and ECMA scripts shown in  to  are just examples. In other words, the present invention is not limited to such examples. The HTML and ECMA scripts have flexibility in their descriptions. Thus, even if the HTML and ECMA scripts are partly changed, similar operations can be accomplished.","2-7. Decoder Model",{"@attributes":{"id":"p-0321","num":"0355"},"figref":"FIG. 39","b":["100","100"]},"All operations of the player decoder  are controlled by a CPU (Central Processing Unit) (not shown). Streams and data flows of individual portions of the player decoder  are monitored and controlled by the CPU.","When the disc is loaded into the drive device (not shown), as described above, a file \u201cstartup.js\u201d is reproduced. In accordance with the description of the file \u201cstartup.js\u201d, a scenario file is read. In according with the description of the scenario file, an HTML file, moving picture data displayed on the moving picture plane , image data displayed on the subtitle plane  and the graphics plane , another scenario file that is called from the foregoing scenario file, and sound data are read from the disc.","In the following description, among those data that is read from the disc, streams such as moving picture data, sub pictures (subtitle data), and sound data that should be continuously processed are referred to as real time streams. In contrast, non-real time data such as a scenario file, an HTML file, an image data file, and a play list file that do not need to be continuously processed are referred to as store objects. The store objects are stored in a memory or the like and expanded thereon. When necessary, the store objects are processed.","The player decoder  has two systems of input channels that are channel () and channel (). A store object is input to an input terminal  of the input channel (). A real time stream is input to an input terminal  of the input channel (). Alternatively, a store object may be input to the input terminal . According to the first mode of the present invention, a real time stream and a part of store objects that are input to the input terminal  are for example MPEG2 TSs.","A real time stream that is input to the input terminal  is not limited to an MPEG2 TS. As long as a real time stream can be transmitted in the unit of a packet and multiplexed with video data, audio data, still picture data, or the like, a stream that has another format can be input. At this point, a PID filter  that will be described later is used as a demultiplexer that demultiplexes video data, audio data, still picture data, or the like.","When the rotation speed of the disc in the drive device is increased for example twice and the read transfer speed of the disc is increased, the reading operations for two systems of the channels () and () drive device from the disc are performed in time division basis.","First of all, the system of the input channel () will be described. A store object that is input to the input terminal  is input to a switch circuit . When a program code of an ECMA script, an HTML file, or the like as a store object is input, the switch circuit  selects an output terminal A. The input program code is stored in a code buffer .","When image data as a store object is input, the switch circuit  selects an output terminal B. As a result, the input image data is input to a switch circuit . When a real time stream that is input to the input terminal  does not contain image data displayed on the subtitle plane  or the graphics plane , the switch circuit  selects an input terminal A. The image data that is input from the switch circuit  is stored in a contents buffer .","Likewise, when image data displayed on the subtitle plane  or the graphics plane  is contained in a real time stream that is input to the input terminal , the switch circuit  selects an input terminal B. As a result, the image data is stored in the contents buffer . Store objects stored in the code buffer  and the contents buffer  are read when necessary and supplied to a multimedia engine .","The image data of the store object stored in the contents buffer  is also supplied to a sub picture decoder  and a still picture decoder  through switch circuits  and , respectively.","The multimedia engine  comprises an XML parser A, a script interpreter B, and a graphic renderer C. The multimedia engine  may be composed of independent hardware. Alternatively, the multimedia engine  may be accomplished by a process of a predetermined program that a CPU (not shown) executes.","The XML parser A has a function for parsing an XML (Extensible Markup Language) document. In addition, the XML parser A can also parse an HTML document. An HTML document parsed by the XML parser A is converted into a format that can be executed by the player decoder . The script interpreter B analyzes an ECMA script and converts it into a format that can be executed by the player decoder . The graphic renderer C decodes image data and obtains a format that can be expanded on the subtitle plane  and the graphics plane .","The multimedia engine  performs processes for the XML parser A, the script interpreter B, and the graphic renderer C with a work memory of a buffer . For example, the XML parser A and the script interpreter B uses a code buffer of the buffer . The graphic renderer C uses a graphics buffer D of the buffer . The buffer  further comprises a font buffer B that stores font data used to display a character string and a tree buffer C that stores the parsed result of the HTML document by the XML parser A in a hierarchical tree structure.","The multimedia engine  reads for example an ECMA script from the code buffer . When necessary, in accordance with the description of the ECMA script, the multimedia engine  reads another ECMA script and an HTML document from the code buffer  and reads image data from the contents buffer . Data that is stored in the code buffer  and the contents buffer  can be stored in the code buffer  and the contents buffer  until the data becomes unnecessary. Thus, data stored in the code buffer  and the contents buffer  can be repeatedly read when necessary.","In addition, the multimedia engine  performs a demultiplexing process for the plurality of types of input data, a JavaVM (Java (registered trademark) virtual machine) function, and so forth. Moreover, the multimedia engine  receives a user's input from a remote control commander, a pointing device, or the like and performs a process in accordance with the user's input. The user's input is supplied to the sub picture decoder , the still picture decoder , an audio decoder , an MPEG video decoder , and a system decoder  that will be described later.","Image data processed by the graphic renderer C is supplied to a sub picture plane  and a still picture plane  through switch circuits  and , respectively. In addition, the image data is supplied to the graphics plane  and the M\/S switch plane . In this example, it is assumed that image data supplied to the sub picture plane  and the graphics plane  has the PNG format. Timing at which the image data is supplied to the planes , , , and  is controlled by the multimedia engine . The M\/S switch plane  controls the switch circuit . The switch circuit  selects one of still picture data that is output from the still picture plane  (that will be described later) and moving picture data that is output from the moving picture plane  and supplies the selected data to the downstream stage.","The sub picture plane  and the graphics plane  correspond to the foregoing subtitle plane  and graphics plane , respectively. The still picture plane  and\/or moving picture plane  corresponds to the foregoing moving picture plane . Each of the sub picture plane , the graphics plane , the still picture plane , and the moving picture plane  is composed of for example a frame memory.","The multimedia engine  also supplies a control signal that causes one of the still picture plane  or the moving picture plane , the sub picture plane , and the graphics plane  to be selected to a presentation processor  that will be described later. Likewise, the multimedia engine  supplies a control signal that controls an output of an audio stream to a presentation processor  that will be described later.","Next, the system of the input channel () will be described. A real time stream that is input as an MPEG2 TS to the input terminal  is supplied to the PID filter . The PID filter  extracts a PID (Packet Identification) from the MPEG2 TS transport stream and detects an attribute of a stream contained in a transport packet. The PID filter  separates the input real time stream into corresponding systems for each transport packet in accordance with the attribute of the stream.","When a transport packet is a packet in which image data of a store object is contained, the transport packet is temporarily stored in a buffer TBn A. The transport packet is read at predetermined timing and input to the switch circuit  through the input terminal B that has been selected. Thereafter, the transport packet is stored in the contents buffer  through the switch circuit .","When the PID filter  has determined that the transport packet contains sub picture data, namely subtitle data, in accordance with the PID, the transport packet is temporarily stored in a buffer TBn B and a buffer Bn B. The transport packet is read at predetermined timing and input to the switch circuit  through an input terminal B that has been selected. The transport packet is supplied to the sub picture decoder  through the switch circuit .","The sub picture decoder  removes header information from the supplied transport packet, decodes subtitle data contained in the transport packet, and obtains image data for subtitles. The image data is input to an input terminal B of the switch circuit  and expanded to the sub picture plane  through the switch circuit .","When the PID filter  has determined that a transport packet contains graphics data in accordance with the PID, the transport packet is temporarily stored in a buffer TBn C and a buffer Bn C. The transport packet is read at predetermined timing and input to the switch circuit  through an input terminal B that has been selected. The transport packet is supplied to the still picture decoder  through the switch circuit .","The still picture decoder  removes header information from the supplied transport packet, decodes still picture data contained in the transport packet, and obtains still picture data. The still picture data is input to an input terminal B of the switch circuit  at predetermined timing and expanded to the still picture plane  through the switch circuit .","When the PID filter  has determined that a transport packet contains audio data in accordance with the PID, the transport packet is temporarily stored in a buffer TBn D and a buffer Bn D. The transport packet is read at predetermined timing and supplied to the audio decoder . Audio data contained in the transport packet is compression-encoded in accordance with for example a system based on the MPEG.","The audio decoder  also has for example a linear PCM (Pulse Code Modulation) audio decoder . The audio decoder  removes header information from the input transport stream, decodes compression-encoded audio data contained in the transport packet, and obtains linear PCM audio data.","The linear PCM audio data that is output from the audio decoder  is input to the presentation processor  for audio. In the presentation processor , a sound effect is added to the linear PCM audio data under the control of the multimedia engine  and then obtained from an output terminal .","When the PID filter  has determined that a transport packet contains moving picture data in accordance with the PID, the transport packet is temporarily stored in a buffer TBn E, a buffer MBn , and a buffer EBn , read at predetermined timing, and supplied to the MPEG video decoder . The moving picture data contained in the transport packet has been compression-encoded in accordance with the MPEG2 system.","The MPEG video decoder  removes header information from the supplied transport packet, decodes moving picture data that has been compression-encoded in accordance with the MPEG2 system, and obtains base band moving picture data.","The moving picture data that is output from the MPEG video decoder  is input to an input terminal A of a switch circuit . In addition, the moving picture data is input to an input terminal B of a switch circuit  through a buffer . In the switch circuit , the input terminal A or B is selected at predetermined timing. Output moving picture data is expanded on the moving picture plane .","When the PID filter  has determined that the transport packet contains system information in accordance with the PID, the transport packet is supplied to the system decoder  through buffers TBn F and Bsys . The system decoder  removes header information from the supplied transport packet and extracts the system information therefrom. The system information is supplied to for example a CPU (not shown).","Image data on the sub picture plane  is supplied to a palette  that corresponds to the foregoing palette . The palette has 256 colors. The palette is referenced with an index. YCbCr data is output. In addition, intransparency data \u03b11 is extracted. The YCbCr data and the intransparency data \u03b11 are supplied to the presentation processor .","Image data on the graphics plane  is supplied to an RGB\/YCbCr converting circuit  that corresponds to the RGB\/YCbCr converting circuit . The RGB\/YCbCr converting circuit  converts the color system from RGB (4:4:4) into YCbCr (4:4:4). YCbCr data that is output from the RGB\/YCbCr converting circuit  is supplied to the presentation processor . In addition, intransparency data \u03b12 is extracted from the image data on the graphics plane . The extracted intransparency data is supplied to the presentation processor .","The image data on the still picture plane  is input to an input terminal A. In addition, moving picture data on the moving picture plane  is input to an input terminal B of the switch circuit . The image data on the still picture plane  or the moving picture data on the moving picture plane  is selected by the switch circuit  on the M\/S switch plane . In other words, the still picture plane  is treated like the moving picture plane . An output of the switch circuit  is supplied to the presentation processor  through an up\/down converter .","The up\/down converter  is a circuit that converts the resolution of the image. The up\/down converter  converts for example a high definition (HD) image having a high resolution into a standard definition (SD) image having a standard resolution.","The presentation processor  performs an alpha-blending process using intransparency \u03b1 of image data of the subtitle plane  (sub picture plane ) and intransparency \u03b12 of the graphics plane  (graphics plane ) shown in .","In other words, the presentation processor  combines image data of the still picture plane  or the moving picture plane  that has been selected by the switch circuit  and image data of the sub picture plane  in accordance with the intransparency \u03b11 that has been set to the image data of the sub picture plane . In addition, the presentation processor  combines the image data of which the still picture plane  or the moving picture plane  and the sub picture plane  have been combined and the image data of the graphics plane  in accordance with the intransparency \u03b12 that has been set to the image data of the graphics plane . The image data of which the image data of the graphics plane , the image data (subtitle data) of the sub picture plane , and the image data of the still picture plane  or the moving picture plane  have been combined is obtained from an output terminal .","The presentation processor  can perform an effect process for image data on real time basis.","In the foregoing description, each portion of the player decoder  is composed of hardware. However, the present invention is not limited to such an example. For example, the player decoder  can be accomplished by a process of software. In this case, the player decoder  can be operated on a computer device. Alternatively, the player decoder  can be accomplished by a combination of hardware and software. For example, the audio decoder  and the MPEG video decoder  may be composed of hardware. The rest of the player decoder  may be composed of software.","A program that causes a computer device to execute the player decoder  that is composed of only software or a combination of hardware and software is recorded on a recording medium for example a compact disc read-only disc (CD-ROM) and supplied therewith. The CD-ROM is loaded into a CD-ROM drive of the computer device. The program recorded on the CD-ROM is installed to the computer device. As a result, the foregoing process can be executed on the computer device. Since the structure of the computer device is well known, the description thereof will be omitted.","2-8. User Interface","Next, a user interface according to an embodiment of the present invention will be described.  is a schematic diagram showing an example of state change of a button displayed on the graphics plane . There are two button display states that are a button display state in which a button is displayed on the screen and a button non-display state in which a button is not displayed on the screen. The button non-display state is changed to the button display state. After the button is cleared, the button display state is changed to the button non-display state. The button display state has further three states that are a normal state, a selection state, and an execution state. The button display state can be changed among the three states. The button display state can be changed in one direction among the three states.","Next, with reference to , the state changes of the button display states will be described in detail. When a disc is loaded into the player or when the user presses the menu key of the remote controller, the menu screen  is displayed. When the menu screen  is displayed, the button display states of the buttons A, B, C, D, , and  are changed from the non-display states to the display states. Normally, one of the buttons A, B, C, D, , and  has been placed in the selection state. Now, it is assumed that the button A has been placed in the selection state and the other buttons have been placed in the normal state.","When the user operates for example an arrow key of the remote controller, one (for example, the button A) of the buttons is changed from the normal state to the selection state. In addition, the button A is changed from the selection state to the normal state. The cursor is moved in accordance with the user's operation. When the user operates the OK key of the remote controller, the button B is changed from the selection state to the execution state. As a result, a player operation assigned to the button B is executed.","As described above, player operations are described in a programming language or a script language such as an ECMA script. The program and script of the player operations are recorded on a disc. The program and script of the player operations may be recorded as independent files on a disc. Alternatively, as graphic objects that will be described later, the program and script of the player operations may be multiplexed with a clip AV stream file.","2-9. About Data Structure","Next, data structures of image data of buttons that compose such a menu screen and control information associated with the image data will be described. Now, subtitles and graphics (still pictures) that are displayed other than a moving picture that composes a content main part recorded on a disc will be considered. In the following description, elements such as subtitles and graphics displayed on the screen are considered as objects. The types of objects are categorized as three types that are subtitles, synchronous graphics, and asynchronous graphics as shown in .","Subtitles are displayed in synchronization with a moving picture like subtitles of a movie. Subtitles are image elements that do not relate to user's inputs through for example the remote controller. Graphics are image elements such as buttons on a menu screen that can accept user's inputs. In addition, graphics are categorized as two types of synchronous graphics and asynchronous graphics. Synchronous graphics are image elements in synchronization with a moving picture. Synchronous graphics are for example branch selection screens that are displayed at particular timing while a content main part is being reproduced. Asynchronous graphics are image elements that are displayed not in synchronization with a content main part that is being reproduced. Examples of asynchronous graphics are a menu screen that is initially displayed when a disc is loaded into the player and a screen that is displayed in accordance with a user's input. An image element that is displayed by a Java application that operates on JavaVM and an image element displayed in accordance with the description of an HTML file on browser software are asynchronous graphics.","In the relation of each image element and a main picture displayed on the moving picture plane , subtitles and synchronous graphics are displayed in synchronization with the main picture. Thus, both subtitles and synchronous graphics are synchronous type. On the other hand, since asynchronous graphics are displayed not in synchronization with a main picture, they are asynchronous type as the name implies.","Subtitles and graphics can be categorized in accordance with planes. Subtitles are displayed on the subtitle plane . Synchronous and asynchronous graphics are displayed on the graphics plane .","Since subtitles and synchronous graphics are displayed while a main moving picture is being displayed, it is preferred that they have a common data structure. Hereinafter, subtitles and synchronous graphics having a common data structure are referred to as graphics objects. Since graphics objects are always displayed in synchronization with a moving picture that is being reproduced, when they are multiplexed with a moving picture, they can be easily handled.",{"@attributes":{"id":"p-0371","num":"0405"},"figref":["FIG. 42A","FIG. 42B","FIG. 42C","FIG. 42A"],"b":["200","200","201","202","203"]},"In the following example, it is assumed that image data treated as the graphics object  has a PNG format and that the image data is PNG image data. Alternatively, the graphics object  may be another format image data such as bit map data having the JPEG format, image data that is compressed in accordance with the run length compressing method, or bit map data that is not compression-encoded. For convenience, image data will be represented as PNG image, PNG image data, or the like.","In , , and , the graphics object header  describes information that represents attributes of the graphics object . The attributes of the graphics object  are for example the data size of the graphics object , the number of PNG images that the graphics object  has, palette data used for PNG image data that the graphics object  uses in common, and identification information with which the graphics object  is identified. The identification information is for example a number uniquely assigned to each graphics object . The graphics object header  may describe further another information.","The display control command table  describes information necessary for controlling display of PNG images such as display positions of PNG images that the graphics object  has and display start times and display end times thereof.","The PNG data region  describes image data that has been compression-encoded in accordance with the PNG format (hereinafter, the image data is referred to as PNG data). The PNG data region  can have a plurality of PNG data A, B, . . . , and . The number of PNG data described in the PNG data region  is described in the graphics object header .","It is assumed that a plurality of PNG data A, B, . . . , N described in the PNG data region  are images that are strongly correlated such as a set of a plurality of still pictures that composes an animation or images of three states of a button that is displayed. When these PNG data A, B, . . . , and N are grouped as one graphics object, PNG images can be easily handled.","The graphics object  has time information that describes time at which the graphics object  can be displayed. In the example of which a real time stream is transmitted as an MPEG2 TS, pts (Presentation Time Stamp) defined in the MPEG2 (Moving Pictures Experts Group 2) is used as the time information. The pts is time management information of an output that is reproduced. The pts is measured by a clock of 90 kHz as a value having a length of 33 bits. When the STC (System Time Clock) of the reference decoder of the MPEG system accords with the pts, a corresponding access unit is reproduced and output. One graphics object  can be displayed after time represented by the pts. After the time represented by the pts, the display of the graphics object  is turned on and off with a display control command. Since the display of the graphics object  is managed with the display control command, after the display of the graphics object  is turned off, the same graphics object  can be displayed.",{"@attributes":{"id":"p-0378","num":"0412"},"figref":"FIG. 42B","b":["200","203","1","203","1","200","200","1","203","1","1","1","202"]},"On the other hand, when an effect such as an animation of which images are varied is applied to subtitles, a plurality of PNG data () B-, PNG data () C-, PNG data () D-, . . . corresponding to individual motions of the animation may be described in one graphics object  as represented by dotted lines shown in . In addition, PNG data of subtitles of different languages such as Japanese subtitles and English subtitles can be described as PNG data () A-, PNG data () B-, . . . in one graphics object .",{"@attributes":{"id":"p-0380","num":"0414"},"figref":"FIG. 42C","b":["200","200","203","200","203","2","203","2","203","3"]},"When the graphics object  has only PNG data A- for subtitles as represented by solid lines shown in , a display control command for the PNG data A- is described in the display control command table  of the graphics object . When the graphics object  has a plurality of PNG data A-, B-, and C- as shown in , it is necessary to identify a display control command described in the display control command table  for the plurality of PNG data A-, B-, and C-.","When the initial state of a button of a graphics object  shown in  has been designated as the selection state, a button image that is displayed first and placed at the beginning of the PNG data region  should not be the PNG data A- for the normal state, but the PNG data B- for the selection state. According to the first mode of the present invention, the display control is performed outside the graphics object .","The initial state of each button, display start and display stop, a program that is executed in the execution state of each button, and so forth would be designated by an external script program of a graphics object , for example, foregoing ECMA script or JavaScript. PNG data for a button that is displayed is changed when the user operates an arrow key of the remote controller and moves the cursor. In this case, the player changes PNG data of each button in accordance with a user's input.","According to the first mode of the present invention, a graphics object  is divided into packets that are prescribed in the MPEG2, multiplexed with a clip AV stream, and recorded as a clip AV stream file on a disc. As shown in , a graphics object  is divided and contained in PES (Packetized Elementary Stream) packets , , . . . that are prescribed in the MPEG2. At this point, the graphics object header , the display control command table , and the beginning of individual PNG data A, B, . . . , are contained at the beginning of the payload of each of the PES packets , , . . . As a result, when a graphics object  is reproduced, it can be easily searched for each data thereof.","A graphics object  divided and contained in the PES packets , , . . . is further divided into TS packets having a fixed data size of 188 bytes (not shown) and multiplexed with a stream of moving picture data and sound data such as a clip AV stream.","2-10. About Decoder Model for Graphics Objects",{"@attributes":{"id":"p-0386","num":"0420"},"figref":["FIG. 44","FIG. 39","FIG. 44","FIG. 39","FIG. 44","FIG. 39"],"b":["240","200","240","106","116","100","240","240"]},"A clip AV stream is supplied from the terminal  to the PID filter . The PID filter  functions as a demultiplexer for an MPEG TS (transport stream) and extracts moving picture data, audio data, and a graphics object  from the MPEG TS in accordance with the PID of the TS. The moving picture data is supplied to the buffer TBn E, which is a video buffer. Audio data is supplied to a buffer D that is an audio buffer. The graphics object  is supplied to the buffer TBn B, which is an input buffer of a graphics object (denoted by \u201cGOBJ\u201d in ).","The graphics object  is read from the buffer TBn B and supplied to a GOBJ parser . The GOBJ parser  is for example one of functions of the sub picture decoder  shown in . The GOBJ parser  reads the graphics object header  from the supplied graphics object , extracts palette data from the graphics object header , and separates the display control command table  and the PNG data region  from the graphics object header . The palette data and the display control command table  are supplied to a command processor\/graphic renderer . PNG data A, B, . . . of the PNG data region  are temporarily stored in a PNG decoder buffer . The PNG decoder buffer  corresponds to the buffer Bn B shown in .","The PNG data  stored in the PNG decoder buffer  is decoded by a PNG decoder  that is one of functions of the sub picture decoder  and output as bit map data. The bit map data is stored in an object buffer . The object buffer  corresponds to the graphics buffer D shown in .","The command processor\/graphic renderer  reads the bit map data stored in the object buffer  in accordance with a display control command described in the display control command table  and transfers the bit map data to a plane buffer  at designated time. The plane buffer  corresponds to for example the sub picture plane  and the graphics plane  shown in . Plane buffers A and B (not shown) may be disposed for subtitles and graphics objects other than subtitles. Alternatively, the sub picture plane  and the graphics plane  may be regions different from the plane buffer .","In addition, the command processor\/graphic renderer  supplies palette data supplied from the GOBJ parser  to a common palette table  that corresponds to the palette  shown in . The command processor\/graphic renderer  has a part of functions of the multimedia engine  and a part of functions of the sub picture decoder  shown in .","When a graphics object  composes a button, as described above, PNG data A, B, and C corresponding to three types of states of the button are contained in the graphics object . The PNG data A, B, and C are decoded by the PNG decoder  and stored in the object buffer .","On the other hand, an input from for example the user's remote controller is received by the command processor\/graphic renderer . The command processor\/graphic renderer  reads a bit map from the object buffer  in accordance with the user's input and transfers the bit map to the plane buffer . When the user's input causes the state of the button to be changed from the selection state to the execution state, bit map data that corresponds to the button image of the execution state is selectively read from the object buffer  and transferred to the plane buffer .","The command processor\/graphic renderer  can perform a special effect process such as an extracting process for the bit map data that is read from the object buffer  in accordance with a display control command.","According to the first mode of the present invention, since the sampling depth of one pixel of PNG data is eight bits, data of eight bits per pixel is arranged in the plane buffer . Data of the plane buffer  is read at intervals of a scanning period of a displaying system that performs a displaying process for such as a display device. Bit map data that is read from the plane buffer  is supplied to the common palette table  that corresponds to for example the palette  shown in . The common palette table  converts the bit map data into color information of real RGB (4:4:4) in accordance with a palette index value and extracts intransparency data \u03b11 and \u03b12 from the bit map data. Color information of RGB (4:4:4) is converted into color information of YCbCr (4:4:4) of a converting circuit (not shown). The color information of YCbCr (4:4:4) is supplied to the presentation processor  shown in  along with the intransparency data \u03b11 and \u03b12.","A special effect that requires a process for changing a palette and intransparency such as fade in\/fade out is accomplished by the command processor\/graphic renderer  that varies data of the common palette table  in accordance with a display control command. Alternatively, common palette tables A and B (not shown) may be disposed for subtitles and a graphics object  other than subtitles.",{"@attributes":{"id":"p-0397","num":"0431"},"figref":["FIG. 45A","FIG. 45B","FIG. 45C","FIG. 45D"],"b":["111","227","228","229","227","227"]},{"@attributes":{"id":"p-0398","num":"0432"},"figref":["FIG. 45A","FIG. 45B","FIG. 45C","FIG. 45D"],"b":["1","2","3","201"]},"In , PNG data of the graphics object GOBJ# is input to the GOBJ input buffer. At time dts of GOBJ#, decoding of the PNG data is started. In , the PNG data is transferred from the GOBJ input buffer to the PNG decoder . The PNG data is decoded and bit map data is obtained. In reality, the PNG data is temporarily moved from the GOBJ input buffer to the PNG decoder buffer . The PNG decoder  performs a decoding process for data stored in the PNG decoder buffer .","Since the PNG decoder  has an upper limit of a decoding speed, data is supplied from the GOBJ input buffer to the PNG decoder buffer  so that the transfer speed of the data does not exceed the decoding speed of the PNG decoder . Thus, PNG data is input to the PNG decoder buffer  at a data transfer speed corresponding to a slope against a vertical line that represents that the process time of PNG data in the PNG decoder  is 0.","Even if PNG data has not been fully input to the PNG decoder , decoding of the PNG data can be started. In the example shown in , , , and , after the object GOBJ# stored in the GOBJ input buffer has been fully transferred to the PNG decoder , an input of PNG data of the next object GOBJ# to the GOBJ buffer is started.","Likewise, PNG data of the object GOBJ# and the object GOBJ# is input to the PNG decoder buffer  at respective transfer speeds corresponding to particular slopes B and C, respectively. In reality, the slope B varies in a plurality of regions.","When the valid period of the object GOBJ# starts at time pts of GOBJ#, bit map data of the object GOBJ# that has been decoded and stored in the PNG decoder buffer is transferred to the object buffer  (). The valid period of the object GOBJ# transferred to the object buffer  continues until time represented by presentation end of GOBJ#.","In the valid period of the object GOBJ#, when a command Display ON Cmd. of GOBJ# is issued, bit map data of the object GOBJ# stored in the object buffer  is transferred to the plane buffer  and displayed (). As will be described later, the upper limit of the transfer speed of bit map data to the plane buffer  varies depending on an influence of a bus width and the like. Thus, bit map data is written to the plane buffer  at a transfer speed corresponding to for example a particular slope D.","Likewise, bit map data of the other objects GOBJ# and object GOBJ# is transferred at transfer speeds corresponding to slopes E, F, and G and written to the plane buffer .","The object GOBJ# is continuously displayed until a command Display OFF cmd. of GOBJ# that causes the object GOBJ# to be cleared is issued. When the command Display OFF cmd. of GOBJ# is issued, the bit map data of the object GOBJ# stored in the plane buffer  is discarded and the object GOBJ# is cleared on the screen.","The objects GOBJ# and GOBJ# are successively input to the GOBJ buffer. Like the object GOBJ#, decoding of the objects GOBJ# and GOBJ## is started at time dts of GOBJ# and time dts of GOBJ#. PNG data is supplied to the PNG decoder . The PNG decoder  decodes the PNG data with a PNG decoder buffer and outputs bit map data. The valid period of the object GOBJ# is designated time pts of GOBJ#. A command Display ON cmd. of GOBJ# (not shown in  to ) causes the object GOBJ# to be displayed. The object buffer  transfers bit map data to the plane buffer . The object GOBJ# is displayed until the command Display OFF cmd. of GOBJ# is issued.","In the example shown in , after the object GOBJ# is cleared with a command Display OFF cmd. of GOBL# (not shown), the object GOBJ# is displayed again with a command Display ON cmd. of GOBJ#. Bit map data of the object GOBJ# is kept stored in the object buffer  until valid period end time presentation end of GOBJ# is designated to the object GOBJ#. Thus, with the command Display ON cmd. of GOBJ#, the object GOBJ# can be repeatedly displayed.","On the other hand, the valid period designated for the object GOBJ# overlaps with the valid period designated for the object GOBJ#. In this case, the object buffer  stores a plurality of bit map data in different regions in accordance with a blank capacity thereof. For example, while bit map data of the object GOBJ# is transferred from the object buffer  to the plane buffer  and displayed, when bit map data of the object GOBJ# is transferred from a different region of the object buffer , data of two bit maps can be displayed at the same time.","2-11. About Transfer Speed of Graphics","Next, the case that the graphics object decoder model  (hereinafter referred to as decoder model ) is built in the player will be considered. To allow data reproduced from the same disc to have compatibility with different players, it would be necessary to apply predetermined restriction to the decoder model . For example, the decoder model  has an upper limit of the capability of the graphics process. Thus, when graphics data that exceeds the upper limit of the capability is input, it becomes impossible to perfectly decode the graphics data. As a result, the graphics data cannot be normally displayed.","The minimum capability of the graphics process that the player side should have will be prescribed in a standard. On the other hand, graphics that can be processed in the minimum capability prescribed in the standard will be prepared on the contents producer side. By matching the capability of the graphics process that the player side has with the capability of the graphics process that the contents producer side prepares, the reproduction compatibility can be maintained.","According to the first mode of the present invention, in , a data transfer speed R() from the GOBJ parser  to the PNG decoder buffer  and a data transfer speed R() from the command processor  to the plane buffer  are prescribed.","The data transfer speed R() prescribes the data transfer amount pre unit time of data that is input to the PNG decoder buffer . In other words, the slopes A, B, and C shown in  correspond to the data transfer speed R(). That prescribes the decode capability that represents the amount for which the PNG decoder  disposed downstream of the PNG decoder buffer  can decode compression-encoded graphics data in a unit time. Thus, by restricting the data transfer speed R(), the input compression-encoded graphics data can be prevented from being imperfectly decoded and being improperly displayed.","The data transfer speed R() prescribes an update speed of an image. The plane buffer  corresponds to a screen actually displayed on the display device. Thus, the update speed of graphics that the user sees depends on the write speed of data to the plane buffer . The data transfer speed R() prescribes the minimum update interval of all a plane, namely all a screen in the unit of [bytes\/second]. In other words, the slopes D, E, F, and G shown in  correspond to the data transfer speed R().","When a part of a plane is updated, since the amount of image data that is updated is small, it is updated at a shorter period than the minimum update interval prescribed as the data transfer speed R(). However, the update interval is not always proportional to the data amount of the image data that is updated. The update interval is largely affected by the arrangement of image data on a plane.","Next, with reference to , the update speed of a plane will be described in detail. It is assumed that the object buffer  stores two graphics objects  and  and that these two graphics objects  and  are written to the plane buffer  and displayed.","The graphics objects  and  are read from the object buffer  and supplied to the command processor\/graphic renderer . An output of the command processor\/graphic renderer  is restricted at the foregoing data transfer speed R() so as to restrict the update speed (update interval) on the screen.","At this point, the update speeds of the graphics objects  and  depend on how they are placed on the plane rather than the total of their data amounts. This is because a regular graphics processor that performs a graphics process updates a plane in each rectangular region.","For example, a plane is updated with a square region  that contains all the graphics objects  and  placed on the plane. In other words, the command processor\/graphic renderer  forms image data of the square region  in accordance with arrangement information of the graphics objects  and . The image data of the square region  of the square region  is supplied to the plane buffer  through a bus. The plane buffer  substitutes data of the region corresponding to the square region  with data of the square region  in accordance with a designated display position.","Since image data that is output from the command processor\/graphic renderer  is bit map data, the image data has a data amount in accordance with the area of the image rather than the content of the image. In the example shown in , the data amount of the image of the square region  that contains the graphics objects  and  can be represented with for example (width\u00d7height) pixels, namely (width\u00d7height bytes).","Since the data transfer speed to the plane buffer  is defined as speed R() [bytes\/second], it is clear that the graphics objects  and  can be updated in {speed R()\/(width\u00d7height)} seconds. After {speed R()\/(width\u00d7height)} has elapsed, the next graphics object can be drawn. Thus, when the disc producer side creates a program that allows two graphics objects to be drawn at an interval of at least the foregoing time period, the same graphics can be displayed by any player. Thus, the reproduction compatibility can be maintained by any player.","When the data transfer speed R() is estimated, the animation speed of subtitles can be decided so that reproduction compatibility can be maintained as will be described later.","2-12. Details of Structure of Graphics Objects","Next, a structure of the graphics object  will be described in detail.  shows syntax that describes an example of a structure of the graphics object . The graphics object header , the display command control table , and the PNG data region  shown in  correspond to a block GraphicsObjectHeader( ), a block GOBJCommandTable( ), and a block PNGImageRegion( ), respectively.","The block GraphicsObjectHeader( ) starts with a field length. The field length has a data length of eight bits, an integer that is 0 or larger. The field length describes the length immediately after the field length until the end of the block GraphicsObjectHeader( ) in bytes. A field presentation_end_time_stamp has a data length of 33 bits, an integer that is 0 or larger. The field presentation_end_time describes valid period end time of the graphics object . The valid period of the graphic object is from a pts of a PES packet header until valid period end time described in this field presentation_end_time_stamp. A field Number_of_PNG_images has a data length of eight bits, an integer that is 0 or larger, and describes the number of PNG images described in the block PNGImageRegion( ). A field Number_of_DispCmds has a data length of eight bits, an integer that is 0 or larger, and describes the number of display control commands described in a block GOBJCommandTable( ).","A block GlobalPaletteTable( ) in the block GraphicsObjectHeader( ) describes information of a palette table commonly used in the graphics object . Information of a palette table described in the block GlobalPaletteTable( ) is described as the contents of the common palette table . A field start_address_of_PNG image(i) has a data length of 32 bits, an integer that is 0 or larger, and describes the position at which data PNG_image(i) of an i-th PNG image starts with the relative number of bytes from the beginning of the block GraphicsObject( ).","A field PNG_file_name(i) describes a file name of PNG data that starts with the field start_address_of_PNG_image(i). The contents of the field PNG_image(i) that is a field in the block PNGImageRegion( ) are the same as those of a single PNG file. A block PNGImageRegion( ) is created by connecting one or more PNG files. For example, in , the PNG data A, B, . . . , and are connected and the block PNGImageRegion( ) is created. At this point, a file name can be described in the field PNG_file_name(i) so that the file name is not lost. In contrast, when the PNGImageRegion( ) is decomposed and individual PNG files are obtained, the individual fields PNG_image(i) are independent files having file names described in the field PNG_file_name(i).","The block GOBJCommandTable( ) is composed of a command group DispCmds(i) that is a collection of display control commands that are executed at the same time. The command group DispCmds(i) describes display control commands starting with a command execution_time (time) that describes an execution time. In other words, a portion after the command execution_time (time) until the next command execution_time (time) composes one command group DispCmd(i).","As described above, the block PNGImageRegion( ) describes a field PNG_image(i) that is data of one image that has been compression-encoded in accordance with the PNG system.","Any number of padding_word can be described between the block GraphicsObjectHeader( ) and the block GOBJCommandTable( ). Likewise, any number of padding_word can be described between the block GOBJCommandTable( ) and the block PNGImageRegion( ).",{"@attributes":{"id":"p-0430","num":"0464"},"figref":"FIG. 48"},"A field palette_index_number describes an index number assigned to colors and intransparency of a field red_value, a field green_value, a field blue_value, and a field alpha that are preceded by the field palette_index_number. Image data references colors and intransparency with the index number.","In a loop of a for statement of the block GlobalPaletteTable( ), the field palette_index_number that has the same value should not be described more than twice. Each of the field red_value, the field green_value, and the field blue_value has a data length of eight bits, an integer that is 0 or larger. The field red_value, the field green_value, and the field blue_value designate red, green, and blue, respectively. The field alpha has a data length of eight bits. The field alpha represents intransparency \u03b1. When the value of the field alpha is 0, it represents perfect transparent. When the value of the field alpha is 255, it represents perfect intrasparent.","Each PNG image can have a chunk of palette information PLTE. According to the first mode of the present invention, the palette information PLTE is not used, but palette information defined by the block GlobalPaletteTable( ). When a plurality of PNG images are displayed at the same time, if the PNG images use colors of different palettes, it will be difficult to display the PNG images in correct colors. In other words, a plurality of PNG images described in the field PNG_image(i) of GraphicsObject( ) reference the common block GlobalPaletteTable( ) and use the common palette table described in the block GlobalPaletteTable( ).","Next, the command group DispCmds(i) will be described. The command group DispCmds(i) describes display control commands that control the display of a graphics object . In the command group DispCmds(i), a command execution_time(start_time) causes a command described before the next command execution_time(start_time) to be executed at designated time start_time. The start point of the time start_time is the pts of the graphics object . The unit of the time start_time is the same as that of the pts.","One command group DispCmds(i) can describe a plurality of commands that are executed at the time start_time described in the command execution_time(start_time). Commands described in the command group DispCmds(i) are executed simultaneously at the time start_time described in the command execution_time(start_time). Before the commands described in the command group DispCmds(i) have been executed, if the time start_time described in the command execution_time(start_time) of the next command group DispCmds(i+1) has elapsed, the execution of the command group DispCmds(i) is cancelled. Instead, the next command group DispCmds(i+1) is executed.","Display control commands besides the command execution_time(start_time) described in the command group DispCmds(i) are thought to be as listed in  and . These display control commands are assigned numbers as shown in  and .\n\n","These seven types of commands are just examples. In other words, commands in the command group DispCmds(i) are not limited to those commands. Other display control commands can be defined and added to the command group DispCmds(i).","The display start command () and the display end command () of the graphics object  are so-called fade in\/fade out commands that are described as a command fade_in(fade_in_time) and a command fade_out (fade_out_time), respectively.","The fade-in is designated by the command fade_in(fade_in_time). The command fade_in(fade_in_time) causes a graphics object  to be gradually displayed from the non-display state to the display state. By gradually increasing the value of the intransparency \u03b1 of the alpha-blending corresponding to the time fade_in_time, the fade-in can be accomplished. When the command execution_time(start_time) is followed by the command fade_in(fade_in_time), the graphics object  that is transparent gradually becomes intransparent after the time start_time designated by the command execution_time (start_time). After the time designated by the argument time fade_in_time has elapsed, the value of the intransparency \u03b1 of all the palette indexes is set to a value designated on the common palette table.","When the time fade_in_time of the command fade_in(fade_in_time) has been set to 0, the graphics object  is immediately displayed in colors and intransparency \u03b1 designated on the palette table.","The fade-out is an inverse process of the fade-in. The fade-out is designated by the command fade_out (fade_out_time). The command fade_out (fade_out_time) causes a graphics object  that is displayed to be gradually cleared. By gradually decreasing the value of the intransparency \u03b1 of the alpha-blending corresponding to the time fade_out_time, the fade-out can be accomplished. When the command execution_time(start_time) is followed by the command fade_out (fade_out_time), a graphics object  that is intransparent gradually becomes transparent immediately after the time start_time designated by the command execution_time(start_time). After the time designated by the argument time fade_out_time has elapsed, the value of the intransparency \u03b1 of all the palette indexes becomes 0. As a result, the graphics object  fully becomes transparent and invisible.","When the time fade_out_time of the command fade_out (fade_out_time) is set to 0, the graphics object  is immediately cleared.","When the value of the intransparency \u03b1 is gradually varied in the fade-in and fade-out as time elapses, more natural fade-in and fade-out effects can be preferably obtained. Alternatively, in the fade-in, after the time designated by the time fade_in_time has elapsed, the value of the intransparency \u03b1 should match the value designated on the palette table. However, the resolution and graduation of the intransparency \u03b1 are not designated by a command. In reality, the resolution and gradation of the intransparency \u03b1 depend on the installed system.","In the foregoing example, the commands are represented as texts such as \u201cfade-in( )\u201d and \u201cfade_out( )\u201d for high recognizability. However, actually, the commands fade_in( ) and fade_out( ) are converted into predetermined binary values along with their arguments and described in DispCmds(i). That applies to other commands that will be described later.","The palette table color and intransparency \u03b1 change command () causes palette information to be changed. This command is described in the format of change_palette (index, newR, newG, newB, newAlpha). A PNG image displayed simultaneously on the subtitle plane  and the graphics plane  references the common palette table that is shown in  and that is defined by the syntax shown in . Palette information defined as GlobalPaletteTable( ) is used as the common palette table. With the command change_palette (index, newR, newG, newB, and newAlpha), the common palette information can be changed.","In other words, the values index, newR, newG, and newAlpha described as arguments in the command change_palette (index, newR, newG, newB, newAlpha) cause values R, G, and B of three primary colors of color index values represented by the palette number index to be changed to the values newR, newG, and newB and the value of the intransparency \u03b1 to be changed to the value newAlpha.","The command () that causes the display position and size of a graphics object to be set on a plane is used in the format of set_display_box(x, y, x, y). The command () causes a graphics object  to be placed in a square region (x, y) (x, y) defined with coordinates (x, y) and (x, y) on the plane. The command () that causes a display range of a graphics object to be set is used in the format of set_clipping_box(a, b, a, b). The command () causes a square region (a, b) (a, b) defined with coordinates (a, b) and (a, b) of a PNG image of a graphics object  to be displayed on the plane.","Next, with reference to  and , the command set_display_box(x, y, x, y) and the command set_clipping_box(a, b, a, b) will be described in detail. As shown in , on the coordinates shown in  and , the upper left corner of the display screen is defined as an origin, the horizontal right direction is denoted by x, the lower vertical direction is denoted by y, and coordinates are denoted by (x, y).","As shown in , the command set_clipping_box(a, b, a, b) causes a square region (a, b) (a, b) that is actually displayed to be set in a PNG image  of a graphics object . In the example shown in , it is assumed that the square region (a, b) (a, b) to be set is smaller than the PNG image . The command set_display_box(x, y, x, y) causes a real display position of the square region (a, b) (a, b) to be set on a plane of a square region (x, y) (x, y) (see. ). In other words, only the square region (a, b) (a, b) of the PNG image  is displayed against the square region (x, y) (x, y) on the screen.","When the square region (a, b) (a, b) is larger than the square region (x, y) (x, y) that is actually displayed, only the PNG image of the square region (x, y) (x, y) in the square region (a, b) (a, b) is displayed. In contrast, when the square region (a, b) (a, b) is smaller than the square region (x, y) (x, y) that is actually displayed, the outside of the square region (a, b) (a, b) in the square region (x, y) (x, y) is treated as a transparent region.","When the foregoing display control commands are described along with a plurality of commands execution_time(start_time), subtitles and synchronous graphics that vary as time elapses can be displayed. For example, in the graphics object  shown in , a plurality of command groups DispCmds(i) are described in the block GOBJCommandTable( ). Each of the command groups DispCmds(i) describes the display control commands execution_time(start_time) whose times start_time are different so as to execute the command groups DispCmds(i) at the start times designated by start_time.",{"@attributes":{"id":"p-0452","num":"0494"},"figref":["FIG. 52","FIG. 52","FIG. 52"],"b":["200","200"]},"In the first command group DispCmds(), a command set_display_box(800, 800, 1300, 900) causes a display region on a plane to be set. A command set_clipping_box(0, 0, 500, 100) causes a display region of a PNG image of a graphics object  to be set. A command fade_in (2 sec) causes a fade-in process for two seconds to be started at time [0]. In the next command group DispCmds(), a command change_palette(index, newR, newG, newB, Alpha) describes color index values [1], [2], [3], and [4]. The command group DispCmds() also causes colors and intransparency \u03b1 referenced by the index values [1], [2], [3], and [4] to be changed at time [800]. The next command group DispCmds() causes a graphics object  that is displayed to be faded out for two seconds at time [2000].","As shown in , when the command groups DispCmds(), DispCmds(), and DispCmds() are successively described, for example subtitles that vary as time elapses can be accomplished. In other words, when the command groups DispCmds(), DispCmds(), and DispCmds() are properly used, subtitles and button images can be displayed as animations.",{"@attributes":{"id":"p-0455","num":"0497"},"figref":["FIG. 53A","FIG. 53B","FIG. 53C","FIG. 53D","FIG. 53A","FIG. 53D","FIG. 52"],"b":"0"},{"@attributes":{"id":"p-0456","num":"0498"},"figref":["FIG. 54A","FIG. 54B","FIG. 54A"],"b":["260","260","1","1","2","2","0","1","1","2","2","260","1","1","2","2","260"]},"In the next command group DispCmds(), a command execution_time(start_time) causes predetermined time that elapses after the execution of the command group DispCmds() to be set as start time. A command set_display_box(x\u2032, y\u2032, x\u2032, y\u2032) causes a display region to be moved on the plane to be set. Likewise, in the next command group DispCmds(), a command execution_time(start_time) causes predetermined time that elapses after the execution of the command group DispCmds() to be set as start time. A command set_display_box(x\u2033, y\u2033, x\u2033, y\u2033) causes a display region to be moved on the plane to be set.","Thus, as shown in , a PNG image  as subtitles can be moved to a square region (x, y) (x, y), a square region (x\u2032, y\u2032) (x\u2032, y\u2032), and a square region (x\u2033, y\u2033) (x\u2033, y\u2033) on a plane.",{"@attributes":{"id":"p-0459","num":"0501"},"figref":["FIG. 55A","FIG. 55B","FIG. 55A"],"b":["262","261","1","1","2","2","0","1","1","2","2","262","260","1","1","2","2","260"]},"In the next command group DispCmds(), a command execution_time(start_time) causes predetermined time that elapses after the execution of the command group DispCmd() to be set as start time. A command set_clipping_box(a\u2032, b\u2032, a\u2032, b\u2032) causes a display region to be moved in the PNG image  to be set. Likewise, in the next command group DispCmds(), a command execution_time(start_time) causes predetermined time that elapses after the execution of the command group DispCmds() to be set as start time. A command set_clipping_box(a\u2033, b\u2033, a\u2033, b\u2033) causes a square region to be moved in the PNG image  to be set.","Thus, as shown in , a square region as a part of a PNG image  as subtitles is moved from a square region (a, b) (a, b) to a square region (a\u2032, b\u2032) (a\u2032, b\u2032) to a square region (a\u2033, b\u2033) (a\u2033, b\u2033) in a square region (x, y) (x, y) on a plane. As a result, the subtitles can be scrolled.",{"@attributes":{"id":"p-0462","num":"0504"},"figref":["FIG. 56A","FIG. 56B","FIG. 56A"],"b":["265","265","1","1","2","2","1","1","2","2","0","1","1","2","2","1","1","2","2","266"]},"For example, the command set_display_box(x, y, x, y) causes a square region (x, y) (x, y) that is displayed on a plane to be set. The command set_clipping_box(a, b, a, b) causes a square region (a, b) (a, b) that is displayed in the PNG image  to be set. The square region (x, y) (x, y) and the square region (a, b) (a, b) form the frame A.","In the next command group DispCmds(), a command execution_time(start_time) causes predetermined time elapses after the execution of the command group DispCmds() to be set as start time. A command set_display_box(x\u2032, y\u2032, x\u2032, y\u2032) causes a square region (x\u2032, y) (x\u2032, y\u2032) to be set on the plane. A command set_clipping_box(a\u2032, b\u2032, a\u2032, b\u2032) causes a square region (a\u2032, b\u2032) (a\u2032, b\u2032) to be set in the PNG picture . The square region (x\u2032, y\u2032) (x\u2032, y\u2032) and the square region (a\u2032, b\u2032) (a\u2032, b\u2032) form a frame B to which the frame A is moved. Likewise, in the next command group DispCmds(), a command execution_time(start_time) causes predetermined time that elapses after the execution of the command group DispCmds() to be set as start time. A command set_display_box(x\u2033, y\u2033, x\u2032, y\u2033) causes a square region (x\u2033, y\u2033) (x\u2033, y\u2033) to be set on the plane. A command set_clipping_box(a\u2033, b\u2033, a\u2033, b\u2033) causes a square region (a\u2033, b\u2033) (a\u2033, b\u2033) to be set in the PNG image . The square region (x\u2033, y\u2033) (x\u2033, y\u2033) and the square region (a\u2033, b\u2033) (a\u2033, b\u2033) form a frame C to which the frame B is moved.","Thus, as shown in , while a square region of a part of the PNG image  of subtitles is being moved, the square region can be moved from the region A to the region B to the region C on the plane.","Thus, according to the first mode of the present invention, since the display control of the graphics object  is performed by the command groups DispCmds(i) of which each display control command is grouped by the command execution_time(start_time), various displays can be easily accomplished on the subtitle plane  and the graphics plane .","2-13. About Effect Sounds","According to the first mode of the present invention, a sound output can be synchronized with a display control of a graphics object . A sound output is defined by the display control command (), which causes an effect sound to be reproduced, and the display control command (), which causes an effect sound to be assigned to image data in the display control commands () to (), excluding the command execution_time(start_time), of the foregoing command group DispCmds(i). Sound data is assigned a unique identification sound_id.","An effect sound is a sound that is reproduced in synchronization with or in accordance with display control of subtitles or a button rather than a sound reproduced in synchronization with a moving picture or a still picture displayed on the moving picture plane (for example, in a movie, a sound recorded along with a movie picture in pairs).","As described in the related art section, the user operates keys (direction keys) assigned to up, down, left, and right directions with for example remote control commander (hereinafter referred to as remote controller) so as to select one button displayed on the menu screen. Thereafter, with an OK key, the user causes the operation assigned to the selected button to be executed. Each button has three states that are the normal state (non-selection state), the selection state, and the execution state. The three states of each button can be assigned different graphics objects. Thus, button images (shapes and colors) can be changed for the three states of each button. It is preferred that the user can easily distinguish the states of buttons with different images.","In addition, the three states of each button can be assigned different effect sounds. For example, an effect sound that is generated when the user selects a button is assigned to a button image of \u201cselection state\u201d. In addition, an effect sound such as a click sound that is generated when a buttons is placed in the execution state is assigned to a button image of \u201cexecution state\u201d.","An effect sound assigned to the button image of \u201cselection state\u201d is referenced with an identifier sound_id of sound data that generates the effect sound. When the user selects the button, the sound data referenced with the identifier sound_id is read from the memory of the player and reproduced as an effect sound. Likewise, an effect sound assigned to the button image of \u201cexecution state\u201d is referenced with an identifier sound_id of sound data that generates the effect sound. When the user selects the button and operates the OK key, the button becomes the execution state. At this point, the sound data referenced with the identifier sound_id of the effect sound assigned to the button image of \u201cexecution state\u201d, is read from the memory of the player and reproduced.","The display control command (), which causes an effect sound to be reproduced, of the command group DispCmds(i) is described in the format of play_sound(sound_id). The command play_sound(sound_id) causes sound data identified by an identifier sound_id to be reproduced. When the command play_sound(sound_id) is described in a command group DispCmds(i), sound data identified by the identifier sound_id is reproduced at time start_time designated by the command execution_time(start_time).","For example, when the command play_sound(sound_id) is used along with a command fade_in(fade_in_time) and a command fade_out(fade_out_time), sound data as an effect sound can be reproduced while subtitles are being displayed and\/or cleared.  shows an example of which the command play_sound(sound_id) is used. In the example shown in , in the first command group DispCmds(), a command fade_in(2 sec) causes a graphics object to be faded in for two seconds at start time [0]. A command play_sound() causes sound data identified by the identifier sound_id [1] to be reproduced. Thereafter, in the command group DispCmds(), a command execution_time(800) causes a display color to be changed at time [800]. A command play_sound() causes sound data identified by the identifier sound_id [2] to be reproduced. In the command group DispCmds(), a command execution_time(2000) and a command fade_out(1 sec) cause the graphics object to be faded out for one second at time [2000]. A command play_sound() causes sound data identified by the identifier sound_id to be reproduced.","The command (), which causes an effect sound to be assigned to PNG data, is described in the format of set_sound(PNG_image_id, sound_id). The command set_sound(PNG_image_id, sound_id) causes sound data designated by the identifier sound_id to be reproduced for PNG data identified by the identifier PNG_image_id. This command set_sound(PNG_image_id, sound_id) causes the sound data identified by the identifier PNG_image id to be reproduced when PNG data identified by the identifier PNG_image_id is displayed. The identifier PNG_image_id of the PNG data is the same as the value of the loop counter i of PNG_image(i) of the block PNGImageRegion( ) shown in .","It is considered that the command set_sound (PNG_image_id, sound_id) is used for PNG data of buttons in the selection state and the execution state. As a result, when the normal state of a button is changed to the execution state or vice versa, sound data assigned to PNG data that represents each state can be generated as an effect sound. Beside this example, this command set_sound(PNG_image_id, sound_id) can be used for PNG data for other than buttons.",{"@attributes":{"id":"p-0476","num":"0518"},"figref":["FIG. 58","FIG. 58"],"b":["200","203","203","203","203"]},"The graphics object  shown in  describes only the command group DispCmds() that is executed in the display control command table  at time [0] by the command execution_time (). Since an identifier PNG_image_id starts with [0], the identifier PNG_image id [0] represents PNG data A in the normal state; the identifier PNG_image_id [1] represents PNG data B in the selection state; and the identifier PNG_image_id [2] represents PNG data C in the execution state.","When the PNG data B of the button in the selection state of which the identifier PNG image_id is [1] is displayed by the command set_sound(1, 10), sound data identified by the identifier sound_id [10] is reproduced as an effect sound. Likewise, when the PNG data C of the button in the execution state of which the identifier PNG_image_id is [2] is displayed by the command set_sound(, ), sound data identified by the identifier sound_id [11] is reproduced as an effect sound.","Although not shown in , one or a plurality of types of sound data may be pre-stored in an internal memory or the like of the player. For example, predetermined sound data may be pre-stored in an internal non-volatile memory or the like of the player before shipment.","Alternatively, sound data as an effect sound may be prerecorded on the disc of which a graphics object  and a content as moving data have been recorded. When the content is reproduced from the disc, the sound data may be read. As a method for recording sound data on the disc, a file for the sound data is prepared. When the content is reproduced from the disc, the file is pre-read and stored in the memory of the player.","Alternatively, like a graphics object , PES packets that contain sound data are created. The PES packets are divided into TS packets. The TS packets are multiplexed with a clip AV stream.","Alternatively, sound data may be placed in the graphics object header  of the graphics object . Alternatively, sound data corresponding to a PNG image contained in the graphics object  may be contained in a region immediately preceded by the PNG image data region  (not shown in  to ).","In any method, since sound data can be pre-read from the disc and pre-stored in the memory of the player, when the state of a button created with a PNG image is changed to the selection state or the execution state, an effect sound can be generated. Sound data is assigned a unique identifier sound_id, the sound data can be uniquely identified.","2-14. About Methods for Storing Sound Data to Disc","There are three methods for storing sound data to the disc. Next, these methods will be described.\n\n","Next, with reference to , , and , (1) the method for multiplexing sound data with the graphics object  (hereinafter referred to as first storing method) will be described in detail.  and  shows an example of which sound data is added to the graphics object  and then multiplexed with a clip AV stream.",{"@attributes":{"id":"p-0486","num":"0531"},"figref":"FIG. 59A","b":["204","203","200","204","204","204","204","204","204","204","203","203","203","200"],"i":["n","n ","n "]},"The sound data A, B, . . . may be data that has not been compression-encoded for example AIFF (Audio Interchange File Format) file or WAVE file or data that has been compression-encoded for example MP3 (Moving Pictures Experts Group 1 Audio Layer 3) file, AAC (Advanced Audio Coding) file, or ATRAC (Adaptive Transform Acoustic Coding) file. When sound data that has been compression-encoded is contained, the player side should have an audio decoder in accordance with the compression-encoding system.",{"@attributes":{"id":"p-0488","num":"0533"},"figref":"FIG. 59B","b":["200","204","2","204","2","203","203","2","203","2","203","2","203"]},"In this case, the PNG data region  for button images is followed by the sound data region . The sound data region  contains sound data A- that is reproduced when the button is placed in the selection state and sound data B- that is reproduced when the button is placed in the execution state. Thus, when PNG data of a button image is displayed, sound data corresponding to a button state is reproduced. It is considered that an effect sound reproduced by the player is mainly used as a button click sound. Thus, in such a structure, the major purpose of the present invention can be sufficiently accomplished.",{"@attributes":{"id":"p-0490","num":"0535"},"figref":["FIG. 60","FIG. 44","FIG. 60","FIG. 44"],"b":["240","240"]},"A clip AV stream is input as an MPEG TS from a terminal  and supplied to a PID filter . The clip AV stream has a graphics object  that contains sound data. The PID filter  extracts moving picture data, sound data, and graphics object  from the clip AV stream. The extracted graphics object  is supplied to a GOBJ parser  through a buffer TBn B. The GOBJ parser  reads a graphics object header  from the graphics object . The GOBJ parser  extracts palette data from the graphics object  in accordance with the graphics object header  and separates the graphics object  into a display control command table , a PNG data region , and a sound data region  in accordance with the graphics object header .","The palette data and the display control command table  are supplied to a command processor\/graphic renderer . In addition, sound data A, B, . . . , of the sound data region  are supplied to the command processor\/graphic renderer  and then stored in corresponding buffers (not shown).","The command processor\/graphic renderer  reads sound data from the buffers in accordance with display control commands described in the display control command table  supplied from the GOBJ parser  and outputs the sound data. When the sound data A, B, . . . , and contained in the graphics object  have been compression-encoded, the command processor\/graphic renderer  decodes them and outputs the decoded sound data.","The sound data that is output from the command processor\/graphic renderer  is supplied to an audio mixer  and output to a presentation processor . When another sound data has been input to the audio mixer , this sound data is mixed with those sound data at a predetermined ratio and then output.",{"@attributes":{"id":"p-0495","num":"0540"},"figref":["FIG. 61","FIG. 59A","FIG. 59B","FIG. 47"],"b":"200"},"2-14b. Second Storing Method","Next, (2) the method for creating sound data files corresponding identifiers sound_id, sound data being not multiplexed with a clip AV stream (hereinafter this method is referred to as second storing method). For example, as shown in , a directory SOUND that contains sound data is placed under a directory BDAV. The directory SOUND contains PCM waveform data as sound data. For example, a sound data file \u201csound1.aiff\u201d having the AIFF format is placed in the directory SOUND. All sound data files placed in the directory SOUND are read when the disc is initially loaded into the player and then stored in an internal memory of the player.","Each piece of sound data is assigned a unique identifier sound_id. A script or the like calls desired sound data with an identifier sound_id from the memory.","In this case, as shown in , a sound id region  is disposed in a graphics object . Sound id data A and B are contained in the sound id region . In the example shown in , PNG data A, B, and C corresponding to a normal state, a selection state, and an execution state of a button are contained in the PNG data region . The Sound id data A and B are identifiers sound_id corresponding to the PNG data B and C, respectively. When the PNG data B is displayed, sound data corresponding to the identifier sound_id represented by the sound id data A stored in the memory of the player is reproduced.","For example, as shown in , PNG data and sound data may be correlated in accordance with the display control command table .","Unlike a display control command shown in  and , since sound data is identified with an identifier sound_id, an effect sound of sound data can be generated anytime not in synchronization with graphics that are displayed.","In this method, since sound data is read from the memory using an identifier sound_id, the number of types of effect sounds is restricted by the number of identifiers sound_id. In addition, the number of types of effect sounds that can be used is restricted by the capacity of the internal memory of the player.","Next, with referenced to , that method will be described in detail. When the disc  is loaded, a player initially accesses the disc. All sound data is read from a directory SOUND placed under a directory BDAV. The sound data (PCM data) that has been read is stored in an internal memory  of the player. At this point, a unique identifier sound_id is assigned to each piece of sound data. Alternatively, an identifier sound_id may be added to each piece of the sound data recorded on the disc .","In the example, 16 pieces of sound data are read from the disc . Identifiers sound_id=1 to 16 are assigned to those pieces of sound data. In addition, the data sizes of those pieces of the sound data are obtained. In the example shown in , it is assumed that in the example shown in  the pieces of the sound data assigned the identifiers sound_id=1 to 16 have data sizes of d bytes, d bytes, . . . , and d bytes, respectively.","For example, on a menu screen  that displays buttons A, B, and C, when an operation is preformed for the button C, sound data corresponding to an identifier sound_id assigned to the button C is read from a memory . In the example shown in , sound data corresponding to an identifier sound_id=1 is assigned to the execution state of the button C. Sound data that is read from the memory  is processed in a predetermined manner and temporarily stored in a buffer B. Thereafter, the sound data is supplied to an audio mixer . The audio mixer  mixes the sound data with sound data associated with for example moving picture data as a content main part and outputs the mixed data as a sound.","A buffer A temporarily stores sound data associated with for example moving picture data as a content main part. When timing at which sound data stored in the buffers A and B is read therefrom is adjusted, an effect sound corresponding to the operation of the button C is output from the buffer B at proper timing of sound data stored in the buffer A. In this example, with identifier sound_id=0, no-sound data reproduction mode is designated.","In such a model, the total capacity of sound data that can be read from the disc  is restricted to the capacity of the memory . In addition, the capacity of each piece of sound data is restricted in accordance with the capacity of the buffer B. In other words, when the capacity of the memory  is denoted by capacity M (bytes) and the capacity of the buffer B is denoted by capacity Dmax (bytes), it is necessary to satisfy the following two conditions.\n\n","In other words, when the conditions (1) and (2) are prescribed as rules on the player side and the disc producer side, reproduction compatibility of sound data such as effect sounds can be maintained.","As described above, in the case that sound data is not multiplexed with a clip AV stream (second storing method), when the disc is initially loaded into the player, all sound data is read therefrom. However, the preset invention is not limited to such an example. In other words, sound data can be read from the disc in a plurality of sessions. For example, all sound data used for one of sections of a scenario is read and stored in the memory. At this point, sound data stored in the memory for the preceding section of the scenario is erased. As a result, even if the data amount of sound data of one scenario exceeds the capacity of the memory, the sound data can be handled.","All sound data can be recorded in a predetermined region of the disc. Alternatively, sound data may be separately recorded in a plurality of regions of the disc. When sound data is separately recorded in a plurality of regions of the disc, sound data for sections of a scenario may be recorded at positions of the disc corresponding to the sections of the scenario. Alternatively, sound data may be downloaded from a server connected through a network.","In the method for multiplexing sound data with a clip AV stream (first storing method) shown in  and , the number of types of sound data is not restricted. As a result, different type of sound data can be assigned to each image. When necessary, sound data is supplied with a clip AV stream. Thus, a different type of sound data can be used whenever a clip AV stream is supplied. Moreover, in the first storing method, since sound data is read from a clip AV stream along with image data, the reading model can be simply structured. In addition, the number of files of sound data and the sizes of files are not restricted except for the capacity of the disc.","However, in the first storing method, when the same sound data is used for different graphics objects, since their graphics objects each should have the same sound data, the sound data becomes redundant. In addition, since sound data should be extracted from a graphics object, after a clip AV stream is demultiplexed, sound data should be separated from the graphics object.","2-14c. Third Storing Method","Next, (3) the method for creating one data file for a plurality of pieces of sound data, sound data being not multiplexed with a clip AV stream (hereinafter this method is referred to as third storing method) will be described. A plurality of pieces of sound data are contained in for example a file \u201cHdmvSound.bdmv\u201d. As shown in , the file \u201cHdmvSound.bdmv\u201d is placed under a directory BDAV of a management structure of files recorded on the recording medium defined in the \u201cBlu-ray Disc Rewritable Format Ver 1.0 part 3\u201d shown in . When the disc is loaded into the player, the file \u201cHdmvSound.bdmv\u201d is initially accessed and read. Before a clip AV stream (for example, a movie) recorded as a main content on the disc is read, the file \u201cHdmvSound.bdmv\u201d is preloaded to the memory of the player.","In , placed in the directory STREAM are clip AV streams as main contents of the disc.",{"@attributes":{"id":"p-0514","num":"0561"},"figref":"FIG. 65","b":"32"},"An argument of a for loop automatically assigns an identifier sound_id with which one piece of sound data is referenced. The for loop describes information of sound data referenced with the identifier sound_id corresponding to the argument.","A block attributes( ) describes an attribute of the sound data. A field channel_assignment describes a channel assignment of the sound data. The field channel_assignment describes an attribute for example monaural or two-channel stereo. A field sampling_frequency describes a sampling frequency of the sound data, for example 48 kHz. A field bits_per_sample describes the number of quantizer bits of the sound data, for example 16 bits.","A field sound_data_start_address has a data length of 32 bits. The field sound_data_start_address describes the start address of the block data_block of the start byte of sound data referenced with the field sound_id in the for loop. A field sound_data_length has a data length of 32 bits. The field sound_data_length describes the byte length of the sound data. After the for loop, a block data_block is placed through padding words. The block data_block is a region in which sound data is really placed.",{"@attributes":{"id":"p-0518","num":"0565"},"figref":"FIG. 66","b":["600","600","601","602"]},"Placed in the sound data portion  is sound data referenced with identifier sound_id=1 to identifier sound_id=n. For example, the end of particular sound data and the beginning of the next sound data are connected at a byte boundary. Likewise, sound data referenced with identifier sound_id=1 to identifier sound_id=n is successively placed. In the sound data portion , the start address is designated with the field sound_data_start_address in the for loop portion  whose argument corresponds to the identifier sound_id. A region from the designated address for the length designated by the field sound_data_length of the loop is referenced as sound data of the identifier sound_id corresponding to the argument of the loop.",{"@attributes":{"id":"p-0520","num":"0567"},"figref":["FIG. 67","FIG. 67","FIG. 63"],"b":["400","400","400","410"]},"As shown in , each piece of sound data is designated in the loop portion  of the file \u201cHdvmSound.bdmv\u201d in accordance with address information and data length information. Each piece of the sound data is identified by the corresponding identifier sound_id. In the example shown in , the file \u201cHdmvSound.bdmv\u201d contains m pieces of sound data. The identifiers sound_id=1, 2, . . . , and m are assigned to the m pieces of sound data. The capacity of each piece of sound data can be obtained with the data length information and the number of quantizer bits bits_per_sample corresponding to the identifier sound_id.","In this example, it is assumed that sound data has been encoded in accordance with the PCM system. However, the present invention is not limited to such an example. Sound data may have been compression-encoded in accordance with a predetermined system such as the MPEG1 layer 3 (mp3) system, the Advanced Audio Coding (AAC) system, or the Adaptive Transform Acoustic Coding (ATRAC) system and stored in a sound data portion . In this case, each piece of sound data is placed in the sound data portion  in such a manner that the end of each piece of sound data is connected to the beginning of the next piece of sound data.","For example, it is assumed that a menu screen  displays buttons A, B, and C. On the menu screen , the button C is composed of a button image set  that has button images C-, C-, and C- that represent a normal state, a selection state, and an execution state. When button images are changed in accordance with the three button states, the user can easily distinguish these states from each other. In the example shown in , sound data of identifier sound_id=2 is assigned to the button image C- of the selection state. Sound data of identifier sound_id=1 is assigned to the button image C- of the execution state. When the value of the identifier sound_id is \u201c0\u201d, although a button image is displayed, no sound is output.","When the user operates the button C to change the selection state to the execution state with the remote commander, the button image changes from the button image C- to the button image C-. In addition, the sound data of identifier sound_id=1 assigned to the button image C- is read from the internal memory  and reproduced.","In other words, the button image C- is displayed. In addition, the memory  is accessed in accordance with address information and data length information for identifier sound_id=1 correlated with the button image C- and sound data of identifier sound_id=1 is read from the memory . The sound data that is read from the memory  is temporarily stored in a buffer B and then supplied to an audio mixer . The audio mixer  mixes the sound data that has been read from the memory  with sound data corresponding to moving picture data of the main part of the content that has been output from a buffer A and output the mixed sound.","Like the second storing method shown in , in the third storing method, the total capacity of sound data that can be read from the disc  and the capacity of each piece of sound data are restricted in accordance with the capacity of the memory  and the capacity of the buffer B.","Next, an example of the structure of a graphics object according to the third storing method will be described. In the third storing method, button images that compose a menu screen of the Graphical User Interface (GUI) using the graphics plane  are encoded as one stream. Hereinafter, a stream of which button images have been combined is referred to as an interactive graphics stream.","For example, on the menu screen  shown in , button images of the buttons A, B, and C are combined as an interactive graphics stream  (see ) and encoded. When one button such as the button C is composed of a button image set  having a plurality of button image data C-, C-, and C-, they are encoded as the interactive graphics stream  along with the button image data of the buttons A and B. The interactive graphics stream  is multiplexed with the transport stream and recorded on the disc.",{"@attributes":{"id":"p-0529","num":"0576"},"figref":["FIG. 68A","FIG. 68B","FIG. 68A"],"b":["700","700","701","702","702","702","702","702","702","702"]},"As shown in , the interactive graphics stream  is placed in payloads of a plurality of transport packets assigned the same PID. The transport packets are multiplexed as a transport stream.",{"@attributes":{"id":"p-0531","num":"0578"},"figref":"FIG. 69","b":["701","701","701"]},"The button layout and command describe one or more button information , , . . . , and so forth that compose a menu screen as a GUI. In the button information , a field button_number describes an identifier button_number that identifies each button. Each button is identified and referenced with the identifier button_number. A field selected_state_sound_id describes an identifier sound_id that referenes sound data correlated with a button image of \u201cselection state\u201d. A field activated_state_sound_id describes an identifier sound_id that references sound data correlated with a button image of \u201cexecution state\u201d. As shown in , a field neibour_info describes button numbers Upper_button_number, Lower_button_number, Left_button_number, and Right_button_number adjacent to this button on the screen.","A field Normal_state_object_id describes an identifier object_id of a button image referenced when the button is in the \u201cnormal state (non selection state)\u201d. A field Selected_state_object_id describes an identifier object_id of a button image referenced when the button is in the \u201cselection state\u201d. A field Activates_state_object_id describes an identifier object_id of a button image referenced when the button is in the \u201cexecution state\u201d. A field command describes operation information assigned to a button that is in the execution state.","2-15. Another Example of Plane","In the foregoing example, as shown in , , and , for the graphics plane , YCbCr (4:4:4) or RGB (4:4:4) can be selected as a color system. However, the present invention is not limited to such an example. In other words, as shown in , a graphics plane \u2032 may be defined mainly for bit map images for buttons. As shown in , like the subtitle plane , the graphics plane \u2032 may be composed of 1920 pixels\u00d71080 lines, the sampling depth of each pixel being eight bits, the color system using a palette having 256 colors and eight-bit color map addresses.","In this case, the moving picture plane , the subtitle plane , and the graphics plane \u2032 are combined by a structure shown in . For simplicity, in , similar portions to those in  are denoted by similar reference numerals and their description will be omitted.","Image data of the graphics plane \u2032 is input to a palette table A and output as image data of RGB (4:4:4). When intransparency of the alpha-blending has been designated for the image data, designated intransparency \u03b12 (0\u2266\u03b12\u22661) is output from the palette table A. Input data and output data of the palette table A and palette data stored in the palette table A are the same as those shown in  and . Thus, their description will be omitted.","RGB data that is output from the palette table A is supplied to an RGB\/YCbCr converting circuit B and converted into YCbCr data as unified data of moving picture data. The YCbCr data that is output from the RGB\/YCbCr converting circuit B is input to a multiplying device .","When image data that is used in the graphics plane \u2032 is data in accordance with the PNG format, intransparency data \u03b12 (where 0\u2266\u03b12\u22661) can be set to each pixel of the image data. The intransparency data \u03b12 is supplied to a multiplying device . The multiplying device  multiplies a luminance signal Y and color difference signals Cb and Cr of the YCbCr data that are input from the RGB\/YCbCr converting circuit B by the intransparency data \u03b12. The multiplied result of the multiplying device  is input to one input terminal of an adding device . The complement of the intransparency data \u03b12, namely (1\u2212\u03b12), is supplied to a multiplying device .","2-16. About Another Example of Decoder Model",{"@attributes":{"id":"p-0539","num":"0586"},"figref":["FIG. 74","FIG. 39","FIG. 74","FIG. 39"],"b":["100","200","12","100"]},"Sound data that is not multiplexed with the clip AV stream is input as data of for example an input channel () to an input terminal . Thereafter, the sound data is supplied to a content buffer  through switch circuits  and . On the other hand, a clip AV stream of which sound data has been multiplexed with a graphics object  is input to an input terminal . A PID filter  separates the graphics object  from the clip AV stream and temporarily stores the graphics object  in a buffer TBn A. Thereafter, the graphics object  is supplied to a content buffer  through the switch circuit .","A graphics object  that does not contain sound data is multiplexed with an clip AV stream and supplied to the input terminal . The PID filter  separates a transport packet that composes the graphics object  from the clip AV stream. The transport packet is temporarily stored in a buffer TBn B or a buffer TBn C. The transport packet stored in the buffer TBn B is supplied to a buffer Bn B. The graphics object  is collected in accordance with the PID header. The graphics object  is supplied to a graphics decoder A  through a switch circuit . From the transport packet stored in the buffer Bn C, the graphics object  is collected through the buffer Bn C. The graphics object  is supplied to a graphics decoder B  through a switch circuit .","The graphics decoders A  and B  remove header information from the supplied transport packets, decode image data placed in the transport packets, and obtain image data for bit map data for subtitles or graphics.","On the other hand, image data placed in the graphics object  that contains sound data is read from the content buffer . The image data is supplied to the graphics decoders A  and B  through the switch circuits  and , respectively.","In the example shown in , the graphics decoder A  decodes PNG format image data. In contrast, the graphics decoder B  decodes JPEG format image data. The graphics decoders A  and B  may decode other format image data. Alternatively, the graphics decoders A  and B  may decode different format image data.","An output of the graphics decoder A  is supplied to an input terminal B of a switch circuit  and an input terminal B of a switch circuit  and then supplied to a sub picture plane  and a graphics plane  through the switch circuits  and , respectively.","A multimedia engine  has a sound player D along with the structure shown in . A buffer  has a sound buffer E along with the structure shown in . A sound player D decodes sound data that is read from the content buffer  through the sound buffer E, obtains the decoded sound data as for example linear PCM audio data, and outputs it. The sound data that is output from the sound player D is supplied to a presentation processor . The presentation processor  mixes the sound data that has been supplied from the sound player D with sound data that has been supplied from an audio decoder  and outputs the mixed sound data to an output terminal .","Sound data as an effect sound such as a click sound that is generated when for example a button image is clicked is reproduced by the sound player D. The sound data is stored in the sound buffer E and reproduced by the sound player D. The sound player D performs a reproducing process as for example software for the sound data.","The multimedia engine  reads an ECMA script stored in for example a code buffer , analyzes the ECMA script, reads another ECMA script and an HTML document from the code buffer , and reads image data and audio data from the content buffer . Sound data can be stored in the content buffer  like other data.","In addition, the multimedia engine  receives user's commands from the remote controller commander, the pointing device, and so forth and processes the commands. The multimedia engine  generates control signals corresponding to the process results for the user's commands and to each script. The control signals are supplied to the graphics decoders A  and B , the audio decoder , an MPEG video decoder , and a system decoder .","Image data that has been processed by a graphics renderer C is supplied to a sub picture plane  and a graphics plane  through the switch circuits  and , respectively. The sub picture plane  and the graphics plane  are composed of for example frame memories. The sub picture plane  and the graphics plane  correspond to the subtitle plane  and the graphics plane \u2032 shown in , respectively.","In this example, it is assumed that image data supplied from the graphics renderer C to the sub picture plane  and the graphics plane  is bit map data of which image data of for example the PNG format or JPEG format has been decoded by the graphics renderer C.","In addition, the multimedia engine  supplies to the presentation processor  a control signal that causes one of the sub picture plane , the graphics plane , and the moving picture plane  to be switched to another plane. The multimedia engine  supplies to the presentation processor  a control signal that controls an output of the audio stream.","Image data on the sub picture plane  is supplied to a palette  corresponding to the palette table  shown in . The 256-color palette is referenced with an index. As a result, RGB data and intransparency data \u03b11 are output. The RGB data is supplied to an RGB\/YCbCr converting circuit  corresponding to the RGB\/YCbCr converting circuit  shown in . As a result, the color system of the image data is converted from RGB (4:4:4) into YCbCr (4:4:4). The YCbCr data that is output from the RGB\/YCbCr converting circuit  is supplied to the presentation processor .","Image data on the graphics plane  is supplied to a palette  corresponding to the palette table A shown in . The 256-color palette is referenced with an index. As a result, RGB data and intransparency data \u03b12 are output. The RGB data is supplied to an RGB\/YCbCr converting circuit  corresponding to the RGB\/YCbCr converting circuit B shown in . As a result, the color system of the image data is converted from RGB (4:4:4) into YCbCr (4:4:4). The YCbCr data that is output from the RGB\/YCbCr converting circuit  is supplied to the presentation processor .","In addition, moving picture data on the moving picture plane  is supplied to the presentation processor  through an up\/down converter .","As described above, the presentation processor  performs an alpha-blending process using the intransparency \u03b11 of the image data on the subtitle plane  (sub picture plane ) and the intransparency \u03b12 of the image data on the graphics plane \u2032 (graphics plane ). This process mixes image data on the moving picture plane , the image data on the subtitle plane , and the image data on the graphics plane \u2032. The presentation processor  can perform an effect process for the image data in real time. The image data that has been mixed between planes and for which an effect process has been performed is supplied to an output terminal .","2-17. Further Example of Decoder Model",{"@attributes":{"id":"p-0557","num":"0604"},"figref":["FIG. 75","FIG. 75","FIG. 39","FIG. 74"],"b":"100"},"As the internal memory of the player, a sound buffer E of a buffer  can be used. For example, sound data that is read when the disc is initially accessed is input from a terminal . The sound data is supplied to the sound buffer E through a switch circuit  and a content buffer . When a program code stored in a code buffer  is executed, necessary sound data is read from the sound buffer E and input from a terminal .","A real time stream that is input as an MPEG ES from a terminal  is supplied to a PID filter . When a PID of a transport packet represents that it contains an interactive graphics stream , the transport stream is temporarily stored in a buffer A. The transport stream is read at proper timing and input to a switch circuit  that has selected an input terminal B and stored in a content buffer  through the switch circuit .","An interactive composition segment  of the interactive graphics stream  is read from the content buffer  and supplied to a multimedia engine . In addition, button image data , , . . . are read from the content buffer  and supplied to a graphics decoder B  through a switch circuit .","Sound data that is input from the terminal  is temporarily stored in a buffer . A mixer  mixes the sound data supplied from the terminal  with sound data that has been supplied from an audio decoder  at a predetermined mixing ratio and supplies the mixed sound data to a presentation processor . The mixing ratio of the mixer  can be set on the player decoder \u2033 side under the control of a sound player D corresponding to user's data input.","In , for convenience, the buffer  is independent from the mixer . However, actually, the buffer  and the mixer  are built in the presentation processor . Thus, in consideration of the relation with the structure shown in , the buffer  corresponds to the buffer B, and the mixer  corresponds to the audio mixer . The buffer A shown in  is built in the presentation processor .","When sound data has been compression-encoded and recorded on the disc, sound data that is read from the disc is decoded as linear PCM audio data and stored in the buffer . For example, the sound player D decodes compression-encoded sound data that has been read from the disc and stores the decoded sound data to the sound buffer E. Sound data can be decoded by the audio decoder . Alternatively, the sound data may be decoded by software.","In the foregoing example, in the decoder model shown in , before a main content such as a movie recorded on the disc is reproduced, sound data as an effect sound is preloaded from the disc and stored in the internal memory of the player decoder. When the directory and file structures shown in  are used, only one file \u201cHdmvSound.bdmv\u201d for sound data as an effect sound can exist in the directory BDMV. When the player initially accesses the disc, the player preloads the sound data file for an effect sound to the internal memory of the player.","Besides this example, as shown in , it can be thought that a play list is accompanied by data for reproducing an effect sound. In this case, with for example the sub play item shown in , sound data to be reproduced as an effect sound assigned to a button can be referenced. For example, a file name (file \u201cHdmvSoundxx.bdmv\u201d) for sound data is described in a sub play item.","Alternatively, as a method for adding reference information for a file that contains sound data as an effect sound, the block UIAppInfoPlayList( ) shown in  may be used. In this case, a field for the file name \u201cHdmvSoundx.bdmv\u201d may be added to the syntax of the block UIAppInfoPlayList( ).","Before reproducing a play list, the player preloads sound data referenced with reference information (for example, a sub play item) to a file that contains sound data as an effect sound to the internal memory.",{"@attributes":{"id":"p-0568","num":"0615"},"figref":["FIG. 77","FIG. 77","FIG. 65","FIG. 66"],"b":"602"},"3. Second Mode of Present Invention","Next, a second mode of the present invention will be described. According to the first mode of the present invention, a reproduction program for controlling reproduction for data on the disc is described with an ECMA script and an HTML document. In contrast, according to the second mode, a reproduction program is described with an original data structure and a descriptive language rather than an ECMA script and an HTML document. A scenario descriptive language that is used in the second mode of the present invention defines a command group of original display control commands for subtitle images and button images on the basis of modified navigation commands for the DVD video. Thus, according to the second mode of the present invention, a menu screen for the blu-ray disc can be more suitably and flexibly displayed than that of the first mode.","3-1. About Scenarios","According to the second mode of the present invention, since the originally defined scenario descriptive language is used, it is not necessary to define event handlers unlike with the case that an ECMA script is used in the first mode. For example, since the originally defined scenario descriptive language can pre-define events necessary for executing a scenario, events for a scenario does not need to be defined in a program.","Since the originally defined scenario descriptive language is used, the internal structure of the scenario shown in  does not need the global event handler definition  and the local event handler definition .  shows a scenario \u2032 described according to the second mode. A play list A described as an entry play list at the beginning of the scenario \u2032 is initially executed after the disc is loaded into the player. When a predetermined command is issued on the menu screen, a play list B is reproduced. After the play list B has been reproduced, a play list C is reproduced. In the example shown in , when the play list C is reproduced, graphics data A is read and a screen A for prompting the user to select a branch of the story is displayed.","Thereafter, as shown in  in the first mode, the scenario \u2032 is reproduced. When a mark has been set in a play list, a branch of a play list or a joint of play lists can be performed at the position of the mark.","Each play list has a sequence of commands (a program) for operations that are performed when a mark, user input, or a player's operation change is detected. The player executes the program to perform the operations.","Even if any one of play lists A to M of the scenario \u2032 is being reproduced, when the menu button on the remote control commander is pressed, a menu screen  for a list of scenarios is displayed (see ). Next, a process for reproducing a play list for the menu screen  will be described. In this case, as an event handler corresponding to an event (menu button \u201con\u201d event) that takes place when the menu button on the remote control commander is pressed, a command that causes a play list for the menu screen  to be displayed is described as one scenario.","3-2. Categories of Scenarios","One scenario is defined in the BDVM directory. One scenario is composed of one or more play lists. Categories of scenarios will be described with reference to , , , and . Based on connections of play lists, structures of scenarios can be largely categorized as three types that are (1) single play list, (2) sequential play list, and (3) multiple play list as shown in .","The single play list, categorized as (1), is a scenario composed of one play list as shown in . For the single play list, a time line can be defined. There is no interrupt during reproduction of the scenario. When the content of the single play list is a movie, after the disc is loaded, only the main part of the movie is reproduced.","The sequential play list, categorized as (2), is a scenario composed of a plurality of play lists that are linearly arranged without a branch as shown in . The play lists are arranged in such a manner that the end of one play list is connected to the beginning of the next play list. In the sequential play list, a time line can be defined for each play list. When the content of the sequential play list is a movie, the scenario is composed of a menu screen and a main part of a movie. After the disc is loaded, a play list that causes a menu screen to be displayed is executed. When the reproduction of the main part of the movie is designated on the menu screen, the next play list is executed and the main part of the movie is reproduced.","The multiple play list, categorized as (3), is a scenario that has a connection of a branch or a joint of play lists. In the multiple play list, a time line cannot be defined through all play lists. Instead, a time line is defined in each play list. With the multiple play list, an interactive function and a game function for varying reproduction contents in accordance with a user's input can be accomplished. When the content of the multiple play list is a movie, a multiple angle function that allows the user to select a desired angle from various angles photographed for the same scene can be accomplished.","As will be described later, one scenario is defined for the BDVM directory. However, it is necessary to allow the user to recognize the scenario in smaller units. Nevertheless, the unit of a play list does not always accord with a unit that the user can recognize. When one play list describes three movies, it is necessary to allow the user to see a search point of each movie. A search point (entry point) that is independent from the structure of a play list is hereinafter referred to as title and\/or chapter.","Next, with reference to , titles and chapters will be described. A title represents any reproduction start point in a scenario. In the example shown in , a title  is placed at the beginning of a play list A. A title  is placed in the middle of a play list D. A region after the beginning of the play list A until the title  is the title . A chapter is a unit of which a title is sub-divided. The can also recognize a chapter as a reproduction start point. The title  is sub-divided into chapters. In the example shown in , the title  has chapters , , and . Thus, the title  is sub-divided into three portions. As shown in , each of a title and a chapter can be placed in the middle of a play list.","3-3. About Virtual Player Model","A scenario described in the scenario descriptive language according to the second mode of the present invention can be reproduced by the BD virtual player model shown in  according to the first mode of the present invention. After the disc is loaded into a BD virtual player , it reads as a PBC program  a scenario described in the scenario descriptive language originally defined in the second mode of the present invention from the disc and operates in accordance with the description of the scenario. The BD virtual player  is controlled corresponding to an event that takes place while the BD virtual player  is operating.","A scenario has two regions for commands including a program having commands that cause the player to be operated. The two regions are referred to as global command region and local command region.","The global command region has global commands that are effective for the entire scenario. For example, the global program region describes a program that causes the player to initialize parameters when the disc is loaded into the player and to jump to a play list that composes a menu screen. The local command region describes programs for play lists. In the second mode of the present invention, local commands are categorized as four types of commands that are pre-commands, play item commands, post commands, and button commands.",{"@attributes":{"id":"p-0584","num":"0631"},"figref":["FIG. 82A","FIG. 82B","FIG. 82A"],"b":["30","30","30","32","31","32"]},"A command group (a program) that is initially read and executed when the disc is loaded into the player is referred to as global commands. The global commands describe for example an advertisement picture (trailer) and a jump command that jumps to a play list that composes a menu screen. The player reproduces the play list in accordance with the commands.",{"@attributes":{"id":"p-0586","num":"0633"},"figref":["FIG. 82B","FIG. 28"],"b":["30","40","30","32","41","42","30"]},"Next, with reference to  and , reproduction of a play list in the play list reproduction phase will be described.  shows an example of which a play list is composed of a single play item. A play list has a pre-command region, a play item command region, and a post-command region that describes respective programs. In the play list reproduction phase, a pre-command of the pre-command region is executed (at step S). After the pre-command has been executed, the player enters a play item reproduction phase for play items that compose the play list (at step S). In the play item reproduction phase, a stream whose start point and end point are designated by a play item is reproduced (at step S). When the stream has been reproduced up to the end point, the play item command is executed (at step S). After the play item command has been executed, a post command of the post-command region is executed (at step S). As a result, the play list has been reproduced.","The post command is normally a jump command that describes as a jump command a play list to be reproduced next or a play list that composes a menu screen. When there is no a jump command, the player enters the stop state (the state B shown in ).",{"@attributes":{"id":"p-0589","num":"0636"},"figref":"FIG. 83B"},"When the play list describes a plurality of play items, in the play list reproduction phase, a pre-command is executed (at step S). In the next play item reproduction phase, a stream is reproduced from the start point to the end point of each play item and a play item command is executed for each play item. In the example shown in , a first play item stream is reproduced (at step S-). Thereafter, the corresponding play item command is executed (at step S-). Thereafter, a second play item stream (not shown) is reproduced (at step S-). The corresponding play item command is executed (at step S-). These operations are repeated for the number of the play items. After the last play item stream has been reproduced (at step S-) and the corresponding play item command has been executed (at step S-), the play item reproduction phase is completed. After the play item reproduction phase has been completed, a post command is executed (at step S). As a result, the play list reproduction phase is completed.","According to the second mode of the present invention, scenarios, play lists, and play items that are executed on the BD virtual player  can be hierarchically considered. In other words, as shown in , one scenario layer  is placed above a BD virtual player layer . A play list layer  that has one or a plurality of play lists is placed above the scenario layer . A play item (PI) layer  is placed above the play list layer . Each play list may have one or a plurality of play items.","In such a hierarchical structure, play lists and play items are executed by the BD virtual player through the scenario layer . Thus, when control commands for play lists are described in a scenario, branches and so forth of the play lists can be easily accomplished. This applies to play items as shown in .","3-4. About Syntax","Next, a method for storing commands and databases that describe a scenario to the disc according to the second mode of the present invention will be described. In the second mode of the present invention, it is assumed that data necessary for accomplishing an extended function of the BDAV format is described in a scenario file \u201cscenario.pbc\u201d. The scenario file \u201cscenario.pbc\u201d is placed under the directory BDAV in the management structure for files recorded on the recording medium defined in the \u201cBlu-ray Disc Rewritable Format Ver 1.0 part 3\u201d shown in .",{"@attributes":{"id":"p-0594","num":"0641"},"figref":"FIG. 86"},"A block GlobalCommand( ) starts from a fixed position, the 41-st byte from the beginning of the file. The block GlobalCommand( ) describes a program that is executed when the player initially accesses the disc (namely, when the player initially reproduces data from the disc after it is loaded into the player). The global command is placed in the block GlobalCommand( ). The block GlobalCommand( ) is followed by any number of padding_word so that blocks are spaced apart from each other.","The block TitleEntry( ) describes a list of search points in a scenario. One scenario is created for the BDAV directory. A scenario defines the reproduction order of a plurality of play lists placed under the BDAV directory. The user can see a scenario as if it were composed of a plurality of \u201ctitles\u201d rather than one image\/sound unit.","When one disc contains three movies, although the disc has only one scenario that defines the reproduction order of the movies, the user will see the disc as if it contained three titles. Alternatively, the user will see that disc as if it were divided into four titles including a title menu screen with which the user can select one of the three titles. Since the user considers a menu screen as one image\/sound unit, according to the second mode of the present invention, the menu screen is considered as a kind of a title.","Thus, since the unit of a scenario that defines connections of play lists is different from the unit that the user considers as a block of image\/sound, search points need to defined in a scenario. A search point in a scenario is referred to as a title entry.","The block Scenario( ) describes a \u201cscenario\u201d. The block Scenario( ) describes information about the reproduction order of play lists, a local command area of each play list, and so forth.",{"@attributes":{"id":"p-0600","num":"0647"},"figref":"FIG. 87"},{"@attributes":{"id":"p-0601","num":"0648"},"figref":"FIG. 88"},"A field number_of_Chapters describes the number of chapters described in a for loop that follows. As described above, chapters are divided portions of a title. The user can see chapters like titles. Chapters are used as search points of a scenario. A field Title_number has a data length of 16 bits, an unsigned integer, and describes a title number to which a chapter corresponding to the current loop counter value of the for loop (hereinafter, the chapter is referred to as this chapter). A field chapter_entry_Playlist_file_name describes a file name of a play list file of a play list that this chapter represents. A field chapter_ref_to_PlayItem_id describes a play item number that this chapter represents. A field chapter_time_stamp describes the time of a play item that this chapter represents.","A block Title_Menu_Call_PL( ) describes play lists that compose a menu displayed when the user causes the player to display titles of the disc. The user designates a title by pressing for example a title menu key on a remote commander that remotely operates the player. Each scenario has one title menu. The title menu is a menu with which the user can see search points of titles. When the user selects his or her desired title on the title menu with for example the remote commander, the player obtains a play list from a title entry list corresponding to information described in the for loop after the field number_of_Titles and starts reproducing the play list.","In the block Title_Menu_Call_PL( ), a field flags describes attribute information about a title menu. A field TitleMenu_entry_PlayList_name describes a play list that composes a title menu or a play list that is an entry point of a play list group. A field TitleMenu_ref_to_PlayItem_id describes a play item number of a play item with which a play list starts. When a play list is reproduced from the beginning, the value of the field TitleMenu_ref_to_PlayItem_id is [0].","A field TitleMenu_chapter_time_stamp describes the time of a play item. When a play item is reproduced from the beginning, the field TitleMenu_chapter_time_stamp describes the time of the beginning of the play item. A field UOP_mask_table( ) describes information about a user's operation that is restricted. When the user performs an operation described in the field UOP_mask_table( ), the player does not respond to the user's operation. When the user is prohibited from performing a fast forward operation, a user's operation that is prohibited is described in the field UOP_mask_table( ).",{"@attributes":{"id":"p-0606","num":"0653"},"figref":"FIG. 89"},"The for loop is followed by data of this play list. A field flags describes attribute information of a play list. Since data described in the field flags do not directly relate to the second mode of the present invention, the description will be omitted. A field PL_UOP_mask_table( ) describes information about a user's operation that is restricted for each play list. While this play list is being reproduced, only a user's operation permitted in both a command UOP_mask_table( ) (that will be described later) and the field PL_UOP_mask_table( ) can be performed. However, eventually, it is determined whether or not a user's operation can be performed in accordance with data described in a block PI_UOP_mask_table( ), that will be described later, along with the foregoing command and field.","A field Parental_level describes information necessary for restricting audience who watch this play list. The information describes ages and age groups of audience who can watch this play list.","A field number_of_Pre_Commands describes the number of commands (pre-commands) that compose a program executed before this play list is reproduced. The programs are described in a field PL_Command(i). A field number_of_Post_Commands describes the number of commands that compose a program executed after this play list is reproduced (post-commands). A program is described in a field Pl_Command(i). A field Pre_Commands_start_id describes the start number of a program that is executed in the command table before the play list is reproduced. The number corresponds to a parameter i of the field PL_Command(i). A field Post_Commands_start_id describes the start number of a program that is executed in the command table after the play list is reproduced. The number corresponds to the parameter i of the field PL_Command(i).","A field number_of_PlayItems describes the number of play items that compose this play list. A field PI_UOP_mask_table( ) describes information about a user's operation that is restricted for each play item. Only a user's operation permitted in the three types of tables, which are the command UOP_mask_table( ) (that will be described later), the command PL_UOP_mask_table( ), and the field PI-UOP-mask-table can be performed while the play item is being reproduced.","A field PI_Commands_Start_id describes the start number of a command that is executed in the command table after the play item is reproduced. The number represents the parameter i of the field PL_Command(i). A field number_of_PL_Commands describes the number of commands in the command table represented by a for loop that follows. A command contained in the field PL_Command(i) is successively assigned the number i. A field PL_Command(i) describes one command. The number i is referenced from the field Pre_Commands_start_id, the field Post_Commands_start_id, the field PI_Commands_start_id, and so forth.","3-5. About Commands",{"@attributes":{"id":"p-0612","num":"0659"},"figref":["FIG. 90","FIG. 90"],"b":"30"},"Next, methods for designating the reproduction start position will be described. A method LinkPlayList(playListNumber) starts the reproduction of a play list designated by \u201cplayListNumber\u201d. A method LinkPlayItem (playListNumber, playItemNumber) starts the reproduction of a designated play item in a designated play list. \u201cplayItemNumber\u201d is \u201cPlayItem_id\u201d whose value starts from \u201c0\u201d. When the value of \u201cplayItemNumber\u201d is designated \u201c0\u201d, the play list to which the play item belongs is reproduced from the beginning.","A method Link(position)(object) jumps in a scenario from the current position to the preceding or following play list, play item, or chapter. A parameter \u201cposition\u201d describes one of \u201cprev\u201d, \u201cnext\u201d, \u201ctop\u201d, \u201cparent\u201d, and \u201ctail\u201d. A parameter \u201cobject\u201d describes a jumping method for an object (play list, play item, or chapter).","A method Exit stops the reproduction of a scenario. In this case, the value of the standard register is not held. A method RSM causes resume information stored in the memory of the player to be called, the resume information to be set to the register, and a scenario to be reproduced.","Next, methods for getting the states of the player will be described. A method getMenuDescriptionLanguage( )gets the language in which the menu is displayed. A method getScenarioNumber( ), a method getPlayListNumber( ), and a method getChapterNumber( ) gets a scenario number, a play list number, and a chapter number that are being reproduced, respectively. A method getPlayerSupport( ) gets version information of the player.","Next, methods for video streams will be described. A method getVideoStreamAvailability( ) gets information that represents whether or not a designated video stream is contained. A method setVideoStreamNumber( ) gets a video stream to be decoded. A method getVideoStreamNumber( ) gets a video stream number that has been selected. A method getVideoStreamAttr( ) gets attributes of a video stream that has been selected. The attributes are for example encoding system of the video stream, resolution, aspect ratio, display mode in the case that the aspect ratio is 4:3, and presence\/absence of closed caption. A method setAngleNumber( ) describes an angle number. A method getAngleNumber( ) gets an angle number that has been selected. A method getMaxVideoStream( ) gets the maximum number of video streams.","To reproduce contents data from the disc in accordance with the scenario file \u201cscenario.pbc\u201d, an engine that analyzes a scenario descriptive language according to the second mode is added to the multimedia engine  of the player decoders , \u2032, and \u2033 shown in , , and  according to the first mode.","When the disc is loaded into a drive device (not shown) of the player decoder \u2032 shown in , first of all, the scenario file \u201cscenario.pbc\u201d is reproduced. The reproduced scenario file \u201cscenario.pbc\u201d is input as a store object from the input terminal  to the player decoder \u2032. The scenario file \u201cscenario.pbc\u201d is supplied to the code buffer  through the switch circuit . The scenario file \u201cscenario.pbc\u201d is analyzed by the scenario file analyzing engine of the multimedia engine . Scenario data is read corresponding to the analyzed result. Moving picture data displayed on the moving picture plane , image data displayed on the subtitle plane  and the graphics plane  (or graphics plane \u2032), and another scenario file, sound data, and so forth that are read from a play list file and a scenario file are read from the disc.","4. Others","In the foregoing example, the first, second, and third storing methods for sound data are applied to the first mode of the present invention. However, the first, second, and third storing method for sound data can be applied to the second mode of the present invention.","In the foregoing example, the present invention is applied to the blu-ray disc. However, the present invention can be applied to large capacity disc-shaped recording mediums of other systems.","Although the present invention has been shown and described with respect to a best mode thereof, it should be understood by those skilled in the art that the foregoing and various other changes, omissions, and additions in the form and detail thereof may be made therein without departing from the spirit and scope of the present invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The invention will become more fully understood from the following detailed description, taken in conjunction with the accompanying drawing, wherein similar reference numerals denote similar portions, in which:",{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":["FIG. 2A","FIG. 2B","FIG. 2C"]},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 4A","FIG. 4B","FIG. 4C"]},{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0076","num":"0075"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0079","num":"0078"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0082","num":"0081"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 29A","FIG. 29B"]},{"@attributes":{"id":"p-0084","num":"0083"},"figref":["FIG. 30A","FIG. 30B","FIG. 30C","FIG. 30D"]},{"@attributes":{"id":"p-0085","num":"0084"},"figref":["FIG. 31A","FIG. 31B","FIG. 31C","FIG. 31D"]},{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0087","num":"0086"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0088","num":"0087"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0089","num":"0088"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0091","num":"0090"},"figref":"FIG. 37"},{"@attributes":{"id":"p-0092","num":"0091"},"figref":"FIG. 38"},{"@attributes":{"id":"p-0093","num":"0092"},"figref":"FIG. 39"},{"@attributes":{"id":"p-0094","num":"0093"},"figref":"FIG. 40"},{"@attributes":{"id":"p-0095","num":"0094"},"figref":"FIG. 41"},{"@attributes":{"id":"p-0096","num":"0095"},"figref":["FIG. 42A","FIG. 42B","FIG. 42C"]},{"@attributes":{"id":"p-0097","num":"0096"},"figref":"FIG. 43"},{"@attributes":{"id":"p-0098","num":"0097"},"figref":"FIG. 44"},{"@attributes":{"id":"p-0099","num":"0098"},"figref":["FIG. 45A","FIG. 45B","FIG. 45C","FIG. 45D"]},{"@attributes":{"id":"p-0100","num":"0099"},"figref":"FIG. 46"},{"@attributes":{"id":"p-0101","num":"0100"},"figref":"FIG. 47"},{"@attributes":{"id":"p-0102","num":"0101"},"figref":"FIG. 48"},{"@attributes":{"id":"p-0103","num":"0102"},"figref":["FIG. 49A","FIG. 49B"]},{"@attributes":{"id":"p-0104","num":"0103"},"figref":["FIG. 50A","FIG. 50B"],"b":["1","1","2","2","1","1","2","2"]},{"@attributes":{"id":"p-0105","num":"0104"},"figref":"FIG. 51"},{"@attributes":{"id":"p-0106","num":"0105"},"figref":"FIG. 52"},{"@attributes":{"id":"p-0107","num":"0106"},"figref":["FIG. 53A","FIG. 53B","FIG. 53C","FIG. 53D"]},{"@attributes":{"id":"p-0108","num":"0107"},"figref":["FIG. 54A","FIG. 54B"]},{"@attributes":{"id":"p-0109","num":"0108"},"figref":["FIG. 55A","FIG. 55B"]},{"@attributes":{"id":"p-0110","num":"0109"},"figref":["FIG. 56A","FIG. 56B"]},{"@attributes":{"id":"p-0111","num":"0110"},"figref":"FIG. 57"},{"@attributes":{"id":"p-0112","num":"0111"},"figref":"FIG. 58"},{"@attributes":{"id":"p-0113","num":"0112"},"figref":["FIG. 59A","FIG. 59B","FIG. 59C"]},{"@attributes":{"id":"p-0114","num":"0113"},"figref":"FIG. 60"},{"@attributes":{"id":"p-0115","num":"0114"},"figref":"FIG. 61"},{"@attributes":{"id":"p-0116","num":"0115"},"figref":"FIG. 62"},{"@attributes":{"id":"p-0117","num":"0116"},"figref":"FIG. 63"},{"@attributes":{"id":"p-0118","num":"0117"},"figref":"FIG. 64"},{"@attributes":{"id":"p-0119","num":"0118"},"figref":"FIG. 65"},{"@attributes":{"id":"p-0120","num":"0119"},"figref":"FIG. 66"},{"@attributes":{"id":"p-0121","num":"0120"},"figref":"FIG. 67"},{"@attributes":{"id":"p-0122","num":"0121"},"figref":["FIG. 68A","FIG. 68B"]},{"@attributes":{"id":"p-0123","num":"0122"},"figref":"FIG. 69"},{"@attributes":{"id":"p-0124","num":"0123"},"figref":"FIG. 70"},{"@attributes":{"id":"p-0125","num":"0124"},"figref":"FIG. 71"},{"@attributes":{"id":"p-0126","num":"0125"},"figref":"FIG. 72"},{"@attributes":{"id":"p-0127","num":"0126"},"figref":"FIG. 73"},{"@attributes":{"id":"p-0128","num":"0127"},"figref":"FIG. 74"},{"@attributes":{"id":"p-0129","num":"0128"},"figref":"FIG. 75"},{"@attributes":{"id":"p-0130","num":"0129"},"figref":"FIG. 76"},{"@attributes":{"id":"p-0131","num":"0130"},"figref":"FIG. 77"},{"@attributes":{"id":"p-0132","num":"0131"},"figref":"FIG. 78"},{"@attributes":{"id":"p-0133","num":"0132"},"figref":"FIG. 79"},{"@attributes":{"id":"p-0134","num":"0133"},"figref":["FIG. 80A","FIG. 80B","FIG. 80C"]},{"@attributes":{"id":"p-0135","num":"0134"},"figref":"FIG. 81"},{"@attributes":{"id":"p-0136","num":"0135"},"figref":["FIG. 82A","FIG. 82B"]},{"@attributes":{"id":"p-0137","num":"0136"},"figref":["FIG. 83A","FIG. 83B"]},{"@attributes":{"id":"p-0138","num":"0137"},"figref":["FIG. 84A","FIG. 84B"]},{"@attributes":{"id":"p-0139","num":"0138"},"figref":"FIG. 85"},{"@attributes":{"id":"p-0140","num":"0139"},"figref":"FIG. 86"},{"@attributes":{"id":"p-0141","num":"0140"},"figref":"FIG. 87"},{"@attributes":{"id":"p-0142","num":"0141"},"figref":"FIG. 88"},{"@attributes":{"id":"p-0143","num":"0142"},"figref":"FIG. 89"},{"@attributes":{"id":"p-0144","num":"0143"},"figref":"FIG. 90"}]},"DETDESC":[{},{}]}
