---
title: Consistent logical naming of initiator groups
abstract: A technique enables efficient access to logical unit numbers (luns) or virtual disks (vdisks) stored on a storage system, such as a multi-protocol storage appliance. The technique allows a grouping of initiators by a “human friendly” logical name that is mapped to a lun or vdisk on the storage appliance. The initiators are clients operating in, e.g., a storage area network (SAN) environment that initiate requests for the vdisk using block-based access protocols, such as the Small Computer Systems Interface (SCSI) protocol encapsulated over TCP/IP (iSCSI) or over fibre channel (FCP). The technique enables access to the vdisk by all initiators that are members of the initiator group (igroup). An igroup is a logical named entity that is assigned to one or more addresses associated with one or more initiators. These addresses may comprise fibre channel (FC) world wide name (WWN) or iSCSI name identifiers (IDs). Therefore, rather than having to specify these IDs when desiring access to a vdisk, an initiator need only specify the human friendly name of the igroup.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07293152&OS=07293152&RS=07293152
owner: Network Appliance, Inc.
number: 07293152
owner_city: Sunnyvale
owner_country: US
publication_date: 20030423
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF AN ILLUSTRATIVE EMBODIMENT"],"p":["The present invention relates to network storage systems and, more particularly, to accessing information stored on networked storage systems.","A storage system is a computer that provides storage service relating to the organization of information on writable persistent storage devices, such as memories, tapes or disks. The storage system may be deployed within a storage area network (SAN) or a network attached storage (NAS) environment. When used within a NAS environment, the storage system may be embodied as a file server including an operating system that implements a file system to logically organize the information as a hierarchical structure of directories and files on, e.g., the disks. Each \u201con-disk\u201d file may be implemented as a set of data structures, e.g., disk blocks, configured to store information, such as the actual data for the file. A directory, on the other hand, may be implemented as a specially formatted file in which information about other files and directories are stored.","The file server, or filer, may be further configured to operate according to a client\/server model of information delivery to thereby allow many client systems (clients) to access shared resources, such as files, stored on the filer. Sharing of files is a hallmark of a NAS system, which is enabled because of semantic level of access to files and file systems. Storage of information on a NAS system is typically deployed over a computer network comprising a geographically distributed collection of interconnected communication links, such as Ethernet, that allow clients to remotely access the information (files) on the filer. The clients typically communicate with the filer by exchanging discrete frames or packets of data according to pre-defined protocols, such as the Transmission Control Protocol\/Internet Protocol (TCP\/IP).","In general, NAS systems utilize file-based protocols to access data stored on the filer. Each NAS client may therefore request the services of the filer by issuing file system protocol messages (in the form of packets) to the file system over the network. By supporting a plurality of file system protocols, such as the conventional Common Internet File System (CIFS), the Network File System (NFS) and the Direct Access File System (DAFS) protocols, the utility of the filer may be enhanced for networking clients.","A SAN is a high-speed network that enables establishment of direct connections between a storage system, such as an application server, and its storage devices. The SAN may thus be viewed as an extension to a storage bus and, as such, an operating system of the storage system enables access to stored information using block-based access protocols over the \u201cextended bus\u201d. In this context, the extended bus is typically embodied as Fibre Channel (FC) or Ethernet media (i.e., network) adapted to operate with block access protocols, such as Small Computer Systems Interface (SCSI) protocol encapsulation over FC (FCP) or TCP\/IP\/Ethernet (iSCSI).","SCSI is a peripheral input\/output (I\/O) interface with a standard, device independent protocol that allows different peripheral storage devices, such as disks, to attach to the is storage system. These storage devices may be locally attached to the storage system or, in the case of a SAN environment, attached via a network. In SCSI terminology, clients operating in a SAN environment are initiators that initiate requests and commands for data stored on the storage devices. The storage system is a target configured to respond to the requests issued by the initiators in accordance with a request\/response protocol. The SAN clients typically identify and address the stored information in the form of blocks or disks by logical unit numbers (\u201cluns\u201d).","In SCSI addressing, each initiator has a world wide name (WWN) or iSCSI name that is used by the initiator to access a lun entity, such as a disk, on the storage system. For example, each system on a FC SAN has a WWN, which is a 64-bit location independent identifier (ID) that is written in hexadecimal notation; iSCSI names are analogous to WWNs, but with a different format. The iSCSI names are used with the iSCSI protocol as IDs when restricting block-level access to a lun by one or more initiators. Thus, each time an initiator desires access to a lun, the WWN ID or iSCSI name must be provided to the storage system by a client\/user of the initiator. This is an inefficient and possibly error-prone approach to accessing luns on a SAN storage system.","The present invention overcomes the disadvantages of the prior art by providing a technique that enables efficient access to logical unit numbers (luns) or virtual disks (vdisks) stored on a storage system, such as a multi-protocol storage appliance. The technique allows a grouping of initiators by a \u201chuman friendly\u201d logical name that is mapped to a lun or vdisk on the storage appliance. By \u201chuman friendly\u201d it is meant, generally, a hierarchical naming convention that may use a spoken language name including an arbitrary label selected by a user or administrator. The initiators are clients operating in, e.g., a storage area network (SAN) environment that initiate requests for the vdisk using block-based access protocols, such as the Small Computer Systems Interface (SCSI) protocol encapsulated over TCP\/IP (iSCSI) or over fibre channel (FCP). The inventive technique enables access to the vdisk by all initiators that are members of the initiator group (igroup). An igroup is a logical named entity that is assigned to one or more addresses associated with one or more initiators. These addresses may comprise fibre channel (FC) world wide name (WWN) or iSCSI name identifiers (IDs). Therefore, rather than having to specify these IDs when desiring access to a vdisk, an initiator need only specify the human friendly name of the igroup.","According to the invention, the technique includes a method of creating logical igroups of initiators, each identified by a human-friendly name or label, and binding of each created igroup to one or more WWN or iSCSI IDs. An igroup may contain one initiator (in the case of a simple initiator-to-initiator group binding) or more initiators (in the case of a SAN cluster or a single client with multiple initiators for redundancy and\/or multipathing purposes). In addition, the technique includes a method of assigning a lun ID to a vdisk and specifying the igroup of initiators that are allowed access to the vdisk, i.e., the clients to which the vdisk is exported. In other words, the igroup name is used to map a vdisk to all member initiators of the igroup. An initiator can be part of more than one igroup and inherit the vdisk (lun) mapping from all the groups.","An igroup has certain attributes, such as transport protocol type and operating system type of the member initiators. Illustratively, the igroup need not be homogeneous in terms of these attributes, i.e., an igroup can contain initiators having different combinations of FCP and\/or iSCSI as a transport. For example, iSCSI and FCP initiators can be combined into a single igroup. In addition, igroup can support various operating system initiator members. This allows operations, such as graceful rolling upgrade of a FCP SAN cluster to an iSCSI cluster, with no application downtime. Moreover, membership of the igroups can be modified at any time, i.e., initiators can be added to or removed from an igroup and, as a consequence, inherit or lose the mappings of the igroup, respectively.","Advantageously, the inventive technique obviates the need to use a WWN or iSCSI name ID during operation of the multi-protocol storage appliance except in a command used to bind the ID to an igroup. All other operations and commands invoked via, e.g., a user interface use only the igroup. This is a powerful and consistent abstraction with fundamental implications on global updates, e.g., when replacing an initiator in a client and the need to globally replace a WWN or iSCSI name, and in achieving goals of simplicity to create the multi-protocol storage appliance.",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1","b":"100"},"The multi-protocol storage appliance  is illustratively embodied as a storage system comprising a processor , a memory , a plurality of network adapters ,  and a storage adapter  interconnected by a system bus . The multi-protocol storage appliance  also includes a storage operating system  that provides a virtualization system (and, in particular, a file system) to logically organize the information as a hierarchical structure of named directory, file and virtual disk (vdisk) storage objects on the disks . An example of a multi-protocol storage appliance that may be advantageously used with the present invention is described in co-pending and commonly assigned U.S. patent application Ser. No. 10\/215,917 titled A Multi-Protocol Storage Appliance that Provides Integrated Support for File and Block Access Protocols, which application is hereby incorporated by reference as though fully set forth herein.","Whereas clients of a NAS-based network environment have a storage viewpoint of files, the clients of a SAN-based network environment have a storage viewpoint of blocks or disks. To that end, the multi-protocol storage appliance  presents (exports) disks to SAN clients through the creation of logical unit numbers (luns) or vdisk objects. A vdisk object (hereinafter \u201cvdisk\u201d) is a special file type that is implemented by the virtualization system and translated into an emulated disk as viewed by the SAN clients. The multi-protocol storage appliance thereafter makes these emulated disks accessible to the SAN clients through controlled exports.","In the illustrative embodiment, the memory  comprises storage locations that are addressable by the processor and adapters for storing software program code and data structures associated with the present invention. The processor and adapters may, in turn, comprise processing elements and\/or logic circuitry configured to execute the software code and manipulate the data structures. The storage operating system , portions of which are typically resident in memory and executed by the processing elements, functionally organizes the storage appliance by, inter alia, invoking storage operations in support of the storage service implemented by the appliance. It will be apparent to those skilled in the art that other processing and memory means, including various computer readable media, may be used for storing and executing program instructions pertaining to the invention described herein.","The network adapter  couples the storage appliance to a plurality of clients over point-to-point links, wide area networks, virtual private networks implemented over a public network (Internet) or a shared local area network, hereinafter referred to as an illustrative Ethernet network . For this NAS-based network environment, the clients are configured to access information stored on the multi-protocol appliance as files. Therefore, the network adapter  may comprise a network interface card (NIC) having the mechanical, electrical and signaling circuitry needed to connect the appliance to a network switch, such as a conventional Ethernet switch . The clients  communicate with the storage appliance over network  by exchanging discrete frames or packets of data according to pre-defined protocols, such as the Transmission Control Protocol\/Internet Protocol (TCP\/IP).","The clients  may be general-purpose computers configured to execute applications over a variety of operating systems, including the Solaris\u2122\/ Unix\u00ae and Microsoft Windows\u00ae operating systems. Client systems generally utilize file-based access protocols when accessing information (in the form of files and directories) over a NAS-based network. Therefore, each client  may request the services of the storage appliance  by issuing file access protocol messages (in the form of packets) to the appliance over the network . For example, a client running the Windows operating system may communicate with the storage appliance  using the Common Internet File System (CIFS) protocol over TCP\/IP. On the other hand, a client running the Solaris operating system may communicate with the multi-protocol appliance using either the Network File System (NFS) protocol over TCP\/IP or the Direct Access File System (DAFS) protocol over a virtual interface (VI) transport in accordance with a remote DMA (RDMA) protocol over TCP\/IP. It will be apparent to those skilled in the art that other clients running other types of operating systems may also communicate with the integrated multi-protocol storage appliance using other file access protocols.","The storage network \u201ctarget\u201d adapter  also couples the multi-protocol storage appliance  to clients  that may be further configured to access the stored information as blocks or disks. For this SAN-based network environment, the storage appliance is coupled to an illustrative Fibre Channel (FC) network . FC is a networking standard describing a suite of protocols and media that is primarily found in SAN deployments. The network target adapter  may comprise a FC host bus adapter (HBA) having the mechanical, electrical and signaling circuitry needed to connect the appliance  to a SAN network switch, such as a conventional FC switch . In addition to providing FC access, the FC HBA offloads fiber channel network processing operations for the storage appliance.","The clients  generally utilize block-based access protocols, such as the Small Computer Systems Interface (SCSI) protocol, when accessing information (in the form of blocks, disks or vdisks) over a SAN-based network. SCSI is a peripheral input\/output (I\/O) interface with a standard, device independent protocol that allows different peripheral devices, such as disks , to attach to the storage appliance . In SCSI terminology, clients  operating in a SAN environment are initiators that initiate requests and commands for data. The multi-protocol storage appliance is thus a target configured to respond to the requests issued by the initiators in accordance with a request\/response protocol. The initiators and targets have endpoint addresses that, in accordance with the FC protocol, comprise worldwide names (WWN). A WWN is a unique identifier, e.g., a node name or a port name, consisting of an 8-byte number.","The multi-protocol storage appliance  supports various SCSI-based protocols used in SAN deployments, including SCSI encapsulated over TCP (iSCSI) and SCSI encapsulated over FC (FCP). The initiators (hereinafter clients ) may thus request the services of the target (hereinafter storage appliance ) by issuing iSCSI and FCP messages over the network  to access information stored on the disks. It will be apparent to those skilled in the art that the clients may also request the services of the integrated multi-protocol storage appliance using other block access protocols. By supporting a plurality of block access protocols, the multi-protocol storage appliance provides a unified and coherent access solution to vdisks\/luns in a heterogeneous SAN environment.","The storage adapter  cooperates with the storage operating system  executing on the storage appliance to access information requested by the clients. The information may be stored on the disks  or other similar media adapted to store information. The storage adapter includes I\/O interface circuitry that couples to the disks over an I\/O interconnect arrangement, such as a conventional high-performance, FC serial link topology. The information is retrieved by the storage adapter and, if necessary, processed by the processor  (or the adapter  itself) prior to being forwarded over the system bus  to the network adapters , , where the information is formatted into packets or messages and returned to the clients.","Storage of information on the appliance  is preferably implemented as one or more storage volumes (e.g., VOL1-2 150) that comprise a cluster of physical storage disks , defining an overall logical arrangement of disk space. The disks within a volume are typically organized as one or more groups of Redundant Array of Independent (or Inexpensive) Disks (RAID). RAID implementations enhance the reliability\/integrity of data storage through the writing of data \u201cstripes\u201d across a given number of physical disks in the RAID group, and the appropriate storing of redundant information with respect to the striped data. The redundant information enables recovery of data lost when a storage device fails.","Specifically, each volume  is constructed from an array of physical disks  that are organized as RAID groups , , and . The physical disks of each RAID group include those disks configured to store striped data (D) and those configured to store parity (P) for the data, in accordance with an illustrative RAID 4 level configuration. It should be noted that other RAID level configurations (e.g. RAID 5) are also contemplated. In the illustrative embodiment, a minimum of one parity disk and one data disk may be employed. However, a typical implementation may include three data and one parity disk per RAID group and at least one RAID group per volume.","To facilitate access to the disks , the storage operating system  implements a write-anywhere file system that cooperates with virtualization modules to provide a function that \u201cvirtualizes\u201d the storage space provided by disks . The file system logically organizes the information as a hierarchical structure of named directory and file objects (hereinafter \u201cdirectories\u201d and \u201cfiles\u201d) on the disks. Each \u201con-disk\u201d file may be implemented as set of disk blocks configured to store information, such as data, whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization system allows the file system to further logically organize information as a hierarchical structure of named vdisks on the disks, thereby providing an integrated NAS and SAN appliance approach to storage by enabling file-based (NAS) access to the files and directories, while further enabling block-based (SAN) access to the vdisks on a file-based storage platform.","In the illustrative embodiment, the storage operating system is preferably the NetApp\u00ae Data ONTAP\u2122 operating system available from Network Appliance, Inc., Sunnyvale, Calif. that implements a Write Anywhere File Layout (WAFL\u2122) file system. However, it is expressly contemplated that any appropriate storage operating system, including a write in-place file system, may be enhanced for use in accordance with the inventive principles described herein. As such, where the term \u201cWAFL\u201d is employed, it should be taken broadly to refer to any storage operating system that is otherwise adaptable to the teachings of this invention.","As used herein, the term \u201cstorage operating system\u201d generally refers to the computer-executable code operable on a computer that manages data access and may, in the case of a multi-protocol storage appliance, implement data access semantics, such as the Data ONTAP storage operating system, which is implemented as a microkernel. The storage operating system can also be implemented as an application program operating over a general-purpose operating system, such as Solaris or Windows, or as a general-purpose operating system with configurable functionality, which is configured for storage applications as described herein.","In addition, it will be understood to those skilled in the art that the inventive technique described herein may apply to any type of special-purpose (e.g., storage serving appliance) or general-purpose computer, including a standalone computer or portion thereof, embodied as or including a storage system. Moreover, the teachings of this invention can be adapted to a variety of storage system architectures including, but not limited to, a network-attached storage environment, a storage area network and disk assembly directly-attached to a client or host computer. The term \u201cstorage system\u201d should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or systems.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 2","b":["200","210","212","214","216","218","220","222","224","226","218"]},"An iSCSI driver layer  provides block protocol access over the TCP\/IP network protocol layers, while a FC driver layer  operates with the FC HBA  to receive and transmit block access requests and responses to and from the integrated storage appliance. The FC and iSCSI drivers provide FC-specific and iSCSI-specific access control to the luns (vdisks) and, thus, manage exports of vdisks to either iSCSI or FCP or, alternatively, to both iSCSI and FCP when accessing a single vdisk on the multi-protocol storage appliance. In addition, the storage operating system includes a disk storage layer  that implements a disk storage protocol, such as a RAID protocol, and a disk driver layer  that implements a disk access protocol such as, e.g., a SCSI protocol.","Bridging the disk software layers with the integrated network protocol stack layers is a virtualization system .  is a schematic block diagram of the virtualization system  that is implemented by a file system  interacting with virtualization modules illustratively embodied as, e.g., vdisk module  and SCSI target module . It should be noted that the vdisk module , the file system  and SCSI target module  can be implemented in software, hardware, firmware, or a combination thereof. The vdisk module  is layered on the file system  to enable access by administrative interfaces, such as a streamlined user interface (UI ), in response to a system administrator issuing commands to the multi-protocol storage appliance . In essence, the vdisk module  manages SAN deployments by, among other things, implementing a comprehensive set of vdisk (lun) commands issued through the UI , e.g., a command line interface (CLI ) or a graphical user interface (GUI ), by a system administrator. These vdisk commands are converted to primitive file system operations (\u201cprimitives\u201d) that interact with the file system  and the SCSI target module  to implement the vdisks.","The SCSI target module , in turn, initiates emulation of a disk or lun by providing a mapping procedure that translates luns into the special vdisk file types. The SCSI target module is illustratively disposed between the FC and iSCSI drivers ,  and the file system  to thereby provide a translation layer of the virtualization system  between the SAN block (lun) space and the file system space, where luns are represented as vdisks . To that end, the SCSI target module has a set of application programming interfaces (APIs ) that are based on the SCSI protocol and that enable a consistent interface to both the iSCSI and FCP drivers , . By \u201cdisposing\u201d SAN virtualization over the file system , the multi-protocol storage appliance reverses the approaches taken by prior systems to thereby provide a single unified storage platform for essentially all storage access protocols.","The file system  is illustratively a message-based system; as such, the SCSI target module  transposes a SCSI request into one or more messages representing an operation(s) directed to the file system. For example, a message generated by the SCSI target module may include a type of operation (e.g., read, write) along with a pathname (e.g., a path descriptor) and a filename (e.g., a special filename) of the vdisk object represented in the file system. Alternatively, the generated message may include an operation type and file handle containing volume\/inode information. The SCSI target module  passes the message into the file system layer  as, e.g., a function call , where the operation is performed.","The file system provides volume management capabilities for use in block-based access to the information, such as vdisks, stored on the storage devices, such as disks. That is, in addition to providing file system semantics, such as naming of storage objects, the file system  provides functions normally associated with a volume manager. These functions include (i) aggregation of the disks, (ii) aggregation of storage bandwidth of the disks, and (iii) reliability guarantees, such as mirroring and\/or parity (RAID), to thereby present one or more storage objects layered on the file system. A feature of the multi-protocol storage appliance is the simplicity of use associated with these volume management capabilities, particularly when used in SAN deployments.","The file system  illustratively implements the WAFL file system having an on-disk format representation that is block-based using, e.g., 4 kilobyte (kB) blocks and using inodes to describe the files . The WAFL file system uses files to store metadata describing the layout of its file system; these metadata files include, among others, an inode file. A file handle, i.e., an identifier that includes an inode number, is used to retrieve an inode from disk. A description of the structure of the file system, including ondisk inodes and the inode file, is provided in U.S. Pat. No. 5,819,292, titled Methodfor Maintaining Consistent States of a File System and for Creating User-Accessible Read-Only Copies of a File System by David Hitz et al., issued Oct. 6, 1998, which patent is hereby incorporated by reference as though fully set forth herein.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 4","b":["400","410","450","410","400","412","416","418","1","420","410","430","450","412","450","450"]},"Specifically, the data section  of a regular on-disk inode may include user data or pointers, the latter referencing 4 kB data blocks on disk used to store the user data. Each pointer is preferably a logical volume block number to thereby facilitate efficiency among the file system and the disk storage (RAID) layer  when accessing the data on disks. Given the restricted size (128 bytes) of the inode, user data having a size that is less than or equal to 64 bytes is represented, in its entirety, within the data section of that inode. However, if the user data is greater than 64 bytes but less than or equal to 64 kB, then the data section of the inode comprises up to 16 pointers, each of which references a 4 kB block of data on the disk. Moreover, if the size of the data is greater than 64 kilobytes but less than or equal to 64 megabytes (MB), then each pointer in the data section  of the inode references an indirect inode that contains 1024 pointers, each of which references a 4 kB data block on disk. Each data block is loaded from disk  into memory  in order to access the data. In addition, the size field  of the metadata section  of the inode refers to the size of the file.","Broadly stated, all inodes of the file system are organized into the inode file. A file system (FS) info block specifies the layout of information in the file system and includes an inode of a file that includes all other inodes of the file system. Each volume has an FS info block that is preferably stored at a fixed location within, e.g., a RAID group of the file system. The inode of the root FS info block may directly reference (point to) blocks of the inode file or may reference indirect blocks of the inode file that, in turn, reference direct blocks of the inode file. Within each direct block of the inode file are embedded inodes, each of which may reference indirect blocks that, in turn, reference data blocks of a file or vdisk.","Referring again to , the file system implements access operations to vdisks , as well as to files  and directories (dir ) that coexist with respect to global space management of units of storage, such as volumes  and\/or qtrees . A qtree  is a special directory that has the properties of a logical sub-volume within the namespace of a physical volume. Each file system storage object (file, directory or vdisk) is illustratively associated with one qtree, and quotas, security properties and other items can be assigned on a per-qtree basis. The vdisks and files\/directories may be layered on top of qtrees  that, in turn, are layered on top of volumes  as abstracted by the file system \u201cvirtualization\u201d layer .","Note that the vdisk storage objects in the file system  are generally associated with SAN deployments of the multi-protocol storage appliance, whereas the file and directory storage objects are associated with NAS deployments of the appliance. The files and directories are generally not accessible via the FC or SCSI block access protocols; however, a file can be converted to a vdisk and then accessed by either the SAN or NAS protocol. The vdisks are thus accessible as luns from the SAN (FC and SCSI) protocols.","According to the invention, the UI  (CLI  and\/or GUI ) interacts with the vdisk module  to introduce attributes and persistent lun map bindings that assign numbers to a created vdisk. These lun map bindings are thereafter used to export vdisks as certain SCSI identifiers (IDs) to the clients. In particular, the created vdisk can be exported via a lun mapping technique to enable a SAN client to \u201cview\u201d (access) a disk. Vdisks (luns) generally require strict controlled access in a SAN environment; sharing of luns in a SAN environment typically occurs only in limited circumstances, such as clustered file systems, clustered operating systems and multi-pathing configurations. A system administrator of the multi-protocol storage appliance determines which vdisks (luns) can be exported to a SAN client. Once a vdisk is exported as a lun, the client may access the vdisk over the SAN network utilizing a block access protocol, such as FCP and iSCSI.","SAN clients typically identify and address disks by logical numbers or luns. However, an \u201cease of management\u201d feature of the multi-protocol storage appliance is that system administrators can manage vdisks and their addressing by logical names. To that end, the CLI  and\/or GUI  interact with the vdisk module  and SCSI target module  to map logical names to vdisks. The present invention relates to a technique that allows a grouping of initiators by a \u201chuman friendly\u201d logical name that is mapped to a lun or vdisk stored on the multi-protocol storage appliance to thereby enable access to the vdisk by all initiators that are members of the initiator group (igroup). As used herein, a \u201chuman friendly\u201d logical name is an arbitrary label selected by the user of administrator that may be a spoken name, a path designation or include a hierarchical naming convention. An exemplary human friendly name would be \u201cadministrators\u201d for a name of an igroup that comprises the administrators of a given network.","An igroup is a logical named entity that is assigned to one or more addresses, e.g., WWN or iSCSI name identifiers (IDs), associated with one or more initiators (depending upon whether a clustered environment is configured). The multi-protocol storage appliance manages export control of vdisks by logical names through the use of igroups. As described herein, an \u201cigroup create\u201d command essentially \u201cbinds\u201d (associates) those addresses to a logical name or igroup. Therefore, rather than having to specify these IDs when desiring access to a vdisk, an initiator need only specify the human friendly name of the igroup.","As noted, a vdisk is a special file type in a volume that derives from a plain (regular) file, but that has associated export controls and operation restrictions that support emulation of a disk. Illustratively, the vdisk is a multi-inode object comprising a special file inode and a plurality of associated streaminodes, including an attributes stream inode and a lunmap streaminode. The special file (lun) inode functions as a data container for storing data, such as application data, associated with the emulated disk. The lunmap inode contains a list of igroups to which the vdisk is exported, along with one or more addresses associated with one or more initiators that are assigned to each igroup.",{"@attributes":{"id":"p-0054","num":"0053"},"figref":["FIG. 5","FIG. 4"],"b":["500","510","540","550","510","322","518","510","512","513","514","510","520"]},"In order to access the stream_dir inode , the pointer of xinode field  in lun inode  is modified to reference the inode . The stream_dir inode  comprises a metadata section  that includes a type (stream_dir) field  and an xinode field  that references another on-disk inode structure containing, e.g., access control (such as CIFS permission) information associated with the vdisk. The inode  also includes a data section  containing a pointer  that references a stream directory data block associated with the vdisk, such as stream directory block . The stream directory block  comprises a data section  that includes a plurality of entries, each containing an external representation of a streaminode along with mapping information (i.e., the inode number) for that inode. Two of those entries, entries  and , contain mapping information (e.g., pointers) that reference an attributes (stream) inode  and a lunmap (stream) inode , respectively.","The attributes inode  comprises a metadata section  that includes a type (stream) field  and a data section  that functions as a persistent store for holding various named attributes associated with the vdisk . Attributes are an implementation mechanism that is internal to the file system and not managed by users. Examples of attributes include a lun map  and export information  controlling access to the vdisk by, e.g., specifying a list of initiators to which the vdisk is exported (i.e., those that have permissions to access to the vdisk). The lunmap inode  comprises a metadata section  that includes a type (stream) field  and a data section  that functions as a persistent store for holding a list  of name-value pairs. The name is illustratively an igroup name and the value is a lun identifier (ID). The vdisk and its associated inode data structures, including the attributes and lunmap inodes, are further described in co-pending and commonly assigned U.S. patent application Ser. No. 10\/216,453 titled Storage Virtualization by Layering Vdisks on a File System, which application is hereby incorporated by reference as though fully set forth herein.","In the illustrative embodiment, vdisks (luns) are \u201clayered\u201d on top of igroups. The igroup abstracts the underlying details of \u201cnaming\u201d (i.e., identification) of clients or initiators that desire access to the vdisks. The naming details (for purposes of allowing access to a vdisk\/lun by a client\/initiator) may be completely different between block access protocols, such as FCP and iSCSI. However, the logical naming of igroups is consistent with the FC and SCSI standards; the novel technique represents an application of those standards that simplifies access to the vdisks. The igroup abstraction thus decouples implementation of addressing from the underlying details of addressing. In other words, an igroup allows a user to define client or related clients addressing by logical names that are then used by higher layer vdisk (lun) commands to allow access. As a result, a vdisk (lun) can be easily shared over iSCSI and FCP, thereby allowing use in applications such as a mixed iSCSI or FCP cluster. Moreover, reorganization or upgrades of client\/initiators do not affect security assignments (allowing access) at the lun level, since they are indirect via the logical igroup name.","According to the invention, the novel technique includes a method of creating logical igroups of initiators, each identified by a human-friendly name or label, and binding of each created igroup to one or more initiator addresses (e.g., WWN or iSCSI IDs).  is a flowchart illustrating a sequence of steps used to create an igroup in accordance with the present invention. The sequence starts at Step  and proceeds to Step  where a user (system administrator) selects a human-friendly name for the igroup. In Step , a determination is made as to whether there is \u201cclash\u201d (conflict) between that selected name and an existing igroup name. If so, another igroup name is chosen in Step  and the sequence returns to Step  until there is no conflict.","In Step , the user creates an igroup by issuing an \u201cigroup create\u201d command through, e.g., CLI , GUI  or similar administrative interfaces associated with the multi-protocol storage appliance. An example of the igroup create command is:\n\n","wherein the <groupname> parameter indicates the human-friendly name of the igroup and the <nodename(s)> parameter indicates the initiator(s), e.g., the WWN or iSCSI address ID(s), bound to the igroup. An igroup may contain one initiator (in the case of a simple initiator-to-initiator group binding) or more initiators (in the case of a SAN cluster or a single client with multiple initiators for redundancy and\/or multipathing purposes). The created igroup create thus enables grouping of initiators by a human friendly logical name.","In response to the igroup create command, the file system  cooperates with the vdisk module  to create an \u201cin-core\u201d igroup data structure  (e.g., a table in memory ) in Step . In Step , the vdisk module  processes the igroup create command to \u201ccall\u201d primitive operations (\u201cprimitives\u201d) in the file system  to insert the name and addresses specified by the create command into the igroup data structure . This step of the sequence essentially binds the logical, human-friendly name to one or more WWN or iSCSI IDs. Thereafter, in Step , the igroup data structure is written (stored) to the disk . The sequence then ends at Step .",{"@attributes":{"id":"p-0062","num":"0062"},"figref":"FIG. 7","b":["700","710","710","720","730","1","1"]},"The novel technique also includes a method of assigning a lun ID to a vdisk and specifying the igroup of initiators that are allowed access to the vdisk, i.e., the clients to which the vdisk is exported. In other words, this aspect of the inventive technique involves mapping a vdisk (lun) to an igroup.  is a flowchart illustrating a sequence of steps used to map a lun to an igroup in accordance with the present invention. The sequence starts at Step  and proceeds to Step  where a user maps a lun to an igroup by issuing a \u201clun map\u201d command through the CLI , GUI  or similar administrative interfaces associated with the multi-protocol storage appliance. An example of the lun map command is:\n\n","wherein the <path> parameter is a path descriptor containing volume\/inode information and a file handle to a vdisk, the <groupname> parameter indicates the human friendly name of the igroup and the <lunID> parameter indicates the lun ID assigned to the vdisk. Note that the lun ID is unique within the client's (initiator's) lun space. In Step , the vdisk module  processes the lun map command to call primitives in the file system  to retrieve a lun inode and its associated streaminodes of the vdisk from disk, which are then loaded into memory (in-core). In Step , primitives are called to populate the attributes inode  and lunmap inode  of the vdisk with the export information, including igroup and lun ID, specified by the lun map command. In Step , the SCSI target module  is \u201cprimed\u201d with the export information to enable access by the initiators of the igroup to the specified vdisk. The sequence then ends at Step .","The igroup create and lun map commands essentially provide a mapping function between one or more initiators of an igroup and a lun ID that is representative of a vdisk. An initiator can be a member of more than one igroup and inherit the vdisk (lun) mapping from all the groups. The SCSI target module  thereafter implements the mapping function to allow a particular lun or vdisk to be exported to (accessed by) all initiators of a particular igroup. The mapping function is illustratively embodied as igroup definitions stored in the igroup data structure  and export information stored in the stream (lunmap and attributes) inodes. To that end, the SCSI target module is primed with export information, as indicated in Step , by processing the contents of the igroup data structure and streaminodes.","Specifically, the lunmap streaminode  associated with each vdisk specifies the availability (visibility) of the vdisk to one or more igroups with respect to a lun ID. Since the igroups are identified by names associated with lun IDs within the lunmap inode, references are made to the igroup definitions  stored in the igroup data structure  in order to resolve each igroup name with a WWN address or iSCSI ID. The lun ID identified within the value portion of the name-value pair indicates the assigned lun number to the vdisk in accordance with a persistent lunmap \u201cbinding\u201d that enables a SAN client to \u201cview\u201d (access) a vdisk.","According to the invention, the lun map command may be used to export one or more vdisks to the igroup, i.e., make the vdisk(s) \u201cvisible\u201d to the igroup. In this sense, the lun map command is equivalent to an NFS export or a CIFS share. The WWN addresses or iSCSI IDs thus identify the igroups\/clients that are allowed to access those vdisks specified by the lun map command. Thereafter, the logical igroup names are used with all operations internal to the storage operating system. This logical naming abstraction is pervasive throughout the entire vdisk command set, including interactions between a user and the multi-protocol storage appliance. In particular, the igroup naming convention is used for all subsequent export operations and listings of luns that are exported for various SAN clients.","Each igroup has certain associated attributes, such as transport protocol type and operating system type of its member initiators (node names). For example, the initiators within an igroup illustratively support the FCP, iSCSI and ATA transport protocol type. The operating system type attribute refers to the operating system type of the member initiators in the igroup. This latter attribute is provided because a SCSI target (such as the multiprotocol storage appliance) often \u201cbehaves\u201d differently when interacting with different operating systems (e.g., Solaris, Windows, and Linux) of the initiators. Processing of a request received at the storage appliance occurs at lower layers of the storage operating system. Since addresses (WWN or iSCSI IDs) are bound to igroup name, these lower layers \u201cknow\u201d whether the request is received over, e.g., an iSCSI or FCP transport.","In the illustrative embodiment of the present invention, the igroup need not be homogeneous in terms of these attributes, i.e., an igroup can contain initiators having different combinations of FCP, iSCSI and ATA as a transport. For example, iSCSI, FCP and ATA initiators may be combined into a single igroup. In addition, an igroup can support various operating system initiator members. This allows operations, such as graceful rolling upgrade of a FC SAN cluster to an iSCSI cluster, with no application downtime. In addition, membership of the igroups can be modified at any time, i.e., initiators can be added to or removed from an igroup and, as a consequence, inherit or lose the mappings of the igroup, respectively.","Use of the initiator group abstraction is particular advantageous in a situation where a particular initiator (client) may access more than one disk (vdisk) of the multiprotocol storage appliance for various applications. In that case, the user issues, in the following order, a lun create command through the UI that creates, e.g., twenty vdisks called \u201cvdisks-\u201d. The user then issues the igroup create command that binds a WWN of the client (initiator) to a logical name, e.g., \u201cFCPClient\u201d. The WWN represents the address of a host bus adapter (HBA) module on the client and is thus assigned on a per module basis. The user then issues the lun map command that binds the vdisks- to the logical igroup name FCPClient.","Assume now that the HBA module in the client fails and a new adapter is installed in the client that has an address that is different from the address associated with the igroup FCPClient. Accordingly, the client can no longer access the vdisksl-20 because those disks are exported to a WWN address that is different from the new address of the client. To rectify this situation, a user need merely issue \u201cigroup delete\u201d and \u201cigroup add\u201d commands through the UI  of the multi-protocol storage appliance to reflect the new client HBA address. That change then \u201cripples\u201d throughout the vdisk command set to reflect the new association of the igroup name to all of the vdisks-. This feature of the novel multi-protocol storage appliance architecture reflects global, single point changes to an igroup address for all the disks associated with that igroup.","In sum, the novel igroup technique decouples addressing from the actual protocol to thereby enable multi-protocol access to luns via either iSCSI or FCP, each of which has a different addressing scheme. Naming (e.g., hierarchical naming) simplifies management by hiding details of underlying addressing schemes of the transport. The igroup thus comprises a multi-protocol encapsulation of host access control and address information making the vdisk transport protocol independent. That is, the vdisk can be simultaneously accessed by FCP, iSCSI or similar transports, such as ATA and serial ATA, with an abstract human friendly name hiding any addressing details. This feature provides high-level configuration information in the appliance the ability to handle any type of lower-level addressing. Therefore, igroup logical naming comprises (i) a pure naming and simplification arrangement, as well as (ii) an application thereof that cooperate to provide multi-protocol access control through a generalized initiator addressing technique.","Advantageously, the inventive technique obviates the need to use a WWN or iSCSI name ID during operation of the multi-protocol storage appliance except in a command used to bind the ID to an igroup. All other operations and commands invoked via, e.g., a user interface use only the igroup. This is a powerful and consistent abstraction with fundamental implications on global updates, e.g., when replacing an initiator in a client and the need to globally replace a WWN or iSCSI name, and in achieving goals of simplicity to create the multi-protocol storage appliance.","The foregoing description has been directed to specific embodiments of this invention. It will be apparent, however, that other variations and modifications may be made to the described embodiments, with the attainment of some or all of their advantages. Therefore, it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The above and further advantages of invention may be better understood by referring to the following description in conjunction with the accompanying drawings in which like reference numerals indicate identical or functionally similar elements:",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8"}]},"DETDESC":[{},{}]}
