---
title: Effects application based on object clustering
abstract: A system in accordance with the present invention may include one or more processors, memory that receives instructions from the one or more processors according to a clock operating at a frequency, one or more programs stored in the memory, with instructions to: access media content; analyze the media content according to meta data, media characteristics, or other media-related data; and, create a media content object cluster according to the meta data, the media characteristics, or the other media-related data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08495074&OS=08495074&RS=08495074
owner: Apple Inc.
number: 08495074
owner_city: Cupertino
owner_country: US
publication_date: 20090708
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["This application claims the benefit and priority of the U.S. Provisional Patent Application No. 61\/193,853 filed on Dec. 30, 2008, which is hereby incorporated by reference.","The present invention relates generally to the field of media presentations and, in particular, to authoring, rendering, viewing, exporting, and sharing media effects.","Current media presentation applications offer features for creating slides and manually customizing the ways in which a set of slides, i.e., a slideshow\/media presentation, is played. Such applications also offer features for attaching themes to slideshows, where such themes may affect the appearance and general behavior of the slideshows when played. In addition, such applications further offer features such as customizing slide colors, customizing transition behavior, customizing transition delay, and manually adding clip art\/image\/audio\/video files to one or more slides in a slideshow. These applications also permit basic sequential transition, forward or backward, and from one slide to another in a slideshow containing more than one slide. A user may customize the time that one slide should be viewed prior to the application invoking a transition to another slide, which may further have a custom viewing time associated with it as well. However, current media presentations applications do not provide a feature for authoring media effects, comprising: accessing media content; analyzing the media content according to meta data, media characteristics, or other media-related data; and creating a media content object cluster according to the meta data, the media characteristics, or the other media-related data. Moreover, current media presentation applications also do not provide a feature for dynamically profiling a slideshow soundtrack based on various criteria like beats per minute (BPM), rhythmic strength (RS), harmonic complexity (HC), and\/or root mean square density (RMS or RMS strength). Such criteria, when profiled intelligently, may be further used to select appropriate effects and assemble such effects in useful ways applicable to a slideshow. Further, such effects could be customized according to durations, in\/out points, and transitions in-sync with audio alone or the audio of a video. Finally, current media presentation applications do not provide features for automatic, as well as user-defined, authoring, rendering, exporting, and sharing media presentations\/slideshows in an easily integrated modem platform.","Accordingly, the present invention is directed to a system and method for authoring, rendering, exporting, and sharing media effects that substantially obviates one or more problems due to limitations and disadvantages of the related art.","An embodiment of the present invention provides a computer-implemented method for authoring media effects, comprising: accessing media content; analyzing the media content according to meta data, media characteristics, or other media-related data; and, creating a media content object cluster according to the meta data, the media characteristics, or the other media-related data.","Additional features and advantages of the invention will be set forth in the description which follows, and in part will be apparent from the description, or may be learned by practice of the invention. The objectives and other advantages of the invention will be realized and attained by the structure particularly pointed out in the written description and claims hereof as well as the appended drawings.","To achieve these and other advantages and in accordance with the purpose of the present invention, as embodied and broadly described, a system comprises one or more processors; memory; one or more programs stored in memory, the one or more programs comprising instructions to: access media content; analyze the media content according to meta data, media characteristics, or other media-related data; and, create a media content object cluster according to the meta data, the media characteristics, or the other media-related data.","In another aspect, a computer-readable storage medium stores one or more programs configured for execution by a computer, the one or more programs comprising instructions to: access media content; analyze the media content according to meta data, media characteristics, or other media-related data; and, create a media content object cluster according to the meta data, the media characteristics, or the other media-related data.","It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory and are intended to provide further explanation of the invention as claimed.","Reference will now be made in detail to embodiments, examples of which are illustrated in the accompanying drawings. In the following detailed description, numerous non-limiting specific details are set forth in order to assist in understanding the subject matter presented herein. It will be apparent, however, to one of ordinary skill in the art that various alternatives may be used without departing from the scope of the present invention and the subject matter may be practiced without these specific details. For example, it will be apparent to one of ordinary skill in the art that the subject matter presented herein can be implemented on any type of standalone system or client-server compatible system containing any type of client, network, server, and database elements.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 1","FIG. 1"],"b":["1000","1001","1002","1001","1003","6001","7001","1004","1005","1006","1007","1008","6002","7002","1009","1010","1011","1009","1012","1013","1014","1015","1000","1000","1001","6004","7004","9009","1004","1005","7008","7009","9009","1013","1014","1009","1012","6002","7002","7006","7012","7013","9012","1008","1008","1015","1003"]},"In some embodiments, the exemplary embodiment of an application , and its features\/components, may be implemented by one or more modules\/engines (, reference numerals -) executed using an exemplary system  () with a central processing unit (CPU)  (and, alternatively, multiple CPUs), memory  for storing data (e.g., instructions from an operating system  or one or more programs (e.g., , )) to be fetched by the CPU for execution, a display device  for displaying the exemplary application  using a graphics module to a display screen, a network interface card (NIC)  for sending and receiving data over a wired or wireless communications network, local storage  for storing media content and other data (e.g., an operating system , the exemplary embodiment of an application , other applications, etc.), and auxiliary device(s)\/component(s)  (e.g., TV (or, other display), portable storage, portable media player, etc.), which may all be connected via a bus for sending and receiving data according to a frequency (e.g., synchronous or asynchronous).","In some embodiments, the features\/components of the application  may be described as follows. The document  (also, , reference numeral ) is the top level object of the media presentation\/slideshow that may be created (e.g., steps , ) using the exemplary application . The document is the object that may comprise: all of the custom\/default layers ,  (also, , reference numeral ) (e.g., steps , , ), effect containers such as, for example, those within the effect containers region  (also, , reference numeral ); effects such as, for example, those within the effect containers (also, , reference numeral ); gaps  or transitions  for separating or linking effects, respectively (also, , reference numeral ); slides such as, for example, the images of  or other media content as described above (also, , reference numeral , ) (e.g., step , ); frames ; a document\/layer\/effect stack ; a layer\/effect\/slide\/filter stack ; a playlist ; an animation path ; a song ; a keyframe  (which may, for example, be one dimensional (1D) , two dimensional (2D)  or a vector ()); filters ; a layer\/effect container\/effect\/slide\/filter stack ; and, any other possible combination of the aforementioned. Moreover, a document may contain layers that may be stacked\/placed one on top of another to provide the media presentation\/slideshow with an added level of flexibility in what is available for actual display (e.g., steps , , ). Accordingly, the application supports the presentation of less than all of the available layers. Stacking may involve a process, for example, of logically associating, or linking, layers. That is, a background layer  may be considered the lowest level layer in a stack of layers, followed by a foreground layer  and a plurality of other foreground layers, all of which would be logically associated according to their position from, for example, background layer , or from each other foreground layer. During display\/play of a document such as, for example, document , the layers would be displayed\/played according to their respective positions in the stack (logical associations). The next feature\/component is the layers  (background),  (foreground) (also, , reference numeral ) within a document  (also, , reference numeral ) (e.g., steps , ). Each layer ,  of a stack of layers (e.g., aggregated layers; steps , ) within a document can be positioned, sized, and rotated using the exemplary application . Further, each layer ,  may also have a custom audio file\/track (or, alternatively, a set of audio files\/tracks, or other media content) associated with it and other layers , , thus, providing a media presentation\/slideshow with multiple audio files\/tracks during presentation (e.g., steps , ). Each layer ,  may also contain effect containers (like, for example, those illustrated in the effect containers region ) (e.g., steps , ), which may be linked together in a layer using transitions  (also, , reference numeral ) or separated from one another using gaps  (or, alternatively, some other effect separation variable like, for example, random separation\/transition, or a combination of gaps and transitions, etc.) (e.g., ). Transitions , which through visual action\/expression may create the appearance that two effect containers are linked together, may be able to provide a rather \u201cfluid\u201d (or, alternatively, a \u201cnon-fluid\u201d) experience between effect containers when presenting a media presentation\/slideshow. For example, transitions may be the visual action\/expression of a page flipping, a slide dissolving, a slide being pushed along in any direction, a cube breaking apart (or, being assembled), a page rolling for the purpose of unveiling\/hiding contents, a puzzle being assembled (or, disassembled), or any other type of visual action\/expression applied to an effect container or slide and capable of being rendered on a display device. Slides in the exemplary application may be the actual image, movie, text, or other media content that may be within an effect, which may be within an effect container (e.g., steps , ). Slides may have frames applied as an added layer (e.g., on top), where a frame may be a visual element\/expression such as, for example, making an image appear as if it was taken using an instant photo camera (e.g., Polaroid\u00ae), is part of a filmstrip, has a solid\/dashed\/shadowed\/other border surrounding it, or other type of frame-related visual element\/expression. Further, each slide may have an animation path  that may determine which part of a slide image, movie, text, or other media content, is actually displayed\/played; similarly, an animation path  associated with the slide may cause a panning\/zooming effect to be executed on the image, movie, text, or other media content, where the panning\/zooming may occur within the effect of the slide. As applied to a layer, a user may also customize an animation path  via the exemplary application  to, for example, smoothly transition a layer's rotation from around zero (0) degrees all the way to three hundred sixty (360) degrees, over a default or custom period of time (e.g., steps , ). In some embodiments, transitions  may have durations associated with them to determine how long the transitions are played. The transition duration may be subtracted directly from the total duration of the effect containers separated\/divided by the transition. For example, when transitioning from an effect container with a three (3) second duration to another effect container with a three (3) second duration, that is, having a six (6) second total duration, using a transition with a one (1) second duration, the effect containers may only be played for a total of five (5) seconds (i.e., the total six (6) second duration of the effect containers minus the one (1) second transition display\/play duration leaves five (5) seconds of display\/play duration for the effect containers).","In some embodiments, effect containers may be able to determine the order that images (or, alternatively, other media content) associated with a layer (e.g., steps , ) are presented during a media presentation\/slideshow. Such a determination may be based according to characteristics associated with the images (or, alternatively, other media content) (e.g., steps , ). The characteristics may comprise a resolution, size, quality indicator, dots-per-inch, frames per second, window size, bit error rate (BER), compression type, or some other media content characteristic. The exemplary application  may execute this process of assembling the layers (e.g., steps , ) either manually or according to algorithms processing the characteristics and other layer-related data (described above). Further with respect to effect containers (e.g., a container or group of effects), multiple effects may be transitioned as one set into the next effect container. For example, effect containers are necessary in order for different text to be displayed on top of different effects. In some embodiments, from an implementation viewpoint, the effect containers permit the logical\/physical grouping of different effects and link each of the effects to their respective different text, which is to be displayed on top of each respective effect. Each effect container may, for example, further contain a variable for storing a specific duration for determining how long each of the effects associated with an effect container (or, alternatively, \u201cwithin\u201d the effect container) are displayed\/played.","In some embodiments, a keyframe  (which may, for example, be one dimensional (1D) , two dimensional (2D)  or a vector ()), may be used by an animation path  to guide or instruct the rate at which animation path  should operate. Meaning, the higher the value of a keyframe , the increased rate the animation path  may operate (e.g., a faster pan-zoom effect or a faster layer rotation), and the lower the value of a keyframe , the lower rate the animation path  may operate at (e.g., a slower pan-zoom effect or a slower layer rotation). A 1D  keyframe may be a keyframe that animates a property that has one value like, for example, a rotation angle. A 2D  keyframe may be a keyframe that animates a property that has more than one value like, for example, a position (x-axis point, y-axis point) or a size (width\/length, height). And, a vector  keyframe may be a keyframe that animates a property that has more than two values like, for example, colors that manipulate the different values of their constituent color components (e.g., red, green, blue, alpha).","In some embodiments, filters  operate as visual elements that are applied to a layer, effect container, effect, or slide. A filter  may be, for example, a shadow, blurred image, or some other compatible visual element capable of being applied to a layer, effect container, effect, or slide (e.g., steps , ).","In some embodiments, a playlist  associated with a document  may contain a list of songs (e.g., steps , ). The playlist  may organize songs such that they are played in a specific order, determined manually by a user of the exemplary application , or automatically through the exemplary application . An automatic playlist may be created according to song genre, file characteristics (e.g., type, size, date, etc.), or according to the feature for dynamically profiling a slideshow soundtrack based on various criteria like beats per minute (BPM), rhythmic strength (RS), harmonic complexity (HC), and\/or root mean square density (RMS or RMS strength). The songs (e.g., a reference to a playlist) may be stored in digital format in local storage  or on an auxiliary device\/component  that communicates with the system  through a communications protocol or standard. The songs may be stored in a single file (or, other logical\/physical data aggregator) or many files. In addition to songs, a playlist  may contain other compatible media content like videos with audio content (which, for example, may be parsed from the video file into an individual song\/audio file, or playlist). To associate a playlist, song\/audio file, or any compatible media content with a document , the user may select it\/them from the select media content  menu and drag the respective playlist, song\/audio file, or other compatible media content, via the exemplary application , into the effect containers region  (see, for example, the reference to \u201cDrag Audio Here\u201d in the exemplary application ) (e.g., steps , ). Songs may be played in the background while a document is being displayed\/played, or they may, alternatively, be associated with foreground layers or effects that may be organized on top of another, thus, enabling the songs to be switched in coordination with the various switching (e.g., via gaps or transitions) from one layer or effect to another (e.g., steps , ). Further, songs may, according to a default setting, start and stop playing based on the start and stop times that may be given from a media player or media management application. The user of the exemplary application  may, however, define a custom start or stop time via a song (or, playlist) menu option of the application .",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 2","FIG. 1"],"b":["2000","1003","2001","2002","2003","6001","7001","6002","7002","7008","7009","2004","2005","2006","2001","2002","2003","2011","2013","2003","2007","2008","2009","2002","2003","2010","2003","2012","2003","7007","7014","2012","1000","2000","7015","7007"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 2A","b":["2000","2020","2021","2022","2023","2022","2020","2021","2023","2021","2022","2023","2021","20222","2023"]},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 3","b":["1000","4000","4001","3000","4002","4006","4005","3001","3002","3002","3002","3003","3003","3003","3004","3004","3004","3003","3002","3000","3019","1000","4000"]},{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 3A","FIGS. 4-5"],"b":["3000","3020","3021","3022","3023","3000","1000"]},"In some embodiments, the core  module may be considered the low-level data structure module and it may, for example, perform routines for representing how a slideshow\/media presentation document is constructed, and contain the necessary information for accurately representing a slideshow\/media presentation document according to features, many of which are described herein (e.g., steps -, -). Some of those features may include, for example, features related to timing (e.g., gaps , transitions ), positioning (e.g., background layer , foreground layer , effects of effect containers -, slides , filters , text ), sizing (e.g., keyframe , animation path , as well as their interaction), and files (e.g., songs , playlists ).","In some embodiments, the producer  may be considered the module for creating how a slideshow will look and feel (e.g., steps -, -), performing several analyses related to media content (e.g., images, audio, video of layers, effect containers, effects, and slides) (e.g., step ), and automatically assembling slideshows\/media presentations according to data that may result from the analyses (e.g., steps , , ). The several analyses (e.g., step ) may include analysis of characteristics related to layers, effect containers, effects, and slides. Such characteristics may include, for example, layer type (e.g., background , foreground ), layer number (e.g., position in relation to the background-most layer ), number of effect containers, length of gaps  and transitions , type of transitions , type of effects, number of effects, number of slides, type of slides, document length , user preferences (e.g., for ordering layers, effect containers, effects, slides), audio analyses, video analyses, or other similar characteristics. After performing the several analyses using, for example, the producer , the resulting data from the several analyses may be processed by the producer , the core , the renderer , the exporter , or other module (e.g., step ). The producer  may, for example, interface with and utilize the application programming interfaces (API) of frameworks like, for example, browsers or QuickTime\u00ae to gather such information as thumbnail data and resolutions for images, as well as audio or video durations or other characteristics. The gathered information may then be processed by the producer  in accordance with one or more general\/specific algorithms (or, other analytical methods) and then used by the producer  (or, other module with which the producer  may call), for example, to automatically assemble a slideshow or media presentation document (e.g., ). The producer  may further, for example, assemble a document via core  for play\/display using the features of renderer , by accessing photos and coupling such photos with a style (e.g., ) (see description of ). In addition, the producer  may also, for example, perform audio analysis functions on songs  or a set of songs (playlist ) using such analysis like, for example, beat detection\/mapping. The producer  may also keep track of available styles (e.g., ), effects , transitions , and frames .","In some embodiments, the renderer  may be considered the play\/display module. The renderer  may receive slideshow\/media presentation data from, for example, the core  and producer  and may render such data such that it may be sent to a graphics card or other display device (or interface) (e.g., ). The renderer  may interface with QuickTime\u00ae media player (e.g., the framework of QuickTime\u00ae media player) or another compatible application (or, framework) for audio\/video decoding. In addition, the renderer  may also interface with a composer-type application for actual rendering (e.g., of the slides), and the same or another similar application for applying filters .","In some embodiments, the exporter  may be considered the sharing module. The exporter  may, for example, use renderer  to export the slideshow\/media presentation document to different formats (e.g., file formats) like those supported by QuickTime\u00ae or other similar applications. The exporter  may, for example, obtain movie frame-type data from renderer  and add it to a movie-type file. When the exporter  is finished retrieving data for each movie, the slideshow\/media presentation document would be available for access and sharing through the exemplary application  or other applications that may access or handle the document in its final format.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIG. 4","FIG. 4"],"b":["4000","1000"]},{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 5","FIG. 3A","FIG. 4"],"b":["5001","5004","5010","5013","5000","5001","5004","5010","5013","4008","5008","4009","5009","4008","5008","4009","5009","4008","5008","4009","5009"]},{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 6","FIG. 4"],"b":["6000","6001","6002","6003","6004","6000","6001","6004","1000"]},{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 7","FIG. 4"],"b":["7000","6000","7005","7015","7000","7001","7015","1000"]},{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 8","FIG. 4"],"b":["8000","8000","8001","8003","1000"]},{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 9","FIG. 4"],"b":["9000","8000","9004","9012","9000","9001","9012","1000"]},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 10","b":["10000","10001","10005","3021","3022","8001","8003","9001","9012","10001","3021","9008","4006","9007","4004","4005","8001","9001","10003","10004","10005","10004","10005","10004","3009","3008","10005","8002","9002"]},"In some embodiments, in steps , , the producer  or other framework module may analyze the media content through meta data by accessing file characteristics, encoded data, tags\/XML data, or by accessing media characteristics (e.g., camera\/capture device make\/model) or other media-related data. For example, meta data may be one or more of a time associated with the media content's creation, a rating associated with the media content (individually or in the aggregate), keywords associated with the media content, comments associated with the media content, a country\/state\/province\/city associated with the media content, a longitude\/latitude associated with the media content, or some other readable or extrapolated data.","In some embodiments, the producer  or other framework module may further analyze the gathered meta data (like that described above) by comparing and contrasting the similarities and difference that may be prevalent among the meta data, while tracking which meta data is associated with which media content. For example, the analysis may involve comparing and contrasting the date\/time associated with the media content, textual similarities associated with the media content, the places where media content originated or was generated, a rating associated with the media content, or an order (e.g., chronology) associated with the media content. According to the results of such analyses, the producer  or other framework module may create media content object clusters (e.g., steps , ; A) or, more specifically, for example, slide clusters (e.g., A), where the results indicate that one or more media content types may be related (e.g., A-A). Slide clusters may be considered a collection of slides that may be logically grouped according to pre-defined criteria, where the criteria may vary and be defined according to media presentation\/slideshow styles or properties. For example, media content object clusters may be created for media content types where the clusters are time\/order-based (e.g., , reference numeral A), location-based, keyword-based (e.g., , reference numeral A), people-based, camera-based, rating based (e.g., , reference numeral A), or according to some other readable or extractable logical grouping (e.g., steps , ; , reference numeral A) (see description for ). Moreover, based on the analyses, a link strength (e.g., having a value from one (1) to ten (10)) may be associated with a cluster in order to indicate how likely the cluster may be useful to the user, based on how related the media content associated with such a cluster may be. For example, a slide cluster with a link strength value of seven (7) indicates that the media content associated with the cluster is more likely to be closely related than that of a slide cluster with a link strength of two (2). If the media content has no meta data, media characteristics, or other media-related data that the producer  or other framework module may analyze, then a slide cluster with a link strength of one (1) may be created and the media content may be sorted chronologically, if possible, or, alternatively, in a random order.","In some embodiments, slide clusters where media content is sorted chronologically may be used for a media presentation\/slideshow document (e.g., step ) where, for example, the purpose is to tell a story. Further, slide clusters where media content is sorted according to a keyword, burst rate, rating, or date\/time, etc. may be used for a media presentation where, for example, the purpose is to illustrate a portfolio of media content (e.g., a set of sequential time-based images of a wind surfer such as that illustrated in , reference numerals -; or, alternatively, a collection of images of flowers, or a specific location such as that illustrated in , reference numerals , ).",{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 10A","b":["10000","10002","10004","10001","10003","10001","10004"]},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 11","b":["11001","11006","11000","3021","3021","3021","3022","9005","9011","3021","3022","9011"]},{"@attributes":{"id":"p-0055","num":"0054"},"figref":["FIG. 12","FIG. 12"],"b":["12001","12003","3021","12001","3021","3021","3022","9005","9011","12003","12002","12003","12002","3021","12003"]},"It will be apparent to those skilled in the art that various modifications and variations can be made to the present invention without departing from the spirit or scope of the invention. Thus, it is intended that the present invention cover the modifications and variations of this invention provided they come within the scope of the appended claims and their equivalents."],"BRFSUM":[{},{}],"heading":["FIELD OF INVENTION","BACKGROUND OF INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings, which are included to provide a further understanding of the invention and are incorporated in and constitute a part of the specification, illustrate embodiments of the invention and together with the description serve to explain the principles of the invention. In the drawings:",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 10A"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
