---
title: System for executing computer programs on a limited-memory computing machine
abstract: A system for executing computer programs on a target platform having a limited amount of memory. Directives are suitably placed in the computer program source code at natural boundaries. The system uses the directives to extract structural information from the computer program and to produce a description of all program objects; to estimate typical object usage; and, to trigger transparent object paging to and from the limited platform memory during execution of the computer program. The system makes paging decisions prior to runtime by using relevant factors such as the typical usage of program objects and the size of each program object.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07036118&OS=07036118&RS=07036118
owner: Mindspeed Technologies, Inc.
number: 07036118
owner_city: Newport Beach
owner_country: US
publication_date: 20011220
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION","ODE Directives","Program Structure Extraction","Estimating Object Usage","Allocating Objects to Fast Memory","Application Retargeting","Generate Binary Image","Object Management System"],"p":["1. Technical Field","The present invention relates generally to the execution of computer programs on computing machines. More specifically, the present invention relates to a system for the execution of computer programs on computing machines that utilize a two-tier memory hierarchy comprised of a small, fast \u201clocal\u201d memory for program execution and a larger, slower \u201cbulk\u201d memory for program storage.","2. Background Information","Hierarchical memory systems are a well-known solution to the problem of connecting increasingly fast Central Processing Units (CPUs) with increasingly large, slow bulk storage. One or more additional stages of memory, decreasing in size and increasing in speed as one approaches the CPU, are inserted between the CPU and bulk storage. Often, the intermediate memories are too small to contain the entire application at one time. Therefore, paging is used to transfer code and data blocks between adjacent memories in response to the flow of the executing program. The problem within this context is designing and implementing a paging mechanism that effectively incorporates several main design considerations including:\n\n","Previous solutions to this paging problem generally fall into two categories: hardware caching (including the well-known virtual memory) and manual paging. Hardware caching is a well-known automatic mechanism that employs special-purpose hardware to monitor real-time memory access activity, detect cache misses, transfer fixed-size memory blocks (lines) between bulk memory and fast memory, and manage the placement and replacement of these lines within fast memory. The cache hardware design effectively partitions applications into fixed-size pieces, based on the application's location in bulk memory, without regard for the application's structure. The placement\/replacement policy is typically fixed (e.g. Least Recently Used, N-way Set Associative, Random Replacement algorithms) and designed to offer acceptable performance over a class of applications rather than being tuned for a specific application. Adoption of a Hardware Caching solution negatively impacts hardware complexity and power dissipation and, for architectures with multiple, concurrently-accessible memories (such as the Harvard architecture, common to most digital signal processors), requires cache hardware for each memory subsystem.","In manual paging, a programmer manually examines an application's source code and design documentation to understand the various functions embedded within the application and to decipher the application's program structure. Then, with knowledge of the target platform's fast memory resources and architecture, the programmer manually partitions the application and builds in a custom paging mechanism. This paging mechanism is actively managed during run time by program instructions added to the application by the programmer to page the resulting partitions into and out of fast memory as needed in real-time or near real-time. Manual paging requires no special-purpose hardware, but relies heavily on the capabilities of the programmer. The need to understand the underlying application involves substantial effort, especially if the programmer incorporating the paging mechanism is not the application's original programmer. Introduction of a platform with further-reduced fast memory requires another manual paging effort, perhaps by a different programmer. As application complexity increases and fast memory sizes decrease, the ability to manually implement the paging process is negatively impacted by the number of partitions involved and by errors introduced by the programmer.","The present invention provides a system for solving the aforementioned problem and achieves an advance in the field by eliminating the need for special-purpose caching hardware while, at the same time, removing the dependence on time-consuming, error-prone, art-based manual paging. In accordance with one aspect of the present invention, platform-independent directives are embedded within the software application to partition the application into a number of interdependent binary images called \u2018program objects\u2019, which are paged transparently to and from fast memory as needed during execution of the application. The concept of \u2018program objects\u2019 in the context of the present invention is a novel concept which is not related to the term \u2018objects\u2019 in the well-known context of \u2018object-oriented programming\u2019. The present invention defines a technology which transparently sequences the transfer of these objects between bulk memory and fast memory, thereby allowing execution of the application on the target platform.","The directives of the present invention are collectively referred to as \u2018ODE directives\u2019, where ODE denotes the \u2018Object Distribution and Execution\u2019 concept of the present invention. ODE directives serve the following unifying purposes within the system of the present invention:\n\n","In accordance with another aspect of the present invention, the application source code is first annotated by placing ODE directives within the application source code at intrinsic boundaries and at points of dependency. Such annotation can be performed manually (as with applications written in assembly language) or as part of an \u2018ODE aware\u2019 High Level Language (HLL) compiler. The directives identify boundaries in the source code which delineate program objects. The ODE directives also identify interconnections (i.e. dependencies) between the program objects.","Next, automated tools extract program structure from the annotated source code. The program structure includes object names, sizes, types, and dependencies.","The \u2018typical\u2019 usage of program objects during application execution is then estimated by the well-known procedure of stimulating the program with a set of typical test vector sequences and by counting object accesses as exposed by ODE directive occurrences.","Using the program structural and typical usage information, object allocation tools generate object placement rules that specify, a-priori, where objects will reside within fast memory at run time. Placement consists of designating objects as either static (resident for the duration of the application) or overlay (paged as needed) and fixing their locations in fast memory.","Next, automated tools port the application to the target platform by treating the ODE directives as an Application Programming Interface (API) and binding directive occurrences to the Object Management System (OMS) of the present invention. The OMS is a run-time mechanism that implements decisionless paging, driven by the application's placement rules, during execution of the application.","Finally, the resulting executable code and placement rules are merged into a binary application image that serves as the application's executable on the target platform.","The present invention may be described herein in terms of functional block components and processing steps. It should be appreciated that such functional blocks may be realized by any number of hardware components configured to perform the specified functions. In addition, those skilled in the art will appreciate that the present invention may be realized in a software or computer program context in conjunction with any number of conventional computer system environments. Furthermore, the present invention is not limited to the process flows described herein, as any process flow or rearrangement of process steps which captures the features of the present invention is considered to be within the scope of the present invention. It should be noted that the present invention may employ any number of conventional techniques for processing steps such as stimulating a computer program with a set of typical test vector sequences, and the like. Such general techniques that may be known to those skilled in the art are not described in detail herein.","It should be appreciated that the particular implementations and processes shown and described herein are illustrative of the present invention and its best mode and are not intended to otherwise limit the scope of the present invention in any way. For example, the names, types, and number of the various ODE directives may vary in different embodiments of the present invention and are not limited to those described herein.",{"@attributes":{"id":"p-0038","num":"0044"},"figref":["FIG. 1","FIG. 1"]},"As shown in , a set of entities in the application source code, hereinafter referred to as \u2018program objects\u2019 (or simply \u2018objects\u2019), is first defined at step . In accordance with the present invention, an application can be viewed as including sections which comprise executable code, constant data, and volatile (read\/write) data. Each of these three entities, executable code, constant data, and volatile data, constitutes a class of objects, which may be termed \u2018CODE\u2019, \u2018CDATA\u2019, and \u2018VDATA\u2019, respectively.","At step , ODE directives that define program object partitions are placed in the application source code at \u2018natural boundaries\u2019. ODE directives that express linkages between such partitions are placed at other locations in the source code, as explained below. ODE directives can be placed within the source code during the programming process, or can be added to an existing application without detailed knowledge of its inner workings.","With regard to application partitioning, the term \u2018natural boundaries\u2019 refers to boundaries between those entities which provide a conceptual basis for the structure of an application. For example, with regard to coding or analyzing an application, the application's structure may be conceptualized as comprising related entities such as functions and data structures; e.g., \u201cfunction X calls functions Y and Z, and accesses data from tables T1 and T2.\u201d Thus, one natural partitioning approach is to define a program object as a complete function, a complete data table, etc, in accordance with the present method. These program objects then become indivisible atomic units of application program information, represented by their memory images. The method of the present invention moves these program objects between bulk memory and fast memory in their entirety as determined by their dependencies on one another in structure and time.","At step , program structural information, exposed by the ODE directives embedded in the application source code, is extracted directly from the application. This is done by processing the directive-annotated source through the Object Database Compiler, which produces the Object Database. The Object Database comprises a description of all program objects in the applications and the types of interactions between them.","At step , the \u2018typical\u2019 usage of program objects during application execution is estimated. The information gathered in this step provides the basis for the selection of objects for static residency.","At step , the program objects are assigned (\u2018allocated\u2019) to fixed locations in target memory. The purpose of this phase is to determine, a priori, where to place (load) program objects in fast memory during run-time. Placement consists of designating objects as either static (bulk loaded and unloaded at the start and end of execution of an application frame) or overlay (loaded and possibly overwritten, as needed, during application execution) and fixing their locations in memory.","At step , the application is ported to a specific target platform. In this phase, an application's ODE exercise directives are bound to the target's Object Management System (OMS) mechanism, enabling transparent, decisionless, table-driven paging in real-time or near real-time. The OMS comprises the combination of platform-specific hardware and software that serves to control the movement of program objects as triggered by ODE directive occurrences during execution of the ODE-annotated application on the target platform.","Also at step , static\/overlay assignment information is embedded within the ODE directive implementations, enabling direct reference to static objects. Further, a unique Overlay Selector integer is assigned to each overlay object in the application and embedded within the ODE directive implementations in the application executable. OMS uses the Overlay Selector at run time to index an array of data structures that govern each object's transfer between bulk and fast memories when triggered by application execution.","At step , an executable binary image (BIM) is generated as the load module. The binary image contains the executable code and object management data structures that enable decisionless table-driven object transfers during application execution on the target platform.","At step , ODE directives are used to divide the application program source code into program objects according to natural application boundaries as identified in step . Additional directives are embedded into the application source code to indicate linkages between the program objects. Table 1 lists the ODE directives which may be employed when performing the method of the present invention.",{"@attributes":{"id":"p-0049","num":"0055"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"ODE Directives"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"BRANCH toObjectName - If CODE object toObjectName is not present"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"in local memory, load it. Transfer control to toObjectName."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"CALL objectName - If CODE object objectName is not present in local"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"memory, load it. Transfer control to objectName."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"CLOSE objectName - The specified object is no longer required and may"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"be removed from memory. An object may be removed from memory"]},{"entry":[{},"only when no objects depend on it."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"DEF_HANDLE objectName - Compile objectName's handle into current"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"object."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"ENDOBJ objectName - Marks the end of an object. objectName"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"preferably is the same as the corresponding OBJ directive."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"ENTRY objectName - Declares CODE object objectName as the entry"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"point of the application."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"GET objectName, offset, container | (ptr & len) - Read one MAU from"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"objectName + offset and store in container. Alternately, read len"]},{"entry":[{},"MAU starting from objectName + offset and store starting at ptr."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"GET_HANDLE objectName, handleContainer - Return the handle of the"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"specified object in handleContainer."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"OBJ objectName, objectClass - Marks the start of an object. objectName is"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"preferably unique within the application."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"OPEN objectName, pointerContainer - Load objectName if it's not already"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"loaded. Return a pointer to the object in pointerContainer."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"PUT objectName, offset, value | (ptr & len) - Write value to objectName +"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"offset. Alternately write len MAU from ptr to objectName + offset."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"RETURN toObjectName - If CODE object toObjectName is not present"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"in local memory, load it. Transfer control to toObjectName via return"]},{"entry":[{},"linkage."]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"One method of \u2018naturally\u2019 partitioning an application is to define each function in the application as a CODE object, and each data structure in the application as either a CDATA object or a VDATA object (i.e., an \u2018xDATA\u2019 object). A CDATA object comprises \u2018constant\u2019 data, such as a table of values. A VDATA object comprises \u2018volatile\u2019 or read\/write data, such as input\/output data or the application's state. Each CODE or xDATA object is indicated as being an object by bracketing it with directives that define the boundaries of the object and the type of object. The following pseudocode shows function F being defined as a CODE object by bracketing it between OBJ and ENDOBJ directives:",{"@attributes":{"id":"p-0051","num":"0057"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"OBJ(F,CODE);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"-- Body of F--"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ENDOBJ(\u2009);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"In accordance with one aspect of the present invention, object names may be unique within an application. This will allow each name to bind to a unique memory image. In accordance with this aspect of the present invention, multiple instances of an object could not appear in an application, just as two functions having the same name and calling parameters could not coexist in the same application.","Dependencies","The method of the present invention provides a mechanism for exposing the structure of an application as a set of inter-dependent objects. In the model representing the present method, only CODE objects have dependencies, i.e., CDATA and VDATA objects are considered independent. For example, with respect to a CODE object, data dependencies are those data objects that must be present in local memory during the execution of the CODE object, as exposed by OPEN directive occurrences. Code dependencies are created when a CODE object CALLs or BRANCHes or RETURNs to other CODE objects.","The concept of \u201cexercising a dependency\u201d may be defined as \u201cusing what an entity is dependent on.\u201d For example, when X CALLs Y, Y is exercised by X. If a data table is exercised, one or more of its elements is accessed. Exercise of a dependency occurs either explicitly or implicitly.","Explicit exercise of a dependency occurs via an ODE directive so that the retargeting phase of the present method can implement the directive as a specific instruction sequence required to effect the required behavior on the target execution platform. An explicit exercise is a trap door into the Object Management System (OMS), the target-specific mechanism responsible for acquiring, managing and updating program objects in real-time or near real-time.","Table 2 (below) lists the directives through which program objects can be explicitly exercised.",{"@attributes":{"id":"p-0057","num":"0063"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Program Object Explicit Exercise Directives"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Class","Unique Method(s)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"CODE","CALL, RETURN, BRANCH"]},{"entry":[{},"CDATA","OPEN, CLOSE, GET"]},{"entry":[{},"VDATA","OPEN, CLOSE, GET, PUT"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},"Implicit exercise of a dependency occurs when an object is manipulated directly through a pointer (returned by OPEN, see below), rather than through a directive. This allows increased speed of execution (e.g. direct access to a memory table during convolution) and makes the full instruction set of the processor available to the programmer.","Program Object Access and Scope","When it is desired to manipulate the content of an object implicitly, the Object Management System may be notified that access to the object is required and a pointer \u2018p\u2019 to the object can be obtained. This is accomplished by the OPEN directive:",{"@attributes":{"id":"p-0060","num":"0066"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"OBJ(X,CODE);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"--some code \u2014",{}]},{"entry":[{},"pY = OPEN(Y);","\/\/ get Y's image, pY points to Y"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"-- some code exercising Y using pY \u2014"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"CLOSE(Y);","\/\/ Y goes out of scope"]},{"entry":[{},"-- some final code \u2014"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ENDOBJ(\u2009);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The OPEN directive returns a pointer to the specified object and marks, within the application flow, the point at which the object is made available for implicit exercise. The CLOSE directive notifies the Object Management System that the specified object is no longer needed and the associated memory may be freed if no other objects are dependent on it.","In accordance with one aspect of the present invention, within a dependent CODE object, OPENs and CLOSEs may be balanced. Furthermore, in accordance with another aspect of the present invention, each dependent object may explicitly OPEN and CLOSE objects on which it is dependent. If a CALLed object needs access to an object used in a CALLing object, it may explicitly OPEN and CLOSE the object itself. Pointers for implicit exercise are valid only within the confining OPEN\/CLOSE pair.","Note that an object does not need to be OPENed before explicitly exercising it. An explicit exercise trap is sufficient for the Object Management System to determine if the associated object is resident and, if not, to suspend the exercising object and transfer the object from bulk memory to fast memory. Thus, for example, a CODE object does not have to be OPENed before being CALLed.","Data Object Access via GET and PUT","There are occasions where it is desirable to access only a few elements of a data object, as in a structure operation. The present method provides three mechanisms for implementing such access: implicit access, explicit local access, and explicit remote access to a data object.","In implicit access, an object is OPENed and the desired element(s) are then accessed via the object pointer:",{"@attributes":{"id":"p-0066","num":"0072"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"OBJ(X,CODE);"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"pY = OPEN(Y);","\/\/ get Y's image, pY points to Y"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"*(pY+3) += 1;","\/\/Y[3] = Y[3] + 1"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"CLOSE(Y);","\/\/ Y goes out of scope"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"ENDOBJ(\u2009);"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Explicit Local Access uses OPEN, GET and PUT to explicitly access an object locally (i.e. from fast memory):",{"@attributes":{"id":"p-0068","num":"0074"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"OBJ(X,CODE);"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"OPEN(Y);","\/\/ get Y's image, no pointer returned"]},{"entry":[{},"PUT(Y,3,GET(Y,3)+1);","\/\/ Y[3] = Y[3] + 1"]},{"entry":[{},"\u2002CLOSE(Y);","\/\/ Y goes out of scope"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"ENDOBJ(\u2009);"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"If Y is a large object, both prior solutions are potentially overhead-expensive. The entire object must be fetched, even though only one datum of information is modified. To make this type of access more efficient, one may use Explicit Remote Access, where GET and PUT are used without OPENing the exercised object:",{"@attributes":{"id":"p-0070","num":"0076"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"OBJ(X,CODE);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"PUT(Y,3,GET(Y,3)+1);","\/\/ Y[3] = Y[3] + 1"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ENDOBJ(\u2009);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"In the above case, the Object Management System (OMS) may be implemented in one of two ways. The OMS may perform implicit OPENs and CLOSEs, resulting in the same behavior as in the explicit local access example. Alternatively, the OMS may access the specified element(s) directly from, and update the element directly to, bulk memory rather than fetching the entire object. This \u2018remote\u2019 mechanism can dramatically reduce object acquisition and update penalties.","Vector Access","GET and PUT can also transfer multiple minimum addressable units of data directly:",{"@attributes":{"id":"p-0073","num":"0079"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"OBJ(X,CODE);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"112pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"GET(Y,3,p,5);","\/\/ Get Y[3] through Y[7] in *p"]},{"entry":[{},"-- Modify *p --"]},{"entry":[{},"PUT(Y,3,p,5);","\/\/ Update Y[3] through Y[7]"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ENDOBJ(\u2009);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"To this point, objects have been referenced explicitly by name. This constitutes static binding, in which knowledge of object usage is available at compile time. Often, however, the identity of the object to be exercised may not be known until run time. For example, the application may choose one of several data tables depending on run-time conditions. One typical way to handle this situation is to code a table of pointers to the tables, then index the table at run-time to get the pointer for the specific table required. The pointer table is statically bound at compile time, but dynamically referenced at run time.","In a limited memory environment as dealt with by the method of the present invention, this solution of statically binding pointers at compile time is not available because program object pointers exist only at run-time within the scoping OPEN\/CLOSE directives of an exercising CODE object. Pointers cannot be statically bound into a data table because the pointers do not exist at build time. To allow use of the programming paradigm described above, the present method defines the concept of Object Handles. An Object Handle is a numeric, rather than symbolic, reference to a program object. The DEF_HANDLE directive returns an object handle as illustrated by the following code:",{"@attributes":{"id":"p-0076","num":"0082"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"OBJ(ptrTab,CDATA);"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"OBJ_HANDLE array[3] = {"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"DEF_HANDLE(T1);","\/\/ define handle for object T1"]},{"entry":[{},"DEF_HANDLE(T2);","\/\/ define handle for object T2"]},{"entry":[{},"DEF_HANDLE(T3);","\/\/ define handle for object T3"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"};"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"ENDOBJ(\u2009);"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"The GET_HANDLE directive is used to access a handle from the table, which can then be used as if it were a name in any of the other directives:",{"@attributes":{"id":"p-0078","num":"0084"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"OBJ(someFunction,CODE);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"238pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"-- some code that gets a table index I --"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"105pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"pPtrTab=OPEN(ptrTab);","\/\/ OPEN ptrTab"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"hTable=GET_HANDLE(pPtrTab+(I*Obj_handle_size));","\/\/ read handle"]},{"entry":[{},{},"\/\/ from table"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"105pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"CLOSE(ptrTab);","\/\/ don't need ptrTab"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"pObj=OPEN(hTable);","\/\/ OPEN table by handle"]},{"entry":[{},"-- use the selected table --"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"105pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"CLOSE(hTable);","\/\/ CLOSE table by handle"]},{"entry":[{},"-- some more code--"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"ENDOBJ(\u2009);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"GET_HANDLE can also be used directly on named objects:"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"OBJ(someOtherFunction,CODE);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"238pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"if (someCondition)"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"h = GET_HANDLE(objX);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"238pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"else"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"h = GET_HANDLE(objY);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"105pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"CALL h;","\/\/ calling via handle"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ENDOBJ(\u2009);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"In any significant piece of application code, there are natural partitions which are effectively defined by the code itself, apart from the functional (e.g. function, table, structure) partitioning described earlier. These partitions occur at change-of-flow points, or flow breaks. A flow break occurs when a CALL or BRANCH is made. All code between flow breaks will inevitably execute, so it is advantageous to package all such sequential code, terminated by a flow break, as an object. If performed globally, such an exercise results in an application with \u201cnatural\u201d partitioning. Such natural partitioning is advantageous when compared with traditional fixed-line-size hardware cache. These \u2018natural partitions\u2019 are analogous to variable cache lines, specific to the application.","The present method ensures that such naturally partitioned objects will execute in their entirety, which is an advantage over traditional cache operation, wherein a cache miss results in a fetch of the requested data\/instruction group, as well as the \u201cnext data\/instruction group\u201d, based on the assumption that future execution or access will occur in that group. In the present method, the program object-based nature of the application partition means that a \u201ccache miss\u201d will result in the fetching of exactly the data required. Since flow breaks are already marked by directives (e.g., BRANCH, CALL), no additional work is required to enable natural partitioning. Such flow-break partitioning can be automated or manually (programmer) directed.","The following code presents an example of a manually inserted flow break:",{"@attributes":{"id":"p-0082","num":"0088"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"OBJ(X,CODE);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"-- some code --"]},{"entry":[{},"BRANCH(LT,Y,BREAK); \/\/ on less-than, goto Y"]},{"entry":[{},"-- some more code"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ENDOBJ(\u2009);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"In this example, it is obvious to a practitioner in the art (e.g., a programmer) that the code forks at the BRANCH. Since the portion of the code after the BRANCH may or may not be executed in a given instance, fetching this portion as part of X will sometimes prove a wasted effort. Thus, a BREAK may be coded into the BRANCH, directing the ODE-aware source processor (compiler or assembler) to end X with the BRANCH and start a new, non-programmer-defined object (e.g., X0) after the BRANCH. The BRANCH directive now always triggers acquisition of a new object, either Y or X0.","Following is an additional example of a manual flow break:",{"@attributes":{"id":"p-0085","num":"0091"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"OBJ(A,CODE);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"-- some code --"]},{"entry":[{},"CALL(B,BREAK); \/\/ call B, return to A_0!"]},{"entry":[{},"-- some more code"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ENDOBJ(\u2009);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"In the above example, the return from B actually triggers acquisition of A0. This example shows why implementation of manual breaks is optional: the run-time required to implement such a bifurcated flow change may cause an unacceptable performance impact. Manual BREAKs allow an integrator to fine-tune performance by selective insertion of BREAK directives.","Automatic global partitioning may optionally be performed by instructing the ODE-aware source processor to always insert breaks at flow change directives (CALL, BRANCH), i.e., as if all flow break directives were annotated with the BREAK directive. This results in a naturally partitioned application with perhaps considerably more objects than were defined by the programmer. Such an implementation may be useful on platforms with hardware-assisted object acquisition. In any event, such a step is completely transparent to the programmer and application.","Entry Point","Every application must have an entry point at which it starts execution. The ENTRY directive exposes the program CODE object that serves as the execution \u201cseed\u201d:\n\n","This example marks program CODE object X as the entry point for the application.","The next step in the present method, step  (shown in ), is performed after the application source code has been annotated by insertion of the ODE directives described above. The purpose of this phase is to extract program structural information, exposed by the ODE directives, directly from the application.",{"@attributes":{"id":"p-0091","num":"0098"},"figref":["FIG. 4","FIG. 4","FIG. 5"],"b":["401","410","500","500","510","516","530","500","410"]},"The Object Descriptor  is the lowest-level structure in Object Database . Each object in an application has associated with it a unique Object Descriptor . The plurality of Object Descriptors representing all objects in an application is termed the Object Descriptor Pool . The Object Database Compiler  generates Object Descriptors  from ODE OBJ\/ENDOBJ directive pairs encountered in the source code (and from flow breaks, if any). The Object Descriptor  specifies the object's class, size and name.","For CODE objects only, the Object Descriptor also contains a list (which is possibly empty) of Dependency Descriptors . These Dependency Descriptors  collectively constitute an object's Dependency List . Each Dependency Descriptor  specifies an Object Descriptor pointer  (identifying the object the listing object is dependent on) and the \u201cExercise Type\u201d  of dependency (BRANCH, CALL, OPEN). Each Dependency Descriptor  is generated from an ODE exercise directive encountered in the source (duplicate references to the same object are filtered). Note that handle-based exercises are marked with a NULL Object Descriptor Pointer .","As shown in , the Object Table  is an array of pointers to the Object Descriptors  of all program objects comprising the application. By locating and traversing Object Table , the Structure Extractor  is able to determine the number, types, sizes and attributes of all program objects.","The Entry Descriptor  points to the Object Descriptor of the CODE object that serves as the application's entry point. The Object Database Compiler generates Entry Descriptor  when the ENTRY directive is encountered in the source code.","Generation of the Object List  and Data Dependency Database  by the Structure Extractor  is next explained, using the Object Database  as input. The Object List  is generated by extracting the object information from the Object Table  in the Object Database , sorted by object type and name. The Object List  lists all objects of all types in the application. In addition, unique integer Object IDs are assigned to each CODE object in the application. These are used in the retargeting phase to resolve the context of exercised overlay data objects. This is explained in detail below in the application retargeting section.","An example of an Object List  is shown below in Table 3.",{"@attributes":{"id":"p-0098","num":"0105"},"tables":{"@attributes":{"id":"TABLE-US-00013","num":"00013"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Object List"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"56pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Object Name","Object ID","Type","Size"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"56pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"A","1","CODE","257"]},{"entry":[{},"B","2","CODE","33"]},{"entry":[{},"C","3","CODE","271"]},{"entry":[{},"T1","4","CDATA","1700"]},{"entry":[{},"T2","5","CDATA","3400"]},{"entry":[{},"D1","6","VDATA","46"]},{"entry":[{},"D2","7","VDATA","644"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}]}}},"The Data Dependency Database  is generated by the Structure Extractor  from information in the Object Database . The Data Dependency Database  enumerates, for each CODE object in the application, those CDATA and VDATA objects that the CODE object can OPEN (and therefore implicitly exercise) during its execution. This information is necessary during memory allocation.","Table 4 is an example of a Data Dependency Database :",{"@attributes":{"id":"p-0101","num":"0108"},"tables":{"@attributes":{"id":"TABLE-US-00014","num":"00014"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 4"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"A: D1, D2, T1"]},{"entry":[{},"B: D2, D4"]},{"entry":[{},"C:"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"The first line in Table 4 indicates that CODE object A, at some point in its execution, OPENs data objects D1, D2 and T1. The second line indicates CODE object B's dependence on data objects D2 and D4. The third line indicates that CODE object C has no data dependencies.",{"@attributes":{"id":"p-0103","num":"0110"},"figref":["FIG. 6","FIG. 6"],"b":["422","422","510","500","605","610","660","615","530","531","540","625","630","655","640","422","650"]},"Note here that there is a special procedure required for dependencies on handles. Handles are not resolvable until run-time. When processing the dependencies of a CODE object, if, at step , a dependency on a handle is found (indicated by a NULL Object Descriptor Pointer  and an Exercise Type  of \u2018OPEN\u2019), it is necessary to determine the pool of data objects which the handle can reference, at step . This is necessary in order to enable the a priori memory allocation technique of the present method. Though it may be possible to automate this via source execution path analysis, often the pool of candidates is small enough and localized to the scope of the exercising CODE entity that manual input of the required list of candidate objects is expedient.","Step  (in ) occurs after structure extraction. Its function is to estimate the usage of all application program objects during \u201ctypical\u201d application execution. This information is used during Memory Allocation  to select the best candidates for static allocation.  illustrates the process.","As shown in , ODE-Annotated Source Code , with Usage-Specific ODE Directives , is processed through Build Process step , producing Executable . Usage-specific ODE Directives  implement ODE directives CALL, BRANCH, RETURN, OPEN, and CLOSE in such a manner that their execution, at step , causes exercise event information to be written to a Trace (). Specifically, Executable  is exercised using (\u2018stimulated\u2019 by) test vector suite  on execution platform . Test Vector Suite  comprises a plurality of test vectors (), a concept well-known to practitioners in the art, that define \u2018typical\u2019 stimuli to which the application is likely to be exposed.","Execution of step  thus produces Trace Suite , which comprises a plurality of Traces () in one-to-one correspondence with each of the test vectors (). Trace Suite  is processed by Trace Compiler  to produce Object Usage Database  which enumerates, for each object in the application, the expected (average) number of times the object is exercised (comes into scope) during a \u2018typical\u2019 application \u2018run\u2019.","The specifics of the procedures performed by Build Process step  and Execution Platform step  are dependent on the specific implementation of the source development environment associated with the native language of the ODE-Annotated Source Code .","More specifically, an exemplary source development environment  for the target platform  of  comprises an assembler, linker and simulator, which are programmed utilities well-known to practitioners in the art. Build Process step  utilizes the assembler and linker. Execution Platform step  utilizes the simulator. An exemplary embodiment of usage-specific ODE directives  for the source development environment  is an include file, or header file, a form well-known to practitioners in the art. Each ODE directive implementation in the include file uses services of the simulator to write information comprising the exercise type and exercised object to Trace File () during execution of the application, stimulated by test vector (), on the simulator. At step , ODE-annotated source code  is assembled and linked for execution on simulator , resulting in executable . Simulator  has enough memory to contain the entirety of executable , which runs in a traditional \u2018flat\u2019, non-paged manner while being stimulated by Test Vector Suite , producing Trace Suite .","An exemplary Trace () is shown below in Table 5.",{"@attributes":{"id":"p-0111","num":"0118"},"tables":{"@attributes":{"id":"TABLE-US-00015","num":"00015"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"119pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 5"},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":[{},{},{},"Exercise"]},{"entry":["Step","Trace","Operation","Count"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["\u20021","CALL X","Fetch X","X = 1"]},{"entry":["\u20022","CALL Y","Fetch Y","Y = 1"]},{"entry":["\u20023","OPEN D1","Fetch D1 (VDATA)","D1 = 1"]},{"entry":["\u20024","OPEN T1","Fetch T1 (CDATA)","T1 = 1"]},{"entry":["\u20025","CALL Z","Fetch Z","Z = 1"]},{"entry":[{},{},"Update D1 (save Y's data context)","D1 = 2"]},{"entry":["\u20026","OPEN D1","Fetch D1 (nested OPEN)","D1 = 3"]},{"entry":["\u20027","CLOSE D1","Update D1","D1 = 4"]},{"entry":["\u20028","RETURN","Re-fetch Y (restore Y's code context)","Y = 2"]},{"entry":[{},{},"Re-fetch D1 (restore Y's data context)","D1 = 5"]},{"entry":[{},{},"Re-fetch T1 (restore Y's data context)","T1 = 2"]},{"entry":["\u20029","CLOSE T1","T1 is CDATA so no update","T1 = 2"]},{"entry":["10","CLOSE D1","D1 is VDATA so update","D1 = 6"]},{"entry":["11","RETURN","Re-fetch X","X = 2"]},{"entry":["12","RETURN","X terminates"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}}}},"The Exercise Count column shows the operation of Trace Compiler , which processes each Trace () of Trace Suite  and keeps an \u2018exercise count\u2019 for each object in the application. This example assumes the memory allocation algorithm defined by the methods referenced by  (described in the next section).","An object's exercise count is incremented whenever that object comes into scope, i.e. when it is resident in memory. Note that at this stage, static\/overlay decisions have not yet been made, so an exercise count so derived serves to expose an object's potential performance impact as an overlay.","RETURN events are implicit exercises of the returned-to object. Due to the allocation method of  (described in the next section), wherein overlay objects all overwrite each other, a RETURN to an overlay object may require a fetch of that object, hence all RETURNs increment the returned-to object's exercise count. In addition, a RETURN triggers a restoration of the data context of the returned-to object, i.e. the fetching of all data objects that were OPEN at the time the returned-to object did the CALL that caused it to go out of scope. Hence, at step  (in Table 5), D1 and T1 have their exercise counts incremented.","When a VDATA object is CLOSED, the object is written back to bulk memory (updated) in order to preserve its state. Due to the allocation method shown in  (described in the next section), this update also occurs when control transfers to a new CODE object, since the method described with respect to  specifies that the overlay memory area \u2018belongs\u2019 to the active CODE object. Thus, at step  (in Table 5), D1 within Y's context is updated even though the CALLed Z also uses D1. Note that when a CDATA object is CLOSEd no update is required so its exercise count doesn't change.","An exemplary Object Usage Database  for the single Trace () is shown in Table 6 below:",{"@attributes":{"id":"p-0117","num":"0124"},"tables":{"@attributes":{"id":"TABLE-US-00016","num":"00016"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 6"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"X","2"]},{"entry":[{},"Y","2"]},{"entry":[{},"Z","1"]},{"entry":[{},"D1","6"]},{"entry":[{},"T1","2"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"Over a plurality of such Test Vectors () and resulting Traces (), one might find that object usage varies from Trace to Trace. Averaging the individual Traces might produce an exemplary Object Usage Database  shown in Table 7, below:",{"@attributes":{"id":"p-0119","num":"0126"},"tables":{"@attributes":{"id":"TABLE-US-00017","num":"00017"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 7"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"X","2"]},{"entry":[{},"Y","2"]},{"entry":[{},"Z","0.5"]},{"entry":[{},"D1","5.2"]},{"entry":[{},"T1","1.8"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"The Object Usage Database  exposes an application's \u201ctypical\u201d object usage, for a given allocation strategy, in a platform-independent \u2018object domain.\u2019","The next phase in the present method, target memory allocation, is performed at step  (in ), after the application's structural dependencies and typical object usage characteristics have been determined as described above.",{"@attributes":{"id":"p-0122","num":"0129"},"figref":"FIG. 11","b":["421","422","1101","1106","1106","1107"]},"In the preferred embodiment, each object is prioritized for static allocation by a cost function termed \u2018penalty density\u2019. An object's penalty density is a measure of the cost of acquiring the object as an overlay. The ith object's penalty density Pdepends on the following object and target characteristics:","(a) the object's size S, from Object List ;","(b) the object's typical usage N, from Object Usage Database ;","(c) the average number of platform clock cycles Cof control overhead, required to process a fetch request for object i. This parameter is determined by the OMS implementation for a specific platform and captures the execution time of the ODE directive traps, communication overhead to the object server, and server execution time;","(d) the average number of platform clock cycles Arequired to acquire control (arbitration latency) of the data transfer entity that actually does the transfer of object i. This parameter is determined by analysis or empirical measurement of the target hardware platform bus characteristics; and","(e) the average number of platform clock cycles Trequired to transfer object i's image between bulk storage and local memory. This parameter is a function of the size of the object and the bus transfer characteristics of the target hardware platform.","The penalty density Pfor object i is computed using the following formula:\n\n()]\/S\n","For illustrative purposes of the memory allocation process,  presents an exemplary target hardware platform  on which applications are to run. Platform  includes an application processor  and associated fast memory \/ (here exemplified as a Harvard architecture), which is not large enough to simultaneously contain the entire application's executable code and data image. Target platform  represents only one possible exemplary hardware configuration to which the method of the present invention is applicable. For example, processor  is exemplified herein as a digital signal processor (\u2018DSP\u2019), but processor  could be any other type of processor. It should be noted that the present method is operable with target platforms comprising single processors as well as with platforms comprising distributed processors.","In an exemplary embodiment, application processor  includes a digital signal processor (DSP)  and ROM memory , and is hereinafter referred to simply as DSP . Control processor , which functions as the \u2018Object Server\u2019 , is used for transferring executable code and data between bulk storage synchronous DRAM (SDRAM)  and DSP  fast memory, which comprises program RAM (PRAM)  and data RAM (DRAM) . In , data paths are indicated by solid lines and control paths are indicated by dashed lines. Control processor  communicates with DSP  via dual-port RAM memory . Both data and control information are passed through this dual-port memory , which is used to signal memory transfer requests (and the completion thereof) between control processor  and DSP . Code and data are transferred between SDRAM  and DSP program and data RAM \/ by a DMA controller , which is considered a peripheral device of processor .","For a given application, the memory allocation phase of the present method identifies program objects that are candidates for static caching, in which objects are loaded once at the start of, and remain in memory for the duration of, an application's execution. Candidates for static caching are objects that come into scope often during the application's execution. Areas in PRAM () and DRAM () are reserved for these Static Program Objects. The static allocation address assigned to each Static Program Object by Memory Allocator  of the present method is built into the application's load image. Static Program Objects are exercised by direct reference to their addresses.","Those objects that cannot be statically cached because of memory constraints are instead dynamically paged as they are needed. These objects are termed Overlay Program Objects because they may overwrite one another during execution. Overlay Program Object fast memory spaces are allocated in both PRAM () and DRAM () by Memory Allocator . Allocation addresses are assigned a priori and embedded in the load image of the target application.",{"@attributes":{"id":"p-0134","num":"0141"},"figref":"FIG. 8","b":"211"},"As shown in , at step , all CODE objects are sorted into a Candidate List by decreasing penalty density, with the greatest-penalty object on the top of the list. At step , the Candidate List is searched to find the object with the largest size. At step , a check is made to ensure that program RAM (PRAM)  is large enough to contain the largest CODE object in the Candidate List. If not, the CODE object may be further partitioned, or a larger local memory  may be used. If the size of PRAM  is sufficient, then, at step , an Overlay List is initialized to empty. At step , the size of overlay area () in PRAM  is initially set equal to the size of the entire PRAM area . At step , the current base location ALLOC_BASE for allocating static CODE objects in the static area of PRAM () is set to the base location in PRAM .","At step , the size of overlay area () is adjusted (decreased) by the size of the top CODE object in the Candidate List. At step , the Candidate and Overlay Lists are searched to find the object with the largest size, excluding the top object in the Candidate List. A check is made at step  to determine whether the adjusted overlay area size is at least as large as the size of the largest CODE object in the Candidate List. If not, then at step , the top object in the Candidate List is moved to the Overlay List, and flow proceeds to step . If the adjusted overlay size is sufficient to contain the largest CODE object in the Candidate and Overlay Lists, excluding the top object in the Candidate List, then at step , the top object in the Candidate List is allocated, as a static program object, to the current base location (ALLOC_BASE) of static area () of PRAM . At step , the current base location (ALLOC_BASE) of static area () is adjusted (incremented) by the size of the object allocated in step  (the top object in Candidate List). At step , the size of the overlay area (OVERLAY_SIZE) is adjusted to reflect the decrease in size due to allocation of the object. At step , the top object in the Candidate List is removed from the list. A check is made at step  to determine if there is at least one object remaining in the Candidate List. If so, then the loop (steps \u2013) is repeated to see if there is sufficient memory left in PRAM  to accommodate additional static objects. If, at step , there are no objects left in the list, then all objects in the Overlay List are allocated to ALLOC_BASE, where they overlay each other during program execution.",{"@attributes":{"id":"p-0137","num":"0144"},"figref":["FIG. 9","FIG. 9"],"b":["212","422"]},"As shown in , at step , all xDATA (CDATA and VDATA) objects are sorted into a Candidate List by decreasing penalty density, with the greatest-penalty object on the top of the list. At step , Data Boxes are computed for each CODE object, and the Data Boxes are sorted into a Data Box List by increasing size.",{"@attributes":{"id":"p-0139","num":"0146"},"figref":["FIG. 10","FIG. 10","FIG. 10"],"b":["1000","1"]},{"@attributes":{"id":"p-0140","num":"0147"},"figref":["FIG. 7","FIG. 10","FIG. 10","FIG. 7"],"b":["701","702","703"]},"As shown in , at step , a check is made to ensure that data RAM (DRAM)  is large enough to contain the bottom (largest) Data Box in the Data Box List. If not, a larger local memory  may be used. If the size of DRAM  is sufficient, then, at step , an Overlay List is initialized to empty. At step , the size of overlay area () in DRAM  is initially set equal to the size of the entire DRAM area . At step , the current base location ALLOC_BASE for allocating static DATA objects in the static area of DRAM () is set to the base location in DRAM .","At step , the size of overlay area () is adjusted (decreased) by the size of the top object in the Candidate List. At step , Data Boxes are computed for each CODE object, using all objects in the Candidate and Overlay Lists, excluding the top object in the Candidate List. The list of Data Boxes thus computed is sorted into a Trial List. A check is made at step  to determine whether the adjusted overlay area size is at least as large as the size of the largest (bottom) Data Box in the Trial List. If not, then at step , the top object in the Candidate List is moved to the Overlay List and flow proceeds to step .","If the adjusted overlay size is sufficient to contain the largest Data Box, then at step , the Data Box List is set equal to the Trial List. At step , the top object in the Candidate List is statically allocated to the current base location (ALLOCBASE) of static area () of DRAM . At step , the current base location (ALLOCBASE) of static area () and the overlay size (OVRLAY_SIZE) of overlay area () are adjusted by the size of the object allocated in step  (the top object in the Candidate List). At step , the top object in the Candidate List is removed from the list. A check is made at step  to determine if there is at least one object remaining in the Candidate List. If so, then the loop comprising steps \u2013 is repeated to see if there is sufficient memory left in DRAM  to accommodate additional static objects. If, at step , there are no objects left in the Candidate List, then in step , all remaining Data Boxes in the Data Box List are allocated to ALLOC_BASE, where they overlay each other during program execution. The addresses of the overlay objects in each Data Box are then fixed.","The next phase in the present method, retargeting the application to a specific target, is performed at step  (in ). This binds an ODE-annotated application to the OMS. In this phase, the ODE directives play a role analogous to that performed by a program API (Application Program Interface) and the OMS plays a role similar to an operating system such as Unix or Windows. The present method utilizes the ODE directives as a vehicle in performing the \u201cAPI-like\u201d function of mapping a set of well-defined services to a specific computer's environment.",{"@attributes":{"id":"p-0145","num":"0152"},"figref":["FIG. 12","FIG. 12"],"b":["1220","1230","1240","1210"]},"Assign Overlay Selectors","The Assign Overlay Selectors activity  is a straightforward assignment of consecutive integer identifiers, starting at , to each overlay object in the application. These Overlay Selectors  are embedded within the application executable image, manipulated by ODE directive traps, and ultimately used by Object Server  to index the Overlay Management Array  and quickly access the object's memory residency status and loading information. Overlay data objects exercised from different CODE objects are considered separate objects and therefore have different overlay selectors. The Overlay Selector Database  captures the overlay selector assignments for the overlay objects.",{"@attributes":{"id":"p-0147","num":"0154"},"figref":["FIG. 12","FIG. 11"],"b":["1222","1221","1107","1106"]},"CODE Object Name@ Overlay Selector","or with an xDATA object as:","xDATA Object Name Exercising CODE Object Name@ Overlay Selector","In the example shown in , Overlay Data Object D3 is exercised from CODE objects A and B, thus, the overlay selector () (the integer \u20184\u2019 following the \u2018@\u2019 symbol) for D3:A is different from the overlay selector () (the integer \u20185\u2019 following the \u2018@\u2019 symbol) for D3:B. The \u201c:A\u201d and the \u201c:B\u201d following \u201cD3\u201d in overlay selectors () and () indicate the respective \u2018exercised from\u2019 contexts of the D3 Object.","The Assign Overlay Selectors activity  recognizes overlay xDATA objects within Allocation Database  that are exercised from more than one CODE context, as in D3 above (e.g. the occurrence of D3:A and D3:B within Allocation Database  signifies such a case). In such cases, the Assign Overlay Selectors activity  assigns an additional Overlay Selector for the \u2018alpha object\u2019 (D3 in the example), a context-insensitive entity that enables handle-based references of such multiple-context objects when the exercising context is unclear. This selector is used whenever DEF_HANDLE or GET_HANDLE references targeting such multiple-context objects are encountered in the source, and is resolved by Object Server  via the object's Alpha OMD  and the exercising CODE object's Object ID (see Table 3). This concept is discussed further in the Object Management System section.","Continuing the example of , the Assign Overlay Selectors activity  recognizes that D3 is exercised from more than one CODE context and assigns an overlay selector () (the integer \u20183\u2019) to context-insensitive alpha object D3. This selector is used whenever \u2018DEF_HANDLE D3\u2019 or \u2018GET_HANDLE D3\u2019 references are encountered in the source. D4 is only referenced from one CODE object, E, and therefore no alpha object for D4 is needed.","Overlay Selector Database  is used by the final phase of the present method, binary image generation, to construct the control structures necessary to manage the transfer of overlay objects to and from the target platform during application execution. An automated Selector Assigner mechanism  (typically a programmed utility) performs the Overlay Selector assignments for all ODE applications across all potential execution targets.","Mapping","As shown in , the Mapping activity  is performed for each application ported to the execution platform, resulting in an application specific Mapping Database , the form of which is target specific. In accordance with the present method, an automated Mapper mechanism  (typically a programmed utility) is manually designed and implemented once per execution target to automate the process of Mapping Database generation . The implementation of Mapper  depends on the target-specific ODE Trap Specification . Individual invocations of Mapper  accept the Object List , Allocation Database  and Overlay Selector Database  as input in order to generate a unique Mapping Database  for each individual application. Mapping Database  for the exemplary target platform of  comprises ODE Directive Include File  and Linker Command File .","Build Memory Images","The Build Memory Images activity  produces the Memory Image Database , comprising binary memory images of all program objects comprising the application, as illustrated by exemplary contents . The binary memory image of a program object is the object's contents: executable code for CODE objects; constant data values for CDATA objects; and initializing data values for VDATA objects. An exemplary description best serves to illustrate the Build Memory Images  activity. Assume again the exemplary target platform  of  and the previous discussion of Mapping Database generation .",{"@attributes":{"id":"p-0156","num":"0163"},"figref":"FIG. 15","b":["1240","1510","1511","401","1230","421","1106","1230","215","1521","1520","1530","1521","1106","1230","1530","1540","1530","1521","1241"]},{"@attributes":{"id":"p-0157","num":"0164"},"figref":["FIG. 16","FIG. 1"],"b":["1620","160","1610","1620","1620","1530","1620"]},"BIM  contains two classes of information:","(1) Object Image Pool  comprising the CODE and xDATA object images from Memory Image Database ;","(2) control structures that contain the information necessary to manage the decisionless, table-driven transfer of these objects at run-time.","Item (2), above, further comprises two classes of information:\n\n","In the exemplary target platform of , the load\/unload descriptors and the Overlay Management Array are located in SDRAM . Both types of control structures embed the DMA transaction information. This transaction information includes the DMA parameters necessary for a block data transfer between SDRAM  and program\/data RAM (\/) that allows the run-time management process to be a low-overhead, decisionless table-lookup process.","Following is a description of BIM  creation by the Generate Binary Image activity .","Load Descriptor  comprises a list of components of the form of (), each of which describes a static program object (CODE, CDATA or VDATA). All such static objects defined in the application, as enumerated in Allocation Database , are represented in Load Descriptor . Each static object is loaded from Object Image Pool  to target memory prior to running the application. Load Descriptor  thus serves to drive the load phase of the application life cycle.","Unload Descriptor  comprises a list of components of the form of (), each of which describes a static VDATA program object. All such static objects defined in the application, as enumerated in Allocation Database , are represented in Unload Descriptor . Each static VDATA object is unloaded from target memory to Object Image Pool  within Binary Image  after running the application, in order to preserve the application's state between runs. Unload Descriptor  thus serves to drive the unload phase of the application life cycle. CODE and CDATA objects cannot be changed and do not have to be saved.","Overlay Management Array (OMA)  is constructed from information in Allocation Database , Object List  and Overlay Selector Database . According to the numeric Overlay Selector ordering in Overlay Selector Database , Object Management Descriptor (OMD)  or Alpha OMD  entries are created. Residency () is set to \u2018non-resident\u2019. Src, Dest and Len of entry () are set to the object's memory image base in Object Image Pool , allocated base address in Allocation Database , and object size in Object List , respectively. Overlay List () is constructed by examining which objects are overwritten by the listing object, per the address information in Allocation Database .","Object Image Pool  is assembled from Memory Image Database .","Exemplary Application Lifecycle",{"@attributes":{"id":"p-0167","num":"0178"},"figref":["FIGS. 3A","FIG. 2","FIG. 3A"],"b":["3","3","200","205","210","309","303","304","1621","207","309","204","211","212","215"],"i":["a","a"]},"As shown in , if DSP  issues a CALL to object X (see Table 1: Directives, in the appendix of this document), if X is a Static Program Object, it is already in the static memory area of program RAM (). If X is a Static Program Object, the mapping phase  has implemented the CALL directive as a direct call to X.","If, however, object X is an overlay, mapping phase  has implemented the CALL as a \u2018trap\u2019 (i.e., a sequence of instructions that causes control to be transferred) to the underlying Object Management System (OMS) with X's Overlay Selector. The trap places the Overlay Selector into dual-port memory  along with a command code to fetch object X. The trap then interrupts control processor . The control processor interrupt handler (part of the control processor OMS) gets the command from dual-port memory  and runs a corresponding command handler, which is also part of the OMS.","Next, the command handler determines whether the CALLed object is already present in DSP local memory. This is accomplished by first retrieving the corresponding Overlay Selector from dual-port memory . The Overlay Selector is used to index into the Overlay Management Array  in SDRAM  to point to the Object Management Descriptor (OMD)  that manages object X. The command handler checks entry () of the OMD to see if the object is \u201cresident\u201d, meaning that it is already present in DSP PRAM (). If so, the command handler responds to DSP  immediately via dual-port memory  and instructs the DSP to initiate execution of X. Otherwise, the handler gets DMA transaction information () from OMD  and immediately writes it to DMA controller , starting the transfer of object X into overlay memory area (). The command handler then traverses Overlay List () and marks as \u2018non-resident\u2019 all OMDs in OMA  that correspond to objects overlaid by object X. When the transfer of X is complete, DMA controller  interrupts control processor , and the interrupt handler sends a signal, via dual-port memory , to DSP  to initiate execution of X.","As shown in , when a program completes execution, it interrupts the control processor OMS , which unloads DSP static memory data area () into SDRAM  using the DMA transactions in data unload descriptor  (Unload Descriptor ). This unload is necessary in order to preserve the program's state between runs. Note that, if there is no program state, the data unload descriptor is empty, and no unload operation is performed.","Steps  through , as described in the previous sections, are performed on a \u2018per application\u2019 basis. This section presents a discussion of the Object Management System (OMS). The OMS is designed and implemented once per target platform, and serves to run ODE-annotated applications prepared as described in previous sections.",{"@attributes":{"id":"p-0173","num":"0184"},"figref":"FIG. 13","b":["1300","1310","1320","1321","1311","1340","1330","1310","1320"]},"ODE application  runs from execution host fast memory . During execution, ODE directive occurrences  within the application \u2018trap\u2019  to the execution trap layer . A trap is a target-specific mechanism (e.g., software interrupt, subroutine call, etc.) through which ODE applications signal ODE directive occurrences to execution host . The execution trap layer examines the event and either handles it locally (e.g., CALL X, where X is statically allocated) or communicates a request to Object Server  (e.g., fetch X , where X is identified by a unique, numeric Overlay Selector) via the execution host OS -to-Communication Channel -to-object server host OS  target-specific mechanism. Object Server  uses the Overlay Selector to index Overlay Management Array (OMA) , comprising a plurality of Object Management Descriptors (OMDs) , one for each overlay object in the application.","Object Management Descriptor design is part of the Design OMS Runtime activity . Object Management Descriptor structure and contents vary depending on the specific target and allocation strategy. In an exemplary embodiment, all Object Management Descriptors  contain the following five types of information:\n\n","To enable handle-based references of overlay DATA objects, Overlay Management Array  also contains a plurality of Alpha OMDs , each of which contains a plurality of associations of CODE Object IDs () (see Table 3) with OMD pointers (). These associations allow resolution of a handle-based overlay data object exercise to the correct context-sensitive Object Management Descriptor . For example, a DEF_HANDLE directive that references an overlay data object that can be exercised from multiple CODE objects (i.e., an overlay xDATA object that has multiple execution host memory  load addresses) embeds the Alpha Overlay Selector (), which is used as an OMA index to an Alpha Object Management Descriptor . The exercising CODE object's Object ID, embedded within ODE application  and passed to Object Server  during execution of trap , is then used to resolve the correct context-sensitive Object Management Descriptor .","For clarity, following is an exemplary mapping of the General Target Platform Model  to the exemplary hardware environment (target platform ) of . Object server host  is Control Processor . Execution host  is DSP . Object Image Pool  and Overlay Management Array  reside in bulk SDRAM . Object transfer channel  is implemented by DMA . Execution host memory  comprises the PRAM  and DRAM  entities, as Harvard architecture DSP  requires. Communication Channel  is implemented by Dual-Port RAM , along with interrupt signaling.","Design OMS Runtime","The Design OMS Runtime activity  is necessarily target specific. It is a manual activity that is performed once per platform, resulting in the ODE Trap Specification  and OMS Runtime Specification . The ODE Trap Specification  presents the required behavior and manner of interfacing with Object Management System for each ODE directive. The OMS Runtime Specification  presents the system requirements for implementing the Object Management System on a specific target platform.","In general, the Design OMS Runtime activity  requires knowledge of the specific memory allocation strategy , an examination of the target's hardware capabilities and performance characteristics , and the General Target Platform Model , all within the context of implementing an efficient mechanism for the real-time or near real-time transfer and management of ODE program objects as triggered by ODE exercise directives (BRANCH, CALL, RETURN, OPEN, CLOSE, GET, PUT) within executing applications. Exemplary memory allocation strategies are illustrated in , described previously.","Generating the OMS Runtime Specification","The OMS Runtime Specification  serves as the requirements document for the implementation of OMS on a specific target platform. The method of generating OMS Runtime Specification  for a specific target platform is best illustrated with an example.  illustrates an exemplary application structure calling tree , a construct well-known to practitioners in the art, exemplary memory allocation map  and exemplary Data Dependency Database . In addition, the discussion to follow assumes that the exemplary memory allocation models defined by the algorithms of  are to be used for all applications that will run on the target platform .","Prior to running an application, all static code and data objects are loaded from Object Image Pool  to execution host memory  en masse via object transfer channel . After the application terminates, all static VDATA objects are updated from execution host memory  to Object Image Pool  en masse via object transfer channel . While the application is running, the mechanism described below is in effect.","With reference to the General Target Platform Model , assume that the application starts execution in static CODE object X. When X CALLs static CODE object Y, the CALL directive implements an \u2018informational\u2019 trap  to execution trap layer . The present memory allocation model dictates that Object Server  is kept informed of the program's entry into a new CODE object for use when managing overlay data objects (as discussed below). Therefore, in the exemplary Object Management System design presented here, all CALLs, BRANCHs and RETURNs, even those for static objects, are trapped.","The trap handler within execution trap layer  communicates the \u2018informational\u2019 event to Object Server  via Communication Channel . Object Server  notes that the application is now \u2018in\u2019 a new static CODE object by pushing a new \u2018context\u2019 on a \u2018context stack\u2019 (CS) maintained by the Object Server. Object Server  marks the context as \u2018static\u2019 and signals execution trap layer  to resume, which transfers control to Y's (known) address.","In the present example, assume that Y CALLs overlay W by name, e.g. \u2018CALL W\u2019. This CALL causes a \u2018fetching\u2019 trap . W's Overlay Selector (assigned by Selector Assignor ) is passed to Object Server . Object Server  \u2018pushes\u2019 a new context on the CS and marks it with W's Overlay Selector. Object Server  then indexes Object Management Array  with the Overlay Selector to isolate W's Object Management Descriptor . Object Management Descriptor entry () shows the Object Management Descriptor to be \u2018normal\u2019, so Object Server  checks W's Residency () to see whether W is already \u2018resident\u2019 (as in a loop in Y in which W is repeatedly CALLed). If so, Object Server  signals the application to continue in W. Otherwise, Object Server  uses information () to transfers W to its position in the overlay memory area of execution host memory , marks all Object Management Descriptors in Overlay List () (in this case a single OMD for overlay object Z) as \u2018non-resident\u2019, and signals the application to resume at W.","In the present example, assume that the CALL to W within Z is by a handle passed in to Z by X. This CALL causes a \u2018fetch by handle\u2019 trap . A handle allows direct (by execution host ) determination of the following object attributes: (1) whether the object is static or an overlay; (2) if static, the object's load address; and (3) if an overlay, the object's Overlay Selector. The \u2018fetch by handle\u2019 trap examines the handle. If the object is static it causes an \u2018informational\u2019 trap, then transfers control to the object's address, as extracted from the handle. If the object is an overlay, the trap extracts the Overlay Selector and causes a \u2018fetching\u2019 trap to Object Server , then transfers control to the address returned by Object Server .","When W RETURNs, a \u2018return\u2019 trap causes Object Server  to \u2018pop\u2019 its CS, which removes W's context. Object Server  finds Z's context on the CS so it re-loads Z (via its Object Selector by indexing OMA ), marks it \u2018resident\u2019, invalidates all objects on Overlay List () and signals the application to resume back in Z (via execution host  return linkage), immediately after the CALL directive to W. When Z RETURNs, the \u2018return\u2019 trap causes Object Server  to \u2018pop\u2019 the CS (Z's context), making Y's context active. Since Y's context is marked static, the Object Server knows it doesn't have to re-load anything. The program then resumes in Y after the CALL directive to Z.","With reference to , note that the Data Boxes for X and Y start at the same address  in data memory. Even though X and Y both use D4, D4 gets loaded to a different address depending on which CODE object is using it. Assume X is executing and OPENs D1 by name, e.g. \u2018OPEN D1\u2019. Since D1 is static, the OPEN directive is implemented as a direct access of D1's address, without the need for a trap . When D1 is later CLOSEd, no action is required since if static D1 is VDATA, it will be automatically unloaded when the application terminates.","In the present example, assume X OPENs D4 by name. Since D4 is an overlay, the OPEN is implemented as a \u2018fetching\u2019 trap  that sends the Overlay Selector D4:X (i.e. D4 as exercised by X) to Object Server . Object Server  indexes Overlay Management Array  to isolate D4:X's Object Management Descriptor , checks Residency (), loads D4:X using information () if not resident, marks the Object Management Descriptor \u2018resident\u2019 and invalidates all Object Management Descriptors in Overlay List (). Object Server  discovers from the OMD entry Object Class () that the object is data, so it logs D4:X's Overlay Selector to the current CS context and returns D4:X's address to the application, which continues.","Assume, in the present example, that X OPENs D2 by a handle. The OPEN causes a \u2018fetch by handle\u2019 trap  which checks the handle to see if the exercised object (D2 in this case) is static or an overlay. If static, the object's address is extracted from the handle and used directly. If an overlay, as in this case, the object's Overlay Selector is extracted from the handle and a \u2018fetching\u2019 trap is issued and processed by Object Server  as above. At this point, D2 and D4 are part of X's context, which is maintained on the CS by Object Server .","In the present example, assume that X CLOSEs D4 by name. The CLOSE implements an \u2018update\u2019 trap , passing Overlay Selector D4:X to Object Server . Object Server  selects D4:X's Object Management Descriptor and looks at its Object Class (). If VDATA, Object Server  uses information () to transfer the object from execution host memory  to Object Image Pool  via object transfer channel . Object Server  then removes D4:X's Overlay Selector from the current context.","Continuing with the present example, when X CALLs Y and the \u2018informational\u2019 trap occurs, Object Server  looks at the current data context. If there are VDATA objects that are still OPEN, the Object Server indexes Overlay Management Array  with their Overlay Selectors to unload and save them in order to clean out the overlay data area (CDATA objects are constant and cannot be changed so they do not have to be saved). Object Server  then pushes an empty context onto the CS for use by Y (as described previously).","In the present example, assume that Y GETs the fourth minimum addressable unit (MAU) of D5, D5[4]. The GET causes a \u2018get\u2019 trap , passing D5's handle, the object offset and the exercising CODE object's Object ID (see Table 3) to execution trap layer . Execution trap layer  examines the handle to see if the object is static or an overlay. If static, the operation can be performed \u2018locally\u2019, i.e., without Object Server  involvement. In this case, the object's static base address is extracted from the handle, indexed by the offset and the requested data element is read and returned to the caller. If the object is an overlay, the Overlay Selector is extracted from the handle and a \u2018get\u2019 event is issued to Object Server . Object Server  indexes Overlay Management Array  to identify D5's Object Management Descriptor. If the Object Management Descriptor is \u2018normal\u2019, Object Server  looks at the object's Residency (). If \u2018resident\u2019, Object Server  sends execution trap layer  the object's base address using entry () and flags a \u2018local\u2019 access, in which case execution trap layer  accesses the requested MAU from the locally-resident copy of D5, as described above. If \u2018non-resident\u2019, Object Server  uses information () to locate D5's image in Object Image Pool . Object Server  indexes D5's image by the requested offset and reads the requested datum, which it then returns to execution trap layer  which completes the \u2018get\u2019 trap.","If the Object Management Descriptor is \u2018alpha\u2019, Object Server uses the exercising Object ID to locate the correct OMD pointer (), then proceeds as above. Note that \u2018put\u2019, \u2018get vector\u2019, and \u2018put vector\u2019 traps are also required and work similarly, with the vector-versions using the services of Communication Channel  and\/or object transfer channel , as appropriate, to transfer the data vector.","In the present example, assume that Y OPENs D4 by a handle it was passed by X. The OPEN causes a \u2018fetch by handle\u2019 trap  which checks the handle to see if the exercised object is static or an overlay. If static, the address of the object is extracted from the handle and used directly. If an overlay, as in this case, the object's Overlay Selector is extracted from the handle and a \u2018fetching\u2019 trap is issued with an extra parameter, the Object ID of the exercising CODE object (Y in this case). Here, because D4 has multiple load addresses, the Overlay Selector is that of D4's Alpha OMD . Object Server  indexes Overlay Management Array  and, examining OMA type (), finds that the Object Management Descriptor is for an Alpha Object. Object Server  searches the Object IDs () in the Object Management Descriptor for a match with the Object ID sent by the trap. When found, Object Server  uses the corresponding OMA Pointer () to access D4:Y's Object Management Descriptor . The \u2018fetching\u2019 operation then proceeds as described previously.","Assume that, in the present example, Y then CLOSEs D4 by handle. The CLOSE causes an \u2018update by handle\u2019 trap  which checks the handle to see if the exercised object is static or an overlay. If static, no further action is required since, if the object is VDATA, it will be updated when the application terminates. If the object is an overlay, as in this case, the object's Overlay Selector is extracted from the handle and an \u2018update\u2019 trap is issued with an extra parameter, the Object ID of the exercising CODE object (Y in this case). As indicated above, because D4 has multiple load addresses, the Overlay Selector is that of D4's Alpha OMD . Object Server  indexes Overlay Management Array  and, examining OMA type (), finds that the Object Management Descriptor is for an Alpha Object. Object Server  searches the Object IDs () in the Object Management Descriptor for a match with the Object ID sent by the trap. When found, Object Server  uses the corresponding OMA Pointer () to access D4:Y's Object Management Descriptor . The \u2018update\u2019 operation then proceeds as described previously.","When Y RETURNs, Y's context is \u2018popped\u2019 from the CS and X's data is restored by reloading all OPEN VDATA and CDATA objects.","The above description serves, in essence, as the OMS Runtime Specification . With this specification and a description of the target platform, a target-specific OMS mechanism can be designed and implemented. Such an implementation serves as the \u2018Operating System\u2019 for applications using the ODE \u2018API.\u2019","Generating the ODE Trap Specification","In order to generate the ODE trap specification, the language in the OMS Runtime Specification  is examined to determine what traps are required and what they do. For example, the exemplary design presented above refers to \u2018informational\u2019, \u2018fetching\u2019, \u2018fetch by handle\u2019, \u2018update\u2019, \u2018update by handle\u2019 and \u2018return\u2019 traps, and describes what they do. The detailed OMS \u2018Operating System\u2019 implementation for the design described above determines the specific form a \u2018trap\u2019 takes for the specific target platform and how it is invoked (call, interrupt, etc.). It then remains to define the required behavior, in the context of the available traps, of each of the ODE directives.","An exemplary description best serves to illustrate the process of generating the ODE trap specification. The following description references the target platform of . In the present example, applications for DSP  are written in assembly language, a form well-known to practitioners in the art. Such code is machine processed by a programmed utility well-known as an assembler , which converts the assembly language mnemonics into relocatable machine code. Such an assembler  includes a well-known macro expansion capability, where the assembler expands programmer-defined symbols (\u2018macros\u2019) into sequences of assembly instructions. Each macro takes zero or more parameters and, within each macro, decision processes (e.g., the well-known IF-THEN-ELSE construct) are available.","Linker , a programmed utility well known to practitioners of the art, binds a plurality of individual assemblies, the well-known object files, as output from assembler , into a single executable code entity  by resolving address linkages between them. Linker  also serves to locate groups of object code and data, well-known memory \u2018segments\u2019, to target-specific addresses based on physical memory address ranges. Such location specifications are communicated to Linker  by the well-known technique of using a Linker Command File , which is a target-specific description that drives the general-purpose Linker .","Given the preceding scenario, an exemplary implementation of the ODE directives defines each one as a separate macro. Such macro symbols are used by application programmers to define program object boundaries (OBJ, ENDOBJ) and interdependencies (BRANCH, CALL, RETURN, OPEN, CLOSE, GET, PUT, DEF_HANDLE, GET_HANDLE). These macro definitions are packaged in an include file, a form well-known in the art, which each application source module includes during assembly. For the present exemplary implementation, such include file is identified as part of Mapping Database , and is generated by mechanical means, Mapper  (see Mapping section to follow). Following are descriptions of exemplary implementations of all ODE directives for the exemplary OMS design presented previously for the exemplary target platform of  and the exemplary memory allocation algorithms defined by .","Handles","The term \u2018handle\u2019 is used frequently in the following exemplary directive implementation descriptions. As described previously, within ODE applications objects are exercised either by name or by handle. Because of the possibility of handle-based exercise, every object in an ODE application, whether static or overlay, preferably has a unique handle. For the exemplary target platform of , a static object's handle is defined to be its physical base address in DSP  local memory. An overlay object's handle is defined to be its Overlay Selector, offset by 0x8000. In the exemplary target platform of , a DSP  code or data physical address is always less than 0x8000 due to the small size of PRAM  and DRAM , so this convention provides a convenient indicator (sign bit) that allows traps to easily determine whether the object referenced by a handle is statically resident or requires Object Server  involvement to acquire.","Directive Implementations","OBJ Macro","An exemplary OBJ macro implementation defines a public symbol, an entity well-known to practitioners in the art, to mark the start of a program object and make it \u2018visible\u2019. The macro also defines a \u2018segment\u2019, with a name equal to the object's name, into which the object's contents (either code or data) will be put. Such segments are individually located by location directives in Linker Command File , also generated by Mapper  and comprising the remainder of Mapping Database . An exemplary location directive is as follows:\n\n","The 32-bit LOCATE address 0x00010012 (\u20180x\u2019 denoting hexadecimal\u2019) for object \u2018A\u2019 comprises two parts. The upper 16 bits contain the unique Object ID (hex \u201c0001\u201d in the above example) defined in Object List  (see also  and Table 3). The lower 16 bits (\u201c0012\u201d, above) contain the base address of the object as defined in Allocation Database .","This address format allows overlay objects, which may coexist within the same physical address space, to remain as unique objects within executable code . Embedding the Object ID within executable code  also allows the subsequent Object Image Generator  to extract object images from their Object IDs. Since, in the present example, DSP  addressing is confined within 16 bits, the Object ID is truncated from opcode address fields during linking. However, executable code  retains the full 32-bit address, allowing object identification.","For static data objects and overlay objects with only one location (i.e., objects which are not referenced by more than one CODE object), the LOCATE convention specified above applies. However, for overlay data objects that are multiply-referenced (i.e. overlay objects that are referenced from more than one CODE object and therefore have more than one allocation to overlay memory), the base address is always 0.","ENDOBJ","An exemplary ENDOBJ macro is implemented as a NULL implementation, an \u2018empty\u2019 macro.","DEF_HANDLE","An exemplary DEF_HANDLE macro implementation switches on all program object names, both code and data. This macro inserts the specified object's handle into the currently open segment at the current location counter, a concept well-known by practitioners in the art. If the object is static, its allocated target load address is used. If the object is an overlay and has only one target load address (all CODE objects and xDATA objects that are only exercised from one CODE object), its Overlay Selector, offset by 0x8000, is used. If the object is an xDATA object with multiple target load addresses, e.g. object D1 where CODE objects X and Y exercise it (D1:X and D1:Y), the Alpha Overlay Selector (e.g. ()), offset by 0x8000, is used.","GET_HANDLE","In an exemplary GET_HANDLE macro implementation, the objectName (see APPENDIX, Table 1) parameter can be either a pointer or an object name. If a pointer is specified, an instruction sequence is coded in which the handle at the memory location pointed to by the objectName parameter is read and stored in handleContainer (see APPENDIX, Table 1). Otherwise, the macro switches on all program objects in the application, as defined in Object List . If a static object name is specified, the target load address is loaded into handleContainer. If an overlay object name with only one target load address (all CODE objects and xDATA objects exercised from only one CODE object) is specified, the object's Overlay Selector, offset by 0x8000, is loaded into handleContainer. If an overlay object name with multiple target load addresses (xDATA objects exercised from more than one CODE object) is specified, the Alpha Overlay Selector (e.g. ()), offset by 0x8000, is loaded into handleContainer.","BRANCH","The exercise target of an exemplary BRANCH macro implementation can be specified either by name or by handle. The two cases are coded differently. For name-based references, the exemplary BRANCH macro is implemented as a switch statement, switching on all CODE object names, as contained within Object List . Allocation Database  identifies each code object as either static or dynamic, and includes the object's allocation base address. Static object exercises implement \u2018informational\u2019 traps followed by direct \u2018branch\u2019 instructions to the object's load address. Overlay object exercises implement an OMS \u2018fetching\u2019 trap sequence, specifying the Overlay Selector found in Overlay Selector Database , followed by a direct \u2018branch\u2019 instruction. Handle-based object exercises implement an OMS \u2018fetch by handle\u2019 trap sequence, specifying the handle, followed by an \u2018indirect branch\u2019 instruction. An \u2018indirect branch\u2019 instruction is a branch to the address returned by Object Server  (for handle-based exercises, the address of the exercised object is resolvable and known only at run-time).","CALL","The exercise target of an exemplary BRANCH macro implementation can be specified either by name or by handle. The two cases are coded differently. For name-based references, the exemplary CALL macro is implemented as a switch statement, switching on all CODE object names, as contained within Object List . Allocation Database  identifies each code object as either static or dynamic, and includes the object's allocation base address. Static object exercises implement \u2018informational\u2019 traps followed by direct \u2018call\u2019 instructions to the object's load address. Overlay object exercises implement an OMS \u2018fetching\u2019 trap sequence, specifying the Overlay Selector found in the Overlay Selector Database , followed by a direct \u2018call\u2019 instruction.","Handle-based object exercises implement an OMS \u2018fetch by handle\u2019 trap sequence, specifying the handle, followed by an \u2018indirect call\u2019 instruction. An \u2018indirect call\u2019 instruction is a call to the address returned by Object Server  (for handle-based exercises, the address of the exercised object is resolvable and known only at run-time).","RETURN","An exemplary RETURN macro implementation codes a \u2018return\u2019 trap, then codes a native return instruction, transferring control to the \u2018next level up\u2019 via the program counter stack, an entity well-known to practitioners in the art, of DSP .","OPEN","The exercise target of an exemplary OPEN macro implementation can be specified either by name or by handle. The two cases are coded differently. For name-based references, the exemplary OPEN macro is implemented as a switch statement, switching on all object names, as contained within Object List . Allocation Database  identifies each object as either static or dynamic, and includes the object's allocation base address. If the target object is static, pointerContainer is loaded directly with the object's load address. If the target object is an overlay object, a \u2018fetching\u2019 trap sequence is coded with the object's context-sensitive Overlay Selector. After return, pointerContainer is loaded with the object's load address.","For handle-based references, the address of the object is not known and a \u2018fetch by handle\u2019 trap sequence is coded, providing the handle and the Object ID of the exercising CODE object (known at assembly-time). After return, pointerContainer (see APPENDIX, Table 1) is loaded with the object address returned by Object Server .","CLOSE","The CLOSE macro is only implemented for overlay VDATA objects since they are the only ones that require dynamic writeback to Object Server . Static VDATA objects are written back when the application terminates. CODE and CDATA objects, since they are constant, do not need writeback. The target of a CLOSE can be specified either by name or by handle.","For name-based references, the exemplary CLOSE macro is implemented as a switch statement, switching on all VDATA object names, as contained within Object List . Allocation Database  identifies each code object as either static or dynamic, and includes the object's allocation base address. If the target object is a VDATA overlay, an \u2018update\u2019 trap sequence is coded with the object's context-sensitive Overlay Selector. For handle-based references, an \u2018update by handle\u2019 trap sequence is coded, providing the handle and the Object ID of the exercising object.","GET","In an exemplary GET macro implementation, the target object can be specified by name or by handle. In addition, a single word can be returned to a register or one or more words can be returned to a block specified by a pointer. Single reads with a register destination use the \u2018get\u2019 trap. Destinations marked by a pointer use the \u2018get vector\u2019 trap. If the object is specified by name, a switch on all xDATA objects is implemented. For all objects, a \u2018get\u2019 or \u2018get vector\u2019 trap is coded with the specified macro parameters and the handle of the object, either the object's address (static objects) or the object's Overlay Selector offset by 0x8000 (overlay objects). Note that if an overlay object has multiple load addresses, the Overlay Selector of the object's Alpha OMD is used. If the target object is specified by handle, the handle and calling parameters are passed to a \u2018get\u2019 or \u2018get vector\u2019 trap.","PUT","In an exemplary PUT macro implementation, the target object can be specified by name or by handle. In addition, a single word can be written from a register or immediate value, concepts well-known to practitioners in the art, or one or more words can be written from a block specified by a pointer. Single writes with a register or immediate source use the \u2018put\u2019 trap. Sources marked by a pointer use the \u2018put vector\u2019 trap.","If the object is specified by name, a switch on all VDATA objects is implemented. For all objects, a \u2018put\u2019 or \u2018put vector\u2019 trap is coded with the specified macro parameters and the handle of the object, either the object's address (static objects) or the object's Overlay Selector offset by 0x8000 (overlay objects). Note that if an overlay object has multiple load addresses, the Overlay Selector of the object's Alpha OMD is used. If the target object is specified by handle, the handle and calling parameters are passed to a \u2018put\u2019 or \u2018put vector\u2019 trap.","Although the foregoing description sets forth exemplary embodiments of the invention, the scope of the invention is not limited to these specific embodiments. Modification may be made to the specific form and design of the invention without departing from its spirit and scope as expressed in the following claims. It is to be noted that the specific formats and contents of the files, and the steps described for performing structure extraction, memory allocation, and target mapping described herein, are merely exemplary, and the method of the present invention is operative with other specific formats and steps in accordance with the method disclosed herein."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["A more complete understanding of the present invention may be derived by referring to the detailed description when considered in connection with the Figures, where like reference numbers refer to similar elements throughout the Figures, and:",{"@attributes":{"id":"p-0017","num":"0023"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0018","num":"0024"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0019","num":"0025"},"figref":["FIG. 3A","FIG. 2"]},{"@attributes":{"id":"p-0020","num":"0026"},"figref":["FIG. 3B","FIG. 2"]},{"@attributes":{"id":"p-0021","num":"0027"},"figref":["FIG. 3C","FIG. 2"]},{"@attributes":{"id":"p-0022","num":"0028"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0023","num":"0029"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0024","num":"0030"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0025","num":"0031"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0026","num":"0032"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0027","num":"0033"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0028","num":"0034"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0029","num":"0035"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0030","num":"0036"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0031","num":"0037"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0032","num":"0038"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0033","num":"0039"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0034","num":"0040"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0035","num":"0041"},"figref":"FIG. 17"}]},"DETDESC":[{},{}]}
