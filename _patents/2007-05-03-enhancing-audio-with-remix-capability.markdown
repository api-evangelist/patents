---
title: Enhancing audio with remix capability
abstract: One or more attributes (e.g., pan, gain, etc.) associated with one or more objects (e.g., an instrument) of a stereo or multi-channel audio signal can be modified to provide remix capability. In some implementations, a method can include obtaining a first plural-channel audio signal having one or more objects; obtaining side information, at least some of which represents a relation between the first plural-channel audio signal and the one or more objects; obtaining a set of mix parameters; and generating a second plural-channel audio signal using the side information and the set of mix parameters.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08213641&OS=08213641&RS=08213641
owner: LG Electronics Inc.
number: 08213641
owner_city: Seoul
owner_country: KR
publication_date: 20070503
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","I. Remixing Stereo Signals","II. Quantization and Coding of the Side Information","III. Implementation Details","IV. Remixing of Multi-Channel Audio Signals","V. Enhancements to Basic Remixing Scheme","VI. Blind Generation of Side Information","VI. Architectures, User Interfaces, Bitstream Syntax","VII. Examples of Systems Using Remix Technology"],"p":["This application claims the benefit of priority from European Patent Application No. EP06113521, for \u201cEnhancing Stereo Audio With Remix Capability,\u201d filed May 4, 2006, which application is incorporated by reference herein in its entirety.","This application claims the benefit of priority from U.S. Provisional Patent Application No. 60\/829,350, for \u201cEnhancing Stereo Audio With Remix Capability,\u201d filed Oct. 13, 2006, which application is incorporated by reference herein in its entirety.","This application claims the benefit of priority from U.S. Provisional Patent Application No. 60\/884,594, for \u201cSeparate Dialogue Volume,\u201d filed Jan. 11, 2007, which application is incorporated by reference herein in its entirety.","This application claims the benefit of priority from U.S. Provisional Patent Application No. 60\/885,742, for \u201cEnhancing Stereo Audio With Remix Capability,\u201d filed Jan. 19, 2007, which application is incorporated by reference herein in its entirety.","This application claims the benefit of priority from U.S. Provisional Patent Application No. 60\/888,413, for \u201cObject-Based Signal Reproduction,\u201d filed Feb. 6, 2007, which application is incorporated by reference herein in its entirety.","This application claims the benefit of priority from U.S. Provisional Patent Application No. 60\/894,162, for \u201cBitstream and Side Information For SAOC\/Remix,\u201d filed Mar. 9, 2007, which application is incorporated by reference herein in its entirety.","The subject matter of this application is generally related to audio signal processing.","Many consumer audio devices (e.g., stereos, media players, mobile phones, game consoles, etc.) allow users to modify stereo audio signals using controls for equalization (e.g., bass, treble), volume, acoustic room effects, etc. These modifications, however, are applied to the entire audio signal and not to the individual audio objects (e.g., instruments) that make up the audio signal. For example, a user cannot individually modify the stereo panning or gain of guitars, drums or vocals in a song without effecting the entire song.","Techniques have been proposed that provide mixing flexibility at a decoder. These techniques rely on a Binaural Cue Coding (BCC), parametric or spatial audio decoder for generating a mixed decoder output signal. None of these techniques, however, directly encode stereo mixes (e.g., professionally mixed music) to allow backwards compatibility without compromising sound quality.","Spatial audio coding techniques have been proposed for representing stereo or multi-channel audio channels using inter-channel cues (e.g., level difference, time difference, phase difference, coherence). The inter-channel cues are transmitted as \u201cside information\u201d to a decoder for use in generating a multi-channel output signal. These conventional spatial audio coding techniques, however, have several deficiencies. For example, at least some of these techniques require a separate signal for each audio object to be transmitted to the decoder, even if the audio object will not be modified at the decoder. Such a requirement results in unnecessary processing at the encoder and decoder. Another deficiency is the limiting of encoder input to either a stereo (or multi-channel) audio signal or an audio source signal, resulting in reduced flexibility for remixing at the decoder. Finally, at least some of these conventional techniques require complex de-correlation processing at the decoder, making such techniques unsuitable for some applications or devices.","One or more attributes (e.g., pan, gain, etc.) associated with one or more objects (e.g., an instrument) of a stereo or multi-channel audio signal can be modified to provide remix capability.","In some implementations, a method includes: obtaining a first plural-channel audio signal having a set of objects; obtaining side information, at least some of which represents a relation between the first plural-channel audio signal and one or more source signals representing objects to be remixed; obtaining a set of mix parameters; and generating a second plural-channel audio signal using the side information and the set of mix parameters.","In some implementations, a method includes: obtaining an audio signal having a set of objects; obtaining a subset of source signals representing a subset of the objects; and generating side information from the subset of source signals, at least some of the side information representing a relation between the audio signal and the subset of source signals.","In some implementations, a method includes: obtaining a plural-channel audio signal; determining gain factors for a set of source signals using desired source level differences representing desired sound directions of the set of source signals on a sound stage; estimating a subband power for a direct sound direction of the set of source signals using the plural-channel audio signal; and estimating subband powers for at least some of the source signals in the set of source signals by modifying the subband power for the direct sound direction as a function of the direct sound direction and a desired sound direction.","In some implementations, a method includes: obtaining a mixed audio signal; obtaining a set of mix parameters for remixing the mixed audio signal; if side information is available, remixing the mixed audio signal using the side information and the set of mix parameters; if side information is not available, generating a set of blind parameters from the mixed audio signal; and generating a remixed audio signal using the blind parameters and the set of mix parameters.","In some implementations, a method includes: obtaining a mixed audio signal including speech source signals; obtaining mix parameters specifying a desired enhancement to one or more of the speech source signals; generating a set of blind parameters from the mixed audio signal; generating parameters from the blind parameters and the mix parameters; and applying the parameters to the mixed signal to enhance the one or more speech source signals in accordance with the mix parameters.","In some implementations, a method includes: generating a user interface for receiving input specifying mix parameters; obtaining a mixing parameter through the user interface; obtaining a first audio signal including source signals; obtaining side information at least some of which represents a relation between the first audio signal and one or more source signals; and remixing the one or more source signals using the side information and the mixing parameter to generate a second audio signal.","In some implementations, a method includes: obtaining a first plural-channel audio signal having a set of objects; obtaining side information at least some of which represents a relation between the first plural-channel audio signal and one or more source signals representing a subset of objects to be remixed; obtaining a set of mix parameters; and generating a second plural-channel audio signal using the side information and the set of mix parameters.","In some implementations, a method includes: obtaining a mixed audio signal; obtaining a set of mix parameters for remixing the mixed audio signal; generating remix parameters using the mixed audio signal and the set of mixing parameters; and generating a remixed audio signal by applying the remix parameters to the mixed audio signal using an n by n matrix.","Other implementations are disclosed for enhancing audio with remixing capability, including implementations directed to systems, methods, apparatuses, computer-readable mediums and user interfaces.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 1A","b":["100","100","102","104","106"]},"A. Original and Desired Remixed Signal","The two channels of a time discrete stereo audio signal are denoted and {tilde over (x)}(n) {tilde over (x)}(n) where n is a time index. It is assumed that the stereo signal can be represented as",{"@attributes":{"id":"p-0051","num":"0050"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"msub":{"mover":{"mi":"x","mo":"~"},"mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"I"},"mo":"\u2062","mrow":{"msub":{"mi":["a","i"]},"mo":"\u2062","mrow":{"msub":{"mover":{"mi":"s","mo":"~"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}}],"mo":"="},{"mrow":{"mrow":[{"msub":{"mover":{"mi":"x","mo":"~"},"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"I"},"mo":"\u2062","mrow":{"msub":{"mi":["b","i"]},"mo":"\u2062","mrow":{"msub":{"mover":{"mi":"s","mo":"~"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}}],"mo":"="},"mo":","}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}},"br":{},"sub":["i","i ","i ","i"]},{"@attributes":{"id":"p-0052","num":"0051"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"msub":{"mover":{"mi":"x","mo":"~"},"mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"I"},"mo":"\u2062","mrow":{"msub":{"mi":["a","i"]},"mo":"\u2062","mrow":{"msub":{"mover":{"mi":"s","mo":"~"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"n","mo":"-","msub":{"mi":["d","i"]}}}}}}],"mo":"="},{"mrow":[{"msub":{"mover":{"mi":"x","mo":"~"},"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"I"},"mo":"\u2062","mrow":{"msub":{"mi":["b","i"]},"mo":"\u2062","mrow":{"mrow":{"msub":{"mover":{"mi":"s","mo":"~"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"n","mo":"-","msub":{"mi":["d","i"]}}}},"mo":"."}}}],"mo":"="}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"1.1"}}]}}}}},"In some implementations, the encoding system  provides or generates information (hereinafter also referred to as \u201cside information\u201d) for modifying an original stereo audio signal (hereinafter also referred to as \u201cstereo signal\u201d) such that M source signals are \u201cremixed\u201d into the stereo signal with different gain factors. The desired modified stereo signal can be represented as",{"@attributes":{"id":"p-0054","num":"0053"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"msub":{"mover":{"mi":"y","mo":"~"},"mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"msub":{"mi":["c","i"]},"mo":"\u2062","mrow":{"msub":{"mover":{"mi":"s","mo":"~"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mrow":{"mi":"M","mo":"+","mn":"1"}},"mi":"I"},"mo":"\u2062","mrow":{"msub":{"mi":["a","i"]},"mo":"\u2062","mrow":{"msub":{"mover":{"mi":"s","mo":"~"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}}],"mo":"+"}],"mo":"="},{"mrow":{"mrow":[{"msub":{"mover":{"mi":"y","mo":"~"},"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"msub":{"mi":["d","i"]},"mo":"\u2062","mrow":{"msub":{"mover":{"mi":"s","mo":"~"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mrow":{"mi":"M","mo":"+","mn":"1"}},"mi":"I"},"mo":"\u2062","mrow":{"msub":{"mi":["b","i"]},"mo":"\u2062","mrow":{"msub":{"mover":{"mi":"s","mo":"~"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}}],"mo":"+"}],"mo":"="},"mo":","}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}},"br":{},"sub":["i ","i "]},"A goal of the encoding system  is to provide or generate information for remixing a stereo signal given only the original stereo signal and a small amount of side information (e.g., small compared to the information contained in the stereo signal waveform). The side information provided or generated by the encoding system  can be used in a decoder to perceptually mimic the desired modified stereo signal of [2] given the original stereo signal of [1]. With the encoding system , the side information generator  generates side information for remixing the original stereo signal, and a decoder system  () generates the desired remixed stereo audio signal using the side information and the original stereo signal.","B. Encoder Processing","Referring again to , the original stereo signal and M source signals are provided as input into the filterbank array . The original stereo signal is also output directly from the encoder . In some implementations, the stereo signal output directly from the encoder  can be delayed to synchronize with the side information bitstream. In other implementations, the stereo signal output can be synchronized with the side information at the decoder. In some implementations, the encoding system  adapts to signal statistics as a function of time and frequency. Thus, for analysis and synthesis, the stereo signal and M source signals are processed in a time-frequency representation, as described in reference to .",{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 1B","b":["108","110","112","114","116"]},{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 2","FIG. 2","FIGS. 4 and 5"],"b":["200","202","204","204","202","204","206","202"]},"In some implementations, an input stereo signal and M input source signals are decomposed by the filterbank array  into a number of subbands . The subbands  at each center frequency can be processed similarly. A subband pair of the stereo audio input signals, at a specific frequency, is denoted x(k) and x(k), where k is the down sampled time index of the subband signals. Similarly, the corresponding subband signals of the M input source signals are denoted s(k), s(k), . . . , S(k). Note that for simplicity of notation, indexes for the subbands have been omitted in this example. With respect to downsampling, subband signals with a lower sampling rate may be used for efficiency. Usually filterbanks and the STFT effectively have sub-sampled signals (or spectral coefficients).","In some implementations, the side information necessary for remixing a source signal with index i includes the gain factors aand b, and in each subband, an estimate of the power of the subband signal as a function of time, E{s(k)}. The gain factors aand b, can be given (if this knowledge of the stereo signal is known) or estimated. For many stereo signals, aand bare static. If aor bare varying as a function of time k, these gain factors can be estimated as a function of time. It is not necessary to use an average or estimate of the subband power to generate side information. Rather, in some implementations, the actual subband power Scan be used as a power estimate.","In some implementations, a short-time subband power can be estimated using single-pole averaging, where E{s(k)} can be computed as\n\n()}=\u03b1()+(1\u2212\u03b1)(1)},\u2003\u2003(3)\n\n, where \u03b1\u03b5[0,1] determines a time-constant of an exponentially decaying estimation window,\n",{"@attributes":{"id":"p-0062","num":"0061"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"T","mo":"=","mfrac":{"mn":"1","mrow":{"mi":"\u03b1","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["f","s"]}}}},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"4"}}]}}}},"br":{},"sub":"s "},"In some implementations, some or all of the side information a, band E{s(k)}, may be provided on the same media as the stereo signal. For example, a music publisher, recording studio, recording artist or the like, may provide the side information with the corresponding stereo signal on a compact disc (CD), digital Video Disk (DVD), flash drive, etc. In some implementations, some or all of the side information can be provided over a network (e.g., Internet, Ethernet, wireless network) by embedding the side information in the bitstream of the stereo signal or transmitting the side information in a separate bitstream.","If aand bare not given, then these factors can be estimated. Since, E{{tilde over (s)}(n){tilde over (x)}(n)}=aE{{tilde over (s)}(n)}, acan be computed as",{"@attributes":{"id":"p-0065","num":"0064"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["a","i"]},"mo":"=","mrow":{"mfrac":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"mrow":[{"msub":{"mover":{"mi":"s","mo":"~"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"msub":{"mover":{"mi":"x","mo":"~"},"mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}],"mo":"\u2062"}}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mover":{"mi":"s","mo":"~"},"mi":"i","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}}]},"mo":"."}}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}},"br":{},"sub":"i "},{"@attributes":{"id":"p-0066","num":"0065"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["b","i"]},"mo":"=","mrow":{"mfrac":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"mrow":[{"msub":{"mover":{"mi":"s","mo":"~"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"msub":{"mover":{"mi":"x","mo":"~"},"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}],"mo":"\u2062"}}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mover":{"mi":"s","mo":"~"},"mi":"i","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}}]},"mo":"."}}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}},"br":{},"sub":["i ","i ","i ","i ","i ","i ","i ","i ","1 ","2","i ","1 ","2"]},"In some implementations, the short-time power estimates and gain factors for each subband are quantized and encoded by the encoder  to form side information (e.g., a low bit rate bitstream). Note that these values may not be quantized and coded directly, but first may be converted to other values more suitable for quantization and coding, as described in reference to . In some implementations, E{s(k)} can be normalized relative to the subband power of the input stereo audio signal, making the encoding system  robust relative to changes when a conventional audio coder is used to efficiently code the stereo audio signal, as described in reference to .","C. Decoder Processing",{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 3A","b":["300","300","302","304","306","308"]},"The estimation of the remixed stereo audio signal can be carried out independently in a number of subbands. The side information includes the subband power, E{s(k)} and the gain factors, aand b, with which the M source signals are contained in the stereo signal. The new gain factors or mixing gains of the desired remixed stereo signal are represented by cand d. The mixing gains cand dcan be specified by a user through a user interface of an audio device, such as described in reference to .","In some implementations, the input stereo signal is decomposed into subbands by the filterbank array , where a subband pair at a specific frequency is denoted x(k) and x(k). As illustrated in , the side information is decoded by the decoder , yielding for each of the M source signals to be remixed, the gain factors aand b, which are contained in the input stereo signal, and for each subband, a power estimate, E{s(k)}. The decoding of side information is described in more detail in reference to .","Given the side information, the corresponding subband pair of the remixed stereo audio signal, can be estimated by the remix module  as a function of the mixing gains, cand d, of the remixed stereo signal. The inverse filterbank array  is applied to the estimated subband pairs to provide a remixed time domain stereo signal.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":["FIG. 3B","FIG. 3A","FIG. 12","FIG. 11"],"b":["310","312","314","316","318"]},"D. The Remixing Process","In some implementations, the remixed stereo signal can be approximated in a mathematical sense using least squares estimation. Optionally, perceptual considerations can be used to modify the estimate.","Equations [1] and [2] also hold for the subband pairs x(k) and x(k), and y(k) and y(k), respectively. In this case, the source signals are replaced with source subband signals, s(k).","A subband pair of the stereo signal is given by",{"@attributes":{"id":"p-0076","num":"0075"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mrow":[{"msub":{"mi":"x","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"I"},"mo":"\u2062","mrow":{"msub":{"mi":["a","i"]},"mo":"\u2062","mrow":{"msub":{"mi":["s","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"="},{"msub":{"mi":"x","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"I"},"mo":"\u2062","mrow":{"msub":{"mi":["b","i"]},"mo":"\u2062","mrow":{"msub":{"mi":["s","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":["\u2062","\u2062","="],"mstyle":{"mtext":{}}},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"7"}}]}}}},"br":{}},{"@attributes":{"id":"p-0077","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"msub":{"mi":"y","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"msub":{"mi":["c","i"]},"mo":"\u2062","mrow":{"msub":{"mi":["s","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mrow":{"mi":"M","mo":"+","mn":"1"}},"mi":"I"},"mo":"\u2062","mrow":{"msub":{"mi":["a","i"]},"mo":"\u2062","mrow":{"msub":{"mi":["s","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"+"}],"mo":"="},{"mrow":{"mrow":[{"msub":{"mi":"y","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"msub":{"mi":["d","i"]},"mo":"\u2062","mrow":{"msub":{"mi":["s","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mrow":{"mi":"M","mo":"+","mn":"1"}},"mi":"I"},"mo":"\u2062","mrow":{"msub":{"mi":["b","i"]},"mo":"\u2062","mrow":{"msub":{"mi":["s","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"+"}],"mo":"="},"mo":","}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"8"}}]}}}}},"Given a subband pair of the original stereo signal, x(k) and x(k), the subband pair of the stereo signal with different gains is estimated as a linear combination of the original left and right stereo subband pair,\n\n()=()()+()()\n\n()=()()+()(),\u2003\u2003(9)\n\nwhere w(k), w(k), w(k) and w(k) are real valued weighting factors. The estimation error is defined as\n",{"@attributes":{"id":"p-0079","num":"0078"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"msub":{"mi":"e","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mrow":[{"msub":{"mi":"y","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mover":{"mi":"y","mo":"^"},"mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"-"}],"mo":"="}}},{"mtd":{"mrow":{"mrow":{"mo":"=","mrow":{"mrow":[{"msub":{"mi":"y","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mrow":[{"msub":{"mi":"w","mn":"11"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":"x","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"\u2062"},{"msub":{"mi":"w","mn":"12"},"mo":"\u2062","mrow":{"msub":{"mi":"x","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}],"mo":["-","-"]}},"mo":","}}},{"mtd":{"mrow":{"mo":"=","mrow":{"mrow":[{"msub":{"mi":"y","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mrow":[{"msub":{"mi":"w","mn":"21"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":"x","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"\u2062"},{"msub":{"mi":"w","mn":"22"},"mo":"\u2062","mrow":{"mrow":{"msub":{"mi":"x","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mo":"."}}],"mo":["-","-"]}}}}]},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"mrow":{"mrow":[{"msub":{"mi":"e","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mrow":[{"msub":{"mi":"y","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mover":{"mi":"y","mo":"^"},"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"-"}],"mo":"="}}},{"mrow":{"mo":["(",")"],"mn":"10"}}]}}}}},"The weights w(k), w(k), w(k) and w(k) can be computed, at each time k for the subbands at each frequency, such that the mean square errors, E{e(k)} and E{e(k)}, are minimized. For computing w(k) and w(k), we note that E{e(k)} is minimized when the error e(k) is orthogonal to x(k) and x(k), that is\n\n()}=0\n\n{()}=0.\u2003\u2003(11)\n\nNote that for convenience of notation the time index k was omitted.\n","Re-writing these equations yields\n\n},\n\n}.\u2003\u2003(12)\n","The gain factors are the solution of this linear equation system:",{"@attributes":{"id":"p-0083","num":"0082"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"w","mn":"11"},"mo":"=","mfrac":{"mrow":[{"mrow":[{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}},{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"y","mn":"1"}],"mo":"\u2062"}}]},{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}},{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"2"},{"mi":"y","mn":"1"}],"mo":"\u2062"}}]}],"mo":"-"},{"mrow":[{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}},{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}]},{"msup":{"mi":"E","mn":"2"},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}}}],"mo":"-"}]}},{"msub":{"mi":"w","mn":"12"},"mo":"=","mrow":{"mfrac":{"mrow":[{"mrow":[{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}},{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"y","mn":"1"}],"mo":"\u2062"}}]},{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}},{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"2"},{"mi":"y","mn":"1"}],"mo":"\u2062"}}]}],"mo":"-"},{"mrow":[{"msup":{"mi":"E","mn":"2"},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}}},{"msup":{"mi":"E","mn":"2"},"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}},{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}],"mi":"E"}],"mo":"-"}]},"mo":"."}}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"13"}}]}}}}},"While E{x}, E{x} and E{xx} can directly be estimated given the decoder input stereo signal subband pair, E{xy} and E{xy} can be estimated using the side information (E{s}, a, b) and the mixing gains, cand d, of the desired remixed stereo signal:",{"@attributes":{"id":"p-0085","num":"0084"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"y","mn":"1"}],"mo":"\u2062"}}},{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["a","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["c","i"]},{"mi":["a","i"]}],"mo":"-"}}},{"mo":["{","}"],"msubsup":{"mi":["s","i"],"mn":"2"}}],"mo":["\u2062","\u2062"],"mi":"E"}}],"mo":"+"}],"mo":"="},{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"2"},{"mi":"y","mn":"1"}],"mo":"\u2062"}}},{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["b","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["c","i"]},{"mi":["a","i"]}],"mo":"-"}}},{"mrow":{"mo":["{","}"],"msubsup":{"mi":["s","i"],"mn":"2"}},"mo":"."}],"mo":["\u2062","\u2062"],"mi":"E"}}],"mo":"+"}],"mo":"="}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"14"}}]}}}}},"Similarly, wand ware computed, resulting in",{"@attributes":{"id":"p-0087","num":"0086"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"w","mn":"21"},"mo":"=","mfrac":{"mrow":[{"mrow":[{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}},{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"y","mn":"2"}],"mo":"\u2062"}}]},{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}},{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"2"},{"mi":"y","mn":"2"}],"mo":"\u2062"}}]}],"mo":"-"},{"mrow":[{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}},{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}]},{"msup":{"mi":"E","mn":"2"},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}}}],"mo":"-"}]}},{"msub":{"mi":"w","mn":"22"},"mo":"=","mrow":{"mfrac":{"mrow":[{"mrow":[{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}},{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"y","mn":"2"}],"mo":"\u2062"}}]},{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}},{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"2"},{"mi":"y","mn":"2"}],"mo":"\u2062"}}]}],"mo":"-"},{"mrow":[{"msup":{"mi":"E","mn":"2"},"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}},{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}],"mi":"E"},{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}},{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}]}],"mo":"-"}]},"mo":"."}}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"15"}}]},{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"2"},{"mi":"y","mn":"2"}],"mo":"\u2062"}}},{"mrow":[{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["b","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","i"]},{"mi":["b","i"]}],"mo":"-"}}},{"mrow":{"mo":["{","}"],"msubsup":{"mi":["s","i"],"mn":"2"}},"mo":[".","\u2062"],"mstyle":{"mtext":{}},"mi":"E"},{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"y","mn":"2"}],"mo":"\u2062"}}],"mo":["\u2062","\u2062","\u2062"],"mi":"E"}}],"mo":"+"},{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["a","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","i"]},{"mi":["b","i"]}],"mo":"-"}}},{"mo":["{","}"],"msubsup":{"mi":["s","i"],"mn":"2"}}],"mo":["\u2062","\u2062"],"mi":"E"}}],"mo":"+"}],"mo":"="}],"mo":"="},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"16"}}]}]}}},"br":{}},"When the left and right subband signals are coherent or nearly coherent, i.e., when",{"@attributes":{"id":"p-0089","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"\u03d5","mo":"=","mfrac":{"mrow":{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}}},"msqrt":{"mrow":{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}},{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}]}}}}},{"mrow":{"mo":["(",")"],"mn":"7"}}]}}}},"br":{}},{"@attributes":{"id":"p-0090","num":"0089"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"w","mn":"11"},"mo":"=","mfrac":{"mrow":[{"mi":"E","mo":["(","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"y","mn":"1"}],"mo":"\u2062"}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}}}]}},{"msub":{"mi":"w","mn":"12"},"mo":"=","mrow":{"msub":{"mi":"w","mn":"21"},"mo":"=","mn":"0"}},{"msub":{"mi":"w","mn":"22"},"mo":"=","mrow":{"mfrac":{"mrow":[{"mi":"E","mo":["(","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"y","mn":"2"}],"mo":"\u2062"}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}}]},"mo":"."}}],"mo":[",","\u2062",",","\u2062"],"mstyle":[{"mtext":{}},{"mtext":{}}]}},{"mrow":{"mo":["(",")"],"mn":"18"}}]}}}}},"Under the assumption \u03c6=1, equation [18] is one of the non-unique solutions satisfying [12] and the similar orthogonality equation system for the other two weights. Note that the coherence in [17] is used to judge how similar xand xare to each other. If the coherence is zero, then xand xare independent. If the coherence is one, then xand xare similar (but may have different levels). If xand xare very similar (coherence close to one), then the two channel Wiener computation (four weights computation) is ill-conditioned. An example range for the threshold is about 0.4 to about 1.0.","The resulting remixed stereo signal, obtained by converting the computed subband signals to the time domain, sounds similar to a stereo signal that would truly be mixed with different mixing gains, cand d, (in the following this signal is denoted \u201cdesired signal\u201d). On one hand, mathematically, this requires that the computed subband signals are similar to the truly differently mixed subband signals. This is the case to a certain degree. Since the estimation is carried out in a perceptually motivated subband domain, the requirement for similarity is less strong. As long as the perceptually relevant localization cues (e.g., level difference and coherence cues) are sufficiently similar, the computed remixed stereo signal will sound similar to the desired signal.","E. Optional: Adjusting of Level Difference Cues","In some implementations, if the processing described herein is used, good results can be obtained. Nevertheless, to be sure that the important level difference localization cues closely approximate the level difference cues of the desired signal, post-scaling of the subbands can be applied to \u201cadjust\u201d the level difference cues to make sure that they match the level difference cues of the desired signal.","For the modification of the least squares subband signal estimates in [9], the subband power is considered. If the subband power is correct then the important spatial cue level difference also will be correct. The desired signal [8] left subband power is",{"@attributes":{"id":"p-0095","num":"0094"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"E","mo":["[","}"],"msubsup":{"mi":"y","mn":["1","2"]}},{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":[{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["c","i"],"mn":"2"},{"mi":["a","i"],"mn":"2"}],"mo":"-"}},{"mo":["{","}"],"msubsup":{"mi":["s","i"],"mn":"2"}}],"mo":["\u2062","\u2062"],"mi":"E"}}],"mo":"+"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"19"}}]}}}},"br":{}},{"@attributes":{"id":"p-0096","num":"0095"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mover":{"mi":"y","mo":"^"},"mn":["1","2"]}}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":[{"mi":"w","mn":"11"},{"mi":"x","mn":"1"}],"mo":"\u2062"},{"msub":[{"mi":"w","mn":"12"},{"mi":"x","mn":"2"}],"mo":"\u2062"}],"mo":"+"}},"mn":"2"}}}],"mo":"="}}},{"mtd":{"mrow":{"mo":"=","mrow":{"mrow":[{"msubsup":{"mi":"w","mn":["11","2"]},"mo":["\u2062","\u2062"],"mi":"E","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}}},{"mn":"2","mo":["\u2062","\u2062","\u2062","\u2062"],"msub":[{"mi":"w","mn":"11"},{"mi":"w","mn":"12"}],"mi":"E","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}}},{"msubsup":{"mi":"w","mn":["12","2"]},"mo":["\u2062","\u2062"],"mi":"E","mrow":{"mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}},"mo":"."}}],"mo":["+","+"]}}}}]}},{"mrow":{"mo":["(",")"],"mn":"20"}}]}}}}},"Thus, for \u0177(k) to have the same power as y(k) it has to be multiplied with",{"@attributes":{"id":"p-0098","num":"0097"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":"g","mn":"1"},"mo":"=","mrow":{"msqrt":{"mfrac":{"mrow":[{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":[{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["c","i"],"mn":"2"},{"mi":["a","i"],"mn":"2"}],"mo":"-"}},{"mo":["{","}"],"msubsup":{"mi":["s","i"],"mn":"2"}}],"mo":["\u2062","\u2062"],"mi":"E"}}],"mo":"+"},{"mrow":[{"msubsup":{"mi":"w","mn":["11","2"]},"mo":["\u2062","\u2062"],"mi":"E","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}}},{"mn":"2","mo":["\u2062","\u2062","\u2062","\u2062"],"msub":[{"mi":"w","mn":"11"},{"mi":"w","mn":"12"}],"mi":"E","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}}},{"msubsup":{"mi":"w","mn":["12","2"]},"mo":["\u2062","\u2062"],"mi":"E","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}}],"mo":["+","+"]}]}},"mo":"."}}},{"mrow":{"mo":["(",")"],"mn":"21"}}]}}}}},"Similarly, \u0177(k) is multiplied with",{"@attributes":{"id":"p-0100","num":"0099"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":"g","mn":"2"},"mo":"=","msqrt":{"mfrac":{"mrow":[{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":[{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["d","i"],"mn":"2"},{"mi":["b","i"],"mn":"2"}],"mo":"-"}},{"mo":["{","}"],"msubsup":{"mi":["s","i"],"mn":"2"}}],"mo":["\u2062","\u2062"],"mi":"E"}}],"mo":"+"},{"mrow":[{"msubsup":{"mi":"w","mn":["21","2"]},"mo":["\u2062","\u2062"],"mi":"E","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}}},{"mn":"2","mo":["\u2062","\u2062","\u2062","\u2062"],"msub":[{"mi":"w","mn":"21"},{"mi":"w","mn":"22"}],"mi":"E","mrow":{"mo":["{","}"],"mrow":{"msub":[{"mi":"x","mn":"1"},{"mi":"x","mn":"2"}],"mo":"\u2062"}}},{"msubsup":{"mi":"w","mn":["22","2"]},"mo":["\u2062","\u2062"],"mi":"E","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}}],"mo":["+","+"]}]}}}},{"mrow":{"mo":["(",")"],"mn":"22"}}]}}}},"br":{},"sub":"2"},"A. Encoding","As described in the previous section, the side information necessary for remixing a source signal with index i are the factors aand b, and in each subband the power as a function of time, E{s(k)}. In some implementations, corresponding gain and level difference values for the gain factors aand bcan be computed in dB as follows:",{"@attributes":{"id":"p-0102","num":"0101"},"maths":{"@attributes":{"id":"MATH-US-00019","num":"00019"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["g","i"]},"mo":"=","mrow":{"mn":"10","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":"log","mn":"10"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["a","i"],"mn":"2"},{"mi":["b","i"],"mn":"2"}],"mo":"+"}}}}},{"msub":{"mi":["l","i"]},"mo":"=","mrow":{"mn":"20","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":"log","mn":"10"},"mrow":{"mfrac":{"msub":[{"mi":["b","i"]},{"mi":["a","i"]}]},"mo":"."}}}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"23"}}]}}}}},"In some implementations, the gain and level difference values are quantized and Huffman coded. For example, a uniform quantizer with a 2 dB quantizer step size and a one dimensional Huffman coder can be used for quantizing and coding, respectively. Other known quantizers and coders can also be used (e.g., vector quantizer).","If aand bare time invariant, and one assumes that the side information arrives at the decoder reliably, the corresponding coded values need only be transmitted once. Otherwise, aand bcan be transmitted at regular time intervals or in response to a trigger event (e.g., whenever the coded values change).","To be robust against scaling of the stereo signal and power loss\/gain due to coding of the stereo signal, in some implementations the subband power E{s(k)} is not directly coded as side information. Rather, a measure defined relative to the stereo signal can be used:",{"@attributes":{"id":"p-0106","num":"0105"},"maths":{"@attributes":{"id":"MATH-US-00020","num":"00020"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["A","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mn":"10","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":"log","mn":"10"},"mrow":{"mfrac":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":["s","i"],"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"+"}]},"mo":"."}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"24"}}]}}}}},"It can be advantageous to use the same estimation windows\/time-constants for computing E{.} for the various signals. An advantage of defining the side information as a relative power value [24] is that at the decoder a different estimation window\/time-constant than at the encoder may be used, if desired. Also, the effect of time misalignment between the side information and stereo signal is reduced compared to the case when the source power would be transmitted as an absolute value. For quantizing and coding A(k), in some implementations a uniform quantizer is used with a step size of, for example, 2 dB and a one dimensional Huffman coder. The resulting bitrate may be as little as about 3 kb\/s (kilobit per second) per audio object that is to be remixed.","In some implementations, bitrate can be reduced when an input source signal corresponding to an object to be remixed at the decoder is silent. A coding mode of the encoder can detect the silent object, and then transmit to the decoder information (e.g., a single bit per frame) for indicating that the object is silent.","B. Decoding","Given the Huffman decoded (quantized) values [23] and [24], the values needed for remixing can be computed as follows:",{"@attributes":{"id":"p-0110","num":"0109"},"maths":{"@attributes":{"id":"MATH-US-00021","num":"00021"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mover":{"mi":"a","mo":"~"},"mi":"i"},"mo":"=","mfrac":{"msup":{"mn":"10","mfrac":{"msub":{"mover":{"mi":"g","mo":"^"},"mi":"i"},"mn":"20"}},"msqrt":{"mrow":{"mn":"1","mo":"+","msup":{"mn":"10","mfrac":{"msub":{"mover":{"mi":"l","mo":"^"},"mi":"i"},"mn":"10"}}}}}},{"msub":{"mover":{"mi":"b","mo":"~"},"mi":"i"},"mo":"=","mfrac":{"msup":{"mn":"10","mfrac":{"mrow":{"msub":[{"mover":{"mi":"g","mo":"^"},"mi":"i"},{"mover":{"mi":"l","mo":"^"},"mi":"i"}],"mo":"+"},"mn":"20"}},"msqrt":{"mrow":{"mn":"1","mo":"+","msup":{"mn":"10","mfrac":{"msub":{"mover":{"mi":"l","mo":"^"},"mi":"i"},"mn":"10"}}}}}},{"mrow":[{"mover":{"mi":"E","mo":"^"},"mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":["s","i"],"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"msup":{"mn":"10","mfrac":{"mrow":{"msub":{"mover":{"mi":"A","mo":"^"},"mi":"i"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mn":"10"}},"mo":"\u2062","mrow":{"mrow":{"mo":["{",")"],"mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"+"}},"mo":"."}}],"mo":"="}],"mo":[",","\u2062",",","\u2062"],"mstyle":[{"mtext":{}},{"mtext":{}}]}},{"mrow":{"mo":["(",")"],"mn":"25"}}]}}}}},"A. Time-Frequency Processing","In some implementations, STFT (short-term Fourier transform) based processing is used for the encoding\/decoding systems described in reference to . Other time-frequency transforms may be used to achieve a desired result, including but not limited to, a quadrature mirror filter (QMF) filterbank, a modified discrete cosine transform (MDCT), a wavelet filterbank, etc.","For analysis processing (e.g., a forward filterbank operation), in some implementations a frame of N samples can be multiplied with a window before an N-point discrete Fourier transform (DFT) or fast Fourier transform (FFT) is applied. In some implementations, the following sine window can be used:",{"@attributes":{"id":"p-0113","num":"0112"},"maths":{"@attributes":{"id":"MATH-US-00022","num":"00022"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["w","a"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"l"}},{"mo":"(","mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mrow":{"mi":["n","\u03c0"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mi":"N"}}},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"for","mn":"0"},"mo":["\u2264","<"],"mi":["n","N"]}}},{"mtd":{"mrow":{"mn":"0","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":"otherwise","mo":"."}}}}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"26"}}]}}}}},"If the processing block size is different than the DFT\/FFT size, then in some implementations zero padding can be used to effectively have a smaller window than N. The described analysis processing can, for example, be repeated every N\/2 samples (equals window hop size), resulting in a 50 percent window overlap. Other window functions and percentage overlap can be used to achieve a desired result.","To transform from the STFT spectral domain to the time domain, an inverse DFT or FFT can be applied to the spectra. The resulting signal is multiplied again with the window described in [26], and adjacent signal blocks resulting from multiplication with the window are combined with overlap added to obtain a continuous time domain signal.","In some cases, the uniform spectral resolution of the STFT may not be well adapted to human perception. In such cases, as opposed to processing each STFT frequency coefficient individually, the STFT coefficients can be \u201cgrouped,\u201d such that one group has a bandwidth of approximately two times the equivalent rectangular bandwidth (ERB), which is a suitable frequency resolution for spatial audio processing.",{"@attributes":{"id":"p-0117","num":"0116"},"figref":["FIG. 4","FIG. 4"],"sub":["b-1","b-1","b","0"]},{"@attributes":{"id":"p-0118","num":"0117"},"figref":["FIG. 5","FIG. 5"]},"B. Estimation of Statistical Data","Given two STFT coefficients, x(k) and x(k), the values E{x(k)x(k)}, needed for computing the remixed stereo audio signal can be estimated iteratively. In this case, the subband sampling frequency \u0192is the temporal frequency at which STFT spectra are computed. To get estimates for each perceptual partition (not for each STFT coefficient), the estimated values can be averaged within the partitions before being further used.","The processing described in the previous sections can be applied to each partition as if it were one subband. Smoothing between partitions can be accomplished using, for example, overlapping spectral windows, to avoid abrupt processing changes in frequency, thus reducing artifacts.","C. Combination with Conventional Audio Coders",{"@attributes":{"id":"p-0121","num":"0120"},"figref":["FIG. 6A","FIG. 1A","FIGS. 1-5"],"b":["100","600","602","604","100","606","602","604","606"],"sub":["i","i ","i"],"sup":"2"},{"@attributes":{"id":"p-0122","num":"0121"},"figref":["FIG. 6B","FIG. 1A","FIG. 1A"],"b":["608","100","610","100","612","614"]},{"@attributes":{"id":"p-0123","num":"0122"},"figref":["FIG. 7A","FIG. 3A","FIG. 3A"],"b":["300","700","700","702","704","706","706","300"]},"In the example shown, the bitstream is separated into a stereo audio bitstream and a bitstream containing side information needed by the proposed decoder  to provide remixing capability. The stereo signal is decoded by the conventional audio decoder  and fed to the proposed decoder , which modifies the stereo signal as a function of the side information obtained from the bitstream and user input (e.g., mixing gains cand d).",{"@attributes":{"id":"p-0125","num":"0124"},"figref":["FIG. 7B","FIG. 7A"],"b":["708","700","710","712","714"],"sub":["i ","i"]},"In some implementations, the encoding and remixing systems , , described in previous sections can be extended to remixing multi-channel audio signals (e.g., 5.1 surround signals). Hereinafter, a stereo signal and multi-channel signal are also referred to as \u201cplural-channel\u201d signals. Those with ordinary skill in the art would understand how to rewrite [7] to [22] for a multi-channel encoding\/decoding scheme, i.e., for more than two signals x(k), x(k), x(k), . . . , x(k), where C is the number of audio channels of the mixed signal.","Equation [9] for the multi-channel case becomes",{"@attributes":{"id":"p-0128","num":"0127"},"maths":{"@attributes":{"id":"MATH-US-00023","num":"00023"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":{"mrow":[{"msub":{"mover":{"mi":"y","mo":"^"},"mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"c","mo":"=","mn":"1"},"mi":"C"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":"w","mrow":{"mn":"1","mo":"\u2062","mi":"c"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mo":["(",")"],"mi":"k"}],"mo":["\u2062","\u2062"],"msub":{"mi":["x","c"]}}}],"mo":"="},"mo":","}}},{"mtd":{"mrow":{"mrow":{"mrow":[{"msub":{"mover":{"mi":"y","mo":"^"},"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"c","mo":"=","mn":"1"},"mi":"C"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":"w","mrow":{"mn":"2","mo":"\u2062","mi":"c"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mo":["(",")"],"mi":"k"}],"mo":["\u2062","\u2062"],"msub":{"mi":["x","c"]}}}],"mo":"="},"mo":","}}},{"mtd":{"mi":"\u2026"}},{"mtd":{"mrow":{"mrow":{"mrow":[{"msub":{"mover":{"mi":"y","mo":"^"},"mi":"C"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"c","mo":"=","mn":"1"},"mi":"C"},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["w","Cc"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["x","c"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"\u2062"}}],"mo":"="},"mo":[",","."]}}}]}},{"mrow":{"mo":["(",")"],"mn":"27"}}]}}}},"br":{}},"In some implementations, certain channels can be left unprocessed. For example, for 5.1 surround the two rear channels can be left unprocessed and remixing applied only to the front left, right and center channels. In this case, a three channel remixing algorithm can be applied to the front channels.","The audio quality resulting from the disclosed remixing scheme depends on the nature of the modification that is carried out. For relatively weak modifications, e.g., panning change from 0 dB to 15 dB or gain modification of 10 dB, the resulting audio quality can be higher than achieved by conventional techniques. Also, the quality of the proposed disclosed remixing scheme can be higher than conventional remixing schemes because the stereo signal is modified only as necessary to achieve the desired remixing.","The remixing scheme disclosed herein provides several advantages over conventional techniques. First, it allows remixing of less than the total number of objects in a given stereo or multi-channel audio signal. This is achieved by estimating side information as a function of the given stereo audio signal, plus M source signals representing M objects in the stereo audio signal, which are to be enabled for remixing at a decoder. The disclosed remixing system processes the given stereo signal as a function of the side information and as a function of user input (the desired remixing) to generate a stereo signal which is perceptually similar to the stereo signal truly mixed differently.","A. Side Information Pre-Processing","When a subband is attenuated too much relative to neighboring subbands, audio artifacts are may occur. Thus, it is desired to restrict the maximum attenuation. Moreover, since the stereo signal and object source signal statistics are measured independently at the encoder and decoder, respectively, the ratio between the measured stereo signal subband power and object signal subband power (as represented by the side information) can deviate from reality. Due to this, the side information can be such that it is physically impossible, e.g., the signal power of the remixed signal [19] can become negative. Both of the above issues can be addressed as described below.","The subband power of the left and right remixed signal is",{"@attributes":{"id":"p-0134","num":"0133"},"maths":{"@attributes":{"id":"MATH-US-00024","num":"00024"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"y","mn":["1","2"]}}},{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["c","i"],"mn":"2"},{"mi":["a","i"],"mn":"2"}],"mo":"-"}},"mo":"\u2062","msub":{"mi":"P","msub":{"mi":["s","i"]}}}}],"mo":"+"}],"mo":"="},{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"y","mn":["2","2"]}}},{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["d","i"],"mn":"2"},{"mi":["b","i"],"mn":"2"}],"mo":"-"}},"mo":"\u2062","msub":{"mi":"P","msub":{"mi":["s","i"]}}}}],"mo":"+"}],"mo":"="}],"mo":[",","\u2062",","],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"28"}}]}}}},"br":[{},{},{}],"sub":["si ","1","2","2","1","1","si ","1","1","1","1"],"sup":["2","2","2","2","2","2","2","2","2","\u2212A\/10"]},{"@attributes":{"id":"p-0135","num":"0134"},"maths":{"@attributes":{"id":"MATH-US-00025","num":"00025"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"mrow":[{"mrow":[{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"Q"}},{"mo":["{","}"],"msubsup":{"mi":"x","mn":["1","2"]}}],"mo":["\u2062","\u2062"],"mi":"E"},{"mo":"-","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["c","i"],"mn":"2"},{"mi":["a","i"],"mn":"2"}],"mo":"-"}},"mo":"\u2062","msub":{"mi":"P","msub":{"mi":["s","i"]}}}}}]},"mo":"."}},{"mrow":{"mo":["(",")"],"mn":"29"}}]}}}},"br":{},"sub":["2","2","si","2","2","si "],"sup":["2","2","2","2"]},{"@attributes":{"id":"p-0136","num":"0135"},"maths":{"@attributes":{"id":"MATH-US-00026","num":"00026"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"mrow":[{"mrow":[{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","mi":"Q"}},{"mo":["{","}"],"msubsup":{"mi":"x","mn":["2","2"]}}],"mo":["\u2062","\u2062"],"mi":"E"},{"mo":"-","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"M"},"mo":"\u2062","mrow":{"mrow":{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["d","i"],"mn":"2"},{"mi":["b","i"],"mn":"2"}],"mo":"-"}},"mo":"\u2062","msub":{"mi":"P","msub":{"mi":["s","i"]}}}}}]},"mo":"."}},{"mrow":{"mo":["(",")"],"mn":"30"}}]}}}},"br":[{},{}],"sub":["i","si","11","12","21 ","22 "],"sup":"2"},"For many cases, two weights [18] are adequate for computing the left and right remixed signal subbands [9]. In some cases, better results can be achieved by using four weights [13] and [15]. Using two weights means that for generating the left output signal only the left original signal is used and the same for the right output signal. Thus, a scenario where four weights are desirable is when an object on one side is remixed to be on the other side. In this case, it would be expected that using four weights is favorable because the signal which was originally only on one side (e.g., in left channel) will be mostly on the other side (e.g., in right channel) after remixing. Thus, four weights can be used to allow signal flow from an original left channel to a remixed right channel and vice-versa.","When the least squares problem of computing the four weights is ill-conditioned the magnitude of the weights may be large. Similarly, when the above described one-side-to-other-side remixing is used, the magnitude of the weights when only two weights are used can be large. Motivated by this observation, in some implementations the following criterion can be used to decide whether to use four or two weights.","If A<B, then use four weights, else use two weights. A and B are a measure of the magnitude of the weights for the four and two weights, respectively. In some implementations, A and B are computed as follows. For computing A, first compute the four weights according to [13] and [15] and then set A=w+w+w+w. For computing B, the weights can be computed according to [18] and then B=w+wis computed.","C. Improving Degree of Attenuation when Desired","When a source is to be totally removed, e.g., removing the lead vocal track for a Karaoke application, its mixing gains are c=0, and d=0. However, when a user chooses zero mixing gains the degree of achieved attenuation can be limited. Thus, for improved attenuation, the source subband power values of the corresponding source signals obtained from the side information, \u00ca{s(k)}, can be scaled by a value greater than one (e.g., 2) before being used to compute the weights w, w, wand w.","D. Improving Audio Quality by Weight Smoothing","It has been observed that the disclosed remixing scheme may introduce artifacts in the desired signal, especially when an audio signal is tonal or stationary. To improve audio quality, at each subband, a stationarity\/tonality measure can be computed. If the stationarity\/tonality measure exceeds a certain threshold, TON, then the estimation weights are smoothed over time. The smoothing operation is described as follows: For each subband, at each time index k, the weights which are applied for computing the output subbands are obtained as follows:","If TON(k)>TON, then\n\n()=\u03b1()+(1\u2212\u03b1)(1),\n\n()=\u03b1()+(1\u2212\u03b1)(1),\n\n{tilde over ()}()=\u03b1()+(1\u2212\u03b1)(1),\n\n()=\u03b1()+(1\u2212\u03b1)(1),\u2003\u2003(31)\n\nwhere {tilde over (w)}(k), {tilde over (w)}(k), {tilde over (w)}(k) and {tilde over (w)}(k) are the smoothed weights and w(k), w(k), w(k) and w(k) are the non-smoothed weights computed as described earlier.\n","else\n\n()=(),\n\n()=(),\n\n()=(),\n\n()=().\u2003\u2003(32)\n\nE. Ambience\/Reverb Control\n","The remix technique described herein provides user control in terms of mixing gains cand d. This corresponds to determining for each object the gain, G, and amplitude panning, L(direction), where the gain and panning are fully determined by cand d,",{"@attributes":{"id":"p-0145","num":"0144"},"maths":{"@attributes":{"id":"MATH-US-00027","num":"00027"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["G","i"]},"mo":"=","mrow":{"mn":"10","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":"log","mn":"10"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["c","i"],"mn":"2"},{"mi":["d","i"],"mn":"2"}],"mo":"+"}}}}},{"msub":{"mi":["L","i"]},"mo":"=","mrow":{"mn":"20","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":"log","mn":"10"},"mrow":{"mfrac":{"msub":[{"mi":["c","i"]},{"mi":["d","i"]}]},"mo":"."}}}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"33"}}]}}}}},"In some implementations, it may be desired to control other features of the stereo mix other than gain and amplitude panning of source signals. In the following description, a technique is described for modifying a degree of ambience of a stereo audio signal. No side information is used for this decoder task.","In some implementations, the signal model given in [44] can be used to modify a degree of ambience of a stereo signal, where the subband power of nand nare assumed to be equal, i.e.,\n\n()}=()}=().\u2003\u2003(34)\n","Again, it can be assumed that s, nand nare mutually independent. Given these assumptions, the coherence [17] can be written as",{"@attributes":{"id":"p-0149","num":"0148"},"maths":{"@attributes":{"id":"MATH-US-00028","num":"00028"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"\u03d5","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mfrac":{"msqrt":[{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"msub":{"mi":["P","N"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"-"}},{"mo":["(",")"],"mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"msub":{"mi":["P","N"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"-"}}],"mo":"\u2062"}},{"mrow":{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}]}}]},"mo":"."}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"35"}}]}}}}},"This corresponds to a quadratic equation with variable P(k),\n\n()=(()}+()})()+()}()}(1\u2212\u03c6())=0.\u2003\u2003(36)\n","The solutions of this quadratic are",{"@attributes":{"id":"p-0152","num":"0151"},"maths":{"@attributes":{"id":"MATH-US-00029","num":"00029"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["P","N"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mfrac":{"mtable":{"mtr":[{"mtd":{"mrow":{"mo":"(","mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mrow":{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},"mo":"\u00b1"}],"mo":"+"}}}},{"mtd":{"msqrt":{"mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"+"}},"mn":"2"},"mo":"-","mrow":{"mn":"4","mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mi":["E","E"],"mrow":[{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msup":{"mrow":{"mi":"\u03d5","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mn":"2"}}}]}}}}}]},"mn":"2"},"mo":"."}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"37"}}]}}}}},"The physically possible solution is the one with the negative sign before the square-root,",{"@attributes":{"id":"p-0154","num":"0153"},"maths":{"@attributes":{"id":"MATH-US-00030","num":"00030"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":{"msub":{"mi":["P","N"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mo":"=","mfrac":{"mtable":{"mtr":[{"mtd":{"mrow":{"mo":"(","mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{",")"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":["(","}"],"mi":"k"}}}],"mo":["+","-"]}}}},{"mtd":{"msqrt":{"mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"+"}},"mn":"2"},"mo":"-","mrow":{"mn":"4","mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mi":["E","E"],"mrow":[{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},{"mo":["(",")"],"mrow":{"mn":"1","mo":"-","msup":{"mrow":{"mi":"\u03d5","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},"mn":"2"}}}]}}}}}]},"mn":"2"}},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"38"}}]}}}},"br":{},"sub":["N","1","2"],"sup":["2","2"]},"In some implementations, to control the left and right ambience, the remix technique can be applied relative to two objects: One object is a source with index iwith subband power E{s(k)}=P(k) on the left side, i.e., a=1 and b=0. The other object is a source with index iwith subband power E{s(k)}=P(k) on the right side, i.e., a=0 and b=1. To change the amount of ambience, a user can choose c=d=10and c=d=0, where gis the ambience gain in dB.","F. Different Side Information","In some implementations, modified or different side information can be used in the disclosed remixing scheme that are more efficient in terms of bitrate. For example, in [24] A(k) can have arbitrary values. There is also a dependence on the level of the original source signal s(n). Thus, to get side information in a desired range, the level of the source input signal would need to be adjusted. To avoid this adjustment, and to remove the dependence of the side information on the original source signal level, in some implementations the source subband power can be normalized not only relative to the stereo signal subband power as in [24], but also the mixing gains can be considered:",{"@attributes":{"id":"p-0157","num":"0156"},"maths":{"@attributes":{"id":"MATH-US-00031","num":"00031"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["A","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mn":"10","mo":["\u2062","\u2062"],"msub":{"mi":"log","mn":"10"},"mrow":{"mfrac":{"mrow":[{"mrow":[{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["a","i"],"mn":"2"},{"mi":["b","i"],"mn":"2"}],"mo":"+"}},{"mo":["{","}"],"msubsup":{"mi":["s","i"],"mn":"2"}}],"mo":["\u2062","\u2062"],"mi":"E"},{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"+"}]},"mo":"."}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"39"}}]}}}}},"This corresponds to using as side information the source power contained in the stereo signal (not the source power directly), normalized with the stereo signal. Alternatively, one can use a normalization like this:",{"@attributes":{"id":"p-0159","num":"0158"},"maths":{"@attributes":{"id":"MATH-US-00032","num":"00032"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["A","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mn":"10","mo":["\u2062","\u2062"],"msub":{"mi":"log","mn":"10"},"mrow":{"mfrac":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":["s","i"],"mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mrow":[{"mfrac":{"mn":"1","msubsup":{"mi":["a","i"],"mn":"2"}},"mo":["\u2062","\u2062"],"mi":"E","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mfrac":{"mn":"1","msubsup":{"mi":["b","i"],"mn":"2"}},"mo":["\u2062","\u2062"],"mi":"E","mrow":{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}}],"mo":"+"}]},"mo":"."}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"40"}}]}}}}},"This side information is also more efficient since A(k) can only take values smaller or equal than 0 dB. Note that [39] and [40] can be solved for the subband power E{s(k)}.","G. Stereo Source Signals\/Objects","The remix scheme described herein can easily be extended to handle stereo source signals. From a side information perspective, stereo source signals are treated like two mono source signals: one being only mixed to left and the other being only mixed to right. That is, the left source channel i has a non-zero left gain factor aand a zero right gain factor b. The gain factors, aand b, can be estimated with [6]. Side information can be transmitted as if the stereo source would be two mono sources. Some information needs to be transmitted to the decoder to indicated to the decoder which sources are mono sources and which are stereo sources.","Regarding decoder processing and a graphical user interface (GUI), one possibility is to present at the decoder a stereo source signal similarly as a mono source signal. That is, the stereo source signal has a gain and panning control similar to a mono source signal. In some implementations, the relation between the gain and panning control of the GUI of the non-remixed stereo signal and the gain factors can be chosen to be:",{"@attributes":{"id":"p-0163","num":"0162"},"maths":{"@attributes":{"id":"MATH-US-00033","num":"00033"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"GAIN","mn":"0"},"mo":"=","mrow":{"mn":"0","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}},"mi":"dB"}},{"msub":{"mi":"PAN","mn":"0"},"mo":"=","mrow":{"mn":"20","mo":["\u2062","\u2062"],"msub":{"mi":"log","mn":"10"},"mrow":{"mfrac":{"msub":[{"mi":"b","mrow":{"mi":"i","mo":"+","mn":"1"}},{"mi":["a","i"]}]},"mo":"."}}}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"41"}}]}}}}},"That is, the GUI can be initially set to these values. The relation between the GAIN and PAN chosen by the user and the new gain factors can be chosen to be:",{"@attributes":{"id":"p-0165","num":"0164"},"maths":{"@attributes":{"id":"MATH-US-00034","num":"00034"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"GAIN","mo":"=","mrow":{"mn":"10","mo":["\u2062","\u2062"],"msub":{"mi":"log","mn":"10"},"mfrac":{"mrow":[{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["c","i"],"mn":"2"},{"mi":"d","mrow":{"mi":"i","mo":"+","mn":"1"},"mn":"2"}],"mo":"+"}},{"mo":["(",")"],"mrow":{"msubsup":[{"mi":["a","i"],"mn":"2"},{"mi":"b","mrow":{"mi":"i","mo":"+","mn":"1"},"mn":"2"}],"mo":"+"}}]}}},{"mi":"PAN","mo":"=","mrow":{"mn":"20","mo":["\u2062","\u2062"],"msub":{"mi":"log","mn":"10"},"mrow":{"mfrac":{"msub":[{"mi":"d","mrow":{"mi":"i","mo":"+","mn":"1"}},{"mi":["c","i"]}]},"mo":"."}}}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}},"mo":"\u2062","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},{"mrow":{"mo":["(",")"],"mn":"42"}}]}}}}},"Equations [42] can be solved for cand d, which can be used as remixing gains (with c=0 and d=0). The described functionality is similar to a \u201cbalance\u201d control on a stereo amplifier. The gains of the left and right channels of the source signal are modified without introducing cross-talk.","A. Fully Blind Generation of Side Information","In the disclosed remixing scheme, the encoder receives a stereo signal and a number of source signals representing objects that are to be remixed at the decoder. The side information necessary for remixing a source single with index i at the decoder is determined from the gain factors, aand b, and the subband power E{s(k)}. The determination of side information was described in earlier sections in the case when the source signals are given.","While the stereo signal is easily obtained (since this corresponds to the product existing today), it may be difficult to obtain the source signals corresponding to the objects to be remixed at the decoder. Thus, it is desirable to generate side information for remixing even if the object's source signals are not available. In the following description, a fully blind generation technique is described for generating side information from only the stereo signal.",{"@attributes":{"id":"p-0169","num":"0168"},"figref":"FIG. 8A","b":["800","800","802","804","806","802","804","802","804"],"sub":["i ","i "]},{"@attributes":{"id":"p-0170","num":"0169"},"figref":["FIG. 8B","FIG. 8A"],"b":["808","800","810","812"],"sub":["i ","i","i ","i","i"]},{"@attributes":{"id":"p-0171","num":"0170"},"maths":{"@attributes":{"id":"MATH-US-00035","num":"00035"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["a","i"]},"mo":"=","mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"1","mo":"+","mi":"A"}}}},{"mrow":{"msub":{"mi":["b","i"]},"mo":"=","mfrac":{"msqrt":[{"mi":"A"},{"mrow":{"mn":"1","mo":"+","mi":"A"}}]}},"mo":","}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"43"}}]}}}},"br":{},"sup":["Li\/10","2","2"],"sub":["i ","i ","i","i","i ","i ","i "]},"Next, the subband power of the direct sound is estimated using the subband pair and mixing gains (). To compute the direct sound subband power, one can assume that each input signal left and right subband at each time can be written\n\n,\n\n,\u2003\u2003(44)\n\nwhere a and b are mixing gains, s represents the direct sound of all source signals and nand nrepresent independent ambient sound.\n\nIt can be assumed that a and b are\n",{"@attributes":{"id":"p-0173","num":"0172"},"maths":{"@attributes":{"id":"MATH-US-00036","num":"00036"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"a","mo":"=","mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"1","mo":"+","mi":"B"}}}},{"mi":"b","mo":"=","mfrac":{"msqrt":[{"mi":"B"},{"mrow":{"mn":"1","mo":"+","mi":"B"}}]}}],"mo":[",","\u2062",","],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"45"}}]}}}},"br":{},"sub":["2","1","2 ","1 ","2 ","1","10"],"sup":["2","2"]},"We can compute the direct sound subband power, E{s(k)}, according to the signal model given in [44]. In some implementations, the following equation system is used:\n\n()}=()}+()},\n\n()}=()}+()},\n\n()()}=()}.\u2003\u2003(46)\n","It has been assumed in [46] that s, nand nin [34] are mutually independent, the left-side quantities in [46] can be measured and a and b are available. Thus, the three unknowns in [46] are E{s(k)}, E{n(k)} and E{n(k)}. The direct sound subband power, E{s(k)}, can be given by",{"@attributes":{"id":"p-0176","num":"0175"},"maths":{"@attributes":{"id":"MATH-US-00037","num":"00037"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msup":{"mi":"s","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mfrac":{"mrow":{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"mrow":[{"msub":{"mi":"x","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":"x","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}],"mo":"\u2062"}}},"mi":"ab"},"mo":"."}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"47"}}]}}}}},"The direct sound subband power can also be written as a function of the coherence [17],",{"@attributes":{"id":"p-0178","num":"0177"},"maths":{"@attributes":{"id":"MATH-US-00038","num":"00038"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"E","mo":"\u2062","mrow":{"mo":["{","}"],"mrow":{"msup":{"mi":"s","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}},{"mfrac":{"mrow":{"mi":"\u03d5","mo":"\u2062","msqrt":{"mrow":{"mi":["E","E"],"mo":["\u2062","\u2062","\u2062"],"mrow":[{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["1","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},{"mo":["{","}"],"mrow":{"msubsup":{"mi":"x","mn":["2","2"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}}]}}},"mi":"ab"},"mo":"."}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"48"}}]}}}}},"In some implementations, the computation of desired source subband power, E{s(k)}, can be performed in two steps: First, the direct sound subband power, E{s(k)}, is computed, where s represents all sources' direct sound (e.g., center-panned) in [44]. Then, desired source subband powers, E{s(k)}, are computed () by modifying the direct sound subband power, E{s(k)}, as a function of the direct sound direction (represented by M) and a desired sound direction (represented by the desired source level difference L):\n\n()}=\u222b(())()},\u2003\u2003(49)\n\nwhere \u0192(.) is a gain function, which as a function of direction, returns a gain factor that is close to one only for the direction of the desired source. As a final step, the gain factors and subband powers E{s(k)} can be quantized and encoded to generate side information ().\n",{"@attributes":{"id":"p-0180","num":"0179"},"figref":"FIG. 9","sub":["i","o","o"],"b":"900"},"Note that with the fully blind technique described above, the side information (a, b, E{s(k)}) for a given source signal scan be determined.","B. Combination Between Blind and Non-Blind Generation of Side Information","The fully blind generation technique described above may be limited under certain circumstances. For example, if two objects have the same position (direction) on a stereo sound stage, then it may not be possible to blindly generate side information relating to one or both objects.","An alternative to fully blind generation of side information is partially blind generation of side information. The partially blind technique generates an object waveform which roughly corresponds to the original object waveform. This may be done, for example, by having singers or musicians play\/reproduce the specific object signal. Or, one may deploy MIDI data for this purpose and let a synthesizer generate the object signal. In some implementations, the \u201crough\u201d object waveform is time aligned with the stereo signal relative to which side information is to be generated. Then, the side information can be generated using a process which is a combination of blind and non-blind side information generation.",{"@attributes":{"id":"p-0184","num":"0183"},"figref":"FIG. 10","b":["1000","1000","1002","1004","1006","1008"],"sub":["i ","i ","i","i"],"sup":["2","2"]},"Finally, the function, is applied to the estimated subband powers, which combines the first and second subband power estimates and returns a final estimate, which effectively can be used for side information computation (). In some implementations, the function F( ) is given by\n\nF(E{s(k)}, \u00ca{s(k)})\u2003\u2003(50)\n\n(()}()})=min(()},()}).\n","A. Client\/Server Architecture",{"@attributes":{"id":"p-0186","num":"0185"},"figref":"FIG. 11","b":["1100","1110","1100"]},"The architecture  generally includes a download service  having a repository  (e.g., MySQL\u2122) and a server  (e.g., Windows\u2122 NT, Linux server). The repository  can store various types of content, including professionally mixed stereo signals, and associated source signals corresponding to objects in the stereo signals and various effects (e.g., reverberation). The stereo signals can be stored in a variety of standardized formats, including MP3, PCM, AAC, etc.","In some implementations, source signals are stored in the repository  and are made available for download to audio devices . In some implementations, pre-processed side information is stored in the repository  and made available for downloading to audio devices . The pre-processed side information can be generated by the server  using one or more of the encoding schemes described in reference to , A and A.","In some implementations, the download service  (e.g., a Web site, music store) communicates with the audio devices  through a network  (e.g., Internet, intranet, Ethernet, wireless network, peer to peer network). The audio devices  can be any device capable of implementing the disclosed remixing schemes (e.g., media players\/recorders, mobile phones, personal digital assistants (PDAs), game consoles, set-top boxes, television receives, media centers, etc.).","B. Audio Device Architecture","In some implementations, an audio device  includes one or more processors or processor cores , input devices  (e.g., click wheel, mouse, joystick, touch screen), output devices  (e.g., LCD), network interfaces  (e.g., USB, FireWire, Ethernet, network interface card, wireless transceiver) and a computer-readable medium  (e.g., memory, hard disk, flash drive). Some or all of these components can send and\/or receive information through communication channels  (e.g., a bus, bridge).","In some implementations, the computer-readable medium  includes an operating system, music manager, audio processor, remix module and music library. The operating system is responsible for managing basic administrative and communication tasks of the audio device , including file management, memory access, bus contention, controlling peripherals, user interface management, power management, etc. The music manager can be an application that manages the music library. The audio processor can be a conventional audio processor for playing music files (e.g., MP3, CD audio, etc.) The remix module can be one or more software components that implement the functionality of the remixing schemes described in reference to .","In some implementations, the server  encodes a stereo signal and generates side information, as described in references to , A and A. The stereo signal and side information are downloaded to the audio device  through the network . The remix module decode the signals and side information and provides remix capability based on user input received through an input device  (e.g., keyboard, click-wheel, touch display).","C. User Interface For Receiving User Input",{"@attributes":{"id":"p-0193","num":"0192"},"figref":"FIG. 12","b":["1202","1200","1202"]},"A user can enter a \u201cremix\u201d mode for the device  by highlighting the appropriate item on user interface . In this example, it is assumed that the user has selected a song from the music library and would like to change the pan setting of the lead vocal track. For example, the user may want to hear more lead vocal in the left audio channel.","To gain access to the desired pan control, the user can navigate a series of submenus ,  and . For example, the user can scroll through items on submenus ,  and , using a wheel . The user can select a highlighted menu item by clicking a button . The submenu  provides access to the desired pan control for the lead vocal track. The user can then manipulate the slider (e.g., using wheel ) to adjust the pan of the lead vocal as desired while the song is playing.","D. Bitstream Syntax","In some implementations, the remixing schemes described in reference to  can be included in existing or future audio coding standards (e.g., MPEG-4). The bitstream syntax for the existing or future coding standard can include information that can be used by a decoder with remix capability to determine how to process the bitstream to allow for remixing by a user. Such syntax can be designed to provide backward compatibility with conventional coding schemes. For example, a data structure (e.g., a packet header) included in the bitstream can include information (e.g., one or more bits or flags) indicating the availability of side information (e.g., gain factors, subband powers) for remixing.","The disclosed and other embodiments and the functional operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. The disclosed and other embodiments can be implemented as one or more computer program products, i.e., one or more modules of computer program instructions encoded on a computer-readable medium for execution by, or to control the operation of, data processing apparatus. The computer-readable medium can be a machine-readable storage device, a machine-readable storage substrate, a memory device, a composition of matter effecting a machine-readable propagated signal, or a combination of one or more them. The term \u201cdata processing apparatus\u201d encompasses all apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them. A propagated signal is an artificially generated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus.","A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.","The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).","Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.","To provide for interaction with a user, the disclosed embodiments can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.","The disclosed embodiments can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of what is disclosed here, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (\u201cLAN\u201d) and a wide area network (\u201cWAN\u201d), e.g., the Internet.","The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.",{"@attributes":{"id":"p-0204","num":"0203"},"figref":"FIG. 13","b":"1300"},"In some implementations, the system  includes a mix signal decoder , a parameter generator  and a remix renderer . The parameter generator  includes a blind estimator , user-mix parameter generator  and a remix parameter generator . The remix parameter generator  includes an eq-mix parameter generator  and an up-mix parameter generator .","In some implementations, the system  provides two audio processes. In a first process, side information provided by an encoding system is used by the remix parameter generator  to generate remix parameters. In a second process, blind parameters are generated by the blind estimator  and used by the remix parameter generator  to generate remix parameters. The blind parameters and fully or partially blind generation processes can be performed by the blind estimator , as described in reference to .","In some implementations, the remix parameter generator  receives side information or blind parameters, and a set of user mix parameters from the user-mix parameter generator . The user-mix parameter generator  receives mix parameters specified by end users (e.g., GAIN, PAN) and converts the mix parameters into a format suitable for remix processing by the remix parameter generator  (e.g., convert to gains c, d). In some implementations, the user-mix parameter generator  provides a user interface for allowing users to specify desired mix parameters, such as, for example, the media player user interface , as described in reference to .","In some implementations, the remix parameter generator  can process both stereo and multi-channel audio signals. For example, the eq-mix parameter generator  can generate remix parameters for a stereo channel target, and the up-mix parameter generator  can generate remix parameters for a multi-channel target. Remix parameter generation based on multi-channel audio signals were described in reference to Section IV.","In some implementations, the remix renderer  receives remix parameters for a stereo target signal or a multi-channel target signal. The eq-mix renderer  applies stereo remix parameters to the original stereo signal received directly from the mix signal decoder  to provide a desired remixed stereo signal based on the formatted user specified stereo mix parameters provided by the user-mix parameter generator . In some implementations, the stereo remix parameters can be applied to the original stereo signal using an n\u00d7n matrix (e.g., a 2\u00d72 matrix) of stereo remix parameters. The up-mix renderer  applies multi-channel remix parameters to an original multi-channel signal received directly from the mix signal decoder  to provide a desired remixed multi-channel signal based on the formatted user specified multi-channel mix parameters provided by the user-mix parameter generator . In some implementations, an effects generator  generates effects signals (e.g., reverb) to be applied to the original stereo or multi-channel signals by the eq-mix renderer  or up-mix renderer, respectively. In some implementations, the up-mix renderer  receives the original stereo signal and converts (or up-mixes) the stereo signal to a multi-channel signal in addition to applying the remix parameters to generate a remixed multi-channel signal.","The system  can process audio signals having a variety of channel configurations, allowing the system  to be integrated into existing audio coding schemes (e.g., SAOC, MPEG AAC, parametric stereo), while maintaining backward compatibility with such audio coding schemes.",{"@attributes":{"id":"p-0211","num":"0210"},"figref":["FIG. 14A","FIG. 14A"],"sub":["1 ","2 ","1 ","2","1","1 ","2","2"],"br":[{},{},{}],"in-line-formulae":[{},{},{},{}],"i":["x","n","s","n","n","x","n","as","n","n"]},{"@attributes":{"id":"p-0212","num":"0211"},"figref":"FIG. 14B","b":["1400","1400","1402","1404","1406","1408","1410"]},"In some implementations, an SDV downmix signal is received and decomposed by the filterbank  into subband signals. The downmix signal can be a stereo signal, x, x, given by [51]. The subband signals X(i, k), X(i, k) are input either directly into the eq-mix renderer  or into the blind estimator , which outputs blind parameters, A, P, P. The computation of these parameters is described in U.S. Provisional Patent Application No. 60\/884,594, for \u201cSeparate Dialogue Volume.\u201d The blind parameters are input into the parameter generator , which generates eq-mix parameters, w\u02dcw, from the blind parameters and user specified mix parameters g(i,k) (e.g., center gain, center width, cutoff frequency, dryness). The computation of the eq-mix parameters is described in Section I. The eq-mix parameters are applied to the subband signals by the eq-mix renderer  to provide rendered output signals, y, y. The rendered output signals of the eq-mix renderer  are input to the inverse filterbank , which converts the rendered output signals into the desired SDV stereo signal based on the user specified mix parameters.","In some implementations, the system  can also process audio signals using remix technology, as described in reference to . In a remix mode, the filterbank  receives stereo or multi-channel signals, such as the signals described in [1] and [27]. The signals are decomposed into subband signals X(i, k), X(i, k), by the filterbank  and input directly input into the eq-renderer  and the blind estimator  for estimating the blind parameters. The blind parameters are input into the parameter generator , together with side information a, b, P, received in a bitstream. The parameter generator  applies the blind parameters and side information to the subband signals to generate rendered output signals. The rendered output signals are input to the inverse filterbank , which generates the desired remix signal.",{"@attributes":{"id":"p-0215","num":"0214"},"figref":["FIG. 15","FIG. 14B"],"b":["1406","1","1502","1504","2","1506","1508","1502","1","1504","1","1506","2","1508","2","1502","1506","1504","1508"],"sub":["11","21","12 ","22","1","2"]},{"@attributes":{"id":"p-0216","num":"0215"},"figref":["FIG. 16","FIGS. 1-15","FIG. 1A"],"b":["1600","1602","1604","1606"]},"In some implementations, the original content (e.g., the original mixed audio file), side information and optional preset mix parameters (\u201cremix information\u201d) can be provided to a service provider  (e.g., a music portal) or placed on a physical medium (e.g., a CD-ROM, DVD, media player, flash drive). The service provider  can operate one or more servers  for serving all or part of the remix information and\/or a bitstream containing all of part of the remix information. The remix information can be stored in a repository . The service provider  can also provide a virtual environment (e.g., a social community, portal, bulletin board) for sharing user-generated mix parameters. For example, mix parameters generated by a user on a remix-ready device  (e.g., a media player, mobile phone) can be stored in a mix parameter file that can be uploaded through network  to the service provider  for sharing with other users. The mix parameter file can have a unique extension (e.g., filename.rms). In the example shown, a user generated a mix parameter file using the remix player A and uploaded the mix parameter file to the service provider  through network , where the file was subsequently downloaded through network  by a user operating a remix player B.","The system  can be implemented using any known digital rights management scheme and\/or other known security methods to protect the original content and remix information. For example, the user operating the remix player B may need to download the original content separately and secure a license before the user can access or user the remix features provided by remix player B.",{"@attributes":{"id":"p-0219","num":"0218"},"figref":"FIG. 17A","b":["1702","1704","1706","1708","1710","1712"]},{"@attributes":{"id":"p-0220","num":"0219"},"figref":"FIG. 17B","b":["1714","1714","1714"]},{"@attributes":{"id":"p-0221","num":"0220"},"figref":"FIG. 17C","b":["1716","1716","1716"]},"Other configurations for encoder and decoder interfaces are possible. The interface configurations illustrated in  can be used to define an Application Programming Interface (API) for allowing remix-enabled devices to process remix information. The interfaces shown illustrated in  are examples, and other configurations are possible, including configurations with different numbers and types of inputs and outputs, which may be based in part on the device.",{"@attributes":{"id":"p-0223","num":"0222"},"figref":"FIG. 18","b":["1800","1800","1808","1802","1804","1806","1800","1810","1814","1816"]},"On the encoder side, a mixed audio signal is encoded by the mix signal encoder  (e.g., mp3 encoder) and sent to the decoding side. Objects signals (e.g., lead vocal, guitar, drums or other instruments) are input into the remix encoder , which generates side information (e.g., gain factors and subband powers), as previously described in reference to , for example. Additionally, one or more object signals of interest are input to the signal encoder  (e.g., mp3 encoder) to produce additional side information. In some implementations, aligning information is input to the signal encoder  for aligning the output signals of the mix signal encoder  and signal encoder , respectively. Aligning information can include time alignment information, type of codex used, target bit rate, bit-allocation information or strategy, etc.","On the decoder side, the output of the mix signal encoder is input to the mix signal decoder  (e.g., mp3 decoder). The output of mix signal decoder  and the encoder side information (e.g., encoder generated gain factors, subband powers, additional side information) are input into the parameter generator , which uses these parameters, together with control parameters (e.g., user-specified mix parameters), to generate remix parameters and additional remix data. The remix parameters and additional remix data can be used by the remix renderer  to render the remixed audio signal.","The additional remix data (e.g., an object signal) is used by the remix renderer  to remix a particular object in the original mix audio signal. For example, in a Karaoke application, an object signal representing a lead vocal can be used by the enhanced remix encoder  to generate additional side information (e.g., an encoded object signal). This signal can be used by the parameter generator  to generate additional remix data, which can be used by the remix renderer  to remix the lead vocal in the original mix audio signal (e.g., suppressing or attenuating the lead vocal).",{"@attributes":{"id":"p-0227","num":"0226"},"figref":["FIG. 19","FIG. 18"],"b":["1814","1","2","1904","1902","1","2","1904","1902","1","2","1816","1","2"]},"In some implementations, the downmix signal X (e.g., left channel of original mix audio signal) is combined with additional remix data (e.g., left channel of lead vocal object signal) and scaled by scale modules and , and the downmix signal X (e.g., right channel of original mix audio signal) is combined with additional remix data (e.g., right channel of lead vocal object signal) and scaled by scale modules and . The scale module scales the downmix signal X by the eq-mix parameter w, the scale module scales the downmix signal X by the eq-mix parameter w, the scale module scales the downmix signal X by the eq-mix parameter wand the scale module scales the downmix signal X by the eq-mix parameter w. The scaling can be implemented using linear algebra, such as using an n by n (e.g., 2\u00d72) matrix. The outputs of scale modules and are summed to provide a first rendered output signal Y, and the scale modules and are summed to provide a second rendered output signal Y.","In some implementations, one may implement a control (e.g., switch, slider, button) in a user interface to move between an original stereo mix, \u201cKaraoke\u201d mode and\/or \u201ca capella\u201d mode. As a function of this control position, the combiner  controls the linear combination between the original stereo signal and signal(s) obtained by the additional side information. For example, for Karaoke mode, the signal obtained from the additional side information can be subtracted from the stereo signal. Remix processing may be applied afterwards to remove quantization noise (in case the stereo and\/or other signal were lossily coded). To partially remove vocals, only part of the signal obtained by the additional side information need be subtracted. For playing only vocals, the combiner  selects the signal obtained by the additional side information. For playing the vocals with some background music, the combiner  adds a scaled version of the stereo signal to the signal obtained by the additional side information.","While this specification contains many specifics, these should not be construed as limitations on the scope of what being claims or of what may be claimed, but rather as descriptions of features specific to particular embodiments. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable sub-combination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a sub-combination or variation of a sub-combination.","Similarly, while operations are depicted in the drawings in a particular order, this should not be understand as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.","Particular embodiments of the subject matter described in this specification have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results.","As another example, the pre-processing of side information described in Section A provides a lower bound on the subband power of the remixed signal to prevent negative values, which contradicts with the signal model given in [2]. However, this signal model not only implies positive power of the remixed signal, but also positive cross-products between the original stereo signals and the remixed stereo signals, namely E{xy}, E{xy}, E{xy} and E{xy}.","Starting from the two weights case, to prevent that the cross-products E{xy} and E{xy} become negative, the weights, defined in [18], are limited to a certain threshold, such that they are never smaller than A dB.","Then, the cross-products are limited by considering the following conditions, where sqrt denotes square root and Q is defined as Q=10^\u2212A\/10:\n\n"],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF DRAWINGS","p":[{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1B"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 3B","FIG. 3A"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 6A","FIG. 1"]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 6B","FIG. 1A"]},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 7A","FIG. 3A"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 7B","FIG. 7A"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 8B","FIG. 8A"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 9","sub":"i"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 14A"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 14B"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":["FIG. 15","FIG. 14B"]},{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIG. 16","FIGS. 1-15"]},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 17A"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 17B","FIG. 17A"]},{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 17C","FIG. 17B"]},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 19","FIG. 18"]}]},"DETDESC":[{},{}]}
