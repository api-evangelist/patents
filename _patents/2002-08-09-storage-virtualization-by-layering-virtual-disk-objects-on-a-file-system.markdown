---
title: Storage virtualization by layering virtual disk objects on a file system
abstract: A storage virtualization selection technique “automates” a virtualization selection process to create virtual disk (vdisk) storage objects over a volume of a file system implemented by a storage operating system of a multi-protocol storage appliance. The file system provides a virtualization system that aggregates physical storage of a set of disks or portions (e.g., extents) of disks into a pool of blocks that can be dynamically allocated to form a vdisk. The file system also provides reliability guarantees for the vdisks in accordance with its underlying architecture. That is, the file system organizes its storage within volumes created among the managed disks. The vdisk is thereafter created as a storage object within a volume and, thus, inherits the underlying reliability configuration associated with that volume. The portions are aggregated and allocated as a vdisk with reliability guarantees in response to a request to create the vdisk from a user of the storage appliance and without further user involvement.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07107385&OS=07107385&RS=07107385
owner: Network Appliance, Inc.
number: 07107385
owner_city: Sunnyvale
owner_country: US
publication_date: 20020809
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF AN ILLUSTRATIVE EMBODIMENT"],"p":["The present invention relates to storage systems and, in particular, to storage virtualization on a storage system, such as a multi-protocol storage appliance.","A storage system is a computer that provides storage service relating to the organization of information on writable persistent storage devices, such as memories, tapes or disks. The storage system may be deployed within a storage area network (SAN) or a network attached storage (NAS) environment. When used within a NAS environment, the storage system may be embodied as a file server including an operating system that implements a file system to logically organize the information as a hierarchical structure of directories and files on, e.g., the disks. Each \u201con-disk\u201d file may be implemented as a set of data structures, e.g., disk blocks, configured to store information, such as the actual data for the file. A directory, on the other hand, may be implemented as a specially formatted file in which information about other files and directories are stored.","The file server, or filer, may be further configured to operate according to a client\/server model of information delivery to thereby allow many client systems (clients) to access shared resources, such as files, stored on the filer. Sharing of files is a hallmark of a NAS system, which is enabled because of semantic level of access to files and file systems. Storage of information on a NAS system is typically deployed over a computer network comprising a geographically distributed collection of interconnected communication links, such as Ethernet, that allow clients to remotely access the information (files) on the filer. The clients typically communicate with the filer by exchanging discrete frames or packets of data according to pre-defined protocols, such as the Transmission Control Protocol\/Internet Protocol (TCP\/IP).","In the client\/server model, the client may comprise an application executing on a computer that \u201cconnects\u201d to the filer over a computer network, such as a point-to-point link, shared local area network, wide area network or virtual private network implemented over a public network, such as the Internet. NAS systems generally utilize file-based access protocols; therefore, each client may request the services of the filer by issuing file system protocol messages (in the form of packets) to the file system over the network. By supporting a plurality of file system protocols, such as the conventional Common Internet File System (CIFS), the Network File System (NFS) and the Direct Access File System (DAFS) protocols, the utility of the filer may be enhanced for networking clients.","A SAN is a high-speed network that enables establishment of direct connections between a storage system and its storage devices. The SAN may thus be viewed as an extension to a storage bus and, as such, an operating system of the storage system enables access to stored information using block-based access protocols over the \u201cextended bus\u201d. In this context, the extended bus is typically embodied as Fibre Channel (FC) or Ethernet media (i.e., network) adapted to operate with block access protocols, such as Small Computer Systems Interface (SCSI) protocol encapsulation over FC or TCP\/IP\/Ethernet.","A SAN arrangement or deployment allows decoupling of storage from the storage system, such as an application server, and placing of that storage on a network. However, the SAN storage system typically manages specifically assigned storage resources. Although storage can be grouped (or pooled) into zones (e.g., through conventional logical unit number or \u201clun\u201d zoning, masking and management techniques), the storage devices are still pre-assigned by a user, e.g., a system administrator, to the storage system.","Storage virtualization generally involves the pooling of storage resources from multiple storage devices, such as physical disks, typically across a network by one or more storage systems to create a \u201cuser-defined volume\u201d. The term \u201cvolume\u201d as conventionally used in a SAN environment implies a storage entity that is constructed (by a system administrator) by specifying physical disks and extents within those disks via operations that combine those extents\/disks into a user-defined volume storage entity. An extent is a set of contiguously addressed blocks (or \u201cslices\u201d) of storage within the specified physical disks. Such construction can occur on either the storage device or application server. Storage virtualization is often used as part of a SAN deployment, wherein the user-defined volume appears as a single storage entity to the operating system, regardless of the types of storage devices pooled. Virtualization thus separates the representation of storage to the operating system from the actual physical storage connected over the network.","Storage virtualization has many interpretations, including decoupling of physical disk size limitations and underlying physical structure from a user-defined volume corresponding to a disk or lun. Virtualization may also refer to management of luns, including defining underlying reliability guarantees of the storage. Commonly, this aspect of virtualization is accomplished through explicit mirroring or Redundant Array of Independent (or Inexpensive) Disks (RAID) protection levels to a lun that is formed from the storage pool. That is, the system administrator explicitly defines the underlying reliability guarantees of the constructed user-defined volume. It can be appreciated that this administrative procedure is complex, time consuming and, therefore, costly.","Virtualization may further denote the ability to modify an existing configuration of a lun (e.g., to increase its size) along with the performance characteristics of the lun. However, conventional physical disks and strategies that explicitly construct larger units of storage for use by clients may suffer performance limitations. For example, bandwidth to a user-defined volume constructed through explicit aggregation of a number of disks and\/or \u201cslices\u201d (extents) of those disks may be limited by physical constraints of the underlying properties of the constructed volume.","Therefore, the conventional notion of storage virtualization involves presenting a view of storage (i.e., a user-defined volume) to a client wherein the volume is formed from extents of various disks accessible to the client that are selected by a user or system administrator. The selection process performed by the administrator generally includes (i) choosing the various extents from the disks associated with the storage accessible to the client, (ii) applying underlying reliability guarantees (such as RAID or mirroring) to those extents to ensure the reliability of the volume, and (iii) presenting those reliable extents as a single storage entity (e.g., disk or lun) to a client. The present invention is directed to efficiently carrying out a storage virtualization selection process on a storage system.","The present invention relates to a storage virtualization selection technique that \u201cautomates\u201d a virtualization selection process to \u201clayer\u201d (create) virtual disk (vdisk) storage objects over a volume of a file system implemented by a storage operating system of a storage system, such as a multi-protocol storage appliance. Broadly stated, the file system provides a virtualization system that aggregates physical storage of a set of disks or portions (e.g., extents) of disks into a pool of blocks that can be dynamically allocated to form a vdisk. The file system also provides reliability guarantees for the vdisks in accordance with its underlying architecture. That is, the file system organizes its storage within volumes created among the managed disks. The vdisk is thereafter created as a storage object within a volume and, thus, inherits the underlying reliability configuration associated with that volume. Notably, the portions are aggregated and allocated as a vdisk with reliability guarantees in response to a request to create the vdisk from a user of the storage appliance, such as a system administrator, and without further involvement of the user.","According to an aspect of the invention, the technique further provides an on-disk representation of a vdisk for a file system. A vdisk is a special file type in a volume that derives from a plain (regular) file, but that has associated export controls and operation restrictions that support emulation of a disk. Specifically, the vdisk is a multi-inode object comprising a special file inode and at least one associated stream inode that are managed as a single \u201cencapsulated\u201d storage object within the file system. The special file inode functions as a main container for storing data associated with the emulated disk. The stream inode functions as a persistent store for storing various attributes which allow the vdisk to be exported as a logical unit number (lun) to, e.g., storage area network (SAN) clients. These attributes include security information that also allow the encapsulated vdisk to persist, e.g., over reboot operations, and enable management of the vdisk as a single disk object in relation to the SAN clients.","Advantageously, the underlying reliability configuration of a volume defines the reliability characteristics of a vdisk created within that volume. This \u201cinherited\u201d reliability approach of the multi-protocol appliance simplifies management of the vdisk because a user (system administrator) does not have to address the reliability issue on a storage object (vdisk) basis. Rather, the system administrator need merely render global choices of reliability with respect to an entire volume.",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1","b":"100"},"The multi-protocol storage appliance  is illustratively embodied as a storage system comprising a processor , a memory , a plurality of network adapters ,  and a storage adapter  interconnected by a system bus . The multi-protocol storage appliance  also includes a storage operating system  that provides a virtualization system (and, in particular, a file system) to logically organize the information as a hierarchical structure of named directory, file and virtual disk (vdisk) storage objects on the disks . An example of a multi-protocol storage appliance that may be advantageously used with the present invention is described in co-pending and commonly assigned U.S. patent application Ser. No. 10\/215,917 filed Aug. 9, 2002 titled A Multi-Protocol Storage Appliance that Provides Integrated Support for File and Block Access Protocols, which application is hereby incorporated by reference as though fully set forth herein.","Whereas clients of a NAS-based network environment have a storage viewpoint of files, the clients of a SAN-based network environment have a storage viewpoint of blocks or disks. To that end, the multi-protocol storage appliance  presents (exports) disks to SAN clients through the creation of logical unit numbers (luns) or vdisk objects. A vdisk object (hereinafter \u201cvdisk\u201d) is a special file type that is implemented by the virtualization system and translated into an emulated disk as viewed by the SAN clients. The multi-protocol storage appliance thereafter makes these emulated disks accessible to the SAN clients through controlled exports, as described further herein.","In the illustrative embodiment, the memory  comprises storage locations that are addressable by the processor and adapters for storing software program code and data structures associated with the present invention. The processor and adapters may, in turn, comprise processing elements and\/or logic circuitry configured to execute the software code and manipulate the data structures. The storage operating system , portions of which are typically resident in memory and executed by the processing elements, functionally organizes the storage appliance by, inter alia, invoking storage operations in support of the storage service implemented by the appliance. It will be apparent to those skilled in the art that other processing and memory means, including various computer readable media, may be used for storing and executing program instructions pertaining to the invention described herein.","The network adapter  couples the storage appliance to a plurality of clients over point-to-point links, wide area networks, virtual private networks implemented over a public network (Internet) or a shared local area network, hereinafter referred to as an illustrative Ethernet network . For this NAS-based network environment, the clients are configured to access information stored on the multi-protocol appliance as files. Therefore, the network adapter  may comprise a network interface card (NIC) having the mechanical, electrical and signaling circuitry needed to connect the appliance to a network switch, such as a conventional Ethernet switch . The clients  communicate with the storage appliance over network  by exchanging discrete frames or packets of data according to pre-defined protocols, such as the Transmission Control Protocol\/Internet Protocol (TCP\/IP).","The clients  may be general-purpose computers configured to execute applications over a variety of operating systems, including the UNIX\u00ae and Microsoft\u00ae Windows\u2122 operating systems. Client systems generally utilize file-based access protocols when accessing information (in the form of files and directories) over a NAS-based network. Therefore, each client  may request the services of the storage appliance  by issuing file access protocol messages (in the form of packets) to the appliance over the network . For example, a client running the Windows operating system may communicate with the storage appliance  using the Common Internet File System (CIFS) protocol over TCP\/IP. On the other hand, a client running the UNIX operating system may communicate with the multi-protocol appliance using either the Network File System (NFS) protocol over TCP\/IP or the Direct Access File System (DAFS) protocol over a virtual interface (VI) transport in accordance with a remote DMA (RDMA) protocol over TCP\/IP. It will be apparent to those skilled in the art that other clients running other types of operating systems may also communicate with the integrated multi-protocol storage appliance using other file access protocols.","The storage network \u201ctarget\u201d adapter  also couples the multi-protocol storage appliance  to clients  that may be further configured to access the stored information as blocks or disks. For this SAN-based network environment, the storage appliance is coupled to an illustrative Fibre Channel (FC) network . FC is a networking standard describing a suite of protocols and media that is primarily found in SAN deployments. The network target adapter  may comprise a FC host bus adapter (HBA) having the mechanical, electrical and signaling circuitry needed to connect the appliance  to a SAN network switch, such as a conventional FC switch . In addition to providing FC access, the FC HBA offloads fiber channel network processing operations for the storage appliance.","The clients  generally utilize block-based access protocols, such as the Small Computer Systems Interface (SCSI) protocol, when accessing information (in the form of blocks, disks or vdisks) over a SAN-based network. SCSI is a peripheral input\/output (I\/O) interface with a standard, device independent protocol that allows different peripheral devices, such as disks , to attach to the storage appliance . In SCSI terminology, clients  operating in a SAN environment are initiators that initiate requests and commands for data. The multi-protocol storage appliance is thus a target configured to respond to the requests issued by the initiators in accordance with a request\/response protocol. The initiators and targets have endpoint addresses that, in accordance with the FC protocol, comprise worldwide names (WWN). A WWN is a unique identifier, e.g., a node name or a port name, consisting of an 8-byte number.","The multi-protocol storage appliance  supports various SCSI-based protocols used in SAN deployments, including SCSI encapsulated over TCP (iSCSI) and SCSI encapsulated over FC (FCP). The initiators (hereinafter clients ) may thus request the services of the target (hereinafter storage appliance ) by issuing iSCSI and FCP messages over the network  to access information stored on the disks. It will be apparent to those skilled in the art that the clients may also request the services of the integrated multi-protocol storage appliance using other block access protocols. By supporting a plurality of block access protocols, the multi-protocol storage appliance provides a unified and coherent access solution to vdisks\/luns in a heterogeneous SAN environment.","The storage adapter  cooperates with the storage operating system  executing on the storage appliance to access information requested by the clients. The information may be stored on the disks  or other similar media adapted to store information. The storage adapter includes I\/O interface circuitry that couples to the disks over an I\/O interconnect arrangement, such as a conventional high-performance, FC serial link topology. The information is retrieved by the storage adapter and, if necessary, processed by the processor  (or the adapter  itself) prior to being forwarded over the system bus  to the network adapters , , where the information is formatted into packets or messages and returned to the clients.","Storage of information on the appliance  is preferably implemented as one or more storage volumes (e.g., VOL\u2013 ) that comprise a cluster of physical storage disks , defining an overall logical arrangement of disk space. The disks within a volume are typically organized as one or more groups of Redundant Array of Independent (or Inexpensive) Disks (RAID). RAID implementations enhance the reliability\/integrity of data storage through the writing of data \u201cstripes\u201d across a given number of physical disks in the RAID group, and the appropriate storing of redundant information with respect to the striped data. The redundant information enables recovery of data lost when a storage device fails.","Specifically, each volume  is constructed from an array of physical disks  that are organized as RAID groups , , and . The physical disks of each RAID group include those disks configured to store striped data (D) and those configured to store parity (P) for the data, in accordance with an illustrative RAID 4 level configuration. However, other RAID level configurations (e.g. RAID 5) are also contemplated. In the illustrative embodiment, a minimum of one parity disk and one data disk may be employed. However, a typical implementation may include three data and one parity disk per RAID group and at least one RAID group per volume.","To facilitate access to the disks , the storage operating system  implements a write-anywhere file system that cooperates with virtualization modules to provide a function that \u201cvirtualizes\u201d the storage space provided by disks . The file system logically organizes the information as a hierarchical structure of named directory and file objects (hereinafter \u201cdirectories\u201d and \u201cfiles\u201d) on the disks. Each \u201con-disk\u201d file may be implemented as set of disk blocks configured to store information, such as data, whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization system allows the file system to further logically organize information as a hierarchical structure of named vdisks on the disks, thereby providing an integrated NAS and SAN appliance approach to storage by enabling file-based (NAS) access to the files and directories, while further enabling block-based (SAN) access to the vdisks on a file-based storage platform.","In the illustrative embodiment, the storage operating system is preferably the NetApp\u00ae Data ONTAP\u2122 operating system available from Network Appliance, Inc., Sunnyvale, Calif. that implements a Write Anywhere File Layout (WAFL\u2122) file system. However, it is expressly contemplated that any appropriate storage operating system, including a write in-place file system, may be enhanced for use in accordance with the inventive principles described herein. As such, where the term \u201cWAFL\u201d is employed, it should be taken broadly to refer to any storage operating system that is otherwise adaptable to the teachings of this invention.","As used herein, the term \u201cstorage operating system\u201d generally refers to the computer-executable code operable on a computer that manages data access and may, in the case of a multi-protocol storage appliance, implement data access semantics, such as the Data ONTAP storage operating system, which is implemented as a microkernel. The storage operating system can also be implemented as an application program operating over a general-purpose operating system, such as UNIX\u00ae or Windows NT\u00ae, or as a general-purpose operating system with configurable functionality, which is configured for storage applications as described herein.","In addition, it will be understood to those skilled in the art that the inventive technique described herein may apply to any type of special-purpose (e.g., storage serving appliance) or general-purpose computer, including a standalone computer or portion thereof, embodied as or including a storage system. Moreover, the teachings of this invention can be adapted to a variety of storage system architectures including, but not limited to, a network-attached storage environment, a storage area network and disk assembly directly-attached to a client or host computer. The term \u201cstorage system\u201d should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or systems.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 2","b":["200","210","212","214","216","218","220","222","224","226","218"]},"An iSCSI driver layer  provides block protocol access over the TCP\/IP network protocol layers, while a FC driver layer  operates with the FC HBA  to receive and transmit block access requests and responses to and from the integrated storage appliance. The FC and iSCSI drivers provide FC-specific and iSCSI-specific access control to the luns (vdisks) and, thus, manage exports of vdisks to either iSCSI or FCP or, alternatively, to both iSCSI and FCP when accessing a single vdisk on the multi-protocol storage appliance. In addition, the storage operating system includes a disk storage layer  that implements a disk storage protocol, such as a RAID protocol, and a disk driver layer  that implements a disk access protocol such as, e.g., a SCSI protocol.","Bridging the disk software layers with the integrated network protocol stack layers is a virtualization system .  is a schematic block diagram of the virtualization system  that is implemented by a file system  interacting with virtualization modules illustratively embodied as, e.g., vdisk module  and SCSI target module . It should be noted that the vdisk module , the file system  and SCSI target module  can be implemented in software, hardware, firmware, or a combination thereof. The vdisk module  is layered on the file system  to enable access by administrative interfaces, such as a streamlined user interface (UI ), in response to a system administrator issuing commands to the multi-protocol storage appliance . In essence, the vdisk module  manages SAN deployments by, among other things, implementing a comprehensive set of vdisk (lun) commands issued through the UI  by a system administrator. These vdisk commands are converted to primitive file system operations (\u201cprimitives\u201d) that interact with the file system  and the SCSI target module  to implement the vdisks.","The SCSI target module , in turn, initiates emulation of a disk or lun by providing a mapping procedure that translates luns into the special vdisk file types. The SCSI target module is illustratively disposed between the FC and iSCSI drivers ,  and the file system  to thereby provide a translation layer of the virtualization system  between the SAN block (lun) space and the file system space, where luns are represented as vdisks . To that end, the SCSI target module has a set of application programming interfaces (APIs ) that are based on the SCSI protocol and that enable a consistent interface to both the iSCSI and FCP drivers , . By \u201cdisposing\u201d SAN virtualization over the file system , the multi-protocol storage appliance reverses the approaches taken by prior systems to thereby provide a single unified storage platform for essentially all storage access protocols.","The file system  is illustratively a message-based system; as such, the SCSI target module  transposes a SCSI request into a message representing an operation directed to the file system. For example, the message generated by the SCSI target module may include a type of operation (e.g., read, write) along with a pathname (e.g., a path descriptor) and a filename (e.g., a special filename) of the vdisk object represented in the file system. The SCSI target module  passes the message into the file system layer  as, e.g., a function call , where the operation is performed.","The file system provides volume management capabilities for use in block-based access to the information stored on the storage devices, such as disks. That is, in addition to providing file system semantics, such as naming of storage objects, the file system  provides functions normally associated with a volume manager. These functions include (i) aggregation of the disks, (ii) aggregation of storage bandwidth of the disks, and (iii) reliability guarantees, such as mirroring and\/or parity (RAID), to thereby present one or more storage objects layered on the file system. A feature of the multi-protocol storage appliance is the simplicity of use associated with these volume management capabilities, particularly when used in SAN deployments.","The file system  illustratively implements the WAFL file system having an on-disk format representation that is block-based using, e.g., 4 kilobyte (kB) blocks and using inodes to describe the files . The WAFL file system uses files to store metadata describing the layout of its file system; these metadata files include, among others, an inode file. A file handle, i.e., an identifier that includes an inode number, is used to retrieve an inode from disk. A description of the structure of the file system, including on-disk inodes and the inode file, is provided in U.S. Pat. No. 5,819,292, titled Method for Maintaining Consistent States of a File System and for Creating User-Accessible Read-Only Copies of a File System by David Hitz et al., issued Oct. 6, 1998, which patent is hereby incorporated by reference as though fully set forth herein.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 4","b":["400","410","450","410","400","412","414","416","418","420","410","430","450","412","450","450"]},"Specifically, the data section  of a regular on-disk inode may include user data or pointers, the latter referencing 4 kB data blocks on disk used to store the user data. Each pointer is preferably a logical volume block number to thereby facilitate efficiency among the file system and the disk storage (RAID) layer  when accessing the data on disks. Given the restricted size (128 bytes) of the inode, user data having a size that is less than or equal to 64 bytes is represented, in its entirety, within the data section of that inode. However, if the user data is greater than 64 bytes but less than or equal to 64 kB, then the data section of the inode comprises up to 16 pointers, each of which references a 4 kB block of data on the disk. Moreover, if the size of the data is greater than 64 kilobytes but less than or equal to 64 megabytes (MB), then each pointer in the data section  of the inode references an indirect inode that contains 1024 pointers, each of which references a 4 kB data block on disk. Each data block is loaded from disk  into memory  in order to access the data. In addition, the size field  of the metadata section  of the inode refers to the size of the file.","Broadly stated, all inodes of the file system are organized into the inode file. A file system (FS) info block specifies the layout of information in the file system and includes an inode of a file that includes all other inodes of the file system. Each volume has an FS info block that is preferably stored at a fixed location within, e.g., a RAID group of the file system. The inode of the root FS info block may directly reference (point to) blocks of the inode file or may reference indirect blocks of the inode file that, in turn, reference direct blocks of the inode file. Within each direct block of the inode file are embedded inodes, each of which may reference indirect blocks that, in turn, reference data blocks of a file or vdisk.","Referring again to , the file system implements access operations to vdisks , as well as to files  and directories (dir ) that coexist with respect to global space management of units of storage, such as volumes  and\/or qtrees . A qtree  is a special directory that has the properties of a logical sub-volume within the name-space of a physical volume. Each file system storage object (file, directory or vdisk) is illustratively associated with one qtree, and quotas, security properties and other items can be assigned on a per-qtree basis. The vdisks and files\/directories may be layered on top of qtrees  that, in turn, are layered on top of volumes  as abstracted by the file system \u201cvirtualization\u201d layer .","Note that the vdisk storage objects in the file system  are associated with SAN deployments of the multi-protocol storage appliance, whereas the file and directory storage objects are associated with NAS deployments of the appliance. The files and directories are generally not accessible via the FC or SCSI block access protocols; however, a file can be converted to a vdisk and then accessed by either the SAN or NAS protocol. The vdisks are accessible as luns from the SAN (FC and SCSI) protocols and as files by the NAS (NFS and CIFS) protocols.","While vdisks are self-contained objects containing all data necessary for proper operation and authorization, a vdisk table of contents (VTOC ) is provided as a performance enhancement to finding and loading vdisks. The VTOC is not necessary for correct operation and can be reconstructed dynamically by a scan of the vdisks. The VTOC  is a per-volume data structure stored in a metadata file that is used to optimize location determination and initialization of persistent vdisks  in a volume . The VTOC  comprises one or more records , wherein each record includes flags and file entry information that, as noted, can be dynamically reconstructed from information stored in an encapsulated storage object representing the vdisk within the file system . In particular, each record  includes file entries containing (i) a file identifier (inode number) on the volume, (ii) generation number of the vdisk (lun) inode; and (iii) directory information. The directory information, in turn, comprises a file block number in a parent directory (qtree root) containing an entry for the vdisk, along with an index of directory entries in a parent directory block.","The present invention relates to a storage virtualization selection technique that \u201cautomates\u201d a virtualization selection process to layer vdisks  over a volume  of the file system . In response to a user request (command) to create a vdisk, the file system aggregates physical storage of a set of disks  or portions (extents or \u201cslices\u201d) of disks into a pool of blocks that can be dynamically allocated to form the vdisk . The file system also provides reliability guarantees for the vdisks in accordance with its underlying architecture. That is, the file system  organizes its storage within volumes created among the managed disks. The vdisk  is thereafter created as a named storage object within a volume  and, thus, inherits (assumes) the underlying reliability configuration associated with that volume. Notably, the portions are aggregated and allocated as a vdisk with reliability guarantees without further involvement of the user of the storage appliance, such as a system administrator.","Specifically, storage of information on the disks  of the multi-protocol storage appliance is not typed; only \u201craw\u201d bits are stored on the disks. The file system  is configured to write (store) the information on the disks as long, continuous stripes across those disks in accordance with input\/output (I\/O) storage operations that aggregate the bandwidth of all the disks of a volume. According to the inventive technique, the file system organizes that information as vdisks across the disks of the volume. When information is retrieved from the vdisks, the I\/O operations are not directed to disks specified by a user. Rather, those operations are transparent to the user because the file system \u201cstripes\u201d that data across all the disks of the volume in a reliable manner according to its write anywhere layout policy. Thus, the vdisk  does not have to be explicitly configured because the virtualization system  creates a vdisk in a manner that is transparent to the user.","As noted, the file system  organizes information as named file, directory and vdisk objects within volumes  of disks . Underlying each volume  is a collection of RAID groups \u2013 that provide protection and reliability against disk failure(s) within the volume. The information serviced by the multi-protocol storage appliance is protected according to an illustrative RAID 4 configuration. This level of protection may be extended to include, e.g., synchronous mirroring on the appliance platform. A vdisk  created on a volume that is protected by RAID 4 \u201cinherits\u201d the added protection of synchronous mirroring if that latter protection is specified for the volume . In this case, the synchronous mirroring protection is not a property of the vdisk but rather a property of the underlying volume and the reliability guarantees of the file system . This \u201cinheritance\u201d feature of the multi-protocol storage appliance simplifies management of a vdisk because a system administrator does not have to deal with reliability issues.","A vdisk is a special file type in a volume that derives from a plain (regular) file, but that has associated export controls and operation restrictions that support emulation of a disk. More specifically, the vdisk  is a multi-inode object comprising a special file mode and at least one associated stream inode that are managed as a single, encapsulated storage object within the file system . The vdisk  illustratively manifests as an embodiment of the stream inode that, in cooperation with the special file inode, creates a new type of file storage object having the capacity to encapsulate specific security, management and addressing (export) information. An example of a stream inode object that may be advantageously used with the present invention is described in U.S. patent application Ser. No. 09\/891,159 now U.S. Pat. No. 6,643,654 issued Nov. 4, 2003, titled System and Method for Representing Named Data Streams Within an On-Disk Structure of a File System, by K. Patel, which application was filed on Jun. 25, 2001 and is incorporated by reference as though frilly set forth herein.","According to an aspect of the invention, the storage virtualization technique de-couples physical disk size limitations and underlying physical structure from the disk or lun presented to a client. A user may specify \u201cright size\u201d storage as a block device (vdisk) for use by a client using, e.g., a construct that eases management from a client perspective with respect to the vdisk that appears as a physical disk. That is, the vdisk is illustratively a fixed size object that is allocated from a global storage pool of the file system by requesting a specific size using a simple \u201clun create\u201d command, either through a command line interface (CLI ) or a graphical user interface (GUI ).","Although the vdisk is not a physical disk within the multi-protocol storage appliance, the storage virtualization technique \u201cemulates\u201d a physical disk, i.e., in a manner that is transparent to the user and client. One important emulation property of a disk implemented by the technique is that the vdisk cannot be created nor destroyed (removed) except through the CLI or GUI. Implicit in this property is while it is accessible over a NAS protocol (following an explicit action via command to share), a vdisk cannot be implicitly extended by a NAS operation writing outside its allocated space. The vdisk may be resized, e.g., made larger (\u201cgrow\u201d) or smaller (\u201cshrink\u201d), in place without a copy operation and in a manner transparent to the client. Notably, the vdisk may grow or shrink under user control (e.g., via lun commands issued through the UI ) while preserving block and NAS multi-protocol access to its application data. Additional storage space is allocated when the vdisk is grown; when shrunk, the extra space from the vdisk is returned to the global free pool. Moreover, the user (system administrator) has the ability to dynamically (\u201con-the-fly\u201d) create vdisks for use in conventional block access applications.","The inventive technique also simplifies management of the vdisks by identifying them in a storage device and with administration tools used on a client by simple names (consisting of user-defined letters and numbers). SAN clients typically identify and address disks by logical numbers or luns. However, the automated storage virtualization technique allows system administrators to manage vdisks and their addressing by logical names. To that end, the vdisk module  of the multi-protocol storage appliance maps logical names to vdisks. For example when creating a vdisk, the system administrator \u201cright size\u201d allocates the vdisk and assigns it a name that is generally meaningful to its intended application (e.g., \/vol\/vol0\/database to hold a database).","The storage virtualization technique addresses the issue of performance limitations by defining a vdisk abstraction of a disk \u201con top of\u201d the file system. This abstraction aggregates the bandwidth of the underlying disks by providing greater bandwidth for the vdisk than that obtainable by the concatenation of a smaller number of disk drives needed solely to satisfy space requirements. Additionally, delayed allocation policies and write coalescing of the file system can serve to optimize the bandwidth of the vdisk compared to a pure physical implementation. As noted, layering of the vdisk on top of the file system also allows the vdisk to inherit the reliability configuration (e.g., RAID 4 and\/or synchronous mirroring) of the underlying volume.","According to another aspect of the invention, the storage virtualization technique provides an on-disk representation of the vdisk  stored on the multi-protocol storage appliance.  is a schematic block diagram illustrating an on-disk representation  of inode data structures, including vdisk (lun) and stream (attributes) inodes, in accordance with the present invention. A directory (DIR) inode  includes a data section  of pointers  that references directory data blocks, one of which is directory block . The directory block includes a plurality of entries, each containing an external representation of an inode (i.e., the name of the inode) along with mapping information (i.e., the inode number) for that inode. One of those entries, entry , contains mapping information (e.g., a pointer) that references a lun inode .","The lun inode  is the special file inode that functions as a main container for storing data associated with the vdisk . That is, the lun inode comprises a data section  that may store the actual (user or application) data or pointers referencing 4 kB data blocks on disk used to store the data. The data stored in this \u201cdefault\u201d container can be retrieved (read) and stored (written) by a client using conventional block access protocols, such as the SCSI protocol. When appropriately configured, a vdisk may also be accessed using conventional file-level access protocols, such as the NFS protocol. In this configuration, a vdisk \u201cappears\u201d to be a regular file for such accesses. The lun inode  also comprises a metadata section  containing metadata such as the type  (i.e., a special vdisk type) and size  of the vdisk that, upon creation of the inode, is zero. A flag_stream flag  identifies the lun inode  as having not only a default data container section  but also one or more stream \u201csections\u201d, as provided by stream_dir inode .","In order to access the stream_dir inode , the pointer of xinode field  in lun inode  is modified to reference that inode. The stream_dir inode  comprises a metadata section  that includes a type (stream_dir) field  and an xinode field  that references another on-disk inode structure containing, e.g., access control (such as CIFS permission) information associated with the vdisk. The inode  also includes a data section  containing a pointer  that references a stream directory data block associated with the vdisk, such as stream directory block . The stream directory block  comprises a data section  that includes a plurality of entries, each containing an external representation of a stream inode along with mapping information (i.e., the inode number) for that inode. One of those entries, entry , contains mapping information (e.g., a pointer) that references an attributes (stream) inode .","The attributes inode  comprises a metadata section  that includes a type (stream) field  and a data section  that functions as a persistent store for holding various named attributes associated with the vdisk . Attributes are an implementation mechanism that is internal to the file system and not managed by users. These attributes include information that allows the vdisk to be exported as a logical unit number (lun) to, e.g., SAN clients. In addition, the attributes include information that allow the encapsulated vdisk to persist, e.g., over reboot operations, and enable management of the vdisk as a single disk object in relation to the SAN clients.","Examples of the attributes include, among others, geometry , SCSI serial number , space reservation , state (on-line\/off-line)  and export information , the latter controlling access to the vdisk by, e.g., specifying a list of initiators to which the vdisk is exported (i.e., those that have permissions to access to the vdisk). The geometry information  pertains to the physical geometry of the vdisk  needed for emulation of a disk or lun. For example, the vdisk size (as provided by a user) is algorithmically converted to geometry information (e.g., cylinder size), which may be returned to a SAN client as representative of the disk or lun. Although the geometry  is illustratively shown as persistently stored in the attributes inode , in an alternate embodiment, the geometry information  may be calculated dynamically (on-the-fly).","Specifically, the resizability of a vdisk is considered during vdisk creation and geometry selection. A minimum 10\u00d7 resize capability is illustratively factored into selection of initial disk geometry. That is, the initial requested size of the vdisk is increased by 10\u00d7 to calculate a resulting cylinder size used as the basis for the geometry. The resulting cylinder size is also a limiting factor on how large a vdisk can be resized. The geometry information is constant; i.e., once the vdisk is created, most all aspects of its geometry are fixed. Only the number of cylinders may change which, in the illustrative embodiment, has a maximum value of 65,535.","Other entries ,  of the stream directory block  contain mapping information (e.g., pointers) that references other stream inodes, such as a lunmap (stream) inode  and a persistent reservations (stream) inode . The lunmap inode  comprises a metadata section  that includes a type (stream) field  and a data section  that functions as a persistent store for holding a list  of name-value pairs. In the illustrative embodiment, the name is an initiator group (igroup) name and the value is a lun identifier (ID). An igroup is a logical named entity that is assigned to one or more addresses associated with one or more initiators (depending upon whether a clustered environment is configured). These addresses may comprise WWN addresses or iSCSI IDs. A \u201clun map\u201d command is used to export one or more vdisks to the igroup, i.e., make the vdisk(s) \u201cvisible\u201d to the igroup. In this sense, the \u201clun map\u201d command is equivalent to an NFS export or a CIFS share. The WWN addresses or iSCSI IDs thus identify the clients that are allowed to access those vdisks specified by the lun map command.","The persistent reservations inode  comprises a metadata section  that includes a type (stream) field  and a data section  that functions as a persistent store for holding a list  of persistent reservation records that provide ownership and access information relating to the vdisk. Persistent reservations are described in SCSI-3 Primary Commands-3, by Committee T10 of the National Committee for Information Technology Standards. Each persistent reservation record comprises a nexus (initiator ID) , a reservation key (WWN)  and a reservation type (shared, exclusive, read, write) .","In sum, the novel vdisk storage object is structured to contain data and metadata needed to control and manage that object in a single storage entity that is easy to manage within the framework of the storage operating system  executing on the multi-protocol storage appliance . To that end, the vdisk (data and attributes) is managed as a single encapsulated unit within the file system. This \u201cencapsulation\u201d property enables applications executing on the storage appliance to operate with the vdisk without having to be recoded. The encapsulated association of data and attributes also ensures preservation during data protection operations. For example, the encapsulation property enables \u201cbinding\u201d of the data and attributes associated with an encapsulated vdisk storage entity when backing up that entity during, e.g., an asynchronous mirroring operation.","Specifically, the binding between the data (file inode) and attributes (stream inode) of a vdisk creates a single encapsulated object that is \u201cself-describing\u201d in that it contains all the information necessary to, e.g., access that object. Thus, no \u201cexternal\u201d information is needed to describe the vdisk object. It should be noted that there is no binding between a vdisk and disk blocks during write operations (or read operations when defragmentation takes place transparently \u201con-the-fly\u201d). The disk blocks are mapped to logical block addresses of an object residing in the file system. In this case, the file system functions as a dynamic volume manager. This decoupling is a result of using the file system as an underlying storage manager.","According to the invention, the vdisk has a number of other properties, including being \u201cspaced reserved\u201d. That is, unlike regular files that may be of arbitrary size and that may accommodate continuous write operations that increase the sizes of the files, the vdisk is limited to the storage space specified when it is created. A created vdisk may, however, be explicitly resized in order to increase its storage space. A vdisk is also a \u201csparse\u201d file type in the sense that it consumes no storage space at creation and, therefore, does not have to be fully populated. The file system only allocates storage space, e.g., blocks, for the vdisk as data is stored in those blocks; therefore, the vdisk functions as a \u201cplaceholder\u201d that does not have pre-allocated storage.","When a vdisk is created with a specific size, the space reservation property ensures that storage space corresponding to the specified size is always reserved within the file system despite creation of additional files and vdisks, and generation of persistent images of the file system. The sparse file type property further ensures that a write operation does not fail to a vdisk (which would be equivalent to a disk failure from the perspective of a SAN client). This guarantee that write operations to existing vdisks always complete is needed to support transparency to a client.","An advantage of the sparse file property is that creation of a vdisk (e.g., \u201clun create\u201d) occurs substantially instantaneously. Since storage space associated with the vdisk is not pre-allocated, creation of the vdisk occurs fast and efficiently with only accounting information initially needed. Blocks of storage are thereafter allocated as write operations occur to the vdisk. In this context, pre-allocation of blocks involves initializing (\u201czeroing\u201d) the contents of those blocks which, for a large sized disk, could consume a substantial amount of time. Not only does this property allow rapid creation of a vdisk, it also supports data integrity and privacy (i.e., there is no need to initialize data nor to destroy old data).",{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 6","b":["600","602","352","354","320","330","330","320"]},"For example, the vdisk module cooperates with the file system  to check the specified path descriptor and size in Step . This check operation verifies that (i) the volume specified within the path descriptor exists, (ii) the (special file) name has not been previously allocated in the specified volume, and (iii) there is sufficient storage space for the created vdisk within the specified volume. A determination is then made in Step  as to whether the specified path descriptor and size successfully check. If not, vdisk creation is aborted in Step  and the sequence ends at Step . If the path descriptor and size do check, the file system and the vdisk module cooperate to create a file inode associated with the vdisk and set the specified size for that inode (Step ). At step  of the vdisk creation process, a regular (plain) file is created in accordance with, e.g., a create file inode (create_file) primitive.","Thereafter, in Step , a stream inode is created in accordance with a create stream inode (create_stream) primitive. This stream inode is created for purposes for storing attributes associated with (\u201cbound to\u201d) the vdisk to be created. In Step , the stream inode is populated with attributes provided by the user. Here, a primitive (stream_write) is executed that stores information in the stream inode. The attributes may include, among others, the state of the vdisk, permissions for sharing the vdisk over network file system protocols and SCSI inquiry information, e.g., a SCSI serial number. Note that a file owner and group ID parameter is set for use when the vdisk is exported over the network file system protocols. Space reservation guarantees are also set so that write operations to the vdisk do not fail. Another primitive is then executed to convert the type of the file inode from regular to \u201cvdisk\u201d (Step ), to thereby create the vdisk (lun) inode in Step . Note that conversion of the file type from regular to vdisk in Step  protects against possible corruption of the file system. The sequence then ends in Step .","While there has been shown and described an illustrative sequence of steps for creating a vdisk in accordance with the inventive technique, it is to be understood that various other adaptations and modifications may be made within the spirit and scope of the invention. For example, in an alternate embodiment, Steps \u2013 of the illustrative vdisk creation process may be altered to directly create a vdisk (lun) inode, including the stream inode and population of the stream inode with attributes. Moreover, it will be understood to those skilled in the art that other methods of construction may be employed that ensure such atomicity of creation from the perspective of a user in accordance with the principles of the inventive technique.","Advantageously, the vdisk manifests as an embodiment of a stream inode object that, in cooperation with a file inode object, creates a new, special type of file storage object having the capacity to encapsulate specific security, management and addressing (export) information. In particular, the vdisk encapsulates security information (e.g., access control and persistent reservation records) that restrict\/control access to the vdisk, thereby providing multi-protocol access over either NAS or SAN (block) protocols while preserving data integrity. For example, read access to a vdisk over a NAS protocol may be allowed, while read\/write access to the vdisk may be allowed over a SAN (block) protocol. However, write access to the vdisk over the NAS protocol is allowable if access over block protocols is denied. The special file type of the vdisk enhances management of a collection of vdisks for purposes such as inventory and recovery from back-up media. Moreover, the special type facilitates distinguishing of a vdisk for certain operations, such as space reservation, through support of the underlying file system.","The foregoing description has been directed to specific embodiments of this invention. It will be apparent, however, that other variations and modifications may be made to the described embodiments, with the attainment of some or all of their advantages. For example, it is expressly contemplated that the teachings of this invention can be implemented as software, including a computer-readable medium having program instructions executing on a computer, hardware, firmware, or a combination thereof. Accordingly this description is to be taken only by way of example and not to otherwise limit the scope of the invention. It is thus the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The above and further advantages of invention may be better understood by referring to the following description in conjunction with the accompanying drawings in which like reference numerals indicate identical or functionally similar elements:",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
