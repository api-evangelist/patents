---
title: Method and apparatus using multiple sensors in a device with a display
abstract: In a device having a display, at least one sensor signal is generated from a sensor in the device. One or more context values are then generated from the sensor signal. The context values indicate how the device is situated relative to one or more objects. At least one of the context values is then used to control the operation of one or more aspects of the device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07289102&OS=07289102&RS=07289102
owner: Microsoft Corporation
number: 07289102
owner_city: Redmond
owner_country: US
publication_date: 20010606
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["REFERENCE TO RELATED APPLICATION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS","Activating an Audio Receiver","Changing Display Orientation","Tilt Scrolling","Scrolling Without Menu Bar and Start Bar","Selective Display of Toolbars","Display Contrast Adjustment","Power Management"],"p":["The present invention claims priority from a U.S. Provisional application having Ser. No. 60\/218,748, filed on Jul. 17, 2000 and entitled \u201cMETHOD AND APPARATUS USING MULTIPLE SENSORS IN A MOBILE DEVICE.\u201d","The present invention relates to devices with displays. In particular, the present invention relates to computing and mobile devices.","Mobile devices, such as personal information managers (PIMs), cellular telephones, pagers, watches, and wearable computers typically include one or more buttons or touch screens through which the mobile device receives explicit instructions from the user. For example, the user can press buttons to explicitly instruct the device to enter a full-power mode, activate an application, or scroll through an image on the display.","Although the devices are responsive to information provided through such explicit instructions, they are generally not responsive to information that is present in the manner in which the device is being handled by the user. For example, the devices do not automatically enter a full-power mode, even when the user is holding the device in a manner that is consistent with wanting to use the device.","The reason these devices are not responsive to such handling information is that they typically are not equipped with the sensors needed to detect the information nor with the software needed to interpret the information.","Because these devices are generally not responsive to the manner in which the user is holding the device, the user is forced to enter explicit instructions into the device to achieve various functions. In light of this, mobile devices are needed that can sense how they are being handled in order to perform certain background functions that expand the functionality of the mobile device without requiring the user to perform any additional actions.","In a device having a display, at least one sensor signal is generated from a sensor in the device. One or more context values are then generated from the sensor signal. The context values indicate how the device is situated relative to one or more objects. At least one of the context values is then used to control the operation of one or more aspects of the device.","The invention includes several aspects. In one aspect, an image on a display is scrolled at a rate that is based on the difference between a current tilt angle and a tilt angle when tilt scrolling was activated. A further aspect of the invention adjusts the contrast of a display based on the tilt angle of the display.","Other aspects of the invention control the power mode of the device based on whether it is being handled, its orientation, and\/or whether it is being gestured toward.","Still further aspects of the invention activate applications based on the device being in a particular orientation while being held by the user.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1","b":["200","200","202","204","206","208","210"]},"Memory  is implemented as a non-volatile electronic memory such as a random access memory (RAM) with a battery back-up module (not shown) such that information stored in memory  is not lost when the general power to mobile device  is shut down. A portion of memory  is preferably allocated as addressable memory for program execution, while another portion of memory  is preferably used for storage, such as to simulate storage on a disk drive.","Memory  includes an operating system , application programs , and an object store . During operation, operating system  is preferably executed by processor  from memory . Operating system , in one preferred embodiment, is a WINDOWS\u00ae CE brand operating system commercially available from Microsoft Corporation. Operating system  is preferably designed for mobile devices, and implements database features that can be utilized by applications  through a set of exposed application programming interfaces and methods. The objects in object store  are maintained by applications  and operating system  at least partially in response to calls to the exposed application programming interfaces and methods.","Communication interface  represents numerous devices and technologies that allow mobile device  to send and receive information. The devices include wired and wireless modems, satellite receivers and broadcast tuners to name a few. Mobile device  can also be directly connected to a computer to exchange data therewith. In such cases, communication interface  can be an infrared transceiver or a serial or parallel communication connection, all of which are capable of transmitting streaming information.","Input\/output components  include a variety of input devices that have previously been found on mobile devices such as a touch-sensitive screen, buttons, rollers, and a microphone as well as a variety of output devices including an audio generator, a vibrating device, and a display. The devices listed above are by way of example and need not all be present on mobile device .","Mobile device  also includes additional input devices under the present invention. Under one embodiment, these input devices are connected to the mobile device through a separate serial port  and a peripheral interface controller (PIC) microprocessor . In other embodiments, these additional devices are connected to processor  through communication interface  and PIC microprocessor  or through PIC microprocessor  directly. Under one embodiment, a microchip 16C73A peripheral interface controller is used as the PIC microprocessor. In still further embodiments, PIC microprocessor  is not present and the input devices are connected to processor  through various ports such as serial port  or through communication interface .","Under the embodiment of , The additional input devices include two touch sensors  and , a forward\/back tilt sensor , a left\/right tilt sensor , a proximity sensor  consisting of an infrared transmitter  and an infrared receiver , a digital compass , and a gravity switch . The sensing signals from the infrared receiver , left\/right tilt sensor , forward\/back tilt sensor , digital compass , and gravity switch  are provided through respective amplifiers , , ,  and  to analog inputs of PIC microprocessor . These analog inputs are connected to analog-to-digital converters within PIC microprocessor . In other embodiments, the sensors provide a digital output and thus are connected to digital inputs on the microprocessor.","In the embodiment of , touch sensors  and  are provided to a separate peripheral interface controller microprocessor  which converts the touch signals into digital values and provides the digital values to PIC microprocessor . In other embodiments, touch sensors  and  are connected directly to analog or digital inputs in PIC microprocessor  instead of being connected to PIC  or are connected to processor .","PIC microprocessor  also includes a connection to the power bus of mobile device , which is shown as connection  in . PIC microprocessor  also includes a connection to a power switch , which enables PIC microprocessor  to turn mobile device  on and off. Note that PIC microprocessor  always receives power and, under one embodiment, is able to control which of the sensors receives power at any one time. This allows PIC microprocessor  to manage power consumption by only sending power to those sensors that it anticipates will need to be active.","Under one embodiment, PIC microprocessor  continuously samples the sensors and transmits packets representing the state of these sensors at a rate of approximately 400 samples per second through serial port . In some embodiments, samples are reported at lower speeds to conserve power and processing resources. Some sensors may be reported at different sampling rates than others (e.g. tilt may be updated more frequently than touch).","Under one embodiment, touch sensor  is a capacitive touch sensor that is divided into two regions. In other embodiments, it is also possible to implement this sensor with a single detector pad. This touch sensor is spread across the back and sides of mobile device . This is shown in more detail in  which show a back, left side view and right side view of the outside of mobile device . In , , and , touch sensor  is shown as two regions  and . Region  extends from the left side to the back of mobile device  and region  extends from the right side to the back of mobile device . When a user touches either section  or , the capacitance associated with the touched section changes indicating that the user has touched the device. Note that although the touch sensors are shown on the exterior of the device in the embodiment of , in other embodiments, the touch sensor is located beneath an outer covering of the device.","Touch sensor  is shown in , which is a front view of mobile device . In the embodiment of , touch sensor  is located on the left bezel of display screen . In other embodiments, touch sensor  is located on the outer casing on the front portion of mobile device , but not necessarily on bezel  of mobile device .","In some embodiments, the touch sensors described above are realized using a plurality of independent touch sensors that each provides a separate touch signal. In other embodiments, the touch sensors are replaced with position sensors that indicate the location where the user is touching the device. Those skilled in the art will recognize that additional touch sensors may be added to the mobile device within the scope of the present invention.","Left\/right tilt sensor  and forward\/back tilt sensor  are shown as a single dotted element  in . These tilt sensors are embedded within the casing of mobile device  and in one embodiment are located at a point about which users typically pivot mobile device  when tilting the device. Note that the tilt sensor's position within the mobile device is unimportant as it senses only the angle of its physical attitude with respect to gravity. The sensor's angular position within the device is important.","Under one embodiment, an Analog Devices ADXL05 two-axis linear accelerometer is used for tilt sensors  and . Such a sensor detects forward\/backward tilt, shown by arrows  of , and left\/right tilt, shown in the bottom view of  as arrows . The sensor also responds to linear accelerations, such as those resulting from shaking the device. Typically, the tilt sensor has a response curve both in the forward\/back direction and left\/right direction with the form:",{"@attributes":{"id":"p-0039","num":"0038"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"Angle","mo":"=","mrow":{"msup":{"mi":"sin","mrow":{"mo":"-","mn":"1"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mrow":{"mi":"T","mo":"-","msub":{"mi":["T","c"]}},"mi":"k"}}}},"mo":"\u2003"}},{"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"1"}}]}}}},"br":{},"sub":"c ","b":"282","figref":"FIG. 1"},"In addition, the tilt sensors do not respond to rotation about an axis running from the front to the back of the mobile device. Thus, the tilt sensors are unable to sense the spinning of the mobile device on its back when laid on a flat table. Digital magnetic compass  of  is thus provided in some embodiments to indicate this type of rotation. In other embodiments, solid state gyros are used instead of the compass.","When present, gravity switch  and digital compass  are also internal to mobile device . They are not shown in  to reduce the complexity of .","Note that the additional input devices of  do not all have to be present under the present invention. Different embodiments of the invention will use different numbers of and different combinations of these additional sensors. Further, additional sensors may be added without affecting the functions of the sensors discussed in the present application.","Transmitter  and receiver  of proximity sensor  are shown in . In the embodiment of , transmitter  is shown below and to the right of receiver , and both the transmitter and receiver are located at the top front of mobile device .","Under one embodiment, a timer  drives transmitter  at 40 kilohertz and transmitter  is an infrared light emitting diode with a 60\u00b0 beam angle. Under such embodiments, receiver  is also an infrared receiver that is capable of operating at the same frequency as transmitter . The light produced by transmitter  bounces off objects that are near mobile device  and the reflected light is received by receiver . Receiver  typically has an automatic gain control such that the strength of the received signal is proportional to the distance to the object.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 7","FIG. 7","FIG. 7","FIG. 7"],"b":["702","704","706","200","708","200","710","200"]},{"@attributes":{"id":"p-0046","num":"0045"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["Z","cm"]},"mo":"=","mfrac":{"mi":"k","msup":{"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mfrac":{"mi":"p","msub":{"mi":["p","max"]}},"mo":"-","mi":"c"}},"mo":"\u2003"},"mi":"a"}}}},{"mrow":{"mi":"EQ","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"2"}}]}}}},"br":{},"sub":["cm ","max "]},"Under one embodiment, the power consumed by proximity sensor  is limited by pulsing transmitter  a few times a second when the user is out of range, or by reducing the duty cycle of timer .","In other embodiments, IR receiver  generates a digital signal instead of the analog signal shown in . The digital signal provides a representation of the transmitted signal. However, as the distance between the device and the user increases, the number of errors in the digital signal increases. By counting these errors, PIC  is able to determine the distance between the user and the device.",{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 8","FIG. 8","FIG. 1"],"b":["800","250"]},"Context information server  acts as a broker between the sensor values received by the microprocessor  and a set of applications  operating on mobile device . Context information server  continuously receives sensor data packets from PIC , converts the raw data into a logical form, and derives additional information from the sensor data.","Applications  can access the logical form of information generated by context information server  either by polling a block of shared memory  in which context information server  stores the logical form information, or alternatively by asking context information server  to provide a specific piece of information via a system event message when a specific sensor value changes.","In addition, applications can post certain context information with context information server  so that it may be shared with other applications. Such posting is described in greater detail in context with one embodiment of the present invention described below.","In , a first in\/first out memory stack  is also provided that stores a history of past states for mobile device . These past states are used in certain embodiments of the present invention as described further below.","Tables 1, 2, 3 and 4 below provide lists of the context variables that can be generated by context information server 800. In the description column of each table, specific values for the variables are shown in italics. For example, the DISPLAYORIENTATION variable can have Display Orientation context values of flat, portrait, landscape left, landscape right, or portrait upside down.",{"@attributes":{"id":"p-0055","num":"0054"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"63pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 1"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"Group","Context Variable","Description"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Touch","Holding&Duration","Whether or not"]},{"entry":[{},{},{},"the user is"]},{"entry":[{},{},{},"holding the"]},{"entry":[{},{},{},"device and for"]},{"entry":[{},{},{},"how long"]},{"entry":[{},{},"TouchingBezel&","Whether user is"]},{"entry":[{},{},"Duration","touching screen"]},{"entry":[{},{},{},"bezel and for"]},{"entry":[{},{},{},"how long"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}}}},{"@attributes":{"id":"p-0056","num":"0055"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"63pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 2"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"Group","Context Variable","Description"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Tilt\/","TiltAngleLR,","Left\/Right and"]},{"entry":[{},"Accelerometer","TiltAngleFB","Forward\/Back"]},{"entry":[{},{},{},"tilt angles in"]},{"entry":[{},{},{},"degrees"]},{"entry":[{},{},"DisplayOrientation,","Flat, Portrait,"]},{"entry":[{},{},"Refresh","LandscapeLeft,"]},{"entry":[{},{},{},"LandscapeRight,"]},{"entry":[{},{},{},"or Portrait-"]},{"entry":[{},{},{},"UpsideDown. A"]},{"entry":[{},{},{},"Refresh event is"]},{"entry":[{},{},{},"posted if apps"]},{"entry":[{},{},{},"need to update"]},{"entry":[{},{},{},"orientation"]},{"entry":[{},{},"HzLR, MagnitudeLR,","Dominant"]},{"entry":[{},{},"HzFB, Magnitude FB","frequency and"]},{"entry":[{},{},{},"magnitude from"]},{"entry":[{},{},{},"FFT of tilt"]},{"entry":[{},{},{},"angles over the"]},{"entry":[{},{},{},"last few seconds"]},{"entry":[{},{},"LookingAt,","If user is"]},{"entry":[{},{},"Duration","looking at"]},{"entry":[{},{},{},"display"]},{"entry":[{},{},"Moving & Duration","If device is"]},{"entry":[{},{},{},"moving in any"]},{"entry":[{},{},{},"way."]},{"entry":[{},{},"Shaking","If device is"]},{"entry":[{},{},{},"being shaken"]},{"entry":[{},{},"Walking,","If user is"]},{"entry":[{},{},"Duration","walking"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}}}},{"@attributes":{"id":"p-0057","num":"0056"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 3"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"Group","Context Variable","Description"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Proximity","Proximity","Estimated"]},{"entry":[{},{},{},"distance in cm"]},{"entry":[{},{},{},"to proximal"]},{"entry":[{},{},{},"object"]},{"entry":[{},{},"ProximityState,","Close, InRange,"]},{"entry":[{},{},"Duration","OutOfRange,"]},{"entry":[{},{},{},"AmbientLight"]},{"entry":[{},{},{},"(when out-of-"]},{"entry":[{},{},{},"range and bright"]},{"entry":[{},{},{},"ambient light is"]},{"entry":[{},{},{},"present)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}}}},{"@attributes":{"id":"p-0058","num":"0057"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 4"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]},{"entry":[{},"Group","Context Variable","Description"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Other","Scrolling","If user is"]},{"entry":[{},{},{},"currently"]},{"entry":[{},{},{},"scrolling"]},{"entry":[{},{},{},"(posted by"]},{"entry":[{},{},{},"scroll app)"]},{"entry":[{},{},"VoiceMemoGesture","If recording a"]},{"entry":[{},{},{},"voice memo."]},{"entry":[{},{},{},"(posted by voice"]},{"entry":[{},{},{},"recording app)"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"3","align":"center","rowsep":"1"}}]}]}}}}},"The context variables of Table 1 are generated based on signals from the touch sensors, those in Table 2 are generated based on tilt sensors, those in Table 3 are generated based on the proximity sensors, and those in Table 4 are posted by other applications and are not generated directly from the sensor data.","The sensors described in  have many novel uses under the present invention. Each of these uses is described below.","Many applications on mobile devices activate an audio receiver to receive an audio input that is further processed. For example, the audio signal can be recorded, can be used as input to a speech recognition system, or can be transmitted.","Typically, devices have activated their audio receiver based on the user pressing a button or activating a particular application. Thus, the user must physically manipulate a button or keyboard in order to activate and deactivate the audio receiver.","The present invention provides a means for automatically activating an audio receiver based on how the user is holding the input device.","In its most basic form, the present invention activates the audio receiver based on a proximity sensor that senses when the input device is close to the user. In more complex embodiments, the input device must also be held by the user before the audio receiver will be activated; this prevents accidental activation of the audio receiver when the device is in a purse or briefcase. In the embodiment of , the user is considered to be holding the device when the touch sensors on the side and back of the device are activated.","In still more complex embodiments, the user must also tilt the device before the audio receiver will be activated. For instance, in one embodiment, the user must hold mobile device  in an almost vertical position. Under one embodiment, the angle of tilt must be within a specific range. Since users typically tilt an input device to the left and back when making the gesture associated with wishing to speak into the input device, both left\/right tilt and forward\/back tilt can be examined to determine if the tilt is proper. These tilt angles correspond to the approximate angle at which one would hold a device such as a mobile phone when speaking into it. Several ranges of tilt signals can be used, such that tilting will be recognized if the device is held either in the left or the right hand.","This can be seen in , which shows left\/right tilt along horizontal axis  and forward\/back tilt along vertical axis . A block  indicates the acceptable ranges for left\/right and forward\/back tilt for activating the audio receiver.","The conditions of being held, having the device in close enough proximity, and having the device properly tilted must all be met for at least 0.1 seconds before the audio receiver is activated under one embodiment of the present invention.","In embodiments that use proximity, touch, and tilt to determine when to activate the audio receiver, the audio receiver is deactivated if any one of these criteria stops being met. For example, if the user stops holding the device, or the user takes the device away from their mouth, the audio receiver would be deactivated.","Under some embodiments, to assist the user in knowing when the audio receiver is active, a sound is emitted by mobile device  when the receiver is activated. Another sound is then emitted when the audio receiver is deactivated. In still further embodiments, a separate sound is provided to indicate that the gesture is proper for activating the audio receiver before the audio receiver is actually activated.","Using the context variables of Tables 1-4, an application would determine whether to activate its audio receiver based on the HOLDING and DURATION context variable, the TiltAngleLR and TiltAngleFB context variables, and the Proximity or ProximityState context variables. In some embodiments, the sequence of recent values is used to determine a composite gesture, rather than just comparing instantaneous values.","As noted above, the activation of an audio receiver can be used when recording an audio message, when applying an audio signal to a speech recognition system or when transmitting a voice signal either across a computer network or through a cellular network. In addition, the activation of an audio receiver can be made through a phone, or any hand held device that is capable of receiving audio signals.","It is thought by the present inventors that by eliminating the need to press an activation button, the user is able to concentrate more on other tasks while speaking into the audio receiver. Thus, since the user does not have to concentrate on pressing and maintaining tension on a particular button, they are better able to concentrate on other tasks while speaking.","Although the above embodiment has been described in connection with activating an audio receiver, it may be generalized to starting other applications based on the mobile device being placed in an appropriate orientation for the application. For example, if the user is holding the device in an orientation that is indicative of listening to the device, an application that automatically plays voice mail could be activated. Another example would be answering a call on a cell phone: when the phone rings, the user picks it up and places it next to his or her ear to answer the call. Because of the sensed gesture, there is no need to perform secondary preparatory actions to answer the call (such as pressing a TALK button or opening a flip-top cover). Such preparatory actions are unnecessary under the present invention and as such the present invention eliminates extra steps that may be distracting or unfamiliar to the user.","In other embodiments of the present invention, the tilt sensor is used to detect the orientation of the mobile device so that the image on the display of the mobile device may be matched to the mobile device orientation.",{"@attributes":{"id":"p-0075","num":"0074"},"figref":["FIG. 10","FIG. 10","FIG. 11"],"b":["1100","1102","1100","1104","1104","1100"]},"Under the present invention, the displayed image may be matched to the orientation of the device through a simple rotation of the display image or through a redrawing of the display image based on the orientation of the device and the relative dimensions of the display in that orientation.","A simple rotation is typically performed by using the center of the screen as the center of rotation. For such rotations, a transform of points x, y in the document to a point x\u2032, y\u2032 on the screen is given by equation 3:\n\n\u2003\u2003EQ. 3\n\nwhere T is a translation and R is the 2D rotation matrix for 0\u00b0, 90\u00b0, 180\u00b0, or 270\u00b0.\n","A redrawing of the image that takes the dimensions of the display into consideration allows applications to change the contents of the image before redrawing the image. For instance, a word processing application can recalculate word wrapping based on the dimensions of the display in its new orientation. Thus, the number of words per line will change when the image is drawn in its new orientation. An example of this effect can be seen by comparing the text in image  to the text in image .","Context information server  causes the image to be refreshed by sending an appropriate notification to applications . These applications then generate a new image for the display.","To determine the orientation of the mobile device, most embodiments of the present invention examine both the left\/right tilt of the mobile device and the front\/back tilt.  provides a graph showing the display orientation context values determined by context information server  for various combinations of left\/right tilt context values and forward\/back tilt context values, found in the TiltAngleLR context variable and the TiltAngleFB context variable, respectively. In , left\/right tilt context values are shown along horizontal axis  and forward\/back tilt context values are shown along vertical axis . In , there are four orientation regions , , , and , which are separated by deadbands , ,  and .  also includes a flat area , that corresponds to the mobile device being laid flat.","Orientation area  is related to an upright portrait orientation for a mobile device such as mobile device  of . This is the typical or natural way for a user to hold the mobile device. Orientation areas  and  are associated with a rotation of the mobile device counterclockwise and clockwise 90\u00b0, respectively. Orientation area  is associated with the mobile device being rotated 180\u00b0 so that is upside down.","Transitions between these areas nominally occur when the left\/right tilt equals the forward\/back tilt. As shown by deadbands , ,  and , the display does not switch immediately at these angles. Instead, there is a plus or minus 5\u00b0 deadband to prevent jitter. Thus, the device must tilt through the entire deadband zone before context information server  of  will issue a new orientation value. In some embodiments, there is a further 0.5 second time-out. The orientation of the device must remain at the new orientation for 0.5 full seconds before the display format changes.","Under some embodiments of the present invention, the mobile device's directional inputs are also remapped to match the orientation of the mobile device. For example, directional input  of  has a different mapping in the two figures. In , pressing directional input  toward the screen corresponds to moving upward through the text. In , pressing directional input  toward the screen corresponds to moving left through the text.","Under one embodiment of the present invention, the orientation of the display is stabilized to avoid undesired switching of the displayed orientation as the user places the mobile device on a flat surface. During the process of placing a mobile device on a flat surface, it is common for the user to tip the mobile device slightly in one or more directions. Without the stability provided by this embodiment, the display may switch to other orientations that the user does not want.","Under one embodiment of the present invention, orientation stability is maintained by using a first-in-first-out queue of recent display orientations. Such a queue is shown as FIFO  in . The FIFO-queue includes a list of recent display orientations.","When the user puts down the device, indicated by the tilt sensors indicating the device is flat and the touch sensors indicating that the device is not being held, context information server  searches through FIFO  to find the most recent stable orientation other than flat. An orientation is considered stable if it was maintained for more than 1 or 2 seconds. This stable orientation is then selected as the orientation to be used while the device remains flat.","Under embodiments of the present invention, a user can scroll through a displayed document, spreadsheet, or image, simply by tilting the input device. In most embodiments, the user indicates their desire to use tilt scrolling by touching the touch pad on the bezel of the mobile device. Although in the embodiments discussed below, a touch sensor is used to indicate a desire to begin tilt scrolling, other inputs can be used within the scope of the present invention to indicate that the user wishes to begin tilt scrolling.","Under one embodiment of the invention, when the user indicates that they wish to begin tilt scrolling, the mobile device captures the current forward\/back tilt and left\/right tilt and uses these tilt angles as the starting orientation for the device. The direction and speed of scrolling is then determined relative to this starting orientation.","By capturing this starting orientation, the present invention keeps the displayed image from scrolling until the user tilts the device from its initial position. This makes the scrolling behave in a more predictable manner and is different from prior art tilt scrolling devices. In prior art devices, the direction and speed of the scrolling is determined relative to tilt angles of zero or tilt angles that the user must set using a separate command to \u201crecenter\u201d the device. As such, the device will begin to scroll immediately if the device is tilted when the user indicates that they want to activate tilt scrolling. The present invention improves on the use of a \u201crecenter\u201d command by combining recentering with the initiation of scrolling (i.e. as soon as the user touches the bezel to start scrolling, this also resets the starting angles for the tilt).","Under the present invention, the rate and direction of forward\/back scrolling is related to the angle of forward\/back tilting by:\n\n\u00b7sgn()\u00b7max(\u2225,0)\u2003\u2003EQ. 4\n\nwhere vis the calculated velocity for the forward-backward scrolling, k is the control gain, dAis the change in the forward\/back tilt angle relative to a beginning orientation, dAis the size of a dead band, and a is a non-linear parameter. Under one embodiment, k=0.2, \u03b1=1.6 and dA=1\u00b0-4\u00b0. A similar equation is used to determine left\/right scrolling based on left\/right tilt angle.\n","The scrolling control can be single axis where the device examines the left\/right tilt and the forward\/back tilt and only scrolls along the axis with the larger tilt angle. Thus, if the relative forward\/back tilt is larger than the relative left\/right tilt, the image is scrolled based only on the forward\/back tilt. Alternatively, the scrolling control may be mixed exclusive axis, where a square dead band is applied around the zero tilt point, such that small tilts are ignored. For instance, if a user tilts the device a small amount forward but a large amount left, the image will only scroll left. However, if the user increases the forward tilt, the image will scroll diagonally. Lastly, the scrolling control can be a dual axis control in which both forward\/back tilt and left\/right tilt are used at the same time to scroll the image without a dead band.","Under one embodiment of the present invention, tilt scrolling is combined with the orientation matching described above. This represents a significant challenge since both techniques utilize the tilting of the device for changing the display.","Under the present invention, once scrolling has been initiated, the tilt of the device is only applied to the scrolling and is not used to change the orientation of the display. Thus, tilting the mobile device will not cause the orientation to switch until scrolling is deactivated.","The application that is controlling the scrolling helps to enforce this rule by posting a scrolling value with Context Information Server . This value is shown in Table 4. Once this value is posted, Context Information Server  suspends updates to the DISPLAYORIENTATION value until scrolling has stopped.","In addition, when the user releases the scrolling button or the scrolling touch sensor, the system does not automatically change the orientation based on the current tilt. Instead, the system allows the user 1 or 2 seconds to return the mobile device to the position it was in when scrolling was initiated. After that waiting period, the orientation of the image is changed to match the orientation of the mobile device.","In many applications, a displayed document is shown with banners that provide menus, scroll bars, and\/or command icons. Under one embodiment of the present invention, the inventors have discovered that users do not need the command menus or the command icons during scrolling. Thus, under one embodiment of the invention, applications remove their menu bars and command bars from the display during scrolling. Note that this invention is not limited to mobile devices and may be used on any computing system or with any type of mobile device. By removing the menu bars or command icons, more screen area is available for showing the image that is being scrolled. This makes it easier for the user to find the information they want.","The removal of the command bars during scrolling is independent of tilt scrolling. In other words, the aspect of removing command bars may be practiced regardless of how the scrolling is initiated.","Under one embodiment, the input used to remove the menu bars and command icons is the same as that used to initiate scrolling. For example, in a tilt scrolling application, the menu bar and command icons disappear as soon as the user presses the button or touch sensor that indicates that tilt scrolling is to be initiated. Under such embodiments, a larger dead zone from the zero orientation angle may be needed to ensure that the image does not scroll when the user just wants to view the full screen.","Under some embodiments of the present invention, several touch sensors are provided on the mobile device. For a given application, each touch sensor is associated with a different toolbar. When the user is touching a particular touch sensor, its corresponding toolbar is displayed. However, when the user is not touching the touch sensor, the toolbar is hidden so that more of the document or image may be displayed. In some embodiments, the touch sensor may be associated with an entire application (rather than just a toolbar) so that the user may switch applications temporarily by maintaining contact with the touch sensor. In this case, further interaction with the application using the stylus (touch-screen) causes the switch to become permanent.","One problem encountered when using a tilted liquid crystal display is that as the display is tilted away from the user, the contrast of the displayed image is lessened. The present invention improves the displayed image by increasing the contrast of the display as the user tilts the display away from them. Note that this aspect of the present invention is not limited to personal information managers and may be used with any LCD device such as a pager, watch, laptop computer, cell phone, or stand alone LCD display. Under one embodiment, the contrast is set according to the following equation:\n\ncontrast=\u2003\u2003EQ. 5\n\nwhere m is a constant equal to \u22120.135, b is a constant equal to 5.25, dAis the change from the ideal viewing angle as measured by a tilt sensor in the display, and \u201ccontrast\u201d is the change in the contrast setting. Note that these values correspond to the software contrast settings of 1-10 available on the Cassiopeia E105 device. To prevent hysteresis, a tilt angle change of more than 3\u00b0 is typically required before the contrast is adjusted.\n","Under one embodiment of the present invention, a mobile device places itself in a full-power mode based on how the device is being handled. In one particular embodiment, the invention uses a combination of sensors to determine whether the user wants the device to be in full-power mode. In particular, the system uses a touch sensor to determine whether the user is holding the device and a tilt sensor to determine whether the user has properly oriented the device so that it is likely they are looking at it. By using both a touch sensor and an orientation sensor, the present invention avoids placing the device in full-power mode when it is in a briefcase.","In one particular embodiment, the orientation for full-power mode is a left\/right tilt of between plus or minus 15\u00b0, a forward\/back tilt of greater than \u22125\u00b0, and an upright portrait orientation. If the user maintains this orientation for at least 0.5 seconds, PIC microprocessor  of  places the device in full-power mode using power switch . The required time interval can be set as desired but is used to prevent powering up due to transient signals.","In other embodiments, the present invention prevents a mobile device from entering an idle mode if the user is handling the device or gesturing toward the device. In idle mode, the mobile device reduces the power consumption of the device by turning off the display. Typically, a mobile device will enter idle mode if the user has not pressed a button or touched the screen for some period of time. Under certain types of usage, users find that the system powers down when they would rather have it remain active. For instance, this often happens when the user is reading a large amount of text or is trying to interact with someone else while periodically relating to the text.","Under one embodiment of the invention, the device is prevented from entering an idle mode when context information server  determines that the user is holding the input device or when it determines that there is motion near the device. Such motion can be detected by changes in the output of the proximity sensor and is indicative of a user gesturing toward the device.","Note that this embodiment relies on motion and not just proximity. This is done to allow the device to enter idle mode when it is placed near a fixed object while it is not being used. For example, under the present invention, the device will still enter idle mode if a stack of paper is placed on top of the device.","Although the present invention has been described with reference to preferred embodiments, workers skilled in the art will recognize that changes may be made in form and detail without departing from the spirit and scope of the invention."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 4","FIG. 2"]},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 5","FIG. 2"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 6","FIG. 2"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
