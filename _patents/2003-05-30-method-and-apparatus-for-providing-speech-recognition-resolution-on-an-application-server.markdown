---
title: Method and apparatus for providing speech recognition resolution on an application server
abstract: A method of providing speech recognition resolution on an application server in a communication network includes receiving an utterance from an end-user, for example, at a Voice Gateway in response to a prompt by an application prompt, capturing the utterance, and dispatching it via the application server to a speech recognition provider. The method further includes performing item-matching via a search algorithm, returning items matching the utterance to the application server, and returning relevant utterance matches to the application, for example, on the Voice Gateway, for communication to the user.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07016845&OS=07016845&RS=07016845
owner: Oracle International Corporation
number: 07016845
owner_city: Redwood Shores
owner_country: US
publication_date: 20030530
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application claims the benefit of U.S. Provisional Application No. 60\/425,178, filed Nov. 8, 2002 the entire content of which is hereby incorporated by reference. The field of the invention relates, in general, to speech recognition, and more particularly to a method and apparatus for providing speech recognition resolution on an application server.","A Voice application written for example in VoiceXML (a derivative of the Extensible Markup Language (XML)) processes spoken input from a user through the use of grammars, which define what utterances the application can resolve. VoiceXML (VXML) allows a programmer to define a \u201cgraph\u201d that steps a user through a selection process\u2014known as voice dialogs. The user interacts with these voice dialogs through the oldest interface known to mankind: the voice. Hence, VoiceXML is a markup language for building interactive voice applications which, for example, function to provide recognition of audio inputs such as speech and touch-tone Dual Tone Multi-Frequency (DTMF) input, play audio, control a call flow, etc. . . .","A VoiceXML application comprises a set of VoiceXML files. Each VoiceXML file may involve one or more dialogs describing a specific interaction with the user. These dialogs may present the user with information and\/or prompt the user to provide information. A VoiceXML application functions similar to an Internet-based application accessed through a web browser, in that it typically does not access the data at a dial-in site but often connects to a server that gathers the data and presents it. The process is akin to selecting a hyperlink on a traditional Web page. Dialog selections may result in the playback of audio response files (either prerecorded or dynamically generated via a server-side text-to-speech conversion).","Grammars can be used to define the words and sentences (or touch-tone DTMF input) that can be recognized by a VoiceXML application. These grammars can, for example, be included inline in the application or as files, which are treated as external resources. Instead of a web browser, VoiceXML pages may be rendered through Voice Gateways, which may receive VoiceXML files served up by a web or application server as users call in to the gateway.","Voice Gateways typically comprise seven major components, as follows: a Telephony Platform that can support voice communications as well as digital and analog interfacing, an ASR Engine, a Text To Speech synthesis (TTS) engine, a Media Playback engine to play audio files, a Media Recording engine to record audio input, a Dual Tone Multi-Frequency (DTMF) Engine for touchtone input, and a Voice Browser (also known as a VoiceXML Interpreter). When a VoiceXML file is rendered by a Voice Gateway, the grammars may be compiled by the ASR (Automated Speech Recognition) engine on the Voice Gateway.","The resolution capabilities of standard ASR engines are often fairly limited because performance in resolving utterances declines quickly with size, typically limiting grammar sizes to the order of a few thousand possible utterances. In the past, this problem with using large grammars for applications such as directory automation services was sometimes addressed through the use of specialized hardware and software solutions, which included a telephony interface, resource manager, specialized ASR and TTS engine, customized backend data connectivity, and proprietary dialog creation environments integrated together in one package. The specialized ASR in these packages is sometimes capable of resolving grammars with millions of allowable utterances. However, this specialized hardware and software solution has many drawbacks, for example it does not take advantage of the centralization of data and standardization of data access protocols. Furthermore, these specialized systems often create a requirement that the call flow elements of a large-scale grammar application must be designed as part of the proprietary dialog creation environment, which effectively makes these applications non-portable. Furthermore, utilization of these specialized systems often locks users into the particular TTS engines and telephony interfaces provided as part of the specialized system, further reducing the ability to switch implementations of the underlying large-scale search technology.","Enabling large-scale grammar resolution through an application server resolves many of these drawbacks. Specifically, enabling large-scale grammar resolution in the application server can allow the information and data resources that will make up the large scale grammar to remain in a centralized location. Application servers make use of a variety of industry standard data connectivity methods and protocols. Taking advantage of this data centralization allows for reduced duplication of data and memory state. Additionally, by consolidating large-scale grammar resolution through an application server, administration of the large-scale search technology can be simplified.","Large-scale grammar resolution through an application server can further allow application developers to write their applications in any language supported by the application server, rather than in the proprietary format of a Dialog Creation Environment. Application developers can therefore make use of standard programming conventions, execution models, and APIs (Application Programming Interfaces) when writing their applications.","In one embodiment, a method for speech recognition resolution on an application server in a communication network is provided which includes receiving an utterance from an end-user or an application in response to a prompt by an application, such as a VoiceXML application, and capturing the utterance and dispatching it via the application server to a speech recognition engine, for example, a large-scale grammar search technology. The method further includes performing item-matching via a search algorithm, returning items matching the utterance to the application server, and returning relevant utterance matches to the application for communication to the user.","While the present invention is susceptible of embodiments in various forms, there is shown in the drawings and will hereinafter be described some exemplary and non-limiting embodiments, with the understanding that the present disclosure is to be considered an exemplification of the invention and is not intended to limit the invention to the specific embodiments illustrated.","In this application, the use of the disjunctive is intended to include the conjunctive. Thee use of definite or indefinite articles is not intended to indicate cardinality. In particular, a reference to \u201cthe\u201d object or \u201ca\u201d object is intended to denote also one of a possible plurality of such objects.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1","b":["100","112","100","106","106","102","104"]},"In a specific embodiment, the communication network  allows an end user to make a voice channel connection to the data network  for audio communication over a voice based telephony communication system such as a telephony switch\/control system , examples of which include the following systems: a public telephone switch , a VoIP (Voice over Internet Protocol) media gateway , a Private Branch Exchange (PBX) system , etc. For example, the public switch  may be any public carrier and may also include other communication networks; it may include a wireless telecommunication network that provides connectivity to the public switched telephone network (PSTN), control functions, and switching functions for wireless users, as well as connectivity to Voice Gateways.","The exemplary communication network  shown comprises a Voice Gateway , which is coupled to the telephony switch\/control system , for example the public switch . The telephony switch\/control system  couples the audio communication from the Voice Gateway  to the suitable (voice receiver) end user device . An application server , which may be any suitable server such as Oracle9iAS, is coupled to the Voice Gateway  and to a large-scale search engine , as shown. The application server  may, for example, run a Web site, or Internet application, and in one embodiment allows the Website or the application to be accessible from any browser or mobile device.","The application server  may be coupled to a database  as shown. This database  may, in one embodiment, host the dataset to be treated as a large-scale grammar and may be synchronized as needed by the application server . The database  may be coupled to the large-scale search engine  to provide the data sets required for initializing the grammar in item matching searches.","Referring to , the Voice Gateway  provides an audio communication bridge between the telephony\/switch control system , and the application server  as shown using any standard format. As indicated earlier, a Voice Gateway  can support multiple technologies including, but not limited to Automated Speech Recognition (ASR), Text-To-Speech (TTS) technologies, browser functionalities (e.g. for connecting to the Internet using standard TCP\/IP [Transmission Control Protocol over Internet Protocol] protocols to interpret voice data in formats such as Voice XML, SALT, XHTML+V, etc. . . ), media playback and recording capabilities and telephony technologies to connect the system to the telephony network. Examples of other protocols and languages that may be used in various embodiments include, but are not limited to: WAP (Wireless Application Protocol), HTML (Hyper Text Markup Language), HDML\/WML, MXML, XHTHL, etc.","Referring to the embodiment of , the application server  interacts with both the Voice Gateways  and the large-scale search providers , for example, third party search providers. This interaction can involve, for example, user management, session management, and Voice XML (VXML) delivery to the Voice Gateway  end of the communication path. This interaction may further involve large-scale search server configuration, search space administration, and third party large-scale search technology administration at the third party provider  end of the communication path. The third party large-scale search providers  may be designed to provide state-of-the-art voice search algorithms, as well as multiple dictionaries and search spaces. In some embodiments the third party large-scale search provider may be integrated with the application server and\/or may be provided by the provider of other technology in the system.","The methods disclosed herein may be performed by the application server  or some other processor using instructions that may reside on a computer-readable medium. The computer-readable medium may be any suitable computer readable storage medium such as, but not limited to random access memory, read-only memory, flash memory, CDROM, DVD, solid-state memory, magnetic memory, optical memory, and the like.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 2","FIG. 2","FIG. 1"],"b":["200","210","102","210","104","202","202","212","212","213","202","202","204","206"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 3","FIG. 3"],"b":["300","312"]},"In the specific system configuration illustrated in , a web-based administration tool  that may be accessed, for example, from a personal computer is coupled to the application server . As illustrated, in one alternative, the application server may include the capability to deliver applications to wireless devices (wireless option). In turn, the application server  is coupled to a database  that contains the dataset to be treated as a large-scale grammar. The application server  is also coupled to a large-scale grammar search provider technology , for example, via the TCP\/IP communication protocol. This large-scale grammar search provider  may in one embodiment utilize voice search algorithms that return matches corresponding to an end user utterance by utilizing multiple dictionaries and search spaces. These matches are typically returned to the application server  as an ordered list of elements. The application server  keeps track of the different available search provider technologies, creates and manages search spaces, and is in effect the administrator of the large-scale grammar search provider .","The search spaces may typically be defined by a number of protocols such as the LDAP (Lightweight Directory Access Protocol, used for accessing online directory services), by relational DB (Data Base) information\/retrieval tools such as the database Connect String and the SQL (Structured Query Language) query, by Flat File access, and by other known data store protocols including but not limited to Object-Oriented DB's, hierarchical DB's, etc. The term \u201csearch space\u201d is used to refer to any generalized dataset, which may include but is not limited to the following examples: a table in a database, a set of LDAP entries, or a delimited flat file, which has been initialized and primed in a large-scale voice search engine. The application server , as shown in the embodiment of , verifies that each large-scale grammar search provider  is primed and initialized to resolve each grammar defined in the search spaces of the administration tool . This system configuration permits applications that use large-scale grammars to be developed and used in the same manner as any other application on the application server .","Whenever a new third-party large-scale grammar search technology provider is introduced to the system administration tool , it may be subsequently registered with the application server  (via its large-scale search server). Further, when the system administration tool  is used to initialize a new search space (e.g. consisting of a dataset and its related voice-searchable fields), the large-scale search server component of the application server  notifies the third-party large-scale grammar technology provider  that there is a new search space that needs to be initialized. Subsequently, the third-party large-scale search technology provider  performs the necessary priming and initialization steps to configure the new search space and maintain it as an available dictionary or grammar set. An application developer can then write and deploy an application through the application server  and utilize the new third-party large-scale search technology.","The inputs to a large-scale voice search system can in some embodiments be a dataset and a user utterance. The output of the system may be a weighted list of entries from the dataset that phonetically match the user utterance. Due to the technical requirements of initialization and priming, datasets preferably are provided and initialized on the third party large-scale search system prior to runtime. Hence, the large-scale voice search server component of the application server  then addresses two technical issues. The first issue concerns the establishing, specifying and maintaining a set of search spaces. The second issue relates to the access of a particular large-scale search provider's technology  and the querying of a particular search space with a user utterance and navigation through the weighted result set.","In one example, the wireless option of the application sever  utilizes wireless capabilities to provide a web-based administration tool through which search spaces are defined and maintained. This portal is referred to as the \u201clarge-scale voice search server\u201d. In addition, search interfaces and drivers can be used to facilitate the communication between the search server and multiple search providers . For example, a single, generalized search API could be utilized by application developers for performing searches, and by the administration tool to handle the details of driver and search space initialization. The use of a generic search driver would abstract the differences between the various search provider drivers, whereas specific search provider drivers would format and transmit messages in a manner specific to the corresponding large-scale search technology.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 4","b":["400","412","102","410","411","412","411","410","412","410","412","410"]},"In one embodiment, the Voice Gateway  may capture a user utterance in response to the application prompts. The user utterance may originate from any suitable source, for example, a live end user, an application, etc. If the utterance to be interpreted is part of a small grammar, then the corresponding grammar may be stored in a grammar file to be accessed and cached at the same time as the VoiceXML document is served to the Voice Gateway . In this case, the processing of the utterance against the application grammar can occur at application runtime using the standard ASR engine on the Voice Gateway . If the utterance to be interpreted is part of a large-scale voice search, then in one embodiment the utterance is recorded by the Voice Gateway  and sent to the application server . The recorded utterances are dispatched to the third-party large-scale technology search provider  by the application server's large-scale search server, along with a specification of the search space to be used and the contents of the recording (data fields to be matched).","Once the third-party large-scale search technology search provider  receives the utterance and associated information from the application server , it then may perform a search algorithm over the corresponding maintained dictionary (or grammar set), and return items matching the utterance from the specified search space, for example, in the form of an ordered list of elements (also called an n-best list) and corresponding confidence metrics. Further, the application server  may use the list as an index into the selected search space to return the specific data relevant to the application, and may then serve up a new markup page to the Voice Gateway . The large-scale search application, as shown in block , may make use of a number of components. Specifically, in one embodiment, the application may have an XML UI\/API (User Interface\/Application Programming Interface) layer used to present the user interface of the application. The XML layer may make application calls to the Public Java API which represents the generalized large-scale search API. The generalized public Java API may in turn invoke a public Driver API which abstracts away the specific implementation details of any one large-scale search provider technology.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 5","FIG. 6","FIG. 5"],"b":["600","106","112","106","110","112","114"]},"The flow chart of  first depicts, as shown at step , a preliminary phase that reflects an example of the setup and the coordination utilized for the initial registration of a new third-party large-scale search technology  with an application server . Step  illustrates the initialization of a search space and the notification of the new search space to third-party large-scale search technology, and the initialization of the new search space and the development of corresponding applications is illustrated, at steps  and  respectively.","Once this preliminary phase is completed, the large-scale grammar search system of the network  is ready to provide large-scale grammar resolution on the application server . The Voice Gateway  requests an application from the application server , at step , based for example on a dialed telephone number or a user input request. In turn, the application server  serves up the requested application to the Voice Gateway  at step . The end-user utterance is captured by the Voice Gateway  and forwarded to the application server  at step . The user utterance may also be from other sources such as an application. The utterance is then dispatched to the third party large-scale technology provider  along with the specification of the search space, at step . Once the utterance with its associated information are received by the third party search provider , a search algorithm is performed by the third-party large scale search technology over the relevant search space to return a corresponding n-best list of matches, at step . The application server , then, uses the returned items as an index into the specified search-space to return the data relevant to the application, at step . Note that steps  through  may be repeated as necessary according to the application.",{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIGS. 7 through 16","b":["700","800","1600"]},"Referring to , an embodiment of a directory dialog  starts at step . The progress of an end-user call through the directory dialog  in the illustrated embodiment relies on a multitude of outputs, shown as gray boxes, which are statements produced by the related application, and on the user inputs, which are the user responses shown as black boxes to those application statements. As shown, the directory dialog  would prompt the user for specific responses based on the user's previous inputs. For example, once the application seeks a response to a \u201cfull name\u201d or a \u201ccancel\u201d prompt, at step , it may be directed to a \u201cnew search\u201d sub-dialog branch of the directory dialog for a \u201ccancel\u201d user's input as in step , or to the \u201cmain menu\u201d if the user failed to provide any response, as in step . Whereas if the user did spell the desired name, the directory dialog would ask the user to spell the person's name one letter at a time or to enter it on the touch-tone keypad, as in step . A \u201chelp\u201d input would prompt the user to say the person's name as in step . If the user utterance provides a full \u201cname\u201d input, the application would analyze it for a confidence level, at step . A high confidence level would lead to a search results directory branch for item matching, as in step . A low confidence level would lead to a check of recorded samples, at step . The check of recorded samples may to lead a \u201crepeat name\u201d branch as in step , or to \u201cspell last name\u201d branch as in step ","Referring to the exemplary embodiment of a sub-dialog branch  illustrated in , once a \u201cSpell last name\u201d sub-dialog branch is initiated at step , the application seeks a response to a \u201cspell the person's last name\u201d prompt, at step , it may be directed to a \u201csearch results\u201d new search sub-dialog branch for a \u201cspelled name\u201d user's input as in step , or depending on how many times the user failed to provide a response to the \u201cspell the person's last name\u201d prompt, it may be directed to the \u201cget first letter\u201d sub-dialog branch, as in step ","Referring to , once a \u201cGet first letter\u201d dialog branch  is initiated, as in step , the application in the embodiment of  seeks a response from the user to a prompt to spell the person's name one letter at a time or to enter it on the touch-tone keypad, at step . If the user fails to provide a response, after an allowable number of similar repeat prompts, or if the utterance is not matched by the application, at steps  and , the user is directed to the \u201cmain menu\u201d dialog branch, at step . If the user successfully spells\/enters the requested letter, or requests a delete of the last utterance, or seeks help, the application would return to the beginning of the current dialog branch by initiating a \u201cget next letter\u201d as in step \u2032. If the spelling of the person's name were completed, the application would initiate the \u201csearch results\u201d branch as in step , to return matching items. If the user spells\/enters a \u201chelp\u201d, a \u201cletter\u201d or a \u201cdelete\u201d utterance, the application would proceed to a \u201cGet next letter\u201d branch of the dialog, as in step \u2032. Otherwise, subsequently to a \u201cnew search\u201d user utterance, the application would proceed to a \u201cNew Search\u201d branch as in step ","Referring to the example embodiment of , once a \u201csearch results\u201d dialog branch  is initiated, at step , a match count test is performed at step . A count of zero matches would lead to a check as to whether the input was entered by either spelling the name or pressing touchtone (DTMF) keys, at step . In the affirmative, a \u201cchoose search type\u201d sub-dialog branch would be initiated, at step , otherwise, the user would be asked to retry spelling the name one letter at a time. A favorable count of one would make the application initiate a \u201cread details or call\u201d sub-dialog branch, as in step . Whereas if the match count is equal or greater than 2, a test for identical names is pursued at step . The application would seek a response to prompts that cater to  separate situations, i.e. results with either unique or identical names, at step . Subsequently and after a predetermined number of attempts, at steps  and , a failure to respond by the user or a failure to match the user's input would lead the application to initiate a \u201cmain menu\u201d sub-dialog branch, as in step . Otherwise, a user response requesting to \u201ccancel\u201d or to initiate a \u201cnew search\u201d would initiate a \u201cnew search\u201d sub-dialog branch, as in step . A request for \u201chelp\u201d would initiate a re-prompt of the current sub-dialog branch as in step \u2032. A successful name spelling would initiate a \u201cread details or call\u201d sub-dialog branch to retrieve relevant contact information for the matched person's name, as in step ","Referring to , once a \u201cchoose search type\u201d sub-dialog branch  is initiated, at step , a user, in the illustrated embodiment of , could choose to either spell the person's name one letter at a time (voice input) or to enter it on the touch-tone keypad (DTMF input), at step . Subsequently, the application would seek a response to a request to spell again or to start over with a new search, at step . If the user fails to provide a response, after an allowable number of similar prompts, or if the utterance is not understood by the application, the user is directed to the \u201cmain menu\u201d sub-dialog branch as in step . If the user requests a \u201ccancel\u201d or a \u201cnew search\u201d, the application would proceed to a \u201cnew search\u201d sub-dialog branch as in step . If the user seeks \u201chelp\u201d, then the application would initiate a \u201csearch type\u201d re-prompt as in step \u2032. Otherwise, a \u201cspell again\u201d input by the user, would make the application initiate a \u201cget first letter\u201d sub-dialog branch, as in step ","Referring to the embodiment of , once a \u201cread details or call\u201d sub-dialog branch  is initiated at step a failed telephone number availability check, at step , would make the application initiate a \u201cread details\u201d sub-dialog branch, at step . Subsequently to a successful telephone number availability check, the application would seek a response to a \u201csay details\u201d or \u201chold and I'll call the person\u201d or \u201csay cancel\u201d prompt, at step . If no response is detected, a sub-dialog branch to call the person is initiated at step . If the application is unable to match the user utterance, it would return the user to the main menu, at step . A \u201ccancel\u201d utterance input by the user would lead to the \u201csearch results\u201d or the \u201cnew search\u201d sub-dialog branches, at step and respectively. A \u201cget manager's details\u201d utterance would lead the user to the corresponding branch at step . Similarly, other corresponding utterances would lead the user to the \u201cplace call\u201d, or the \u201csend email\u201d, or the \u201cdetails\u201d, or to a re-prompt of the \u201cget details or call\u201d branch, at steps or or or \u2032 respectively.","Referring to the embodiment of , once a \u201cread details\u201d sub-dialog branch  is initiated at step , the application would provide details such as first name, last name, title, division, email address, manager's name, etc. Subsequently a check whether any phone numbers, email addresses, or manager's name were present is performed at step . In the negative, the application would initiate a \u201cnew search\u201d sub-dialog branch, at step . In the affirmative, the application would seek a response for either a \u201ccall work\u201d, \u201csend email\u201d, \u201cget manager's email\u201d, \u201crepeat details\u201d, or \u201cnew search\u201d prompt, at step . If no response is detected after 4 attempt prompts, at step , a sub-dialog branch to return to the main menu is initiated at step . If the application is unable to match the user utterance after at 3 attempt prompts, it would return the user to the main menu, at step . Otherwise, a \u201ccancel\u201d utterance input by the user would lead to the \u201csearch results\u201d or the \u201cnew search\u201d sub-dialog branches, at step and respectively. Similarly, other utterances would lead the user to their corresponding \u201cget manager's details\u201d, the \u201cplace call\u201d, the \u201csend email\u201d, the \u201cread details\u201d, the \u201cnew search\u201d, or to a re-prompt of the \u201cdetails\u201d branch, at steps , , , , \u2032, and respectively.","Referring to , once a \u201cget manager's details\u201d sub-dialog branch  is initiated in the illustrated embodiment at step , a manager presence information check is performed, at step . In the negative, the application would initiate a \u201cread details\u201d sub-dialog branch at step . Otherwise, a selection change to the manager, at step , would result in the application initiating also a \u201cread details\u201d sub-dialog branch at step , this time providing the details for the manager's directory entry.","Referring to the exemplary embodiment of , once a \u201cplace call\u201d sub-dialog branch  is initiated at step , a telephone number availability check is performed, at step . In the negative, the application would initiate a \u201cread details\u201d sub-dialog branch at step . Otherwise, a statement of \u201ccalling\u201d is announced, and the application would make the call, at step .","Referring to the embodiment of , once a \u201csend email\u201d sub-dialog branch  is initiated at step , a email address availability check is performed at step . In the negative, the application would initiate a \u201cread details\u201d sub-dialog branch at step . Otherwise, the application would create email to be sent to the selected directory entry, at step .",{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIGS. 17A and 17B","FIG. 17A","FIG. 17B"],"b":["1700","1702"]},"In another embodiment, the large-scale search technology may be integrated in the application server. At a first level, this integration at the application server may provide access to large-scale grammar searching of any general dataset. The key components of this application server solution may include an API that initiates searches of a search space at runtime, and that may provide the functionality of a single-turn query returning an n-best list of matches, as well as the administrative functionality to manage (prime and update) different search spaces. At a second level of integration, a generic search module may encapsulate all business logic associated with the activities of invoking the large-scale search driver. Front-end developers writing their applications on the wireless platform may utilize this search module to perform large-scale voice searches.","Specific embodiments of methods and apparatus for providing large-scale grammar resolution on an application server have been described for the purpose of illustrating the manner in which the invention is made and used. It should be understood that the implementation of other variations and modifications of the invention and its various aspects will be apparent to one skilled in the art, and that the invention is not limited by the specific embodiments described. Therefore, it is contemplated to cover any and all modifications, variations, or equivalents that fall within the true spirit and scope of the basic underlying principles disclosed and claimed herein."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF DRAWINGS","p":["The invention, together with the advantages thereof, may be understood by reference to the following description in conjunction with the accompanying figures, which illustrate some embodiments of the invention.",{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 5","FIG. 6"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIGS. 7 through 16"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIGS. 17A and 17B"}]},"DETDESC":[{},{}]}
