---
title: User interface construction with mockup images
abstract: A mockup image can be received at a user interface designer module and a representation of the mockup image can be overlaid with a representation of a user interface that is under construction. One or more visual features of the user interface and one or more visual features of the mockup image can be matched. Also, one or more guides can be matched to one or more features in a mockup image, and one or more features of a user interface that is under construction can be automatically matched to the one or more guides.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08650503&OS=08650503&RS=08650503
owner: Microsoft Corporation
number: 08650503
owner_city: Redmond
owner_country: US
publication_date: 20090708
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Most computer user interface display concepts are created by artists using image drawing or design applications, such as Microsoft Visio\u00ae or Adobe Photoshop\u00ae. The resulting concepts are typically passed on to software developers as digital mockup images, such as JPEG files, bitmap files, etc. The developers typically use the concepts to create actual user interfaces using user interface designers, such as Microsoft's Visual Studio\u00ae. As used herein, a user interface is code that can produce a visual display of a type that can allow interaction with a user, such as a Web page, a dialog, etc. User interfaces typically include features, such as links, buttons, etc., that facilitate such interaction. Developers typically try to produce an actual user interface that is as close to the concept as possible by comparing the user interface designer's representation of the user interface to a representation of the mockup image in the form of a paper printout or an on-screen display that is separate from the user interface representation.","Whatever the advantages of previous user interface construction tools and techniques, they have neither recognized the user interface construction tools and techniques described and claimed herein, nor the advantages produced by such tools and techniques. In embodiments of the tools and techniques described herein a mockup image representation can be overlaid with a user interface representation. Overlaying the representations includes representing the representations in a common space (e.g., a common coordinate system, a common computer display area, etc.). The resulting overlay can allow visual features of the user interface to be modified to match visual features of the mockup image. The overlay may include a mockup image representation being overlaid over a user interface representation or the user interface representation being overlaid over the mockup image representation.","In one embodiment, the tools and techniques can include receiving a mockup image at a user interface designer module and overlaying a representation of the mockup image with a representation of a user interface that is under construction. Overlaying can include overlaying the mockup image representation over the user interface representation or overlaying the user interface representation over the mockup image representation. One or more visual features of the user interface and one or more visual features of the mockup image can be matched.","In another embodiment of the tools and techniques, a representation of a user interface that is under construction can be displayed in a display area. A mockup image representation can also be displayed in the display area. The mockup image representation and the user interface representation can be blended so that the mockup image representation and the user interface representation are visible in the display area. User input that is directed at a feature of the user interface representation can be received, and a feature of the user interface that corresponds to the feature of the user interface representation can be modified in response to receiving the user input.","In yet another embodiment of the tools and techniques, guides can be matched to features in a mockup image. Features of a user interface that is under construction can be automatically matched to the guides.","This Summary is provided to introduce a selection of concepts in a simplified form. The concepts are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter. Similarly, the invention is not limited to implementations that address the particular techniques, tools, environments, disadvantages, or advantages discussed in the Background, the Detailed Description, or the attached drawings.","Described embodiments are directed to techniques and tools for improved construction of user interfaces from mockup images. Such improvements may result from the use of various techniques and tools separately or in combination.","Such techniques and tools may include overlaying a mockup image representation and a user interface representation of a user interface under construction. As noted above, overlaying the representations includes representing the representations in a common space (e.g., a common coordinate system, a common computer display area, etc.). For example, the image may be automatically analyzed, and a user interface may be automatically generated, with one or more features of the user interface being automatically matched to the mockup image. For example, this matching can be done by comparing positional coordinates of user interface and mockup image features in a common coordinate system where the user interface representation and the mockup image representation have been overlaid. Overlaying may or may not include displaying the overlaid representations on a computer display.","As another example, overlaying can include displaying an overlay that includes a representation of a user interface and a representation of a mockup image being blended. With the user interface representation and the mockup image being blended, a user can easily see whether features of the user interface representation are out of alignment with the mockup image. Accordingly, the user can provide user input to add, modify, and\/or delete features of the user interface to match the user interface features (as shown by the user interface representation) with the mockup image. Moreover, the techniques and tools may include snapping the user interface features to guides corresponding to features in the mockup image. For example, this snapping can be done in response to user input that moves the corresponding features toward the guides.","In existing user interface creation techniques, user interface representations are compared to either on-screen images that are separate from the user interface representations, or paper printouts. With these existing techniques, it can be a difficult and time consuming task to make an application with a complex user interface look alike across multiple user interface elements and to follow an artistic concept or template, especially if fine accuracy, such as one-pixel accuracy is desired. The tools and techniques described herein can make the creation and fine tuning of user interfaces (dialogs, HTML web pages, etc.) easier and more efficient.","Accordingly, one or more substantial benefits can be realized from the tools and techniques described herein. However, the subject matter defined in the appended claims is not necessarily limited to the benefits described herein. A particular implementation of the invention may provide all, some, or none of the benefits described herein. Although operations for the various techniques are described herein in a particular, sequential order for the sake of presentation, it should be understood that this manner of description encompasses rearrangements in the order of operations, unless a particular ordering is required. For example, operations described sequentially may in some cases be rearranged or performed concurrently. Techniques described herein with reference to flowcharts may be used with one or more of the systems described herein and\/or with one or more other systems. Moreover, for the sake of simplicity, flowcharts may not show the various ways in which particular techniques can be used in conjunction with other techniques.","I. Exemplary Computing Environment",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1","b":"100"},"The computing environment () is not intended to suggest any limitation as to scope of use or functionality of the invention, as the present invention may be implemented in diverse general-purpose or special-purpose computing environments.","With reference to , the computing environment () includes at least one processing unit () and memory (). In , this most basic configuration () is included within a dashed line. The processing unit () executes computer-executable instructions and may be a real or a virtual processor. In a multi-processing system, multiple processing units execute computer-executable instructions to increase processing power. The memory () may be volatile memory (e.g., registers, cache, RAM), non-volatile memory (e.g., ROM, EEPROM, flash memory), or some combination of the two. The memory () stores software () implementing user interface construction with mockup images.","Although the various blocks of  are shown with lines for the sake of clarity, in reality, delineating various components is not so clear and, metaphorically, the lines of  and the other figures discussed below would more accurately be grey and fuzzy. For example, one may consider a presentation component such as a display device to be an I\/O component. Also, processors have memory. The inventors hereof recognize that such is the nature of the art and reiterate that the diagram of  is merely illustrative of an exemplary computing device that can be used in connection with one or more embodiments of the present invention. Distinction is not made between such categories as \u201cworkstation,\u201d \u201cserver,\u201d \u201claptop,\u201d \u201chandheld device,\u201d etc., as all are contemplated within the scope of  and reference to \u201ccomputer,\u201d \u201ccomputing environment,\u201d or \u201ccomputing device.\u201d","A computing environment () may have additional features. In , the computing environment () includes storage (), one or more input devices (), one or more output devices (), and one or more communication connections (). An interconnection mechanism (not shown) such as a bus, controller, or network interconnects the components of the computing environment (). Typically, operating system software (not shown) provides an operating environment for other software executing in the computing environment (), and coordinates activities of the components of the computing environment ().","The storage () may be removable or non-removable, and may include magnetic disks, magnetic tapes or cassettes, CD-ROMs, CD-RWs, DVDs, or any other medium which can be used to store information and which can be accessed within the computing environment (). The storage () stores instructions for the software ().","The input device(s) () may be a touch input device such as a keyboard, mouse, pen, or trackball; a voice input device; a scanning device; a network adapter; a CD\/DVD reader; or another device that provides input to the computing environment (). The output device(s) () may be a display, printer, speaker, CD\/DVD-writer, network adapter, or another device that provides output from the computing environment ().","The communication connection(s) () enable communication over a communication medium to another computing entity. Thus, the computing environment () may operate in a networked environment using logical connections to one or more remote computing devices, such as a personal computer, a server, a router, a network PC, a peer device or another common network node. The communication medium conveys information such as data or computer-executable instructions or requests in a modulated data signal. A modulated data signal is a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media include wired or wireless techniques implemented with an electrical, optical, RF, infrared, acoustic, or other carrier.","The tools and techniques can be described in the general context of computer-readable storage media. Computer-readable storage media are any available storage media that can be accessed within a computing environment. By way of example, and not limitation, with the computing environment (), computer-readable storage media include memory (), storage (), and combinations of the above.","The tools and techniques can be described in the general context of computer-executable instructions, such as those included in program modules, being executed in a computing environment on a target real or virtual processor. Generally, program modules include routines, programs, libraries, objects, classes, components, data structures, etc. that perform particular tasks or implement particular abstract data types. The functionality of the program modules may be combined or split between program modules as desired in various embodiments. Computer-executable instructions for program modules may be executed within a local or distributed computing environment. In a distributed computing environment, program modules may be located in both local and remote computer storage media.","For the sake of presentation, the detailed description uses terms like \u201cdetermine,\u201d \u201cchoose,\u201d \u201cmodify,\u201d and \u201coperate\u201d to describe computer operations in a computing environment. These and other similar terms are high-level abstractions for operations performed by a computer, and should not be confused with acts performed by a human being, unless performance of an act by a human being (such as a \u201cuser\u201d) is explicitly noted. The actual computer operations corresponding to these terms vary depending on the implementation.","II. User Interface and Mockup Image Overlay System and Environment",{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 2","b":["200","200","210","210","210","220","222","220"]},"The user interface designer () may analyze the mockup image () and create guides () that correspond to the visual features () of the mockup image (). To facilitate the creation of the guides (), the image () may be created with particular colors that signal the user interface designer () that the colors correspond to particular features () (e.g., buttons may be outlined in a particular color of red). Alternatively, the colors of the mockup image () may serve as the guides () without the user interface designer () creating separate guides (). The user interface designer () can generate and modify a user interface () that is under construction. The user interface () is the code that will be used to generate the actual display of the user interface, such as the dialog, the web page, etc. For example, the user interface () may include the actual hypertext markup language code for a hypertext markup language page, or preliminary code that will be translated or compiled into the actual hypertext markup language code. The user interface () can include a variety of features (), such as active button features, passive or linking text features, passive or linking graphical features, or combinations of these.","The user interface designer () can overlay a representation of the mockup image () and a representation of the user interface (), and can match the locations (which can include sizes and shapes) of the user interface features () to the locations of the mockup image features (). For example, the user interface designer may automatically generate the user interface () and match the locations of one or more of the features () of the user interface () to one or more of the features () of the mockup image () using the guides (). Even if the user interface designer () does not automatically generate the user interface (), the user interface designer may still automatically match the locations of one or more of the user interface features () and one or more of the mockup image features (). As an example, the locations may be matched by mapping the guides () or some other representation of one or more features of the mockup image () and a representation of one or more features of the user interface () to a common space, such as a common coordinate system. With the representations mapped to the common space, the location coordinates corresponding to the features () of the user interface () can be automatically modified to match the location coordinates corresponding to the features () of the mockup image ().","As an alternative to, or in addition to, such automatic matching, the user interface designer can assist a user in matching the locations of the user interface features () and the mockup image features (). For example, the user interface designer () can also provide a designer interface (), which can be displayed on a computer display. The designer interface can include a user interface representation (), which can include displayed features that visually represent the visual features () of the user interface () under construction. Moreover, the designer can include a mockup image representation (), which can include displayed features that visually represent the visual features () of the mockup image (). The user interface representation () and the mockup image representation () can be overlaid in a display area (), such as by blending the displays of the user interface representation () and the mockup image representation (). For example, the mockup image representation () can be displayed as a semi-transparent image over the user interface representation (). Alternatively, the user interface representation () can be displayed as a semi-transparent image over the mockup image representation ().","The semi-transparent overlay of the user interface representation () and the mockup image representation () can be implemented in various ways. For example, the semi-transparent image can be painted as an alpha-blended image directly inside the opaque dialog's device context (e.g., the mockup image representation () can be painted as a semi-transparent image in the device context of a dialog of the user interface representation ()). In this example, the blending can occur at the end of the dialog's paint event, after the frame, background and controls are already painted. Each time there is a paint event happening in any of the opaque dialog's elements (frame, background, children controls, etc.) the semi-transparent image can be repainted\/re-blended inside the opaque dialog's device context. The semi-transparent image can be painted and blended by converting the image that is to be displayed semi-transparently to a bitmap file if it is not already a bitmap file, and calling the Windows\u00ae GDI application programming interface \u201cAlphaBlend\u201d, which can have the following syntax:",{"@attributes":{"id":"p-0038","num":"0037"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u2003BOOL AlphaBlend("},{"entry":"\u2003\u2003_in HDC hdcDest, \/\/ Handle to the destination device context."},{"entry":"\u2003\u2003_in int xoriginDest, \/\/ Specifies the x-coordinate, in logical units,"},{"entry":"of the upper-left corner of the destination rectangle."},{"entry":"\u2003\u2003_in int yoriginDest, \/\/ Specifies the y-coordinate, in logical units,"},{"entry":"of the upper-left corner of the destination rectangle."},{"entry":"\u2003\u2003_in int wDest, \/\/ Specifies the width, in logical units, of the"},{"entry":"destination rectangle."},{"entry":"\u2003\u2003_in int hDest, \/\/ Specifies the height, in logical units, of the"},{"entry":"destination rectangle."},{"entry":"\u2003\u2003_in HDC hdcSrc, \/\/ Handle to the source device context."},{"entry":"\u2003\u2003_in int xoriginSrc, \/\/ Specifies the x-coordinate, in logical units,"},{"entry":"of the upper-left corner of the source rectangle."},{"entry":"\u2003\u2003_in int yoriginSrc, \/\/ Specifies the y-coordinate, in logical units,"},{"entry":"of the upper-left corner of the source rectangle."},{"entry":"\u2003\u2003_in int wSrc, \/\/ Specifies the width, in logical units, of the source"},{"entry":"rectangle."},{"entry":"\u2003\u2003_in int hSrc, \/\/ Specifies the height, in logical units, of the source"},{"entry":"rectangle."},{"entry":"\u2003\u2003_in BLENDFUNCTION ftn \/\/ Specifies the alpha-blending function"},{"entry":"for source and destination bitmaps, a global alpha value to be applied to"},{"entry":"the entire source bitmap, and format information for the source bitmap."},{"entry":"\u2003);"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"As another example of implementing a semi-transparent overlay, the semi-transparent image can be displayed in a shadow dialog, which can be kept on top of the dialog displaying the opaque image. For example, the shadow dialog can be semi-transparent and it can include a representation of the semi-transparent image (such as the mockup image). The shadow dialog can be made aware of the position and paint state of the opaque dialog so that the shadow dialog can be kept on top of the opaque dialog. The semitransparent dialog can be made semitransparent (and can be made to allow events such as mouse clicks to pass through the semitransparent dialog to the opaque dialog below it) by calling the Microsoft MFC library reference \u201cCWnd::ModifyStyleEx,\u201d as in the following example:",{"@attributes":{"id":"p-0040","num":"0039"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u2003\u2003\/\/ This example would make the dialog box transparent by changing"},{"entry":"the dialog window's extended styles."},{"entry":"\u2003\u2003int CMyDialog::OnCreate(LPCREATESTRUCT lpCreateStruct)"},{"entry":"\u2003{"},{"entry":"\u2003\u2003if (CDialog::OnCreate(lpCreateStruct) == \u22121)"},{"entry":"\u2003\u2003\u2003return \u22121;"},{"entry":"\u2003\u2003ModifyStyleEx(0, WS_EX_TRANSPARENT);"},{"entry":"\u2003\u2003return 0;"},{"entry":"\u2003}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"User input () can be directed to the designer interface (). For example, the user input () can be directed to features of the user interface representation () in the display area (). For example, the user input () can include input from a keyboard, mouse, touch pad, touch screen, track ball, and\/or some other input device that is intended to move a feature () of the user interface () toward a corresponding feature () of the mockup image (), such as by dragging and dropping a corresponding feature of the user interface representation () toward a corresponding feature of the mockup image representation (). The designer interface () may implement features to assist in accurate matching of locations of user interface features () and mockup image features (), such as snap and\/or glue operations that are often used in graphical programs such as Microsoft's Visio\u00ae drawing and diagramming software. For example, as a user provides input to drag a user interface feature () toward a corresponding mockup image feature (), the user interface designer () can automatically snap the user interface feature () to match the location (which can include the size and\/or shape) of the mockup image feature ().","Referring now to , some examples of displayed overlays of user interface representations and mockup image representations will be discussed, where the represented user interfaces are dialogs. In other examples, the user interfaces may be other types of user interfaces, such as markup language pages, overall visual environments for applications, etc. A user interface that is under construction can be formed as a default test dialog without initially being matched to a mockup image, and the dialog can be represented by a user interface representation (), which can be a display of the dialog on a computer display. The user interface representation () can include visual features, such as edges () of the dialog, static text (), buttons (), designs (), and interior lines (). The user interface representation () can also include other types of visual features.","A mockup image can be used to represent a visual concept to which the test dialog is to be matched to form a form a final dialog, such as a dialog for inclusion with a computer application being developed. A representation () of the mockup image can be displayed on a computer display, and can include visual features that are similar to those of the test dialog. For example, the mockup image representation () can include dialog edges (), static text (), buttons (), designs (), and interior lines (), among other features.","As is illustrated at the bottom of , the user interface representation () can be overlaid with the mockup image representation () to form an overlay (), which can be presented in a display area of a computer display with the representations (, ) being blended. For example, the mockup image representation () can be displayed as a semi-transparent image (as illustrated by dashed lines and non-bolded text in ) over the user interface representation (), which can be displayed as an opaque image. This can be done using standard image display blending techniques, such as by using the existing application programming interfaces discussed above, which are available to developers of applications for the Windows\u00ae operating system. This can allow a dialog developer to see where modifications can be made to features of the user interface representation () to match the locations (including size, etc.) of those features to the features of the mockup image representation (), and thereby modify the underlying user interface dialog to match the mockup image.","Referring to , a representation () of a user interface designer interface is illustrated. The designer interface representation () can include a user interface representation () and a mockup image representation () in an overlay (), as discussed above. In addition, the designer interface representation () can include other features to assist in constructing user interfaces, such as a properties dialog representation (), which can include a list () of properties of the designer interface that can be modified in response to user input. For example, the list () can include a mockup image list item (), where a path to a mockup image to be represented in the designer interface representation () can be specified. In addition, a mockup transparency list item () can specify a transparency value for the mockup image representation (). The list () can also include other items, such as a \u201cno active\u201d list item () and an \u201coverlapped window\u201d list item (). The \u201coverlapped window\u201d list item () can specify whether an overlay is implemented by painting a user interface representation and a mockup image representation inside a single user interface space (such as a single dialog), or the overlay is implemented by painting the representations in two interface spaces, such as a main dialog and a shadow dialog. The list () can include other items in addition to or instead of the list items illustrated in . For example, the list () can include a \u201cmove mockup to background\u201d list item along with a value of true or false, which can specify whether the mockup image representation is displayed over the user interface representation (in the foreground) or under the user interface representation (in the background). The properties dialog representation () can also include an explanation () of a highlighted list item. User input can modify the values of the list items (, , , ) in standard ways, such as by directing input at the target areas of the list items (, , , ) to modify the values of the list items (, , , ). For example, the input can include mouse clicks on the list items (, , , ), followed by selections from menus or dialogs, or entering values using a keyboard.","Moreover, features of the user interface representation () can be modified (created, moved, resized, deleted, etc.) to match the features of the mockup image representation (). This can be done in standard ways, such as by dragging and dropping buttons, lines, designs, etc., or entering text with keyboard entries or cut-and-paste techniques. The modifications can be assisted using automated or semi-automated techniques, such as snap-and-glue techniques, where features of the user interface representation () can snap to features of the mockup image representation (), such as by using guides to which the features can snap. Such modifications can result in modifications to the user interface that is represented by the user interface representation (), so that the user interface can match the mockup image that is represented by the mockup image representation ().","Referring now to , such modifications are illustrated. At the top of , a user interface representation () and a mockup image representation () are illustrated in an overlay (). As can be seen, the user interface representation () does not match the mockup image representation () at the top of . However, the locations of features of the user interface representation () can be modified to match the locations of features of the mockup image representation (), as illustrated by the overlay () at the bottom of . For example, the modifications can include deleting features (e.g., \u201cCOPYRIGHT\u00a9 2009\u201d text), adding or creating features (e.g., \u201cOUR WEBSITE\u201d and \u201cOUR EMAIL\u201d buttons), moving features (e.g., moving the edges of the user interface representation (), moving the \u201cOK\u201d button to match the \u201cCLOSE\u201d button), resizing features (e.g., resizing the \u201cOK\u201d button to match the size of the \u201cCLOSE\u201d button), and\/or modifying text and\/or designs (e.g., in the \u201cOK\u201d button, replacing \u201cOK\u201d with \u201cCLOSE\u201d).","III. Mockup Image and User Interface Overlay Techniques","Mockup image and user interface overlay techniques will now be discussed. These techniques may be done with the systems and environments discussed above, or with some other computing system and\/or environment.","Referring to , a mockup image and user interface overlay technique will be discussed. In the technique, a mockup image can be received () at a user interface designer module. A representation of the mockup image can be overlaid () with a representation of a user interface that is under construction in the user interface designer module. The user interface can be any of many different types of user interfaces, such as a dialog or a markup language page (e.g., a hypertext markup language page). Overlaying can include mapping representations of the mockup image and the user interface in a common space, such as a common coordinate system or a common computer display, so that locations of features of the representations can be compared in that common space. Overlaying () can include displaying a designer interface of the user interface designer module on a computer display. The designer interface can include the user interface representation displayed in a display area, as well as the mockup image representation displayed semi-transparently over the user interface representation. Overlaying can include blending the user interface representation and the mockup image representation on a computer display.","In addition, locations of one or more visual features of the user interface can be matched () to one or more visual features of the mockup image. Matching () can include receiving user input directed at the display area from a user input device (such as user input directed at one or more features of the user interface representation), as well as modifying the user interface and the user interface representation in response to the user input. If the mockup image representation is displayed over the user input representation, the user input can be passed through the mockup image representation to the user input representation. Matching () may include automatically matching one or more visual features of the user interface and one or more visual features of the mockup image in the common coordinate system, which may include snapping one or more features of the user interface to one or more features of the mockup image.","Referring now to , another mockup image and user interface overlay technique will be described. In the technique, a representation of a user interface that is under construction (such as a dialog, markup language page, etc.) can be displayed (), and a mockup image representation can also be displayed (). The mockup image representation and the user interface representation can both be displayed ( and ) in one display area, and the representations can be blended () so that both are visible in the display area. For example, blending () can include displaying the mockup image representation as a semitransparent image over the user interface representation. User input directed at a feature of the user interface representation can be received (), and in response, a feature of the user interface that corresponds to the feature of the user interface representation can be modified (). For example, the feature may be one or more edges of the user interface, and the feature may be modified by resizing the user interface. The user interface representation may also be modified in response to the user input. The user input may be passed through the mockup image representation to the user interface representation.","Referring now to , another user interface and mockup image overlay technique will be discussed. In the technique, one or more guides are matched () to one or more features in a mockup image. The technique can also include displaying () a designer interface of a user interface designer module on a computer display. The designer interface can include a user interface representation of the user interface that is under construction, as well as the mockup image representation. The mockup image representation and the user interface representation can be blended in the designer interface. The technique can also include receiving () user input directed at the user interface representation from a user input device. In response to the user input, one or more of the features of the user interface that is under construction can be moved () toward one or more of the guides. In addition, one or more of the user interface features can be automatically matched () to one or more of the guides, such as by snapping.","Referring to , yet another user interface representation and mockup image overlay technique will be described. In the technique, user input can be received (), and one or more guides can be matched () to one or more features of a mockup image. In addition, a user interface can be generated (), such as being generated automatically in response to the user input. In addition, user interface features of a user interface under construction can be matched () to the guides. The matching () can also be done automatically in response to the user input. In other words, the matching can be done without requiring additional user input that directs the matching.","Although the subject matter has been described in language specific to structural features and\/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
