---
title: Translating two-dimensional user input on three-dimensional scene
abstract: A computing system translates two-dimensional (2D) graphical input by a user who is selecting one or more 2D images in a three-dimensional (3D) scene of 3D models created by model 3D objects. The computing system comprises a viewport module, a retrieve module, set ray module and, a hit detection module. The viewport module defines 2D boundaries of the 3D scene and a view point location in 3D space for viewing the 3D scene. The retrieve module retrievies a selection point location in 2D space for the 2D graphical input. The set ray module sets a pick ray in 3D space based on the view point location and the selection point location. The hit detection module detects a hit by the pick ray on a 3D model in the 3D scene. In this computing system there is a method of processing a hierarchy of computer program visual objects for detecting a hit by 2D input on 2D and 3D images displayed by a computing system. The method begins by traversing branches of a first tree hierarchy of visual objects to leaf objects. Next the method detects whether the next unprocessed leaf object is a visual 2D object with 2D geometry or a model 3D object with 3D geometry. Lastly the method calls a 2D process to detect a hit on the 2D geometry of a visual object if a visual 2D object is detected and calls the 3D process to detect a hit on the 3D geometry of a visual object if a model 3D object is detected.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08031190&OS=08031190&RS=08031190
owner: Microsoft Corporation
number: 08031190
owner_city: Redmond
owner_country: US
publication_date: 20040503
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATION","TECHNICAL FIELD","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION","Specification for Framework\/Viewport3D Level","HitTesting into VisualMaterial","Other Embodiments"],"p":["The present application is related to U.S. patent application Ser. No. 10\/838,935, entitled INTEGRATION OF THREE DIMENSIONAL SCENE HIERARCHY INTO TWO DIMENSIONAL COMPOSITING SYSTEM, filed May 3, 2004, which has now issued as U.S. Pat. No. 7,145,562, and U.S. patent application Ser. No. 10\/838,936 entitled MODEL 3D CONSTRUCTION APPLICATION PROGRAM INTERFACE, filed May 3, 2004, both applications assigned to the Assignee of the present invention and hereby incorporated by reference in their entirety.","The invention relates generally to the field of computer graphics. More particularly, the invention relates to translating user input through two-dimensional elements into a three-dimensional scene in a two-dimensional compositing system.","The limits of the traditional model of accessing graphics on computer systems are being reached, in part because memory and bus speeds have not kept up with the advancements in main processors and\/or graphics processors. In general, the current model for preparing a frame using bitmaps requires too much data processing to keep up with the hardware refresh rate when complex graphics effects are desired. As a result, when complex graphics effects are attempted with conventional graphics models, instead of completing the changes that result in the perceived visual effects in time for the next frame, the changes may be added over different frames, causing results that are visually undesirable.","Further, this problem is aggravated by the introduction of three-dimensional (3D) graphics into the two-dimensional (2D) compositing system to display a mixed scene with 2D images and 3D scenes. One of the problems with such a mixed system is how to translate a user's 2D mechanical input with a mouse, pen or other pointing device into a computer input when the user is pointing at a 2D view of a 3D scene on a computer display screen. What is needed is a graphics generation and compositing system that can translate the user input into computer input for 3D scenes as well as the standard 2D images.","It is with respect to these considerations and others that the present invention has been made.","The above and other problems are solved by a computing system for translating two-dimensional (2D) graphical input by a user who is selecting one or more 2D images in a three-dimensional (3D) scene of 3D models created by model 3D objects. The computing system comprises a viewport module, a retrieve module, a set ray module and, a hit detection module. The viewport module defines 2D boundaries of the 3D scene and a view point location in 3D space for viewing the 3D scene. The retrieve module retrievies a selection point location in 2D space for the 2D graphical input. The set ray module sets a pick ray in 3D space based on the view point location and the selection point location. The hit detection module detects a hit by the pick ray on a 3D model in the 3D scene.","In accordance with still other aspects, the present invention relates to a method of processing a hierarchy of computer program visual objects for detecting a hit by 2D input on two dimensional (2D) and three-dimensional (3D) images displayed by a computing system. The method traverses branches of a first tree hierarchy of visual 2D and 3D objects. Next the method detects whether the next unprocessed object is a visual 2D object with 2D geometry or a model 3D object with 3D geometry. Lastly the method calls a 2D process to detect a hit on the 2D geometry of a visual object if a visual 2D object is detected and calls the 3D process to detect a hit on the 3D geometry of an object if a model 3D object is detected.","In a further aspect of the method, the 3D process comprises setting a camera view point, and converting the 2D input into a ray based on the camera view point, the ray penetrating the 3D space of the images of one or more 3D models defined by the model 3D objects.","The invention may be implemented as a computer process, a computing system or as an article of manufacture such as a computer program product or computer readable media. The computer readable media may be a computer storage media readable by a computer system and encoding a computer program of instructions for executing a computer process. The computer readable media may also be a propagated signal on a carrier readable by a computing system and encoding a computer program of instructions for executing a computer process.","These and various other features as well as advantages, which characterize the present invention, will be apparent from a reading of the following detailed description and a review of the associated drawings.","The logical operations of the various embodiments of the present invention are implemented (1) as a sequence of computer implemented acts or program modules running on a computing system and\/or (2) as interconnected machine logic circuits or circuit modules within the computing system. The implementation is a matter of choice dependent on the performance requirements of the computing system implementing the invention. Accordingly, the logical operations making up the embodiments of the present invention described herein are referred to variously as operations, structural devices, acts or modules. It will be recognized by one skilled in the art that these operations, structural devices, acts and modules may be implemented in software, in firmware, in special purpose digital logic, and any combination thereof without deviating from the spirit and scope of the present invention as recited within the claims attached hereto.",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1","b":["10","12","14","16","16","20","16","14","16","12","14","15"]},"When 2D hit detection operation is called and there is a 2D view of a 3D scene, the operation flow enters the basic hit detection routine in  and begins at get camera view operation . This operation retrieves the 3D location of the camera view point or eye point . Generally, the camera view point  is aligned with the center of the display screen  although it could be placed in other alignments with the display screen. Get cursor point operation  retrieves the 3D location of the cursor point  on the display screen . Set pick ray operation  sets the path of a ray  from the camera view point  through the cursor point  and into 3D scene space based on the 3D locations of these two points. The pick ray  proceeds into 3D space to intersect 3D model  at hit or intersection point . The intersection point location will be an X, Y, Z location along the pick ray.","Ray hit detect operation  will detect the intersection point  on the model based on the ray information and the 3D geometry of the 3D model . There may be multiple intersections as the pick ray  passes through the 3D model. In  there will be a second intersection point (not shown) as the pick ray exits the cube .","Report operation  reports the results of the hit detection. The results will be 3D results and include a display of the model intersected by the ray (a reference to the 3D model object is reported from which the display is rendered), the intersection location of the hit by the ray, multiple hits and intersection location of each hit, and further any model 3D program objects traversed in the 3D scene tree in performing the hit detection. This latter information is referred to as the hit path or pick path. Lastly, the hit detection is converted to 2D information. The 2D information of the hit is known because the cursor point location is known. To this cursor point location is added the above 3D hit information.","The hit detection operational flow is described more completely hereinafter in reference to ,  and . An exemplary operative hardware and software environment for implementing the invention will now be described.","Exemplary Operating Environment",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 2","b":["100","100","100","100"]},"The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, tablet devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like. The invention may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, and so forth, which perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices.","With reference to , an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer . Components of the computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, Accelerated Graphics Port (AGP) bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","The computer  typically includes a variety of computer-readable media. Computer-readable media can be any available media that can be accessed by the computer  and includes both volatile and nonvolatile media, and removable and non-removable media. By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can accessed by the computer . Communication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer-readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules  and program data .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media, discussed above and illustrated in , provide storage of computer-readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules  and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers herein to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer  through input devices such as a tablet (electronic digitizer) , a microphone , a keyboard  and pointing device , commonly referred to as mouse, trackball or touch pad. Other input devices (not shown) may include a joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . The monitor  may also be integrated with a touch-screen panel  or the like that can input digitized input such as handwriting into the computer system  via an interface, such as a touch-screen interface . Note that the monitor and\/or touch screen panel can be physically coupled to a housing in which the computing device  is incorporated, such as in a tablet-type personal computer, wherein the touch screen panel  essentially serves as the tablet . In addition, computers such as the computing device  may also include other peripheral output devices such as speakers  and printer , which may be connected through an output peripheral interface  or the like.","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet. When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface  or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Software Environment for Processing the Visual Tree Hierarchy",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 3","FIG. 3"],"b":["200","202","204","206","212","204","202","206","206","208","210","212"]},"The graphics layer architecture  includes a high-level composition and animation engine , which includes or is otherwise associated with a caching data structure . The caching data structure  contains a scene graph comprising hierarchically-arranged objects that are managed according to a defined object model, as described below. In general, the visual API layer  provides the program code  (and the presenter system ) with an interface to the caching data structure , including the ability to create objects, open and close objects to provide data to them, and so forth. In other words, the high-level composition and animation engine  exposes a unified media API layer  by which developers may express intentions about graphics and media to display graphics information, and provide an underlying platform with enough information such that the platform can optimize the use of the hardware for the program code. For example, the underlying platform will be responsible for caching, resource negotiation and media integration.","The high-level composition and animation engine  passes an instruction stream and possibly other data (e.g., pointers to bitmaps) to a fast, low-level compositing and animation engine . As used herein, the terms \u201chigh-level\u201d and \u201clow-level\u201d are similar to those used in other computing scenarios, wherein in general, the lower a software component is relative to higher components, the closer that component is to the hardware. Thus, for example, graphics information sent from the high-level composition and animation engine  may be received at the low-level compositing and animation engine , where the information is used to send graphics data to the graphics subsystem including the hardware .","The high-level composition and animation engine  in conjunction with the program code  builds a scene graph to represent a graphics scene provided by the program code . For example, each item to be drawn may be loaded with drawing instructions, which the system can cache in the scene graph data structure . As will be described below, there are a number of various ways to specify this data structure , and what is drawn. Further, the high-level composition and animation engine  integrates with timing and animation systems  to provide declarative (or other) animation control (e.g., animation intervals) and timing control. Note that the animation system allows animate values to be passed essentially anywhere in the system, including, for example, at the element property level , inside of the visual API layer , and in any of the other resources. The timing system is exposed at the element and visual levels.","The low-level compositing and animation engine  manages the composing, animating and rendering of the scene, which is then provided to the graphics subsystem . The low-level engine  composes the renderings for the scenes of multiple applications, and with rendering components, implements the actual rendering of graphics to the screen. Note, however, that at times it may be necessary and\/or advantageous for some of the rendering to happen at higher levels. For example, while the lower layers service requests from multiple applications, the higher layers are instantiated on a per-application basis, whereby is possible via the imaging mechanisms  to perform time-consuming or application-specific rendering at higher levels, and pass references to a bitmap to the lower layers.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIGS. 4 and 5","FIG. 4","FIG. 3","FIG. 4"],"b":["300","400","302","304","306","304","306","304","308","218","306","308","218","222","310","315","302","316","317","318","319"]},{"@attributes":{"id":"p-0041","num":"0040"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public abstract class Visual : VisualComponent"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public Transform Transform { get; set; }"]},{"entry":[{},"public float Opacity { get; set; }"]},{"entry":[{},"public BlendMode BlendMode { get; set; }"]},{"entry":[{},"public Geometry Clip { get; set; }"]},{"entry":[{},"public bool Show { get; set; }"]},{"entry":[{},"public HitTestResult HitTest(Point point);"]},{"entry":[{},"public bool IsDescendant(Visual visual);"]},{"entry":[{},"public static Point TransformToDescendant("]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Visual reference,"]},{"entry":[{},"Visual descendant,"]},{"entry":[{},"Point point);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"public static Point TransformFromDescendant("]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Visual reference,"]},{"entry":[{},"Visual descendant,"]},{"entry":[{},"Point point);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public Rect CalculateBounds( ); \/\/ Loose bounds"]},{"entry":[{},"public Rect CalculateTightBounds( ); \/\/"]},{"entry":[{},"public bool HitTestable { get; set; }"]},{"entry":[{},"public bool HitTestIgnoreChildren { get; set; }"]},{"entry":[{},"public bool HitTestFinal { get; set; }"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"A transformation, set by the transform property, defines the coordinate system for the  sub-graph of a visual. The coordinate system before the transformation is called pre-transform coordinate system, the one after the transform is called post-transform coordinate system, that is, a visual with a transformation is equivalent to a visual with a transformation node as a parent. A more complete description of the visual tree and the compositing system is included in the related patent application entitled INTEGRATION OF THREE DIMENSIONAL SCENE HIERARCHY INTO TWO DIMENSIONAL COMPOSITING SYSTEM cross-referenced above.","Translation of User Input for 3D Scene","With the above hardware and software environment in mind,  illustrates a visual tree that produces a window on a computer display screen when processed by the compositing system described above. The visual 2D root object  for the window has three children, panel visual object , checkbox visual object , and viewport 3D object . The panel visual object  is a container visual object and has two children, a button visual object  and a scrollbar visual object . Thus the visual tree defines a window with a button, a scroll bar and checkbox along with a 3D scene viewed as a 2D camera image.","The viewport 3D control object  contains screen bounds  and camera parameters . The screen bounds includes the 2D boundaries of the of the 3D scene. The 2D boundaries in X, Y coordinates of the display area might be 0, 0, 500, 500 to define a viewport 500 units square. A reference or pointer  in the viewport 3D object  points to the 3D scene, and more particularly to the root object in the 3D scene. In , pointer  points to 3D group object  in the 3D scene . The 3D scene is made up of two 3D group objects, two 3D primitive draw objects and a light object. Each of the 3D primitive draw objects  and  contains drawing instructions including the 3D geometry for a model. The light object  specifies the illumination of the drawn model created by primitive objects . Primitive object  also contains mesh information  and material information , and primitive  contains mesh information  and material information . The material information  in this example is a further visual tree that has panel visual 2D object , and two children visual 2D objects, button object  and scroll bar object . In other words, some 2D control images are embedded in the 3D scene.","The input translation operations for a visual tree begins when a primary caller in another higher level program calls either Visual.HitTest entry  in the 2D process operations of  or Model3D.HitTest entry  in the 3D process operations of . The transition between the two operational flows of  for processing visual 2D objects and 3D model objects is seamless to the user.","For the visual tree example in , the operation flow called is the 2D process of . That call is from the primary caller for detecting a hit in the window image rendered by the visual tree in . The operation flow for 2D hit testing the window enters at 2D Visual.HitTest entry . Move operation  moves the processing to the next object in the tree which has not been processed. The first such object is window object . The operation flow enters loop  which contains call operation  and more objects test operation . As objects are processed for a 2D hit, the operation flow around the loop  walks the process through the tree.","Call operation  calls Hit Test Core 2D module entry point . At entry point  the operation flow passes to viewport 3D test operation . Test operation  detects whether the object is a viewport 3D object or a visual 2D object. In this case windows object  is a visual 2D object, and the operation flow branches \u201cNO\u201d to detect 2D hit operation . The 2D hit detect operation  compares the cursor point location to the 2D geometry of window object . If the cursor point is within the 2D geometry, i.e. the area covered by the window frame, there is a hit on the window. Hit 2D geometry test operation  tests whether a hit was detected. If there was a hit, the operation flow branches YES to generate 2D hit result operation . The 2D hit result is the cursor point location and the visual identifier of the visual 2d object whose image was hit. The operation flow then passes to return-to-caller operation . If no hit was detected, the operation flow branches NO from test operation  to return-to-caller operation . The return operation  returns the operational flow to the caller which in this case in call operation .","At call operation  the flow is directed to more objects test operation . More objects test operation  detects whether there are more objects to be hit tested in the tree. If there are, the operation flow branches YES to move operation . Move operation  moves down the left most branch of the tree to panel object  in  which is the next unprocessed object. The branches of the tree will be processed from left to right.","Panel object  is another visual 2D object and is processed in the same manner as just discussed for window object . Return operation again returns the flow to call operation  and the flow passes to move operation . Processing now moves to the first child of panel object  which is button visual 2D object . Button object is processed for a 2D hit as described above and the flow returns to call operation  and hence to move operation . The next unprocessed object in the same branch is the scroll bar visual object . This is a visual 2D object, and the operation flow will again pass to detect 2D hit operation  through viewport 3D test operaion . Detect 2D hit operation  will process the scroll bar visual object  in the same manner as described above for the processing of the window object . If a hit is detected, generate operation  will generate a 2D hit result, and the operation flow passes to return-to-caller operation . Likewise if a hit is not detected, the operation flow passes to return-to-caller operation . The operation flow again returns to the call operation , and move operation  walks the visual tree in  to the first object in the next branch, i.e. check box object .","After the checkbox object , which is 2D, is processed, move operation  walks the tree to viewport 3D object . The viewport 3D object  will be detected by viewport 3D test operation , and the operation flow will branch YES to 3D convert operation. Convert operation  creates a pick ray from the camera eye point and the cursor point in the same manner as described above in . Call operation  now calls the 3D process by calling Model3D.HitTest. The 3D process operational flow is illustrated in , and call operation  passes the operation flow to 3D process entry point .","In , the operation flow for 3D hit testing the 3D scene enters at Model3D.HitTest entry . Move operation  moves the processing to the next object in the tree which has not been processed. The first such object is 3D group object  which is also the root node of the 3D scene tree. The operation flow enters loop  which contains call operation  and more objects test operation . As objects are processed for a 3D hit, the operation flow around the loop  walks the process through the branches of the 3D scene tree from left to right.","Call operation  calls Hit Test Core 3D module entry point . At entry point  the operation flow passes to detect 3D hit operation . Detect 3D hit operation compares the path of the pick ray  () to the 3D geometry of the model drawn by the object being tested. The first object is 3D group object . Since 3D group objects have no 3D geometry, no hit will be detected. Of course 3D group objects could be redefined to also draw models and have 3D geometry. In the preferred embodiment, the primitive 3D objects have 3D geometry, and a hit may be detected. If the ray intersects the model drawn by the 3D object, a hit has occurred. Hit 3D geometry test operation  tests whether a hit occurred. If a hit did occur, the operation flow passes to 2D content test operation . If a hit did not occur, the operation flow passes to return-to-caller operation . The return operation  returns the operational flow to the caller which in this case is call operation .","A return to call operation  causes the flow to pass around loop  to more objects test operation . More objects test operation  detects whether there are more objects to be hit tested in the 3D scene tree. If there are, the operation flow branches YES to move operation . Move operation  moves down the left most branch of the tree to 3D group object  in  which is the next unprocessed object. The branches of the tree will be processed from left to right.","Model 3D object  is another group object and will not have 3D geometry. Accordingly, detect 3D hit operation  will not detect a hit. Return operation  again returns the flow to call operation  and the flow passes to move operation . Processing now moves to the model 3D light object  which is the next unprocessed object in the same branch of the 3D scene tree . Light object  is processed for a 3D hit as described above, but light objects do not have 3D geometry. Therefore detect 3D hit operation will not detect a hit, and the flow returns to call operation  and hence to move operation . The next unprocessed object in the same branch is the 3D primitive object . Primitive objects do have 3D geometry as they draw the 3D models. Detect 3D hit operation  compares the path of the pick ray  () to the 3D geometry of the model drawn by primitive . If the ray intersects the model, a hit has occurred. Hit 3D geometry test operation  tests whether a hit occurred. If a hit did not occur the operation flow passes to return-to-caller operation . If a hit did occur, the operation flow passes to 2D content test operation .","Since the primitive object  in  has no visual 2D objects attached, the operation flow would branch NO from 2D content test operation  to generate Model3D hit result . The 3D hit result includes the identification of the model hit, the hit path or pick path\u2014nodes in the 3D scene tree traversed to reach object that was hit\u2014, mesh intersected, intersection coordinates, and distance along pick ray. From the generate result operation  the operation flow passes to return-to-caller operation . At return-to-caller operation , the operation flow returns to the call operation . More objects test operation  detects that there are more objects in the 3D scene tree to be processed. Move operation  walks the 3D scene tree to the next branch and to 3D primitive object , the next unprocessed object.","The 3D primitive  object does have material information  that includes visual 2D objects. Accordingly, the operation flow branches YES from 2D content test operation  to convert to 2D operation . The convert to 2D operation converts from the pick ray back to the cursor point location. Then call Visual.HitTest operation  calls 2D process operations in , and the operation flow enters  at entry point . The 2D process of  will now process a second 2D visual tree consisting of visual 2D objects ,  and . The loop  walks this second 2D visual tree through visual 2D object  to visual 2D objects  and . Each of these objects is checked for a 2D hit by operations  and . Detect operation  detects a hit if the cursor point is within the 2D geometry of the panel visual 2D object . If there is a hit, generate operation  generates the 2D hit result; if there was no hit, the operation flow passes to return-to-caller operation . Now the caller is call operation . The next unprocessed object is button object , and the hit test core 2D process is called again by call operation .","The button object is not a viewport 3D object so detect 2D hit operation  checks for a hit by the cursor point on the button 2D geometry of button visual object . The hit test operation  detects whether a hit occurred. If there was a hit, generate operation  generates the 2D hit result; if there was no hit, the operation flow passes to return-to-caller operation  and back to call operation . Move operation  then moves the test process to scroll bar visual 2D object  which is processed in the same way as panel object  and button object . Return operation  then returns the flow to call operation  and hence to more objects test operation . More objects test operation  detects there are no more objects in this second visual 2D tree and so branches the flow NO to return-to-caller operation . The caller in this case is call operation  in the 3D process shown in .","When call operation  detects the return of the process control, it passes the operation flow to generate operation  to generate model 3D hit result for the primitive . The operation flow then passes to return-to-caller operation . From the return operation , the operation flow is returned to call operation  in . Call operation  now passes the operation flow to any 3D results test operation . If there have been no 3D hit results from models in the 3D scene , the operation flow proceeds to return-to-caller operation . If there are 3D hit results, generate visual hit test result generates one or more 3D hits results into a 2D hit results. This is accomplished by attaching the 3D hit results to a cursor point location and visual identifier. Thus the normal 2D hit result has attached to it nested 3D hit information from the 3D hit result information generated by generate operation  in . The operation flow then proceeds to return-to-caller operation .","Return operation  now returns program control to call operation  and hence to more objects test operation . Since there are no more objects to be processed in the visual tree of , the operation flow branches NO to return to caller operation . In this case the caller is the primary caller (not shown) that called to the visual hit test process at entry point  translate input, i.e. hit detection, on the visual tree in . The operations called by the primary caller are now completed, and program control will be returned to the higher level program containing the primary caller.","Model 3D Hit Test API's","The following API's are defined for Model 3D Hit Test.","Model3D","The following additions to public abstract class Model3D allow the model to describe how it relates to hit testing as well as support initiation of the hit test.",{"@attributes":{"id":"p-0064","num":"0063"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public abstract class Model3D : ..."]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"... existing abstract class Model 3D definitions ..."]},{"entry":[{},"\/\/ Support for hit testing against alternate model3d"]},{"entry":[{},"public HitTestModel HitTestModel"]},{"entry":[{},"{ get; set; } \/\/ default = Box"]},{"entry":[{},"public Model3D AlternateModelForHitTest"]},{"entry":[{},"{ get; set; } \/\/ default = Model3D.Empty"]},{"entry":[{},"\/\/ Enumerating yields general HitTestResult3D objects."]},{"entry":[{},"public IEnumerable<HitTestResult3D>"]},{"entry":[{},"HitTest(HitTestParamaters3D params);"]},{"entry":[{},"\/\/ Enumerating yields HitTestResult3D objects."]},{"entry":[{},"All other overloads"]},{"entry":[{},"\/\/ forward to this more general version."]},{"entry":[{},"public IEnumerable<HitTestResult3D>"]},{"entry":[{},"HitTest(HitTestParamaters3D params,"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"HitTestFilter filter);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"HitTestModel","HitTestModel is used to control the 3D geometry used to test the intersection of the pick ray and the model. Values are:",{"@attributes":{"id":"p-0067","num":"0066"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Value","Description"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ActualModel","Tests against the actual geometry of"]},{"entry":[{},{},"this Model."]},{"entry":[{},"AlternateModel","Tests against the alternate geometry"]},{"entry":[{},{},"specified by the AlternateModel property."]},{"entry":[{},{},"This allows the user to do things like"]},{"entry":[{},{},"specify a convex hull to reduce the"]},{"entry":[{},{},"complexity of hit testing."]},{"entry":[{},"BoundingBox","Tests against the bounding box surrounding"]},{"entry":[{},{},"the model. Exposes the internal bounding box"]},{"entry":[{},{},"probing we do as a means to do fast,"]},{"entry":[{},{},"approximate hit tests."]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"HitTest( )","The Model3D.HitTest( ) method kicks off the whole process. It makes a (conceptually) complete pass at the tree (though not necessarily in the actual implementation), and returns an enumerator that will yield the HitTestResult3Ds when traversed.","The HitTest method optionally takes a HitTestFilter delegate. This is the same filter delegate used in 2D. The HitTestFilter delegate is called back with each Model3D as the scene graph is walked. Unlike 2D where the tree order is consistent with Z-order 3D must (conceptually) walk the entire tree because the first hit we encounter is not necessarily the closest.","HitTestParameters3D","The HitTest( ) methods on Model3D take a HitTestParameters3D object which defines the geometry and options to be used for the hit test. This an abstract base class with the concrete RayHitTestParameter and ConeHitTestParameter implementations.",{"@attributes":{"id":"p-0072","num":"0071"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public abstract class HitTestParameters3D"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ If true, the enumerator returned from HitTest( )"]},{"entry":[{},"should yield results sorted by"]},{"entry":[{},"\/\/ increasing distance from the origin of the hit test cone."]},{"entry":[{},"Otherwise the order"]},{"entry":[{},"\/\/ is arbitrary. Default is true."]},{"entry":[{},"public bool OrderResults { get; set; }"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The flags sent into HitTest are shown above in the definition of HitTestFlags, and are interpreted as follows. Note that they each default to false.","RayHitTestParameters","A concrete implementation of HitTestParameters3D which defines the hit test geometry as a ray. Note the lack of \u201c3D\u201d suffix. The use of a ray implies a 3D domain for hit testing.",{"@attributes":{"id":"p-0075","num":"0074"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"public class RayHitTestParameters : HitTestParameters3D"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public RayHitTestParameters(Point3D origin, Vector3D direction);"]},{"entry":[{},"public Point3D Origin { get; }"]},{"entry":[{},"public Vector3D Direction { get; }"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"A concrete implementation of HitTestParameters3D which defines the hit test geometry as a cone. Note the lack of \u201c3D\u201d suffix. The use of a cone implies a 3D domain for hit testing.",{"@attributes":{"id":"p-0077","num":"0076"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public class ConeHitTestParameters : HitTestParameters3D"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public ConeHitTestParameters(Point3D origin,"]},{"entry":[{},"Vector3D direction, double"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"spreadAngle);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public Point3D Origin { get; }"]},{"entry":[{},"public Vector3D Direction { get; }"]},{"entry":[{},"public double SpreadAngle { get; }"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"HitTestResult3D represents a single hit Model3D resulting from a Model3D.HitTest( ) invocation.","It is retrieved by access through the IEnumerable returned from Model3D.HitTest( ).","HitTestResult3D is an abstract class with concrete implementations for Ray and Cone intersection.",{"@attributes":{"id":"p-0081","num":"0080"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"public abstract class System.windows.Media.Media3D.HitTestResult3D"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"private HitTestResult3D( ); \/\/ no public construction"]},{"entry":[{},"public Model3D ModelHit { get; } \/\/ the Model3D that was hit"]},{"entry":[{},"public IEnumerable<Model3D> HitPath { get; }"]},{"entry":[{}," \/\/ list of Model3D's on the way down"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"This property is filled with the 3D model that was hit. This is any Model3D in the hierarchy that was hit. Thus, if we have:","Model3DGroup\n\n","And the MeshPrimitive3D is hit then there will be a separate HitTestResult3D for each of these three Model3D's. However, only the last one, the HitTestResult3D from the MeshPrimitive3D, will contain intersection information.","(NOTE: This behavior can be overridden with the filter delegate)","HitPath","HitPath is a lazily evaluated IEnumerable that enumerates from the model hit backwards up the graph to the root. This is an important source of information to disambiguate multiple paths to the same Model3D, since they can be multi-parented.","The \u201cbottom up\u201d ordering was chosen because it is assumed that the common case for using this property will be to check your parent to disambiguate your self in a multiple use scenarios.","The decision to include the ModelHit in the HitPath was made for consistency with other 3D frameworks where the result of a hit test is a pick path and there necessarily includes the model hit. From this perspective, ModelHit is just syntactic sugar for the first item in your pick path.","RayHitTestResult","A concrete implementation of HitTestResult3D which adds details of the intersection of a Model3D with a Ray. Note the lack of \u201c3D\u201d suffix. The use of a ray implies a 3D domain for hit testing.",{"@attributes":{"id":"p-0090","num":"0091"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public class RayHitTestResult : HitTestResult3D"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ No public construction"]},{"entry":[{},"internal RayHitTestResult( )"]},{"entry":[{},"\/\/ Enumerating yields RayIntersection objects for each"]},{"entry":[{},"\/\/ intersection between the model and the ray (there can be"]},{"entry":[{},"\/\/ multiple intersections per model.)"]},{"entry":[{},"\/\/"]},{"entry":[{},"public IEnumerable<RayIntersection> Intersections { get; }"]},{"entry":[{},"\/\/ Returns the closest intersection"]},{"entry":[{},"public RayIntersection ClosestIntersection { get; }"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"A concrete implementation of HitTestResult3D which adds details of the intersection of a Model3D with a Ray. Note the lack of \u201c3D\u201d suffix. The use of a ray implies a 3D domain for hit testing.",{"@attributes":{"id":"p-0092","num":"0093"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"public class ConeHitTestResult : HitTestResult3D"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ No public construction"]},{"entry":[{},"internal RayHitTestResult( )"]},{"entry":[{},"\/\/ Enumerating yields ConeIntersection objects for each"]},{"entry":[{},"\/\/ intersection between the model and the cone (there can be"]},{"entry":[{},"\/\/ multiple intersections per model.)"]},{"entry":[{},"\/\/"]},{"entry":[{},"public IEnumerable<RayIntersectionDetails> Intersections { get; }"]},{"entry":[{},"\/\/ Returns the closest intersection"]},{"entry":[{},"public RayIntersectionDetails ClosestIntersection { get; }"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"RayIntersection is an abstract class that has concrete subclasses for each type of Model3D that is able to provide detailed information about its intersection with a ray. The RayHitTestResult.Intersections property returns an IEnumerable that, when iterated over, yields RayIntersections.","It's up to the receiving application to take these RayIntersections and cast them, based on type, to their proper concrete subclass in order to access the content of the specific subclasses.",{"@attributes":{"id":"p-0095","num":"0096"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"public abstract class System.Windows.Media.Media3D.RayIntersection"},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ point of intersection to cone tip (for this face)"]},{"entry":[{},"public abstract double DistanceToRayOrigin { get; }"]},{"entry":[{},"\/\/ the point in model space of the intersection"]},{"entry":[{},"public abstract Point3D PointHit { get; }"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}},"ul":{"@attributes":{"id":"ul0004","list-style":"none"},"li":{"@attributes":{"id":"ul0004-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0005","list-style":"none"},"li":["DistanceToRayOrigin\u2014the distance to the origin of the hit-testing ray from the mesh's point of intersection.","PointHit\u2014The point in the hit model's coordinate system where the ray intersected this face.\n\nRayMesh3DIntersectionDetails\n"]}}}},"RayMesh3DIntersection is a concrete extension of RayIntersection which adds details about the intersection between the ray and the Mesh3D.",{"@attributes":{"id":"p-0097","num":"0100"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public class RayMesh3DIntersection : RayIntersection"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"private RayMesh3DIntersection( ); \/\/ no public construction"]},{"entry":[{},"public Mesh3D MeshHit { get; }"]},{"entry":[{},"\/\/ Information for hit location interpolation."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public int","VertexIndex1 { get; }"]},{"entry":[{},"public int","VertexIndex2 { get; }"]},{"entry":[{},"public int","VertexIndex3 { get; }"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public double VertexWeight1 { get; }"]},{"entry":[{},"public double VertexWeight2 { get; }"]},{"entry":[{},"public double VertexWeight3 { get; }"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"ul":{"@attributes":{"id":"ul0006","list-style":"none"},"li":{"@attributes":{"id":"ul0006-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0007","list-style":"none"},"li":"MeshHit\u2014the Mesh3D that was hit."}}}},"The final parameters provide the information necessary for an application to blend and interpolate vertex information properly based on where on the triangle the hit occurred.\n\n","TBD. The below is a snippit form the original spec which included heuristics from coercing a cone intersection into a hit point:",{"@attributes":{"id":"p-0100","num":"0106"},"figref":"FIG. 9","b":["902","904","906","902","904","908","910","912","914"]},"An application may choose to use DistanceToRay  to prefer a hit that might be directly on the ray, albeit it farther away, than one slightly off the ray.","Note that DistanceToTip  is always the distance to the point on the hit geometry closest to the ray. This is required for continuity, otherwise the distance could \u201cjump\u201d when the geometry passes through the ray. If a given primitive is hit more than once (say it has an S-like topology and the ray comes in from the top), then multiple Intersectioninfo's are returned.","Details for Other Model3D's",{"@attributes":{"id":"p-0103","num":"0109"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public class Viewport3D : FrameworkElement"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"..."]},{"entry":[{},"public double HitTestSpreadAngle { get; set; }"]},{"entry":[{}," \/\/ default to 5 degrees."]},{"entry":[{},"public static readonly DependencyProperty"]},{"entry":[{},"HitTestSpreadAngleProperty;"]},{"entry":[{},"..."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"At the Viewport3D level, the only additional API required is for determining hit test cone spread angle, since Viewport3D gains all of the hit testing entry points from Visual\/FrameworkElement (such as HitTestCore and HitTestBounds). The basic implementation of it is straightforward:\n\n","Note that Viewport3D always sets its Model's IncludeInHitTestResult3Ds to true, so it will at least receive confirmation that the Viewport3D's model as a whole was hit or not hit. IHitTestResult3DContainer","When the user initiates a 2D HitTest on Viewport3D the result can be cast to a IHitTestResult3DContainer which is defined as follows:",{"@attributes":{"id":"p-0107","num":"0117"},"tables":{"@attributes":{"id":"TABLE-US-00013","num":"00013"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public class IHitTestResult3DContainer"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"public IEnumerable<HitTestResult3D> Results { get; }"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"This is the means by which the programmer can extract the 3D intersection information from a hit test initiated from 2D. In practice, this would look as follows:",{"@attributes":{"id":"p-0109","num":"0119"},"tables":{"@attributes":{"id":"TABLE-US-00014","num":"00014"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"PointHitTestResult result2D = visual.HitTest(p);"]},{"entry":[{},"\/\/ Check to see if we hit an 3D geometry"]},{"entry":[{},"IHitTestResult3DContainer ht3dResults = result2D as"]},{"entry":[{},"IHitTestResult3DContainer"]},{"entry":[{},"if (ht3dResults != null)"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ We did hit 3D geometry, enumerate the 3D results"]},{"entry":[{},"foreach(HitTestResult3D result3D in hr3dResults.Results)"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"}"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"Hit testing continues into a VisualMaterial mapped onto 3D. As described above, the proper delegates and 2D parameters are being sent down into the 3D hit test. When a VisualMaterial is encountered, the 2D walk can be resumed, but needs to occur at the right spot in the 2D coordinate system of the VisualMaterial. This is done by taking the IntersectionInfo from the 3D hit, calculating texture coordinates of that hit, and mapping that back to 2D coordinates from which to begin the next level of hit testing into 2D. The continuation of the hit testing will proceed without the knowledge of the clients that 3D was ever transitioned through.","A pick ray is defined by the camera location and cursor point location in . However, a pick ray might also be defined by data input. In other words the user could simply input data defining the pick ray. Particularly, if a user wished to start hit detection in the 3D scene tree, the user would input the pick ray data and call the 3D hit test method on a model 3D object. Further the camera in one preferred embodiment shown in  is a perspective camera. However an orthographic camera could be used. With such a camera, all rays are parallel so the only camera information required is the aim direction for the camera. The pick ray into the 3D scene would be from the cursor point location in the aim direction of the camera.","Also, the pick ray is a projection of a point\u2014the cursor point projected in a direction based on the camera view point. Alternative embodiments for the perspective camera include a light beam in the shape of cone. In this case, the intersection between the cone and a 3D model is an area bounded by the model's intersection with the cone. A cone in effect is the projection of a circle rather than projection of a point. Other 2D shapes might be used in place of the circle to obtain other intersection effects. Also if the camera is orthographic with all rays parallel, than the light beam is an extrusion of that 2D shape into the 3D space of the 3D scene.","Note that a 3D scene can contain visual material which has a 2D scene which includes another viewport 3D object. This second viewport 3D object contains a second 3D scene. Thus, by using multiple viewport 3Ds and multiple visual materials, 2D and 3D content can be nested in each other any number of times.","Although the invention has been described in language specific to computer structural features, methodological acts and by computer readable media, it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific structures, acts or media described. Therefore, the specific structural features, acts and mediums are disclosed as exemplary embodiments implementing the claimed invention.","The various embodiments described above are provided by way of illustration only and should not be construed to limit the invention. Those skilled in the art will readily recognize various modifications and changes that may be made to the present invention without following the example embodiments and applications illustrated and described herein, and without departing from the true spirit and scope of the present invention, which is set forth in the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 6","FIG. 7","FIG. 8"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7","b":["2","3"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
