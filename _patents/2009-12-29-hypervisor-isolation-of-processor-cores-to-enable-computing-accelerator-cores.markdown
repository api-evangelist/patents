---
title: Hypervisor isolation of processor cores to enable computing accelerator cores
abstract: Techniques for utilizing processor cores include sequestering processor cores for use independently from an operating system. In at least one embodiment of the invention, a method includes executing an operating system on a first subset of cores including one or more cores of a plurality of cores of a computer system. The operating system executes as a guest under control of a virtual machine monitor. The method includes executing work for an application on a second subset of cores including one or more cores of the plurality of cores. The first and second subsets of cores are mutually exclusive and the second subset of cores is not visible to the operating system. In at least one embodiment, the method includes sequestering the second subset of cores from the operating system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09058183&OS=09058183&RS=09058183
owner: Advanced Micro Devices, Inc.
number: 09058183
owner_city: Sunnyvale
owner_country: US
publication_date: 20091229
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY OF EMBODIMENTS OF THE INVENTION","DETAILED DESCRIPTION"],"p":["1. Field of the Invention","The invention is related to computer systems and more particularly to multi-core computer systems.","2. Description of the Related Art","In general, the number of central processing unit (CPU) cores (i.e., processor cores) and\/or processors included within a computing system is increasing rapidly. Referring to , an exemplary computing system  includes multiple processors , each of which includes one or more processor cores (e.g., processor cores ). Processors  are coupled to other processors , memory , devices , and storage  by one or more hub integrated circuits (e.g., memory controller hub and I\/O controller hub), bus (e.g., PCI bus, ISA bus, and SMBus), other suitable communication interfaces, or combinations thereof. An operating system (e.g., Microsoft Windows, Linux, and UNIX) provides an interface between the hardware and a user (i.e., computing applications, e.g., applications ). Execution of operating system  may be distributed across a plurality of cores .","Although a computing system includes multiple processor cores, a typical computing system may not be able to utilize all processor cores or utilize all processor cores efficiently. For example, an operating system may be able to access and control only a limited number of CPU cores, leaving idle other cores in the computing system.","Accordingly, techniques for utilizing processor cores include sequestering processor cores for use independently from an operating system. In at least one embodiment of the invention, a method includes executing an operating system on a first subset of cores including one or more cores of a plurality of cores of a computer system. The operating system executes as a guest under control of a virtual machine monitor. The method includes executing work for an application on a second subset of cores including one or more cores of the plurality of cores. The first and second subsets of cores are mutually exclusive and the second subset of cores is not visible to the operating system. In at least one embodiment, the method includes sequestering the second subset of cores from the operating system.","In at least one embodiment of the invention, an apparatus includes a plurality of cores and an operating system software encoded in one or more media accessible to the plurality of cores. The apparatus includes hypervisor software encoded in one or more media accessible to the plurality of cores and executable on one or more of the plurality of cores. The hypervisor software is executable to control execution of the operating system software as a guest on a first set of cores including one or more cores of the plurality of cores and to execute at least some work of an application on a second set of cores including one or more cores of the plurality of cores. The second set of cores is not visible to the operating system.","In at least one embodiment of the invention, a computer program product includes one or more functional sequences executable as, or in conjunction with, a virtual machine monitor and configured to execute an operating system sequence as a guest under control of the virtual machine monitor on a first set of cores including one or more cores of a plurality of cores. The computer program product includes one or more functional sequences to execute at least some work of an application on a second set of cores including one or more cores of the plurality of cores. The second set of cores is not visible to the operating system.","The use of the same reference symbols in different drawings indicates similar or identical items.","Referring to , virtualization of a computing system is used to hide physical characteristics of the computing system from a user (i.e., software executing on the computing system) and instead, presents an abstract emulated computing system (i.e., a virtual machine (VM)) to the user. Physical hardware resources of computing system  are exposed to one or more guests (e.g., guests ) as one or more corresponding isolated, apparently independent, virtual machines (e.g., VM ). For example, a virtual machine may include one or more virtual resources (e.g., VCPU, VMEMORY, and VDEVICES) that are implemented by physical resources of computing system  that a virtual machine monitor (VMM) (i.e., hypervisor, e.g., VMM ) allocates to the virtual machine.","As referred to herein, a \u201cvirtual machine monitor\u201d (VMM) or \u201chypervisor\u201d is software that provides the virtualization capability. The VMM provides an interface between the guest software and the physical resources. Typically, the VMM provides each guest the appearance of full control over a complete computer system (i.e., memory, central processing unit (CPU) and all peripheral devices). A Type 1 (i.e., native) VMM is a standalone software program that executes on physical resources and provides the virtualization for one or more guests. A guest operating system executes on a level above the VMM. A Type 2 (i.e., hosted) VMM is integrated into or executes on an operating system, the operating system components execute directly on physical resources and are not virtualized by the VMM. The VMM is considered a distinct software layer and a guest operating system may execute on a third software level above the hardware. Although the description that follows refers to an exemplary Type 1 VMM, techniques described herein may be implemented in a Type 2 VMM.","Referring back to , while VM  has full control over the virtual resources of virtual machine , VMM  retains control over the physical resources. A guest system, e.g., an instance of an operating system (e.g., Windows, Linux, and UNIX) executes on a corresponding virtual machine and shares physical resources with other guest systems executing on other virtual machines. Thus, multiple operating systems (e.g., multiple instances of the same operating system or instances of different operating systems) can co-exist on the same computing system, but in isolation from each other.","VMM  is executed by some or all processor cores in the physical resources. An individual guest is executed by a set of processor cores included in the physical resources. The processors switch between execution of VMM  and execution of one or more guests . As referred to herein, a \u201cworld switch\u201d is a switch between execution of a guest and execution of a VMM. In general, a world switch may be initiated by a VMMCALL instruction or by other suitable techniques, e.g., interrupt mechanisms or predetermined instructions defined by a control block, described below. Although a particular world switch may be described herein as being initiated using a particular technique, other suitable techniques may be used. During a world switch, a current processor core environment (e.g., guest or VMM) saves its state information and restores state information for a target core environment (e.g., VMM or guest) to which the processor core execution is switched. For example, a VMM executes a world switch when the VMM executes a guest that was scheduled for execution. Similarly, a world switch from executing a guest to executing a VMM is made when the VMM exercises control over physical resources, e.g., when the guest attempts to access a peripheral device, when a new page of memory is to be allocated to the guest, or when it is time for the VMM to schedule another guest, etc.","Virtualization techniques may be implemented using only software (which includes firmware) or by a combination of software and hardware. For example, some processors include virtualization hardware, which allows simplification of VMM code and improves system performance for full virtualization (e.g., hardware extensions for virtualization provided by AMD-V and Intel VT-x). Software, as described herein, may be encoded in at least one computer readable medium selected from the set of a disk, tape, or other magnetic, optical, or electronic storage medium.","Virtualization techniques may be used to isolate or sequester one or more processor cores of a computing system from an operating system executing as a guest on one or more other processing cores of the computer system under control of a VMM. In at least one embodiment of a virtualization system, sequestered cores may be configured as de facto accelerators. That is, sequestered cores are used by the VMM to complete work initiated from within the operating system environment. Although the host cores and the sequestered cores reside within a shared memory environment, the sequestered cores are not managed by the operating system directly. The VMM is configured as a vehicle for communicating between the sequestered cores and the host cores. An exemplary VMM implements a memory-based solution for propagating work requests, page faults, and completion information using a queue-based architecture implemented within a shared memory space. Computational work may be initiated within the confines of the guest operating system. A VMM then coordinates work between the operating system and the sequestered cores. Accordingly, a VMM may be used to implement general computational acceleration. A VMM and sequestered cores may be used to implement instant-on application usage. In addition, a VMM may be used to configure sequestered cores as network device accelerators.","The number of cores used by a guest operating system (i.e., host cores) may be selectable. For example, the number of host cores may be the maximum number of cores that a particular guest operating system is able to utilize. However, in at least one embodiment of a virtualization system, the number of cores used by the guest operating system is not limited thereto, and a system may be configured with a predetermined number of cores for an operating system that is less than a maximum number of cores.","Referring to , exemplary computing system  includes VMM . VMM  emulates a decoupled architecture, i.e., VMM  sequesters cores to execute applications or application tasks. In at least one embodiment, VMM  sequesters cores  from cores . In at least one embodiment, VMM  assigns host cores  and sequestered cores  separate virtual memory spaces. In at least one embodiment, VMM  assigns host cores  and sequestered cores  a shared virtual memory space. Techniques for implementing a shared virtual memory space are described in U.S. patent application Ser. No. 12\/648,550, entitled \u201cSYSTEMS AND METHODS IMPLEMENTING NON-SHARED PAGE TABLES FOR SHARING MEMORY RESOURCES MANAGED BY A MAIN OPERATING SYSTEM WITH ACCELERATOR DEVICES,\u201d naming Patryk Kaminski, Thomas Woller, Keith Lowery, and Erich Boleyn, as inventors, now U.S. Pat. No. 8,719,543, issued May 6, 2014, and U.S. patent application Ser. No. 12\/648,556, entitled \u201cSYSTEMS AND METHODS IMPLEMENTING SHARED PAGE TABLES FOR SHARING MEMORY RESOURCES MANAGED BY A MAIN OPERATING SYSTEM WITH ACCELERATOR DEVICES,\u201d naming Patryk Kaminski, Thomas Woller, Keith Lowery, and Erich Boleyn, as inventors, both filed on or about the filing date of the instant application, which applications are hereby incorporated by reference herein.","In at least one embodiment, VMM  maintains a set of control blocks, which include state and control information for execution of a guest on host cores  and a set of state and control information for execution of a work unit on sequestered cores . In at least one embodiment, these control blocks are known as virtual machine control blocks (VMCBs). Each guest and de facto accelerator may be associated with a corresponding control block. Exemplary control blocks may be stored in memory and\/or in storage of the host hardware and include state and control information for a corresponding guest or de facto accelerator and\/or state and control information for the VMM. For example, a control block includes state information corresponding to core state at a point at which a guest last exited. Exemplary control blocks may be accessed by particular instructions and information may be stored in particular fields of predetermined data structures.","In at least one embodiment of computing system , VMM  is configured to isolate at least one core (e.g., sequestered cores ) for use as a de facto accelerator. Operating system  (e.g., Microsoft Windows) executes as a guest on host cores  (e.g., x86 cores) and application  executes on operating system . Kernel mode driver , which executes on operating system , exchanges information with VMM  to provide user application  indirect access to the de facto accelerators. The guest operating system may utilize sequestered cores  using kernel mode driver , e.g., using a call. Communications between VMM  and guest operating system  and between VMM  and de facto accelerators are accomplished using queues in shared virtual memory (e.g., work queue , command queue , fault queue , and response queue ).","Scheduler  includes a thread pool across which work items are distributed to available segregated cores . In at least one embodiment of scheduler , the work units are assigned to available segregated cores using round-robin scheduling; however, other suitable scheduling algorithms (e.g., dynamic priority scheduling, etc.) may be used in other embodiments of scheduler . In at least one embodiment of computing system , scheduler  is a user-mode scheduler, which allows scheduling to be performed separate from the operating system. However, in at least one embodiment of computing system , scheduler  is a kernel-mode scheduler, which requires modification of kernel-level portions of the operating system. In at least one embodiment of computing system , at least some of the functionality of scheduler  is performed by VMM  and\/or at least some of the functionality of scheduler  is performed by kernel mode driver . VMM  maintains relevant topology and architecture information in an information or control structure that is visible to kernel mode driver . VMM  provides at least information about available de facto accelerators to kernel mode driver .","In at least one embodiment of computing system , a fault queue , command queue , response queue , and work queue  are implemented in shared virtual memory space. All of those queues require operating system access (e.g., kernel mode access). In at least one embodiment of computing system , the queues must be accessible from outside of the process context of a creating application. Thus, operating system  must provide memory translation. Only the work queue requires user-mode access. In at least one embodiment, queues, , , , and  use non-locking implementations and are configured for a single reader and a single writer. Virtual machine monitor  enqueues to fault queue  and response queue . Kernel mode driver  dequeues from fault queue  and response queue . Kernel mode driver  enqueues to command queue  and VMM  dequeues from command queue . Application  enqueues to work queue . Scheduler , which may be implemented using VMM  and\/or kernel mode driver , dequeues from work queue .","In at least one embodiment of computing system , application  calls queueing application programming interface (API)  to initialize the queueing interfaces. Queueing API  instantiates kernel mode driver  and makes documented input\/output control (ioctl) calls to allocate the queues. Kernel mode driver  receives the ioctl command and allocates queues that may be read or written by appropriate entities (e.g., VMM  and kernel mode driver ), consistent with the description above. Kernel mode driver  creates an internal work table that associates work queue  with an address space. Kernel mode driver  also creates a page table and allocates stacks for the de facto accelerators. Kernel mode driver  creates a kernel mode thread and also returns a pointer to work queue  for use by application .","In at least one embodiment of computing system , polling techniques are used to process the queues. In at least one embodiment of computing system , rather than using polling techniques, communications between VMM  and guest operating system  and between VMM  and sequestered cores , configured as de facto accelerators, are achieved using doorbell techniques. In general, any writer (e.g., kernel mode driver , queuing API , or VMM ) to a queue will ring a doorbell to notify a recipient (e.g., kernel mode driver  or VMM ) of available queue items. In at least one embodiment of the computing system, VMM  supports a VMM call that serves as a doorbell for a specific queue. Information that indicates which queue contains a new entry, and\/or other suitable information, is included in the parameters of the VMM call. In addition, VMM  rings the doorbell of kernel mode driver  by issuing a software interrupt. Different software interrupts may be used to distinguish between different doorbell recipients.","For example, application  may push an entry into work queue  via queueing API  and kernel mode driver  rings a doorbell for VMM , e.g., by executing a VMMCALL, to indicate that the work queue has a new entry. The VMMCALL instruction transfers control from guest operating system  to VMM . Similarly, when kernel mode driver  pushes a command into command queue , kernel mode driver  rings a doorbell (e.g., by executing a VMMCALL) for VMM  to indicate that the command queue has a new entry. In yet another example, when a work unit has completed on a sequestered core  configured as a de facto accelerator, VMM  may push an entry into fault queue  and send a fault queue interrupt via a local Advanced Programmable Interrupt Controller (APIC) to a host core . VMM  can ring the doorbell of kernel mode driver  using software interrupts. The particular interrupt number used is stored in a field in a configuration block and maintained by kernel mode driver .","Application  creates work queue  and registers with kernel mode driver  for an entry point in the work queue table. Application  uses queuing API  to add work items to work queue . Queuing API  rings the doorbell of scheduler . In embodiments where scheduling logic resides in kernel mode driver , kernel mode driver  will read work queue . Accordingly, calls to VMM  will explicitly include an indicator of which core should be targeted by VMM . In response to the doorbell, scheduler  determines whether a de facto accelerator is available. If no de facto accelerator is available, scheduler  updates a status to indicate that work queue  is not empty. If a de facto accelerator is available, scheduler  reads work queue . Scheduler  selects an available de facto accelerator and makes a scheduling call to VMM .","In at least one embodiment of computing system , when scheduler  is distinct from VMM , scheduler  may write a command to command queue  and ring the doorbell of VMM . Then VMM  sets up execution context and initializes a target sequestered core  configured as a de facto accelerator. VMM  writes to response queue  and scheduler  processes response queue  to maintain visibility into status (e.g., availability) of sequestered cores . When scheduler  dequeues a work item from work queue , scheduler  consults a list of available de facto accelerators of sequestered core  configured as de facto accelerators and selects a target sequestered core . Scheduler  then creates and enqueues a command queue entry that indicates the work item and the target sequestered core . Then scheduler  rings the doorbell of VMM . In order for scheduler  to maintain an accurate view of resource availability, scheduler  should be notified of work item completion. In at least one embodiment of computing system , a system stack is manipulated so that a return from a work item makes a VMM call to notify VMM  of work item completion.","Referring to , , and , upon a system reset, VMM  boots on the cores of system  (e.g., host cores  and sequestered cores ) (). In at least one embodiment, VMM  is booted from memory (e.g., on a hard drive), separately from the Basic Input Output System. Virtual machine monitor  then boots operating system  as a guest on operating system cores  and sequesters cores  from cores  (). For example, when booting operating system , VMM  informs operating system  of a number of cores on which to execute. Then operating system  will not attempt to access sequestered cores . Other techniques for sequestering cores  from operating system cores  include modifying the BIOS tables so that operating system  is aware of only a particular number of cores less than a total number of cores, with virtual machine monitor  controlling the environments on both sets of cores. Those BIOS tables may either be loaded automatically from read-only memory or patched in by VMM . In another technique for sequestering cores from the operating system, VMM  intercepts operating system commands to configure a number of operating system cores.","After the cores are sequestered and the operating system has booted, operating system  loads an accelerated computing kernel mode device driver  (). Application  runs on operating system  (). Application  generates work units, which are then scheduled to execute on sequestered cores  (). Upon completion, VMM  notifies operating system  of completed work ().","Referring to , , and , a work unit initiation process is described in additional detail. In at least one embodiment of computing system , kernel mode driver  creates an internal work table, which may be used for adding work queue table entries (). Application  creates a work queue and registers with kernel mode driver  for an entry in the work queue table (). While executing, application  pushes a work queue entry onto work queue  (). Kernel mode driver  notifies VMM  that work queue  has a new entry () using a doorbell (e.g., VMMCALL), as described above, or other suitable notification technique. Virtual memory monitor  processes the doorbell on host cores  and sends an INIT inter-processor interrupt (IPI) to a particular sequestered core . Virtual machine monitor  processes an exit to VMM  on the particular sequestered core  (). If the particular sequestered core  is idle (i.e., is not already processing a work unit), VMM  pulls a next work unit entry from work queue  (), modifies a VMCB, and begins execution of code for processing the work unit (). Otherwise, the particular sequestered core continues executing a previously launched work unit. In at least one embodiment of computing system , if a particular sequestered core  is already executing a work unit, VMM  will not interrupt that particular sequestered core  with an exit to VMM .","While processing a work unit, a sequestered core  configured as a de facto accelerator may experience a page fault (i.e., sequestered core  accesses a page that is mapped in address space but is not loaded into physical memory). Referring to , , and , in at least one embodiment of computing system , those page faults experienced by sequestered core  are recognized by VMM  and a world switch occurs to VMM  (). Virtual machine monitor  obtains page fault information from the sequestered core and creates a kernel-level page fault entry, which VMM  pushes onto user fault queue  (). Virtual machine monitor  issues a fault queue interrupt via a local APIC to one of host cores  (). Kernel mode driver  interrupt handler processes the interrupt and executes a fault queue deferred procedure call and reads the fault off of system fault queue . Kernel mode driver  updates the page tables associated with the user process () and generates a command (e.g., CMD_RESUME including a field for a target core) for resuming execution by the sequestered core  configured as a de facto accelerator (). Kernel mode driver  pushes that command into command queue  () and rings a doorbell of VMM  (e.g., VMMCALL) that indicates that command queue  has a new entry (). Virtual machine monitor  processes the VMMCALL on host core  and issues an inter-processor interrupt (i.e., INIT IPI) to a sequestered core  that includes queue handler  (i.e., de facto accelerator core ), which processes command queue . In response to the inter-processor interrupt, de facto accelerator core  reads command queue  and processes the command (e.g., CMD_RESUME) (), e.g., by sending an inter-processor interrupt to an appropriate sequestered core  to resume processing the work unit (). Virtual machine monitor  then processes a VMEXIT (e.g., performs a world switch) and the sequestered core  resumes processing the work unit ().","Referring to , , and , in at least one embodiment of computing system , once a work unit has been processed and the sequestered core  executes a last instruction for the work unit, the sequestered core  executes a routine that includes one or more instructions that indicate the work unit has completed execution (e.g., VMMCALL) (). Accordingly, sequestered core  returns to execution of VMM , and VMM  processes the indicator of work unit completion (). In at least one embodiment of computing system , VMM  determines whether it is configured to issue a notification of work unit completion (). If VMM is not configured to issue a notification, VMM  will proceed to process a next work unit (). Alternatively, VMM will issue a completion directive. In at least one embodiment, VMM  pushes a work unit completion entry into system fault queue  and VMM  sends a fault queue interrupt (e.g., via local APIC) to an operating system core  ().","Kernel mode driver  processes the fault queue interrupt and reads an entry from system fault queue. Kernel mode driver  locates the user process context associated with the fault entry and pushes the fault entry into a particular user fault queue  for the process context (). A user work thread handler in kernel mode driver  pulls a fault entry from user fault queue  and completes the work unit ().","Referring to , in at least one embodiment of computing system , sequestered cores  are configured for instant-on application usage, rather than as de facto accelerators. Upon a system reset, VMM  boots on the cores of system  (e.g., host cores  and sequestered cores ) (). For example, VMM  may reside in the BIOS and automatically sequesters cores  from cores  (). Virtual machine monitor  is configured to have access to the file system and runs a user application on one or more of sequestered cores  (). Meanwhile, VMM  boots operating system  as a guest on host cores  (). Virtual machine monitor  includes one or more drivers or basic input output system (i.e., BIOS interface) functions to access media containing an application that will initially run on sequestered cores .","Although VMM  is described as a virtual machine monitor in general, in at least one embodiment, VMM  is a minimalistic implementation of a virtual machine monitor that is configured to provide the functionality described herein, and few other virtualization functions. In another embodiment, the functionality of VMM  described herein is incorporated into a general virtual machine monitor that provides other typical virtual machine functions. In at least one embodiment of computing system , virtual machine monitors may be nested, e.g., operating system  is a VMM machine monitor that is controlled by VMM  consistent with the functionality described herein. In at least one embodiment of computing system , use of virtualization techniques to sequester cores requires no modification to the operating system.","The description of the invention set forth herein is illustrative, and is not intended to limit the scope of the invention as set forth in the following claims. For example, while the invention has been described in an embodiment in which sequestered cores are configured as de facto accelerators for an application execution on a guest operating system under control of a VMM, one of skill in the art will appreciate that the teachings herein can be utilized for instant-on applications, network device acceleration, and general computational acceleration. For example, VMM  may coordinate with a network router device to accelerate packet inspection functions using sequestered cores . In addition, although the invention has been described in a computing system in general, embodiments of the teachings described herein may be included in servers, desktop systems (e.g., personal computers), embedded applications (e.g., mobile communications devices) and other suitable applications. Variations and modifications of the embodiments disclosed herein may be made based on the description set forth herein, without departing from the scope and spirit of the invention as set forth in the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention may be better understood, and its numerous objects, features, and advantages made apparent to those skilled in the art by referencing the accompanying drawings.",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 5","FIG. 3"]},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 6","FIG. 3"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 7","FIG. 3"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 8","FIG. 3"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 9","FIG. 3"]}]},"DETDESC":[{},{}]}
