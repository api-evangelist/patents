---
title: Method and apparatus for multithreaded processing of data in a programmable graphics processor
abstract: A graphics processor and method for executing a graphics program as a plurality of threads where each sample to be processed by the program is assigned to a thread. Although threads share processing resources within the programmable graphics processor, the execution of each thread can proceed independent of any other threads. For example, instructions in a second thread are scheduled for execution while execution of instructions in a first thread are stalled waiting for source data. Consequently, a first received sample (assigned to the first thread) may be processed after a second received sample (assigned to the second thread). A benefit of independently executing each thread is improved performance because a stalled thread does not prevent the execution of other threads.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07015913&OS=07015913&RS=07015913
owner: NVIDIA Corporation
number: 07015913
owner_city: Santa Clara
owner_country: US
publication_date: 20030627
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND","SUMMARY","DISCLOSURE OF THE INVENTION"],"p":["One or more aspects of the invention generally relate to multithreaded processing, and more particularly to processing graphics data in a programmable graphics processor.","Current graphics data processing is exemplified by systems and methods developed to perform a specific operation on several graphics data elements, e.g., linear interpolation, tessellation, texture mapping, depth testing. Traditionally graphics processing systems were implemented as fixed function computation units and more recently the computation units are programmable to perform a limited set of operations. In either system, the graphics data elements are processed in the order in which they are received by the graphics processing system. Within the graphics processing system, when a resource, e.g., computation unit or data, required to process a graphics data element is unavailable, the processing of the element stalls, i.e., does not proceed, until the resource becomes available. Because the system is pipelined, the stall propagates back through the pipeline, stalling the processing of later received elements that may not require the resource and reducing the throughput of the system.","For the foregoing reasons, there is a need for improved approaches to processing graphics data elements.","The present invention is directed to a system and method that satisfies the need for a programmable graphics processor that supports processing of graphics data elements in an order independent from the order in which the graphics data elements are received by the programmable graphics processing pipeline within the programmable graphics processor.","Various embodiments of the invention include a computing system comprising a host processor, a host memory, a system interface configured to interface with the host processor, and the programmable graphics processor for multithreaded execution of program instructions. The graphics processor includes at least one multithreaded processing unit configured to receive samples in a first order to be processed by program instructions associated with at least one thread. Each multithreaded processing unit includes a scheduler configured to receive the program instructions, determine availability of source data, and schedule the program instructions for execution in a second order independent of the first order. Each multithreaded processing unit further includes a resource tracking unit configured to track the availability of the source data, and a dispatcher configured to output the program instructions in the second order to be executed by the at least one multithreaded processing unit.","Further embodiments of the invention include an application programming interface for a programmable graphics processor comprising a function call to configure a multithreaded processing unit within the programmable graphics processor to enable processing of samples independent of an order in which the samples are received.","Yet further embodiments of the invention include an application programming interface for a programmable graphics processor comprising a function call to configure a multithreaded processing unit within the programmable graphics processor to disable processing of samples independent of an order in which the samples are received.","Various embodiments of a method of the invention include processing a first program instruction associated with a first thread and a second program instruction associated with a second thread. A first sample to be processed by a program instruction associated with a first thread is received before a second sample to be processed by a program instruction associated with a second thread is received. First source data required to process the program instruction associated with the first thread are determined to be not available. Second source data required to process the program instruction associated with the second thread are determined to be available. The program instruction associated with the second thread to process the second sample in the execution unit is dispatched prior to dispatching the program instruction associated with the first thread to process the first sample in the execution unit.","Further embodiments of a method of the invention include using a function call to configure the graphics processor. Support for processing samples of at least one sample type independent of an order in which the samples are received by a multithreaded processing unit within the graphics processor is detected. The function call to configure the multithreaded processing unit within the graphics processor to enable processing of the samples independent of an order in which the samples are received is issued for the at least one sample type.","Yet further embodiment so of a method of the invention include rendering a scene using the graphics processor. The multithreaded processing unit within the graphics processor is configured to enable processing of samples independent of an order in which the samples are received. The multithreaded processing unit within the graphics processor process the samples independent of the order in which the samples are received to render at least a portion of the scene.","The current invention involves new systems and methods for processing graphics data elements in an order independent from the order in which the graphics data elements are received by a multithreaded processing unit within a graphics processor.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1","b":["100","10","170","100","110","114","112","112","115","115","112","115"]},"Host Computer  communicates with Graphics Subsystem  via System Interface  and a Graphics Interface  within a Graphics Processor . Data received at Graphics Interface  can be passed to a Front End  or written to a Local Memory  through Memory Controller . Graphics Processor  uses graphics memory to store graphics data and program instructions, where graphics data is any data that is input to or output from components within the graphics processor. Graphics memory can include portions of Host Memory , Local Memory , register files coupled to the components within Graphics Processor , and the like.","Graphics Processor  includes, among other components, Front End  that receives commands from Host Computer  via Graphics Interface . Front End  interprets and formats the commands and outputs the formatted commands and data to an IDX (Index Processor) . Some of the formatted commands are used by Programmable Graphics Processing Pipeline  to initiate processing of data by providing the location of program instructions or graphics data stored in memory. IDX , Programmable Graphics Processing Pipeline  and a Raster Analyzer  each include an interface to Memory Controller  through which program instructions and data can be read from memory, e.g., any combination of Local Memory  and Host Memory . When a portion of Host Memory  is used to store program instructions and data, the portion of Host Memory  can be uncached so as to increase performance of access by Graphics Processor .","IDX  optionally reads processed data, e.g., data written by Raster Analyzer , from memory and outputs the data, processed data and formatted commands to Programmable Graphics Processing Pipeline . Programmable Graphics Processing Pipeline  and Raster Analyzer  each contain one or more programmable processing units to perform a variety of specialized functions. Some of these functions are table lookup, scalar and vector addition, multiplication, division, coordinate-system mapping, calculation of vector normals, tessellation, calculation of derivatives, interpolation, and the like. Programmable Graphics Processing Pipeline  and Raster Analyzer  are each optionally configured such that data processing operations are performed in multiple passes through those units or in multiple passes within Programmable Graphics Processing Pipeline . Programmable Graphics Processing Pipeline  and a Raster Analyzer  also each include a write interface to Memory Controller  through which data can be written to memory.","In a typical implementation Programmable Graphics Processing Pipeline  performs geometry computations, rasterization, and pixel computations. Therefore Programmable Graphics Processing Pipeline  is programmed to operate on surface, primitive, vertex, fragment, pixel, sample or any other data. A fragment is at least a portion of a pixel, i.e., a pixel includes at least one fragment. For simplicity, the remainder of this description will use the term \u201csamples\u201d to refer to surfaces, primitives, vertices, pixels, or fragments.","Samples output by Programmable Graphics Processing Pipeline  are passed to a Raster Analyzer , which optionally performs near and far plane clipping and raster operations, such as stencil, z test, and the like, and saves the results or the samples output by Programmable Graphics Processing Pipeline  in Local Memory . When the data received by Graphics Subsystem  has been completely processed by Graphics Processor , an Output  of Graphics Subsystem  is provided using an Output Controller . Output Controller  is optionally configured to deliver data to a display device, network, electronic control system, other Computing System , other Graphics Subsystem , or the like.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 2","FIG. 1"],"b":["150","135","150"]},"Samples, such as surfaces, primitives, or the like, are received from IDX  by Programmable Graphics Processing Pipeline  and stored in a Vertex Input Buffer  in a register file, FIFO (first in first out), cache, or the like (not shown). The samples are broadcast to Execution Pipelines , four of which are shown in the figure. Each Execution Pipeline  includes at least one multithreaded processing unit, to be described further herein. The samples output by Vertex Input Buffer  can be processed by any one of the Execution Pipelines . A sample is accepted by a Execution Pipeline  when a processing thread within the Execution Pipeline  is available as described further herein. Each Execution Pipeline  signals to Vertex Input Buffer  when a sample can be accepted or when a sample cannot be accepted. In one embodiment Programmable Graphics Processing Pipeline  includes a single Execution Pipeline  containing one multithreaded processing unit. In an alternative embodiment, Programmable Graphics Processing Pipeline  includes a plurality of Execution Pipelines .","Execution Pipelines  can receive first samples, such as higher-order surface data, and tessellate the first samples to generate second samples, such as vertices. Execution Pipelines  can be configured to transform the second samples from an object-based coordinate representation (object space) to an alternatively based coordinate system such as world space or normalized device coordinates (NDC) space. Each Execution Pipeline  communicates with Texture Unit  using a read interface (not shown in ) to read program instructions and graphics data such as texture maps from Local Memory  or Host Memory  via Memory Controller  and a Texture Cache . Texture Cache  is used to improve memory read performance by reducing read latency. In an alternate embodiment Texture Cache  is omitted. In another alternate embodiment, a Texture Unit  is included in each Execution Pipeline . In yet another alternate embodiment program instructions are stored within Programmable Graphics Processing Pipeline .","Execution Pipelines  output processed samples, such as vertices, that are stored in a Vertex Output Buffer  in a register file, FIFO, cache, or the like (not shown). Processed vertices output by Vertex Output Buffer  are received by a Primitive Assembly\/Setup . This unit calculates parameters, such as deltas and slopes, to rasterize the processed vertices. Primitive Assembly\/Setup  outputs parameters and samples, such as vertices, to Raster Unit . The Raster Unit  performs scan conversion on samples, such as vertices, and outputs samples, such as fragments, to a Pixel Input Buffer . Alternatively, Raster Unit  resamples processed vertices and outputs additional vertices to Pixel Input Buffer .","Pixel Input Buffer  outputs the samples to each Execution Pipeline . Samples, such as pixels and fragments, output by Pixel Input Buffer  are each processed by only one of the Execution Pipelines . Pixel Input Buffer  determines which one of the Execution Pipelines  to output each sample to depending on an output pixel position, e.g., (x,y), associated with each sample. In this manner, each sample is output to the Execution Pipeline  designated to process samples associated with the output pixel position. In an alternate embodiment, each sample output by Pixel Input Buffer  is processed by an available Execution Pipeline .","A sample is accepted by a Execution Pipeline  when a processing thread within the Execution Pipeline  is available as described further herein. Each Execution Pipeline  signals to Pixel Input Buffer  when a sample can be accepted or when a sample cannot be accepted. Program instructions associated with a thread configure programmable computation units within a Execution Pipeline  to perform operations such as texture mapping, shading, blending, and the like. Processed samples are output from each Execution Pipeline  to a Pixel Output Buffer . Pixel Output Buffer  optionally stores the processed samples in a register file, FIFO, cache, or the like (not shown). The processed samples are output from Pixel Output Buffer  to Raster Analyzer .","Execution Pipelines  are optionally configured using program instructions read by Texture Unit  such that data processing operations are performed in multiple passes through at least one multithreaded processing unit, to be described further herein, within Execution Pipelines . Intermediate data generated during multiple passes can be stored in graphics memory.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 3","b":["330","331","344","240","330"]},"In  program instructions within instruction Sequence  are stored in graphics memory, i.e., Host Memory , Local Memory , register files coupled to the components within Graphics Processor , and the like. Each program counter ( through ) in instruction Sequence  corresponds to a program instruction within instruction Sequence . The program counters are conventionally numbered sequentially and can be used as an index to locate a specific program instruction within Sequence . The first instruction  in the sequence  represents is the program instruction corresponding to program counter . A base address, corresponding to the graphics memory location where the first instruction  in a program is stored, can be used in conjunction with a program counter to determine the location where a program instruction corresponding to the program counter is stored.","In this example, program instructions within Sequence  are associated with three threads. A Thread , a Thread  and a Thread  are each assigned to a different sample and each thread is uniquely identified by a thread identification code. A program instruction within Sequence  is associated with a thread using a program counter that is stored as a portion of thread state data, as described further herein. Thread  thread state data includes a program counter of  as shown in Sequence . The program counter associated with Thread  is a pointer to the program instruction in Sequence  corresponding to program counter  and stored at location . The instruction stored at location  is the next instruction to be used to process the sample assigned to Thread . Alternatively, an instruction stored at location  is the most recently executed instruction to process the sample assigned to Thread .","The thread state data for Thread  and Thread  each include a program counter of , as shown in , referencing the program instruction corresponding to program counter  in Program  and stored at location . Program counters associated with threads to process samples within a primitive, surface, or the like, are not necessarily identical because the threads can be executed independently. When branch instructions are not used, Thread , Thread  and Thread  each execute all of the program instructions in Sequence .","The number of threads that can be executed simultaneously is limited to a predetermined number in each embodiment and is related to the number of Execution Pipelines , the amount of storage required for thread state data, the latency of Execution Pipelines , and the like. Each sample is a specific type, e.g., primitive, vertex, or pixel, corresponding to a program type. A primitive type sample, e.g., primitive, is processed by a primitive program, a vertex type sample, e.g., surface or vertex, is processed by a vertex program, and a pixel type sample, e.g., fragment or pixel, is processed by a shader program. Likewise, a primitive thread is associated with program instructions within a primitive program, a vertex thread is associated with program instructions within a vertex program, and a pixel thread is associated with program instructions within a shader program.","A number of threads of each thread type that may be executed simultaneously is predetermined in each embodiment. Therefore, not all samples within a set of samples of a type can be processed simultaneously when the number of threads of the type is less than the number of samples. Conversely, when the number of threads of a type exceeds the number of samples of the type within a set, more than one set can be processed simultaneously. Furthermore, when the number of threads of a type exceeds the number of samples of the type within one or more sets, more than one program of the type can be executed on the one or more sets and the thread state data can include data indicating the program associated with each thread.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 4","b":["240","400","240","400","400","420","215","220","420","420","420","260","270"]},"The source sample is stored in either Pixel Input Buffer  or Vertex Input Buffer . When a thread is assigned to a sample, the thread is allocated storage resources to retain intermediate data generated during execution of program instructions associated with the thread. The thread identification code for a thread may be the address of a location in Thread Control Buffer  in which the thread state data for the thread is stored. In one embodiment, priority is specified for each thread type and Thread Control Buffer  is configured to assign threads to samples or allocate storage resources based on the priority assigned to each thread type. In an alternate embodiment, Thread Control Buffer  is configured to assign threads to samples or allocate storage resources based on an amount of sample data in Pixel Input Buffer  and another amount of sample data in Vertex Input Buffer .","An Instruction Cache  reads one or more thread entries, each containing thread state data, from Thread Control Buffer . Instruction Cache  may read thread entries to process a group of samples. For example, in one embodiment a group of samples, e.g., a number of vertices defining a primitive, four adjacent fragments arranged in a square, or the like, are processed simultaneously. In the one embodiment computed values such as derivatives are shared within the group of samples thereby reducing the number of computations needed to process the group of samples compared with processing the group of samples without sharing the computed values.","In an embodiment of Multithreaded Processing Unit , priority is specified for each thread type and Instruction Cache  is configured to read thread entries based on the priority assigned to each thread type. In another embodiment, Instruction Cache  is configured to read thread entries based on the amount of sample data in Pixel Input Buffer  and the amount of sample data in Vertex Input Buffer . Instruction Cache  determines if the program instructions corresponding to the program counters and sample type included in the thread state data for each thread entry are available in Instruction Cache . When a requested program instruction is not available in Instruction Cache  it is read (possibly along with other program instructions stored in adjacent memory locations) from graphics memory. In an alternate embodiment Instruction Cache  can be shared between Multithreaded Processing Units  within Execution Pipeline .","The program instructions corresponding to the program counters from the one or more thread entries are output by Instruction Cache  to a scheduler, Instruction Scheduler . A cache miss in Instruction Cache  can result in instructions being output by Instruction Cache  in an order which is different than the order in which the samples to be processed by the instructions were received by Thread Control Buffer . For example when an instruction to process a first received sample is not stored in Instruction Cache  and an instruction to process a second received sample is stored in Instruction Cache , the instruction to process the second received sample will be output by Instruction Cache  to Instruction Scheduler  while the instruction to process the first received sample is read from graphics memory.","The number of instructions output each clock cycle from Instruction Cache  to Instruction Scheduler  can vary depending on whether or not the instructions are available in the cache. The number of instructions that can be output each clock cycle from Instruction Cache  to Instruction Scheduler  may also vary between different embodiments. In one embodiment, Instruction Cache  outputs one instruction per clock cycle to Instruction Scheduler . In an alternate embodiment, Instruction Cache  outputs a predetermined number of instructions per clock cycle to Instruction Scheduler .","Instruction Scheduler  contains storage resources to store a predetermined number of instructions in an IWU (instruction window unit) . Each clock cycle, Instruction Scheduler  evaluates whether any instruction within the IWU  can be executed based on the availability of computation resources in an Execution Unit  and source data stored in a Register File . An instruction specifies the location of source data needed to execute the instruction. In addition to Register File , other locations of source data include Pixel Input Buffer , Vertex Input Buffer , locations in Local Memory , locations in Host Memory , and the like. A resource tracking unit, Resource Scoreboard , tracks the status of source data stored in registers in Register File . Specifically, registers scheduled to be written during processing, i.e., destination registers, are marked as \u201cwrite pending\u201d. When a destination register is written, its status is updated and the \u201cwrite pending\u201d mark is removed. In one embodiment a destination register is marked as \u201cwrite pending\u201d by setting a bit in Resource Scoreboard  corresponding to the destination register. The bit is cleared when the destination register is written, indicating that data stored in the register is available to be used as source data. Similarly, Resource Scoreboard  may also track the availability of the computation resources in an Execution Unit .","During the evaluation process, in one embodiment Instruction Scheduler  is configured to give priority to threads based on thread age (lowest program counter or greatest number of clock cycles resident in IWU ). A CU (Comparison Unit)  is used to compare program counters. In an alternate embodiment, in addition to program counters, thread state data such as stack depths, nesting levels, subroutine calls, or the like are used to determine thread age. An STU (Scheduling Timeout Unit)  is used to count the number of consecutive clock cycles each instruction in IWU  is resident in IWU . In one embodiment, priority is specified for each thread type and Instruction Cache  is configured to read thread entries based on the priority assigned to each thread type. In another embodiment, Instruction Cache  is configured to read thread entries based on the amount of sample data in Pixel Input Buffer  and the amount of sample data in Vertex Input Buffer .","When Instruction Scheduler  determines which instructions and associated threads will be executed, Instruction Scheduler  outputs at least one instruction to a dispatcher, Instruction Dispatcher , updates destination register status and computation resource availability in Resource Scoreboard  and increments each program counter associated with the threads in Thread Control Buffer  associated with the at least one instruction output. In this manner, Instruction Scheduler  is able to schedule the execution of the instructions associated with each thread such that the processing of a sample is one or more instructions ahead of the processing of another sample. As a result of Instruction Scheduler  not being constrained to schedule instructions for execution on each sample within a set of data synchronously, the samples are not necessarily processed or output in the order in which they were received.","Instruction Dispatcher  gathers the source data specified in an instruction and outputs the instruction and source data to Execution Unit . Execution Unit  is configured by the program instruction to process samples using programmable computation units to perform operations such as linear interpolation, derivative calculation, blending, and the like, and output the processed sample to a destination specified by the instruction. The destination can be Vertex Output Buffer , Pixel Output Buffer , or Register File . When execution of an instruction is complete, Execution Unit  updates Resource Scoreboard  to indicate that destination registers are written and the computation resources used to process the instruction are available. Likewise, Execution Unit  updates each program counter associated with the threads in Thread Control Buffer  following the execution of a loop or branch instruction. In an alternate embodiment, Resource Scoreboard  snoops an interface between Execution Unit  and Register File  to update register status.","When the program instructions associated with a thread have completed execution, the storage resources allocated to retain intermediate data generated during execution of the thread become available for allocation to another thread, i.e., the storage resources are deallocated and the thread is flagged as available in Thread Control Buffer . When a program instruction stored in Instruction Cache  has completed execution on each sample within the one or more sets that the program instruction is programmed to process, the program instruction is retired from Instruction Cache  (by being overwritten).","The occurrence of image artifacts caused by failing to maintain sample processing order for each output pixel position between frames or within a frame can be significantly reduced or eliminated by processing pixel type samples, e.g., pixels, fragments, and the like, for each output pixel location, in the order in which the pixel type samples are received. Processing the pixel type samples for each output pixel location in the order in which the pixel type samples are received can be achieved by permitting pixel type samples corresponding to each output pixel location to be processed by a dedicated Multithreaded Processing Unit  and by preventing the occurrence of position hazards. A position hazard exists when more than one pixel type sample corresponding to an output pixel position within an output buffer is being processed by any Multithreaded Processing Unit  because the order in which samples will be processed is not deterministic, i.e., is not necessarily the same as the order in which the samples are received. In one embodiment each Multithreaded Processing Unit  is configured to process several output pixel locations distributed across an output image. In an alternate embodiment each Multithreaded Processing Unit  is configured to process several adjacent output pixel locations within the output image. In another embodiment each Multithreaded Processing Unit  is configured to process regions of four adjacent pixels arranged in a square, with each square distributed within the output image.","Thread Control Buffer  can be configured to accept only one fragment or pixel from Pixel Input Buffer  corresponding to each output pixel position within an output buffer and wait until the one fragment or pixel is processed before accepting another fragment or pixel corresponding to the same output pixel position within the output buffer. The output pixel position is stored as a portion of portion of thread state data in Thread Control Buffer . An output buffer ID specifying a unique output buffer containing output pixel positions is also optionally stored as a portion of thread state data in Thread Control Buffer . A process independent of order received (PIOR) flag is used to disable the prevention of position hazards. Disabling the PIOR flag during rendering eliminates image artifacts that can be introduced when fragment or pixel processing order for each output pixel location within an output buffer is not maintained between frames or within a frame. Enabling the PIOR flag during rendering can improve performance. Furthermore, a PIOR flag may be dedicated for each thread type to selectively enable or disable PIOR for each thread type.","In an alternate embodiment each Multithreaded Processing Unit  is configured to process fragments and pixels corresponding to any output pixel position and Pixel Input Buffer  can be configured to output only one fragment or pixel corresponding to each output pixel position within an output buffer. In the alternate embodiment Pixel Input Buffer  waits until the one fragment or pixel corresponding to an output pixel position within an output buffer is processed before outputting another fragment or pixel corresponding to the same output pixel position within the output buffer.",{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 5A","b":["400","501","420","220","215","503","420","220","215","505","430","515","430","440","515","440","505","470"]},"In step  Instruction Scheduler  determines if source data required to process the program instruction associated with the other thread are available, and, if so, in step  Instruction Scheduler  outputs the program instruction associated with the other thread to Instruction Dispatcher . In step  Instruction Dispatcher  also dispatches the program instruction associated with the other thread and updates the register status for destination registers. If in step  Instruction Scheduler  determines source data required to process the program instruction associated with the other thread are not available, Instruction Scheduler  remains in step . In an alternate embodiment, in step  Instruction Scheduler also determines if a computation resource within Execution Unit  required to process the program instruction associated with the other thread is available.","If in step  Instruction Scheduler  determines source data required to process the program instruction associated with the thread are not available, in step  Instruction Scheduler  determines if source data required to process the program instruction associated with the other thread are available. If in step  Instruction Scheduler  determines source data required to process the program instruction associated with the other thread are not available, Instruction Scheduler  returns to step . If in step  Instruction Scheduler  determines source data required to process the program instruction associated with the other thread are available, in step  Instruction Scheduler  outputs the program instruction associated with the other thread to Instruction Dispatcher  prior to outputting the program instruction associated with the thread. In step  Instruction Dispatcher  also dispatches the program instruction associated with the other thread and updates the register status for destination registers.","In step , Instruction Scheduler  determines if source data required to process the program instruction associated with the thread is available, and, if so, in step  Instruction Scheduler  outputs the program instruction associated with the thread to Instruction Dispatcher . In step  Instruction Dispatcher  also dispatches the program instruction associated with the thread and updates the register status for destination registers. If in step  Instruction Scheduler  determines source data required to process the program instruction associated with the thread are not available, Instruction Scheduler  remains in step .","In an alternate embodiment, in step  Instruction Scheduler also determines if a computation resource within Execution Unit  required to process the program instruction associated with the other thread is available and in step  Instruction Scheduler also determines if a computation resource within Execution Unit  required to process the program instruction associated with the thread is available.",{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 5B","b":["400","520","420","220","215","521","420","523","420","525","420","525","420","420","525"]},"If in step  Thread Control Buffer  determines a position hazard does not exist for the sample, Thread Control Buffer  stores at least a portion of the output pixel position of the sample as state information. In step , Thread Control Buffer  determines if a thread is available to process the sample in Multithreaded Processing Unit , and, if so, in step  Thread Control Buffer  assigns a thread to the sample. When a thread is not available in step , Thread Control Buffer  does not proceed to step  until a thread becomes available. In step  the busy flag portion of the thread state data is marked unavailable and the program counter corresponding to the first instruction to process the sample is stored in the thread state data. In step  Thread Control Buffer  also stores the position corresponding to the sample in the thread state data. In step  Thread Control Buffer  allocates storage resources for storing intermediate data generated during execution of the thread. The storage resources may be in graphics memory.","In step  Instruction Cache  fetches one or more instructions referenced by the program counter by reading the thread state data for the thread in Thread Control Buffer  with a busy flag indicating the thread is assigned to a sample. The one or more instructions can be located in Instruction Cache , a local storage resource, Local Memory , or Host Memory . Instruction Cache  outputs the one or more instructions to Instruction Scheduler . In step , Instruction Scheduler  determines if the one or more instructions can be scheduled based on source data availability, and, if not, remains in step . If in step  Instruction Scheduler  determines the one or more instructions can be scheduled based on source data availability, in step  Instruction Scheduler  updates the program counter stored in Thread Control Buffer , updates destination register status and outputs the one or more instructions to Instruction Dispatcher . The program counter can be updated by outputting a modified program counter to Thread Control Buffer  or by outputting a value, indicating the number of the one or more scheduled instructions, to be added to the program counter. The one or more instructions are output either in parallel or serially to Instruction Dispatcher  as specified by Instruction Scheduler . Instructions within a program can be scheduled for parallel execution by Instruction Scheduler  when the instructions are independent from each other and parallel execution will not modify the function of the program.","In step  Instruction Dispatcher  gathers the source data specified by each of the one or more instructions and outputs the instruction and the source data to Execution Unit . In step  Execution Unit  executes the one or more instructions associated with the thread to process the sample. Execution Unit  writes processed sample data to each destination specified by the one or more instructions and updates destination register status in Resource Scoreboard . In step  Execution Unit  also updates the program counter associated with the thread when a branch or loop instruction is executed and the program counter is different than the program counter updated in step . In step  Execution Unit determines if there are more instructions in the thread, and, if so, returns to step . If Execution Unit  determines there are no more instructions in the thread and there are no pending destination register writes associated with the thread, in step  the thread busy flag is marked as available in Thread Control Buffer  and the storage resources are effectively deallocated.","In an alternate embodiment steps  and  are completed by Instruction Scheduler  instead of being completed by Thread Control Buffer . In yet another alternate embodiment steps  and  are completed by Instruction Dispatcher  prior to gathering source data instead of being completed by Thread Control Buffer .","Rather than processing one sample as shown in , Multithreaded Processing Unit  receives a stream of samples, additional threads are assigned to each sample and instructions are fetched for each thread. Instruction Scheduler  determines which instructions can be scheduled, choosing amongst instructions that process different samples. In this manner Multithreaded Processing Unit  can simultaneously process one or more samples using at least one program, where each sample may be processed in an order that is independent of the order in which the samples were received by Multithreaded Processing Unit . Likewise, each Multithreaded Processing Unit  can simultaneously process one or more samples using at least one program, where each sample may be processed in an order that is independent of the order in which the samples were received by Execution Pipeline .",{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 6","b":["430","605","430","435","430","430","435","610","430","437","435","435","610","430","435","435","615","435","435","410","435","420"]},"If in step  Instruction Scheduler  determines none of the instructions in IWU  has remained in IWU  for a time longer than the scheduling timeout limit, in step  Instruction Scheduler  determines if a synchronization mode is enabled. If in step  Instruction Scheduler  determines a synchronization mode is enabled, in step  Instruction Scheduler  checks for synchronization and proceeds to step . In one embodiment, instructions with equal program counters are considered synchronized. In another embodiment, in addition to program counters, thread state data such as stack depths, nesting levels, subroutine calls, or the like are used to determine two or more threads are synchronized.","In step  Instruction Scheduler  determines if any of the instructions are synchronized, and, if not, in step  those instructions are removed from IWU . If in step  Instruction Scheduler  determines the instructions in IWU  are synchronized Instruction Scheduler  proceeds to step . In an alternate embodiment, the instruction synchronization can be included in either Thread Control Buffer  or Instruction Cache  and instructions that are not synchronized are not output from Instruction Cache  to Instruction Scheduler .","In step  Instruction Scheduler  sorts the instructions remaining in IWU  by thread age, e.g., from oldest to newest. In step  Instruction Scheduler  reads from Resource Scoreboard  to determine source data availability. In step  Instruction Scheduler  compares the source data availability with the source data requirements of the sorted instructions. In step  Instruction Scheduler  determines which instructions can be scheduled for execution and in step  Instruction Scheduler  writes Resource Scoreboard  as needed to update destination register status. Unavailability of source data required to process a received sample can result in a later received sample being processed before the received sample.","In step  Instruction Scheduler  writes to Thread Control Buffer  to update the program counter for each thread corresponding to an instruction that was scheduled for execution. In step  Instruction Scheduler  outputs the scheduled instructions to Instruction Dispatcher .","Conventional graphics processing systems have not permitted the scheduling of instructions for execution on each sample within a set of samples in an order independent from the order in which the samples were received because doing so can result in image artifacts. For example, image artifacts can be introduced when fragment or pixel processing order is not maintained for each output pixel location between frames or within a frame. Specifically, intersecting or coincident primitives or surfaces can yield different results for a fragment or pixel where the computed depth values for the intersecting or coincident primitives or surfaces are equal. For example, along a line of intersection between two primitives, a fragment can be \u201creordered\u201d resulting in an artifact caused when an earlier transmitted fragment is determined to be \u201cbehind\u201d a later transmitted fragment due to reordering resulting in the earlier transmitted fragment being processed after the later transmitted sample. As sequential frames of the scene are viewed, the line of intersection can seem to wiggle, sparkle, or crawl. Likewise, when two primitives are coincident and different colors, pixels within sequential frames can change color from frame to frame when fragments are \u201creordered\u201d. Furthermore, the color of each pixel within the two primitives is dependent on processing order such that within a frame the two primitives may appear speckled. It is possible to reduce visual artifacts by enabling and disabling the PIOR for pixel type sample processing during rendering.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 7A","b":["150","701","114","150","150","703","114","150","105","150","706","706"]},{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 7B","b":["710","150","720","730","150","740","114","150"]},"A device driver executed by Host Processor  detects that Programmable Graphics Processing Pipeline  supports the PIOR and communicates that information to the API. A graphics application executed by Host Processor  can issue the function call to configure Programmable Graphics Processing Pipeline  within Graphics Processor  to process pixel and fragment samples ignoring position hazards, by enabling the PIOR. In one embodiment the function call communicates with Graphics Processor  via the device driver to modify a flag or bits in a register that is readable by Programmable Graphics Pipeline  and the flag or bits control the state of the PIOR.","When images are rendered with PIOR enabled artifacts can be introduced during the rendering of non-opaque primitives. Correct rendering of transparent primitives requires rendering all of the opaque primitives and then rendering depth sorted non-opaque primitives. Because the non-opaque primitives are sorted prior to being received by the graphics processor, any reordering can result in blending artifacts. It is possible to reduce the occurrence of artifacts by enabling and disabling the PIOR during rendering.",{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 7C","b":["710","150","725","730","150","745"]},"The invention has been described above with reference to specific embodiments. It will, however, be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The foregoing description and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense. The listing of steps in method claims do not imply performing the steps in any particular order, unless explicitly stated in the claim. Within the claims, element lettering (e.g., \u201ca)\u201d, \u201cb)\u201d, \u201ci)\u201d, \u201cii)\u201d, etc.) does not indicate any specific order for carrying out steps or other operations; the lettering is included to simplify referring to those elements."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE VARIOUS VIEWS OF THE DRAWINGS","p":["Accompanying drawing(s) show exemplary embodiment(s) in accordance with one or more aspects of the present invention; however, the accompanying drawing(s) should not be taken to limit the present invention to the embodiment(s) shown, but are for explanation and understanding only.",{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 4","FIG. 2"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIGS. 5A and 5B","FIG. 4"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 6","FIG. 4"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIGS. 7A","FIG. 1"],"b":["7","7"]}]},"DETDESC":[{},{}]}
