---
title: Gesture-based commands for a group communication session on a wireless communications device
abstract: In an embodiment, a user equipment (UE) detects that a user has made a pre-defined gesture that is associated with setting up a group communication session (GCS) with a communication group. The UE transmits a call request message to an application server to request set-up of the GCS. In another embodiment, the UE receives a user input requesting the UE to monitor for gestures by a user of the UE during the GCS. The UE then monitors one or more sensors during the GCS to detect whether the user of the UE has made a pre-defined gesture. In another embodiment, during the GCS, the UE detects that the user has made a pre-defined gesture, maps the detected gesture to a gesture-based command associated with transitioning the UE's floor-holder status and then transmits a request to facilitate the floor-holder status transition to the application server in accordance with the gesture-based command.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08666406&OS=08666406&RS=08666406
owner: QUALCOMM Incorporated
number: 08666406
owner_city: San Diego
owner_country: US
publication_date: 20110512
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY","DETAILED DESCRIPTION"],"p":["1. Field of the Invention","Embodiments relate to gesture-based commands for a group communication session on a wireless communications device.","2. Description of the Related Art","Wireless communication systems have developed through various generations, including a first-generation analog wireless phone service (1G), a second-generation (2G) digital wireless phone service (including interim 2.5G and 2.75G networks) and a third-generation (3G) high speed data\/Internet-capable wireless service. There are presently many different types of wireless communication systems in use, including Cellular and Personal Communications Service (PCS) systems. Examples of known cellular systems include the cellular Analog Advanced Mobile Phone System (AMPS), and digital cellular systems based on Code Division Multiple Access (CDMA), Frequency Division Multiple Access (FDMA), Time Division Multiple Access (TDMA), the Global System for Mobile access (GSM) variation of TDMA, and newer hybrid digital communication systems using both TDMA and CDMA technologies.","The method for providing CDMA mobile communications was standardized in the United States by the Telecommunications Industry Association\/Electronic Industries Association in TIA\/EIA\/IS-95-A entitled \u201cMobile Station-Base Station Compatibility Standard for Dual-Mode Wideband Spread Spectrum Cellular System,\u201d referred to herein as IS-95. Combined AMPS & CDMA systems are described in TIA\/EIA Standard IS-98. Other communications systems are described in the IMT-2000\/UM, or International Mobile Telecommunications System 2000\/Universal Mobile Telecommunications System, standards covering what are referred to as wideband CDMA (W-CDMA), CDMA2000 (such as CDMA2000 1xEV-DO standards, for example) or TD-SCDMA.","In W-CDMA wireless communication systems, user equipments (UEs) receive signals from fixed position Node Bs (also referred to as cell sites or cells) that support communication links or service within particular geographic regions adjacent to or surrounding the base stations. Node Bs provide entry points to an access network (AN)\/radio access network (RAN), which is generally a packet data network using standard Internet Engineering Task Force (IETF) based protocols that support methods for differentiating traffic based on Quality of Service (QoS) requirements. Therefore, the Node Bs generally interacts with UEs through an over the air interface and with the RAN through Internet Protocol (IP) network data packets.","In wireless telecommunication systems, Push-to-talk (PTT) capabilities are becoming popular with service sectors and consumers. PTT can support a \u201cdispatch\u201d voice service that operates over standard commercial wireless infrastructures, such as W-CDMA, CDMA, FDMA, TDMA, GSM, etc. In a dispatch model, communication between endpoints (e.g., UEs) occurs within virtual groups, wherein the voice of one \u201ctalker\u201d is transmitted to one or more \u201clisteners.\u201d A single instance of this type of communication is commonly referred to as a dispatch call, or simply a PTT call. A PTT call is an instantiation of a group, which defines the characteristics of a call. A group in essence is defined by a member list and associated information, such as group name or group identification.","In an embodiment, a user equipment (UE) detects that a user has made a pre-defined gesture that is associated with setting up a group communication session (GCS) with a communication group. The UE transmits a call request message to an application server to request set-up of the GCS. In another embodiment, the UE receives a user input requesting the UE to monitor for gestures by a user of the UE during the GCS. The UE then monitors one or more sensors during the GCS to detect whether the user of the UE has made a pre-defined gesture. In another embodiment, during the GCS, the UE detects that the user has made a pre-defined gesture, maps the detected gesture to a gesture-based command associated with transitioning the UE's floor-holder status and then transmits a request to facilitate the floor-holder status transition to the application server in accordance with the gesture-based command.","Aspects of the invention are disclosed in the following description and related drawings directed to specific embodiments of the invention. Alternate embodiments may be devised without departing from the scope of the invention. Additionally, well-known elements of the invention will not be described in detail or will be omitted so as not to obscure the relevant details of the invention.","The words \u201cexemplary\u201d and\/or \u201cexample\u201d are used herein to mean \u201cserving as an example, instance, or illustration.\u201d Any embodiment described herein as \u201cexemplary\u201d and\/or \u201cexample\u201d is not necessarily to be construed as preferred or advantageous over other embodiments. Likewise, the term \u201cembodiments of the invention\u201d does not require that all embodiments of the invention include the discussed feature, advantage or mode of operation.","Further, many embodiments are described in terms of sequences of actions to be performed by, for example, elements of a computing device. It will be recognized that various actions described herein can be performed by specific circuits (e.g., application specific integrated circuits (ASICs)), by program instructions being executed by one or more processors, or by a combination of both. Additionally, these sequence of actions described herein can be considered to be embodied entirely within any form of non-transitory computer readable storage medium having stored therein a corresponding set of computer instructions that upon execution would cause an associated processor to perform the functionality described herein. Thus, the various aspects of the invention may be embodied in a number of different forms, all of which have been contemplated to be within the scope of the claimed subject matter. In addition, for each of the embodiments described herein, the corresponding form of any such embodiments may be described herein as, for example, \u201clogic configured to\u201d perform the described action.","A High Data Rate (HDR) subscriber station, referred to herein as user equipment (UE), may be mobile or stationary, and may communicate with one or more access points (APs), which may be referred to as Node Bs. A UE transmits and receives data packets through one or more of the Node Bs to a Radio Network Controller (RNC). The Node Bs and RNC are parts of a network called a radio access network (RAN). A radio access network can transport voice and data packets between multiple UEs.","The radio access network may be further connected to additional networks outside the radio access network, such core network including specific carrier related servers and devices and connectivity to other networks such as a corporate intranet, the Internet, public switched telephone network (PSTN), a Serving General Packet Radio Services (GPRS) Support Node (SGSN), a Gateway GPRS Support Node (GGSN), and may transport voice and data packets between each UE and such networks. A UE that has established an active traffic channel connection with one or more Node Bs may be referred to as an active UE, and can be referred to as being in a traffic state. A UE that is in the process of establishing an active traffic channel (TCH) connection with one or more Node Bs can be referred to as being in a connection setup state. A UE may be any data device that communicates through a wireless channel or through a wired channel. A UE may further be any of a number of types of devices including but not limited to PC card, compact flash device, external or internal modem, or wireless or wireline phone. The communication link through which the UE sends signals to the Node B(s) is called an uplink channel (e.g., a reverse traffic channel, a control channel, an access channel, etc.). The communication link through which Node B(s) send signals to a UE is called a downlink channel (e.g., a paging channel, a control channel, a broadcast channel, a forward traffic channel, etc.). As used herein the term traffic channel (TCH) can refer to either an uplink\/reverse or downlink\/forward traffic channel.",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1","b":["100","100","102","104","120","102","126","102","108","110","112","102","108","110","112"]},"Referring back to , the components of the wireless communications system  and interrelation of the elements of the exemplary embodiments of the invention are not limited to the configuration illustrated. System  is merely exemplary and can include any system that allows remote UEs, such as wireless client computing devices , , ,  to communicate over-the-air between and among each other and\/or between and among components connected via the air interface  and RAN , including, without limitation, core network , the Internet, PSTN, SGSN, GGSN and\/or other remote servers.","The RAN  controls messages (typically sent as data packets) sent to a RNC . The RNC  is responsible for signaling, establishing, and tearing down bearer channels (i.e., data channels) between a Serving General Packet Radio Services (GPRS) Support Node (SGSN) and the UEs \/\/\/. If link layer encryption is enabled, the RNC  also encrypts the content before forwarding it over the air interface . The function of the RNC  is well-known in the art and will not be discussed further for the sake of brevity. The core network  may communicate with the RNC  by a network, the Internet and\/or a public switched telephone network (PSTN). Alternatively, the RNC  may connect directly to the Internet or external network. Typically, the network or Internet connection between the core network  and the RNC  transfers data, and the PSTN transfers voice information. The RNC  can be connected to multiple Node Bs . In a similar manner to the core network , the RNC  is typically connected to the Node Bs  by a network, the Internet and\/or PSTN for data transfer and\/or voice information. The Node Bs  can broadcast data messages wirelessly to the UEs, such as cellular telephone . The Node Bs , RNC  and other components may form the RAN , as is known in the art. However, alternate configurations may also be used and the invention is not limited to the configuration illustrated. For example, in another embodiment the functionality of the RNC  and one or more of the Node Bs  may be collapsed into a single \u201chybrid\u201d module having the functionality of both the RNC  and the Node B(s) .",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 2A","FIG. 2A","FIG. 2A"],"b":["126","126","160","165","175","175"]},"Generally, GPRS is a protocol used by Global System for Mobile communications (GSM) phones for transmitting Internet Protocol (IP) packets. The GPRS Core Network (e.g., the GGSN  and one or more SGSNs ) is the centralized part of the GPRS system and also provides support for W-CDMA based 3G networks. The GPRS core network is an integrated part of the GSM core network, provides mobility management, session management and transport for IP packet services in GSM and W-CDMA networks.","The GPRS Tunneling Protocol (GTP) is the defining IP protocol of the GPRS core network. The GTP is the protocol which allows end users (e.g., access terminals) of a GSM or W-CDMA network to move from place to place while continuing to connect to the internet as if from one location at the GGSN . This is achieved transferring the subscriber's data from the subscriber's current SGSN  to the GGSN , which is handling the subscriber's session.","Three forms of GTP are used by the GPRS core network; namely, (i) GTP-U, (ii) GTP-C and (iii) GTP\u2032 (GTP Prime). GTP-U is used for transfer of user data in separated tunnels for each packet data protocol (PDP) context. GTP-C is used for control signaling (e.g., setup and deletion of PDP contexts, verification of GSN reach-ability, updates or modifications such as when a subscriber moves from one SGSN to another, etc.). GTP\u2032 is used for transfer of charging data from GSNs to a charging function.","Referring to , the GGSN  acts as an interface between the GPRS backbone network (not shown) and the external packet data network . The GGSN  extracts the packet data with associated packet data protocol (PDP) format (e.g., IP or PPP) from the GPRS packets coming from the SGSN , and sends the packets out on a corresponding packet data network. In the other direction, the incoming data packets are directed by the GGSN  to the SGSN  which manages and controls the Radio Access Bearer (RAB) of the destination UE served by the RAN . Thereby, the GGSN  stores the current SGSN address of the target UE and his\/her profile in its location register (e.g., within a PDP context). The GGSN is responsible for IP address assignment and is the default router for the connected UE. The GGSN also performs authentication and charging functions.","The SGSN  is representative of one of many SGSNs within the core network , in an example. Each SGSN is responsible for the delivery of data packets from and to the UEs within an associated geographical service area. The tasks of the SGSN  includes packet routing and transfer, mobility management (e.g., attach\/detach and location management), logical link management, and authentication and charging functions. The location register of the SGSN stores location information (e.g., current cell, current VLR) and user profiles (e.g., IMSI, PDP address(es) used in the packet data network) of all GPRS users registered with the SGSN , for example, within one or more PDP contexts for each user or UE. Thus, SGSNs are responsible for (i) de-tunneling downlink GTP packets from the GGSN , (ii) uplink tunnel IP packets toward the GGSN , (iii) carrying out mobility management as UEs move between SGSN service areas and (iv) billing mobile subscribers. As will be appreciated by one of ordinary skill in the art, aside from (i)-(iv), SGSNs configured for GSM\/EDGE networks have slightly different functionality as compared to SGSNs configured for W-CDMA networks.","The RAN  (e.g., or UTRAN, in Universal Mobile Telecommunications System (UMTS) system architecture) communicates with the SGSN  via a Iu interface, with a transmission protocol such as Frame Relay or IP. The SGSN  communicates with the GGSN  via a Gn interface, which is an IP-based interface between SGSN  and other SGSNs (not shown) and internal GGSNs, and uses the GTP protocol defined above (e.g., GTP-U, GTP-C, GTP\u2032, etc.). While not shown in , the Gn interface is also used by the Domain Name System (DNS). The GGSN  is connected to a Public Data Network (PDN) (not shown), and in turn to the Internet , via a Gi interface with IP protocols either directly or through a Wireless Application Protocol (WAP) gateway.","The PDP context is a data structure present on both the SGSN  and the GGSN  which contains a particular UE's communication session information when the UE has an active GPRS session. When a UE wishes to initiate a GPRS communication session, the UE must first attach to the SGSN  and then activate a PDP context with the GGSN . This allocates a PDP context data structure in the SGSN  that the subscriber is currently visiting and the GGSN  serving the UE's access point.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 2B","FIG. 1","FIG. 2B","FIG. 2B","FIG. 2B"],"b":["100","1","120","1","3","120","162","162","188","175","182","184","186","170","2","5","120","164","162","164","188","175","182","184","186","170","4","175","175"]},"Referring to , UEs ,  and  . . . N are illustrated as wireless cell-phones, UE  is illustrated as a wireless tablet-PC and UE  is illustrated as a wired desktop station. However, in other embodiments, it will be appreciated that the wireless communication system  can connect to any type of UE, and the examples illustrated in  are not intended to limit the types of UEs that may be implemented within the system. Also, while the AAA , the provisioning server , the IMS\/SIP registration server  and the application server  are each illustrated as structurally separate servers, one or more of these servers may be consolidated in at least one embodiment of the invention.","Further, referring to , the application server  is illustrated as including a plurality of media control complexes (MCCs)  . . . N B, and a plurality of regional dispatchers  . . . N A. Collectively, the regional dispatchers A and MCCs B are included within the application server , which in at least one embodiment can correspond to a distributed network of servers that collectively functions to arbitrate communication sessions (e.g., half-duplex group communication sessions via IP unicasting and\/or IP multicasting protocols) within the wireless communication system . For example, because the communication sessions arbitrated by the application server  can theoretically take place between UEs located anywhere within the system , multiple regional dispatchers A and MCCs are distributed to reduce latency for the arbitrated communication sessions (e.g., so that a MCC in North America is not relaying media back-and-forth between session participants located in China). Thus, when reference is made to the application server , it will be appreciated that the associated functionality can be enforced by one or more of the regional dispatchers A and\/or one or more of the MCCs B. The regional dispatchers A are generally responsible for any functionality related to establishing a communication session (e.g., handling signaling messages between the UEs, scheduling and\/or sending announce messages, etc.), whereas the MCCs B are responsible for hosting the communication session for the duration of the call instance, including conducting an in-call signaling and an actual exchange of media during an arbitrated communication session.","Referring to , a UE , (here a wireless device), such as a cellular telephone, has a platform  that can receive and execute software applications, data and\/or commands transmitted from the RAN  that may ultimately come from the core network , the Internet and\/or other remote servers and networks. The platform  can include a transceiver  operably coupled to an application specific integrated circuit (\u201cASIC\u201d ), or other processor, microprocessor, logic circuit, or other data processing device. The ASIC  or other processor executes the application programming interface (\u201cAPI\u201d)  layer that interfaces with any resident programs in the memory  of the wireless device. The memory  can be comprised of read-only or random-access memory (RAM and ROM), EEPROM, flash cards, or any memory common to computer platforms. The platform  also can include a local database  that can hold applications not actively used in memory . The local database  is typically a flash memory cell, but can be any secondary storage device as known in the art, such as magnetic media, EEPROM, optical media, tape, soft or hard disk, or the like. The internal platform  components can also be operably coupled to external devices such as antenna , display , push-to-talk button  and keypad  among other components, as is known in the art.","Referring to , UE  further includes a plurality of sensors  . . . N, . The sensors  are coupled to the components of the platform , and are configured to detect one or more pre-defined gestures made with UE  by a user. As used herein, a pre-defined gesture corresponds to one or more actions initiated by a user of the mobile device (e.g., the user flicks his\/her wrist while holding UE , the user places UE  into his\/her pocket or backpack, the user places UE  removes UE  from his\/her pocket or backpack, etc.). The sensors  . . . N  provide sensor measurement data to an API on UE  that is configured to compare the sensor measurement data with a set of sensor data profiles to determine whether the sensor measurement data matches any of the sensor data profiles. As will be described below in more detail, if a match is found, the pre-defined gesture is said to be detected, and a gesture-based command associated with the matching sensor profile can then be executed by UE . The sensor profiles against which the sensor measurement data is compared can either be preset or built-into the API that detects the pre-defined gestures, or alternatively the API can dynamically form new sensor profiles in a \u2018learning\u2019 mode whereby the UE  performs a gesture and the sensors  . . . N  are used to build or generate a sensor profile that corresponds to the gesture made by the user while in learning mode.","In an embodiment, the sensors  . . . N  can include (a) a light sensor, (b) a pressure sensor, (c) a gyroscopic sensor, (d) an accelerometer, (e) a touch-screen proximity sensor, (f) a fingerprint sensor and\/or (g) a haptic sensor. The one or more user-initiated actions can include (a) the user flicks his\/her wrist while holding UE , (b) the user walking or jogging with the UE , (c) the user picking up UE  from a surface or storage location, (d) the user placing UE  onto a surface or into a storage location, (e) the user shakes UE , and\/or (f) a proximity of the user's fingers being close to a display of UE .","Accordingly, an embodiment of the invention can include a UE including the ability to perform the functions described herein. As will be appreciated by those skilled in the art, the various logic elements can be embodied in discrete elements, software modules executed on a processor or any combination of software and hardware to achieve the functionality disclosed herein. For example, ASIC , memory , API  and local database  may all be used cooperatively to load, store and execute the various functions disclosed herein and thus the logic to perform these functions may be distributed over various elements. Alternatively, the functionality could be incorporated into one discrete component. Therefore, the features of the UE  in  are to be considered merely illustrative and the invention is not limited to the illustrated features or arrangement.","The wireless communication between the UE  or  and the RAN  can be based on different technologies, such as code division multiple access (CDMA), W-CDMA, time division multiple access (TDMA), frequency division multiple access (FDMA), Orthogonal Frequency Division Multiplexing (OFDM), the Global System for Mobile Communications (GSM), or other protocols that may be used in a wireless communications network or a data communications network. For example, in W-CDMA, the data communication is typically between the client device , Node B(s) , and the RNC . The RNC  can be connected to multiple data networks such as the core network , PSTN, the Internet, a virtual private network, a SGSN, a GGSN and the like, thus allowing the UE  or  access to a broader communication network. As discussed in the foregoing and known in the art, voice transmission and\/or data can be transmitted to the UEs from the RAN using a variety of networks and configurations. Accordingly, the illustrations provided herein are not intended to limit the embodiments of the invention and are merely to aid in the description of aspects of embodiments of the invention.","Below, embodiments of the invention are generally described in accordance with W-CDMA protocols and associated terminology (e.g., such as UE instead of mobile station (MS), mobile unit (MU), access terminal (AT), etc., RNC, contrasted with BSC in EV-DO, or Node B, contrasted with BS or MPT\/BS in EV-DO, etc.). However, it will be readily appreciated by one of ordinary skill in the art how the embodiments of the invention can be applied in conjunction with wireless communication protocols other than W-CDMA.","In a conventional server-arbitrated communication session (e.g., via half-duplex protocols, full-duplex protocols, VoIP, a group session over IP unicast, a group session over IP multicast, a push-to-talk (PTT) session, a push-to-transfer (PTX) session, etc.), a session or call originator sends a request to initiate a communication session to the application server , which then forwards a call announcement message to the RAN  for transmission to one or more targets of the call.","User Equipments (UEs), in a Universal Mobile Telecommunications Service (UMTS) Terrestrial Radio Access Network (UTRAN) (e.g., the RAN ) may be in either an idle mode or a radio resource control (RRC) connected mode.","Based on UE mobility and activity while in a RRC connected mode, the RAN  may direct UEs to transition between a number of RRC sub-states; namely, CELL_PCH, URA_PCH, CELL_FACH, and CELL_DCH states, which may be characterized as follows:\n\n","Accordingly, URA_PCH State (or CELL_PCH State) corresponds to a dormant state where the UE periodically wakes up to check a paging indicator channel (PICH) and, if needed, the associated downlink paging channel (PCH), and it may enter CELL_FACH state to send a Cell Update message for the following event: cell reselection, periodical cell update, uplink data transmission, paging response, re-entered service area. In CELL_FACH State, the UE may send messages on the random access channel (RACH), and may monitor a forward access channel (FACH). The FACH carries downlink communication from the RAN , and is mapped to a secondary common control physical channel (S-CCPCH). From CELL_FACH State, the UE may enter CELL_DCH state after a traffic channel (TCH) has been obtained based on messaging in CELL_FACH state. A table showing conventional dedicated traffic channel (DTCH) to transport channel mappings in radio resource control (RRC) connected mode, is in Table 1 as follows:",{"@attributes":{"id":"p-0048","num":"0051"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"DTCH to Transport Channel mappings in RRC connected mode"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"42pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"RACH","FACH","DCH","E-DCH","HS-DSCH"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"5","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"5","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"6","colwidth":"42pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["CELL_DCH","No","No","Yes","Yes","Yes"]},{"entry":["CELL_FACH","Yes","Yes","No","Yes (rel. 8)","Yes (rel. 7)"]},{"entry":["CELL_PCH","No","No","No","No","Yes (rel. 7)"]},{"entry":["URA_PCH","No","No","No","No","No"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"In conventional Push-to-Talk (PTT) communication sessions supported upon UEs or cellular telephones, a dedicated PTT button is used to trigger a number of call set-up and in-call functions, such as (i) initiating a PTT call, (ii) answering an announced PTT call, (iii) requesting the floor for a PTT call and\/or (iv) releasing the floor for the PTT call.","While the PTT button is typically implemented as a dedicated physical button, newer phones (e.g., Android-based phones, the iPhone as shown in  at , etc.) are relying more heavily upon touch-screen interfaces. Thus, PTT clients implemented on touch-screen based phones can support the functionality of a dedicated PTT button via a soft-key or touch-screen button. However, these \u2018virtual\u2019 PTT buttons have been found to be less desirable in certain respects as compared to the dedicated physical PTT buttons. For example, power consumption of the UE increases when its display or screen is maintained in an on-state in order to receive indications that the user has pressed the virtual PTT button, the user interface is more cumbersome (e.g., the user must actually look at the UE's display to figure out where the virtual PTT button is positioned instead of simply \u2018feeling\u2019 a tactile physical button with his\/her finger, the user must navigate to a screen where the virtual PTT button is presented, etc.) and there is more latency detecting inputs to a virtual PTT button as compared to a dedicated physical PTT button.",{"@attributes":{"id":"p-0051","num":"0054"},"figref":["FIG. 4","FIG. 4"],"b":["1","1","400","400","1","1","1"]},"Upon selecting the PTT group in , the user of UE  pushes a dedicated or virtual PTT button on UE  to indicate his\/her desire to initiate a PTT session with the selected PTT group, . UE  detects that the user has pressed the PTT button in , and UE  then configures a call message that is configured to request initiation of a PTT session with the selected PTT group by the application server , . UE  sends the call message to the RAN , which then forwards the call message to the application server , . The application server  receives the call message from UE , identifies and locates the target UEs  . . . N associated with the PTT session to be initiated, and then announces the PTT session to the target UEs  . . . N, .","Referring to , assume that at least one of target UEs  . . . N sends a message back to the application server  to acknowledge and accept the announced PTT session, . The application server  sends an indication to UE  that the PTT session is now active or connected and that UE  holds the floor, . UE  begins transmitting media in association with the PTT session in , and the application server  forwards UE 's media to the target UEs  . . . N, .",{"@attributes":{"id":"p-0054","num":"0057"},"figref":["FIG. 5","FIG. 5","FIG. 3"],"b":["1","1","1","1","200","1","1","233","1"]},"Referring to , assume that UE  is operating in a state whereby one or more of sensors  . . . N  are activated and are being used to monitor for gestures by the user of UE , . In an example, UE  may operate in a low-power mode whereby the sensors  . . . N  are active while other components, such as an application processor and\/or a display of UE , are powered down. As noted above, the gestures that are being monitored in  may include (a) the user flicking his\/her wrist while holding UE , (b) the user walking or jogging with the UE , (c) the user picking up UE  from a surface or storage location, (d) the user placing UE  onto a surface or into a storage location, (e) the user shaking UE , and\/or (f) a proximity of the user's fingers being close to a display of UE .","Also, the pre-defined gestures that UE  is configured to detect at  can be either user-defined gestures or preset gestures that are pre-loaded in association with a multimedia application or client configured to manage UE 's PTT sessions. In the case of user-defined gestures, the user of UE  can either select a subset of available preset gestures (more specifically, sensor data profiles corresponding to the gestures) through the multimedia client and select commands to be associated with each gesture in the subset. Alternatively, prior to setting up the PTT session, the user of UE  can engage a learning mode or training mode whereby the user of UE  performs a custom gesture while one or more of sensors  . . . N  are activated. The multimedia client can then generate a sensor data profile of the custom gesture to be associated with a particular gesture-based command (e.g., initiate PTT session with PTT group #, initiate PTT session with currently highlighted or selected PTT group, etc.), and can thereafter compare current sensor measurement data against the sensor data profile to determine when the user makes the custom gesture. Similarly, with respect to the preset or default gestures that are built into the multimedia client, each preset or default gesture can be associated with a particular sensor data profile to be compared against current sensor measurement data to determine when the user makes the preset or default gesture.","Based on the monitoring via the sensors  . . . N  of , UE  determines whether the sensors  . . . N  have detected that the user of UE  has made one of a plurality of pre-defined gestures, . If UE  determines that the user of UE  has not made one of the plurality of pre-defined gestures in , the process returns to  and UE  continues to monitor for a detection of one of the plurality of pre-defined gestures. Otherwise, if UE  determines that the user of UE  has made one of the plurality of pre-defined gestures in , UE  determines a given PTT group that is associated with the detected pre-defined gesture, .","With respect to  of , in an example, the determination of  may be based exclusively upon the detected pre-defined gesture. For example, the pre-defined gesture detected at  may be mapped to a gesture-based command for initiating a PTT session with a particular PTT group, such that the PTT group is determined at  based solely upon the detection (e.g., as opposed to requiring the user to separately select or highlight the PTT group to be called). In another example, the pre-defined gesture detected at  may be mapped to a gesture-based command for initiating a PTT session but may not necessarily be PTT-group specific. In this case, the determination of  may be the result of a secondary PTT group indication. For example, the user of UE  may have already scrolled or highlighted to a particular PTT group and then made the gesture, detected at , in order to trigger UE  to call the highlighted or selected PTT group.","Referring to , after detecting the pre-defined gesture at  and determining the given PTT group to call in , UE  configures a call message to request initiation of a PTT session with the given PTT group by the application server , . UE  sends the call message to the RAN , which then forwards the call message to the application server , . The application server  receives the call message from UE , identifies and locates the target UEs  . . . N associated with the PTT session to be initiated, and then announces the PTT session to the target UEs  . . . N, .","Referring to , assume that at least one of target UEs  . . . N sends a message back to the application server  to acknowledge and accept the announced PTT session, . The application server  sends an indication to UE  that the PTT session is now active or connected and that UE  holds the floor, . UE  begins transmitting media in association with the PTT session in , and the application server  forwards UE 's media to the target UEs  . . . N, .","While  is directed to a process of setting-up or initiating a PTT session based upon a detection of a pre-defined gesture by a user of an originating UE, other embodiments are directed to in-call gesture-recognition so that in-call functions can be controlled by users participating in a PTT session with gestures instead of relying solely upon interaction with a dedicated or virtual PTT button and\/or screen menu. In particular,  illustrates a process of activating in-call gesture-recognition for a PTT session, whereas  illustrate processes by which a user controls floor-transfers via in-call gestures during a PTT session.","Referring to , assume that UE  determines to initiate a PTT session with a given PTT group, . In , similar to , UE  may be configured as discussed above with respect to UE  of , such that UE  is provisioned with sensors  . . . N  which can be used to facilitate a detection of gestures made by the user of UE .","With respect to , the determination of  may correspond to  through  of , such that the determination of  is the culmination of a detection of a pre-defined gesture made by the user of UE , followed by an association or mapping of the detected pre-defined gesture to a particular PTT group. Alternatively, the determination of  may correspond to  through  of , such that the determination of  is the culmination of a conventional dedicated or virtual PTT button-push by the user of UE .","Referring to , after determining to initiate the PTT session with the given PTT group in , UE  configures a call message to request initiation of a PTT session with the given PTT group by the application server , . UE  sends the call message to the RAN , which then forwards the call message to the application server , . The application server  receives the call message from UE , identifies and locates the target UEs  . . . N associated with the PTT session to be initiated, and then announces the PTT session to the target UEs  . . . N, .","Referring to , at some point after the determination of  while the PTT session is being set-up by the application server , UE  presents a prompt to its user for an indication with regard to whether an in-call gesture-recognition function is to be activated at UE , . For example, the prompt of  can correspond to a video, audio, text and\/or vibration output by UE  to the user, which is configured to notify the user to provide input indicative of whether the user desires to activate the in-call gesture-recognition function. For example, the user input can correspond to pressing a touch-screen or physical button associated with turning-on or turning-off the in-call gesture-recognition function. In another example, the user input can correspond to one of a plurality of pre-defined gestures associated with turning-on or turning-off the in-call gesture-recognition function. In this case, UE  may begin monitoring or continue to monitor for gestures as in  of  in conjunction with presenting the prompt to the user in .","In a further example, the user's opportunity to activate the in-call gesture-recognition function may be limited to a window of time during set-up of the PTT session and\/or at the beginning of the PTT session. In this case, UE  may start a timer in conjunction with presenting the prompt at , and in the case that no user input is received in response to the prompt, UE  sets the in-call gesture-recognition function to a default level (e.g., either activated or de-activated). Accordingly, UE  can permit its user a relatively brief opportunity to control whether gesture-based commands will be used by the user of UE  during the PTT session. As will be appreciated, if the in-call gesture-recognition function is activated in an indiscriminate manner, it is possible a user could inadvertently make gestures that were not actually intended to trigger gesture-based commands.","Based on the user input received in response to the prompt of  (or lack thereof), UE  determines whether to activate the in-call gesture-recognition function at UE  for the PTT session at . If UE  determines not to activate the in-call gesture-recognition function at UE  for the PTT session at , the process advances to  of  and the PTT session is conducted by the user of UE  without gesture-based command support. Otherwise, if UE  determines to activate the in-call gesture-recognition function at UE  for the PTT session at , UE  activates the in-call gesture-recognition function in  and the PTT session is conducted by the user of UE  without gesture-based command support.","Referring to , at some point after the application server  announces the PTT session to target UEs  . . . N, assume that at least one of target UEs  . . . N sends a message back to the application server  to acknowledge and accept the announced PTT session, . The application server  sends an indication to UE  that the PTT session is now active or connected and that UE  holds the floor, . UE  begins transmitting media in association with the PTT session in , and the application server  forwards UE 's media to the target UEs  . . . N, .","During the PTT session, UE  monitors for gestures made by the user of UE , , and based on the gesture-monitoring, UE  selectively executes in-call gesture-based commands, . The monitoring that occurs at  may be similar to the monitoring that occurs at  of , except that the monitoring at  occurs in-call whereas the monitoring at  of  occurs during set-up of the PTT session. Examples of the type of gesture-based commands that can be executed during the PTT session, or in-call, at  are described below in more detail with respect to .","Referring to , assume that UE  is participating in a PTT session with target UEs  . . . N, and that UE  is the current floor-holder of the PTT session. Accordingly, UE  transmits media in association with the PTT session in A, and the application server  forwards UE 's media to the target UEs  . . . N, A. In an example, A and A can correspond to media exchanged during a PTT session established in accordance with  and\/or .","While UE  is participating in the PTT session, similar to  of , assume that UE  is operating in a state whereby one or more of sensors  . . . N  are activated and are being used to monitor for pre-defined gestures made by the user of UE , A. As noted above, the pre-defined gestures that are being monitored in A may include (a) the user flicking his\/her wrist while holding UE , (b) the user walking or jogging with the UE , (c) the user picking up UE  from a surface or storage location, (d) the user placing UE  onto a surface or into a storage location, (e) the user shaking UE , and\/or (f) a proximity of the user's fingers being close to a display of UE . While the examples of pre-defined gestures for monitoring provided with respect to  of  are the same as the pre-defined gestures monitored at A, it will be appreciated that the pre-defined gestures monitored for PTT session initiation at  of  need not be the same as the in-call pre-defined gestures monitored at A. In other words, different types of gestures can be used to initiate PTT sessions as compared to gestures that are used to control in-call functions (e.g., floor control, etc.).","Also, similar to  of , the pre-defined gestures that UE  is configured to detect at A can be either user-defined gestures or preset gestures that are pre-loaded in association with a multimedia application or client configured to manage UE 's PTT sessions. In the case of user-defined gestures, the user of UE  can either select a subset of available preset gestures (more specifically, sensor data profiles corresponding to the gestures) through the multimedia client and select commands to be associated with each gesture in the subset. Alternatively, prior to setting up the PTT session, the user of UE  can engage a learning mode or training mode whereby the user of UE  performs a custom gesture while one or more of sensors  . . . N  are activated. The multimedia client can then generate a sensor data profile of the custom gesture to be associated with a particular gesture-based command (e.g., request floor, release floor, change floor status, terminate call, etc.), and can thereafter compare current sensor measurement data against the sensor data profile to determine when the user makes the custom gesture. Similarly, with respect to the preset or default gestures that are built into the multimedia client, each preset or default gesture can be associated with a particular sensor data profile to be compared against current sensor measurement data to determine when the user makes the preset or default gesture.","Based on the monitoring via the sensors  . . . N  of A, UE  determines whether the sensors  . . . N  have detected that the user of UE  has made one of the plurality of pre-defined gestures, A. If UE  determines that the user of UE  has not made one of the plurality of pre-defined gestures in A, the process returns to A and UE  continues to monitor for a detection of one of the plurality of pre-defined gestures while UE  continues its participation in the PTT session as floor-holder. Otherwise, if UE  determines that the user of UE  has made one of the plurality of pre-defined gestures in A, UE  maps the detected pre-defined gesture to a gesture-based command associated with floor-transitions of UE , A.","In A of , UE  determines to release the floor of the PTT session based upon the gesture-based command associated with floor-transitions of UE  at A. In an example, the determination of A can be based upon the gesture-based command corresponding to an explicit indication for UE  to achieve a state whereby UE  is not the floor-holder of the PTT session. In another example, the determination of A can be based upon the gesture-based command corresponding to an indication for UE  to change its current floor-status, such that the determination by UE  to release the floor at A is based both upon the floor-status transition command in conjunction with UE 's current status as floor-holder.","After determining to release the floor in A, UE  sends a message to the RAN  indicating UE 's floor-release request, and the RAN  forwards UE 's floor-release message to the application server , A. The application server  then grants the floor to one of target UEs  . . . N, A. While not shown explicitly in , the floor-grant of A can be based upon a floor-request message from the new floor-holder that is received at the application server  before or after the floor-release message of A. The new floor-holder UE among target UEs  . . . N then begins transmitting media in association with the PTT session in A, and the application server  forwards the new floor-holder UE's media to the UE , A. While not shown explicitly in , if N>2, the application server  may also forward the media from UE  to at least one of target UEs  . . . N other than the new floor-holder UE.",{"@attributes":{"id":"p-0076","num":"0079"},"figref":["FIG. 7B","FIG. 7A","FIG. 7B"],"b":["1","2","2","2","700","170","2","1","705","170","2","3"]},"While UE  is participating in the PTT session, similar to  of , assume that UE  is operating in a state whereby one or more of sensors  . . . N  are activated and are being used to monitor for gestures by the user of UE , B. B is similar to A of , and as such will not be described further for the sake of brevity.","Based on the monitoring via the sensors  . . . N  of B, UE  determines whether the sensors  . . . N  have detected that the user of UE  has made one of the plurality of pre-defined gestures, B. If UE  determines that the user of UE  has not made one of the plurality of pre-defined gestures in B, the process returns to B and UE  continues to monitor for a detection of one of the plurality of pre-defined gestures while UE  continues its participation in the PTT session by monitoring the PTT traffic from UE . Otherwise, if UE  determines that the user of UE  has made one of the plurality of pre-defined gestures in B, UE  maps the detected pre-defined gesture to a gesture-based command associated with floor-transitions of UE , B.","In B of , UE  determines to request the floor of the PTT session based upon the gesture-based command associated with floor-transitions of UE  at B. In an example, the determination of B can be based upon the gesture-based command corresponding to an explicit indication for UE  to achieve a state whereby UE  is the floor-holder of the PTT session. In another example, the determination of B can be based upon the gesture-based command corresponding to an indication for UE  to change its current floor-status, such that the determination by UE  to request the floor at B is based both upon the floor-status transition command in conjunction with UE 's current status as a non-floor-holder. In other words, the pre-defined gesture detected at B can be the same as the pre-defined gesture detected at A of  except for the detection in  occurring while UE  is not the floor-holder.","After determining to request the floor in B, UE  sends a floor request message to the RAN , and the RAN  forwards UE 's floor-request to the application server , B. The application server  then notifies UE  that its floor has been released or revoked, B, and the application server  grants the floor to UE , B. UE  then begins transmitting media in association with the PTT session in B, and the application server  forwards UE 's media to target UEs  . . . N, B. At this point, the process can return to A of  with UE  as floor-holder for the PTT session.","While not shown explicitly in , in-call gesture-based commands need not be limited to invoking a floor-transition. In another embodiment, in-call gesture-based commands can include modifications to volume or other UE-specific call parameters, a command to terminate a particular UE's participation in the PTT session, and so on.","While references in the above-described embodiments of the invention have generally used the terms \u2018call\u2019 and \u2018session\u2019 interchangeably, it will be appreciated that any call and\/or session is intended to be interpreted as inclusive of actual calls between different parties, or alternatively to data transport sessions that technically may not be considered as \u2018calls\u2019. Also, while above-embodiments have generally described with respect to PTT sessions, other embodiments can be directed to any type of communication session, such as a push-to-transfer (PTX) session, a half-duplex session, a full-duplex session, an emergency VoIP call, etc.","Those of skill in the art will appreciate that information and signals may be represented using any of a variety of different technologies and techniques. For example, data, instructions, commands, information, signals, bits, symbols, and chips that may be referenced throughout the above description may be represented by voltages, currents, electromagnetic waves, magnetic fields or particles, optical fields or particles, or any combination thereof.","Further, those of skill in the art will appreciate that the various illustrative logical blocks, modules, circuits, and algorithm steps described in connection with the embodiments disclosed herein may be implemented as electronic hardware, computer software, or combinations of both. To clearly illustrate this interchangeability of hardware and software, various illustrative components, blocks, modules, circuits, and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application, but such implementation decisions should not be interpreted as causing a departure from the scope of the present invention.","The various illustrative logical blocks, modules, and circuits described in connection with the embodiments disclosed herein may be implemented or performed with a general purpose processor, a digital signal processor (DSP), an application specific integrated circuit (ASIC), a field programmable gate array (FPGA) or other programmable logic device, discrete gate or transistor logic, discrete hardware components, or any combination thereof designed to perform the functions described herein. A general purpose processor may be a microprocessor, but in the alternative, the processor may be any conventional processor, controller, microcontroller, or state machine. A processor may also be implemented as a combination of computing devices, e.g., a combination of a DSP and a microprocessor, a plurality of microprocessors, one or more microprocessors in conjunction with a DSP core, or any other such configuration.","The methods, sequences and\/or algorithms described in connection with the embodiments disclosed herein may be embodied directly in hardware, in a software module executed by a processor, or in a combination of the two. A software module may reside in RAM memory, flash memory, ROM memory, EPROM memory, EEPROM memory, registers, hard disk, a removable disk, a CD-ROM, or any other form of non-transitory storage medium known in the art. An exemplary non-transitory storage medium is coupled to the processor such that the processor can read information from, and write information to, the non-transitory storage medium. In the alternative, the non-transitory storage medium may be integral to the processor. The processor and the non-transitory storage medium may reside in an ASIC. The ASIC may reside in a user terminal (e.g., access terminal). In the alternative, the processor and the non-transitory storage medium may reside as discrete components in a user terminal.","In one or more exemplary embodiments, the functions described may be implemented in hardware, software, firmware, or any combination thereof. If implemented in software, the functions may be stored on or transmitted over as one or more instructions or code on a non-transitory computer-readable medium. Non-transitory computer-readable media includes both computer storage media and communication media including any medium that facilitates transfer of a computer program from one place to another. A storage media may be any available media that can be accessed by a computer. By way of example, and not limitation, such computer-readable media can comprise RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other non-transitory medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Also, any connection is properly termed a non-transitory computer-readable medium. For example, if the software is transmitted from a website, server, or other remote source using a coaxial cable, fiber optic cable, twisted pair, digital subscriber line (DSL), or wireless technologies such as infrared, radio, and microwave, then the coaxial cable, fiber optic cable, twisted pair, DSL, or wireless technologies such as infrared, radio, and microwave are included in the definition of medium. Disk and disc, as used herein, includes compact disc (CD), laser disc, optical disc, digital versatile disc (DVD), floppy disk and blu-ray disc where disks usually reproduce data magnetically, while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer-readable media.","While the foregoing disclosure shows illustrative embodiments of the invention, it should be noted that various changes and modifications could be made herein without departing from the scope of the invention as defined by the appended claims. The functions, steps and\/or actions of the method claims in accordance with the embodiments of the invention described herein need not be performed in any particular order. Furthermore, although elements of the invention may be described or claimed in the singular, the plural is contemplated unless limitation to the singular is explicitly stated."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["A more complete appreciation of embodiments of the invention and many of the attendant advantages thereof will be readily obtained as the same becomes better understood by reference to the following detailed description when considered in connection with the accompanying drawings which are presented solely for illustration and not limitation of the invention, and in which:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 2A","FIG. 1"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 2B","FIG. 1"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4","b":"1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIGS. 7A-7B"}]},"DETDESC":[{},{}]}
