---
title: Indexing face templates using linear models
abstract: A novel, linear modeling method to model a face recognition algorithm based on the match scores produced by the algorithm. Starting with a distance matrix representing the pair-wise match scores between face images, an iterative stress minimization algorithm is used to obtain an embedding of the distance matrix in a low-dimensional space. A linear transformation used to project new face images into the model space is divided into two sub-transformations: a rigid transformation of face images obtained through principal component analysis of face images and a non-rigid transformation responsible for preserving pair-wise distance relationships between face images. Also provided is a linear indexing method using the linear modeling method to perform the binning or algorithm-specific indexing task with little overhead.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08331632&OS=08331632&RS=08331632
owner: The United States of America, as represented by the Secretary of the Department of Commerce, the National Institute of Standards and Technology
number: 08331632
owner_city: Washington
owner_country: US
publication_date: 20090213
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","STATEMENT OF GOVERNMENT INTEREST","FIELD OF INVENTION","BACKGROUND","SUMMARY OF INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["This application is a Continuation-in-Part of co-pending U.S. patent application Ser. No. 12\/187,028, filed Aug. 6, 2008; which claims priority to U.S. Provisional Patent Application 60\/954,187, filed Aug. 6, 2007; and this application claims priority to currently pending U.S. Provisional Patent Application No. 61\/065,581, filed Feb. 13, 2008.","This invention was made with Government support under Grant No. DCA200-02-D-5014 awarded by the Department of Homeland Security. The Government has certain rights in the invention.","This invention relates to biometric recognition systems; more specifically, a method of indexing face templates using linear models.","Biometric technologies have become an integral part of many secure access systems. Biometric-based authentication systems are being deployed in both low-risk secure systems, such as laptops and cell phones, and to relatively high-risk secure systems such as military bases and airports. The use of biometric technologies has a number of advantages over password or smartcard-based technologies, such as user convenience, high security, and less fraud. However, like many other authentication technologies, biometric-based systems are also vulnerable to security breaches. The cost of replacing a biometric token or template is higher to that of a password or a smart card, with severe security and privacy implications. The templates can be reused over digital networks or can be used to reproduce synthetic biometric templates such as fake fingers or model faces. In the case of face templates, there is an additional risk that the identity of a person using a biometric access system in a highly secure facility can be revealed. Several sources of security breaches in biometric-based authentication systems have been found. Some countermeasures have also been proposed to nullify such threats and the standardized biometric application programming interface (BioAPI) is continuously updated with countermeasure guidelines such as encrypting templates, avoiding storage and transmission of original templates, and performing quantization of match scores.","In general, most biometric authentication systems have four major modules: a biometric template acquisition sensor, a matching module to compare a new template to an enrolled template, a decision module using predefined thresholds for particular operational points, and a database for enrolled templates (template gallery). In many applications, it is not possible to integrate all these modules into one unit. In such scenarios, the information is passed from one unit to the other through digital channels and\/or stored in digital media for offline processing. Each module possesses different levels of security threats, and different countermeasures are necessary to nullify such threats. For instance, \u2018aliveness\u2019 detection at the sensor unit will detect any attempts to hack the system with synthetic templates. Similarly, a secure database or a secure digital channel will prevent any unauthorized access to templates over a network. In applications, where the matching module and decision module are not integrated together, the \u2018match scores\u2019 must be stored in a digital media or transmitted through a digital channel to a decision module. Security breaches resulting from attacks on match scores can occur in distributed network cluster biometric systems with a central decision unit. Such networks are common in wide-area monitoring contexts.","The dominant approach for a match score-based attack on a biometric system is based on hill climbing. C. Soutar was the first to propose an iterative template adaptation method, popularly known as the hill climbing attack, to break into a biometric system based on match scores. , Secure, vol. 5, p. 46-49 (2002). As shown in , hill-climbing approach 1 attacks the account of a subject, referred to as the targeted subject, by starting from arbitrary face template  and iteratively refining it in operation . Face recognition system (FRS)  outputs match score , which is the distance between arbitrary face template  and target subject . At every iteration, if the modified template results in a better score than the previous match score in operation , then the modified template is retained in operation , or else, it is discarded and the prior template is modified again in operation . The process is iterated until the template is accepted as the targeted subject in operation . With this method, a break-in may be achieved using a final template that does not look like any real face, as long as it deceives the system. In other words, it is not a face reconstruction method but just a break-in strategy.","One countermeasure for the first generation of hill climbing approaches is to quantize the match scores. In this approach, the FRS outputs match scores, but does not alter the match scores with small changes in input images. With appropriate quantization, it is not possible to get the incremental feedback needed by these approaches. Therefore, A. Adler developed a modified hill climbing attack for a face recognition system with quantized match scores using an additional independent set of eigenfaces. , Proc. Canadian Conf. Electrical and Computer Eng., p. 469-472 (May 2004). In Adler's modification, after initializing the process with an arbitrary face template, at every iteration, the previously updated template is multiplied with randomly selected eigenfaces having different weights. This generates templates farther away from the previous template. The face template that results in a better match score is retained as the updated image for the next iteration. The process terminates when there is no further improvement in match scores. Experimental results on a commercial face recognition algorithm show that after nearly 4,000 attempts, a high match score is achieved with 99% confidence. Later, Adler extended this idea to work with encrypted face templates. , Proc. Int'l Conf. Audio and Video-Based Biometric Person Authentication, p. 1100-1109 (July 2005).","Security breaches are possible not only in face biometrics but in other biometric applications also. U. Uludag and A. Jain extended the hill climbing approach to break into minutiae-based fingerprint recognition system. , Proc. SPIE-EI 2004, Security, Steganography and Watermarking of Multimedia Contents, p. 622-633 (January 2004).","Although hill climbing-based attacks can successfully break a particular targeted account, effective countermeasures for such attacks can also be created. One property of hill climbing-based attacks is that they require a large number of attempts before success. Therefore, one possible countermeasure for such attacks is to restrict the number of consecutive, unsuccessful attempts. However, this still leaves the system vulnerable to a spyware-based attack that interlaces its false attempts with attempts by genuine users (successful attempts) and collects information to iterate over a period of time. However, in most hill climbing-based attacks, the templates at the ith attempt (iteration) are generated from the (i\u22121)th attempts (iterations) and are similar to each other. Therefore, if all unsuccessful attempts for a particular targeted account within a fixed time interval are monitored, a pattern of similar faces with decreasing dissimilarity scores will be found. Therefore, a continuous observation of unsuccessful match scores will help to detect hill climbing-based spyware attacks.","Multidimensional Scaling (MDS) has been used to derive models for standard classifiers such as nearest neighborhood, linear discriminant analysis, and linear programming problem from the dissimilarity scores between objects. E. Pekalska, P. Paclik, and R. P. W. Duin, \u201cA generalized kernel approach to dissimilarity based classification,\u201d , vol. 2, pp. 175-211 (2001). A similar framework has also been suggested, where pair-wise distance information is embedded in the Euclidean space, and an equivalence is drawn between several clustering approaches with similar distance-based learning approaches. V. Roth, J. Laub, M. Kawanabe, and J. M. Buhmann, \u201cOptimal cluster preserving embedding of non-metric proximity data,\u201d , vol. 25, no. 12, pp. 1540-1551 (2003). There are also studies that statistically model similarity scores so as to predict the performance of the algorithm on large data sets based on results on small data sets [20]-[23]. P. Wang, Q. Ji, and J. L. Wayman, \u201cModeling and predicting face recognition system performance based on analysis of similarity scores,\u201d , vol. 29, no. 4, pp. 665-670 (2007); S. Mitra, M. Savvides, and A. Brockwell, \u201cStatistical performance evaluation of biometric authentication systems using random effects models,\u201d , vol. 29, no. 4, pp. 517-530 (2007); R. Wang and B. Bhanu, \u201cLearning models for predicting recognition performance,\u201d (), pp. 1613-1618 (2005); and G. H. Givens, J. R. Beveridge, B. A. Draper, and P J Phillips, \u201cRepeated measures glmm estimation of subject-related and false positive threshold effects on human face verification performance,\u201d -p. 40 (2005). For instance, Grother and Phillips proposed a joint density function to independently predict match scores and non-match scores from a set of match scores. P. Grother and P. J. Phillips, \u201cModels of large population recognition performance,\u201d In , pp. 68-75 (2004). Apart from face recognition, methods have been proposed to model and predict performances for other biometric modalities and objects recognition. M. Boshra and B. Bhanu, \u201cPredicting performance of object recognition,\u201d , vol. 22, no. 9, pp. 956-969 (2000) and D. J. Litman, J. B. Hirschberg, and M. Swerts, \u201cPredicting automatic speech recognition performance using prosodic cues,\u201d , pp. 218-225 (2000).","Recently, a method of modeling a face recognition algorithm using an affine transform was developed. P. Mohanty, S. Sarkar, and R. Kasturi, , Proc. IEEE Workshop Face Recognition Challenge (June 2005). Starting from distances computed by any face recognition algorithm, such as the Face Recognition Grand Challenge (FRGC) baseline algorithm, the modeling process calculates the best affine transform that approximates it. The modeling process is a closed-form solution based on classical Multidimensional Scaling (MDS).","Attempts to find vulnerabilities have focused on modifications of the hill-climbing technique; however, these techniques have become identifiable by recognition systems as attacks because of their iterative nature. Discovery of vulnerabilities in recognition systems, therefore, needed to be expanded beyond variations of the hill-climbing technique, in order for countermeasures to be designed to further prevent security breaches resulting from a recognition system's vulnerabilities. Although a process of modeling a face recognition algorithm was available, the process needed modification and improvement to better model the FRS and a method was needed to utilize the improved modeling process to identify vulnerabilities in face recognition systems.","To meet this need, a non-iterative method of reconstructing unknown image templates of biometric systems using match scores was developed. P. Mohanty, S. Sarkar, and R. Kasturi, -, IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 29, No. 12 (December 2007). The non-iterative method is the subject of U.S. patent application Ser. No. 12\/187,028, which is herein incorporated by reference. This method provides a way of reconstructing biometric image templates using the match scores of distinct images from a face recognition system (FRS). When the reconstruction method \u2018breaks in\u2019 to a FRS, it creates no obvious patterns in the match scores, preventing detection by the FRS. Known countermeasures are not effective in preventing security breaches caused by the method, and new countermeasures will be difficult to design because of the absence of an obvious pattern in the match scores.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 2","b":["1","10","10","9","17","17","2","9","10","1","10","10","1"]},"A simplified diagram of reconstruction method  is shown in . A set of face images different from the gallery and probe sets is used as \u2018break-in\u2019 set . Modeling process  creates a model of FRS's  face recognition algorithm. FRS  is treated as a complete black box and no reverse engineering is performed on it. Instead, an assumption is made as to the type of face recognition algorithm used by FRS . It may be possible to identify the recognition algorithm given score matrices of known algorithms, but this is not necessary for the success of reconstruction method .","Modeling process  is an offline procedure and needs to be constructed only once for a given recognition algorithm. Once the model is built, templates are presented from break-in set  to FRS , which calculates match scores  to unknown target template . Unknown target template  represents an enrolled template in the FRS, which when reconstructed results in a successful \u2018break-in\u2019. Embedding process  then uses match scores  to embed unknown target template  in the model. Finally, template construction process  manipulates the model to construct unknown target template .","Although this process of modeling a face recognition algorithm was available, the process needed modification and improvement to more efficiently model the FRS.","The present invention includes a two-fold method of building linear models of an unknown face recognition algorithm. This two-fold modeling method is an improvement over the single pass approach adopted in the prior modeling process. In an embodiment, the method comprises providing a training set (X) comprising a plurality of face images; providing a score matrix (D) containing the scores between pairs of the plurality of face images of the training set; converting the score matrix (D) to an equivalent Euclidean matrix (D); using stress minimization with iterative majorization to determine a set of coordinates for the training set from the equivalent Euclidean matrix (D). A score between a pairs of face images is the distance between the pair of the face images. The scores are produced by the unknown face recognition algorithm. The iterative majorization may be initialized by classical multidimensional scaling.","In another embodiment, the method comprises providing an unknown face recognition algorithm, a training set (X) comprising a plurality of face images, and a score matrix (D) containing the scores between pairs of the plurality of face images; determining if the score matrix (D) is Euclidean; computing the optimal configuration points (Y) from the score matrix (D) using classical multidimensional scaling responsive to the score matrix (D) being Euclidean; converting the score matrix (D) to an equivalent Euclidean matrix (D) responsive to the score matrix (D) being non-Euclidean; and computing optimal configuration points (Y) from the distances contained in the equivalent Euclidean matrix (D) using the initial configuration point (Y) and stress minimization with iterative majorization responsive to the creation of an equivalent Euclidean matrix (D), wherein the initial configuration point (Y) is computed from the equivalent Euclidean matrix (D) using classical multidimensional scaling. A score between a pairs of face images is the distance between the pair of the face images. The scores are produced by the unknown face recognition algorithm.","The present invention also includes a novel indexing mechanism for face templates that results in a reduction in face template comparisons in a face recognition system. The face recognition system contains a face recognition algorithm and a plurality of gallery images. In an embodiment, the method comprises determining a linear model of the recognition system; providing a probe face image; projecting the probe face image into the linear model space; and determining the nearest gallery images. In a another embodiment, the method further comprises comparing the nearest gallery images with the probe face image using the recognition algorithm; and outputting the nearest gallery image to the probe face image.","In the following detailed description of the preferred embodiments, reference is made to the accompanying drawings, which form a part hereof, and within which are shown by way of illustration specific embodiments by which the invention may be practiced. It is to be understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the invention.","Intensive research has produced a diverse set of approaches for face recognition. The approaches differ in terms of the features used, distance measures used, need for training, and matching methods. Systematic and regular evaluations, such as the FERET (Facial Recognition Technology), the FRGC (Face Recognition Grand Challenge), and Face Recognition Vendor Test, have provided the ability to identify the top performing approaches. In general, a face recognition algorithm is a module that computes distance (or similarity) between two face images. These distances (or similarities) are also referred to as match scores.","Previous works try to statistically model the match scores. The present method, in contrast, estimates an analytical model that characterizes the underlying face subspace induced by the algorithm and builds a linear transformation from the original template to this global manifold. In addition, the present method does not place any restrictions on the distribution of scores in the training set such as separation between match score distribution and non-match score distribution. The face recognition algorithm to be modeled is treated as a complete black box.","Previous works also briefly introduced reconstruction method , as shown in  and showed that given such a method, it can be used to reconstruct face templates from match scores. However, the conclusions were contingent on the ability to construct a linear model. This was demonstrated only for three different face recognition algorithms. The present invention focuses on modeling process  of reconstruction method . A novel, two-fold method for building linear models has been developed and is presented here. This two-fold method is more sophisticated than the single pass method presented previously. The two-fold method uses iterative stress minimization using a majorization to minimize the error between algorithmic distance and model distance. The output of the classical multidimensional scaling (MDS) initializes this iterative process. The two-fold methods help to build better, generalizable models. The models are better even if the training set used for the face recognition and that used to learn the linear models are different. The empirical conclusions are also based on a more extensive study of six different recognition algorithms.","The present invention also includes an application to indexing of face templates. This novel indexing method results in a reduction in face template comparisons.","Just as linear systems theory allows the characterization of a system based on inputs and outputs, it was found that a face recognition algorithm can also be categorized based on the distances (the \u201coutputs\u201d) computed between two faces (the \u201cinputs\u201d). A diagram of the modeling problem solved by the present invention is shown in . The present method solves the problem by modeling the distances, dcomputed by any given face recognition algorithm, as a function of the given face images, xand x, which is represented mathematically, by a function \u03c6, such that (d\u2212\u2225\u03c6(x)\u2212\u03c6(x)|)is minimized In particular, affine transforms, as shown in , were used, as they provide the simplest model. The affine model proved to suffice for a number of face recognition algorithms. Essentially, the present method finds a subspace that approximates the face recognition algorithm. The transformation allows for the embedding of a new template, not used for training, into this subspace. Providing a linear subspace approximation has a number of benefits. First, a subspace approximation allows for the characterization of face recognition algorithms at a deeper level than just comparing recognition rates. For instance, if \u03c6 is an identity operator, then it would suggest that the underlying face recognition algorithm is essentially performing a rigid rotation and translation to the face representations similar to principal component analysis (PCA). If \u03c6 is a linear operator, then it would suggest that the underlying algorithms can be approximated fairly well by a linear transformation (rotation, shear, stretch) of the face representations. Given training samples, the objective of the present invention is to approximate the subspace induced by a face recognition algorithm from pair-wise relation between two given face templates. It has been demonstrated experimentally that the modeling method of the present invention works well for template based algorithms as well as feature-based algorithms. In practice, it was found that a linear \u03c6 is sufficient to approximate a number of face recognition algorithms, even feature-based ones.","Second, a linear approximation can used to reconstruct face templates just from scores. This ability was demonstrated by P. Mohanty et al. in \u201cFrom scores to face templates: a model-based approach\u201d. This has serious security and privacy implications.","Third, the linear subspace approximation of face recognition algorithms can be used to build efficient indexing mechanisms for face images. This is particularly important for the identification scenarios where one has to perform one to many matches, especially using a computationally expensive face recognition algorithm. The model-based indexing method of the present invention has several advantages over the two-pass indexing method presented previously. In a two-pass indexing method, a linear projection such as PCA is used to select a few gallery images followed by the identification of the probe image within the selected gallery images. However, the performance of this type of system is limited by the performance of the linear projection method even in the presence of a high performing recognition algorithm in the second pass. Whereas the use of linear model of the original algorithm ensures the selection of few gallery images that match those computed by the original algorithm. The advantage of the present model-based indexing method over the PCA-based modeling method has been experimentally demonstrated using two different face recognition algorithms with more than 1,000 subjects in the gallery set.","\u03c6's that are affine transformations were considered, defining a linear subspace model spanned by, possibly non-orthogonal, vectors. A simplified diagram of the modeling method is shown in . The face recognition algorithm (contained in FRS ) being modeled is treated as a black box. For computational reasons, linear model  is decomposed into two parts: a rigid transformation, which can be obtained by any orthogonal subspace approximation of the rigid model, such as PCA; and a non-rigid, affine transformation. Note that the basis of the overall transformation need not be orthonormal.","To arrive at model  a set of face images (break-in set ) are input into FRS , which computes distances between these face images  using the unknown algorithm. These distances are contained in a matrix D, which undergoes a distance modification in operation  to produce an equivalent Euclidean distance matrix D. Equivalent Euclidean distance matrix D then embedded in model space  by undergoing a stress minimization using iterative majorization initialized by classical MDS in operation . This process results in a set of coordinates for break-in set . The affine transformation defines the relationship between these embedded coordinates and the rigid (PCA) space coordinates.","Modeling Process","Modeling process , illustrated in detail in , is used to model the face recognition algorithm of FRS  using approximating affine transformation . The inversion of this transformation is then used by embedding process  (of ) and template construction process  (of ) to reconstruct unknown target template . The inputs to FRS  are two distinct face templates xand xselected from break-in set  and the output is a match score or distance d  between the two templates.","Typically, a face recognition algorithm of an FRS transforms the given image into a point in a low-dimensional space and then performs a distance measure on this model space. This low-dimensional space is usually constructed by statistical methods such as PCA, linear discriminant analysis (LDA), or independent component analysis (ICA) or constructed out of low-level features detected in the images, such as in the elastic bunch graph matching approach.","The face recognition algorithm of FRS  is unknown to modeling process . Modeling process  models a face recognition algorithm, even feature-based ones, by an affine transformation. Modeling process  finds approximating affine transformation  by combining orthogonal (or rigid) transformation  and non-rigid (shear and stretch) transformation  transformation. Rigid portion  is estimated in operation  by any analysis that computes an orthonormal subspace from break-in set , such as PCA. Non-rigid portion  of transformation  enhances performance of modeling process . Approximating affine transformation  preserves distances  among templates  generated by FRS . Any template can be embedded in space  based on its distance d  from a known set of templates, break-in set .","Modeling process  must determine approximating affine transformation A  such that when given images x's, are transformed to affine space , the euclidean distance between the transformed coordinates of the images are similar to the distances computed by FRS . In this notation, x's are N-dimensional row-scanned representations of the images, and affine transformation A  has dimensions M\u00d7N, with M<N.","(Herein, matrices are denoted by bold capital letters A and column vectors by bold small letters a. The identity matrix is denoted by I, a vector of ones by 1, a vector of zeros by 0, and the transpose of A by A.)","Modeling Process Creation of Dot Product Distance Matrix D","drepresents the distance between two image templates of break in set  xand x, (x\u03b5) as computed by FRS . To create the dot product distance matrix D in operation , the distances dare arranged as a K\u00d7K matrix D=[d], where K is the number of images in break-in set .","This process assumes that FRS  outputs dissimilarity scores  of the two templates. However, if FRS  computes similarities , the similarity scores scan be converted  into distances using a variety of transformations, such as (1\u2212s), \u2212log(s), and",{"@attributes":{"id":"p-0056","num":"0055"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mn":"1","msub":{"mi":["s","ij"]}},"mo":"-","mn":"1."}}},"br":{}},"For some recognition algorithms, the observed dissimilarity matrix D  may not exhibit metric properties. In such cases, distance matrix D  must undergo metric distance conversion. A distance measure d is called a metric if it satisfies the following properties:\n\n","First, examine each of the metric properties more closely on D. Two different templates with little variation always produce a nonzero dissimilarity. Therefore, it can be assumed that the reflexive and positivity properties always hold unless small scores are forcefully suppressed to zero. Even if the scores are rounded off to the nearest number or small scores are suppressed to zero, as long as there is not a sparse distance matrix with few positive entries, an embedding in the model space can be found that can approximate the distance matrix D. Further, the positivity property can be imparted with a simple translation of dissimilarities values to a positive range. Second, if the distance matrix D violates the symmetric property, then this property can be reinstated by replacing D with \u00bd (D+D). Although this simple solution will change the performance of the algorithm, this correction can be viewed as a first-cut fix for the modeling transformation to the algorithms that violates symmetric property of match scores.","Third, if the dissimilarity measure does not satisfy the symmetry and triangle inequality property, if required, then these properties can be imparted if a set of pair-wise distances arranged in complete distance matrix is available.","Any given dissimilarity matrix D may violate the metric property and may not be a Euclidean matrix, i.e. a matrix of distances that violates the triangle inequality. However, if D is not a Euclidean distance matrix, then it is possible to derive an equivalent Euclidean distance matrix Dfrom D. This process is described below.","Modeling Process Euclidean Distance Conversion","The flow chart in  is divided into three blocks (, , and ), which are demarcated by curly braces with comments.","In first block , the original dissimilarity matrix D or a similarity matrix converted to dissimilarity matrix with a suitable function, is tested for the Euclidean property. First, the Eigenvalues of D must be computed in operation . If all Eigenvalues are positive, then the top N Eigen values are kept. It also can be inferred that the face recognition algorithm uses Euclidean distance as the distance measure, so, in this particular case, the Euclidean distance measure can be used in the model space as well.","In many cases, the dissimilarity matrix D may not be euclidean. If the original dissimilarity matrix D is not Euclidean (all Eigenvalues are not positive), then, in blocks  and , those properties of the euclidean distance matrix that are violated by D must be found and those properties reinforced by deriving an approximated Euclidean distance matrix Dfrom D. At this point, the distance measure used by the original algorithm is unknown but it is known that the original distance matrix is not Euclidean, so cosine distance measure is consistently used for such model spaces.","If the Eigenvalues of D are not all positive, then it is determined, in operation , if the negative Eigenvalues are significant. If the negative Eigenvalues are not significant, then approximated Euclidean distance matrix Dis obtained by ignoring the negative eigenvalues and keeping the top N Eigen values.","If the negative Eigenvalue are found to be significant in operation , then matrix D must consist of distances that are metric. If matrix D is not metric, then D is modified, in operation , with an appropriate constant using the following proposition:\n\n","If D was metric or, once D has been modified according to proposition 1.1, then it must be determined, in operation , if D is positive and semi-definite. If not, then D is modified, in operation , with an appropriate constant according to the following theorem:\n\n",{"@attributes":{"id":"p-0067","num":"0072"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["d","ij"]},"mo":"+","mi":"h"}},"mfrac":{"mn":["1","2"]}},"mo":",","mrow":{"mi":["i","j"],"mo":"\u2260"}}}},"br":{},"sub":"n"},{"@attributes":{"id":"p-0068","num":"0073"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mfrac":{"mn":["1","2"]},"mo":"\u2062","mi":"HDH"},{"mrow":[{"mi":["where","H"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"I","mo":"-","mrow":{"mfrac":{"mn":"1","mi":"K"},"mo":"\u2062","msup":{"mn":"11","mi":"T"}}}},"mo":"."}],"mo":"="}],"mo":","}}}},"Once D is positive and semi-definite, the eigenvalues are computed again in operation  and the approximated Euclidean distance matrix Dis obtained by keeping the top N Eigen values.","The dimension of the model space is determined by computing the eigenvalues of the matrix",{"@attributes":{"id":"p-0071","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mn":["1","2"]},"mo":"\u2062","mi":"HDH"}}},"br":{}},{"@attributes":{"id":"p-0072","num":"0077"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mn":["1","2"]},"mo":"\u2062","mi":"HDH"}}},"br":[{},{}],"i":"The Dissimilarity Representation for Pattern Recognition: Foundations and Applications, "},"Given a set of face images (break-in set ) and the pair-wise distances between these images (contained in matrix D ), a point configuration is computed in which these pair-wise distances between the projected points on the low-dimensional subspace are preserved.","Once it has been determined whether a distance conversion was necessary in block  of , then the configuration points must be determined If it is determined, in block , that distance conversion was not necessary, then, in operation , classical MDS, as discussed below, will be used to determine the configuration points y. In this case, classical MDS at the very first iteration will result the best configuration points y. Any subsequent iterative process using stress minimization (as also discussed below) will not result in any improvement and can be skipped.","If it was determined, in block , that the distance conversion was necessary, then, in operation , stress minimization with iterative majorization is used to arrive at a point configuration. Stress minimization with iterative majorization is described in more detail below. Iterative majorization is will converge to an optimal point configuration, or, in some cases, settle down to a point configuration contributing to a local maxima. However, in either case, an informative initial guess will reduce the number of iterations and speed up the process.","Here, iterative majorization was initialized with a set of configuration points) Yderived, in operation , by applying classical MDS on the approximate euclidean distance matrix D. The method of classical multidimensional scaling used was adapted from Cox and Cox. T. Cox and M. Cox, 2nd ed. Chapman and Hall (1994).","Modeling Process Determining Configuration Points\u2014Stress Minimization with Iterative Majorization","The objective is to find a point configuration Y=[y, y, . . . , y] such that the squared error in distances \u03a3(d\u2212\u03b4)is minimized, where dis the distance computed between face template xand xand \u03b4is the Euclidean distance between configuration points yand y. Thus, the objective function can be written as",{"@attributes":{"id":"p-0078","num":"0083"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"min","mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":"\u2264"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mrow":{"msub":{"mi":["w","ij"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","ij"]},{"mi":["\u03b4","ij"]}],"mo":"-"}}},"mn":"2"}}}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}},"br":{},"sub":["ij ","ij ","ij","ij","ij "]},{"@attributes":{"id":"p-0079","num":"0084"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}},{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":"<"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mrow":{"msub":{"mi":["w","ij"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["d","ij"]},{"mi":["\u03b4","ij"]}],"mo":"-"}}},"mn":"2"}}],"mo":"="}}},{"mtd":{"mrow":{"mo":"=","mrow":{"mrow":[{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":"<"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["w","ij"]},"mo":"\u2062","msubsup":{"mi":["d","ij"],"mn":"2"}}},{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":"<"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["w","ij"]},"mo":"\u2062","msubsup":{"mi":["\u03b4","ij"],"mn":"2"}}},{"mn":"2","mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":"<"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":[{"mi":["w","ij"]},{"mi":["d","ij"]},{"mi":["\u03b4","ij"]}],"mo":["\u2062","\u2062"]}}}],"mo":["+","-"]}}}},{"mtd":{"mrow":{"mo":"=","mrow":{"msubsup":{"mi":["\u03b7","d"],"mn":"2"},"mo":["+","-"],"mrow":[{"msup":{"mi":"\u03b7","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}},{"mn":"2","mo":"\u2062","mrow":{"mi":"\u03c1","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}}}]}}}}]}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}},"br":{},"sub":"d","sup":"2 "},{"@attributes":{"id":"p-0080","num":"0085"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"msup":{"mi":"\u03b7","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}},{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":"<"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msup":{"mrow":{"msub":{"mi":["w","ij"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["y","i"]},{"mi":["y","j"]}],"mo":"-"}}},"mi":"T"},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["y","i"]},{"mi":["y","j"]}],"mo":"-"}}}}],"mo":"="}}},{"mtd":{"mrow":{"mo":"=","mrow":{"mi":"tr","mo":"\u2061","mrow":{"mo":["(",")"],"msup":{"mi":["YVY","T"]}}}}}}]}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}},"br":{},"sub":["i j","i j "]},{"@attributes":{"id":"p-0081","num":"0086"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["v","ij"]},"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mrow":[{"mi":"j","mo":"=","mn":"1"},{"mi":["j","i"],"mo":"\u2260"}],"mo":","},"mi":"n"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["w","ij"]},"mo":"."}}}}},"br":{}},{"@attributes":{"id":"p-0082","num":"0087"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mi":"\u03c1","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}},{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":"<"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mfrac":{"mrow":{"msub":[{"mi":["w","ij"]},{"mi":["d","ij"]}],"mo":"\u2062"},"msub":{"mi":["\u03b4","ij"]}},"mo":"\u2062","msubsup":{"mi":["\u03b4","ij"],"mn":"2"}}}],"mo":"="}}},{"mtd":{"mrow":{"mo":"=","mrow":{"munder":{"mo":"\u2211","mrow":{"mi":["i","j"],"mo":"<"}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mfrac":{"mrow":{"msub":[{"mi":["w","ij"]},{"mi":["d","ij"]}],"mo":"\u2062"},"msub":{"mi":["\u03b4","ij"]}},"mo":["\u2062","\u2062"],"msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["y","i"]},{"mi":["y","j"]}],"mo":"-"}},"mi":"T"},"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["y","i"]},{"mi":["y","j"]}],"mo":"-"}}}}}}},{"mtd":{"mrow":{"mo":"=","mrow":{"mi":"Tr","mo":"(","mrow":{"mrow":[{"mi":"YU","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Y"}},{"mo":["(",")"],"msup":{"mi":["Y","T"]}}],"mo":"\u2062"}}}}}]}},{"mrow":{"mo":["(",")"],"mn":"4"}}]}}}},"br":{},"sub":"i j"},{"@attributes":{"id":"p-0083","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["u","ij"]},"mo":"=","mrow":{"mo":"{","mrow":{"mrow":[{"mtable":{"mtr":[{"mtd":[{"mrow":{"mfrac":{"mrow":{"mrow":{"mo":"-","msub":{"mi":["w","ij"]}},"mo":"\u2062","msub":{"mi":["d","ij"]}},"msub":{"mi":["\u03b4","ij"]}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mi":"if"}},{"mrow":{"mi":["d","j"],"mo":["\u2260","\u2260"],"mrow":{"mn":"0","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":["and","i"]}}}]},{"mtd":[{"mn":"0"},{"mi":"otherwise"}]}]},"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}},"msub":{"mi":["u","ij"]}},{"munder":{"mo":"\u2211","mrow":{"mrow":[{"mi":"j","mo":"=","mn":"1"},{"mi":["j","i"],"mo":"\u2260"}],"mo":","}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["u","ij"]}}],"mo":"="}}}}},"br":[{},{}],"in-line-formulae":[{},{}],"i":["S","Y","+Tr","YVY","Tr","YU","Y","Y"],"sub":"d","sup":["2","T","T"]},"The configuration points Y can be found by maximizing S(Y) in many different ways. Here, the iterative majorization algorithm proposed by Borg and Groenen was considered. I. Borg and P. Groenen, . Springer Series in Statistics, Springer, (1997). Let,\n\n()=\u03b7()\u22122(())\u2003\u2003(6)\n\nthen T\u2267S and T(Y,Y)=S(Y), hence T(Y,Z) majorizes S(Y). So the optimal set of configuration points Y can be found as follows\n",{"@attributes":{"id":"p-0085","num":"0090"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":{"mrow":{"mfrac":{"mi":["\u03b4T","\u03c3Z"]},"mo":"=","mn":"0"}}},{"mtd":{"mrow":{"mrow":{"mrow":[{"mn":"2","mo":"\u2062","mi":"VY"},{"mn":"2","mo":["\u2062","\u2062"],"mrow":{"mi":"U","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"Z"}},"msup":{"mi":["Z","T"]}}],"mo":"-"},"mo":"=","mn":"0"}}}]}}},"br":{}},"Thus, the iterative formula to arrive at the optimal configuration points can be written as follows\n\n()()\u2003\u2003(8)\n\nwhere, Yis the initial configuration points and V represent the pseudo-inverse of V.\n\nModeling Process Determining Configuration Points\u2014Initial Point\u2014MDS\n","Given the equivalent Euclidean distance matrix D, here the objective is to find K vectors, {y, . . . , y} such that\n\n()=()())\u2003\u2003(9)\n","Eq. 9 can be compactly represented in matrix form as\n\n1+1\u22122\u2003\u2003(10)\n\nwhere Y is matrix constructed using the vectors yas the columns Y=[y, . . . , y] and c is a column vector of the magnitudes of the vectors y's. Thus,\n\n]\u2003\u2003(11)\n","Note that the above configuration points y's are not unique. Any translation or rotation of vectors y's can also be a solution to Eq. 9. To reduce such degrees of freedom of the solution set, constrain the solution set of vectors to be centered at the origin and the sum of the vectors to zero, i.e. \u03a3y=0. To simplify Eq. 10, pre- and post-multiply each side of the equation by centering matrix H=(I1K11T), which gives",{"@attributes":{"id":"p-0090","num":"0095"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"B","mo":"=","mrow":{"mrow":[{"mrow":{"mo":"-","mfrac":{"mn":["1","2"]}},"mo":["\u2062","\u2062"],"msub":{"mi":["HD","E"]},"mi":"H"},{"msup":{"mi":["Y","T"]},"mo":"\u2062","mi":"Y"}],"mo":"="}}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}}},"Because Dis Euclidean matrix, the matrix B is represents the inner product between the vectors, y, and is a symmetric, positive semi-definite matrix. Solving Eq. 12 yields the initial configuration points as",{"@attributes":{"id":"p-0092","num":"0097"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msup":[{"mi":"Y","mrow":{"mo":["(",")"],"mn":"0"}},{"mrow":{"mo":["(",")"],"mrow":{"msubsup":{"mi":["V","EVD","M"]},"mo":"\u2062","msup":{"msubsup":{"mi":["\u0394","EVD","M"]},"mrow":{"mn":["1","2"],"mo":"\/"}}}},"mi":"T"}],"mo":"="}}},"br":[{},{},{}],"sup":["M","M"],"sub":["EVD ","EVD "]},"So far, it has been shown how to find a set of coordinates, Y, such that the Euclidean distance between these coordinates is related to the distances computed by the recognition algorithm by an additive constant. An affine transformation, A, is now found that will relate these coordinates, Y, to the images, X, such that\n\n(\u2212\u03bc)\u2003\u2003(14)\n\nwhere \u03bc is the mean of the images in training set, i.e. average face. This transformation is not restricted to be orthonormal or rigid. A is considered to be composed of two sub-transformations: non-rigid transformation Aand rigid transformation rigid, A, i.e., A=AA. The rigid part Acan be arrived at by any analysis that computes an orthonormal subspace from the given set of training images. In this experiment, PCA is used for the rigid transformation. Let the PCA coordinates corresponding to the non-zero eigenvalues, i.e. non-null subspace, be denoted by X=A(X\u2212\u03bc). The non-rigid transformation, A, relates these rigid coordinates, Xto the distance based coordinates, Y. From Eq. 14\n\n\u2003\u2003(15)\n","Multiplying both sides of Eq. 15 by Xand using the result that XX=\u039b, where \u039bis the diagonal matrix with the non-zero eigenvalues computed by PCA, gives\n\n\u039b\u2003\u2003(16)\n","This non-rigid transformation allows for shear and stress, and the rigid transformation, computed by PCA, together model the face recognition algorithm. Note that the rigid transformation is not dependent on the face recognition algorithm; it is only the non-rigid part that is determined by the distances computed by the recognition algorithm. An alternative viewpoint could be that the non-rigid transformation captures the difference between a PCA recognition algorithm.","Modeling Process Summary of Method",{"@attributes":{"id":"p-0096","num":"0000"},"ul":{"@attributes":{"id":"ul0007","list-style":"none"},"li":{"@attributes":{"id":"ul0007-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0008","list-style":"none"},"li":["Input: a break-in set containing K face images","Determine the dissimilarity\/Similarity matrix D computed on the training using the face recognition algorithm","Check if D is Euclidean and, if necessary, convert to an equivalent Euclidean distance matrix D.","Compute initial configuration points Y","Use the iterative method in Eq. 8 to arrive at the final configuration points. The iteration is terminated when the error S(Y) is less than the tolerance parameter \u03b5, which is empirically set to 0.001 in these experiments.","Compute the rigid sub-transformation Ausing PCA on training set.","Compute the non-rigid sub-transformation A, as shown in Eq. 16.","A=AAis the required model affine transformation.\n\nVerification\u2014Experimental Setup\n"]}}}},"The accuracy of the present linear modeling method was evaluated using six fundamentally different face recognition algorithms and recognition performances of each of these algorithms was compared with corresponding models. The consistency of the linear modeling method was demonstrated on FERET face data sets. The following provides more details about the face recognition algorithms and the distance measures associated with these algorithms, the train sets, and the test sets used in the experiments and the metrics used to evaluate the strength of the purposed modeling method.","Experimental results, presented below, validate that the present linear modeling method generalizes across probe sets representing different variations in face images (FERET probe sets). It is also demonstrated that different distance measures coupled with the PCA algorithm, and normalization of match scores, have minimal impact on the present modeling approach.","Verification\u2014Experimental Setup: Data Sets","The FERET data set, used in this experiment, is publicly available and equipped with pre-defined training, gallery, and probe sets commonly used to evaluate face recognition algorithms. The FERET data set contains 1,196 distinct subjects in the gallery set. A subset of the FRGC training set containing 600 images from the first 150 subjects (increasing order of id) was used to train the present model. This data set was collected at a later date, at a different site, and with different subjects than FERET. Thus, there is a strong separation of train and test set.","Verification\u2014Experimental Setup: Face Recognition Algorithms & Distance Transformation","The present modeling method was evaluated with four different template-based algorithms and two feature-based face recognition algorithms. The template-based approaches include (PCA), Independent Component Analysis (ICA), Linear Discriminant Analysis (LDA), and Bayesian Intrapersonal\/Extrapersonal Classifier (BAY). Note that the BAY algorithm employs two subspaces to compute the distance. A proprietary algorithm (PRP) and Elastic Bunch Graph Matching (EBGM) algorithm were selected to represent the feature-based recognition algorithms. All of the face images used in this experiment, except for EBGM algorithm, were normalized geometrically using the Colorado State University (CSU) Face Identification Evaluation System to have the same eye location, the same size (150\u00d7130) and similar intensity distribution. The EBGM algorithm requires a special normalization process for face images that is manually very intensive. So, the training set that is provided with the CSU data set was used to train the model for the EBGM algorithm. This training set is part of the FERET data set, but different from the probe set used in the experiments.","The six face recognition algorithms and the distance measures associated with each of these algorithms are summarized in the table in . Except for the proprietary and the ICA algorithms, the implementation of all other algorithms are publicly available at Colorado State University (CSU) Face Identification Evaluation System. The implementation of the ICA algorithm has been adapted from M. Bartlett. , Kluwer Academic Publishers (2001). The particular distance measures for each of these algorithms are selected due to their higher recognition rates compared to other possible choices of distance measures. The last two columns in the table in  indicate the range of the similarity\/dissimilarity scores of the corresponding algorithms and the transformation used to convert these scores to a range such that the lower range of all the transformed distances are the same (i.e. the distance between two similar face images are close to 0). The distance measure for the Bayesian Intrapersonal\/Extrapersonal Classifier is a probability measure but due to the numerical challenges associated with small probability values, the distances are computed as the approximations to such probabilities. In addition to the above transformations, the distance between two exact images is set to zero in order to maintain the reflexive property of the distance measure. All of the above-mentioned distance measures also exhibit the symmetric property; thus, no further transformation is required to enforce the symmetric property of the distance measure.","Verification\u2014Experimental Setup: Train and Test Sets","With the exception of the proprietary algorithm, all of the algorithms require a set of face images for the algorithm training process. This training set is different from the training set required to model the individual algorithms. Therefore, two training sets are defined; an algorithm train set (algo-train) and a model train set (model-train). A set of 600 controlled images from 150 subjects (in the decreasing order of their numeric id) from the FRGC training set was used to train the individual algorithms (algo-train). To build the linear model for each algorithm, another subset of the FRGC training set with 600 controlled images from the first 150 subjects (in the increasing order of their numeric id) with four images per subjects (model-train) was used. Due to limited number of subjects in the FRGC training set, few subjects appear in both the training sets; however, there are no common images in algo-train and model-train set. The feature-based EBGM algorithm differs from other algorithms with a special normalization and localization process of face images and requires manual landmark points on the training images. This process is susceptible to errors and needs to be done carefully. So, instead of creating custom ground truth features on a new data set for the EBGM algorithm, the FERET training set containing 493 images provided in the CSU face evaluation system including the special normalized images required for EBGM algorithm was used. The algo-train and the model-train for EBGM algorithm are the same.","The proprietary algorithm does not require any training images. However, while building a model for the proprietary algorithm, it was empirically observed that the performance of the linear model demonstrates higher accuracy on the FERET probe sets when the model is trained (model-train) on the FERET training set. In the result section below, the performance of the linear model with the proprietary algorithm with these two different model-train sets is demonstrated.","To be consistent with other studies, for test sets, the gallery set and four different probe sets as defined in the FERET data set were selected. The gallery set contains 1,196 face images of 1,196 subjects with neutral or minimal facial expression and with frontal illumination. Four sets of probe images (fb, fc, dupI, dupII) were created to verify the recognition performance under four different variations of face images. If the model is correct, the algorithm and model performances should match for all of these probe conditions. The \u2018fb\u2019 set contains 1,195 images from 1,195 subjects with different facial expression than gallery images. The \u2018fc\u2019 set contains 194 images from 194 subjects with different illumination conditions. Both \u2018fb\u2019 and \u2018fc\u2019 images are captured at the same time as that of gallery images. However, 722 images from 243 subjects in probe set \u2018dupI\u2019 are captured between 0 to 1,031 days after the gallery images were captured. Probe set \u2018dupII\u2019 is a subset of probe set \u2018dupI\u2019 containing 234 images from 75 subjects, which were captured at least one and a half year after the gallery images. The above-mentioned numbers of images in probe and gallery sets are pre-defined within the FERET distribution.","Verification\u2014Experimental Setup: Performance Measures to Evaluate the Linear Model","The recognition rates of the algorithms were compared with recognition rates of the linear models in terms of standard Receiver Operating Characteristic (ROC). Given the context of biometrics, this is a more appropriate performance measure than the error in individual distances. How close is the performance of the linear model to that of the actual algorithm on image sets that are different from the train set?","In addition to comparison of ROC curves, the Error in Modeling measure was used to quantify the accuracy of the model at a particular False Acceptance Rate (FAR). The Error in the modeling was computed by comparing the True Positive Rate (TPR) of the linear model with the TPR of the original algorithm at a particular False Positive Rate (FAR).",{"@attributes":{"id":"p-0107","num":"0119"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["Error","in","Modeling"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":{"mo":["(",")"],"mi":"%"}},{"mfrac":{"mrow":[{"mi":"abs","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["TPR","orig"]},{"mi":["TPR","model"]}],"mo":"-"}}},{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["TPR","orig"]},{"mi":["TPR","model"]}],"mo":","}}}]},"mo":"\u00d7","mn":"100"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"17"}}]}}}},"br":{}},"The approximating linear manifold, a stronger metric, Nearest Neighbor Agreement, was examined to quantify the local neighborhood similarity of face images in approximating subspace with the original algorithm. For a given probe P, let Gbe the nearest subject as computed by the algorithm and Gbe the nearest subject based on the linear model. Let,",{"@attributes":{"id":"p-0109","num":"0121"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["s","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["G","i"]},{"mi":["G","j"]}],"mo":","}}},{"mo":"{","mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mi":"if"},{"mrow":{"mn":"1","mo":"=","mi":"j"}}]},{"mtd":[{"mn":"0"},{"mi":"otherwise"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}]}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0110","num":"0122"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"S","mo":"=","mrow":{"mrow":{"mo":["(",")"],"mrow":{"mfrac":{"mn":"1","mi":"P"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"P"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["s","k"]}}}},"mo":"\u00d7","mn":"100"}}}},"br":[{},{}]},"Presented here are the experimental results of the present linear method applied to the six different face recognition algorithms using the FERET probe sets. Using the metrics defined in previous section, the strength of the linear model on FERET data set is demonstrated with complete separation of training and test sets. The experimental results show that the average Error in Modeling for six algorithms is 6.3% for the fafb probe set, which contains a maximum number of subjects among all the four probe sets. It was also observed that the present linear model exhibits an average of 87% accuracy when measured for the similar neighborhood relationship with the original algorithm. A detailed analysis and explanation of these results is presented in the following sub-sections.","Verification\u2014Results: Recognition Performances","Performance of each for the six face recognition algorithms was demonstrated in a series of plots, which are not reproduced here. From these plots, it could be seen that the ROC's matched closely. Not only the recognition performance of the model matched with that of the original algorithm, but it also generalized to the variations in face images represented by the different probe sets. For example, the performance of ICA algorithm in fafc was lower as compared to the rest of the algorithms and the modeling performance was also lower for the ICA algorithm which was a good indication of an accurate model of the underlying algorithm. Similar performances was also observed in the cases of LDA and BAY algorithms. This is evidence of the generalizability of the learnt model across different conditions.","Also, for fafb probe set, the error in the modeling of all the algorithms at 0.001 FAR are 3.8%, 7%, 9%, 5%, 4% and 26% for PCA, LDA, ICA, BAY, EBGM and PRP algorithms, respectively. The high error rate for the PRP algorithm indicates that the linear model for PRP algorithm is under-trained. Note that, the training set used for the proprietary algorithm or the score normalization techniques adapted to optimize the performances are unknown. The performance of the PRP algorithm on four FERET probe sets and the performance of the linear model trained using the FERET training set were also determined. With the FERET training set, the Error in modeling for PRP algorithm in fa-fb probe set is reduced to 13%, and with the normalization process, the error in modeling for the proprietary algorithm is further reduced to 9%. The effect of score normalization on the present modeling method is discussed below.","Verification\u2014Results: Local Manifold Structure",{"@attributes":{"id":"p-0114","num":"0126"},"figref":"FIG. 9"},"Verification\u2014Results: Effect of Distance Measures and Score Normalization","Different face recognition algorithms use different distance measures and, in many cases, the distance measure is unknown and non-Euclidean in nature. In order to study the effect of various distance measures on the present modeling method, the PCA algorithm was used with six different distance measures as mentioned in the first column of the table in . For a stronger comparison, all other parameters, such as the training set and dimension of the PCA space, were kept the same; only the distance measure was changed. These distance measures are implemented in the CSU face evaluation tool. In the table of , the Error in Modeling (see Eqn. 17) for the PCA algorithm is presented with different distance measures on the FERET fafb probe set. Note that, as described in , except for PCA+Euclidean distance, the model uses cosine distance for all other cases. From the table, for different distance measures, the Error in Modeling is on the magnitude of 10% or less. Thus, it is apparent that different distance measures have minimal impact on the present modeling method.","Biometric match scores are often augmented with some normalization procedures before compelled to a threshold-based decision. Most of these score normalization techniques are often carried out as a post processing routine and do affect the underlying manifold of the faces as observed by the face recognition algorithms. The most standard score normalization techniques used in biometric applications are Z-normalization and Min-Max normalization. To observe the impact of normalization on the modeling method, the proprietary algorithm was used with min-max and z-normalization techniques. This is over and above any normalization that might exist in the propriety algorithm, about which there was no information available. The normalization methods were applied on impostor scores. Note that, in this case, the normalization techniques are considered as part of the black box algorithm. As a result, the match scores used to train the model are also normalized in the similar way. The recognition performance of the proprietary algorithm with score normalization to that of modeling method were compared. The score normalization process is a post processing method and does not reflect the original manifold of the face images. The same score normalization techniques were applied to match scores of the model. The difference between the algorithm with normalized match score and the model with the same normalization of match scores is small.","An Application: Indexing Face Databases","In the identification scenario, one has to perform one to many matches to identify a new face image (query) among a set of gallery images. In such scenarios, the query image needs to be compared to all the images in the gallery. Consequently, the response time for a single query image is directly proportional to the gallery size. The entire process is computationally expensive for large gallery sets. One possible approach to avoid such expensive computation and to provide faster response time is to index or bin the gallery set. In the case of well-developed biometrics such as fingerprints, a binning process based on ridge patterns such as whorl loop and arches is used for indexing. For other biometrics where a template is represented by a set of d-dimensional numeric features, Mhatre et al. proposed a pyramid indexing technique to index the database. A. Mhatre, S. Palla, S. Chikkerur, and V. Govindaraju, \u201cEfficient search and retrieval in biometric databases\u201d,\u201d , vol. 5779, pp. 265-273 (2005). Unfortunately, for face images, there is no straightforward and global solution to bin or index face images. As different algorithms use different strategies to compute the template or features from face images, a global indexing strategy is not feasible for face images. For example, Bayesian intra\/extra class approach computes the difference image of the probe template with all the gallery templates; a feature based indexing method is not applicable for this algorithm.","In the present indexing method, the linear modeling method, as described above, is used to model a face recognition algorithm and the linear model is then used to perform binning or an algorithm-specific indexing task, with little or no overhead in computation. A probe image is then projected into the linear model space and the k-nearest gallery images are determined. Then the original face recognition algorithm is used to match the k-selected gallery image with probe image and output the rank of the probe image. Note that, for a perfect indexing, a system with indexing and without indexing will produce the same top-k subjects. A linear projection method, such as PCA, is an example of such first pass pruning method.","The recognition performance of the original algorithm should be better than the first pass linear projection method. Otherwise, the use of a computationally expensive algorithm in the second pass is redundant. Also, if the performance of the first pass algorithm is significantly less than the original algorithm, then the k-gallery images selected by the linear algorithm may not include the nearest gallery images to the probe images as observed by the original algorithm. In this case, the overall identification rate of the system will fall. To minimize this error, the value of k needs to be high, which in turn, reduces the advantages of using an indexing mechanism.","On the other hand, because the linear model approximates the underlying algorithm quite well, it is expected that that basing an indexing method around it should result in a better indexing mechanism. The computation complexity for the modeling method and any other linear projection based indexing method such as PCA is similar, except the training process, which can be done off-line. Of course, for algorithms such as PCA, LDA, and ICA which use the linear projection of raw template, this type of indexing mechanism will result in no additional computational advantage. However, for algorithms such as the Bayesian and EBGM, where numerical indexing of template is not feasible, indexing through a linear model can reduce the overall computational complexity by selecting only a subset of gallery images to be matched with a probe image. In this section, the indexing method of the present invention was demonstrated using the linear method of the present invention and compared with an indexing method based on PCA, coupled with Euclidean distance. The choice of Euclidean distance instead of Mahalanobis distance is to demonstrate the indexing scenario when the first pass linear projection algorithm has lower performance than the original algorithm.","To evaluate the error in the indexing method, the difference in rank values was used for a given probe set with and without the indexing method. If the model extracts the same k nearest gallery image as by the original algorithm, then the rank of a particular probe will not change with the use of the indexing procedure. In such cases, the identification rate at a particular rank will remain the same. However, if the k-nearest gallery subjects selected by the model do not match with the k nearest subjects selected by the original algorithm, then identification rate at a particular rank will decrease. The error in indexing is computed as follows",{"@attributes":{"id":"p-0122","num":"0134"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["E","r"]},"mo":"=","mfrac":{"mrow":{"mi":"max","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["I","r"]},"mo":"-","mover":{"mi":"I","mo":"~"}}}},"msub":{"mi":["I","r"]}}}}},"br":{},"sub":["r ","r ","r ","r ","r"],"figref":["FIGS. 11 and 12","FIGS. 11A and 12A"]},"For the model-based indexing method, the value of the indexing parameter for the Bayesian algorithm is as low as 8 with error in indexing equals to 0.01%. As a result, with the help of the present indexing method, the Bayesian algorithm requires at most eight comparisons to achieve similar rank-1 performance as compared to using the complete gallery set, which requires 1,195 comparison in the case of the FERET-fafb probe set. Similarly, for the other two algorithms, at most 50 comparisons are sufficient to achieve similar identification performance at 0.01% error rate for rank-1 as well as rank-5 identification performances. With this indexing method, the response time is reduced by a factor of",{"@attributes":{"id":"p-0124","num":"0136"},"maths":{"@attributes":{"id":"MATH-US-00019","num":"00019"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mfrac":[{"msub":[{"mi":["C","a"]},{"mi":["C","m"]}]},{"mi":["k","N"]}],"mo":"+"},"mo":","}}},"br":{},"sub":["a ","m ","a","m"]},{"@attributes":{"id":"p-0125","num":"0137"},"maths":{"@attributes":{"id":"MATH-US-00020","num":"00020"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"msub":[{"mi":["C","a"]},{"mi":["C","m"]}]},"mo":"+","mrow":{"mfrac":{"mi":["k","N"]},"mo":"\u2062","mrow":{"mo":"<<","mn":"1."}}}}},"br":{},"sub":["a","m"]},"In case of PCA-based indexing mechanism, a high variation in value of indexing parameter k can be observed. The indexing performance of PCA-based indexing mechanism on FERET fafb probe set for the Bayesian and EBGM algorithm is consistent with that of linear modeling index method. However, in all other cases, particularly in the case of PRP algorithm, the value of k was observed to be very high due to significant performance different between the PCA and the PRP algorithm. Similar values of k are observed even if the Mahalanobis distance is used instead of Euclidean distance for PCA-based indexing method with PRP algorithm as well. For the PRP algorithm on FERET-fafb probe set, the values of k are 2 (5), 48 (52), 198 (199) and 272 (298) for rank-1 and rank-5 error rates respectively, using indexing with PCA with Mahalanobis distance measure as the first pass pruning method. Similarly, FERET-fafb probe set, the values of k are 2 (8), 20 (44), 26(56) and 28 (57) for rank-1 and rank-5 error rates respectively. These results validate the advantages of using a linear model instead of any arbitrary linear projection method for selecting the k-nearest gallery images in the first pass.","It will be seen that the advantages set forth above, and those made apparent from the foregoing description, are efficiently attained and since certain changes may be made in the above construction without departing from the scope of the invention, it is intended that all matters contained in the foregoing description or shown in the accompanying drawings shall be interpreted as illustrative and not in a limiting sense.","It is also to be understood that the following claims are intended to cover all of the generic and specific features of the invention herein described, and all statements of the scope of the invention which, as a matter of language, might be said to fall there between."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["For a fuller understanding of the invention, reference should be made to the following detailed description, taken in connection with the accompanying drawings, in which:",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 4B"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 11A"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 11B"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 12A"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 12B"}]},"DETDESC":[{},{}]}
