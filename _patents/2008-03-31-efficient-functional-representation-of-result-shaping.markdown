---
title: Efficient functional representation of result shaping
abstract: A result shaping methodology is part of a bridge (translation layer) between an entity provider and an underlying store provider. The bridge accepts command trees and parameter values from a consumer (e.g., the entity provider), reshapes the trees as necessary for its underlying store provider to execute, executes resulting commands, and assembles the results from the commands into the nested data reader that the initial command tree requested. The result assembly advantageously takes a mapping declaration and compiles it into a set of expression definitions composed from a small number of simple functions. Each collection in the result has a corresponding expression describing how collection elements are realized given relational results. Other expressions describe boundary detection behavior. These expressions are compiled into functions used to shape relational data into arbitrary object graphs or streaming interfaces. Alternative versions of the expressions for performance or graceful contextual error handling are also compiled.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08209340&OS=08209340&RS=08209340
owner: Microsoft Corporation
number: 08209340
owner_city: Redmond
owner_country: US
publication_date: 20080331
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["More and more frequently, computers are being used to perform various information location and retrieval tasks. Commonly, these information location and retrieval tasks have primarily been in the domain of specialized applications that have been constructed to perform queries against a relational database using a specialized query language. Among the most common of such query languages is the structured query language (SQL). However, recent and dramatic advances in computing technology, for example, increases in processor power and speed and increases in information storage capabilities, have enabled a greater range of information location and retrieval applications on a wider variety of computers.","Traditionally, there have been two main approaches to include information location and retrieval abilities in compiled applications that are written in a high-level programming language. In accordance with the first approach, text of queries written in a query language such as SQL can be encoded as strings within a compiled application program. During execution of the program, text of the query can be passed to a function from an application programming interface (API) that can pass the query to a database to obtain information that result from performance of the query. With the second approach, an embedded text representation of a query is extracted from a source code file by a compiler. The compiler rewrites the query to use an API and re-encodes the query as a text string. These existing techniques suffer from complexity, poor performance, and inexact error reporting.","Recently, querying languages such as extended structured query language (eSQL) and language integrated query (LINQ) have been developed that allow queries of conceptual data, unlike SQL that is intended for pure relational data. Rather than merely getting back fixed number of columns with simple values interpreted for each position, these newer querying languages can get back type information. This capability is leveraged in a platform supporting transformation of data from one domain to another, for instance an Object Relational Mapping System, where large amounts of data needs to be efficiently transformed from one shape to another, for example from relational rows to arbitrarily structured results.","One approach for supporting such queries is to compile a query plan into a procedural method in order to obtain the processing efficiencies. However, such an approach suffers from the complexities of compiling procedures and often has poor error handling. Another approach has been a live interpretation of a description of a pattern with respect to the data, which avoids some of the complexities of compiling procedural methods but lacks the efficiencies of precompiled paths.","The following presents a simplified summary of the innovation in order to provide a basic understanding of some aspects described herein. This summary is not an extensive overview of the claimed subject matter. It is intended to neither identify key or critical elements of the claimed subject matter nor delineate the scope of the subject innovation. Its sole purpose is to present some concepts of the claimed subject matter in a simplified form as a prelude to the more detailed description that is presented later.","The subject innovation relates to systems and\/or methods that leverage an expression library capable of describing shaping functions. Descriptions of a function are transformed into methods with a description of the shaping function maintained. First, every element that is returned, be it a simple element or an element of a nested collection, is represented as a method created on the fly as a fairly simple representation, which is compiled to gain processing efficiencies. Second, the assembly of the method from layering of expressions composed from a small number of simple functions is tracked to enable two-way visibility into the process. Thus, when the results are obtained, the expressions that created these structures are known for interpreting the results. Third, with this visibility in the layering of expressions, multiple versions of the same compiled method can be created to trade off performance for graceful error handling.","In accordance with one aspect of the subject innovation, a method is provided for result shaping of transforming rectangular, relational data from a data store into arbitrarily structured results. A set of expression definitions are compiled for a mapping declaration to initialize a result assembly. A plurality of coordinators are tracked that handle materialization respectively of results for each step of the result assembly. Query data results are demulitplexed by identifying the coordinator for each collection element of the query data results.","In another aspect, an apparatus is provided for result shaping of transforming rectangular, relational data from a data store into arbitrarily structured results. A user interface receives an entity query of conceptual data. A computer readable memory comprises a bridge for causing a computer to process the entity query. The bridge further comprises a result assembly component for assembling a set of expression definitions for a mapping declaration for a pattern derived from the entity query, an expression compiler for compiling the set of expression definitions, a tracking component for tracking a plurality of coordinators that handle materialization respectively of results for each step of the result assembly, and a result demultiplexing component for processing the query data results by identifying the coordinator or coordinators for each element of the query data results.","In an additional aspect, a method is provided of result shaping of transforming rectangular, relational data from a data store into arbitrarily structured results. A set of expression definitions are compiled for a mapping declaration to initialize a result assembly retrieved from an expression library for a query language that can describe shaping functions, the expressions selected from a plurality of stateless functions usable in a cache without recompilation. A coordinator is created that encapsulates logic to materialize a particular result collection. A key is defined demarcating a boundary or chapter for a coordinator whose change indicates a new result. Transformations are described that are needed to take results of executing a relational store command to produce post-relational entity results in a column map by telling a materializer how to group columns in complex types of sub-structures and how to group rows into inline collection nested results. A plurality of coordinators are tracked that handle materialization respectively of results for each step of the result assembly. Query data results are demultiplexed by identifying the coordinator or coordinators for each row of the query data results. Optimization of a result shaping function is made by tailoring based upon data available at runtime.","The following description and the annexed drawings set forth in detail certain illustrative aspects of the claimed subject matter. These aspects are indicative, however, of but a few of the various ways in which the principles of the innovation may be employed and the claimed subject matter is intended to include all such aspects and their equivalents. Other advantages and novel features of the claimed subject matter will become apparent from the following detailed description of the innovation when considered in conjunction with the drawings.","A result shaping methodology is part of a bridge (translation layer) between an entity provider and an underlying store provider. The bridge accepts command trees and parameter values from a consumer (e.g., the entity provider), reshapes the trees as necessary for its underlying store provider to execute, executes resulting commands, and assembles the results from the commands into the nested data reader that the initial command tree requested. The result assembly advantageously takes a mapping declaration and compiles it into a set of expression definitions composed from a small number of simple functions. Each collection in the result has a corresponding expression describing how collection elements are realized given relational results. Other expressions describe boundary detection behavior. These expressions are compiled into functions used to shape relational data into arbitrary object graphs or streaming interfaces. Alternative versions of the expressions for performance or graceful contextual error handling are also compiled.","The claimed subject matter is described with reference to the drawings, wherein like reference numerals are used to refer to like elements throughout. In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the subject innovation. It may be evident, however, that the claimed subject matter may be practiced without these specific details. In other instances, well-known structures and devices are shown in block diagram form in order to facilitate describing the subject innovation.","As utilized herein, terms \u201ccomponent,\u201d \u201csystem,\u201d \u201cinterface,\u201d \u201cstore,\u201d \u201cdevice,\u201d \u201cnetwork,\u201d \u201ccloud,\u201d and the like are intended to refer to a computer-related entity, either hardware, software (e.g., in execution), and\/or firmware. For example, a component can be a process running on a processor, a processor, an object, an executable, a program, a function, a library, a subroutine, and\/or a computer or a combination of software and hardware. By way of illustration, both an application running on a server and the server can be a component. One or more components can reside within a process and a component can be localized on one computer and\/or distributed between two or more computers.","Furthermore, the claimed subject matter may be implemented as a method, apparatus, or article of manufacture using standard programming and\/or engineering techniques to produce software, firmware, hardware, or any combination thereof to control a computer to implement the disclosed subject matter. The term \u201carticle of manufacture\u201d as used herein is intended to encompass a computer program accessible from any computer-readable device, carrier, or media. For example, computer readable media can include but are not limited to magnetic storage devices (e.g., hard disk, floppy disk, magnetic strips . . . ), optical disks (e.g., compact disk (CD), digital versatile disk (DVD) . . . ), smart cards, and flash memory devices (e.g., card, stick, key drive . . . ). Additionally it should be appreciated that a carrier wave can be employed to carry computer-readable electronic data such as those used in transmitting and receiving electronic mail or in accessing a network such as the Internet or a local area network (LAN). Specifically, the subject innovation can be utilized with a variety of hardware configurations such as, but not limited to disability assisted input\/output facilities, voice enabled input\/output, tactile (e.g., Braille, etc.) keyboard, etc. Of course, those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter. Moreover, the word \u201cexemplary\u201d is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as \u201cexemplary\u201d is not necessarily to be construed as preferred or advantageous over other aspects or designs.","Now turning to the figures,  illustrates a system  enables an entity provider  to submit queries conceptual data, depicted as entity command tree , via a bridge  to a store provider . Thereby, rectangular\/relational result data from the store provider  can be reshaped into structured data, which can contain typed results, nested structures, and nested collections.","A result assembly  of the bridge  leverages an expression library  of a query language capable of describing a result shaping function. Simple functions are retrieved that are stateless so that can they can be used from cache without recompilation. Unlike compiling procedural methods, these functions can be compiled with less complexity by a method compiler . The multiplexed coordinators that are defined by the function expressions are maintained by a coordinator tracking component . Thus, when a result reader, depicted at , causes the store provider  to provide a result collection, depicted at , the particular coordinator or coordinators responsible for each row can be demultiplexed for aggregating the results.","With this enhanced two-way process, alternative versions of the compiled functions for result shaping can be maintained, depicted as a stored lean and robust expressions versions component . In particular, sub-expressions that provide for greater particularity in defining compiling errors can be modified to create a high performance \u201clean\u201d expression. Alternatively, a graceful error handling \u201crobust\u201d expression can be used to give a consumer (e.g., entity provider ) insights into the cause of the error. In some aspects, switching between use of the two versions is dynamically determined. For example, use of the lean version could be the default in order to achieve higher performance, recognizing that errors tend to be infrequent. The robust expression would be swapped out for a particular portion that is causing an error to more specifically determine the cause.","A runtime optimization component  enables optimization of shaping functions based on data available only at runtime from the backend database (store provider ). For instance, we are able to tailor the shaping function to a specific column layout in the relational results. Rather than dynamically determine where the data can be found in the result set, we directly encode this knowledge in the shaping function.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 2"},"A methodology  is provided for result shaping of transforming rectangular, relational data from a data store into arbitrarily structured results. In block , a set of expression definitions are compiled for a mapping declaration to initialize a result assembly. In particular, an aggregation of simple relational query functions is created as coordinators in response to a mapping declaration of an entity query.","In block , description of the transformations that make up the result shaping method are maintained. Thus, a plurality of coordinators are tracked that handle materialization respectively of results for each step of result assembly.","In block , contextual error handling sub-expressions are selectively maintained in one version of the expression definitions for dynamic error handling.","In block , the results are read, demultiplexing the query data results by identifying the coordinator or coordinators for each row of the query data results.","In block , a runtime optimization enables optimization of shaping functions based on data available only at runtime from the backend database. For instance, we are able to tailor the shaping function to a specific column layout in the relational results. Rather than dynamically determine where the data can be found in the result set, we directly encode this knowledge in the shaping function.","In , a query system  enables an entity provider  (e.g., consumer) to work on a store provider  using eSQL strings, depicted as either passing directly to an eSQL parser  or first passing through a query<t> component . The parser  takes advantage of an entity command tree  provided by a converter , depicted as converting between LinQ and CQT. The conceptual data querying language in the exemplary implementation is Language Integrated Query (LINQ), a MICROSOFT\u2122 .NET Framework component version 3.5 that adds native data querying capabilities to .NET and is a language using syntax reminiscent of SQL. LINQ defines a set of query operators that can be used to query, project and filter data in arrays, enumerable classes, XML, relational database, and third party data sources. When you formulate a query using LINQ, the LINQ to Entities layer translates the LINQ expression into an internal representation called CQT for Cannonical Query Trees, which is the same representation that results from parsing an Entity SQL statement. So once it's translated, it's handed out to the mapping layer, which will process it the exact same way independently of the fact that the query was initially formulated with LINQ or Entity SQL.","The eSQL parser  passes the \u201centity\u201d command tree, as depicted at  to a view expansion component , which in turn passes the \u201centity\u201d command tree as depicted at  to a bridge  that outputs an \u201centity\u201d data reader  to the store provider .","The bridge  is the translation layer between the entity provider  and the underlying store provider  that the entity provider  is working with. The primary function of the bridge  is to accept command trees  and parameter values from the consumer (typically the entity provider ), reshape the trees as necessary for its underlying store provider  to execute, execute the resulting commands, and assemble the results from the commands into the nested data reader  that the initial command tree  requested.","In , in one aspect, the bridge  is not a single component, but rather a set of related components. A plan compiler  transforms a high-level command tree  in entity terms into lower-level command tree  in store provider terms that can be executed by a data store  that has capabilities equivalent to SQL Server 2000. Specifically, the plan compiler  gets rid of constructs like type constructors, nesting etc, from the user query, converts the user query into one or more flat relational queries, along with reassembly information. In addition, the plan compiler  produces the column map instructions  that a result assembly component  uses to assembly the data returned when the command trees  are executed into the proper shape.","A store command generation component  of the bridge  constructs a DbCommand object (\u201cstore command definition(s)\u201d)  for each store command tree  that the plan compiler  produces. This component  relies upon new interfaces that the data store's ADO.NET Data Provider (not shown) implements to support the generating of these commands . In many cases, the store provider  implements a SQL Generation component (not shown) to translate the command tree into a command text of their native SQL dialect.","A command execution component  of the bridge  executes the store commands , producing a set of store data readers  that contain the raw data, and performing the initialization process for the result assembly component .","The result assembly  of the bridge  applies the column map instructions  that the plan compiler  produced to the raw data coming from the store data readers  that the command execution component  produced and returning a data reader  in the shape that the original entity command tree requested.","In an illustrative implementation, the first two components, the plan compiler  and the store command generation component , occur in the constructor of the EntityCommandDefinition, while the command execution component  and the initial setup for the result assembly component  occur in the internal Execute( ) method the EntityCommandDefinition. In addition, the result assembly component  is an ongoing process that continues for the life of the data reader  returned.","In , an illustrative store command generation component  constructs a DbCommand object (\u201cstore command definition\u201d) for each store command tree  that the plan compiler component  () produces. This component  relies upon new interfaces, store connection  and a command tree in store terms component  of ADO.NET Data Provider (\u201cstore provider services\u201d)  of the data store . In most cases, the store provider  can implement a SQL Generation component (\u201ccreate command definition\u201d)  to translate the command tree  into a command text (\u201cstore command definition\u201d) of their native SQL dialect.","Drilling in a bit deeper, the following diagram of  illustrates how the CreateCommandDefinition method  for the SqlClient Provider functions. In SqlClient, we hand the store version number (from the provided SqlConnection object) and the provided command tree to its SQL Generation component, which produces a command text and (in the case of DML statements) a list of SqlParameter objects. In addition, we run each of the query parameters on the command tree specified through a ParameterGeneration method that builds SqlParameter objects from their TypeUsage. All of these are set on a SqlCommand object that is created using the CreateCommand method of the provided SqlConnection object. The resulting SqlCommand object is then handed to the DbCommandDefinition as its prototype, and that is what is returned.","Command Execution  can be relatively the simplest \u201ccomponent\u201d of the bridge  (), the purpose of the CommandExecution component  is to execute the store commands, producing a set of store data readers that contain the raw data. A SQL connection  is depicted as providing a server version to a SQL generation component  and depicted as creating a SQL command component . The SQL generation component  receives a tree from a command tree component , which provides query parameter (non-DML) to a parameter generation component , which provides List<SQL parameter> to a List<SQL parameters> component  from the SQL generation component . This is added to the parameters collection of the SQL command , providing a prototype for a database (DB) command definition  for a result.","The internal Execute( ) method on the EntityCommandDefinition performs command execution process:",{"@attributes":{"id":"p-0054","num":"0053"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u2003\u2003sealed public class EntityCommandDefinition :"},{"entry":"\u2003\u2003DbCommandDefinition {"},{"entry":"\u2003\u2003\u2003internal DbDataReader Execute(EntityCommand entityCommand,"},{"entry":"CommandBehavior behavior)"},{"entry":"\u2003\u2003}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}},"br":{}},"At this point, the command tree has been executed and control falls through to the initialization portion of the ResultAssembly component, which is described in the next section.","The ResultAssembly component  is responsible for applying the column map instructions that the PlanCompiler  produced to the raw data coming from the store data readers  that the CommandExecution component  produced and returning a data reader  in the shape that the original entity command tree  requested.","There are essentially two portions to ResultAssembly : (1) The initialization portion, depicted in , which occurs as part of CommandExecution, and is responsible for initializing everything needed to perform the second portion. It returns the top-level data reader. (2) The process part that occurs as the data is being read from the top-level data reader (and all resulting data readers and data records) to actually carry out the assembly.","In more detail, a result assembly initialization methodology  has a ColumnMap hierarchy  produced by the PlanCompiler  () is handed to a Translator , which produces Expressions which are eventually compiled into delegates.","These delegates, when executed, will do things such as determine whether there is any data for a collection, or materialize the objects. The delegates utilize a Shaper<T> instance  to gain access to the store data reader  and various pieces state. The delegates are compiled and stored on a CoordinatorFactory<T> object , the instructions about how the Shaper<T> objects  are to be constructed are stored on a ShaperFactory<T> class , along with a reference to the top-level CoordinatorFactory<T> object .","The ShaperFactory<T> class  is cached on a query cache manager , using a cache key constructed from the ColumnMap hierarchy . In this way, multiple queries that have different EntitySQL or LINQ expressions yet that have the same physical shape will use the same instructions.","The Translator class  will return this ShaperFactory<T>512 to its caller, (either a BridgeDataReader constructor , or the ObjectQueryExecutionPlan (not shown).","You can think of Coordinators  as the rules for how a collection result should be assembled, and the Shapers  as the class that stores the current state of all the collections for a given nested collection.","It should be appreciated with the benefit of the present disclosure that the \u201cvalue-layer\u201d returns readers and records with nested readers, and the \u201cobject layer\u201d returns object iterators with nested collections. For value-layer object materialization: (a) The BridgeDataReader constructor  hands the storeDataReader  and metadataworkspace (not shown) from the connection to the ShaperFactory , and asks for a shaper  that will return RecordState objects. (b) The Shaper  produced and the Coordinator  it refers to are handed to the BridgeDataReader , which constructs a BridgeDataRecord  to handle the data and metadata retrieval tasks. (c) The resulting BridgeDataReader  is returned as the result of the EntityCommandDefinition.Execute method (not shown); this will in turn end up in the hands of the consumer, which will use the customary data reader patterns to read data from the result. For Object-Layer object materialization, ObjectQueryExecutionPlan stores this plan, and when the query is executed, it will hand it to the ObjectResult<T>, which is responsible for materializing the object results.","As an overview of result assembly process, let's work through some examples to examine what the result assembly process is responsible for. In case of nested (polymorphic) types, here is the result that the consumer expects the Bridge to return, depicted at  in .","In , the plan compiler generates a query that (essentially) produces the raw data stream as depicted at . In this case, we need to recognize which type the Address column should be constructed as.","Now let's consider a different and more complex example that the consumer expects the Bridge to return, depicted in  at . We are to create a data reader with two normal columns, and two nested collections.","The plan compiler generates a query that (essentially) produces the raw data stream as depicted at  in . Notice that the first row contains data for both the top-level customer, as well as the first row of its nested order collection. The second row repeats the top-level customer data, but contains the second row of its nested order collection. The Third row repeats the data for the top-level customer, but contains data for the first row of its nested contact collection instead of a row for the order collection, and so on.","In , data that is to be ignored is grayed out as depicted at  in the table . In this case, we need recognize when the data in the row: (1) Is for a different collection. (2) Is duplicated because of nested collections. As can be seen from the examples, the PlanCompiler inserted columns into the query. The four types of columns inserted into the stream are: (1) Type Discriminator columns, represented by the TD1 column in the first example, indicates which of the set of polymorphic types the data in the row represents; (2) Entity Set ID columns, represented by the ESID1, ESID2, and ESID3 columns in the examples, indicate which Entity Set the data in the row belongs to (came from); (3) Collection Discriminator columns, represented by the CD1 column in the second example, indicate which nested collection the data in the row belongs to; (4) Null Sentinel columns, represented by the NST1 column in the examples, indicate whether the entire record or complex type is null. If the value for this column is not null indicates that the corresponding record or complex is not null, and vice versa. It helps differentiate between a record or a complex type with all null properties and one that is null.","Each of these columns is added to the query to provide information to the ResultAssembly component to allow it to know what is in the row of the data stream. The expressions produced by the Translator and stored on the CoordinatorFactory look at the values of these columns and \u201cdiscriminate\u201d about what to return.","After each StoreRead is made on the Shaper's enumerator, it runs the root Coordinator's expression process to update the state of the State on the shaper to reflect what is in the row that the StoreDataReader currently has.","In summary, there are a few key concepts that for how the exemplary result assembly functions, such as consuming data versus skipping data. The store data reader is consumed sequentially. A single column of a structure may require multiple reads from the store data reader to skip over it. The Shapers and Coordinators ensure that all data for the column is consumed and discarded. When you're doing a Read from a BridgeDataReader, we end up consuming the rest of the data on the current row, which may involve multiple reads from the store, but at the end we will automatically be positioned exactly at the beginning of the next row.","Readers manage collection navigation; records manage structured types. The DataReaders surfaced in the Bridge essentially manage the navigation of their collection, while relying upon the DataRecords to manage returning data and metadata. This is done to minimize the amount of duplicate code, since every method of the DataRecord is also on the DataReader (but not the other way around). In addition, the Shapers for value-layer result assembly produce RecordState objects, which can include for both value-layer and object-layer materialization.","It should be appreciated with benefit of the present disclosure that Shaper<RecordState> is being utilized rather than Shaper<BridgeDataRecord>. The primary reason for this is that DataReaders are generally streaming, and there is no need to create a new record each time you need to return one. Simply re-using the old record (swapping current and next values) is far more efficient, maintaining performance.","These RecordState objects are stored in the State array in the Shaper. There is one RecordState for each polymorphic type the query can return, and the Element expression of the Coordinator will return the correct one based upon the type discriminators in the query.","The RecordState objects contain all the values for each of the columns (In fact there is a current and pending set of values, so we can be reading forward for nested collections without destroying column values for columns that come after the nested collection.","The \u201cpublic\u201d objects (BridgeDataReader and BridgeDataRecord) just delegate to their RecordState for state.","We manage the state of the Result Assembly on the RecordState because the \u201cpublic\u201d BridgeDataReader and BridgeDataRecord, being derived from public classes, do not provide enough typing to manage the state. Consider how you would handle Polymorphic types or the EntityRef hierarchy with those two objects alone. The RecordState provides a much more natural way to manage state. In practice, then, the public objects pretty much are facades around the RecordStates, relying upon them for all their work.","There are actually two enumerators. The Shaper object is an IEnumerable<T>. When the BridgeDataReader or the ObjectResult want to begin processing, the call the GetEnumerator method on the shaper, and it returns an IEnumerator<T>","For simple results that have no nested readers, we simply wrap the store data reader and do nearly nothing; each row belongs to the same collection, so there isn't any reason to do anything. This is the Shaper<T>.SimpleEnumerator class.","For results that have nested readers we need to \u201ccoordinate\u201d which result is being returned. For this case, we use the Shaper<T>.NestedEnumerator class.","Nested enumerators for objects cache results, values do not.","One key item to note is that although both object-layer and value-layer materialization with nested collections use the same NestedEnumerator class, there is a difference in how it works for each of these.","Objects must materialize all objects from the bottom-up to produce the requested object graph, so they will cache all nested results in Lists, and return the top level objects only after all their children have been materialized.","Value-layer materialization, on the other hand, is intended to be streaming, and as such it returns each RecordState as it is found.","With the visibility gained by tracking the transformations made to create the result, a range of trade-offs are possible between performance and error handling. In particular, while translating mapping declarations into expression trees, we annotate certain expression sub-trees to indicate an alternative (generally more expensive but also more helpful) representation of the same logic. When an error is encountered at runtime, we can rerun a particular branch and provide more useful context to the user. For instance, when realizing a \u201cCategory\u201d entity we may generate the following expression to represent the initialization of the \u201cCategoryID\u201d property, depicted in  at . The call to GetInt32 may throw, but because the call appears within a larger expression, we cannot provide a specific reason for the failure to the user.","Advantageously, we can in parallel produce a separate version of the expression depicted, in  at , that can be used in case of errors. Note that in this second example, the context for the operation (the type name \u201cCategory\u201d and the property name \u201cCategoryID\u201d) are captured. In addition, the call to GetPropertyValueWithErrorHandling replaces the call to DbDataReader.GetInt32, and is able to take its time figuring out the root cause of the error.","This kind of rewriting is possible because of the simple representation of the realization delegate functions. As a side-benefit, we can produce in a single code path two versions of the same logic without introducing explicit branches in the performant runtime function.","In the discussion above, System.Data.Objects.ObjectQuery<T> results (LINQ, CommandTree and Entity-SQL based) can be produced indirectly from store reader results by way of the BridgeDataReader, EntityDataReader and ObjectMaterializer. This layering is inefficient. An alternative strategy is to create results directly from the underlying store reader. To do this, we pay an up-front cost to compile a delegate (or a chain of delegates for nested results) that directly produces typed results given a store reader. To offset the high cost of emitting these delegates, they are cached.","Consider the following example. The user issues the following query:",{"@attributes":{"id":"p-0090","num":"0089"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"var query = from c in context.Categories"]},{"entry":[{},"\u2003\u2003\u2003\u2002\u2009select new { Category = c, Products = c.Products };"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},{"@attributes":{"id":"p-0091","num":"0090"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"SELECT c.CategoryID, c.CategoryName, p.ProductID, p.ProductName"},{"entry":"FROM Categories AS c LEFT OUTER JOIN"},{"entry":"\u2003Products AS p ON c.CategoryID = p.CategoryID"},{"entry":"ORDER BY c.CategoryID, p.ProductID"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0092","num":"0091"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"56pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["CategoryID","CategoryName","ProductID","ProductName"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Beverages","1","Tea"]},{"entry":["1","Beverages","2","Coffee"]},{"entry":["2","Food","NULL","NULL"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}}}},"We expected the following results:",{"@attributes":{"id":"p-0094","num":"0093"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":[{},"TABLE 2"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]},{"entry":[{},"Category","Products"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{1, Beverages}","{1, Tea}, {2, Coffee}"]},{"entry":[{},"{2, Food}","Empty"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"Shaper. The Shaper is used by ObjectResult and by BridgeDataReader to materialize query results. The shaper exposes the root level coordinator for the query (see Section 4.3 for examples). When we begin to process results (GetEnumerator) from the store reader, the root coordinator becomes active. As new rows are read, we may transition to other coordinators, or yield results for the current coordinator. For an ObjectQuery, yielding really means aggregating; we don't return to the user until an entire top-level row has all of its results available. This allows the user to examine all data in the row without explicitly iterating over nested results. For reader scenarios, the user is expected to iterate of nested results, so yielding really means \u201ctelling the reader that the next result is available\u201d.","A coordinator decides it's time to yield a new result when its key has changed. For instance, the root coordinator's key in the reference example is \u2018CategoryID\u2019, and new results are yielded in the first and third rows.","The coordinator factory exposes the following compiled delegates to manage this state: (a) SetKeys: remembers the key values for the current result. Coordinator delegates use the Shaper.State object array to \u201cremember\u201d information. While the delegates are being compiled, we allocate space in this array. A coordinator calls this method when it begins processing a result; (b) CheckKeys: determines whether or not key values have changed. When the key values change, it tells us we've reached a boundary, and that it's time to yield some new results. This is called from the shaper's NestedEnumerator (through the coordinator's FindBoundary method) after each read from the store data reader. (c) Element: constructs a new element of the collection given values in the current store reader row. (d) ElementWithErrorHandling: when something fails in the Element delegate, we call this to provide better error messages. It's just a transformation of the Element delegate that tries to isolate where the failure occurred. (e) HasData: determine whether the current store reader row has values for the current coordinator. For instance, the \u2018products\u2019 coordinator in the above example has no data in the third row. A lack of data tells us it's time to cede control to the next coordinator (this is particularly important where there are multiple nested coordinators at the same depth.).","As examples of coordinators, consider that a coordinator handles the creation of a particular result collection. Some queries require only a root level coordinator. For instance, the following example results in a single \u2018root\u2019 coordinator yielding Product instances:",{"@attributes":{"id":"p-0099","num":"0098"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003\u2003ObjectResult<Product> result ="]},{"entry":[{},"context.Products.Execute(MergeOption.NoTracking);"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"Other queries have nested results. The following example contains a top-level coordinator but also two nested coordinators (siblings), one coordinating a nested products collection, the other coordinating a nested orders collection:",{"@attributes":{"id":"p-0101","num":"0100"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"var query = context.Categories.Select(c => new {"},{"entry":"Products = c.Products, Orders = c.Products.SelectMany(p => p.Orders) });"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"Coordinators can also be deeply nested, as in the following example where the nested products collection includes nested order collections:",{"@attributes":{"id":"p-0103","num":"0102"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"var query = context.Categories.Select(c => new { Category = c,"]},{"entry":[{},"\u2003Products = c.Products.Select(p => new { Product = p,"]},{"entry":[{},"Orders = p.Orders } ) } );"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}}},"A ColumnMap graph is translated into a shaper by the Translator class. Since a certain amount of state is maintained when results are being materialized, the output of the translator is actually a ShaperFactory, which supports the creation of new Shaper instance for every query. The factory instance is immutable (which allows it to be used in the query cache) but its output can maintain state specific to the current result stream. The coordinators used by the shaper follow a similar pattern (the ShaperFactory has a CoordinatorFactory; the Shaper has a Coordinator).","As we walk the ColumnMap graph, we construct a LINQ expression describing the Coordinator.Element delegate. While translation is performed, a CoordinatorScratchPad aggregates information about the coordinator hierarchy. This scratchpad can then be used to construct the coordinator hierarchy and the result shaper","The overall approach is that as the Translator traverses the ColumnMap graph, it produces expressions for each structured type that gathers all the data for that structured type into a RecordState object. These RecordState objects are stored in the Shaper objects state array, and each unique type in a polymorphic type has its own RecordState.","The RecordState object maintains two separate object arrays\u2014one for the current values and one for the pending values. This allows us to process nested collections without damaging column values that follow it in the record. The RecordState object also maintains the current and pending EntityRecordInfo objects if the record is the result of an Entity. The EntityKey property of the EntityRecordInfo changes from row to row so it cannot be static.","All static information about the records, such as the DataRecordInfo, the column names, the FieldNameLookup object, the Types are stored on a RecordStateFactory which is used to create the RecordState objects at runtime. These RecordStateFactory objects are stored on the CoordinatorFactory object that can return them. (And they are stored on the ShaperFactory that is cached)","Just as the Translator uses a CoordinatorScratchPad to aggregate the information for Coordinator objects, it uses a RecordStateScratchPad, which is stored on the CoordinatorScratchpad. When we build the CoordinatorFactory objects, we build the RecordStateFactory objects that are stored on them.","Two interesting methods on the RecordState are: (a) AcceptPendingValues: swaps the current and pending values and EntityRecordInfo objects; called from the BridgeDataReader when it's read a row. This is the only time we know the pending values are complete and that the current values are no longer needed. This is a recursive call, because there may be nested records in the values that also need to have their pending values accepted. (b) GatherData: when the Element expression on the Coordinator has determined that a specific RecordState should be returned, it calls the GatherData method on it which calls the GatherData expression on the RecordStateFactory. This expression will then call GetValue for each of the values that are to be part of the record from the store data reader and call SetColumnValue to ensure they're in the pending values. SetEntityRecordInfo is also called in this process.","EntityDataReader and ObjectQuery\/ObjectResult have different requirements. The reader allows the user to access columns in each record sequentially. If a record contains a column containing a nested reader, the nested reader can also be accessed sequentially. On the other hand, the user accesses object results via an Ienumerator which exposes each element in its entirety. If there is a nested collection, its contents are aggregated and returned as part of the parent element. In both cases, relational results are shaped into structured results in a similar way, but the streaming and \u2018wholesale\u2019 exposure of these structures force us to parcel out the results in different ways.","To address this discrepancy, we introduce an additional layer of abstraction: an enumerator that translates every relational row to an array containing entries for every coordinator outputting a new result in the current row. For instance, the following query:",{"@attributes":{"id":"p-0113","num":"0112"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"SELECT c, c.Address, c.Orders"]},{"entry":[{},"FROM Customers as c"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}}},"br":{}},{"@attributes":{"id":"p-0114","num":"0113"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"11"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"6","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"7","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"8","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"9","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"10","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"11","colwidth":"14pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 3"},{"entry":{"@attributes":{"namest":"1","nameend":"11","align":"center","rowsep":"1"}}},{"entry":[{},{},{},{},{},{},{},{},"Coordinators",{},{}]},{"entry":[{},"Relational",{},{},{},{},{},{},"array","Key"]},{"entry":["Step","CustomerID","Name","CollDisc","AddressID","City","OrderID","Quantity","Depth0","Depth1"]},{"entry":{"@attributes":{"namest":"1","nameend":"11","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["0","Start",{},{},{},{},{},{},{},{},{}]},{"entry":["1","C1","Alice","1","A1","Halifax","Null","Null","Customers","Addresses","C1"]},{"entry":["2","C1","Alice","1","A2","Boston","Null","Null","Null","Addresses","C1"]},{"entry":["3","C1","Alice","2","Null","Null","O1","10","Null","Orders","C1"]},{"entry":["4","C2","Bob","Null","Null","Null","Null","Null","Customers","Null","C2"]},{"entry":["5","C3","Charlie","2","Null","Null","O2","20","Customers","Orders","C3"]},{"entry":["6","C3","Charlie","2","Null","Null","O3","30","Null","Orders","C3"]},{"entry":["7","End"]},{"entry":{"@attributes":{"namest":"1","nameend":"11","align":"center","rowsep":"1"}}}]}}}}},"When we read the first row (step ), we encounter a new key value for the root coordinator (which yields \u201cCustomers\u201d), and as a result determine there is a new customer. Based on the value of the collection discriminator column \u201cCollDisc\u201d, we determine that the first row also contains an element of the \u201cAddresses\u201d coordinator. As a result, our coordinator array now contains the \u201cCustomers\u201d and \u201cAddresses\u201d coordinators, at depths  and  respectively. Note that we use different criteria to determine whether there is a new customer and whether there is a new address. In the case of the customer, we have a key column \u201cCustomerID\u201d which is processed in the SetKeys and CheckKeys delegates. In the case of the address, we have a discriminator column \u201cCollDisc\u201d which is processed by the HasData delegate. Generally speaking, a coordinator may have both\/either\/neither keys nor discriminators.","In the second step, we encounter a new address. In this case, there coordinator at depth  is null indicating that there is no new root element (we're still reading \u201cAlice\u201d).","In the fourth step, we encounter a new customer \u201cBob\u201d. He has no addresses and no orders, so in this case there is no coordinator at depth .","The row enumeration is interpreted differently for a reader result and an object result. In the reader result, we yield a RecordState every time a new element is produced at any depth. As a result, a particular row yields between 0 and n states. In the above example, we yield the following states at each step:",{"@attributes":{"id":"p-0119","num":"0118"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"77pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 4"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["Step","Yielded states (Coordinator[Element])"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Customers[C1]"]},{"entry":[{},"Addresses[A1]"]},{"entry":["2","Addresses[A2]"]},{"entry":["3","Orders[O1]"]},{"entry":["4","Customers[C2]"]},{"entry":["5","Customers[C3]"]},{"entry":[{},"Orders[O2]"]},{"entry":["6","Orders[03]"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"For the object result, we return a result only when a new root level element is encountered. We actually return the previous element since we need to wait until all elements of its children have been loaded. With respect to the same example, we have:",{"@attributes":{"id":"p-0121","num":"0120"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"63pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 5"},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["Step","Previous","Current","Yield previous?"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["0","\u2014","\u2014","No"]},{"entry":["1","\u2014","{C1, {A1}, { }}","No"]},{"entry":["2","\u2014","{C1, {A1, A2},","No"]},{"entry":[{},{},"{ }}"]},{"entry":["3","\u2014","{C1, {A1, A2},","No"]},{"entry":[{},{},"{O1}}"]},{"entry":["4","{C1 . . . }","{C2}","Yes"]},{"entry":["5","{C2}","{C3, { }, {O2}}","Yes"]},{"entry":["6","{C2}","{C3, { }, {O2, O3}}","No"]},{"entry":["7","{C3 . . . }","\u2014","Yes"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}}}},"If a result is \u201csimple\u201d (e.g. there is no nesting and no keys to check), we can use a simpler (common) pattern. We yield an element or record state for each relational row.","With regard to caching, the ObjectQueryCacheEntry includes a ShaperFactory. The factory allows us to skip recompilation of delegates, which can be expensive. Since multiple queries can have identical column maps (e.g., all queries that filter\/order a particular entity set), we also independently cache the ShaperFactory. The key for these entries is a representation of the column map. Related classes: (a) ColumnMapKeyBuilder: constructs a string serving as the identifier for a column map graph. (b) ShaperFactoryQueryCacheEntry: a cache entry which stores the ShaperFactory instance. (c) ShaperFactoryQueryCacheKey: used to lookup factories in the cache. Uses the identifier built by ColumnMapKeyBuilder.","Moreover, those skilled in the art will appreciate that the inventive methods may be practiced with other computer system configurations, including single-processor or multi-processor computer systems, minicomputers, mainframe computers, as well as personal computers, hand-held computing devices, microprocessor-based and\/or programmable consumer electronics, and the like, each of which may operatively communicate with one or more associated devices. The illustrated aspects of the claimed subject matter may also be practiced in distributed computing environments where certain tasks are performed by remote processing devices that are linked through a communications network. However, some, if not all, aspects of the subject innovation may be practiced on stand-alone computers. In a distributed computing environment, program modules may be located in local and\/or remote memory storage devices.",{"@attributes":{"id":"p-0125","num":"0124"},"figref":"FIG. 15","b":["1100","1100","1110","1110","1100","1120","1120","1120"]},"One possible communication between a client  and a server  can be in the form of a data packet adapted to be transmitted between two or more computer processes. The system  includes a communication framework  that can be employed to facilitate communications between the client(s)  and the server(s) . The client(s)  are operably connected to one or more client data store(s)  that can be employed to store information local to the client(s) . Similarly, the server(s)  are operably connected to one or more server data store(s)  that can be employed to store information local to the servers .","With reference to , an exemplary environment  for implementing various aspects of the claimed subject matter includes a computer . The computer  includes a processing unit , a system memory , and a system bus . The system bus  couples system components including, but not limited to, the system memory  to the processing unit . The processing unit  can be any of various available processors. Dual microprocessors and other multiprocessor architectures also can be employed as the processing unit .","The system bus  can be any of several types of bus structure(s) including the memory bus or memory controller, a peripheral bus or external bus, and\/or a local bus using any variety of available bus architectures including, but not limited to, Industrial Standard Architecture (ISA), Micro-Channel Architecture (MSA), Extended ISA (EISA), Intelligent Drive Electronics (IDE), VESA Local Bus (VLB), Peripheral Component Interconnect (PCI), Card Bus, Universal Serial Bus (USB), Advanced Graphics Port (AGP), Personal Computer Memory Card International Association bus (PCMCIA), Firewire (IEEE 1394), and Small Computer Systems Interface (SCSI).","The system memory  includes volatile memory  and nonvolatile memory . The basic input\/output system (BIOS), containing the basic routines to transfer information between elements within the computer , such as during start-up, is stored in nonvolatile memory . By way of illustration, and not limitation, nonvolatile memory  can include read only memory (ROM), programmable ROM (PROM), electrically programmable ROM (EPROM), electrically erasable programmable ROM (EEPROM), or flash memory. Volatile memory  includes random access memory (RAM), which acts as external cache memory. By way of illustration and not limitation, RAM is available in many forms such as static RAM (SRAM), dynamic RAM (DRAM), synchronous DRAM (SDRAM), double data rate SDRAM (DDR SDRAM), enhanced SDRAM (ESDRAM), Synchlink DRAM (SLDRAM), Rambus direct RAM (RDRAM), direct Rambus dynamic RAM (DRDRAM), and Rambus dynamic RAM (RDRAM).","Computer  also includes removable\/non-removable, volatile\/non-volatile computer storage media.  illustrates, for example, disk storage . Disk storage  includes, but is not limited to, devices like a magnetic disk drive, floppy disk drive, tape drive, Jaz drive, Zip drive, LS-100 drive, flash memory card, or memory stick. In addition, disk storage  can include storage media separately or in combination with other storage media including, but not limited to, an optical disk drive such as a compact disk ROM device (CD-ROM), CD recordable drive (CD-R Drive), CD rewritable drive (CD-RW Drive) or a digital versatile disk ROM drive (DVD-ROM). To facilitate connection of the disk storage devices  to the system bus , a removable or non-removable interface is typically used such as interface .","It is to be appreciated that  describes software that acts as an intermediary between users and the basic computer resources described in the suitable operating environment . Such software includes an operating system . Operating system , which can be stored on disk storage , acts to control and allocate resources of the computer system . System applications  take advantage of the management of resources by operating system  through program modules  and program data  stored either in system memory  or on disk storage . It is to be appreciated that the claimed subject matter can be implemented with various operating systems or combinations of operating systems.","A user enters commands or information into the computer  through input device(s) . Input devices  include, but are not limited to, a pointing device such as a mouse, trackball, stylus, touch pad, keyboard, microphone, joystick, game pad, satellite dish, scanner, TV tuner card, digital camera, digital video camera, web camera, and the like. These and other input devices connect to the processing unit  through the system bus  via interface port(s) . Interface port(s)  include, for example, a serial port, a parallel port, a game port, and a universal serial bus (USB). Output device(s)  use some of the same type of ports as input device(s) . Thus, for example, a USB port may be used to provide input to computer  and to output information from computer  to an output device . Output adapter  is provided to illustrate that there are some output devices  like monitors, speakers, and printers, among other output devices , which require special adapters. The output adapters  include, by way of illustration and not limitation, video and sound cards that provide a means of connection between the output device  and the system bus . It should be noted that other devices and\/or systems of devices provide both input and output capabilities such as remote computer(s) .","Computer  can operate in a networked environment using logical connections to one or more remote computers, such as remote computer(s) . The remote computer(s)  can be a personal computer, a server, a router, a network PC, a workstation, a microprocessor based appliance, a peer device or other common network node and the like, and typically includes many or all of the elements described relative to computer . For purposes of brevity, only a memory storage device  is illustrated with remote computer(s) . Remote computer(s)  is logically connected to computer  through a network interface  and then physically connected via communication connection . Network interface  encompasses wire and\/or wireless communication networks such as local-area networks (LAN) and wide-area networks (WAN). LAN technologies include Fiber Distributed Data Interface (FDDI), Copper Distributed Data Interface (CDDI), Ethernet, Token Ring and the like. WAN technologies include, but are not limited to, point-to-point links, circuit switching networks like Integrated Services Digital Networks (ISDN) and variations thereon, packet switching networks, and Digital Subscriber Lines (DSL).","Communication connection(s)  refers to the hardware\/software employed to connect the network interface  to the bus . While communication connection  is shown for illustrative clarity inside computer , it can also be external to computer . The hardware\/software necessary for connection to the network interface  includes, for exemplary purposes only, internal and external technologies such as, modems including regular telephone grade modems, cable modems and DSL modems, ISDN adapters, and Ethernet cards.","What has been described above includes examples of the subject innovation. It is, of course, not possible to describe every conceivable combination of components or methodologies for purposes of describing the claimed subject matter, but one of ordinary skill in the art may recognize that many further combinations and permutations of the subject innovation are possible. Accordingly, the claimed subject matter is intended to embrace all such alterations, modifications, and variations that fall within the spirit and scope of the appended claims.","In particular and in regard to the various functions performed by the above described components, devices, circuits, systems and the like, the terms (including a reference to a \u201cmeans\u201d) used to describe such components are intended to correspond, unless otherwise indicated, to any component which performs the specified function of the described component (e.g., a functional equivalent), even though not structurally equivalent to the disclosed structure, which performs the function in the herein illustrated exemplary aspects of the claimed subject matter. In this regard, it will also be recognized that the innovation includes a system as well as a computer-readable medium having computer-executable instructions for performing the acts and\/or events of the various methods of the claimed subject matter.","There are multiple ways of implementing the present innovation, e.g., an appropriate API, tool kit, driver code, operating system, control, standalone or downloadable software object, etc. which enables applications and services to use the advertising techniques of the invention. The claimed subject matter contemplates the use from the standpoint of an API (or other software object), as well as from a software or hardware object that operates according to the advertising techniques in accordance with the invention. Thus, various implementations of the innovation described herein may have aspects that are wholly in hardware, partly in hardware and partly in software, as well as in software.","The aforementioned systems have been described with respect to interaction between several components. It can be appreciated that such systems and components can include those components or specified sub-components, some of the specified components or sub-components, and\/or additional components, and according to various permutations and combinations of the foregoing. Sub-components can also be implemented as components communicatively coupled to other components rather than included within parent components (hierarchical). Additionally, it should be noted that one or more components may be combined into a single component providing aggregate functionality or divided into several separate sub-components, and any one or more middle layers, such as a management layer, may be provided to communicatively couple to such sub-components in order to provide integrated functionality. Any components described herein may also interact with one or more other components not specifically described herein but generally known by those of skill in the art.","In addition, while a particular feature of the subject innovation may have been disclosed with respect to only one of several implementations, such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore, to the extent that the terms \u201cincludes,\u201d \u201cincluding,\u201d \u201chas,\u201d \u201ccontains,\u201d variants thereof, and other similar words are used in either the detailed description or the claims, these terms are intended to be inclusive in a manner similar to the term \u201ccomprising\u201d as an open transition word without precluding any additional or other elements."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 5","FIG. 4"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 6","FIG. 5"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 7","FIG. 4"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 9","FIG. 8"]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 11","FIG. 10"]},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 12","FIG. 11"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 16"}]},"DETDESC":[{},{}]}
