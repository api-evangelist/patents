---
title: Computational models for supporting situated interactions in multi-user scenarios
abstract: Individuals may interact with automated services as one or more parties, where such individuals may have collective (as well as individual) intents. Moreover, parties may concurrently communicate with the interface, and the interface may have to manage several concurrent interactions with different parties. Single-individual interfaces may be unable to react robustly to such dynamic and complex real-world scenarios. Instead, multi-party interfaces to service components may be devised that identify individuals within a scene, associate the individuals with parties, track a set of interactions of the parties with the service component, and direct the service component in interacting with the parties. A multi-party interface may also detect and politely handle interruptions, and may identify information items about individuals and parties based on context and history, prioritize the intents of the individuals and parties, and triage interactions accordingly.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08473420&OS=08473420&RS=08473420
owner: Microsoft Corporation
number: 08473420
owner_city: Redmond
owner_country: US
publication_date: 20090626
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Many computing scenarios arise where a computational system may interact with one or more individuals, who may request various services provided by the system through many types of human\/computer interfaces. For example, an automated system may listen to natural language speech from a user, and may endeavor to process the natural language input to identify and fulfill various requests. When the interaction with the user is complete, the automated system may await input from an additional user, and may therefore service a series of individual users.","This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter, nor is it intended to be used to limit the scope of the claimed subject matter.","In many scenarios involving the collaboration of people with one another, people recognize and coordinate with multiple people who may have different relationships and roles. Often, contextual cues, locomotive trajectories, relative positions, poses, attention, gaze, utterances, and gestures may be significant in understanding roles, goals, and the intents of one or more parties, and such observations and inferences may be useful for coordinating and collaborating in an effective and elegant manner. However, computer systems that service individual users in series may be poorly equipped to evaluate real-world situations in which individuals dynamically form parties, and who may attempt to interact with the computer system in an informal and uncoordinated manner, while perhaps also interacting with each other.","As a first example, a number of individuals may approach the computer system in a short timeframe, and it may be up to the computer system to identify the relationships between the individuals based on contextual information, such as proximity, spatio-temporal trajectories, mutual attention, and conversations. As a first such scenario, a mother with an ill child may approach a medical kiosk, carrying the child or with the child in tow, and the kiosk may wish to engage both the mother and the child in an elegant dialog to probe the history and current symptomatology of the child's illness. As a second such scenario, a robotic home eldercare system may have to recognize and distinguish the human health professional who is engaging in care from the elder. As a third such scenario, two people may approach a digital receptionist with the ability to engage in spoken dialog at a building lobby and seek information on transportation or directions; the digital receptionist may seek to understand the relationships between the two people: e.g. are they peers, or is one a visitor and the other one their host? As a fourth scenario, an educational computer system might interact with a group of children to engage them in a cooperative or competitive learning game, or to simply tutor them on a specific subject (e.g. math, physics, history, etc.); such a system might seek to understand which children are trying to dominate the game, and give others an opportunity to contribute. As these scenarios illustrate, the relationships between individuals that a computer system may seek to understand range from the relatively simple, e.g., \u201care these people in a group together?\u201d to more complex, semantic or social relationships (e.g., caregiver vs. patient, visitor vs. host, dominant vs. dominated, etc.)","As a second example, the orderly pace and turn-taking protocol of natural conversation with a single user may be complicated by input from numerous individuals, communication from multiple individuals in the same party, interruptions, and distractions. For instance, two people approaching the aforementioned digital receptionist at the building for directions may interact separately or together with the computing system to inquire about directions as they also engage in conversation with one another on topics related and unrelated to the request for directions. As a third example, the computer system may have to identify a collective intent of a party and by the individuals thereof, and to prioritize such intents and triage interactions with interacting parties. For instance, in the digital receptionist example, a third person may appear to walk with the two individuals who jointly seek directions yet be approaching and waiting to engage the receptionist about another task, or may momentarily interrupt the existing conversation. In the learning game example, multiple children may respond simultaneously, overlapping with each other, and the computer system might endeavor to impose and regulate turn-taking.","The present disclosure addresses the challenge of endowing computing systems with the competency that might be expected in people for recognizing, communicating, and coordinating with multiple people and\/or other computational agents to achieve one or more goals. Competencies involved in recognizing the intents, attention, roles, and relationships among individuals are not only useful in situations where a computing system is playing the role of a personified digital receptionist or robot, but may extend to a broad spectrum of applications and scenarios. The abilities to observe and understand multiple parties may be harnessed in numerous settings where machines interact with people and, increasingly, where machines interact with one another. Such applications include the extension of simple policies to more sophisticated, valuable behaviors, enabling machines to act with the awareness attributed to human intelligence in the past.","In view of these complexities and opportunities for enhanced automated services, a computer system may be developed to manage the interactions of a set of individuals with a service component, which may be configured to provide a set of services to individuals. The computer system may be devised to identify the individuals within a scene, and to assign such individuals to parties based on contextual factors. The computer system may also track the attention of each individual and the engagement of the parties with the computer system, and to manage interactions with the parties, such as initiating and maintaining an interaction, pacing and planning of conversation, and handling interruptions by various individuals. The computer system may also deduce information about each individual and party based on the conversation, contextual factors such as appearance, objects carried, spatio-temporal trajectory, proximity, pose, eye gaze, sustained attention, gestures, and the history of the individual during previous interactions; in addition to facilitating the services provided by the service component, this information may promote the interaction with the individual and party. These capabilities may permit the computer system to interact more adeptly and naturally with individuals in real-world scenarios, thereby leading to a more effective, efficient, helpful, and pleasant interactive experience.","To the accomplishment of the foregoing and related ends, the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects, advantages, and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.","The claimed subject matter is now described with reference to the drawings, wherein like reference numerals are used to refer to like elements throughout. In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident, however, that the claimed subject matter may be practiced without these specific details. In other instances, structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.","Many real-world computing scenarios involve an interaction of a computer with an individual who wishes to request and receive services. This class of computer systems may be viewed as a service component that has access to a set of resources, that safeguards or regulates access to these resources through a business logic, and that communicates with a user who wishes to access such resources in a particular scenario. As a first example, an automated ma\u00eetre d' of a restaurant may interact with a user who wishes to inquire about the cuisine, request or change a reservation, place an order, or pay a bill. As a second example, an automated taxi service may facilitate a driver and passengers by accepting a destination, providing recommendations and information about locations, and settling a taxi fare. As a third example, a receptionist of a building may identify visitors, arrange appointments and conferences, and mediate access by guests to the building. Such service components may comprise a set of input components (e.g., keyboards and microphones); a set of output components (e.g., speakers and displays) and a service system that can accept various types of requests from the individual, apply a business logic to determine how such requests may be handled, and communicate to individuals the results of such business logic.",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 1","b":["10","10","10"]},"Contemporary systems for such scenarios often interact with individuals on a first-come, first-served basis. For example, a kiosk may operate in a passive or standby mode until activated by a user (e.g., by touching a touchscreen, speaking into a microphone or handset, or swiping a badge or fingerprint through a corresponding reader.) The kiosk may then initiate an interaction, such as by displaying a main menu or prompting the user to state a request, and may process subsequent input from the user through the business logic that safeguards access to the resources. When the interaction with the user is concluded (e.g., when the intent of the user is satisfied, or when the user abandons the interaction), the kiosk may reenter the passive or standby mode until activated by a subsequent user, and may then initiate a new interaction.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 2","FIG. 1"],"b":["22","24","24","34","10","36","34","32","32","30","34","34","24","28","32","34"]},"At the beginning of the exemplary scenario of , the service component  may be idle, awaiting a beginning of an interaction with an individual. At a first time point , an individual  may initiate an interaction  with the service component  through the interface . The knowledge system  may evaluate the input from the individual  received through the microphone, determine that the individual  wishes to initiate an interaction , and issue a responsive greeting on the display. At a second time point , the individual  may issue a natural-language request to the interface  as part of the interaction , such as a request for a reservation. The interface  may parse the request (e.g., a variety of semantically equivalent natural-language queries, such as \u201ccan I get a table?\u201d, \u201cwe need a table,\u201d and \u201ctable, please\u201d) and may deliver normalized input (e.g., \u201cRequest Table\u201d) to the service component  for processing through the knowledge system . If the request is found to be valid and satisfiable, the service component  may update the resource set  according to the request (e.g., by adding a reservation in a reservation set for the individual ) and may notify the individual  through the interface , e.g., on the output device .","Also at the second time point  of , a second individual  may approach the service component , and may form a queue behind the first individual  while awaiting an opportunity to interact with the service component . At a third time point , the individual  may terminate the interaction  with the service component , e.g., by saying \u201cDone,\u201d and the service component  may respond (through the interface ) by terminating the interaction . At a fourth time point , the first individual  departs, and the service component  enters an idle state. At a fifth time point , the second individual  may take the opportunity to interact with the service component  that is now idle, and the service component  may initiate a second interaction  (through the interface ) with the second individual . In this manner, the service component  may serve various individual  in series, whereby a first interaction  with a first individual  is initiated, processed through the knowledge system , and concluded before a second interaction  with a second individual  may be initiated. The interface  may facilitate the service component  by parsing input and rendering output, thereby enabling the service component  to focus on applying the business logic of the knowledge system  to manage access to the resource set . Service components  and interfaces  that interact with individuals  as in the exemplary scenario of  may be easily designed, e.g., as a menu system or a natural language parser; may interact with individual  in many ways, e.g., by voice, text, or telephonic notepad; and may be used in a wide variety of service-oriented scenarios.","However, in many real-world scenarios, the service component  illustrated in  may be inadequate, inefficient, or frustrating to use in several aspects. Many interactions  with the service component  through an interface  may involve more than one individual  comprising a party. The individuals  may have a common intent as part of the party, but may also have separate intents , and multiple individuals  of the party may attempt to communicate with the service component  in sequence or even concurrently; they may also communicate with each other. Additionally, multiple parties may be present, and may attempt to communicate with the service component  concurrently. For example, a first party may temporarily suspend an interaction  with the service component  (e.g., during a side conversation), and a second party may attempt to interpose a brief interaction  with the service component  in the interim. These and other complications may arise from the multi-individual and multi-party nature of real-world scenarios, and a service component  that is not equipped to manage such interactions may be insufficient.","One such scenario involves the common experience with elevators, which typically involve the use of buttons to order elevators to schedule floors as destinations, and open and close doors, where, for example, timers and beam-breaking detectors are used to control how long elevator doors remain open. The operation of elevators can be extended by analysis of a scene external and\/or internal to elevators. One or more parties may be viewed; their intents to use an elevator may be inferred; and elevators can be ordered and doors held elegantly and with etiquette when someone is at a distance or is involved in the finishing of a conversation, thereby avoiding the typical incidents of people running to catch the elevator, extending their arms to break beams or to even pushing buttons to order elevators to a floor. These ideas may be applied to control electric doors, which today often exhibit a great number of false positive openings when people are detected as being in proximity of a sensor. People and intelligent computational scene analyses and learning may identify that one or more people are walking past a door and not through the door entry, and may recognize spatio-temporal trajectories and the associated intents to pass by the door or use a door. Moreover, these inferences may be made in advance of when the inference might ordinarily be harnessed by the automated door system in making decisions. The techniques discussed herein may be developed and utilized to provide more adept, multi-party computer interfaces in many such scenarios.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 3","b":["26","22","24","32","22","24","32","22","50","22","24","32","24","26","22","52","22","24","54","40","22","22","40","22","22","32","40","26","24","40","22","32","22","40","32","24","26","32","22"]},"Additionally, at the third time point  of , a third individual  might also approach the service component  who is awaiting an availability of a previously requested table. At a fourth time point , while the first individual  and second individual  are engaged in a brief side conversation, the third individual  may interpose an inquiry to service component  (through the interface ) about the previous request. However, the interface  does not identify that the request is being issued by someone other than the first individual  with whom the first interaction  is transpiring. The interface  therefore presents the input to the service component , which attempts to process the input by the third individual  as part of the first interaction , but finds this input inconsistent with the first interaction , and the interface  reports an unhelpful message to the third individual . At the fifth time point , the third individual  provides input to the interface  abandoning the inquiry and departs. The interface  duly presents the received input to the service component , which interprets this input as an abandonment of the first interaction . Consequently, when the first individual  resumes the interaction with the service component  regarding the table request, the service component  initiates a second interaction  without the information provided during the first interaction . The output presented by the interface , although a logical result of the application of the input received by the interface  through the knowledge system , may thereby confuse and frustrate the first individual .","The exemplary scenario of  illustrates several shortcomings of a single-individual interface  in a real-world scenario. As a first example, the interface  was unable to recognize the presence of the second individual  or the relationship between the second individual  and the first individual , and was unable to deduce that the request of the first individual  might be expanded to accommodate the second individual . Moreover, the interface  was unable to understand the context of the conversation between the first individual  and the second individual ; and instead of applying the indirect request within this conversation to the previous request of the first individual , the interface  accepted the speech of the first individual  as input directed to the service component , which was inapplicable to the interaction . As a second example, the interface  was unable to distinguish the first individual  from the third individual , and failed to identify the inquiry of the third individual  as a separate interaction from the currently active first interaction . Moreover, the interface  failed to relate the inquiry of the third individual  to a recent interaction with the third individual , which may have occurred only a few moments before the first time point . As a third example, when the first individual  attempts to resume the first interaction  (perhaps without even being aware of the interposition of the third individual ), the service component  responds in an amnesiac manner by initiating a second interaction  with a greeting, potentially confusing and frustrating the first individual  and the second individual . These and other limitations arise from the inability of the interface  to identify and process concurrent interactions  with multiple individuals  comprising multiple parties, as may often arise in many real-world scenarios.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 4","b":["32","24","22","22","26","70","22","24","32","22","72","22","26","72","74","22","32","24","76","40","22","32","40","72","40","22","40","22","40","40","22","32","40","72","32","22","40","26","72","32","24","40","72","32"]},"As further illustrated in , when the third individual  approaches the service component , the third individual  may stand apart from and not oriented to the first individual  and the second individual , and there may be no acknowledgement of familiarity or conversation. The interface  may identify the third individual , but may associate the third individual  with second party , as no relationship is detected with the individuals of the first party . When the third individual  speaks to the interface , the interface  may initiate a second interaction  with the second party . The interface  may also choose to permit this interposed second interaction  because of the implied suspension of the first interaction  with the first party . (By contrast, if the third individual  had interrupted the first interaction , the interface  may have politely asked the third individual  to hold the inquiry until the first interaction  was complete.) Moreover, the interface  may identify the third individual  from a recently completed interaction with the third individual ; may interpret the inquiry of the third individual  in the context of the recent interaction; and may respond in a more natural and helpful manner. Finally, when the first individual  resumes the interaction  with the with the service component , the interface  may identify the first individual  and the first party , and may resume the interaction  in a natural manner. The smoother and more helpful handling of these interactions  by the interface , in contrast with the discontinuous and confusing interactions  illustrated in , are made possible by the configuration of the interface  to identify multi-party interactions , and to interact with various individuals  in the context of the identified parties  and the interactions  therewith.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 5","FIG. 4","FIG. 3"],"b":["100","90","22","92","100","24","22","100","94","28","96","98","32","22","24","34","36","22"]},"Accordingly, the exemplary system  of  may be configured to manage interactions of the service component  with at least two parties  within the scene . For example, the exemplary system  may comprise an individual identifying component , which may be configured to identify individuals  within the scene  (e.g., through a face recognition algorithm operating on video input received from the input component .) The individual identifying component  may therefore generate an individual set , comprising representations of the individuals  identified within the scene . The exemplary system may also comprise a party identify component , which may be configured to associate individuals  within the scene  (e.g., those represented in the individual set ) with at least one party  (e.g., by evaluating the proximity of respective individuals , the spatio-temporal trajectory of individuals , the orientation of the individuals  with respect to others, communications and mutual attention among individuals  indicating affiliation or familiarity, and communications directed to the service component  indicating affiliation.) The party identifying component  thereby generates a party set  comprising representations of the respective parties  identified within the scene  and associations of the individuals  represented in the individual set . The exemplary system  also comprises an interaction tracking component , which may be configured to track interactions  with at least one interaction party  (i.e., with one or more parties  participating in a particular interaction .) For respective interactions , the interaction tracking component  may receive communications from individuals  of the interaction parties , and based on these communications, may direct the service component  in communicating to the interaction parties . As a first example, the interaction tracking component  may evaluate the input received from the individuals  of an interaction party  and may provide information to the service component  that may be used in the knowledge system , e.g., which interaction  is to be currently addressed by the service component , and the number of individuals  within each interaction party  in the active interaction . As a second example, the interaction tracking component  may receive output from the service component  (e.g., scripted responses generated by the knowledge system ) and may relay this information to particular individuals  and interaction parties  through the output device . In this manner, the exemplary system  may facilitate the service component  in interacting with the individuals  in a multi-party manner, thereby enabling some or all of the advantages illustrated in . Moreover, these advantages may be achievable for many types of knowledge system  that may be useful within a wide range of scenarios.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 6","b":["120","26","24","72","92","120","28","94","24","30","96","98","22","92","120","122","124","22","92","96","120","126","22","72","22","26","72","22","120","128","26","114","132","120","134","22","114","26","136","24","114","22","24","22","72","120","32","138"]},"Still another embodiment involves a computer-readable medium comprising processor-executable instructions configured to apply the techniques presented herein. An exemplary computer-readable medium that may be devised in these ways is illustrated in , wherein the implementation  comprises a computer-readable medium  (e.g., a CD-R, DVD-R, or a platter of a hard disk drive), on which is encoded computer-readable data . This computer-readable data  in turn comprises a set of computer instructions  configured to operate according to the principles set forth herein. In one such embodiment, the processor-executable instructions  may be configured to perform a method of managing interactions of a service component with at least two parties within a scene, such as the exemplary method  of . In another such embodiment, the processor-executable instructions  may be configured to implement a system for managing interactions of a service component with at least two parties within a scene, such as the exemplary system  of . Many such computer-readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.","The techniques discussed herein may be devised with variations in many aspects, and some variations may present additional advantages and\/or reduce disadvantages with respect to other variations of these and other techniques. Moreover, some variations may be implemented in combination, and some combinations may feature additional advantages and\/or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments (e.g., the exemplary method  of  and the exemplary system  of ) to confer individual and\/or synergistic advantages upon such embodiments.","A first aspect that may vary among embodiments of these techniques relates to the scenarios in which embodiments of these techniques may be utilized. As a first variation, these techniques may be used as an interface to many types of service components , which may be configured in many ways to manage access to a resource set  (such as a set of services that may be requested and performed on behalf of the individuals  according to a business logic.) As a first example, the service component  may comprise a knowledge system, such as the exemplary knowledge system  of , which may be configured to receive requests presented in a normalized manner, to perform various actions on the resource set , and to provide scripted output. As a second example, the service component  may utilize a learning function, such as a fuzzy logic classifier or a neural network, to infer the actions to be performed on the resource set  on behalf of the individuals  and parties . Additionally, such service components may operate in a variety of real-world service-oriented scenarios, such as an automated ma\u00eetre d' of a restaurant; an automated taxi service that facilitates the taxi transaction; or an automated receptionist or security guard of a building. In some of these scenarios, the service component may handle an interaction  involving multiple parties , e.g., an automated auction mediator that handles a concurrent set of auctions, where each auction involves a selling party  and one or more bidding parties .",{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 8","b":["150","22","72","22","22","22","26","22","24","22","22","22","22","22"]},"Instead, and as illustrated in , the exemplary techniques may be utilized to permit multiple individuals  in various parties  to perform an interaction  together. For example, an interface  to a service component  that manages access to a resource set  (e.g., a flight check-in database) through a knowledge system  (e.g., the business logic of handling passenger check-in) may be connected to a set of kiosks, each featuring input devices  (e.g., a camera and a microphone) and an output device  (e.g., a display.) The configuration of the kiosks through a multi-party interface  may permit each kiosk to provide a wider array of services and to achieve a higher efficiency of use. A first kiosk  may check in a party  by allowing the individuals  of the first party to interact with the kiosk together (e.g., \u201cboth passengers, please answer the following security questions together . . . \u201d) By contrast, the same process may have involved separately checking in each individual , either in series on a single kiosk or by concurrently occupying two kiosks. A second kiosk  may handle an interaction  involving multiple parties, such as a negotiation and allocation of available seats among a set of standby travelers for a flight. Such multi-party transactions may be difficult to perform on a kiosk with a single-individual interface, and may have involved a representative of the airline, but may be readily achievable through a multi-party interface  such as described herein.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 9","FIG. 9"],"b":["160","22","72","92","22","162","164","22","164","22","22","164","160","166","96","164","164","164","24","114","164","164","114","164","164","166","22","164","166","164","166","162","22","162","22","166","164","164","22","22","22","22","166"]},"Upon passing through the door , the individuals  may enter a second scene  comprising the lobby of the building. Whereas the door  provides building access to all visitors who wish to enter, the second scene  may enable restricted access to the building through one or more gates , which may be unlocked for authorized visitors but may remain locked to obstruct entry by unauthorized individuals. In many contemporary scenarios, such gates may be operated by comparatively primitive security mechanisms, such as badge readers that may read security badges presented by individuals  or keypads configured to accept a security code. Alternatively, a human receptionist may be present to interact with individuals  and to operate of the gates. By contrast, in the exemplary scenario  of , an exemplary system  may monitor the second scene  and may control the gates  through an automation component, e.g., a set of motors configured to open and close the gates , or a mechanized lock that permits or restricts an attempt by an individual  to push through the gate . The exemplary system  may be equipped with various input devices  (e.g., a camera mounted atop a display and a pair of microphones that may triangulate the location of speaking individuals ) and\/or output devices (e.g., a set of speakers  and a display, whereupon may be rendered an avatar  presented as an interface to the service component , i.e., the business logic involved in servicing individuals  present in the lobby.) The exemplary system  may verify the security clearance of individuals  and may admit authorized individuals  by opening or unlocking the gates . Moreover, the exemplary system  may provide more sophisticated services, such as allowing an employee to register a visitor; allowing visitors to contact employees to request access to the building; arranging meetings within the building among employees and visitors; providing directions to individuals  within the building and corporate campus; and requesting shuttles for individuals  who wish to leave the building. These services may often involve the authentication of individuals , e.g., through face, voice, or other biometric recognition or by a card reader; the association of individuals  with parties ; the identification of relationships between individuals ; and the determination and prioritization of intents of the individuals , as well as the communication with the individuals  in a natural and sociable manner. The exemplary system  may therefore exhibit the social awareness of a receptionist, which may be more pleasant, helpful, and efficient than a basic security mechanism.","Authorized individuals  who pass through the gates  may then enter a third scene , involving an elevator  configured to transport individuals  vertically among the floors of the building. Many contemporary elevators are controlled by comparatively primitive interfaces, such as push-button interfaces that enable individuals to perform basic elevator operations, including selecting floors and opening or closing the doors of the elevator. However, the exemplary scenario  of  features an exemplary system  configured to operate an automation component (e.g., a winch controlling the raising and lowering of the elevator  and the motor operating the doors  of the elevator ) on behalf of individuals  operating in a multi-party setting. The exemplary system  may be equipped with various input devices  (e.g., cameras and microphones positioned at each floor and within the elevator ) and output devices  (e.g., a speaker and a display rendering an avatar  within the elevator .) Utilizing these capabilities, the exemplary system  may detect individuals  within the third scene  (including the exterior proximity of the elevator portal on various floors, as well as the interior of the elevator ) and may allow such individuals  to request transportation to various floors, e.g., through push-button interfaces or speech recognition. The exemplary system  may also provide more sophisticated functionality. As a first example, the exemplary system  may predict the intent of an individual  to board the elevator  (perhaps while the individual  is far down the hallway), and may automatically send the elevator  to the floor of the individual . As a second example, the exemplary system  may identify parties  and may query the parties  for destinations instead of individually querying several individuals  of the same party . As a third example, the exemplary system  may utilize face recognition to identify an individual , consult a meeting schedule to predict a destination of the individual , and convey the individual  to the correct floor without prompting, and may even direct the individual  to the location of the meeting. As a fourth example, the exemplary system  may allocate a set of elevators more efficiently, e.g., by allocating one elevator  to pick up individuals  on several floors who are headed to the same floor, or by detecting an elevator  filled to capacity and passing any floors with boarding individuals. The exemplary system  may therefore exhibit the social awareness of a human elevator operator, and may more easily communicate with individuals  while more efficiently and desirably allocating the resources of one or more elevators . In this manner, the exemplary systems presented in  operate, individually or in cooperation, to provide a more capable, efficient, and user-friendly interface between individuals  and parties  and the service components  and automation components regulating the provision of various physical resources. Those of ordinary skill in the art may devise many such scenarios in which the techniques described herein may be utilized.","A second variation of this first aspect involves the types of devices  that may be utilized in multi-party interfaces  such as described herein. As a first example, a diverse set of input devices  may be configured to detect various individuals  using and communicating with the interface , e.g., to generate input pertaining to the at least one individual , and to deliver the input to the individual identifying component . A microphone may capture voice input from an individual , and a keyboard, touchscreen, or other tactile device may capture data entry form the individual . A still or video camera may capture an image of an individual , and an infrared camera, light sensor, or other device may detect the presence of individuals  and distinguish among individuals  within the scene . Biometric devices may detect many physiological properties of an individual , such as a face detector that may measure a face and match the metrics against a face-matching database of known individuals , or a fingerprint reader that may identify an individual  according to a fingerprint. Other types of scanners may detect other identifiers of an individual  (e.g., a radiofrequency identification [RFID], barcode, or magnetic scanner configured to read an identification card or credit card of the individual .) Moreover, these input devices  may cooperate in detecting, identifying, and locating an individual ; e.g., an array of microphones may, in addition to accepting voice input from an individual , triangulate the position of the individual  within the scene , while a videocamera may identify the individual  using a face-matching database.","As a second example of this second variation, a diverse set of output devices  may be operated by the interface  (or directly utilized by the service component ) to render the output of the service component , e.g., to receive output from the interaction tracking component  to be delivered to at least one individual  associated with at least one party , and to render the output to the at least one individual . For example, a speaker may present a synthesized voice, while a display may present text or pictorial output to an individual . These components may also operate synergistically, e.g., to produce a visual representation of an avatar of the service component  that speaks to individuals  using a simulated voice. Additional components may be manipulated in the interaction , such as a printer (e.g., configured to print boarding passes for air travelers), a vehicle operated in whole or in part by an automated driver, and a security turnstile operated by an automated receptionist or security guard.","As a third example of this second variation, the system may comprise various resources to be regulated by the service component . In a first such scenario, the system may be devised to regulate one or more virtual resources, such as a database storing various types of data (e.g., the reservation book for the restaurant in the exemplary scenario  of ) or a computing resource that may perform various tasks on behalf of such individuals  (e.g., a ticket booking system in an air travel scenario that may perform various ticket issuing and validating services on behalf of individuals ). In a second such scenario, the resource may comprise a physical resource that may be controlled by an embodiment of these techniques, such as a door, a gate, an elevator, a printer, a dispenser, a robot, or a train or other type of vehicle. The system may therefore comprise an automation component that is configured to control the physical resource according to the service component. As a first example, the service component may specify the logical operations to be performed by an elevator to convey multi-individual parties to different floors of a building, and an automation component may accept output from the service component and may control the operation of the elevator to perform the output (e.g., opening and closing the elevator doors and moving among the floors of the building.) As a second example, the service component may represent the logic of a receptionist of a building to which access is regulated by a security mechanism, such as a gate. The system may therefore include a gate actuator that may unlock the gate to permit authorized visitors to enter the building (as determined by the service component) and may lock the gate to obstruct entry by unauthorized individuals. Many such resources may be included in many such scenarios utilizing the techniques discussed herein.","A third variation of this first aspect involves the architecture of embodiments of these techniques. While the exemplary scenario  of  illustrates one exemplary system , many such architectures may be utilized in other embodiments, e.g., to customize the interface  for a particular scenario or to confer additional advantages upon the embodiment.  presents an exemplary scenario  featuring a more detailed architecture of these techniques, comprising a set of components of a computer  wherein the interactions of a service component  are managed by an exemplary system  configured as described herein. The computer  might also comprise, e.g., a set of input devices, such as one or more cameras  and one or more microphones ; a set of output devices, such as a display  and a speaker ; and a processor  that may execute the portions of the exemplary system  that are configured as processor-executable instructions. The camera(s)  may deliver output to a face tracking algorithm , which may identify faces of individual  within a scene . The microphone(s)  may deliver output to a speech recognizer , which may identify voices and detect spoken words from the individuals  within the scene. Additional input processing may also be performed; e.g., the video input from the camera(s)  may be evaluated to identify visual characteristics of respective individuals , such as the position of a visually identified individual  within the scene , and the audio input from an array of microphones  may be triangulated to identify a position of a speaking individual  within the scene . Together, these input variables may be delivered to the exemplary system . Similarly, the output of the exemplary system  may be delivered to the display  and to the speaker  by way of some output rendering components. For example, an avatar renderer  may render a visual representation of an avatar of the service component  to be displayed on the display , and textual output may be processed by a speech synthesizer  to synthesize a voice of the avatar to be delivered through the speaker .","Within this computer , the exemplary system  may be provided to mediate the input and output data and the service component . For example, the input may be delivered to the individual identifying component , which may be configured to identify individuals  within the scene , and to the party identifying component , which may be configured to associate individuals  within the scene  with at least one party . However, as illustrated in , the architecture of the interaction tracking component  may be divided into more specific units.","As a first example, the interaction tracking component  may comprise an interaction establishing component , which may be configured to track interactions  that may be established between the service component  and at least one interaction party  of an interaction . For example, the interaction tracking component  may be configured to identify when an individual  or party  indicates an intent to establish an interaction  with the service component , or to join an existing interaction ; which interaction  the service component  is currently active, and whether an interaction  is inactive (e.g., if an individual  is distracted by a side-conversation); and when interaction  are terminated by the interaction parties  or the service component . The interaction establishing component  may therefore serve as an interface to other components of the interaction tracking component  (e.g., \u201cwho wishes to speak to the service component  first?\u201d) As one example, output to be delivered to multiple interaction parties  may be enqueued, and the interaction establishing component  may triage the delivery of information to the interaction parties  based on the priority of the information, the costs of waiting for the various interaction parties, social constraints, and social etiquette rules.","As a second example, the interaction tracking component  of  may comprise an interaction coordinating component , which may be configured to, for respective interactions , coordinate communications of the service component  with individuals  of the interaction parties . For example, the interaction coordinating component  may coordinate a conversation by detecting whether an individual  in an interaction party  is speaking, which individual  is speaking, whether the individual  is speaking to the service component  or to someone else, when each individual  has the conversational floor (i.e., the right to speak according to conversational norms), and when the service component  has the conversational floor, i.e., an opportunity arises to respond with output from the service component . The interaction coordinating component  might also direct output from the service component  to a particular individual  within an interaction party , or may direct output concerning all individuals  of interaction party  to a party leader of the interaction party . Additionally, the interaction coordinating component  may detect and handle interruptions by individuals . Depending on context, the interaction coordinating component  might allow an individual  to interrupt the service component , or might attempt to preclude or overcome an interruption. In exceptional cases, the interaction coordinating component  may identify when a speaking individual  may be interrupted by the service component . The interaction coordinating component  may therefore establish and respect a natural conversational pacing of the service component  while communicating with interaction parties  within an interaction  (e.g., \u201cwhen may the service component  speak?\u201d)","As a third example, the interaction tracking component  of  may comprise a knowledge component , which may be configured to identify information items about the individuals  within the scene . As a first example, the knowledge component  may endeavor to classify particular individuals  based on video input, such as by the type of clothing worn, and\/or audio input, such as a stress level detected in the voice of an individual . As a second example, the knowledge component  may record a profile of individuals  with whom the knowledge component  has previously interacted. When an individual  approaches the service component  for a second time, the knowledge component  may match the face and\/or other biometrics (including for instance voice, height, or even clothing) of the individual  to the stored profile of the individual , and may retrieve the known information about the individual , such as by continuing a previously interrupted interaction  or by predicting the current intent of the individual . The knowledge component  may deliver the information items detected about an individual  to the service component , which may use such information items in providing the services to the individual . As another example, the knowledge component  may also exhibit proactive awareness of the scene , such as by monitoring individuals  and parties  that are not yet involved in an interaction  for information that might later be used to initiate an interaction . For example, an individual  may be identified as waiting in a restaurant lobby, until a second individual  arrives and speaks with the individual . If the individual  then approaches the service component , the knowledge component  may identify the individual  and the second individual  as a party  that is likely to request a table for two.","As a fourth example, the interaction tracking component  of  may comprise a conversation component , which may be configured, for respective interactions , to deliver output from the service component  into the interaction  with the at least one interaction party . For example, the conversation component  may determine and formulate questions to be asked of the individuals  and the interaction parties  in order to solicit information to be used by the service component , and how to deliver the output of the service component  to various interaction parties  and individuals . The conversation component  may therefore determine, based on the input from the individuals  and interaction parties  and from the output of the service component , what, when, how, and to whom information is to be communicated by the service component . Moreover, the conversation component  may deliver selected conversational output to the interaction coordinating component , which may identify an opportunity to speak (through the speaker  via the speech synthesizer ) to the target of the communication, which may in turn rely on the interaction establishing component  to determine when the interaction  of interest is active. In this manner, the architecture of the interaction tracking component  may interoperate to achieve the directing of the service component  in communicating with the individuals  in a multi-party, multi-individual scenario. However, other architectures may be devised by those of ordinary skill in the art while implementing the techniques discussed herein.","A second aspect that may vary among embodiments of these techniques relates to the information that may be gathered about individuals  in order to identify such individuals , to identify the associations of individuals  with parties , and to interact with such individuals  in a multi-user, multi-party manner. In social situations, humans may identify many types of behaviors that suggest roles, relationships, and intentions of individuals  and parties  within a scene . As a first example, the relative spatio-temporal trajectory, proximity and facing of a first individual with respect to a second individual may be indicative of an interaction therebetween or a party association. For example, two individuals  may be identified as a party  if they are positioned near and facing each other, if they are walking together in proximity and at approximately the same pace, if the first individual  catches up with the second individual  and matches pace; or may be identified as different parties if they are standing near but facing away from each other, or if they are in proximity only because the scene is small or crowded. As a third example, natural language evaluation applied to speaking individuals  within a scene  may be capable of differentiating individuals  who are discussing a matter as a party  from individuals  who are engaged in trivial conversation, or who are not speaking to each other (e.g., who are instead talking on cellphones.) As a third example, physical gestures by and among individuals may indicate relationships (e.g., handshakes or a nod of the head) and\/or intentions (e.g., in the exemplary scenario  of , an individual  may signal the elevator  by pointing at the elevator, nodding, or walking briskly toward the elevator, or may dismiss an offer for the elevator  by waving away the elevator , shaking the head, or walking slowly or tangentially in the vicinity of the elevator .) As a fourth example, the gaze of an individual  may be detected, e.g., by a face identification algorithm that may extrapolate the orientation of the individual's head and eyes, and may project the orientation of the eyes of the individual  to identify the focal point of the gaze of the individual . Those of ordinary skill in the art may identify many such behaviors, and to utilize such behaviors in many of the evaluative processes involved in the techniques discussed herein.","A third aspect that may vary among embodiments of these techniques relates to the identification of individuals  and parties  within the scene , such as may be performed by the party identifying component  in the exemplary system  of . Many factors may be included in the identification of individuals  and the association of such individuals  with parties . An embodiment of these techniques may be configured to identify individuals  within the scene , such as with a face tracking algorithm . Moreover, the embodiment may be configured to identify particular features of an individual , such as the position or movement of the individual within the scene  and the orientation of the individual  (e.g., where the user is looking or facing.) Based on this information, the interface  may then associate each individual  with one or more parties . For example, if positions of individuals  are identified, a party identifying component  may associate an individual with one or more parties according to the position of the individuals  within the scene , relative to the positions of other individuals  who are associated with a party . Embodiments may also take into account various behaviors, such as the relative spatio-temporal trajectory, proximity and orientation of respective individuals , a natural language analysis of the dialogue among individuals, and nonverbal gestures that indicate mutual familiarity and confederacy. Moreover, parties may change over time as individuals  join or leave a party , as parties  merge, or as a party  splits into two or more parties  that seem to have different agendas. Embodiments of these techniques may therefore monitor the ongoing social relationships of the individuals  to update the identification of parties  associated therewith.",{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 11","b":["220","32","96","32","22","92","22","22","32","22","72","222","224","222","226","222","224","228","230","234","32","232","92","230","32","232","234","236","230","32","238","240","242","22","72","32","22","244","32","22","22","72","32","72","22","92","22","72"]},"A fourth aspect that may vary among embodiments of these techniques relates to the tracking of interactions  by the parties  with the service component , such as by tracking the engagement of various individuals  with the service component . This tracking may be performed (e.g., by an interaction establishing component ) to orient higher-order components of the embodiment (such as the interaction coordinating component , the knowledge component , and the conversation component  of ) to the individuals  of a particular interaction party  of an interaction . A simple embodiment of this tracking may involve waiting for one of the identified parties  to indicate an intent to interact with the service component , engaging that party  in an interaction  through completion, and then awaiting an intent to interact from another party . Even this simple embodiment may present advantages, e.g., by identifying the individuals  within the scene  who comprise the interaction party ; however, more sophisticated embodiments may incorporate additional features for tracking an interaction. As one such example, the embodiment may track multiple interactions  (such as multiple sets of interaction parties  standing in a queue), may serially select one interaction  at a time as an active interaction, may process the active interaction through completion, and may then select the next interaction  as the active interaction. More sophisticated embodiments may evaluate the behaviors of the individual , e.g., indications that the individual  is anxious to speak or is frustrated with the logic or output of the service component.","In some variations of this fourth aspect, the embodiment may designate an engagement status of various parties  with the service component , such as an \u201cengaged\u201d status (currently interacting with the service component ), an \u201cunengaged\u201d status (not currently interacting with the service component ), and a \u201cwaiting to engage\u201d status (intending to interact with the service component . These designations may be made, e.g., according to the positions and orientations of respective individuals  as illustrated in , and may facilitate the selection of interactions  to be processed by the service component . As a first example, if at least two parties are identified in a \u201cwaiting to engage\u201d status while no party is in an \u201cengaged\u201d status, an interaction  may be initiated or resumed with at least one of these waiting parties . As a second example, if a party  enters a \u201cwaiting to engage\u201d status (e.g., by first approaching the service component  or by ending a side-conversation and turning toward the service component ) while the embodiment is already engaged in another interaction  with an interaction party , the embodiment may acknowledge the party  in the waiting state (e.g., \u201cI'll be with you in a moment.\u201d) As a third example, if the service component  identifies a party  that is to be engaged, but if the party  is in an unengaged status, the embodiment may solicit the party  to engage in an interaction .","Other variations of this fourth aspect involving the designation of engagement statuses of various parties  involve an assignment of priority to respective interactions . Priority may be assigned in many ways, e.g., by order of parties  in a queue, by the number or identities of individuals  comprising the party , or by the anticipated duration of the interaction . As a third variation, if multiple parties  are identified in a \u201cwaiting to engage\u201d status, the party  having the highest priority may be selected first for an interaction . As a fourth variation, if the service component  is engaging a first party  (in an \u201cengaged\u201d status) when a second party  enters a \u201cwaiting to engage\u201d status that has a comparatively higher priority than the first party, the lower priority interaction  may be suspended, and the higher priority interaction  may be initiated; and when the higher priority interaction  concludes, the lower priority interaction  may be resumed.","As a fifth example of this fourth aspect, an embodiment of these techniques that manages several interactions  may select a particular interaction  as an \u201cactive\u201d interaction  to be engaged, and may suspend the other interactions  to be handled later. Accordingly, the embodiment may be equipped with an attention indicator, which may be controlled by the embodiment to indicate the interaction parties  of the active interaction , in addition to directing the service component  to interact with the interaction parties  of the active interaction . When the active interaction  is complete, a second interaction  may be selected, and the attention indicator may then indicate the interaction parties  thereof. In this manner, the embodiment may signal to the individuals  which parties  are permitted to interact with the service component . As one such example, the embodiment may comprise a display, upon which may be displayed an avatar of the service component  (e.g., a visual character representing the service component .) The avatar may therefore present a friendly, interactive agent that may perform services on behalf of the parties  by interacting with the service component . Moreover, the avatar may serve as an attention indicator. For example, if the positions of respective individuals  within the scene  may be determined, the gaze of the avatar may be directed to focus on an interaction party  in order to signal the active interaction . This may be achieved by computing a direction from the display to the position of an individual  of the interaction party , displaying the avatar focusing in the direction of the individual . Alternatively or additionally, the avatar may emulate behaviors, e.g., a depiction of nodding while an individual  is speaking to indicate that the service component  understands the intents and requests of the individual . Those of ordinary skill in the art may devise many ways of managing the interactions with the service component  while implementing the techniques discussed herein.",{"@attributes":{"id":"p-0067","num":"0066"},"figref":["FIG. 12","FIG. 1"],"b":["32","24","10","32","174","32","250","224","228","32","32","256","72","72","32","26","32","228","22","224","224","32","252","224","224","174","224","252","258","32","174","228","228","254","252","32","254","260","252","224","224","256","262","32","228","32","26","22","224","32","254","174","228","228","32","32","26","72","24","26"]},"A fifth aspect that may vary among embodiments of these techniques relates to the coordination of interactions  with various interaction parties  and individuals  associated therewith, such as may be achieved by the interaction coordinating component  in the exemplary system  of . Once an embodiment has selected a party  with whom to initiate an interaction , communication may be established with the party  that simulates a natural dialogue. As a first variation, the output of the service component  may be directed to the interaction parties  according to a conversational \u201cturn-taking\u201d approach, wherein an interface  detects incoming communications from any interaction party  directed to the interface , and then provides information (both information generated in response to the input from the interaction parties , and new information that is relevant to the interaction ) during a communication opportunity, such as between periods of incoming communications. Such opportunities may comprise, e.g., periods of silence between vocalizations by the interaction parties ; periods of inactivity between touchscreen or keyboard input; or periods of stillness between hand gestures, such as by an individual  communicating via sign language. In this manner, the interface  may avoid interrupting or talking over any individual . However, in some scenarios, it may be desirable to interrupt a communicating individual , e.g., if urgent or time-sensitive information becomes available that may of significant interest to the individual . Therefore, as a second variation, the interface  may be configured to recognize high priority information, and to politely interrupt a communicating individual  in order to provide the high priority information (\u201cexcuse me, but your flight is about to depart . . . \u201d)","As a third variation, an embodiment may be configured to contend with interruptions by various individuals , who may or may not be a focus of attention (e.g., a member of an interacting party  in an active transaction; a member of another interacting party  in another transaction; or a member of a party  that is not interacting with the service component .) If such interruption occurs during a communication opportunity, such as when the interface  is communicating to an individual , the interface  may be configured to suspend the communications opportunity. Alternatively or additionally, the interface  may endeavor to react to the nature of the interruption. For example, a distraction of an interaction party  in an active interaction  may result in a suspension of the interaction , while an interruption of an active interaction  by another individual  may result in a prioritization of the intent of the interruption (is it an urgent or brief request? does the interrupting individual  seem anxious or stressed? etc.) and either a suspension of the active interaction  or a deferral of the interruption (e.g., \u201cI'll be with you in just a moment.\u201d) Behavioral cues utilized by such individuals  may also be emulated; e.g., a full-body depiction of an avatar may be depicted as standing nearer or oriented toward the individual  who is the current focus of attention of the service component .","As a fourth variation, an embodiment may be configured to direct the output of the service component  to different individuals , based on the nature of the output. For example, an avatar serving as an attention indicator may be rendered to look at an individual  to whom the presented information may relate. In one such embodiment, the party identifying component  may endeavor to identify, among the individuals  associated with a party , a party leader, who may (expressly or implicitly) be designated as the focal point of communication for the party . For example, the party leader may be identified as the individual  who first interacted with the service component , or the individual  positioned closest to the service component  or centrally aligned with the service component . This designation may be used to direct the output of the service component ; e.g., communications relating to the entire interaction party  may be directed to the party leader, while communications relating to a particular individual  in the interaction party  may be directed to the individual . This variation may be useful, e.g., for interacting with large parties  of several individuals , where it might otherwise be difficult to utilize an attention indicator (e.g., where an avatar  is directed to look.)",{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 13","b":["270","32","24","72","22","22","272","32","22","272","174","272","40","174","40","72","272","270","26","24","32","22"]},"A sixth aspect that may vary among embodiments of these techniques relates to the identification and use of knowledge of individuals  and parties  in the context of an interaction  (e.g., as may be achieved by the knowledge component  of .) As a first variation, many sources of information may be accessed to extract many types of information about various individuals . As a first example, information may be identified from various input devices . The position of an individual  within the scene  (e.g., an individual  entering a lobby of a secured building from the outside may be an unknown guest, while an individual  positioned past a security turnstile may be an authorized visitor or an employee.) Useful information may also be obtained from a visual analysis of an individual , such as the dress style of the individual  suggestive of a role or employee type, or an audio analysis of the individual , such as the degree of stress detected in the voice of the individual  suggesting an urgency of an interaction . As a second example, various data stores may relate useful information about an individual ; e.g., a database of known faces may enable an identification of the individual .","As a third example, a learning function may be used to extract useful information about an individual .  illustrates an exemplary scenario  featuring an automated classification of various individuals  according to the type of dress, as determined by a statistical classification analysis, such as that performed by a neural network, logistic regression, or a Bayesian-network classifier. A classification function  may be developed according to such statistical classification analysis and trained with a training data set, such as set of test images  of various individuals  and an identification of the dress type of the individual  (casual, professional, pilot uniform, police, etc.) The classifier function  may then be trained on the training data set until it is able to identify the dress type of the test images within an acceptable level of confidence. The classifier function  may then be included in an interface , which may subsequently capture images  (using a camera as an input device ) of a first individual  and a second individual  comprising a party  in a scene . The images  may then be provided to the classifier function , which may, for respective individuals, identify a dress type . The interface  may then use the identified dress type  to inform the services offered by the interface  to each individual. For example, in a hotel setting, the first individual  identified in professional attire may be offered business-class services, while the second individual  identified in casual attire may be presumed to be a tourist, and may be offered a map of the city and nearby tourist attractions.","Many types of information items may be identified and used in interactions  in various ways. One particularly useful set of information that might be identified relates to the intents of the individuals , such as a deduced reason for an individual  to wish to interact with the service component . An embodiment of these techniques may therefore be configured to identify information items regarding the individuals  within the scene , and to identify at least one intent of an individual  within a party . For example, an airline kiosk, having identified an individual  according to a face-matching algorithm and a lookup in a database of known faces, may attempt to match the identified individual  to flight reservations in order to deduce the flight for which the individual  is checking in. As a second example, interactions  with one or more individuals  may be stored to represent an interaction history with the individual , and subsequent interactions  may be initiated in the context of recently completed interactions  with the same individual(s) .",{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 15","b":["32","292","26","114","290","22","72","32","174","294","26","22","92","32","292","26","22","114","296","22","92","32","22","22","26","22","292","26","22","292","32","296","22","32","26","22","22","26","22","114","24","22"]},"A seventh aspect that may vary among embodiments of these techniques relates to the processing of input from individuals  and interaction parties , and the delivery of output from the service component  into an interaction  (e.g., as performed by the conversation component  of .) Whereas the coordinating of the interaction  may facilitate the protocol for the exchange of information, such as respecting a turn-taking dialogue, the management of the conversation relates to the particular items that are to be communicated, based on the identified information items and intents of the individuals  and interaction parties . For example, based on a particular intent of an interaction party , the conversation may be managed to filter output for relevance based on the intent of the interaction party , or may detect and alter redundant output (e.g., instead of asking each individual  in an interaction party  a set of security questions before boarding a flight, a conversation component  of an interface  may ask all individuals  in the interaction party  to respond together, thereby expediting a check-in process.)","As a first variation of this seventh aspect, after identifying the intents of the interaction parties  or individuals  thereof, an intent prioritizing component may be utilized to compute an intent priority of the intents of the individuals  (e.g., among a set of parties  with individuals  scheduled to board different flights, the intent priority may be based on the chronological proximity of the departure time of each individual's flight.) The service component  may then be directed to initiate an interaction  with the party  whose individuals  have a (singularly or averaged) high intent priority. Moreover, the service component  may be directed to suspend a lower priority interaction in order to initiate a higher priority interaction  with the higher priority interaction party , and may resume the lower priority interaction  once the higher priority interaction  is concluded.","As a second variation of this seventh aspect, a conversation component  may support an interaction  of a service component  with a party  of individuals  by identifying various tasks that may be related to each intent. For example, a first interaction party  may intend to board a flight, and based on this intent, an interface  to the service component  may identify a first set of tasks for the first interaction party , including checking in and checking luggage. A second interaction party  may intend to book a flight for a later trip, and the interface  may identify a set of tasks including searching for qualifying flights for the second interaction party  and booking a reservation. The interface  may therefore initiate an interaction  with one of the interaction parties , and may, upon completing the tasks identified for each intent of the interaction party  or the individuals therein, detect a conclusion of the interaction  and begin a new interaction. Those of ordinary skill in the art may devise many configurations of a conversation component while implementing the techniques discussed herein.","Although the subject matter has been described in language specific to structural features and\/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims.","As used in this application, the terms \u201ccomponent,\u201d \u201cmodule,\u201d \u201csystem\u201d, \u201cinterface\u201d, and the like are generally intended to refer to a computer-related entity, either hardware, a combination of hardware and software, software, or software in execution. For example, a component may be, but is not limited to being, a process running on a processor, a processor, an object, an executable, a thread of execution, a program, and\/or a computer. By way of illustration, both an application running on a controller and the controller can be a component. One or more components may reside within a process and\/or thread of execution and a component may be localized on one computer and\/or distributed between two or more computers.","Furthermore, the claimed subject matter may be implemented as a method, apparatus, or article of manufacture using standard programming and\/or engineering techniques to produce software, firmware, hardware, or any combination thereof to control a computer to implement the disclosed subject matter. The term \u201carticle of manufacture\u201d as used herein is intended to encompass a computer program accessible from any computer-readable device, carrier, or media. Of course, those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.",{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIG. 16","FIG. 16"]},"Although not required, embodiments are described in the general context of \u201ccomputer readable instructions\u201d being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media (discussed below). Computer readable instructions may be implemented as program modules, such as functions, objects, Application Programming Interfaces (APIs), data structures, and the like, that perform particular tasks or implement particular abstract data types. Typically, the functionality of the computer readable instructions may be combined or distributed as desired in various environments.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":["FIG. 16","FIG. 16"],"b":["300","302","302","306","308","308","304"]},"In other embodiments, device  may include additional features and\/or functionality. For example, device  may also include additional storage (e.g., removable and\/or non-removable) including, but not limited to, magnetic storage, optical storage, and the like. Such additional storage is illustrated in  by storage . In one embodiment, computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage  may also store other computer readable instructions to implement an operating system, an application program, and the like. Computer readable instructions may be loaded in memory  for execution by processing unit , for example.","The term \u201ccomputer readable media\u201d as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory  and storage  are examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, Digital Versatile Disks (DVDs) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .","Device  may also include communication connection(s)  that allows device  to communicate with other devices. Communication connection(s)  may include, but is not limited to, a modem, a Network Interface Card (NIC), an integrated network interface, a radio frequency transmitter\/receiver, an infrared port, a USB connection, or other interfaces for connecting computing device  to other computing devices. Communication connection(s)  may include a wired connection or a wireless connection. Communication connection(s)  may transmit and\/or receive communication media.","The term \u201ccomputer readable media\u201d may include communication media. Communication media typically embodies computer readable instructions or other data in a \u201cmodulated data signal\u201d such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.","Device  may include input device(s)  such as keyboard, mouse, pen, voice input device, touch input device, infrared cameras, video input devices, and\/or any other input device. Output device(s)  such as one or more displays, speakers, printers, and\/or any other output device may also be included in device . Input device(s)  and output device(s)  may be connected to device  via a wired connection, wireless connection, or any combination thereof. In one embodiment, an input device or an output device from another computing device may be used as input device(s)  or output device(s)  for computing device .","Components of computing device  may be connected by various interconnects, such as a bus. Such interconnects may include a Peripheral Component Interconnect (PCI), such as PCI Express, a Universal Serial Bus (USB), firewire (IEEE 1394), an optical bus structure, and the like. In another embodiment, components of computing device  may be interconnected by a network. For example, memory  may be comprised of multiple physical memory units located in different physical locations interconnected by a network.","Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example, a computing device  accessible via network  may store computer readable instructions to implement one or more embodiments provided herein. Computing device  may access computing device  and download a part or all of the computer readable instructions for execution. Alternatively, computing device  may download pieces of the computer readable instructions, as needed, or some instructions may be executed at computing device  and some at computing device .","Various operations of embodiments are provided herein. In one embodiment, one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media, which if executed by a computing device, will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further, it will be understood that not all operations are necessarily present in each embodiment provided herein.","Moreover, the word \u201cexemplary\u201d is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as \u201cexemplary\u201d is not necessarily to be construed as advantageous over other aspects or designs. Rather, use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application, the term \u201cor\u201d is intended to mean an inclusive \u201cor\u201d rather than an exclusive \u201cor\u201d. That is, unless specified otherwise, or clear from context, \u201cX employs A or B\u201d is intended to mean any of the natural inclusive permutations. That is, if X employs A; X employs B; or X employs both A and B, then \u201cX employs A or B\u201d is satisfied under any of the foregoing instances. In addition, the articles \u201ca\u201d and \u201can\u201d as used in this application and the appended claims may generally be construed to mean \u201cone or more\u201d unless specified otherwise or clear from context to be directed to a singular form.","Also, although the disclosure has been shown and described with respect to one or more implementations, equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components (e.g., elements, resources, etc.), the terms used to describe such components are intended to correspond, unless otherwise indicated, to any component which performs the specified function of the described component (e.g., that is functionally equivalent), even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition, while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations, such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore, to the extent that the terms \u201cincludes\u201d, \u201chaving\u201d, \u201chas\u201d, \u201cwith\u201d, or variants thereof are used in either the detailed description or the claims, such terms are intended to be inclusive in a manner similar to the term \u201ccomprising.\u201d"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 4","FIG. 1"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 16"}]},"DETDESC":[{},{}]}
