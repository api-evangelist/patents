---
title: System and method for assessing the security posture of a network
abstract: A method and data processing system assesses the security vulnerability of a network by creating a system object model database representing a network. The system object model database supports the information data requirements of disparate network vulnerability analysis programs. The system object model database is exported to the disparate network vulnerability analysis programs. The network is analyzed with each network vulnerability analysis program to produce data results from each program. Data results are correlated to determine the security posture of the network.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07096502&OS=07096502&RS=07096502
owner: Harris Corporation
number: 07096502
owner_city: Melbourne
owner_country: US
publication_date: 20000208
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"p":["This invention was made with Government support under Contract No. F30602-96-C-0289 awarded by the United States Air Force. The Government has certain rights in this invention.","This invention relates to the field of networks, and more particularly, this invention relates to the field of assessing the security posture of networks.","Information systems and computer network infrastructures currently under development are now being built with consideration for what constitutes an acceptable risk (or adequate protection). System assets, such as the hardware, software and system nodes of a computer network, must be protected to a degree consistent with their value. Additionally, these assets must be protected only until the assets lose their value. Any security features and system architecture should also provide sufficient protection over the life of the processed data. To assess whether or not any risk associated with a network is acceptable, a security engineer typically gathers all pertinent information, and then analyzes the risk associated with the network.","Risk analysis is a complex and time consuming process, which is necessary to determine the exposures within a network and their potential harm. As an example, when analyzing the security risks in a computer network, the security engineering typically follows the following steps:","1) Identify assets of the overall computing system.","2) Identify vulnerabilities of assets. This step typically requires imagination in order to predict what damage might occur to the assets and from what sources. The three basic goals of computer security are ensuring secrecy, integrity and availability. A vulnerability is any situation that could cause loss of one of those three qualities.","3) Predict likelihood of occurrence (exploitation), i.e., determining how often each exposure will be exploited. Likelihood of occurrence relates to the stringency of the existing controls and the likelihood that someone or something will evade the existing controls.","4) Compute any uncovered cost per year (expected annual loss) by determining the expected cost of each incident.","5) Survey applicable controls and their costs.","6) Project annual savings of control.","This last step of the analysis is a cost-benefit analysis, i.e., does it cost less to implement a control or to accept the expected cost of the loss? Risk analysis leads to a security plan, which identifies responsibility for certain actions to improve security.","Today, the rapid evolution of technology and proliferation of computers with increased power mandate the use of commercial-off-the-shelf (COTS) hardware and software components for cost effective solutions. This strong dependence on COTS implies that commercial grade security mechanisms are sufficient for most applications. Security architectures, therefore, must be structured to build operational, mission-critical computer systems with relatively weak COTS components. Higher assurance components can be placed at community or information boundaries, forming an enclave-based security architecture that implements a defense-in-depth approach to information assurance.","There are some design tools, i.e., software programs, available to the system architect to assist in maximizing the available protection mechanisms while remaining within the development budget. Current generation risk analysis tools usually are single vendor solutions that address a particular aspect or aspects of risk. These tools tend to fall into one of three categories:","1) Tools that work from documented vulnerability databases and possibly repair known vulnerabilities. Tools of this type are vendor-dependent for database updates, either through new product versions or by a subscription service. Examples from this category include ISS' Internet Scanner, Network Associates, Inc.'s CyberCop and Harris' STAT.","2) Monolithic tools that use various parameters to calculate a risk indicator. These tools are difficult to maintain and hard to keep current with the rapidly evolving threat and technology environment. An example of this tool category is Los Alamos Vulnerability Assessment (LAVA) tool.","3) Tools that examine a particular aspect of the system, such as the operating system or database management system, but ignore the other system components. SATAN, for example, analyzes operating system vulnerabilities, but ignores infrastructure components such as routers.","The use of multiple tools from a variety of vendors for a single computer network analysis is a labor-intensive task. Typically, a security engineer will have to enter a description or representation of the system (network) multiple times in multiple formats. The security engineer then must manually analyze, consolidate and merge the resulting outputs from these multiple tools into a single report of a network's security posture. Afterwards, the security engineer can complete the risk analysis (calculating expected annual loss, surveying controls, etc.), and then repeat the process to analyze alternatives among security risks, system performance, mission functionality and the development budget.","Also, none of these tools use an aggregate \u201csnapshot\u201d approach to the system with a \u201cdrill down\u201d or layered approach to facilitate how one addresses risk at various layers (network, platform, database, etc.) of the system. These tools provide little assistance to system designers when analyzing alternatives among security risk, system performance and mission functionality. Instead, a \u201crisk solution\u201d is provided that addresses the particular aspect of risk that a given tool was designed to calculate. To develop a comprehensive risk assessment, a security engineer would have to become proficient in the use of several tools and manually correlate the resulting outputs.","One aspect of successful risk analysis is a complete and accurate accumulation of data to generate system models used by the analysis tools. Many current risk analysis tools depend on surveys filled out by users, system operations personnel, and analysts to acquire the data for development of a system model used in the analysis. Alternatively, a tool can actively scan a computer network to test various vulnerabilities against system components.","However, these methods have drawbacks. Textual or survey-based knowledge solicitation techniques are labor intensive and potentially tedious for the analyst. Many of the existing tools reuse the same information to analyze different aspects of the system security. It would be more advantageous to use a centralized repository of modeling data, which could provide a basis for shared inputs among existing tools. This repository could be used to generate data sets for use by risk analysis tools, allowing multiple tools to be run against the same system without separate input activities, thus reducing the possibility of operator error. The use of multiple risk analysis reasoning engines, or backbends, would allow various aspects of the system to be analyzed without the cost of developing one tool to perform all types of analysis. Integration of the information and the resulting informed assessments available by applying multiple tools would produce a more robust and accurate picture of a system's security posture. These results can facilitate more informed system design decisions, providing a framework for alternative evaluation and comparison.","It is therefore an object of the present invention to provide a data processing system and method for assessing the security posture of a network without having to analyze the network a multiple number of times.","In accordance with the present invention, a method and data processing system assesses the security posture of a network. The method comprises the steps of creating a system object model database representing a network. The system object model database supports the information data requirements of disparate network vulnerability assessment\/risk analysis programs. This system object model database is imported to the disparate network vulnerability analysis programs. The network is analyzed with each network vulnerability\/risk analysis program to produce data results from each program. These data results are correlated to determine the security posture of the network.","In still another aspect of the present invention, the method comprises the step of exporting the system object model database to the network vulnerability analysis programs via an integrated application programming interface. The method also comprises the step of modeling the network as a map on a graphical user interface. A class hierarchy is established to define components of the network vulnerability analysis programs and share common data and programming traits. The data results of the network vulnerability analysis programs use fuzzy logic processing for correlating the data results in still another aspect of the present invention.","The method can also comprise the step of running the network vulnerability analysis programs to obtain data results pertaining to network system details, network topologies, node level vulnerabilities and network level vulnerabilities.","In still another aspect of the present invention, a computer program resides on a medium that can be read by a program. This computer program comprises instructions to cause a computer to create a system object model database representing a network, wherein the system object model database supports the information data requirements of network vulnerability\/risk analysis programs that analyze discrete network portions. The computer program also has instructions to import the system object model database of the network to the network vulnerability analysis programs and analyze the network with each network vulnerability analysis program to produce data results from each program. The computer program also causes a computer to correlate the data results of the network vulnerability analysis programs to determine the security posture of the network.","In still another aspect of the present invention, the computer program comprises instructions for displaying an integrated application programming interface and importing the system object model database to the network vulnerability analysis programs via the integrated application programming interface.","The computer program also includes instructions for modeling the network as a map on a graphical user interface and establishing a class hierarchy to define components of the network vulnerability analysis programs that share common data and programming traits. The computer program can also comprise instructions for correlating the data results of the network vulnerability analysis programs used in fuzzy logic processing and obtain data results that pertain to network system details, network topologies, node level vulnerabilities and network level vulnerabilities.","In still another aspect of the present invention, a data processing system assesses the security posture of a network and comprises a plurality of disparate network vulnerability analysis programs used for analyzing a network. A system object model database represents the network to be analyzed and supports the information data requirements of the network vulnerability assessment\/risk analysis programs. An applications programming interface imports the system object model database of the network to the network vulnerability analysis programs. A processor correlates the data results obtained from each network vulnerability analysis program after analyzing the network to determine the security posture of the network.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 1","b":["100","102","104","105","106","108","106","107","110","112","114"]},"Using the example of , frequent problems found on networks include hosts, such as the internal servers , which run unnecessary services, for example, a denial of service and anonymous FTP or misconfigured web servers that could be an internal server, for example, CGI scripts, anonymous FTP and SMTP. The internal LAN's  could include unpatched, outdated, vulnerable or default configured software and firmware and weak passwords. LAN's could also include improperly exported file sharing services, such as NetWare file services and NetBIOS. The internal LAN  could also include misconfigured or unpatched windows NT servers and problems caused by a lack of comprehensive policies, procedures, standards and guidelines. A remote-access server  could have unsecured remote-access points and the external router  could have information leakage through services, such as SNMP, SMIP, finger, roosers, SYSTAT, NETSTAT, TELNET banners, Windows NT TCP 139 SMB (server message block), and zone transfers to non-named server hosts. It could also have inadequate logging, monitoring and detecting capabilities. The branch office  could have a misappropriated trust relationship such as RLOGIN, RSH, or REXEC. The firewall  could be misconfigured or have a misconfigured router access control list.","Although these network problems are only an example of common problems found on networks , there are many other problems that could occur, as is well known to those skilled in the art.","The present invention is advantageous because the system and method of the present invention allows the vulnerabilities of a network system to be identified. The software of the data processing system and method can be located on a user terminal , as shown in , showing an identified vulnerability of a node  connected in the internal LAN . For purposes of description, the data processing system and method of the present invention can be referred to as a Network Vulnerability Tool (NVT), i.e., a tool a user uses to determine network vulnerabilities and risks.","The data processing system forming the NVT of the present invention can be loaded on a Pentium PC platform running Windows NT. This type of platform can provide a low cost solution and support a large variety of assessment tools, also commonly referred to as network vulnerability assessment or risk analysis programs throughout this description. These network vulnerability analysis programs typically are the standard COTS\/GOTS programs known by security engineers, and include HP Open View, which allows network automatic discovery or manual network modeling; ANSSR (Analysis of Network System Security Risks) as manufactured by Mitre Corporation, a GOTS network system analysis tool, which allows passive data gathering and single occurrence of loss. NSA's risk assessment methodology known as RAM (risk assessment model) can also be used and is implemented in the DPL-f decision support programming language. RAM also allows passive data gathering for event tree logic, prioritizes the task list, and allows a mathematical model with multiple risks\/services. It is event based over time.","DPL (decision programming language) is a decision support software package that facilitates the modeling of complex decisions. It allows a user to incorporate uncertainty and flexibility into a decision process. DPL provides a graphical interface for building a model, and performs analyses on the model. DPL-f contains the functionality built into DPL and provides a graphic interface for fault tree construction. This feature allows the modeler to create fault trees and incorporate them into DPL models. DPL-f also contains unique analytic tools. These tools include the ability to calculate explicitly the probability of any event in the tree and perform fault tree-specific types of sensitivity analysis. DPL-f provides an interface for incorporating time series into a model. This allows a modeler to account for devaluation, capital growth or other time-bearing quantities without changing the structure of the model. DPL-f provides RAM with additional capabilities for rapid fault tree construction, libraries of embedded fault trees, an expert opinion generation system, enumeration and ordering of cut sets and a graphical portrayal of risk over time.","The ISS Internet scanner as developed by Internet Security Systems Corporation (ISS) allows active data gathering and scans a network for hosts, servers, firewalls and routers and assesses security and policy compliance with networks, operating systems and software applications. It allows a snapshot in time and a computer network compliance report. These programs are disparate network vulnerability analysis programs that the NVT of the present invention allows for integration.","The NVT of the present invention is based on a knowledge solicitation framework, which incorporates a graphical description of a network topology. This topology is used to capture network attributes and analyzed subsequently for security vulnerabilities. Graphical user interface is also used to improve accuracy of the network model.","In accordance with the present invention, the system and method of the NVT automatically maps an existing network and can display the existing network as a model on a graphical user interface, such as shown in . For example, HP Open View could graphically depict a network topology. Once the software has been given the IP address of a default router for the network, the NVT of the present invention can use Open View and search for computers and other devices attached to the network. NVT performs an active search, pinging possible IP addresses on the network, and adding whatever response information it receives to its network map. NVT also provides a manual method to draw a proposed network with the graphical user interface, as illustrated, to support drag and drop. A system architecture can be defined, including security critical information for alternative designs or node editing to provide additional details as required to provide complete logical network planning. A user can also represent an entire network on a map by using a sub-network icon.","When a network system description has been completed, the NVT of the present invention represents and stores the description in an object\/class hierarchy, as shown as an example in , as will be explained below. A single topological system object model supports the information data needs of the disparate network vulnerability analysis programs (tools). Fuzzy logic processing of the results allows correlation of the results from the programs into a cohesive vulnerability\/risk assessment to obtain a vulnerability posture of the network, as shown in the graphical user interface at . The single representation of the system simplifies the use of multiple tools and eliminates redundant data entry. It also provides a foundation for addressing the problem of incomplete data for a given vulnerability assessment tool and future knowledge negotiation capabilities.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 3","b":["130","132","134","136","138","138"]},"This model  uses object oriented (OO) methodology to provide an extensible set of components in a class hierarchy that can be combined to represent a network. The class hierarchy provides a means of defining components with shared common traits, while retaining the specifics that distinguished it from other components. In addition to an implicit hierarchical relationship, object oriented techniques provide a containment mechanism in which an object can contain a reference to any object, including itself. This provides a flexible mechanism for representing any physical or logical entity. Also, object oriented representation lends itself to ready modification and extension and is ideal for an information assurance arena where changes and new technologies arise daily.","As shown in , filters  are associated with each of the network vulnerability analysis programs , ,  and allow only that data required by a respective network vulnerability programs to be exported to the tool (program). The filters are a C++ base class that provide a set of virtual methods to allow data movement between the NVT system and a program. The filter also provides a means for the NVT to control execution of the tool and complete data needed by a tool. NVT views each tool as a filter, calling the appropriate method within the filter to perform the desired task, including initializing, running, importing data and exporting data. Each tool can have a concrete filter subclass and provide the means to define each method specifically for the tool, while still providing the generic and well-defined programming interface (API) to NVT. This allows all tools to be treated the same within NVT, allowing the addition and removal of tools without changing any of the existing NVT codes.","Establishing communication between DPL-f and NVT using the filter technology is straightforward. A DPL-f filter is tasked with the specifics of building and populating fault trees. As an analysis tool, a default tree can represent a node in a network as developed and provide a probability value for events such as denial of service, loss of data and data compromise. Actually, DPL-f can be used as a final result tool.","The network is then analyzed with each network vulnerability analysis program to produce data results from each program. The data results are correlated to determine a security posture of the network. Network validation can occur through the fuzzy logic processing of the invention, as will be explained below, and the system GUI can have input to a user display.","An overview of the network is created as a model  by an automatic network discovery or manual entry , such as through HP Open View, and an appropriate filter  allows the system GUI  to display the network model as shown in  via an appropriate data input  to a user display . It is also possible to have a risk GUI  to assess visually the risk vulnerability, a log  of the risk\/vulnerability report, a risk assessment  as part of the GUI , all through the network validation , using a plug-in or fuzzy rule set as will be described in greater detail below. Any incomplete data resolution  can also be handled.",{"@attributes":{"id":"p-0064","num":"0063"},"figref":["FIG. 4","FIG. 3","FIG. 4"],"b":["138","162","164","166","168","170","138","172","174","176","178","180","182","184","186"]},{"@attributes":{"id":"p-0065","num":"0064"},"figref":["FIGS. 5 and 6","FIG. 5","FIG. 6","FIG. 5"],"b":["200","202","204","206","208","210","208","208","208","208"],"i":["a ","b ","c "]},{"@attributes":{"id":"p-0066","num":"0065"},"figref":["FIGS. 7\u201310","FIG. 7"],"b":["220","220","222","224","224","226","222","230","232","234"]},"A select data sensitivity pop up window (box)  is user selectable through the menu options for selected network elements (), and has user selected items for selecting the sensitivity of network elements. The sensitivity for data on any node (node  in the example shown in ) can be selected for unclassified, sensitive, confidential, secret, restricted secret or top secret with appropriate Okay, Random and Default buttons.","A select node configuration edit pop up window (box)  is shown in  and can have user selectable vulnerability profiles for selecting a vulnerability profile of a network element or node.  also shows the network model diagram with the central hub and the interconnected nodes. It is possible that a user can edit the manager window  entries, which also allows the network discovery to occur through appropriate selection of buttons. Naturally, network icons can be selected and moved as necessary for editing and design alternatives.","After the security posture has been established through the system, icons representative of high risk network elements can turn colors, such as red, the hub . Other selected icons could turn yellow, indicative of a less severe risk node, such as the HP4 node  shown in . It is possible that shaded areas around the node or portions of the network could be colored red or yellow indicative of higher risk vulnerability. It is also possible that the connection line could turn red or yellow to indicate a poor connection between elements.",{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 10","b":["270","272","274","276"]},{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 16","FIG. 17","FIG. 17"],"b":["280","282","284","286","288","290"]},"Referring now in greater detail to , the goal oriented fuzzy logic decision making is illustrated. As shown in , the system model database  and results  from the respective network vulnerability analysis programs are combined together using an applications programming interface and expert correlation to form a data fact base  through data fuzzification. Goal oriented fuzzy logic decision rules operate through fuzzy inference network rules  and fuzzy evidential reasoning rules  to determine the security posture of a network based on predetermined goals .","The fuzzy logic processing of the present invention uses data fusion, evidential reasoning and inference network techniques. As known to those skilled in the art, evidential reasoning is a technique in which facts are gathered that support and refute a given hypothesis. The result is the proof or rejection of the hypothesis with a certain degree of confidence. The fuzzy logic processing of the present invention uses evidential reasoning to accumulate evident from the system and tool findings for each criteria, thereby merging the system assessment data into a single point of reference, the conformance of the system to a particular criteria. By suppling a set of criteria for fusion, the system constrains the fusion problem and reduces the search base. Evidential reasoning has previously been used to perform level-one multi-sensor data fusion, and is a common global reasoning technique in fuzzy expert systems, such as the type of system known to those skilled in the art as fuzzyCLIPS, developed by NASA. The result is a set of fuzzy evidential rules whose purpose is to accumulate evidence for a given set of requirements. This resolves potentially conflicting, ambiguous and redundant data from expert correlation and draws conclusions with available data, even if it is incomplete.","The accuracy of the result is contingent upon the quantity and quality of the data available and it may be necessary to perform additional refinement on the available data prior to the application of fuzzy logic processing, while also maintaining the probabilistic nature of the data. This refinement uses inference networks and provides a method of reasoning about probability using heuristics, thereby removing the need for extensive a priori knowledge. The relation between the goals and potential security metrics encourages cross fertilization. As known to those skilled in the art, the fuzzyCLIPS uses fuzzy facts, which can assume any value between 0 and 1. The result can be viewed as a two dimensional plot of a continuous function bounded vertically by 0 and 1.","Data fusion is used with the system object database, data results data fact base. Intelligence data fusion is a multi-level, multi-disciplinary-based information process to yield the integration of information from multiple intelligence sources (and perhaps multiple intelligence disciplines) to produce specific and comprehensive, unified data about an entity (its situation, capabilities, and the threat it imposes). Data fusion provides information based on the available inputs. The intelligence data fusion process is typically partitioned into four levels, described in Table 1 below.",{"@attributes":{"id":"p-0076","num":"0075"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"THE LEVELS AND PURPOSES OF THE INTELLIGENCE"},{"entry":"DATA FUSION PROCESS"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"77pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Data Fusion Level","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Object Refinement","Transforms data into consistent frame of"]},{"entry":[{},{},"reference"]},{"entry":[{},{},"Refines and extends, in time, estimates of"]},{"entry":[{},{},"object position, kinematics or attributes"]},{"entry":[{},{},"Assigns data to objects to allow application"]},{"entry":[{},{},"of estimation process"]},{"entry":[{},{},"Refines the estimation of object identity"]},{"entry":["2","Situation","Develops description of current relationships"]},{"entry":[{},"Refinement","among objects and events in the context of the"]},{"entry":[{},{},"environment"]},{"entry":[{},{},"A symbolic, reasoning process by which"]},{"entry":[{},{},"distributions of fixed and tracked entities and"]},{"entry":[{},{},"events and activities are associated with"]},{"entry":[{},{},"environmental and performance data in the"]},{"entry":[{},{},"context of an operational problem"]},{"entry":["3","Threat Refinement","Projects the current \u201csituation\u201d into the future"]},{"entry":[{},{},"and draws inferences about threats,"]},{"entry":[{},{},"vulnerabilities and opportunities for"]},{"entry":[{},{},"operations"]},{"entry":["4","Process Refinement","Monitors process performance to provide"]},{"entry":[{},{},"information for real-time control and long-"]},{"entry":[{},{},"term improvement"]},{"entry":[{},{},"Identifies what information is needed to"]},{"entry":[{},{},"improve the multi-level fusion product"]},{"entry":[{},{},"Determines the source specific data"]},{"entry":[{},{},"requirements to collect required information"]},{"entry":[{},{},"Allocates and directs the sources to achieve"]},{"entry":[{},{},"mission goals"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"As noted before, NVT combines multiple types of data, from multiple sources, with other contextual information to form an integrated view of a networked system's security posture. NVT provides a user with a simple expression of the vulnerability posture of a given system or system design, and enables them to perform \u201cwhat if\u201d analysis for functionality, performance, and countermeasure trades, for the purpose of refining and improving the system or system design.","In computer security engineering, sensors are the various vulnerability assessment and risk analysis tools, along with the GUI to gather information, as needed, from the user. The resulting outputs from these tools take the form of both qualitative and quantitative data, in a variety of formats from different vendors. For computer security engineering, the objects of interest are the nodes in a network (computing system), i.e. the assets, including hardware, software and data. The situation of interest is an assessment of the weaknesses in the security system of a computer network segment that might be exploited to cause harm or loss of secrecy, integrity or availability.","Assessing the risk faced by a computing system involves an assessment of the threats faced, their likelihood of occurrence (exploitation), and the expected cost of the loss (or harm). Finally, the network (computing system) can be refined based on the results of cost-benefits analysis. This requires information on protective measures (controls or countermeasures) appropriate for particular vulnerabilities and their costs. The cost-benefit analysis seeks to determine if it costs less to use a control or countermeasure, or accept the expected cost of the loss. This leads to the development of a security plan to improve security of a computer network system.","Table 2 contains an example of a first partitioning of this data fusion process for computer security engineering that could be used with the present invention, with four processing levels, corresponding to the four levels found in Table 1. As illustrated in , inputs to this process would consist of the object model database , results from individual tools , , , and other contextual information. The different data fusion levels 1\u20134 are indicated generally at , ,  and .",{"@attributes":{"id":"p-0081","num":"0080"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 2"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"INITIAL PROCESSING LEVELS OF DATA FUSION FOR"},{"entry":"COMPUTER SECURITY RISK ANALYSIS"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Data Fusion Levels","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Node Data","Transforms data into consistent frame of"]},{"entry":[{},"Refinement","reference"]},{"entry":[{},{},"Refinement of data at the network node-level"]},{"entry":[{},{},"(the objects for computer security data fusion)"]},{"entry":[{},{},"Data from multiple tools - correlated (assigned"]},{"entry":[{},{},"to appropriate nodes) and possibly combined at"]},{"entry":[{},{},"each node"]},{"entry":[{},{},"Refines the estimation of object identity -"]},{"entry":[{},{},"network node (workstation) is a system-of-"]},{"entry":[{},{},"systems, consisting of an OS, critical applications,"]},{"entry":[{},{},"a database and data"]},{"entry":[{},{},"Vulnerability analysis at this level does not yet"]},{"entry":[{},{},"constitute situation assessment"]},{"entry":["2","Network Segment","Refinement of the situation at the network"]},{"entry":[{},"Refinement","segment-level (system-of-systems level)"]},{"entry":[{},{},"Develops description of current relationships"]},{"entry":[{},{},"among objects (nodes) in the context of the"]},{"entry":[{},{},"environment (a network segment)"]},{"entry":[{},{},"A symbolic, reasoning process by which"]},{"entry":[{},{},"information about entities (nodes, network"]},{"entry":[{},{},"segments) and environment are associated with"]},{"entry":[{},{},"evidence about computer security goals,"]},{"entry":[{},{},"requirements"]},{"entry":[{},{},"Combining tool results at the network segment-"]},{"entry":[{},{},"level"]},{"entry":[{},{},"The situation of interest is the assessment of"]},{"entry":[{},{},"the network segment's vulnerabilities or"]},{"entry":[{},{},"exposures"]},{"entry":["3","Risk Refinement","Refinement of the exposures and their potential"]},{"entry":[{},{},"for harm (risk) within a computing system"]},{"entry":[{},{},"Projects the current \u201csituation\u201d (state of the"]},{"entry":[{},{},"computer network system) into the future and"]},{"entry":[{},{},"draws inferences about threats, vulnerabilities and"]},{"entry":[{},{},"opportunities for operations"]},{"entry":[{},{},"Based on vulnerabilities, concerns, context,"]},{"entry":[{},{},"cost, threats"]},{"entry":[{},{},"Refinement of a system design with the"]},{"entry":[{},{},"identification of controls that reduce one or more"]},{"entry":[{},{},"vulnerabilities"]},{"entry":[{},{},"Based on countermeasures, components, cost"]},{"entry":[{},{},"Identifies what information is needed to"]},{"entry":[{},{},"improve the multi-level fusion product"]},{"entry":[{},{},"Facilitate long-term improvement of the system"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"While the data fusion used in the present invention provides a conceptual framework for addressing the problem of merging results from multiple vulnerability assessment and risk analysis tools, expert systems, inference networks and evidential reasoning are used to implement the fusion concepts and merge tool results. The flexibility of fuzzy decision technology, in particular, fuzzy expert systems, offers the means to address these problems. A primary benefit of a fuzzy expert system is its ability to use and assimilate knowledge from multiple sources.","Fuzzy logic provides the technique for representing and inferring from knowledge that is imprecise, uncertain or unreliable. Similar to traditional expert systems, a fuzzy expert system can represent knowledge in the form of a system of IF\/THEN rules in which the antecedents, consequent, or both are fuzzy rather than crisp. Fuzzy logic is used to determine how well fuzzy facts match the rules, and to what degree this match affects the rule's conclusion.","In accordance with the present invention, an inference network is a hierarchy of heuristic rules that can propagate probabilities without requiring extensive knowledge of a priori probabilities (e.g. Bayesian networks). The heuristic rules can be developed using expert knowledge on how the probabilities propagate, allowing conclusions to be drawn with limited knowledge of a priori probabilities. This results in low-level discrete probabilities being accurately reflected in higher-level conclusions. Probabilities of low-level events (such as probability of password compromise based on lifetime) need to be part of any conclusions drawn on higher-level events (vulnerability of password).","Initial studies of NVT uses accumulation of evidence to modify a fuzzy-fact and represent the change in state required by the current system. This state change fuzzy-fact is then used to modify the system and the new state is fed back into the change of state rules in an endless cycle, using global contribution. FuzzyCLIPS allows the definition of fuzzy-fact types, but only one fact of each type will ever exist. Therefore every rule that manipulates that fact type actually modifies a single fact, leading to accumulation of evidence.","Global contribution and accumulation of evidence have lead to a FuzzyCLIPS methodology that defines fuzzy-facts representing different vulnerability states. These facts will use global contribution and accumulation of evidence to acquire final values reflecting the tested system's vulnerability, i.e., evidential reasoning. This method reflects the well-defined use of fuzzy logic control systems, limiting the execution to a finite number of cycles instead of allowing it to run continuously. FuzzyFusion\u2122 has been developed by Harris Corporation of Melbourne, Fla., and will use this methodology to accumulate evidence from rules based on knowledge from network security experts. In particular, FuzzyFusion\u2122 will employ evidential reasoning as a technique in which facts are gathered supporting and refuting a given hypothesis. The result is the proof or rejection of the hypothesis with a certain degree of confidence.","Initial knowledge extraction has resulted in the use of security requirements to accumulate evidence, i.e. how well does a system meet the requirements. This demonstrates a strong correlation between the methods of verifying a database (e.g. AFCERTS) and verifying security requirements, leading to using the database and requirements as global contribution facts to accumulate evidence, illustrated in . This also shows how varying the granularity of the goals directly impacts the granularity of the assessment, i.e. the assessment will only be as detailed as the goals. The accumulation of evidence is being viewed as a goal orientated approach to obtaining the results while maintaining the use of a forward inference technique, and for now will be phrased as \u201cGoal-based Fusion\u201d.","One example of how fuzzy logic can be applied with merging tool results in computer security uses the combination of results from ANSSR and ISS Internet Scanner, two of the tools currently used within one aspect of NVT. The outputs of the tools are both quantitative (ANSSR) and qualitative (Internet Scanner). Fuzzy logic allows the system to represent both data types within the same system. Then an initial hypothesis is formulated, and fuzzy logic is used to gather evidence to contradict or support the hypothesis.","For this example, an initial hypothesis could be that auditing is invalid in an existing network system. The system user then exercises the ANSSR and ISS Internet Scanner tools. If ANSSR supplies a number 90 (out of 100), that auditing is sufficient. Fuzzy logic allows NVT to account for this as strong refuting evidence for the initial hypothesis that auditing is invalid. If Internet Scanner supplies the qualitative data that User Access is not audited, fuzzy logic accounts for this as supporting evidence, which is combined with the evidence from ANSSR. When the tools are finished, the contributing evidence for auditing is represented as a single fuzzy fact that provides a measure of how well auditing is implemented.","FuzzyFusion\u2122 as developed by Harris Corporation of Melbourne, Fla. is a means to consolidate and merge the results of vulnerability assessment and risk analysis tools, employed within the NVT into a unified report. In particular, FuzzyFusion\u2122 is developed to implement Levels 1 and 2 fusion. FuzzyFusion\u2122 is accomplished through the use of a fuzzy expert system (Goal-Oriented Fuzzy Logic Decision Rules) using FuzzyCLIPS, which combines the outputs of the various tools, user concerns about system risks and vulnerabilities, and expert understanding of the results of each tool and how these fit into a larger information system security picture. Thus, NVT users obtain a simple expression of the security posture of a given computing system, or system design, and can perform \u201cwhat if\u201d analysis for functionality, performance, and countermeasure trades.",{"@attributes":{"id":"p-0091","num":"0090"},"figref":"FIG. 14"},"Data Fuzzification  converts the results from the individual vulnerability assessment and risk analysis tools , ,  into fuzzy-facts, and stores those along with the Common System Model (CSM), i.e., system object model database , into the (FuzzyCLIPS) Fact-Base . Individual tool results (after fuzzification) and the CSM  are exported for Expert Correlation processing  (Data Framework Merge Rules) to resolve system information and integrate tool output based on security expertise. Expert opinion can be used to determine the specific fuzzy values attributed to the low-level events.","The Expert Correlation (Data Framework Merge Rules)  is a collection of fuzzy expert rules to perform node-level data refinement (Level-1) or network-segment refinement (Level-2). These rules correlate and consolidate the (fuzzified) outputs from the vulnerability assessment and risk analysis tools, using expertise from security engineers. These rules leverage extensive experience in security assessment to resolve low-level systems data and tool results. These rules resolve system information and integrate tool output. Expert Correlation Rule processing  can also transform low-level data from the CSM and tool results into high level conclusions. For example,","IF auditing is on with these flags,","AND the audit data is not backed up,","THEN auditing is unreliable.","Working from fuzzy-facts in the Fact-Base , a set of Level-1 fusion rules can consolidate the vulnerabilities for each node, resulting in a vulnerability rating for each node in the network. This rating can be imported back to NVT for display. Similarly, a set of Level-2 fusion rules can consolidate the vulnerabilities for each network segment, resulting in a vulnerability rating for each network segment. This can again be imported back for display.","The data is then subject to Fuzzy Inference Network Rules processing . It may be necessary to perform additional refinement on the available data prior to the application of Fuzzy Evidential Reasoning Rules , while maintaining the probabilistic nature of the data. This refinement will use inference networks, as known to those skilled in the art, which provides a method of reasoning about probability using hueristics, thereby removing the need for extensive a priori knowledge.","Fuzzy Evidential Reasoning Rules  are a collection of fuzzy expert rules to merge individual tool results into a higher level assessment, from a systems-level perspective, of a network's security posture. These rules provide a mechanism for merging the CSM, tool results and the results from the Expert Correlation (Data Framework Merge Rules)  into a unified report. This also removes the necessity of dealing with incomplete and conflicting data from the forward-chaining expert system used in Expert Correlation.","Evidential reasoning use a technique in which facts are gathered to support and refute a given hypothesis. The result is the proof or rejection of the hypothesis with a certain degree of confidence. FuzzyFusion\u2122 uses evidential reasoning to accumulate evidence from the Common System Model and tool findings for each criterion, thereby merging the computer network system assessment data into a single point of reference, the conformance of the system to particular criteria. By supplying a set of criteria for fusion, NVT constrains the fusion problem and reduces the search space, referred to earlier as goal-based fusion. The result will be a set of fuzzy evidential rules whose sole purpose is to accumulate evidence for a given set of requirements. This resolves the potentially conflicting, ambiguous and redundant data from Expert Correlation (Data Framework Merge Rules) , and draws conclusions with the available data, even if it is incomplete. Obviously, the accuracy of the result is contingent upon the quantity and quality of the data available.","As noted before, the fuzzy logic processing is goal oriented. Goals for Evidence Accumulation processing  may be derived from a Security Requirements Database , a Computer Security Metrics Database , or a Vulnerability Database , such as a database composed of AFCERTs. Bounding fusion to pre-defined goals limits computation times. FuzzyFusion\u2122 goals provide mechanism to obtain IA metrics.","The FuzzyFusion\u2122 process has a number of advantages over traditional approaches. Crisp expert systems would require extremely large knowledge bases to encompass the necessary data and, yet, would still have a problem with incomplete data and conflicting results. Bayesian and probability networks require extensive and often unavailable a priori knowledge of probabilities. Algorithmic solutions do not fit the probabilistic and heuristic nature of the security problem.","Rete-based expert systems such as FuzzyCLIPS suffer from a geometric increase in execution time based on the number of rules and facts present in the system. This leads to breaking the analysis into subnetworks. FuzzyFusion\u2122 will add subnetwork and scaling capabilities. The nodes for each subnetwork will be evaluated as a group, and then groups of subnetworks will be evaluated. Grouping the rules for each type of analysis into different modules will reduce the size of the Rete-network. In addition to decreasing execution time, this will also introduce a scalable method of analyzing networks that maps to the network model used by NVT.","As shown in , the other possible data spaces could include a threat knowledge database , cost database  as part of Level 3 fusion and a counter measure knowledge base, component database and cost database as part of Level 4 fusion.","This application is related to copending patent applications entitled, \u201cSYSTEM AND METHOD FOR ASSESSING THE SECURITY POSTURE OF A NETWORK AND HAVING A GRAPHICAL USER INTERFACE\u201d and \u201cSYSTEM AND METHOD FOR ASSESSING THE SECURITY POSTURE OF A NETWORK USING GOAL ORIENTED FUZZY LOGIC DECISION RULES\u201d which are filed on the same date and by the same assignee and inventors, the disclosures which are hereby incorporated by reference.","Many modifications and other embodiments of the invention will come to the mind of one skilled in the art having the benefit of the teachings presented in the foregoing descriptions and the associated drawings. Therefore, it is to be understood that the invention is not to be limited to the specific embodiments disclosed, and that the modifications and embodiments are intended to be included within the scope of the dependent claims."],"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Other objects, features and advantages of the present invention will become apparent from the detailed description of the invention which follows, when considered in light of the accompanying drawings in which:",{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIGS. 8A and 8B"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 17"}]},"DETDESC":[{},{}]}
