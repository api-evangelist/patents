---
title: Stereoscopic conversion with viewing orientation for shader based graphics content
abstract: The example techniques of this disclosure are directed to generating a stereoscopic view from an application designed to generate a mono view. For example, the techniques may modify instructions for a vertex shader based on a viewing angle. When the modified vertex shader is executed, the modified vertex shader may generate coordinates for vertices for a stereoscopic view based on the viewing angle.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09538164&OS=09538164&RS=09538164
owner: QUALCOMM Incorporated
number: 09538164
owner_city: San Diego
owner_country: US
publication_date: 20130110
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This disclosure relates to graphics data processing, and more particularly, to graphics data processing for stereoscopic view.","Stereoscopic view refers to a perceived image that appears to encompass a 3-dimensional (3D) volume. To generate the stereoscopic view, a device displays two images on a 2-dimensional (2D) area of a display. These two images include substantially similar content, but with slight displacement along the horizontal axis of one or more corresponding pixels in the two images. The simultaneous viewing of these two images, on a 2D area, causes a viewer to perceive an image that is popped out of or pushed into the 2D display that is displaying the two images. In this way, although the two images are displayed on the 2D area of the display, the viewer perceives an image that appears to encompass the 3D volume.","The two images of the stereoscopic view are referred to as a left-eye image and a right-eye image, respectively. The left-eye image is viewable by the left eye of the viewer, and the right-eye image is not viewable by the left eye of the viewer. Similarly, the right-eye image is viewable by the right eye of the viewer, and the left-eye image is not viewable by the right eye of the viewer. For example, the viewer may wear specialized glasses, where the left lens of the glasses blocks the right-eye image and passes the left-eye image, and the right lens of the glasses blocks the left-eye image and passes the right-eye image.","Because the left-eye and right-eye images include substantially similar content with slight displacement along the horizontal axis, but are not simultaneously viewable by both eyes of the viewer (e.g., because of the specialized glasses), the brain of the viewer resolves the slight displacement between corresponding pixels by commingling the two images. The commingling causes the viewer to perceive the two images as an image with 3D volume.","In general, the techniques of this disclosure are directed to modifying instructions that generate a mono view to cause a graphics processing unit (GPU) to generate a stereoscopic view. A shader program of the GPU may be designed to generate a mono view. The techniques described in this disclosure modify the instructions of such a shader program based at least on a viewing angle to generate stereoscopic view. For example, the techniques modify instructions of the shader program to displace a location of a pixel by one direction for one of the views of the stereoscopic view, and to displace the location of the pixel in another direction for the other view of the stereoscopic view. The direction in which the modified shader program displaces the location of the pixel is based on the viewing angle.","In one example, the disclosure describes a method for graphics processing. The method includes determining, with a processor, a viewing angle relative to a display, receiving, with the processor, instructions for a vertex shader that is configured to operate on an image of a mono view, and modifying, with the processor, the instructions for the vertex shader to include one or more instructions based on the viewing angle to generate a modified vertex shader. In this example, the modified vertex shader, when executed, generates vertex coordinates for vertices of a stereoscopic view. The method also includes instructing, with the processor, a graphics processing unit (GPU) to execute the modified vertex shader.","In one example, the disclosure describes an apparatus. The apparatus includes a graphics processing unit (GPU) and a processor. The processor is configured to determine a viewing angle relative to a display, and modify the instructions for the vertex shader to include one or more instructions based on the viewing angle to generate a modified vertex shader. In this example, the modified vertex shader, when executed, generates vertex coordinates for vertices of a stereoscopic view. The processor is also configured to instruct the GPU to execute the modified vertex shader.","In one example, the disclosure describes a processor. The processor is configured to determine a viewing angle relative to a display, receive instructions for a vertex shader that is configured to operate on an image of a mono view, and modify the instructions for the vertex shader to include one or more instructions based on the viewing angle to generate a modified vertex shader. In this example, the modified vertex shader, when executed, generates vertex coordinates for vertices of a stereoscopic view. The processor is also configured to instruct a graphics processing unit (GPU) to execute the modified vertex shader.","In one example, the disclosure describes an apparatus that includes a graphics processing unit (GPU), means for determining a viewing angle relative to a display, means for receiving instructions for a vertex shader that is configured to operate on an image of a mono view, and means for modifying the instructions for the vertex shader to include one or more instructions based on the viewing angle to generate a modified vertex shader. In this example, the modified vertex shader, when executed, generates vertex coordinates for vertices of a stereoscopic view. The apparatus also includes means for instructing the GPU to execute the modified vertex shader.","In one example, the disclosure describes a computer-readable storage medium having instructions stored thereon that, when executed, cause one or more processors to determine a viewing angle relative to a display, receive instructions for a vertex shader that is configured to operate on an image of a mono view, and modify the instructions for the vertex shader to include one or more instructions based on the viewing angle to generate a modified vertex shader. In this example, the modified vertex shader, when executed, generates vertex coordinates for vertices of a stereoscopic view. The instructions further cause the one or more processors to instruct a graphics processing unit (GPU) to execute the modified vertex shader.","The details of one or more aspects of the disclosure are set forth in the accompanying drawings and the description below. Other features, objects, and advantages of the disclosure will be apparent from the description and drawings, and from the claims.","The example techniques described in this disclosure are directed to rendering stereoscopic 3-dimensional (S3D) graphics during execution or run time. For example, an application may generate mono view images that are to be rendered by a graphics processing unit (GPU) for display. The techniques described in this disclosure may convert the mono view images to stereoscopic view images during the execution (i.e., during run-time) of the application.","In some examples, the techniques may render S3D graphics without needing any modification to the application that created the graphics or the GPU. In some examples, the techniques described in this disclosure may be implemented by an application processor executing a wrapper to a graphics driver. The wrapper to the graphics driver may be considered as a program that modifies inputs to a previously created graphics driver or modifies the outputs of the previously created graphics driver in accordance with the techniques described in this disclosure. In this way, the techniques described in this disclosure may provide for the GPU to generate S3D graphics without needing to modify the graphics driver that executes on the application processor. However, it may be possible to create a new graphics driver, or modify the previously created graphics driver, so that the application processor, in response to the execution of the graphics driver, implements the example techniques described in this disclosure. For purposes of illustration, the techniques are described as being performed by the application processor executing the graphics driver wrapper.","From the perspective of the application, the application processor executing the application may output graphics data and commands of the application for conventional 3D graphics rendering by GPU. The graphics driver wrapper, executing on the application processor, may modify the commands, as well as instructions that are executed by the GPU, such that the GPU renders S3D graphics on an S3D display. In this disclosure the terms \u201ccommands\u201d and \u201cinstructions\u201d may be used interchangeably. In this way, the GPU can render S3D graphics without any changes to the application that generates the graphics or to the GPU. Accordingly, the techniques described in this disclosure may allow for a viewer to experience S3D graphics for image content generated by applications that were not designed to generate S3D graphics.","Furthermore, the techniques described in this disclosure may account for the viewing angle (i.e., the angle at which the viewer is viewing the display) to determine the manner in which the application processor, via the graphics driver wrapper, modifies the instructions that are executed by the GPU. By accounting for the viewing angle, the viewer may experience high quality S3D graphics even if the display is tilted or the head of the viewer is titled.","In conventional 3D graphics rendering, the GPU generates 3D graphics from a single point of view (e.g., mono view). This single point of view may mean a single image that is viewable by both the right eye and left eye of a viewer. S3D graphics differs from 3D graphics in that S3D graphics generate stereoscopic view. The term stereoscopic view refers to images that are generated from a binocular point of view. In a binocular point of view, there may be two images, where one image is viewable by one of the eyes and not the other, and vice-versa. For example, when a viewer wears specialized glasses, the light that enters through the left lens of the glasses is viewable by the left eye, and not the right eye, and vice-versa. The binocular point of view may be referred to as stereoscopic view.","For example, in S3D graphics, the GPU may generate an image for the left-eye and another image for the right-eye (i.e., a stereoscopic view). The left-eye image is blocked from the right eye of the viewer and directed only to the left eye. The right-eye image is blocked from the left eye of the viewer and directed only to the right eye. The term stereoscopic view refers to two images (e.g., left-eye image and right-eye image) that are each displayed on the display, whereas mono view refers to a single image that is displayed on the display. The combination of the left-eye image and the right-eye image may appear to a viewer as if the image is popping out of or pushing into the display that is displaying the images. This may result in a more realistic and richer viewing experience.","In this disclosure, the concept of an S3D image (e.g., stereoscopic view) and a 3D image (e.g., mono view) should not be confused. A 3D image is an image that is constrained to a 2-dimensional (2D) area of a display. For example, in 3D graphics processing, an application defines 3D primitives, where the primitives form various objects of the application content. These objects form the single image (e.g., mono view) that is constrained to the 2D area of the display.","For instance, objects within a 3D image may appear further away or closer than other objects within the 3D image. However, all of these objects are limited to the 2D area of the display. An S3D image is a perceived image resulting from a brain of a viewer combining the right-eye and left-eye images. The resulting image (i.e., the S3D image) appears to not be constrained to the 2D area of the display. Rather, the S3D image appears to encompass a 3D volume, where the image appears to pop out of or push into the display. For instance, objects within the S3D image appear further away or closer than other objects within a 3D volume, and not a 2D area, as is the case with 3D images.","In other words, 3D graphics processing refers to generating a 3D image (e.g., by 3D primitives defined by an application) that appears to be constrained to the 2D area of the display. This 3D image is referred to as a mono view. S3D refers to rendering for the creation of stereoscopic view, rather than mono view. In stereoscopic view, the right-eye and left-eye images are constrained to the 2D display; however, when the viewer views the stereoscopic view, the image appears to encompass a 3D volume.","The right-eye and left-eye images, that together form the S3D image, may be 3D images. It is the brain of the viewer that causes the viewer to perceive the S3D image when the brain combines the 3D right-eye image and the 3D left-eye image. For instance, when the viewer watches both the right-eye and left-eye images simultaneously, the viewer can perceive depth of the scene based on human binocular vision. The content of the right-eye image and left-eye images may be substantially similar to the content of the single 3D image.","For high quality stereoscopic effect, there may only be horizontal disparity between the left-eye image and the right-eye image. For instance, the location of an object in the left-eye image and the location of the object in the right-eye image may be different. However, the difference may only be in the horizontal direction, and not the vertical direction. It is the horizontal disparity between the objects that causes the binocular vision of the viewer to combine the left-eye image and right-eye image such that the objects appear to pop out of or pushed into the display. Any vertical disparity between the objects may diminish the S3D effect.","The techniques described in this disclosure an application processor, executing a graphics driver or a graphics driver wrapper, may modify instructions that cause the GPU to generate graphics content for a mono view to instructions that cause the GPU to generate graphics content for the stereoscopic view. In other words, prior to modification, the instructions may cause the GPU to generate a single 3D image. Subsequent to modification, the instructions may cause the GPU to generate two 3D images (e.g., the 3D left-eye image and the 3D right-eye image) of the stereoscopic view.","It should be noted that although the techniques described in this disclosure are generally disclosed for 3D images, aspects of this disclosure are not so limited. The techniques of this disclosure may be extended to 2D graphics as well. For example, the single image of the mono view may be a 2D image, and the techniques of this disclosure may modify instructions to cause the GPU to generate two 2D images for the stereoscopic view. In this case, the viewer will perceive a single image that is popped out of or pushed into the display that is displaying the two images for the stereoscopic view. To avoid confusion, the techniques described below refer to a single image for the mono view, and left-eye and right-eye images for the stereoscopic view, with the understanding that these images could be 3D images or 2D images.","The example techniques described in this disclosure the application processor, via the graphics driver or the graphics driver wrapper, may modify instructions issued by an application that are to be performed by the GPU and instructions of a vertex shader program that is to be executed by the GPU. For example, an application processor may execute the application. The application may have been designed to generate a single image (e.g., a mono view), and may generate the graphics content of the single image as a plurality of primitives. In addition, the application may determine pixel values, such as color, transparency, and coordinate values, for each vertex of the primitives.","During execution of the application (e.g., in run-time), the application, via the application processor, issues a command to retrieve instructions of the vertex shader program. The output of the vertex shader program, when executed, may be clipping coordinates for the vertices of primitives generated by the application for the single image (e.g., mono view). The example techniques may modify the instructions of the vertex shader program to generate clipping coordinates for the vertices of primitives for the left-eye image and the right-eye image (e.g., stereoscopic view). The clipping coordinates for the vertices of primitives for the left-eye image and the right-eye image may be based on the viewing angle.","The viewing angle refers to the angle with which a viewer is viewing a display upon which the left-eye and right-eye images are being displayed during the execution of the application (i.e., the viewer's viewing orientation relative to the display). There may be many different ways in which to determine the viewing angle. The techniques described in this disclosure are not limited to any particular manner in which to determine the viewing angle.","Also, during execution of the application, the application, via the application processor, issues a draw instruction to the GPU to instruct the GPU to draw one or more of the primitives within the single image. For instance, in the techniques of this disclosure, the application executing on the application processor outputs instructions as if the GPU is going to generate graphics content for a single image. The techniques described herein modify one or more of the instructions issued by the application, such as the draw instruction, to generate graphics content for the left-eye and right-eye images. In this way, there is no modification to the instructions from the perspective of the application.","For instance, the application processor, via the graphics driver wrapper, monitors the instructions issued by the application. When the application issues a draw instruction, the graphics driver wrapper captures such a draw instruction and issues two draw instructions, where one instruction is to generate graphic content for the left-eye image based on the viewing angle and one instruction is to generate graphics content for the right-eye image based on the viewing angle.","The viewing angle may not remain constant. For example, during execution of the application, the viewer may tilt the device, may tilt his or her head, or both. To account for the possibility of the changes in the viewing angle, the application processor may periodically determine the viewing angle. As one example, after the GPU outputs one combination of the left-eye image and the right-eye image, the techniques may determine the viewing angle. In this example, the graphics driver wrapper may modify the instructions of the vertex shader to account for the change in viewing angle for the next combination of left-eye image and right-eye image rendered by the GPU. Alternatively, the processor may continuously determine the viewing angle, and the graphics driver wrapper may utilize the current viewing angle to determine the manner in which to modify the instructions of the vertex shader.","As described above, the graphics driver wrapper may modify the instructions of the vertex shader to create vertices for primitives for both the left-eye image and right-eye image. For example, the techniques may cause the modified vertex shader to execute twice. In a first instance of execution, the modified vertex shader may displace the clipping coordinates of a vertex in a first direction based on the viewing angle, and in a second instance of execution, the modified vertex shader may displace the clipping coordinates of a vertex in a second direction based on the viewing angle. The GPU may process the vertices displaced in the first direction to render the left-eye image, and may process the vertices displaced in the second direction to render the right-eye image.","However, displacing all of the clipping coordinates in the first direction, and then displacing all of the clipping coordinates in the second direction may result a stereoscopic view in which all objects of the single image generated by the application appear popped out of or pushed into the display that is displaying the left-eye image and the right-eye image. For example, the primitives generated by the application may form different objects. By displacing the clipping coordinates of all of the primitives in the first direction to generate the left-eye image, and displacing the clipping coordinates of all of the primitives in the second direction to generate the right-eye image, all of the objects may appear popped out of or pushed into the display.","Such a result may not be ideal for human binocular vision. For example, the viewer may desire for the some of the objects to pop out more than other objects. As another example, even if all of the objects pop out or push into the display by the same amount, the viewer may desire to control the amount by which the objects pop out or push into the display.","As described in more detail, the application processor, via the graphics driver wrapper, may also modify the instructions of the vertex shader such that some of the objects pop out of or push into the display more than other objects. In some examples, in addition to or instead of modifying the instructions of the vertex shader to allow some objects to pop out or push into the display more than other objects, the application processor, via the graphics driver wrapper, may modify instructions that increase or decrease the horizontal disparity between the left-eye image and the right-eye image. In this manner, the viewer may be able to control the amount by which the stereoscopic view pops out of or pushes into the display.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIG. 1","FIG. 1"],"b":["10","10","10","12","12","12"]},"As illustrated, display  displays 3D image A and 3D image B.  illustrates image A as a solid box, and image B as a dashed box. Image A and image B may each be a 3D image. For example, if each one of image A and B is viewed individually, image A and B would not appear to pop out or push into display  (e.g., appear as if mono view).","However, when image A and image B are viewed together, image A and image B together form a stereoscopic view. For example, image A and image B may include similar image content, but are displaced on display . Specialized glasses worn by a viewer may block the right eye of the viewer from seeing image A, and allow the left eye of the viewer to see image B. The specialized glasses may also block the left eye of the viewer from seeing image B, and allow the right eye of the viewer to see image A. When the viewer views images A and B together the horizontal disparity between images A and B may result in the viewer perceiving an S3D image (i.e., one that appears to be behind display  or ahead of display  and encompasses a 3D volume). In other words, image A is the left-eye image of the stereoscopic view, and image B is the right-eye image of the stereoscopic view.","An application executing on a processor of device  may generate a single image (e.g., mono view). For example, the processor, executing the application, may generate the image content of the single image as a plurality of primitives. The image content of this single image may be similar to the image content of image A and image B. In addition, the processor, executing the application, may determine pixel values, such as color, transparency, and coordinate values, for each vertex of the primitives. The pixel values of the primitives may be referred to as image data. The processor, executing the application, may output the image data and instructions to a graphics processing unit (GPU) of device  instructing the GPU to render the single image.","In accordance with the techniques described in this disclosure, the processor may capture the commands to the GPU that command the GPU to render the single image. For example, the processor may execute a graphics driver or a graphics driver wrapper, and the processor may capture the commands to the GPU, via the graphics driver or the graphics driver wrapper, to render the single image. For purposes of illustration, the techniques are described as being performed by the processor executing the graphics driver wrapper. In general, the techniques describe the graphics driver wrapper performing various functions for ease of description. However, it should be understood that the processor is implementing the techniques via the execution of the graphics driver wrapper.","For example, the graphics driver wrapper may be a program executing on the processor. The graphics driver wrapper may modify the instructions that the graphics driver receives or the instructions that the graphics driver outputs to such that the modified instructions cause the GPU to render stereoscopic view. Accordingly, the techniques described in this disclosure may not require any modification to the graphics driver. Rather, the processor may execute the graphics driver wrapper and execute a previously developed graphics driver. However, it may be possible to modify existing graphics drivers or create new graphics drivers to implement the techniques described in this disclosure.","The processor executing the graphics driver wrapper may modify the commands issued by the processor and cause the GPU to render two images that form the stereoscopic view (e.g., image A and image B). In addition, the processor executing the graphics driver wrapper may modify instructions of a shader program (e.g., a vertex shader) that executes on the GPU. For example, the graphics driver wrapper may modify the instructions of the vertex shader such that the modified vertex shader, when executed on the GPU, displaces a position of a pixel in the single image generated by the application executing on the processor. The graphics driver wrapper may cause the GPU to execute the modified vertex shader twice. In the first execution of the modified vertex shader, the modified vertex shader displaces the positions of the pixels in the single image in one direction. In the second execution of the modified vertex shader, the modified vertex shader displaces the positions of the pixels in the single image in another direction in the second execution. Image A may be the resulting image from the vertex shader displacing pixels of the single image in one direction. Image B may be the resulting image from the vertex shader displacing pixels of the single image in another direction.","In modifying the instructions of the vertex shader, the processor executing the graphics driver wrapper may account for the viewing angle. The viewing angle is the angle at which the viewer is viewing display . For example, in , display  may be considered to be in the landscape mode. If the viewer is viewing straight ahead at display  (i.e., the viewer has not tilted his or her head), the viewing angle may be considered to be zero. If, however, the viewer tilts device  or tilts his or her head, the viewing angle may no longer be zero. For instance, if the viewer rotates device  to be in portrait mode (e.g., tilts device  by 90\u00b0), the viewing angle may be 90\u00b0.","It should be understood that the viewing angle being zero in landscape mode, and 90\u00b0 in portrait mode is provided for purposes of illustration and should not be considered limiting. The techniques described in this disclosure also apply to situations where the viewing angle is zero in the portrait mode and 90\u00b0 in the landscape mode, or any mode in between landscape and portrait mode.","In general, a processor of device  may determine the viewing angle, and the processor, via the graphics driver wrapper executing on the processor, may modify the instructions outputted by the application to the GPU and instructions of a shader program executing on the GPU based on the viewing angle. The graphics driver wrapper may modify the instructions such that the GPU renders two images that form the stereoscopic view, rather than the single image that forms the mono view.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 2","FIG. 2"],"b":["10","10"]},"Most stereoscopic 3D displays have to be used with a constraint on device orientation. For example, most all 3D televisions are viewed in landscape mode. This is reasonable for many devices that are setup for use on a horizontal surface (TV cabinet, desktop, etc.). However, for handheld devices, such as phones and tablets, a viewer may view the display in either landscape or portrait modes, or even with any angular orientation.","For example, in position A, device  is in the landscape mode. For ease of description,  illustrates orientation point , which is located at the top-right corner of device , when device  is in the landscape mode. The viewer may tilt device  by 45\u00b0 (i.e., from position A to position B). In this case,  illustrates that orientation point , in position B, moved in the right, bottom direction relative to orientation point in position A. In this example, the viewing angle may be considered as 45\u00b0.","As another example, the viewer may tilt device  by \u221245\u00b0 (i.e., from position A to position C). In this case,  illustrates that orientation point , in position C, moved in the left, top direction relative to orientation point in position A. In this example, the viewing angle may be considered as \u221245\u00b0. Because the viewer may tilt device  by any amount, the viewing angle may range from \u2212180\u00b0 to 180\u00b0.","For example, landscape and portrait are two typical display modes (e.g., the viewer rotates device  from the landscape more to portrait mode, or vice-versa). In these cases, device  may determine whether device  is in landscape mode or portrait mode, and the processor, via the graphics driver wrapper, may modify instructions to cause the GPU to render the left-eye image and the right-eye image for the landscape mode or portrait mode. However, the viewer may orient device  in any angle, and not just in landscape mode or portrait mode. Accordingly, the processor may account for the viewing angle to determine the manner in which to modify the instructions that are executed on the GPU.","There may be various ways in which to determine the viewing angle. For example, device  may include an accelerometer that device  uses to determine whether to switch from landscape mode to portrait mode. Device  may also include either single- or multi-axis models of the accelerometer to detect magnitude and direction of the proper acceleration. Such an accelerometer may output orientation based on direction of weight changes. The processor of device  may determine the viewing angle based on the output orientation.","As another example, device  may include a gyroscope. The gyroscope may provide a measure of orientation based on the principles of conservation of angular momentum. The processor of device  may determine the viewing angle based on the measure of orientation provided by the gyroscope. Gyroscopes based on other operating principles also exist, such as the electronic, microchip-packaged MEMS gyroscope devices used in consumer electronic devices. The gyroscope may provide a more accurate recognition of movement within a 3D space than the accelerometer.","The outputs of the accelerometer or gyroscope may allow the processor to determine a reasonable estimation of the viewing angle. However, the estimation of the viewing angle may be based on an assumption that the viewer is oriented in a particular manner such as vertically (e.g., the viewer did not tilt his or her head). In other words, the accelerometer or gyroscope may provide an accurate measure of the display orientation, which may be sufficient to determine a reasonable estimation of the viewing angle, but may not provide an accurate measure of the viewer orientation.","In some examples, it may be possible for the processor of device  to determine the orientation of the viewer (e.g., whether the viewer is oriented vertically, or whether the viewer tiled his or her head). For example, either display  or device  may include a built-in front-facing camera. With the front-facing camera, a camera processor may detect the eyes of the viewer or the head orientation of the viewer relative to display . The processor of device  may determine the viewing angle based on the detected eyes or head orientation, as detected by the camera processor.","Besides normal optical camera, other sensors may also be configured to detect eyes or head orientation of the viewer. In general, the techniques described in this disclosure may utilize any technique to determine the viewing angle, including techniques that do not necessarily rely upon detecting the eyes or head of the user. The techniques described in this disclosure should not be considered limited to the examples described above for determining the viewing angle.","For example, the techniques described in this disclosure may only determine the viewing angle based on the outputs of the accelerometer and\/or gyroscope. As another example, the techniques described in this disclosure may determine the viewing angle based only the detected eyes or head of the user. As another example, the techniques described in this disclosure may determine the viewing angle based on the outputs of the accelerometer and\/or gyroscope, and based on the detected eyes or head of the user. As another example, the techniques may determine the viewing angle based on the outputs of the accelerometer and\/or gyroscope and based on one or more other sensors that are configured to determine the viewing orientation of the user. Any permutation and combination of the above, as well as any other techniques, may be used to determine the viewing angle.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIG. 3","FIG. 3","FIG. 3"],"b":["12","10","10","12","12"]},"As illustrated in , device  is in landscape mode; however, the head of the viewer is tilted. In this case, the camera processor of device  may detect the orientation of eyes A and B, and transmit the orientation of eyes A and B to the processor of device . Based on the orientation of eyes A and B, the processor of device  may determine the viewing angle. In accordance with the techniques described in this disclosure, the graphics driver wrapper may modify instructions that execute on the GPU based on the determined viewing angle.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 4","FIG. 4","FIG. 4","FIG. 4"],"b":["20","20","12","10","10"]},{"@attributes":{"id":"p-0072","num":"0071"},"figref":["FIG. 5","FIG. 5","FIG. 5","FIG. 5"],"b":["10","10","22","30","36","42","44","10"]},"Moreover, in some examples, application processor , GPU , and camera processor  may be formed as a common integrated circuit that is housed within a single circuit package (e.g., formed as a common processor). However, aspects of this disclosure are not so limited, and one or more of application processor , GPU , and camera processor  may be separate integrated circuits that are housed in separate circuit packages.","One or more sensors  may be configured to output a measure of the orientation of device  to application processor . Examples of one or more sensors  include an accelerometer and a gyroscope. Camera processor  may receive image data from images captured by a camera (not shown) of device  or a camera (not shown) of display . In the techniques described in this disclosure, the camera may be configured to continuously capture images without user-intervention and in the background. For instance, the captured images do not need to be displayed or stored for later retrieval. From the captured images, camera processor  may determine the orientation of the viewer.","Camera processor  may determine the orientation of the eyes of the viewer to determine the orientation of the viewer. Camera processor  may implement any technique to identify the eyes of the viewer from which camera processor  determines the orientation of the eyes of the viewer. Many, current camera processors are configured to identify the eyes of the viewer, and these current camera processors may be one example of camera processor .","One or more sensors  may output the measure of the orientation of device  to application processor . Camera processor  may output the measure of the viewer orientation to application processor . Application processor  may determine the viewing angle based at least on the measure of the orientation of device  and the measure of the orientation of the viewer. For example, application processor  may determine the viewing angle to be the angle between the orientation of device  and the orientation of the viewer. As described in more detail, application processor  may utilize the viewing angle to determine the manner in which to modify instructions of vertex shader .","Camera processor  may not be necessary in every example. For instance, the measure of the orientation of device  may be sufficient for application processor  to determine the viewing angle. In these examples, application processor  may be preconfigured with a measure of the viewer orientation. Application processor  may determine the viewing angle based on the measure of the orientation of device  and the preconfigured measure of the viewer orientation. As another example, application processor  may determine the viewing angle based on the measure of the orientation of the viewer without using the outputs of one or more sensors . In this example, application processor  may be preconfigured with the orientation of device  (e.g., may be preconfigured to determine that the orientation of device  is landscape when not using the outputs of one or more sensors ).","Utilizing one or more sensors  and camera processor  to determine the viewing angle is provided for purposes of illustration only, and should not be considered limiting. There may other ways in which application processor  may determine the viewing angle, and the techniques described in this disclosure are extendable to such other techniques.","In some examples, application processor  may determine the viewing angle once per generation of the stereoscopic view because the viewer may change the viewing angle. For example, GPU  may output rendered images such as the left-eye image and the right-eye image of the stereoscopic view. After every output of both the left-eye image and the right-eye image, application processor  may determine the viewing angle. As another example, application processor  may continuously determine the viewing angle. As described in more detail, application processor , via graphics driver wrapper , may modify the instructions of vertex shader  based on the current, determined viewing angle such that when vertex shader  processes the next image, vertex shader  may generate clipping coordinates for the next left-eye image and the next right-eye image as determined by application processor .","Application processor  may be the central processing unit (CPU) of device . GPU  may be a processing unit operable to output graphics data for presentation on a display. Examples of application processor , GPU , and camera processor  include, but are not limited to, a digital signal processor (DSP), a general purpose microprocessor, application specific integrated circuit (ASIC), field programmable logic array (FPGA), or other equivalent integrated or discrete logic circuitry.","In some examples GPU  may be specialized hardware that is specifically designed for graphics processing. For example, graphics processing may require fast parallel processing, and GPU  may be specifically designed for such fast parallel processing. It may be possible for GPU  to perform tasks in addition to graphics processing, such as general processing task. Accordingly, GPU  may be considered as a general processing GPU (GPGPU). The techniques described in this disclosure may apply to examples where GPU  performs only graphics related tasks or examples where GPU  is a GPGPU.","System memory  may be an example of a computer-readable storage medium. For example, system memory  may store instructions that cause application processor  and GPU  to perform functions ascribed to each in this disclosure. System memory  may be considered as a computer-readable storage medium comprising instructions that cause one or more processors (e.g., application processor  or GPU ) to perform various functions.","Examples of system memory  include, but are not limited to, a random access memory (RAM), a read only memory (ROM), an electrically erasable programmable read-only memory (EEPROM), CD-ROM or other optical disk storage, magnetic disk storage, or other magnetic storage devices, flash memory, or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer or a processor. System memory  may, in some examples, be considered as a non-transitory storage medium. The term \u201cnon-transitory\u201d may indicate that the storage medium is not embodied in a carrier wave or a propagated signal. However, the term \u201cnon-transitory\u201d should not be interpreted to mean that system memory  is non-movable. As one example, system memory  may be removed from device , and moved to another device. As another example, a storage device, substantially similar to system memory , may be inserted into device . In certain examples, a non-transitory storage medium may store data that can, over time, change (e.g., in RAM).","GPU  may include shader processor  and fixed-function pipeline . Shader processor , sometimes referred to as a shader core, may be a core of GPU  upon which shader programs such as vertex shaders and fragment shaders execute. Fixed-function pipeline  may include hardware units that perform fixed functions. In other words, the shader programs such as vertex shaders and fragment shaders may be software units that execute on shader processor  and allow for functional flexibility, whereas fixed-function pipeline  includes hardware units with fixed functions and minimal functional flexibility.","For example, some earlier versions of GPU included only fixed-function units in a graphics pipeline. In GPU , the fixed-function graphics pipeline of earlier version of the GPU is partially replaced by vertex shaders, such as vertex shader , and fragment shaders. For example, vertex shader  may perform functions such as model view transformation, lighting, and projection, which were performed by fixed-function units in earlier versions of GPUs. The fragment shaders may perform the functions of the fragment stage of the fixed-function units in earlier versions of GPUs.","The example techniques described in this disclosure may modify shader programs that are designed to generate a single three-dimensional (3D) image (e.g., for a mono view), such that when the modified shader programs are executed on shader processor , GPU  generates graphics data for S3D images (e.g., a stereoscopic view) based on a viewing angle. Again, as discussed above, stereoscopic view includes a left-eye image and a right-eye image. The left-eye image and the right-eye image include substantially similar graphics content as the mono view image; however, one or more corresponding pixels of the left-eye and right-eye images may be displaced along the horizontal axis relative to one another.","For example, imagine that the right-eye image is placed on top of the left-eye image. In this case, all of the content in the right-eye image may not line up perfectly with the identical content in the left-eye image. Rather, one or more objects in the right-eye may be to the left or to the right of the identical objects in the left-eye image (e.g., there may be horizontal disparity between the objects in the right-eye image and left-eye image). For high quality stereoscopic effect, there may not be vertical disparity between the objects in the right-eye image and left-eye image.","The left-eye image is viewable by the left eye of the viewer, and the right-eye image is blocked from the left eye of the viewer. The right-eye image is viewable by the right eye of the viewer, and the left-eye image is blocked from the right eye of the viewer. In some examples, the viewer may wear specialized glasses that block the left-eye image from being viewable by the right eye, and the right-eye image from being viewable by the left eye. However, aspects of this disclosure do not necessarily require a viewer to wear specialized glasses. For example, some displays do not require the viewer to wear specialized glasses to experience stereoscopic view. Techniques of this disclosure may be extended to such displays.","GPU  may generate the graphics data for the left-eye image and the right-eye image such that when the viewer views both the left-eye image and the right-eye image at the same time the brain of the viewer causes the viewer to perceive an image that pops out of the display or pushes into the display displaying the two images (e.g., appears to be ahead of or behind the display). This popping out or pushing in is due to the brain of the viewer resolving the horizontal discrepancies in the two images of the stereoscopic view with substantially similar content. For example, the binocular vision of the viewer causes the viewer to view both the left-eye image and the right-eye image at the same time, and the viewer resolves the horizontal discrepancies in the left-eye and right-eye images by perceiving depth.","As an example, application processor  may execute one or more applications, such as application , stored in system memory . Examples of application  include, but are not limited to, web browsers, user interfaces, e-mail applications, spreadsheet applications, word processing applications, graphics authoring applications, video games, or other applications that generate viewable objects for display. For instance, application  may be a video game that when executed outputs graphical content that is displayed on a display.","Application  may be designed by a developer for mono view. For example, application , upon execution, may generate 3D graphics content, where the 3D graphics content is constrained to the 2D area of the display. Application , upon execution on application processor , may divide the generated 3D graphics content into primitives such as triangles, rectangles, or other types of polygons. Each of these primitives may include pixels that are to be displayed on the display. For example, these primitives may form the objects within the image. Application , upon execution on application processor , may also assign pixel values to each of the vertices of the primitives. For example, the pixel values may include 3D coordinates of the vertices, color values of the vertices, and transparency values of the vertices. The pixel values need not include all of the above example components in every aspect of this disclosure.","Application processor  may then forward the pixel values for the vertices to GPU  for further processing. For example, application processor  may include graphics driver , which may be software executing on application processor . Application processor, via graphics driver , may be configured to transmit commands to GPU , and in response, GPU  may perform functions in accordance with the received commands. For example, graphics driver  functions as an interface between GPU  and application processor . When application processor  issues a command to GPU , it is through graphics driver  that GPU  receives the command. For instance, application , executing on application processor , may instruct GPU  to perform a particular task. In this case, graphics driver  may receive the instruction from application  for the particular task, and application processor  may provide the instruction to GPU . In response, GPU  may perform the task.","In some examples, graphics driver  may be designed in accordance with a specific application programming interface (API). For example, graphics driver  may be designed according to the OpenGL or OpenGL ES (embedded system) APIs, which are APIs of the Khronos Group and their specifications are available publicly. However, the techniques of this disclosure may be extendable to the Microsoft DirectX system, such as DirectX 9, 10, or 11, or any other shader-based graphics system and APIs. For purposes of illustration, the techniques of this disclosure are described in the context where the API is the OpenGL ES 2.0 API. However, aspects of this disclosure are not so limited, and can be extended to other APIs or shader-based graphics systems.","To render the primitives received from application processor , shader processor  of GPU  may execute one or more shader programs such as vertex shaders and fragment shaders to generate the pixel values for the pixels of a display. A developer may develop these vertex shaders and fragment shaders in accordance with an API, such as the OpenGL ES 2.0 API used in this disclosure for illustration purposes. The source code for these vertex and fragment shaders may be stored in system memory .","For example, application  may utilize vertex shader , which may be configured to operate on the image of the mono view generated by application . The pixel values of the image of the mono view generated by application  may need to be processed by shader processor  using vertex shader . As one example, vertex shader  may be a vertex shader particularly called by application  during the execution of application  on application processor . Vertex shader  may execute on shader processor  of GPU , and application  may execute on application processor , but vertex shader  and application  may be interrelated for the purposes of displaying the images generated by application .","The source code of vertex shader  may be stored in system memory . Application processor , via graphics driver , may retrieve the source code of vertex shader  and provide the source code for vertex shader  to compiler . Compiler  may compile the source code of vertex shader  to generate object code of vertex shader , and store the object code in system memory . Application processor , via graphics driver , may then instruct GPU  to retrieve the object code of vertex shader  from system memory , and instruct GPU  to execute the object code of vertex shader  on shader processor . Shader processor  may then execute the object code of vertex shader  to process the pixel values for the vertices generated by the execution of application . GPU , in conjunction with fixed-function pipeline  and shader processor , may generate the graphics content for application  for display.","Although system memory  is shown to store source code for only one vertex shader , aspects of this disclosure are not so limited. For example, application  may possibly utilize multiple different vertex shaders, and the source code for each of these vertex shaders may be stored in system memory . For example, the vertex shaders may be content dependent and even scene dependent, and application  may utilize a particular shader based on the content or scene of the image that is to be rendered. Also, application  may require execution of multiple instantiations of vertex shader . For example, shader processor  may execute multiple instantiations of vertex shader  at the same time (e.g., in parallel), where each instantiation of vertex shader  performs substantially similar functions, but on different pixel values. System memory  may similarly store source code for fragment shaders. Graphics driver  may retrieve the source code for the fragment shaders, and compiler  may compile the source code to generate object code for the fragment shaders in a manner similar to that described above for vertex shader .","As will be described in further detail, one or more example techniques of this disclosure may modify vertex shader  (e.g., the source code of vertex shader ) based on the viewing angle prior to the compilation. Compiler  may compile the modified source code to generate object code of modified vertex shader . Shader processor  may execute the object code of modified vertex shader , which may cause GPU  to generate stereoscopic 3D graphics content (e.g., the graphics content for the left-eye image and the right-eye image of S3D). However, prior to describing the modification to vertex shader , the following describes example functionality of vertex shader , which may assist in the understanding of the modification applied to the source code of vertex shader . Furthermore, in this disclosure the terms \u201ccommand\u201d and \u201cinstruction\u201d may be used interchangeably.","As described above, application processor , via application , may generate coordinates for the vertices of the primitives. These coordinates may be referred to as world coordinates, and may be specific to application . In other words, the coordinates of the vertices, as defined by application , may not necessarily be coordinates of the display upon which the primitives are displayed and may also possibly be coordinates for vertices that are outside of a viewable area. Vertex shader  may be designed to convert the world coordinates, which may be in 3D, into 2D coordinates of the display (e.g., display coordinates). To perform this function, vertex shader  may transform the world coordinates into eye coordinates, and then to clipping coordinates. For example, the output of vertex shader , when executed, may be the clipping coordinates of the vertices. The final display coordinates (e.g., the coordinates of the display) may be determined subsequently as part of the fixed-function pipeline .","The clipping coordinates may define a view frustum. The view frustum may define the viewable area of the 3D graphics content. GPU  may utilize the view frustum to cull pixels which reside external to the view frustum. For example, a fixed-function unit of fixed-function pipeline  (e.g., a frustum unit of fixed-function pipeline ) may cull pixels which reside external to the view frustum, as defined by the clipping coordinates generated by vertex shader .","The equation to calculate the clipping coordinates from the world coordinates may be:\n\nclip=eye=world,\u2003\u2003(equation 1)\n\nwhere Vclip is the vertex clip coordinates, Veye is the vertex eye coordinates, Vworld is the vertex world coordinates provided by application , PRJ is a projection matrix, and MVT is a model view transformation matrix (or world view transformation matrix). In some examples, the PRJ and MVT matrices may be combined into a single matrix. However, for ease of understanding, these matrices are described separately.\n","The projection matrix (PRJ) and model view, or world view, transformation matrix (MVT) may be defined by the API. The terms model view and world view may be used interchangeably. Vclip, Veye, and Vworld may include four components (e.g., x, y, z, and w coordinates).","The Vclip, Veye, and Vworld matrices may be represented as:",{"@attributes":{"id":"p-0104","num":"0103"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["V","clip"]},"mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["x","clip"]}}},{"mtd":{"msub":{"mi":["y","clip"]}}},{"mtd":{"msub":{"mi":["z","clip"]}}},{"mtd":{"msub":{"mi":["w","clip"]}}}]}}},"mo":","}},{"mrow":{"mrow":{"msub":{"mi":["V","eye"]},"mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["x","eye"]}}},{"mtd":{"msub":{"mi":["y","eye"]}}},{"mtd":{"msub":{"mi":["z","eye"]}}},{"mtd":{"msub":{"mi":["w","eye"]}}}]}}},"mo":","}},{"mrow":{"msub":{"mi":["V","world"]},"mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["x","world"]}}},{"mtd":{"msub":{"mi":["y","world"]}}},{"mtd":{"msub":{"mi":["z","world"]}}},{"mtd":{"msub":{"mi":["w","world"]}}}]}}}}]}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"2"}}}]}}}}},"The OpenGL, OpenGL ES, and OpenGL ES 2.0 APIs, with programmable shaders, define the PRJ matrix as:",{"@attributes":{"id":"p-0106","num":"0105"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"PRJ","mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mfrac":{"mrow":[{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["z","near"]}},{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}}]}},{"mn":"0"},{"mfrac":{"mrow":[{"mi":["R","L"],"mo":"+"},{"mi":["R","L"],"mo":"-"}]}},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mfrac":{"mrow":[{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["z","near"]}},{"mi":["T","B"],"mo":"-"}]}},{"mfrac":{"mrow":[{"mi":["T","B"],"mo":"+"},{"mi":["T","B"],"mo":"-"}]}},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mrow":{"mo":"-","mfrac":{"mrow":[{"msub":[{"mi":["z","near"]},{"mi":["z","far"]}],"mo":"+"},{"msub":[{"mi":["z","far"]},{"mi":["z","near"]}],"mo":"-"}]}}},{"mrow":{"mo":"-","mfrac":{"mrow":[{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":[{"mi":["z","near"]},{"mi":["z","far"]}]},{"msub":[{"mi":["z","far"]},{"mi":["z","near"]}],"mo":"-"}]}}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mrow":{"mo":"-","mn":"1"}},{"mn":"0"}]}]}}},"mo":","}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"3"}}}]}}}},"br":{},"sub":["near ","far "]},"In some examples, the clipping planes may be symmetrical. For example, \u2212L may be equal to R, and \u2212B may be equal to T. In these instances, the PRJ matrix may simplify to:",{"@attributes":{"id":"p-0108","num":"0107"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"PRJ","mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mfrac":{"mrow":[{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["z","near"]}},{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}}]}},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mfrac":{"mrow":[{"mn":"2","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["z","near"]}},{"mi":["T","B"],"mo":"-"}]}},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mrow":{"mo":"-","mfrac":{"mrow":[{"msub":[{"mi":["z","near"]},{"mi":["z","far"]}],"mo":"+"},{"msub":[{"mi":["z","far"]},{"mi":["z","near"]}],"mo":"-"}]}}},{"mrow":{"mo":"-","mfrac":{"mrow":[{"mn":"2","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":[{"mi":["z","near"]},{"mi":["z","far"]}]},{"msub":[{"mi":["z","far"]},{"mi":["z","near"]}],"mo":"-"}]}}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mrow":{"mo":"-","mn":"1"}},{"mn":"0"}]}]}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"4"}}}]}}}}},"The OpenGL, OpenGL ES, and OpenGL ES 2.0 APIs, with programmable shaders, define the MVT matrix as:",{"@attributes":{"id":"p-0110","num":"0109"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"MVT","mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"msub":{"mi":"a","mn":"11"}},{"msub":{"mi":"a","mn":"12"}},{"msub":{"mi":"a","mn":"13"}},{"msub":{"mi":"a","mn":"14"}}]},{"mtd":[{"msub":{"mi":"a","mn":"21"}},{"msub":{"mi":"a","mn":"22"}},{"msub":{"mi":"a","mn":"23"}},{"msub":{"mi":"a","mn":"24"}}]},{"mtd":[{"msub":{"mi":"a","mn":"31"}},{"msub":{"mi":"a","mn":"32"}},{"msub":{"mi":"a","mn":"33"}},{"msub":{"mi":"a","mn":"34"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"5"}}}]}}}}},"All of the variables of the PRJ and MVT matrices may be defined by application  executing on application processor , and graphics driver  may provide these variables to shader processor  that is executing the object code of vertex shader . As can be seen from equations 1, 4, and 5, with these variables, vertex shader  may determine the Vclip coordinates for each of the vertices. GPU  may utilize the clip coordinates for the vertices and perform further functionality, in conjunction with the functionality of fixed-function pipeline  and fragment shaders, to render an image for display. In this manner, GPU  may generate a mono view for the graphics content generated by application .","In accordance with techniques of this disclosure, while vertex shader  may utilize the variables for the MVT and PRJ matrices to determine the Vclip coordinates, the MVT and PRJ matrices may not be needed to modify vertex shader  (e.g., modify the source code of vertex shader ) to generate the stereoscopic view. In other words, the instructions that the techniques described in this disclosure modify may not require the specific values of the MVT and PRJ matrices.","For example, there may be many ways in which to design vertex shader , and vertex shader  may be content and even scene dependent allowing content developers to utilize many different ways to program vertex shader . Accordingly, it may not be feasible to determine the specific ways in which the MVT and PRJ matrices are defined by the developer. However, the techniques described in this disclosure do not require knowledge of the manner in which the developer developed vertex shader  or the manner in which the developer defined the MVT and PRJ matrices.","The example above describes one way in which to determine the Vclip coordinates for the mono view. There may be many different techniques to calculate the clipping coordinates, and in general, it may be immaterial the particular technique utilized to calculate the clipping coordinates. However, in any event, for 3D graphics content, clipping coordinates (Vclip) may need to be calculated regardless of the technique used to calculate the clipping coordinates. For example, it may even be possible for application processor  to determine the clipping coordinates, and graphics driver  may provide the clipping coordinates to shader processor  that is executing the object code of vertex shader . In this example, the PRJ and MVT matrices may be unity matrices. For example, application processor  may perform the matrix multiplication of equation 1 and provide the results to shader processor . In this example, shader processor  may multiply received values with a unity matrix to generate the Vclip coordinates for each of the vertices generated by application .","However, in any case (e.g., where shader processor  executing vertex shader  determines the clipping coordinates or where shader processor  executing vertex shader  receives the clipping coordinates), vertex shader  may utilize a specific variable to store the clipping coordinates. The specific variable may be particular to the API for which vertex shader  is designed. For example, if vertex shader  is designed in accordance with the OpenGL, OpenGL ES, or OpenGL ES 2.0 APIs, with programmable shaders, vertex shader  may store the clipping coordinates in the gl_Position variable. The gl_Position variable may be declared automatically. There may be a similar variable in other graphics APIs. If vertex shader  is designed in accordance with the OpenGL, OpenGL ES, or OpenGL ES 2.0 APIs, with programmable shaders, vertex shader  may include instructions such as: gl_Position.x=x, gl_Postion.y=y, gl_Position.z=z, and gl_Position.w=w, where, as indicated above in equation 2,",{"@attributes":{"id":"p-0116","num":"0115"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["V","clip"]},"mo":"=","mrow":{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["x","clip"]}}},{"mtd":{"msub":{"mi":["y","clip"]}}},{"mtd":{"msub":{"mi":["z","clip"]}}},{"mtd":{"msub":{"mi":["w","clip"]}}}]}},"mo":"."}}}}},"In one or more example techniques described in this disclosure, graphics driver wrapper , which may be software executing on application processor , may modify the instructions of vertex shader  that define the clipping coordinates for the mono view to define clipping coordinates for the stereoscopic view (e.g., clipping coordinates for the left-eye image and clipping coordinates for the right-eye image). For example, graphics driver wrapper  may receive the determined viewing angle from application processor . Application processor , due to the execution of graphics driver wrapper , may be configured to modify the instructions of vertex shader  based on the viewing angle determined by application processor  to define clipping coordinates for the stereoscopic view.","For example, application processor , via graphics driver wrapper , may modify the instructions of vertex shader  such that when the modified instructions of vertex shader  are executed a first time by shader processor , the modified instructions of vertex shader  displace the clipping coordinates in one direction based on the viewing angle, and when the modified instructions of vertex shader  are executed a second time by shader processor , the modified instructions of vertex shader displace the same clipping coordinates in another direction based on the viewing angle. However, simply displacing the clipping coordinates in different directions, and rendering the resulting images may cause the stereoscopic view to always pop out of display  or always push into display  by a certain fixed amount. Such a result may not be pleasing to the viewer.","For example, assume that the stereoscopic view pops out of display . In this case, the viewer may perceive the stereoscopic view on a plane that is a certain distance in front of display . This plane where the viewer perceives the stereoscopic view may be referred to as a zero disparity plane (ZDP). However, the viewer may desire to perceive the zero disparity plane at a distance different than the current zero disparity plane.","For zero disparity plane adjustment, application processor , via graphics driver wrapper , may increase or decrease the horizontal disparity between the left-eye image and the right-eye image. For example, application  may output a command that defines the viewport of the single image. The term \u201cviewport\u201d refers to the area an image encompasses on display . For example, application  may define the size and location of the single image (e.g., mono view) on display . This definition of the size and location of the single image may be considered as the viewport for the single image. To define the viewport, application processor , via application , may issue a glViewport command whose variables define the size and location of the mono view image on display . Application processor , via graphics driver wrapper , may modify the command that defines the size and location of the single image (e.g., the glViewport command issued by application ) to commands that define the size and location of the left-eye image and the right-eye image (e.g., glViewport commands that define the viewport for the left-eye image and the viewport for the right-eye image) based on the viewing angle. The glViewport command for the left-eye image may constrain the left-eye image to one portion of the display based on the viewing angle, and the glViewport command for the right-eye image may constrain the right-eye image to another portion of the display based on the viewing angle. It may be possible for these two portions to at least partially overlap.","In some examples, application processor , via graphics driver wrapper , may modify the glViewport command to increase or decrease the horizontal disparity between the left-eye image and the right-eye image. For example, when the left-eye image is constrained to one portion, and the right-eye image is constrained to another portion, there may be certain, fixed horizontal disparity between all of the similar objects in the left-eye image and objects in the right-eye image. In other words, the amount of horizontal disparity between each of the corresponding vertices in the left-eye image and right-eye image may be the same. As an illustrative example, assume that the image generated by application  included a ball and a block. In this example, the horizontal disparity between the vertices of the ball in the left-eye image and the right-eye image may be the same as the horizontal disparity between the vertices of the block in the left-eye image and the right-eye image. Accordingly, the resulting stereoscopic view, the ball and the block may appear at the zero disparity plane, where the zero disparity plane is ahead of or behind display . When the ball and block appear at the zero disparity plane that ball and block may not appear pushed in to the zero disparity plane or pushed out of the zero disparity plane.","To adjust the location of the zero disparity plane (e.g., the amount by which the zero disparity place is ahead of or behind display ), application processor , via graphics driver wrapper , may modify the instructions of the glViewport command to allow the viewer to define the horizontal disparity between similar objects in the left-eye image and objects in the right-eye image. For example, the viewer may provide a horizontal disparity value that defines the horizontal disparity between similar objects in the left-eye image and right-eye image.","In this way, the viewer may be considered as defining the horizontal disparity between the left-eye image and the right-eye image because the viewer may further define the amount by which all similar objects in the left-eye image and the right-eye image are horizontally displaced. As described above, the amount of horizontal disparity between the left-eye image and the right-eye image defines the amount by which the stereoscopic view appears ahead of or behind display . Accordingly, by defining the horizontal disparity between the left-eye image and the right-eye image, the viewer may define the location of the zero disparity plane.","In some examples, instead of the viewer defining the horizontal disparity between the left-eye image and the right-eye image, application processor  may estimate the horizontal disparity between the left-eye image and the right-eye image. As one example, application processor  or graphics driver wrapper  may be preloaded with the horizontal disparity value that graphics driver wrapper  uses to increase or decrease the horizontal disparity between the left-eye image and the right-eye image. This horizontal disparity value may be based on an assumption of a common distance from which viewers generally view display . For instance, in examples where device  is a mobile device, most viewers hold device  at approximately the same distance away from their face. Accordingly, most viewers may prefer the zero disparity plane to appear at approximately the same distance ahead of display . Application processor  or graphics driver wrapper  may be preloaded with the horizontal disparity value that creates the zero disparity plane at the commonly preferred distance ahead of display .","As another example, camera processor  may be configured to determine an estimate of the distance of the viewer from display . For instance, camera processor  may identify the head of the viewer, and based on a measure of the head size, camera processor  may estimate a distance of the viewer relative to display . In this example, application processor  may utilize this estimate of the distance of the viewer to determine the horizontal disparity value, where the horizontal disparity value defines the amount of horizontal disparity between the left-eye image and the right-eye image.","In the techniques described in this disclosure, the glViewport command may not be an instruction of vertex shader . Rather, a viewport transformation unit of fixed-function pipeline  may constrain the left-eye image to one portion, and constrain the right-eye image to another portion based on the glViewport command. In these examples, GPU  may provide the glViewport command to the viewport transformation unit of fixed-function pipeline  to constrain the left-eye image to one portion of display  based on the viewing angle, and constrain the right-eye image to another portion of display  based on the viewing angle, such that the zero disparity plane is at the desired location relative to display .","In the above example of the modification of the glViewport command, application processor , via graphics driver wrapper , may define the horizontal disparity between the left-eye image and the right-eye image so that the viewer perceives the stereoscopic view at the desired zero disparity plane. In some examples, even better viewing experience may be realized by allowing the viewer to increase or decrease the horizontal disparity between similar objects by different amounts. For instance, in the glViewport command modification, application processor , via graphics driver wrapper , may modify the glViewport command such that all similar objects in the left-eye image and right-eye are displaced by the same amount. This results in the stereoscopic view appearing ahead or behind display  at the zero disparity plane. However, the viewer may also desire to cause some objects to appear ahead of the zero disparity plane, some objects to appear behind the zero disparity plane, and some objects to appear at the zero disparity plane.","In some examples, rather than the viewer or application processor  determining the horizontal disparity value that defines the location of the zero disparity plane, the viewer may define the location of the zero disparity plane, or application processor  may determine the location of the zero disparity plane. In these examples, application processor , via graphics driver wrapper , may not necessarily need to modify the glViewport command issued by application , other than to cause the glViewport command to execute twice: one for the left-eye image, and another for the right-eye image. Rather, application processor , via graphics driver wrapper , may further modify the instructions of vertex shader  such that vertices of primitives outputted by application  are displaced by different amounts in the left-eye image and the right-eye image.","For instance, in the example where graphics driver wrapper  modifies the glViewport command, graphics driver wrapper  may be considered as defining the horizontal disparity at the image level (e.g., the horizontal disparity between the right-eye image and the left-eye image). For example, graphics driver wrapper  may create two glViewport commands: one to constrain the left-eye image to one portion based on the viewing angle, and the other to constrain the right-eye image to another portion based on the viewing angle. For example, application  may issue the glViewport command that defines the viewport of the single image. Graphics driver wrapper  may modify the glViewport command issued by application  to define the viewport of the left-eye image in a first execution instance, and modify the glViewport command issued by application  to define the viewport of the right-eye image in a second execution instance.","In the example where application processor , via graphics driver wrapper , further modifies the instructions of vertex shader , graphics driver wrapper  may be considered as defining the horizontal disparity at the vertex level (e.g., the horizontal disparity between a vertex in the left-eye image and a vertex in the right-eye image). Accordingly, modifying the instructions of vertex shader  to adjust disparity may provide finer level of disparity adjustment as compared to modifying instructions of the glViewport command to adjust disparity. In the example where graphics driver wrapper  further modifies the instructions of vertex shader , GPU  may utilize the glViewport command issued by application  to define the viewports for the left-eye image and the right-eye image (e.g., no modification of the glViewport command may be needed). For example, graphics driver wrapper  may cause the glViewport command to execute twice: once for each of the left-eye and right-eye images. However, in this example, graphics driver wrapper  may not modify the glViewport command issued by application , and the additional modifications to the instructions of vertex shader  may allow for the vertices to be displaced by different amounts so that some objects appear ahead of the zero disparity plane, some objects appear behind the zero disparity plane, and some objects appear at the zero disparity plane.","For instance, application  may define the vertices of primitives in three-dimensions (e.g., x, y, z, w coordinates), where the w coordinate is the homogenous coordinate. In the techniques described in this disclosure, application processor , via graphics driver wrapper , may utilize a value of the z-coordinate of a vertex to determine the amount by which the vertex is displaced in the left-eye image and the right-eye image. For example, if the value of the z-coordinate is equal to the location of the zero disparity plane, the modified instructions of vertex shader  may not displace the vertex in the left-eye image and the right-eye image. If, however, the value of the z-coordinate is not equal to the location of the zero disparity plane, then the modified instructions of vertex shader  may displace the location of the vertex in the left-eye image and the right-eye image. The amount by which the modified instructions of vertex shader  displace the location of the vertex may be based on the value of the z-coordinate.","In examples where graphics driver wrapper  modifies the glViewport command to adjust the disparity at the image level, graphics driver wrapper  may not further modify the instructions of vertex shader  to adjust the disparity at a vertex level. In examples where graphics driver wrapper  further modifies the instructions of vertex shader  to adjust the disparity at a vertex level, graphics driver wrapper  may not modify the glViewport command to adjust the disparity at the image level. However, aspects of this disclosure are not so limited, and it may be possible for graphics driver wrapper  to modify both the glViewport command to adjust the disparity at the image level, and further modify the instructions of vertex shader  to adjust the disparity between vertices at the vertex level.","Also, when graphics driver wrapper  modifies only the glViewport command to adjust the location of the zero disparity plane, GPU  may be able to render the stereoscopic view faster than when graphics driver wrapper  further modifies the instructions of vertex shader  to adjust the locations of where the objects appear relative to the zero disparity plane (e.g., ahead of, at, or behind the zero disparity plane). This may be because vertex shader  takes longer to execute on shader processor  as compared to the viewport adjustment unit of fixed-function pipeline  adjusting the viewports of the left-eye image and the right-eye image. However, when graphics driver wrapper  further modifies the instructions of vertex shader  to adjust the locations of where the objects appear relative to the zero disparity plane, the rendered stereoscopic view may provide better viewer experience compared to when graphics driver wrapper  modifies the glViewport command. This may be because the further modification of the instructions to vertex shader  allows for some objects to appear ahead of, at, or behind the zero disparity plane, whereas with the modification to the glViewport command all objects appear at the zero disparity plane, which may be ahead of or behind display .","It may be a matter of design choice whether to modify the glViewport command or further modify the instructions of vertex shader . For instance, if rendering time is the important factor, then application processor , via graphics driver wrapper , may modify the glViewport command. If more ideal viewing experience is the important factor, then application processor , via graphics driver wrapper , may further modify the instructions of vertex shader .","Accordingly, graphics driver wrapper  may modify the instructions of vertex shader  such that when the modified instructions of vertex shader  execute of shader processor , GPU  may displace the vertices of the primitives in one direction based on the viewing angle, and in another direction based on the viewing angle. In some examples, graphics driver wrapper  may further modify the instructions of vertex shader  such that when the further modified instructions of vertex shader  execute on shader processor , GPU  may displace the vertices of the primitives in one direction based on the viewing angle and based on a location of the zero disparity plane. In some examples, graphics driver wrapper  may modify the instructions of a glViewport command issued by application  such that a viewport transformation unit of fixed-function pipeline  increases or decreases the horizontal disparity between the left-eye image and right-eye image to adjust the location of the zero disparity plane.","The following describes an example manner in which application processor , GPU , and system memory  may function together to cause GPU  to render stereoscopic view from application  that generates a mono-view. For instance, application processor  may determine the viewing angle based on one or more outputs from one or more sensors  and camera processor . Application processor  may determine the viewing angle periodically such as once per rendering of both the left-eye image and right-eye image by GPU , as one example (i.e., once per generation of the stereoscopic view). Graphics driver wrapper  may utilize this determined viewing angle to modify the instructions issued by application  and to modify the instructions of vertex shader .","For example, to cause GPU  to render an image, application processor  may execute a glShaderSource command of application . The glShaderSource command instructs graphics driver  to retrieve the source code of vertex shader  from system memory . In examples of this disclosure, in response to the glShaderSource command issued by application , graphics driver wrapper  may intercept the source code of vertex shader  before it reaches graphics driver . Application processor , via graphics driver wrapper , may modify the source code of vertex shader  to include instructions that cause modified vertex shader , when executed, to generate graphics content for stereoscopic view based on the viewing angle determined by application processor . For example, graphics driver wrapper  may cause the modified vertex shader  to execute twice. In the first execution, the modified vertex shader  may generate graphics content for the left-eye image based on the viewing angle, and in the second execution, the modified shader  may generate graphics content for the right-eye image based on the viewing angle, or vice-versa. Additionally, in some examples, graphics driver wrapper  may further modify the instructions of vertex shader  to determine the location of vertices based on the location of the zero disparity plane.","Graphics driver wrapper , as executed by application processor , may function as a source code editor. As one example, graphics driver wrapper  may monitor the instructions issued by application . When graphics driver wrapper  recognizes that application  issued the glShaderSource command, graphics driver wrapper  may capture and modify the instructions of vertex shader  (e.g., the source code of vertex shader ). For example, graphics driver wrapper  may include instructions into the source code of vertex shader  that modify the value of the clipping coordinates generated for the single image (e.g., mono view) to generate the clipping coordinates for the left-eye image and the right-eye image (e.g., stereoscopic view) based on the viewing angle.","For example, as indicated above, vertex shader  may include a gl_Position.x variable that stores the value for the xcoordinate, and a gl_Position.y variable that stores the value of y. As discussed in greater detail below, graphics driver wrapper  may include a first instruction into vertex shader  that updates the value of gl_Position.x (e.g., the xcoordinate) based on the viewing angle, and include a second instruction into vertex shader  that updates the value of gl_Position.y (e.g., the ycoordinate) based on the viewing angle.","To generate the left-eye image, the first instruction added into vertex shader  by application processor , via graphics driver wrapper , causes vertex shader  to add a first value to the xvalue. The first value may be based on the distance between the eyes of the viewer and the viewing angle. The second instruction added into vertex shader  by application processor , via graphics driver wrapper , causes vertex shader  to add a second value to the yvalue. The second value may be based on the distance between the eyes of the viewer, the viewing angle, and the height and width of display .","To generate the right-eye image, the instruction added into vertex shader  by graphics driver wrapper  causes vertex shader  to subtract the first value to the xvalue. The first value for the right-eye image may be the same value as the first value for the left-eye image. The second instruction added into vertex shader  by graphics driver wrapper  causes vertex shader  to subtract the second value to the yvalue. The second value for the right-eye image may be the same value as the second value for the left-eye image.","For example, application processor , via graphics driver wrapper , may modify the source code of vertex shader  to add an instruction that changes the value stored in the gl_Position.x variable (e.g., the xcoordinate) to the current value of the gl_Position.x variable plus (z*w\/(R\u2212L)\/2)*X, where z, R, and L are all variables from the PRJ matrix (equation 4), and wis a variable from the Vmatrix (equation 2) (e.g., the vertex coordinates defined by application ). Application processor , via graphics driver wrapper , may modify the source code of vertex shader  to add another instruction that changes the value stored in the gl_Position.y variable (e.g., the ycoordinate) to the current value of the gl_Position.y variable plus (z*w\/(T\u2212B)\/2)*Y, where z, T, and B are all variables from the PRJ matrix (equation 4), and wis a variable from the Vmatrix (equation 2) (e.g., the vertex coordinates as defined by application ).","The value of X may be +D*cos(\u03b1) or \u2212D*cos(\u03b1), where D is an approximation of half the distance between the right eye and the left eye of the viewer, and may be user definable or a preprogrammed value, and alpha, \u03b1, is the viewing angle. Application processor  may determine the viewing angle based on the outputs of one or more sensors  and camera processor , as one example. The value of Y may be +D*sin(\u03b1) or \u2212D*sin(\u03b1).","For example, assume that the distance between the left eye and the right eye is 2*D. In this example, the coordinates of the left eye of the viewer may be (\u2212D, \u2212D, \u2212D), and the coordinates of the right eye of the viewer may be (D, D, D). The Dcoordinate may be considered as zero because the coordinates of the left eye and the right eye may start from the front of the face of the viewer, and the middle of the eyes (i.e., the (0, 0, 0) location is located at the front of the face of the viewer and the point that is in between the left eye and right eye of the viewer). If the viewing angle is alpha, then the coordinates for the left eye of the viewer may be (\u2212D*cos(\u03b1), \u2212D*sin(\u03b1), 0), and the coordinates for the right eye of the view may be (D*cos(\u03b1), D*sin(\u03b1), 0). In this example, if the viewing angle is zero, then the coordinates of the left-eye and right-eye become (\u2212D, 0, 0), and (D, 0, 0). However, when the viewing angle is not zero, the viewing angle may be define the location of the left eye and right eye of the viewer relative to the (0, 0, 0) location. The coordinates for the left eye and right eye may be considered as:",{"@attributes":{"id":"p-0145","num":"0144"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"msub":{"mi":["Eye","left"]},"mo":"=","mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mo":"-","msub":{"mi":["D","x"]}}}},{"mtd":{"mrow":{"mo":"-","msub":{"mi":["D","y"]}}}},{"mtd":{"mrow":{"mo":"-","msub":{"mi":["D","z"]}}}}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mrow":[{"mo":"-","mi":"D"},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"\u03b1"}}],"mo":"*"}}},{"mtd":{"mrow":{"mrow":[{"mo":"-","mi":"D"},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"\u03b1"}}],"mo":"*"}}},{"mtd":{"mn":"0"}}]}}],"mo":"="}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"6"}}}]},{"mtd":[{"mrow":{"msub":{"mi":["Eye","right"]},"mo":"=","mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["D","x"]}}},{"mtd":{"msub":{"mi":["D","y"]}}},{"mtd":{"msub":{"mi":["D","z"]}}}]}},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"D","mo":"*","mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"\u03b1"}}}}},{"mtd":{"mrow":{"mi":"D","mo":"*","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"\u03b1"}}}}},{"mtd":{"mn":"0"}}]}}],"mo":"="}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"7"}}}]}]}}}},"Application processor , via graphics driver wrapper , may add the following instruction to the set of instructions of vertex shader : gl_Position.x+=(z*w\/(R\u2212L)\/2)*X. This may be equivalent to gl_Position.x=gl_Position.x+(z*w\/(R\u2212L)\/2)*X. For example, the gl_Position.x+=commands adds the value defined by the gl_Position.x+=instruction to the value stored by the gl_Position command (e.g., adds the value to x). In some situations, the gl_Position.x+=instruction may simplify to gl_Position.x+=X. The reasons why the gl_Position.x+variable may equal (z*w\/(R\u2212L)\/2)*X or just X are described in further detail below.","Application processor , via graphics driver wrapper , may also add the following instruction to the set of instructions of vertex shader : gl_Position.y+=(z*w\/(T\u2212B)\/2)*Y. This may be equivalent to gl_Position.y=gl_Position.y+(z*w\/(T\u2212B)\/2)*Y. For example, the gl_Position.y+=commands adds the value defined by the gl_Position.y+=instruction to the value stored by the gl_Position command (e.g., adds the value to y). In some situations, the gl_Position.y+=instruction may simplify to gl_Position.y+=Y*width of display  divided by height of display . The reasons why the gl_Position.y+variable may equal (z*w\/(T\u2212B)\/2)*Y or just Y*width of display  divided height of display  are described in further detail below.","In accordance with the techniques of this disclosure, to generate the left-eye image, application processor , via graphics driver wrapper , may define the value of the variable X to be D*cos(\u03b1). This is because that moving of viewing location left is equivalent to moving of object observed right. When X equals +D*cos(\u03b1), the gl_Position.x+=command causes the addition of a constant (e.g. (z*w\/(R\u2212L)\/2)*D*cos(\u03b1) or just D*cos(\u03b1)) to the xcoordinate of each of the vertices generated by application  which causes the vertices to move to the left by a value of D*cos(\u03b1). Also, to generate the left-eye image, application processor , via graphics driver , may define the value of the variable Y to be D*sin(\u03b1). This is because that moving of viewing location down is equivalent to moving of object observed up. When Y equals +D*sin(\u03b1), the gl_Position.y+=command causes the addition of a constant (e.g. (z*w\/(T\u2212B)\/2)*D*sin(\u03b1) or just D*sin(\u03b1)*width of display  divided height of display ) to the ycoordinate of each of the vertices generated by application  which causes the vertices to move to the left by a value of D*sin(\u03b1)*width\/height, where the width is the width of display  and height is the height of display .","To generate the right-eye image, application processor , via graphics driver wrapper , may define the value of the variable X to be \u2212D*cos(\u03b1). This is because that moving of viewing location right is equivalent to moving of object observed left. When X equals \u2212D*cos(\u03b1), the gl_Position.x+=command causes the subtraction of a constant (e.g., (z*w\/(R\u2212L)\/2)*\u2212D*cos(\u03b1) or just \u2212D*cos(\u03b1)) from the xcoordinate of each of the vertices generated by application  which causes the vertices to move to the right by a value of \u2212D*cos(\u03b1). Also, to generate the right-eye image, application processor , via graphics driver wrapper , may define the value of the variable Y to be \u2212D*sin(\u03b1). This is because of that moving of viewing location up is equivalent to moving of object observed down. When Y equals \u2212D*sin(\u03b1), the gl_Position.y+=command causes the subtraction of a constant (e.g., (z*w\/(T\u2212B)\/2)*\u2212D*sin(\u03b1)*width\/height or just \u2212D*cos(\u03b1)*width\/height) from the ycoordinate of each of the vertices generated by application  which causes the vertices to move to the right by a value of \u2212D*sin(\u03b1)*width\/height.","After modifying the source code of vertex shader , application processor  may store the modified source code of vertex shader  in system memory. In some examples, application processor  may store the modified source of vertex shader  in the same location where the unmodified source code of vertex shader  is stored in system memory . In another example, application processor  may store the modified source of vertex shader  in a location in system memory  that is different from the location where the unmodified source code of vertex shader  is stored.","Subsequent to issuing the glShaderSource command, application  issues a glCompileShader command. The glCompileShader command causes compiler , executing on application processor , to compile the modified source code of vertex shader . For example, the glCompileShader command may cause compiler  to retrieve the source code for the modified vertex shader  from system memory , and compile the modified vertex shader . After compiling, compiler  stores the resulting object code in system memory . For example, as illustrated, system memory  includes modified vertex shader . Modified vertex shader  is the object code resulting from compiler  compiling the modified source code of vertex shader .","Moreover, as described above, graphics driver wrapper  may include instructions in the source code of vertex shader  that cause vertex shader  to add a constant to the gl_Position.x variable and the gl_Position.y variable to generate the left-eye image and subtract the constant from the gl_Position.x and the gl_Position.y variable to generate the right-eye image. The object code of modified vertex shader  includes instructions that cause modified vertex shader  to add the constant to the gl_Position.x variable and the gl_Position.y variable to generate the left-eye image and subtract the constant from the gl_Position.x variable and the gl_Position.y variable to generate the right-eye image. As described in more detail, modified vertex shader  receives the value of the constant from application processor , via graphics driver wrapper , in response to a draw command from application .","In some examples, as described above, application processor , via graphics driver wrapper , may further modify the instruction of vertex shader  to further adjust the location of the vertices in the left-eye image and the right-eye image so that some objects appear ahead of, at, or behind the zero disparity plane. For instance, as described above, graphics driver wrapper  may modify the instructions of vertex shader  to include the following instructions: gl_Position.x+=X and gl_Position.y+=Y*width\/height, where X equals +D*cos(\u03b1) and Y equals +D*sin(\u03b1) for the left-eye image, and X equals \u2212D*cos(\u03b1) and Y equals \u2212D*sin(\u03b1) for the right-eye image.","To further allow adjustment at the vertex level, graphics driver wrapper  may modify the instructions of vertex shader  to include the following instructions: gl_Position.x+=X*(1\u2212(gl_Position.w\/ZDP)) and gl_Position.y+=Y*width\/height*(1\u2212(gl_Position.w\/ZDP)). ZDPmay be the user defined or preconfigured value defining the location of the zero disparity plane relative to display . In some other examples, processor  may determine an estimation of the location of the zero disparity plane based on an estimation of the location of the viewer as determined by camera processor . The gl_Position.w variable stores the wcoordinate.","For example, similar to the gl_Position.x and gl_Position.y variables, vertex shader  may store the wcoordinates in the gl_Position.w variable. In examples descried in this disclosure, the wcoordinate may equal the negative of the z-coordinate of a primitive as defined by application . As described above, application  may define primitives as (x, y, z, w). These coordinates may be considered as being defined in the world space (i.e., the vcoordinates of a vertex are (x, y, z, w)).","In the techniques described in this disclosure gl_Position.w may equal \u2212z. The reason why gl_Position.w equals \u2212zis due to the PRJ matrix defined in equations 3 and 4 above. As shown in the PRJ matrix, the value of the third column, fourth row is \u22121. As defined in equation 1 above, Vclip equals PRJ*MVT*Vworld. Accordingly, when the PRJ matrix is multiplied by the Vworld matrix and the MVT matrix, the zcoordinate of Vworld is multiplied by the \u22121 of the third column, fourth row of the PRJ matrix. The wcoordinate equals the result of the multiplication of zby \u22121 (i.e., wequals \u2212z), and the gl_Position.w variable stores the value of w(i.e., gl_Position.w equals \u2212z).","It may be possible to replace the gl_Position.x+=X*(1\u2212(gl_Position.w\/ZDP)) and gl_Position.y+=Y*width\/height*(1\u2212(gl_Position.w\/ZDP)) commands with gl_Position.x+=X*(1+(z\/ZDP)) and gl_Position.y+=Y*width\/height*(1+(z\/ZDP)). However, graphic driver wrapper  may not have access to all of the zvalues outputted by application . In the techniques described in this disclosure, if vertex shader  is designed in accordance with the OpenGL 2.0 ES API, as one example, then vertex shader  may be designed to include the gl_Position.w variable that is equal to w, which in this case is also equal to \u2212z. Accordingly, although graphics driver wrapper  may not have access to the zcoordinate, graphics driver wrapper  may utilize the gl_Position.w variable to determine the value of z.","The zcoordinate may provide a measure of relative depth of the vertices within the single image outputted by application . For example, the single image outputted by application  may be constrained to the 2D area of display ; however, the objects within the single image may appear head of or behind other objects based on the zcoordinate of the vertices. In examples where graphics driver wrapper  modifies the instructions of vertex shader  to include the gl_Position.x+=X*(1\u2212(gl_Position.w\/ZDP)) and gl_Position.y+=Y*width\/height*(1\u2212(gl_Position.w\/ZDP)) commands, graphics driver wrapper  may account for the relative depths of the vertices to determine how much to displace vertices in one direction for the left-eye image and in the other direction for the right-eye image.","For instance, when \u2212za vertex in the single image (i.e., as defined by the gl_Position.w variable) equals ZDP, gl_Position.x+=0, and gl_Position.y+=0. In this case, modified vertex shader  may not displace the vertex in either the left-eye image or right-eye image because gl_Position.x and gl_Position.y for the left-eye image equals gl_Position.x and gl_Postion.y for the right-eye image, respectively. However, when \u2212zof a vertex in the single image does not equal ZDP, then modified vertex shader  may displace the vertex in one direction for the left-eye image based on the viewing angle, and in another direction for the right-eye image based on the viewing angle. Moreover, because the \u2212zcoordinate for vertices in the single image generated by application  may be different, modified vertex shader  may displace different vertices in the single image by different amounts to create the left-eye image and the right-eye image.","In other words, further multiplication of the X and Y*width\/height variables with (1\u2212(gl_Position.w\/ZDP)) results in a vertex level determination of how much a vertex is to be displaced in the left-eye image and the right-eye image. Also, because the vertices in the single image may be displaced by different amounts based on the value of z, in the resulting stereoscopic view, some objects may appear ahead of the zero disparity plane, some objects may appear at the zero disparity plane, and some objects may appear behind the zero disparity plane.","In some examples, instead of or in addition to further modifying the instructions of vertex shader  to multiple the X and Y*width\/height variables with (1\u2212(gl_Position.w\/ZDP)), graphics driver wrapper  may modify the glViewport command to adjust the location of the zero disparity plane. For example, application , upon execution by processor , may also issue a command that defines the viewport of the single image (e.g., a command that defines the size and location of the single image on display ). This command may be the glViewport command. The glViewport command defines the starting coordinates for the image (e.g., x and y coordinates) and the width and length of the image. The starting coordinates and the width and length values of the glViewport command define the size and location of the image.","In some examples, graphics driver wrapper  may capture the glViewport command issued by application . In these examples, graphics driver wrapper  may block graphics driver  from transmitting the glViewport command issued by application  to GPU . Instead, graphics driver wrapper  may store the starting coordinates and the width and length values of the glViewport command, as issued by application , in system memory .","In an alternate example, graphics driver wrapper  may allow graphics driver  to transmit the glViewport command issued by application  to GPU . In this example, similar to above, graphics driver wrapper  may store the starting coordinates and the width and length values of the glViewport command, as issued by application . In this alternate example, prior to GPU  applying the glViewport command issued by application , graphics driver wrapper  may modify the glViewport command issued by application , and transmit the modified glViewport command to GPU . In this manner, although GPU  received the glViewport command issued by application , GPU  may execute the modified glViewport command, which is modified by graphics driver wrapper .","In either example, graphics driver wrapper  may then wait until application  issues a command to GPU  instructing GPU  to draw one or more primitives. This draw command may be a glDraw command. There are various examples of glDraw commands such as glDrawArrays and glDrawElements. Each of these various examples of draw commands is commonly referred to as a glDraw command.","When application  issues the glDraw command, graphics driver wrapper  captures the glDraw command, and blocks graphics driver  from transmitting the glDraw command to GPU . Graphics driver wrapper  then generates instructions that cause GPU  to generate the graphics content for the left-eye image and the right-eye image. As one example, graphic driver wrapper  generates instructions that cause GPU  to execute the object code of modified vertex shader  twice, issues two glViewport commands to define the viewport for the left-eye image and the right-eye image, and issues two glDraw commands.","In examples where graphics driver wrapper  modifies the instructions of vertex shader  to multiply the X and Y*width\/height variables with (1\u2212(gl_Position.w\/ZDP)), graphics driver wrapper  may not modify the glViewport commands, but may still issue to glViewport commands, one for each of the left-eye image and the right-eye image. In examples where graphics driver wrapper  does not modify the instruction of vertex shader  to multiply the X and Y*width\/height variables with (1\u2212(gl_Position.w\/ZDP)), graphics driver wrapper  may modify the glViewport command, and issue two glViewport commands, where the two glViewport commands are different the glViewport command issued by application .","As an overview of the techniques for either the vertex level adjustment of the disparity between vertices or the image level adjustment of the disparity between left-eye image and right-eye image, after graphics driver wrapper  blocks graphics driver  from the transmitting the glDraw command issued by application , graphics driver wrapper  issues a command to GPU  that causes shader processor  to make the modified vertex shader  ready to generate clipping coordinates for a first image of the stereoscopic view (e.g., the left-eye image). Then, graphics driver wrapper  may issue a first glViewport command to a viewport transformation unit of the fixed-function pipeline  which defines the size and location of the first image on the display. Graphics driver wrapper  may then issue a first glDraw command to GPU  that causes GPU  to render the first image constrained to a first portion of the display as defined by the first glViewport command.","Graphics driver wrapper  then issues a command to GPU  that causes shader processor  to make the modified vertex shader  ready to generate clipping coordinates for a second image of the stereoscopic view (e.g., the right-eye image). Then, graphics driver wrapper  may issue a second glViewport command to a viewport to the viewport transformation unit of the fixed-function pipeline  which defines the size and location of the second image on the display. Graphics driver wrapper  may then issue a second glDraw command to GPU  that causes GPU  to render the second image constrained to a second portion of the display as defined by the second glViewport command.","The techniques of this disclosure, described as an overview above, are described in more detail in the following examples. For ease of understanding only, in the following examples, the techniques are described with GPU  generating the graphics content for the left-eye image first, followed by the graphics content for the right-eye image; however, the opposite is also possible.","For example, after graphics driver wrapper  intercepts the glViewport command and then blocks the glDraw command issued by application , graphics driver wrapper  generates an instruction that instructs GPU  to generate clipping coordinates for the left-eye image. Again, it should be noted that in some examples graphics driver wrapper  may block the transmission of the glViewport command issued by application  to GPU . In other examples, graphics driver wrapper  may allow the glViewport command issued by application  to be transmitted to GPU .","As one example, application processor , via graphics driver wrapper , generates an instruction that causes GPU  to execute the object code of modified vertex shader . In response, shader processor  of GPU  executes the object code of modified vertex shader . In addition, application processor , via graphics driver wrapper , transmits the constant value that modified vertex shader  is to add to the gl_Position.x variable to generate the clipping coordinates for the left-eye image. The output of shader processor , due to the execution of the object code of modified vertex shader , is the clipping coordinates for the vertices of the left-eye image.","For instance, as discussed above, graphics driver wrapper  may include the following instructions into the source code of vertex shader : gl_Position.x+=(z*w\/(R\u2212L)\/2)*X, or just gl_Position.x+=X and gl_Position.y+=(z*w\/(T\u2212B)\/2)*Y, or just gl_Position.y+=Y*width\/height, for reasons that will be described. As described above, for vertex level adjustment of the disparity between vertices, graphics driver wrapper  may further modify the gl_Position.x and gl_Postion.y commands in the source code of vertex shader . For instance, in these examples, graphics driver wrapper  may include the following instructions into source code of vertex shader : gl_Position.x+=(z*w\/(R\u2212L)\/2)*X*(1\u2212(gl_Position.w\/ZDP)), or just gl_Position.x+=X*(1\u2212(gl_Position.w\/ZDP)) and gl_Position.y+=(z*w\/(T\u2212B)\/2)*Y*(1\u2212(gl_Position.w\/ZDP)), or just gl_Position.y+=Y*width\/height*(1\u2212(gl_Position.w\/ZDP)), for reasons that will be described","The z, w, R, L, T, and B variables may possibly be known to shader processor , as described above with respect to equations (2) and (4). However aspects of this disclosure do not require shader processor  to know the values of the z, w, R, L, T, and B variables. For example, the z, w, R, L, T, and B variables may each be constants, and therefore the result of (z*w\/(R\u2212L)\/2) and (z*w\/(T\u2212B)\/2) would be a constant value. In this case, the value of (z*w\/(R\u2212L)\/2) and (z*w\/(T\u2212B)\/2) could be estimated or user provided, and multiplied into the value of X or Y, as appropriate. As described in more detail, in some examples, (z*w\/(R\u2212L)\/2) may simplify to 1 and (z*w\/(T\u2212B)\/2) may simply to width\/height of display .","In some examples, shader processor  may not know the value of X and Y. For the left-eye image, graphics driver wrapper  may transmit the value of X and Y to shader processor  in addition to the instruction instructing shader processor  to execute the object code of modified vertex shader . In some examples, the value of X, for the left-eye image, may be +D*cos(\u03b1) and the value of Y, for the left-eye image, may be +D*sin(\u03b1), where D equals approximately half the distance between the eyes of the viewer, and may be user defined or preprogrammed, and alpha, \u03b1, equals the viewing angle as determined by processor . Because the value of variable X is +D*cos(\u03b1), the gl_Position.x+=command causes shader processor  to add the value of D*cos(\u03b1) to the value stored in the gl_Position.x variable (e.g., add D*cos(\u03b1) to the value of x). Also, because the value of Y is +D*sin(\u03b1), the gl_Position.y+=command causes shader processor  to add the value of D*sin(\u03b1)*width\/height to the value stored in the gl_Position.y variable (e.g., add D*sin(\u03b1)*width\/height).","Again, for vertex level adjustment of the vertices, the added gl_Position.x+=command causes shader processor  to add the value of D*cos(\u03b1)*(1\u2212(gl_Position.w)\/(ZDP) to the value stored in the gl_Position.x variable, and the added gl_Position.y+=command causes shader processor  to add the value of D*sin(\u03b1)*(1\u2212(gl_Position.w)\/(ZDP) to the value stored in the gl_Position.y variable. However, such vertex level adjustment of the vertices is not necessary in every example.","Graphics driver wrapper  also defines the viewport for the left-eye image. For example, prior to when application  issued the glDraw command, application  issued the glViewport command that graphics driver wrapper  intercepted. Graphics driver wrapper  also stored the starting coordinates and the width and length values in system memory . In examples where graphics driver wrapper  modified the instructions of vertex shader  for vertex level adjustment of the disparity between vertices, graphics driver wrapper  may not modify the instructions of the glViewport command, and may instead two glViewport commands that are the same as the glViewport command issued by application . In examples where graphics driver wrapper  does not modify the instructions of vertex shader  for vertex level adjustment of the disparity between vertices, graphics driver  may modify the instructions of the glViewport command as described below to determine the location of the zero disparity plane.","To define the viewport for the left-eye image for image level adjustment of the zero disparity plane, graphics driver wrapper  may modify the intercepted glViewport command issued by application . For example, the glViewport command includes four variables, where the first two variables define the starting coordinate for the image on the display, and the last two variables define the width and length of the image. The width and length variables are not necessarily coordinate values. Rather, the width and length variables define the amount by which the image extends from the starting coordinates. For instance, application  may issue a glViewport command that states: glViewport (0, 0, width, length). In this example, the (0, 0) refer to the bottom-left of the display. The variable \u201cwidth\u201d refers to the width of the display, and the variable \u201clength\u201d refers to the length of the display. Accordingly, in this example, application  defines the viewport of the image to encompass the entirety of the display, which would be consistent with a mono view image. However, application  may assign different variables for the glViewport command, other than those illustrated.","In accordance with this disclosure, graphics driver wrapper  may intercept the glViewport command (e.g., glViewport (0, 0, width, length) of the previous example), and modify the variables for this viewport command. For example, graphics driver wrapper  may modify the variables of the glViewport command to constrain the left-eye image to a desired portion of the display. For ease of description, the techniques describe constraining the left-eye image to the left half of the display, and right-eye image to the right half of the display; however, aspects are not so limited.","For the left-eye image, graphics driver wrapper  may modify glViewport command issued by application  to glViewport (0, 0, width\/2, length). In this example, the width\/2 would be half of the width of the display. For example, the modified glViewport command indicates that the left-eye image with start from the left end of the display (e.g., starting from 0 point on the x-axis) and extend rightwards a distance of \u201cwidth\/2,\u201d which would constrain the left-eye image to the left half of the display. Also, the modified glViewport command indicates that the left-eye image will start from the bottom of the display (e.g., starting from the 0 point on the y-axis) and extend upwards a distance of \u201clength,\u201d which would constrain the image to the top and bottom of the display.","In either example (e.g., where the glViewport command is modified or where the glViewport command is not modified), graphics driver wrapper  may then issue a first glDraw command to GPU . In response to the glDraw command, GPU  may process the clipping coordinates for the left-eye image generated by the execution of the object code of the modified vertex shader  through fixed-function pipeline  and fragment shaders. In the example with glViewport command modification, the first glViewport command may constrain the left-eye image to the left half of the display. In the example without glViewport command modification, the first glViewport command may not constrain the left-eye image to the left half of the display. The glDraw command may then cause GPU  to render the left-eye image to a frame buffer for temporary storage. For example, the frame buffer may store the left-eye image until the right-eye image is generated. Then, GPU  may output the entirety of the frame buffer to a display processor (not shown). The display processor may cause the display to display the left-eye image and the right-eye image to generate the stereoscopic view.","Graphics driver wrapper  may repeat the same steps for generating the left-eye image, but for generating the right-eye image. For example, graphics driver wrapper  issues another instruction to cause shader processor  to execute the object code of modified vertex shader . In addition, graphics driver wrapper  transmits the constant value that modified vertex shader  is to subtract from the gl_Position.x variable to generate the clipping coordinates for the right-eye image and to subtract from the gl_Position.y variable to generate the clipping coordinates for the left-eye image. The output of shader processor , due to the execution of the object code of modified vertex shader , is the clipping coordinates for the vertices of the right-eye image.","As described above, graphics driver wrapper  may add the instruction gl_Position.x+=(z*w\/(R\u2212L)\/2)*X, or just gl_Position.x+=X to the source code of vertex shader , and add the instruction gl_Position.y+=(z*w\/(T\u2212B)\/2)*Y, or just gl_Position.y+=Y*width\/height. For the left-eye image, the value of variable X may be +D*cos(\u03b1) and the value of variable Y may be +D*sin(\u03b1). In examples of this disclosure, for the right-eye image, the value of variable X may be \u2212D*cos(\u03b1) and the value of variable Y may be \u2212D*sin(\u03b1). Because the value of variable X is \u2212D*cos(\u03b1), the gl_Position.x+=command causes shader processor  to subtract the value of D*cos(\u03b1) from the value stored in the gl_Position.x variable. Also, because the value of variable Y is \u2212D*sin(\u03b1), the gl_Position.y+=command causes shader processor  to subtract the value of D*sin(\u03b1)*width\/height from the value stored in the gl_Position.y variable.","In some examples (e.g., for image level adjustment of the disparity between the left-eye image and the right-eye image), graphics driver wrapper  also defines the viewport for the right-eye image. As discussed above, for the left-eye image, graphics driver wrapper  defines the viewport to be glViewport (0, 0, width\/2, length) to constrain the left-eye image to the left half of the display. For the right-eye image, graphics driver wrapper  may define the viewport to be glViewport (width\/2, 0, width\/2, length). In this example, the (width\/2, 0) coordinate indicates that the right-eye image will start from the middle of the display and extend rightwards. Also, the (width\/2, length) variables in the glViewport command indicate that the right-eye image will extend half the width of the display and the full length of the display.","Therefore, in this example, the modified glViewport command (e.g., glViewport (width\/2, 0, width\/2, length)) would constrain the right-eye image to the right half of the display. For example, the modified glViewport command indicates that the right-eye image will start from the middle of the display (e.g., starting from the width\/2 point on the x-axis) and extend rightward a distance of \u201cwidth\/2,\u201d which would constrain the right-eye image to the right half of the display. Also, the modified glViewport command indicates that the right-eye image will start from the bottom of the display (e.g., starting from the 0 point on the y-axis) and extend upward a distance of \u201clength,\u201d which would constrain the image to the top and bottom of the display.","Graphics driver wrapper  may then issue a second glDraw command to GPU . In response to the glDraw command, GPU  may process the clipping coordinates for the right-eye image generated by the execution of the object code of the modified vertex shader  through fixed-function pipeline  and fragment shaders. The glDraw command may then cause GPU  to render the right-eye image to the frame buffer for temporary storage. In this case, GPU  may have already stored the left-eye image to the frame buffer, and GPU  may instruct the display processor to retrieve and display the stored left-eye image and right-eye image from the frame buffer to generate the stereoscopic view.","As described above, graphics driver wrapper  may add the instruction gl_Position.x+=command and the gl_Position.y+=command to the source code of vertex shader . It is the gl_Position.x+=command and the gl_Position.y+=command that is added to the source code of vertex shader  that causes the slight displacement between the left-eye image and the right-eye image, based on the viewing angle, to cause the popping out or pushing effect of the stereoscopic view.","In the above examples of the modification to the glViewport command, the modifications to glViewport command constrained the left-eye image to the left half of display , and constrained the right-eye image to the right half of display . However, constraining the left-eye image to the left half of display  and constraining the right-eye image to the right half of display  may not account for the viewing angle, \u03b1. Also, constraining the left-eye image to the left half of display  and constraining the right-eye image to the right half of display  may not allow the viewer to set the desired location of the ZDP.","The following describes the manner in which graphic driver wrapper  may modify the glViewport command to account for viewing angle, and to allow the setting of the zero disparity plane at the desired location. For example, as above, assume that the viewport defined by application  is glViewport (0, 0, width, height), where the location of the left-bottom of display  is (0, 0), and the location of the top-right of display  is (width, height).","In this case, for the left-eye image, graphics driver wrapper  may modify the glViewport command to be glViewport (\u2212VPshift*cos(\u03b1), \u2212VPshift*sin(\u03b1), width\u2212VPshift*cos(\u03b1), height\u2212Vpshift*sin(\u03b1)), where (\u2212VPshift*cos(\u03b1), \u2212VPshift*sin(\u03b1)) is the left-bottom of the left-eye image and (width\u2212VPshift*cos(\u03b1), height\u2212Vpshift*sin(\u03b1)) is the right-top of the left-eye image. For the right-eye image, graphics driver wrapper  may modify the glViewport command to be glViewport (VPshift*cos(\u03b1), VPshift*sin(\u03b1), width+VPshift*cos(\u03b1), height+VPshift*sin(\u03b1)), where (VPshift*cos(\u03b1), VPshift*sin(\u03b1)) is the left-bottom of the right-eye image, and (width+VPshift*cos(\u03b1), height+VPshift*sin(\u03b1)) is the right-top of the right-eye image.","In the above example, the VPshift variable may define the amount of horizontal disparity between the left-eye image and the right-eye image. For example, VPshift may be the horizontal disparity value described above. The horizontal disparity value may indicate the amount by which the viewports of the left-eye image and right-eye image are shifted relative to one another (i.e., the amount of viewport shift), hence the variable VPshift. The viewer may define the value of VPshift to define the location of the zero disparity plane. As another example, processor  may be configured to determine the value of VPshift based on an estimation of how far away the viewer is relative to display . As another example, application  or graphics driver wrapper  may be preconfigured with a value for VPshift.","In some examples, graphics driver wrapper  may further modify the glViewport commands for the left-eye and right-eye images for viewport stretch. The viewport stretching expands the viewports of the left-eye image and the right-eye image such that there is potentially overlap between the left-eye image and the right-eye image. For example, without viewport stretch, the left-eye image and the right-eye image may be constrained to respective portions on the display, and there may not be overlap. To increase or decrease overlap, application processor , via graphics driver wrapper , may further modify the glViewport commands to include viewport stretch. The viewport stretching may also affect the location of the zero disparity plane, and may provide for yet another way in which to control the location of the zero disparity plane to the desired location.","Modifying the glViewport command to include viewport stretch is not necessary in every example. Moreover, in accordance with the techniques described in this disclosure, application processor , via graphics driver wrapper , may modify the glViewport command to include viewport stretch based on the viewing angle. For example, application processor , via graphics driver wrapper , may modify the glViewport commands as follows. For the viewport of the left-eye image, application processor , via graphics driver wrapper , may modify the glViewport command to glViewport(\u2212VPshift*cos(\u03b1), \u2212VPshift*sin(\u03b1), width, height). For the viewport of the right-eye image, application processor , via graphics driver wrapper , may modify the glViewport command to glViewport(0, 0, width+VPshift*cos(\u03b1), height+VPshift*sin(\u03b1)).","As described above, the techniques described in this disclosure may modify the instructions to generate an image for a mono view to generate images for stereoscopic view during execution or run time. For example, a viewer may select application  for execution, which may require the execution of vertex shader  for processing the graphics generated by the execution of application . While application  is executing or running on device , graphics driver , graphics driver wrapper , and compiler  may perform their respective functions on application processor  to cause application processor  to modify the source code of vertex shader  and generate the object code for modified vertex shader . In other words, 3D graphics to S3D graphics conversion is performed in run-time by application processor , via graphics driver wrapper , rather than needing preprogrammed S3D graphics content or prerecorded S3D images or video.","Also, although the above examples are described in the context where application processor , via graphics driver wrapper , adds instructions to and modifies the instructions of vertex shader  and modifies the instruction that defines the viewport, aspects of this disclosure are not so limited. In some examples, rather than graphics driver wrapper , it may be possible for application processor , via graphics driver  or compiler , to modify the instructions of vertex shader  and the instructions outputted by application . However, these examples may require modification to graphics driver  or compiler .","Modification to graphics driver  or compiler  may be more difficult than developing graphics driver wrapper  and having application processor , via graphics driver wrapper , perform the functions described in this disclosure so that GPU  generates the left-eye image and the right-eye image for the stereoscopic view. For example, device  may have been loaded with preexisting graphics driver  and compiler , and it may be difficult to change graphics driver  and compiler . By adding graphics driver wrapper  to cause application processor  to perform the modification to vertex shader , the example techniques may not require modification to preexisting graphics driver  and compiler .","Furthermore, the techniques described above may allow GPU  to generate images for the stereoscopic view without modification to application . For example, some other techniques to generate stereoscopic view may require the developers of application  to modify the source code of application  to generate pixel values for the left-eye and right-eye images. These techniques required assistance from the developer of application  to modify their applications for stereoscopic view, which may be potentially cumbersome task for the developer of application . The example techniques described above may provide stereoscopic view for application , developed for mono view, without any assistance from the developer of application .","Moreover, some other techniques have been proposed to convert 3D graphics to S3D graphics in run-time. However, these other techniques may not account for the viewing angle. For instance, in these other techniques, if the viewing angle changes, the resulting stereoscopic view may appear less than ideal. By accounting for the viewing angle, the techniques provide for richer viewing experience regardless of the angle at which the viewer is viewing display  or regardless of the angle of display .","Also, the techniques described above may not require multiple calls to system memory  for generating the left-eye and right-eye images for stereoscopic view. For example, in some other techniques to generate stereoscopic view, a GPU would generate the left-eye image. Upon completion of the generation of the left-eye image, the GPU would utilize depth information stored in system memory  while generating the left-eye image to generate the right-eye image. However, repeated calls to system memory  to retrieve the depth information may be computationally expensive and may require excessive power consumption.","The example techniques described above may not require such multiple calls to system memory  for the depth information for the left-eye image to generate the right-eye image. For example, graphics driver wrapper  may modify the source code of vertex shader  and the instruction that defines the viewport to generate the left-eye and right-eye images independently from one another, without necessarily needing the depth information of one image to generate the other image.","As described above, graphics driver wrapper  may include the gl_Position.x+=(z*w\/(R\u2212L)\/2)*X or just gl_Position.x+=X command into the source code of vertex shader  that modifies the value of the gl_Position.x variable, and include the gl_Position.y+=(z*w\/(T\u2212B)\/2)*Y or just gl_Position.x+=Y*width\/height, where X equals D*cos(\u03b1) or \u2212D*cos(\u03b1), and Y equals D*sin(\u03b1) or \u2212D*sin(\u03b1). Again, if vertex level adjustment of vertices is desired, graphics driver wrapper  may further multiply the X and the Y variables with (1\u2212gl_Position.w\/ZDP), where gl_position.w stores the wcoordinate, which is equal to \u2212zand ZDPis the desired zero disparity plane location. The following provides the reasons for such an inclusion of instructions into the source code of vertex shader .","As indicated above in equation (1), Vclip=PRJ*Veye=PRJ*MVT*Vworld. The equation for Vclip may be modified to generate clipping coordinates for the left-eye and the right-eye. For example, the clipping coordinates for the left-eye and right-eye may be:\n\nclip_left-eye=left-eye*eye=left-eye*world\u2003\u2003 (equation 8), and\n\nclip_right-eye=right-eye*eye=right-eye*world\u2003\u2003 (equation 9).\n","VTleft-eye and VTright-eye may be 4\u00d74 matrices that are based on an assumed distance of the left eye and right eye away from the mono view. The coordinates of the mono view may be (0, 0, 0), and the left eye may be considered as being located at (D*cos(\u03b1), D*sin(\u03b1), 0), as described in equation 6, and the right eye may be considered as being located at (\u2212D*cos(\u03b1), \u2212D*sin(\u03b1), 0). In other words, the (0, 0, 0) location may be considered as being in the middle of the right eye and the left eye of the viewer. If the left eye is considered to be located (D*cos(\u03b1), D*sin(\u03b1)) away from the middle of the right eye and the left eye, and right eye is considered to be located (\u2212D*cos(\u03b1), \u2212D*sin(\u03b1)) away from the middle of the right eye and the left eye, then D indicates half of the distance between the right eye and left eye of the viewer, and alpha, \u03b1, indicates the viewing angle.","The matrices for VTleft-eye and VTright-eye may be defined as:",{"@attributes":{"id":"p-0204","num":"0203"},"maths":[{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["VT","left_eye"]},"mo":"=","mrow":{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"mn":"0"},{"mrow":{"mi":"D","mo":"*","mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}}}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mrow":{"mi":"D","mo":"*","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mi":"and"}}}},{"@attributes":{"id":"MATH-US-00007-2","num":"00007.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["VT","right_eye"]},"mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":"-","mi":"D"},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":"*"}}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mrow":{"mrow":[{"mo":"-","mi":"D"},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":"*"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}}}}}]},"VTleft-eye and VTright-eye may be rewritten as a sum of two matrices. For example, VTleft-eye may be rewritten as",{"@attributes":{"id":"p-0206","num":"0205"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["VT","left_eye"]},"mo":"=","mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}},{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mi":"D","mo":"*","mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mi":"D","mo":"*","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]}]}},"mo":"."}],"mo":"+"}}}}},"VTright-eye may be rewritten as",{"@attributes":{"id":"p-0208","num":"0207"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["VT","right_eye"]},"mo":"=","mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}},{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":"-","mi":"D"},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":"*"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":"-","mi":"D"},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":"*"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]}]}},"mo":"."}],"mo":"+"}}}}},"By substituting the VTleft-eye matrix into the equation for Vclip_left-eye (equation 7), Vclip_left-eye equals:",{"@attributes":{"id":"p-0210","num":"0209"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["Vclip_left","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}},{"mrow":[{"mi":["PRJ","MVT","Vworld"],"mo":["*","*","*"],"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}}},{"mi":["PRJ","MVT"],"mo":["*","*","*"],"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mi":"D","mo":"*","mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mi":"D","mo":"*","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]}]}},{"mi":"Vworld","mo":"."}]}],"mo":"+"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"10"}}}]}}}}},"By substituting the VTright-eye matrix into the equation for Vclip_right-eye (equation 8), Vclip_right-eye equals:",{"@attributes":{"id":"p-0212","num":"0211"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["VTclip_right","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}},{"mrow":[{"mi":["PRJ","MVT","Vworld"],"mo":["*","*","*"],"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}}},{"mi":["PRJ","MVT"],"mo":["*","*","*"],"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":"-","mi":"D"},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":"*"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":"-","mi":"D"},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":"*"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]}]}},{"mi":"Vworld","mo":"."}]}],"mo":"+"}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"11"}}}]}}}}},"In both equations 10 and 11 (e.g., for Vclip_left-eye and Vclip_right-eye)",{"@attributes":{"id":"p-0214","num":"0213"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":["PRJ","MVT","Vworld"],"mo":["*","*","*"],"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}}}}},"br":{}},{"@attributes":{"id":"p-0215","num":"0214"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"\u2003","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}}}}},"br":{}},"As described above in equation 1, PRJ*MVT*Vworld equals Vclip. Therefore, the Vclip_left-eye and Vclip_right-eye equations (e.g., equations 10 and 11, respectively) can be rewritten as:",{"@attributes":{"id":"p-0217","num":"0216"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":["Vclip_left","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}},{"mi":"Vclip","mo":"+","mrow":{"mi":["PRJ","MVT","Vworld"],"mo":["*","*","*"],"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mi":"D","mo":"*","mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mi":"D","mo":"*","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]}]}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"12"}}}]},{"mtd":[{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"4.4em","height":"4.4ex"}}},"mo":"\u2062","mrow":{"mi":"and","mo":","}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":["Vclip_right","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}},{"mi":"Vclip","mo":"+","mrow":{"mi":["PRJ","MVT"],"mo":["*","*","*"],"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":"-","mi":"D"},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":"*"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":"-","mi":"D"},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":"*"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]}]}},{"mi":"Vworld","mo":"."}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"13"}}}]}]}}}},"By substituting the matrices for the PRJ and MVT (equations 4 and 5, respectively), and performing the matrix multiplication of equation 11, the equation for Vclip_left-eye may simplify to:",{"@attributes":{"id":"p-0219","num":"0218"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":["Vclip_left","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}},{"mi":"Vclip","mo":"+","mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}}}},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*"],"mi":"D"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["T","B"],"mo":"-"}},"mo":"\/","mn":"2"}}}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*"],"mi":"D"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]}]}},{"mi":"Vworld","mo":"."}],"mo":"*"}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0220","num":"0219"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":["Vclip_left","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}},{"mi":"Vclip","mo":"+","mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}}}},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*"],"mi":"D"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["T","B"],"mo":"-"}},"mo":"\/","mn":"2"}}}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*"],"mi":"D"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]}]}},{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["x","world"]}}},{"mtd":{"msub":{"mi":["y","world"]}}},{"mtd":{"msub":{"mi":["z","world"]}}},{"mtd":{"msub":{"mi":["w","world"]}}}]}},"mo":"."}],"mo":"*"}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0221","num":"0220"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":["Vclip_left","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}},{"mi":"Vclip","mo":"+","mrow":{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mo":"(","mrow":{"mo":"(","mrow":{"mrow":[{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}}},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*","*"],"mi":"D","msub":{"mi":["w","world"]}}}}}},{"mtd":{"mrow":{"mo":"(","mrow":{"mo":"(","mrow":{"mrow":[{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["T","B"],"mo":"-"}},"mo":"\/","mn":"2"}}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*","*"],"mi":"D","msub":{"mi":["w","world"]}}}}}},{"mtd":{"mn":"0"}},{"mtd":{"mn":"0"}}]}},"mo":"."}}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0222","num":"0221"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":["Vclip_left","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":"x","mrow":{"mi":["clip_left","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mtd":{"msub":{"mi":"y","mrow":{"mi":["clip_left","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mtd":{"msub":{"mi":"z","mrow":{"mi":["clip_left","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mtd":{"msub":{"mi":"w","mrow":{"mi":["clip_left","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}}]}},{"mo":"\u2003","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"xclip","mo":"+","mrow":{"mo":"(","mrow":{"mo":"(","mrow":{"mrow":[{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}}},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*","*"],"mi":"D","msub":{"mi":["w","world"]}}}}}}},{"mtd":{"mrow":{"mi":"yclip","mo":"+","mrow":{"mo":"(","mrow":{"mo":"(","mrow":{"mrow":[{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["T","B"],"mo":"-"}},"mo":"\/","mn":"2"}}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*","*"],"mi":"D","msub":{"mi":["w","world"]}}}}}}},{"mtd":{"mi":"zclip"}},{"mtd":{"mi":"wclip"}}]}}}],"mo":"="}],"mo":"="}}},"br":{},"sub":["clip ","clip ","near","world ","clip ","near","world ","clip ","near ","world ","clip ","clip "],"b":["42","12"]},"With similar substitutions to those for Vclip_left-eye, the Vclip_right-eye equation may simplify to:",{"@attributes":{"id":"p-0224","num":"0223"},"maths":{"@attributes":{"id":"MATH-US-00019","num":"00019"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":["Vclip_right","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}},{"mi":"Vclip","mo":"-","mrow":{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mo":"(","mrow":{"mo":"(","mrow":{"mrow":[{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}}},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*","*"],"mi":"D","msub":{"mi":["w","world"]}}}}}},{"mtd":{"mrow":{"mo":"(","mrow":{"mo":"(","mrow":{"mrow":[{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["T","B"],"mo":"-"}},"mo":"\/","mn":"2"}}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*","*"],"mi":"D","msub":{"mi":["w","world"]}}}}}},{"mtd":{"mn":"0"}},{"mtd":{"mn":"0"}}]}},"mo":"."}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"14"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0225","num":"0224"},"maths":{"@attributes":{"id":"MATH-US-00020","num":"00020"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"35.3em","height":"35.3ex"}}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mi":"equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"15"}}}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":["Vclip_right","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}},{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":"x","mrow":{"mrow":{"mi":["clip_","right"],"mo":"\u2062"},"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"},"mi":"eye"}}}},{"mtd":{"msub":{"mi":"y","mrow":{"mi":["clip_right","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mtd":{"msub":{"mi":"z","mrow":{"mi":["clip_right","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}},{"mtd":{"msub":{"mi":"w","mrow":{"mi":["clip_right","eye"],"mo":["\u2062","\u2062"],"mstyle":{"mtext":"-"}}}}}]}},{"mo":"\u2003","mrow":{"mo":"\u2003","mrow":{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"xclip","mo":"+","mrow":{"mo":"(","mrow":{"mo":"(","mrow":{"mrow":[{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}}},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*","*"],"mi":"D","msub":{"mi":["w","world"]}}}}}}},{"mtd":{"mrow":{"mi":"yclip","mo":"+","mrow":{"mo":"(","mrow":{"mo":"(","mrow":{"mrow":[{"mi":"znear","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["T","B"],"mo":"-"}},"mo":"\/","mn":"2"}}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}}],"mo":["*","*","*"],"mi":"D","msub":{"mi":["w","world"]}}}}}}},{"mtd":{"mi":"zclip"}},{"mtd":{"mi":"wclip"}}]}},"mo":"."}}}],"mo":"="}],"mo":"="}},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}]}}}},"From equations 14 and 15, it can be seen that by adding the constant",{"@attributes":{"id":"p-0227","num":"0226"},"maths":{"@attributes":{"id":"MATH-US-00021","num":"00021"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"msub":{"mi":["z","near"]},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}},"mo":["*","*","*"],"mi":"D","mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}},"msub":{"mi":["w","world"]}}}},"br":{},"sub":"clip "},{"@attributes":{"id":"p-0228","num":"0227"},"maths":{"@attributes":{"id":"MATH-US-00022","num":"00022"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"msub":{"mi":["z","near"]},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["T","B"],"mo":"-"}},"mo":"\/","mn":"2"}},"mo":["*","*","*"],"mi":"D","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}},"msub":{"mi":["w","world"]}}}},"br":{},"sub":"clip","b":"38"},{"@attributes":{"id":"p-0229","num":"0228"},"maths":{"@attributes":{"id":"MATH-US-00023","num":"00023"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"msub":{"mi":["z","near"]},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}},"mo":["*","*","*"],"mi":"D","mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}},"msub":{"mi":["w","world"]}}}},"br":{},"sub":"clip "},{"@attributes":{"id":"p-0230","num":"0229"},"maths":{"@attributes":{"id":"MATH-US-00024","num":"00024"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"msub":{"mi":["z","near"]},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["T","B"],"mo":"-"}},"mo":"\/","mn":"2"}},"mo":["*","*","*"],"mi":"D","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"alpha"}},"msub":{"mi":["w","world"]}}}},"br":{},"sub":["clip ","near","world","near","world"],"b":["38","16"]},"In some examples, it may be possible to further simplify the gl_Position.x+=command to just gl_Position.x+=X. For example, it is common for the wvariable to be set to 1. Also, OpenGL, OpenGL ES, and OpenGL ES 2.0, with programmable shaders, define a frustum to be:",{"@attributes":{"id":"p-0232","num":"0231"},"maths":{"@attributes":{"id":"MATH-US-00025","num":"00025"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":{"mi":"cot","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["fov","x"]}}},"mo":"=","mfrac":{"msub":{"mi":["z","near"]},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}}},"mo":","}}},"br":{},"sub":["x ","x"]},{"@attributes":{"id":"p-0233","num":"0232"},"maths":{"@attributes":{"id":"MATH-US-00026","num":"00026"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"msub":{"mi":["z","near"]},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}}}},"br":{}},{"@attributes":{"id":"p-0234","num":"0233"},"maths":{"@attributes":{"id":"MATH-US-00027","num":"00027"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mrow":[{"msub":[{"mi":["z","near"]},{"mi":["w","world"]}],"mo":"*"},{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}]},"mo":"*","mi":"X"}}},"br":{}},{"@attributes":{"id":"p-0235","num":"0234"},"maths":{"@attributes":{"id":"MATH-US-00028","num":"00028"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"msub":{"mi":["z","near"]},"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":["R","L"],"mo":"-"}},"mo":"\/","mn":"2"}}}},"br":{},"sub":"world "},"Also, width of display  may equal R\u2212L, and the height of display  may equal T\u2212B. Therefore, the instruction gl_Position.y+=z*w\/((T\u2212B)\/2)*Y may simplify down to the instruction gl_Position.y+=Y*width\/height.","Accordingly, the above equations provide mathematical foundation that illustrates the reasons why adding the instruction gl_Position.x+=(z*w\/(R\u2212L)\/2)*X, or gl_Position.x+=X and gl_Position.y+=(z*w\/(T\u2212B)\/2)*Y, or gl_Position.y+=Y to vertex shader  may be sufficient to displace the mono view image to generate stereoscopic view based on the viewing angle, when executed twice, and where X equals +D*cos(\u03b1) and Y equals +D*sin(\u03b1), in the first execution, and where X equals \u2212D*cos(\u03b1) and Y equals \u2212D*sin(\u03b1) in the second execution. Furthermore, even in examples where (z*w\/(R\u2212L)\/2) does not equal 1, and in examples where (z*w\/(T\u2212B)\/2) does not equal width\/height, the z*w\/(R\u2212L)\/2*D may be a constant value whose value the viewer may select, and similarly the z*w\/(T\u2212B)\/2*D may be constant value whose value the viewer may select.","In other words, in the techniques described in this disclosure, the actual values of z, w, R, L, T, B, and D may not be needed. Rather, the viewer may select a first value for z*w\/(R\u2212L)\/2*D, and a second value for z*w\/(R\u2212L)\/2*D. Graphics driver wrapper  may multiply the first value with cos(\u03b1), and provide the resulting value to vertex shader . The gl_Position.x+=command in vertex shader , which graphics driver wrapper  included in vertex shader , may add the provided value by graphics driver wrapper  to the current value of gl_Position.x to determine the x-clipping coordinate of the vertex in the first execution of the object code of modified vertex shader  for the left-eye image. Also, graphics driver wrapper  may multiply the second value with sin(\u03b1), and provide the resulting value to vertex shader . The gl_Position.y+=command in vertex shader , which graphics driver wrapper  included in vertex shader , may add the provided value by graphics driver wrapper  to the current value of gl_Position.y to determine the y-clipping coordinate of the vertex in the first execution of the object code of modified vertex shader  for the left-eye image.","Similarly, graphics driver wrapper  may multiply the first value with \u22121 and cos(\u03b1), and provide the resulting value to vertex shader . The gl_Position.x+=command in vertex shader , which graphics driver wrapper  included in vertex shader , may add the provided value by graphics driver wrapper  to the current value of gl_Position.x to determine the x-clipping coordinate of the vertex in the second execution of the object code of modified vertex shader  for the right-eye image. Also, graphics driver wrapper  may multiply the second value with \u22121 and sin(\u03b1), and provide the resulting value to vertex shader . The gl_Position.y+=command in vertex shader , which graphics driver wrapper  included in vertex shader , may add the provided value by graphics driver wrapper  to the current value of gl_Position.y to determine the y-clipping coordinate of the vertex in the second execution of the object code of modified vertex shader  for the right-eye image.","In some examples, the viewer may select the values of first value and the second value for the modification of gl_Position.x+=command and the gl_Position.y+=command and\/or the values of VPshift and ZDP. This may allow the viewer to fine tune the stereoscopic effect as desired. For example, the viewer may be able to personalize the stereoscopic effect by defining the amount by which vertices are displaced and the location of the zero disparity plane.","In this way, the techniques of this disclosure may provide for a minor modification to vertex shader , which is designed for mono view, such that when the modified vertex shader is compiled and executed (e.g., the execution of the object code of modified vertex shader ), the resulting images may provide the viewer with a stereoscopic view. The stereoscopic view may provide the viewer with a 3D experience, which may be richer, fuller experience, as compared to viewing an image limited by the 2D area of the display.",{"@attributes":{"id":"p-0242","num":"0241"},"figref":"FIG. 6"},"The angled lines extending from the left eye viewpoint and the right eye viewpoint illustrate the area that the left eye and right eye see, respectively. The straight lines extending from the left eye viewpoint and right eye viewpoint illustrate the orientation of the viewer relative to the orientation of display  (i.e., the viewing angle). In this example, the viewing angle is zero.","As illustrated in , the location of the ZDP is in front of display , and within the zand zclipping planes defined by application . The location of the ZDP may be based on two factors. One factor may be the selected value of D. Another factor may be the value of VPshift (i.e., the horizontal disparity value) which indicates the disparity between the left-eye image and the right-eye image. By selecting the value of D and VPshift, the viewer may select the desired location of the ZDP. In these examples, all objects in the image generated by application  may appear within the ZDP (e.g., in front of display , rather than being constrained to within the surface of display ). As described above, it may be possible for application processor  to determine the value of D and VPshift.","Moreover, in some examples, the VPshift may not be necessary, and the viewer or application processor  may determine the location of ZDP. In these examples, graphics driver wrapper  may modify the values stored in the gl_Position.x and gl_Position.y variables based on the location of the ZDP so that some objects appear ahead of the ZDP, some objects appear at the ZDP, and other objects appear behind the ZDP.",{"@attributes":{"id":"p-0246","num":"0245"},"figref":["FIG. 7","FIG. 7","FIG. 7"],"b":["45","45","45","45","22","22"]},{"@attributes":{"id":"p-0247","num":"0246"},"figref":["FIG. 8","FIG. 8","FIG. 8"],"b":["30","30","66","32","34","66","30","22","66","22","32","34","66","22"]},"As one example, as described above, application processor , executing application , may instruct GPU  to execute the object code of modified vertex shader . In this example, command processor  may receive the command from application processor , and may instruct shader processor  to execute the object code of modified vertex shader . As another example, in some examples, as described above, graphics driver wrapper  may modify the glViewport command issued by application , and provide the modified glViewport commands to GPU . In this example, command processor  may receive the modified glViewport commands, and determine that this command is for viewport transformation unit  of fixed-function pipeline . Command processor  may forward the modified glViewport commands to viewport transformation unit  for applying the viewports for the left-eye image and right-eye image.","For example, as described above, application  may issue a glDraw command that graphics driver wrapper  blocks from transmission to GPU . The glDraw command may trigger graphics driver wrapper  into issuing a first instruction to shader processor  to execute the object code of modified vertex shader . In turn, shader processor  executes the object code of modified vertex shader , and stores the resulting clipping coordinates in its local memory or system memory .","The glDraw command also causes graphics driver wrapper  to issue a first glViewport instruction, which is received by command processor . In examples where image level adjustment of the horizontal disparity between the left-eye and right-eye images is not needed, graphics driver wrapper  may not modify the first glViewport command. In examples where image level adjustment of the horizontal disparity between left-eye and right-eye images is needed, graphics driver wrapper  may modify the first glViewport command based on the viewing angle and the value of VPshift.","Then, graphics driver wrapper  issues the first glDraw command which is received by command processor . Command processor , in response, causes the fixed-function units of fixed-function pipeline  and shader processor  to perform their respective functions to generate the graphics content for a first image of the stereoscopic view (e.g., the left-eye image). For example, as discussed in more detail, in response to the first glDraw command, and when image level adjustment of the horizontal disparity is desired, viewport transformation unit  constrains the first image to a first portion of the display, and per-fragment operation unit  outputs the graphics content of the first image to frame buffer .","After the first image of the stereoscopic view is stored in frame buffer , GPU  repeats the steps to generate the graphics content for the second image of the stereoscopic view. For example, graphics driver wrapper  issues a second instruction to shader processor  to execute the object code of modified vertex shader . In turn, shader processor  executes the object code of modified vertex shader , and stores the resulting clipping coordinates in its local memory or system memory . Graphics driver wrapper  also issues a second glViewport instruction, which is received by command processor . Again, the glViewport instruction may be modified if adjustment of disparity at the image level is desired, and may not be modified if adjustment of disparity at the image level is not desired.","Then, graphics driver wrapper  issues the second glDraw command which is received by command processor . Command processor , in response, causes the fixed-function units of fixed-function pipeline  and shader processor  to perform their respective functions to generate the graphics content for a second image of the stereoscopic view (e.g., the right-eye image). For example, in response to the second glDraw command, and when image level adjustment of the horizontal disparity is desired, viewport transformation unit  constrains the second image to a second portion of the display, and per-fragment operation unit  outputs the graphics content of the second image to frame buffer .","As illustrated in dashed boxes in , shader processor  includes modified vertex shader  and fragment shader . The dashed boxes are to indicate that shader processor  may not actually include modified vertex shader  and fragment shader . Rather, shader processor  may execute the object code of modified vertex shader  and fragment shader . The object of modified vertex shader  and fragment shader  may be stored in system memory .","Fixed-function pipeline  may include one or more fixed-function units such as primitive assembly unit , frustum unit , perspective divide unit , viewport transformation unit , rasterization unit , and per-fragment operation unit . Each of these fixed-function units of fixed-function pipeline  may be hardware units that are hardwired to perform specific graphics related functions. Although these fixed-function units of fixed-function pipeline  are illustrated as separate components, aspects of this disclosure are not so limited. One or more of the fixed-function units of fixed-function pipeline  may be combined together into a common fixed-function unit. Also, there may be more fixed-function units of fixed-function pipeline  than those illustrated in . The one or more fixed-function units of fixed-function pipeline  are illustrated separately to ease understanding.","Moreover, the specific ordering of the fixed-function units of fixed-function pipeline  is illustrated for example purposes and should not be considered limiting. For instance, it may be possible to reorder the fixed-function units of fixed-function pipeline . As one example, one of the functions of per-fragment operation unit  may be to cull pixels that are occluded by overlapping pixels. It may be possible for this function to be performed earlier in fixed-function pipeline .","These fixed-function units of fixed-function pipeline  may provide very limited functional flexibility, as compared to shader processor . For example, shader processor  may be specifically designed to execute programmable shader programs such as modified vertex shader  and fragment shader . These shader programs cause shader processor  to function in the manner defined by the shader programs. In other words, shader programs may define the functionality of shader processor , whereas the functionality of the fixed-function units of fixed-function pipeline  is set.","As described above, graphics driver wrapper  may instruct GPU  to execute the object code of modified vertex shader  twice, where the first execution is for the generation of clipping coordinates for vertices of one of the images of stereoscopic view based on the viewing angle (e.g., left-eye image) and the second execution is for the generation of clipping coordinates for vertices of the other image of stereoscopic view (e.g., right-eye image) based on the viewing angle. In response, to each of these instructions to execute the object code of modified vertex shader , command processor  may instruct shader processor  to retrieve the object code of modified vertex shader  and execute the object code of modified vertex shader . As described above, compiler  may compile the source code of the modified vertex shader and store the resulting object code as the object code of modified vertex shader .","As illustrated in , modified vertex shader  may receive vertex array  and textures  as inputs. Vertex arrays  may include information to generate the pixel values for the vertices generated by application  (e.g., the coordinates of the vertices, color values of the vertices, and transparency values of the vertices), as described above. For example, the coordinates of the vertices of vertex array  may be the world coordinates as defined by application . Textures  may be pixel values for textures that overlay over the generated graphics to provide a more realistic view of the graphics content.","Modified vertex shader , executing on shader processor , may generate the clipping coordinates for each of the vertices. For example, modified vertex shader  may convert the world coordinates of the vertices as defined by application  and stored in vertex array  into clipping coordinates for each of the vertices by performing the matrix multiplication of equation 1, as discussed above with respect to . Furthermore, modified vertex shader , executing on shader processor , may update the gl_Position.x and the gl_Position.y variables, based on the viewing angle, for the clipping coordinates of each of the vertices to provide the displacement for the left-eye image, in the first execution of the object code of modified vertex shader , and to provide the displacement for the right-eye image, in the second execution of the object code of modified vertex shader . Also, modified vertex shader  may perform additional, conventional vertex shader tasks. For example, modified vertex shader  may perform lighting functions on the vertices.","After modified vertex shader  performs the model view transformation (e.g., conversion of the world view coordinates to clipping coordinates, including the displacement with the gl_Position.x+=command and the gl_Position.y+=command), modified vertex shader  provides the clipping coordinates for the vertices to primitive assembly unit  of fixed-function pipeline . Primitive assembly unit  may utilize the clipping coordinates for the vertices to assemble the vertices into primitives. For example, primitive assembly unit  may assemble a plurality of triangles based on the clipping coordinates for the vertices, where the vertices of each of the triangles correspond to vertices received from modified vertex shader . The plurality of triangles is one example of primitives. In general, primitive assembly unit  may assemble the received vertices into any polygon based on the clipping coordinates for the received vertices.","Primitive assembly unit  may transmit the assembled primitives to frustum unit . Frustum unit  may determine whether the assembled primitives are within a view volume. For example, as described above, OpenGL, OpenGL ES, and OpenGL ES 2.0 may define a particular view volume as (fov). However, the frustum may be user definable using, for example, the glFrustum function. Frustum unit  may determine whether a primitive is fully within the view volume, fully external to the view volume, or partially within the view volume and partially external to the view volume. Frustum unit  may cull, from further processing, primitives that are fully external to the view volume and portions of primitives are that external to the view volume. Frustum unit  may keep, for further processing, primitives that are fully within the view volume and portions of primitives that are within the view volume.","Frustum unit  may transmit the remaining primitives and portions of primitives to perspective divide unit . Perspective divide unit  may expand or shrink primitives based on their depth. For example, each of the primitives may be defined by x, y, and z coordinates. The z coordinate may indicate how close or away the primitive is. It should be noted that at this stage, GPU  is generating graphics content for one of the images for the stereoscopic view. Therefore, the concept of proximity of a primitive is in the context of a mono view, not a stereoscopic view.","For instance, perspective divide unit  may shrink some primitives, and expand other primitives. This may create a perception that the shrunk primitives are further away compared to the expanded primitives in a mono view. As described above, it is when these mono view images are displayed that the viewer perceives stereoscopic view. In other words, perspective divide unit  may cause the left-eye image and the right-eye image to be 3D images that are displayed in the 2D area of the display. When the viewer views these 3D images, the displacement caused by the addition of the gl_Position.x+=command and the gl_Position.y+=command, in the left-eye image and the right-eye image, causes the viewer to perceive the stereoscopic 3D (S3D) image that encompasses a 3D volume.","Perspective divide unit  may transmit the primitives to viewport transformation unit . Viewport transformation unit  modifies the size and location of the image to fit the defined viewport. For example, prior to viewport transformation unit , modified vertex shader  and the fixed-function units of fixed-function pipeline  process graphics data as if the image is to be displayed on the entirety of the display. The function of viewport transformation unit  may be to modify the size and location of the image so that the image is constrained to the defined viewport.","It should be understood that in examples where vertex level adjustment of the disparity between vertices in the left-eye image and the right-eye image is desired, viewport transformation unit  may define the viewport of the left-eye image to be the same as the viewport of the single image defined by application . Similarly, in this example, viewport transformation unit  may define the viewport of the right-eye image to be the same as the viewport of the single image defined by application . In examples where vertex level adjustment of the disparity between vertices in the left-eye image and right-eye image is not desired, viewport transformation unit  may constrain the left-eye image to one portion as defined by the modified glViewport command, and constrain the right-eye image to another portion as defined by the modified glViewport command.","For instance, as described above, after the first execution of the object code of vertex shader , which may generate graphics content for the left-eye image (e.g., clipping coordinates for vertices), graphics driver wrapper  may modify the viewport of the left-eye image to constrain the left-eye image to one portion of display  (e.g., left half of display ). For example, after the first execution of the object code of vertex shader , graphics driver wrapper  may modify the glViewport (0, 0, width, length) command, which was previously issued by application  and blocked from GPU , to glViewport (\u2212VPshift*cos(\u03b1), \u2212VPshift*sin(\u03b1), width\u2212Vpshift*cos(\u03b1), height\u2212Vpshift*sin(\u03b1)), and provide this first modified glViewport command to GPU . Command processor  may provide the first modified glViewport command to viewport transformation unit . Viewport transformation unit  may then modify the sizes of the primitives received from perspective divide unit  so that these primitives are constrained to one half of the display, in this example.","After the second execution of the object code of vertex shader , viewport transformation unit  may perform similar functions, but for the right-eye image. For example, the second execution of the object code of vertex shader  may be for the generation of graphics content for the right-eye image (e.g., clipping coordinates for vertices). After this second execution of the object code of vertex shader , graphics driver wrapper  may modify the glViewport (0, 0, width, length) command, which was previously issued by application  and blocked from GPU , to glViewport (VPshift*cos(\u03b1), VPshift*sin(\u03b1), width+VPshift*cos(\u03b1), height+VPshift*sin(\u03b1)), and provide this second modified glViewport command to GPU . Command processor  may forward the second modified glViewport command to viewport transformation unit . In this way, GPU  may be operable to generate left-eye and right-eye images for the stereoscopic view from a mono view image generated by application  during run-time of application , and without relying on depth information to generate the right-eye image from the left-eye image, and vice versa.","Viewport transformation unit  may forward the primitives to rasterization unit  after modifying the viewport after each of the first modified glViewport command and the second modified glViewport command. Rasterization unit  may convert the primitives into pixels of the display. For example, rasterization unit  may determine which pixels of the display are encompassed by each of the primitives. Rasterization unit  may also determine the location of each of these pixels on the displays.","Rasterization unit  may output its graphics data to fragment shader . Fragment shader , sometimes referred to as a pixel shader, may be a shader program that executes on shader processor . For example, the source code for fragment shader  may be stored in system memory , and compiler  may compile the source code of fragment shader  to generate the object code of fragment shader . Alternatively, system memory  may store the object code for fragment shader  without it necessarily being generated by compiler .","Fragment shader  may output the color values for each of the pixels on the display. For example, fragment shader  may define the color of each pixel based on a red-green-blue (RGB) component. Fragment shader  may utilize 8-bits to define the red component, 8-bits to define the green component, and 8-bits to define the blue component, as one illustrative example. Fragment shader  may output the color values to per-fragment operation unit .","Per-fragment operation unit  may cull pixels that are not viewable. For example, a pixel of a further away object may be overlapped by a pixel of a closer object, which per-fragment operation unit  may determine from a z-buffer. The overlapping may cause the pixel of the further away object to be fully occluded. In this case, per-fragment operation unit  may cull the overlapped pixel. Per-fragment operation unit  may also blend pixels together. For example, an overlapping pixel may be translucent so that it does not fully occlude the overlapped pixel. In this case, per-fragment operation unit  may blend the color of these pixels together.","The output of per-fragment operation unit  may be pixel values (e.g., color) for the pixels on the display. Per-fragment operation unit  may output the pixel values to frame buffer , of system memory , for temporary storage. Frame buffer  may store the pixel values for each of the pixels on the display.","Frame buffer  may be considered as a 2D array of storage locations. The number of storage locations with frame buffer  may be twice the number of pixels of display . Also, two storage locations within frame buffer  may correspond to one location on the display. For example, frame buffer  may include two halves, where each half includes storage locations for the entirety of display . In this example, the top-left storage location within the first half and the top-left storage location within the second half within frame buffer  may correspond to the top-left pixel of the display, the storage location to the right of the top-left storage location within the first half and the storage location to the right of the top-left storage location within the second half within frame buffer  may correspond to the pixel to the right of the top-left pixel of the display, and so forth.","After the completion of the first glDraw command, the storage locations located in the first half frame buffer  may store the pixel values for the left-eye image. Similarly, after the completion of the second glDraw command, the storage locations located in the second half of frame buffer  may store the pixel values for the right-eye image. Therefore, after completion of the first and second glDraw commands, frame buffer  may store the pixel values for the left-eye image and the pixel values for the right-eye image.",{"@attributes":{"id":"p-0276","num":"0275"},"figref":["FIG. 9","FIG. 9","FIG. 9","FIG. 8","FIG. 9"]},{"@attributes":{"id":"p-0277","num":"0276"},"figref":["FIG. 9","FIG. 7"],"b":["24","24","46","40","60","58","40","46","60","48","56","58","62","64"]},{"@attributes":{"id":"p-0278","num":"0277"},"figref":["FIGS. 10A-10C","FIGS. 10A-10C","FIGS. 10A-10C","FIG. 10A","FIG. 10B","FIG. 10C","FIGS. 10A-10C"],"b":["42","12","12","12","68","68","70","70","72","72"]},{"@attributes":{"id":"p-0279","num":"0278"},"figref":["FIG. 10A","FIG. 10B","FIG. 10A","FIG. 10B","FIG. 9C"],"b":["10","10","70","70","72","72"]},{"@attributes":{"id":"p-0280","num":"0279"},"figref":["FIG. 11","FIG. 5","FIG. 11","FIG. 5"],"b":["10","10"]},"As illustrated in , device  may include display , application processor , GPU , system memory , which includes frame buffer , camera processor , transceiver module , user interface , display processor , and camera . Display , application processor , GPU , system memory , one or more sensors , and camera processor  may be substantially similar or identical to those illustrated in . For purposes of brevity, only the components that are shown in , but not shown in  are described in detail.","Device , as illustrated in , may include additional modules or units not shown in  for purposes of clarity. For example, device  may include a speaker and a microphone, neither of which are shown in , to effectuate telephonic communications in examples where device  is a mobile wireless telephone or a speaker where device  is a media player. Furthermore, the various modules and units shown in device  may not be necessary in every example of device . For example, user interface  and display  may be external to device  in examples where device  is a desktop computer or other device that is equipped to interface with an external user interface or display.","Camera  may be a front-facing optical camera configured to capture video or images. Camera  may output its captured video or images to camera processor . Camera processor  may determine viewer orientation based on the captured video or images as described above.","Examples of user interface  include, but are not limited to, a trackball, a mouse, a keyboard, and other types of input devices. User interface  may also be a touch screen and may be incorporated as a part of display . Transceiver module  may include circuitry to allow wireless or wired communication between device  and another device or a network. Transceiver module  may include one or more modulators, demodulators, amplifiers, antennas and other such circuitry for wired or wireless communication.","Display processor  may be configured to cause display  to display stereoscopic view. There may be various techniques that display processor  may utilize to cause display  to display stereoscopic view, and aspects of this disclosure may utilize any of these techniques. For example, display processor  may retrieve the left-eye image from one half of frame buffer , retrieve the right-eye image from the other half of frame buffer , and interleave the two images together to provide the stereoscopic view.","As another example, display processor  may control the refresh rate of display . In this example, during each refresh cycle, display processor  may cycle between the left-eye image and the right-eye image. For instance, display processor  may retrieve the left-eye image from one half of frame buffer , expand the left-eye image to the entirety of display , and display left-eye image on display  for one refresh cycle. Then, for the next refresh cycle, display processor  may perform substantially similar functions, but for the right-eye image stored in the other half of frame buffer . In other words, display  may display the left-eye image, then the right-eye image, then the left-eye image, and so forth.","The viewer may be wearing specialized glasses that are synchronized with the refresh rate of display processor . For example, while display  is displaying the left-eye image, the specialized glasses may shutter close the right lens so that only the left eye of the viewer captures the left-eye image. Then, while display  is displaying the right-eye image, the specialized glasses may shutter close the left lens so that only the right eye of the viewer captures the right-eye image, and so forth. If the refresh rate is fast enough, the viewer perceives stereoscopic view where the image pops out of or pushes into display  and encompasses a 3D volume.","In some examples, some conventional display processors may not configured to cause display  to display stereoscopic view. In these examples, the viewer may couple device  to a display that includes a display processor, such as display processor , which is configured to cause display  to present the stereoscopic view. For example, the viewer may couple device  to a stereoscopic view enabled television via transceiver module . For instance, the viewer may couple transceiver module  to the television via a high-definition multimedia interface (HDMI) wire. In this example, application processor  or GPU  may instruct transceiver module  to transmit the pixel values stored in frame buffer  to the display processor of the television. The display processor of this television may then cause the television to display the left-eye and right-eye images to form the stereoscopic view.",{"@attributes":{"id":"p-0289","num":"0288"},"figref":["FIG. 12","FIG. 3"]},"Processor  may execute application  to generate an image for mono view (). Processor  may implement the other blocks of  during the run-time of application . For example, processor  may determine a viewing angle relative to display . In some examples, processor  may determine the viewing angle relative to the display  once per generation of the stereoscopic view. To determine the viewing angle, processor  may determine at least one the viewer orientation such as by camera processor  and display orientation such as by one or more sensors .","Processor , via graphics driver wrapper , may receive instructions for vertex shader  (). Vertex shader  may be configured to operate on the image of the mono view generated by the execution of application .","Processor , via graphics driver wrapper , may modify the instructions of vertex shader to include one or more instructions based on the viewing angle to generate a modified vertex shader (e.g., modified vertex shader  after compiler  compiles vertex shader  after the inclusion of the instructions) (86). In this example, modified vertex shader , when executed on shader processor  of GPU , may generate vertex coordinates for vertices of a stereoscopic view.","For example, processor , via graphics driver wrapper , may add a first instruction in vertex shader  that modifies a first clipping coordinate (e.g., the x) of a vertex of the image of the mono view generated by application  based on the viewing angle. For instance, graphics driver wrapper  may add the gl_Position.x+=X command, where X equals D*cos(\u03b1) in a first execution of modified vertex shader  and equals \u2212D*cos(\u03b1) in a second execution of modified vertex shader . Processor , via graphics driver wrapper , may add a second instruction in vertex shader  that modifies a second clipping coordinate (e.g., the y) of the vertex of the image of the mono view generated by application  based on the viewing angle. For instance, graphics driver wrapper  may add the gl_Position.y+=Y*width\/height, where width and height are the width and height of display , and Y equals D*sin(\u03b1) in the first execution of modified vertex shader  and equals \u2212D*sin(\u03b1) in the second execution of modified vertex shader .","In some examples, as an option, the first and second instructions that graphics driver wrapper  adds may also be based on the location of the zero disparity plane. For example, graphics driver wrapper  may add the gl_Position.x+=X*(1\u2212gl_Position.w\/ZDP), and may add the gl_Position.y+=Y*width\/height*(1\u2212gl_Position.w\/ZDP). The gl_Position.w variable stores the wcoordinate, which is equal to \u2212z, where zis the z-coordinate of the vertex as defined by application . The ZDPindicates the location of the zero disparity plane relative to display .","As an option, processor , via graphics driver wrapper , may modify the viewport command (e.g., glViewport) issued by application  (). This modification of the viewport command may be optional and is therefore illustrated in dashes. Processor , via graphics driver wrapper , may modify the glViewport command to adjust the horizontal disparity between the first and second images of the stereoscopic view (e.g., the horizontal disparity between the left-eye image and the right-eye image). By adjusting the horizontal disparity, graphics driver wrapper  may utilize the modified glViewport command to adjust the location of the zero disparity plane.","Processor , via graphics driver wrapper , may instruct GPU  to execute modified vertex shader  (). For example, processor , via graphics driver wrapper , may instruct GPU  to execute a first instance of the object code of modified vertex shader  on shader processor  to generate a first image (e.g., left-eye image) of the stereoscopic view based on the viewing angle. Processor , via graphics driver wrapper , may instruct GPU  to execute a second instance of the object code of modified vertex shader  on shader processor  to generate a second image (e.g., the right-eye image) of the stereoscopic view based on the viewing angle.","The following pseudo-code provides an example of the functionality of graphics driver wrapper  and application . This pseudo-code is meant to assist with understanding and should not be considered limiting.\n\n","In one or more examples, the functions described may be implemented in hardware, software, firmware, or any combination thereof. If implemented in software, the functions may be stored as one or more instructions or code on a computer-readable medium. Computer-readable media may include computer data storage media. Data storage media may be any available media that can be accessed by one or more computers or one or more processors to retrieve instructions, code and\/or data structures for implementation of the techniques described in this disclosure. By way of example, and not limitation, such computer-readable media can comprise random access memory (RAM), read-only memory (ROM), EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices, or any other medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a computer. Disk and disc, as used herein, includes compact disc (CD), laser disc, optical disc, digital versatile disc (DVD), floppy disk and Blu-ray disc where disks usually reproduce data magnetically, while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer-readable media.","The code may be executed by one or more processors, such as one or more digital signal processors (DSPs), general purpose microprocessors, application specific integrated circuits (ASICs), field programmable logic arrays (FPGAs), or other equivalent integrated or discrete logic circuitry. Accordingly, the term \u201cprocessor,\u201d as used herein may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described herein. Also, the techniques could be fully implemented in one or more circuits or logic elements.","The techniques of this disclosure may be implemented in a wide variety of devices or apparatuses, including a wireless handset, an integrated circuit (IC) or a set of ICs (i.e., a chip set). Various components, modules or units are described in this disclosure to emphasize functional aspects of devices configured to perform the disclosed techniques, but do not necessarily require realization by different hardware units. Rather, as described above, various units may be combined in a hardware unit or provided by a collection of interoperative hardware units, including one or more processors as described above, in conjunction with suitable software and\/or firmware.","Various examples have been described. These and other examples are within the scope of the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF DRAWINGS","p":[{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 10A-10C"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 11","FIG. 5"]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
