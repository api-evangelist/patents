---
title: High performance object cache
abstract: The foregoing needs and other needs are addressed by the present invention, which provides, in one aspect, a mechanism for locating a data object. According to an aspect of the present invention, key values for data objects are generated, each key value may contain a first subkey value and a second subkey value. A mapping associates the first subkey values with storage locations. A particular first subkey value is mapped to storage location that contains second subkeys of a set of key values that correspond to the first subkey value. The storage location also includes additional information that may be used to locate objects associated with the set of key values.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06915307&OS=06915307&RS=06915307
owner: Inktomi Corporation
number: 06915307
owner_city: Foster City
owner_country: US
publication_date: 20020506
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT","Traffic Server","Object Cache Indexing","Content Indexing","Name Indexing","Searching by Object or Name Key","Multi-level Directory Table","Directory Paging","Vector of Alternates","Read Ahead","The Open Directory","Disk Data Layout and Aggregation","Multi-fragment Objects","Space Allocation","Garbage Collection","Scaled Counter Updating","Cache Operations","Implementation of Methods","Hardware Overview"],"p":["This application is a continuation of U.S. application Ser. No. 09\/543,238, entitled \u201cMaintaining Counters for High Performance Object Cache\u201d, filed on Apr. 5, 2000, now U.S. Pat. No. 6,453,319 by Peter Mattis, John Plevyak, Matthew Haines, Adam Beguelin, Brian Totty, and David Gourley, which is divisional and claims priority of U.S. application Ser. No. 09\/060,866, entitled \u201cHigh Performance Object Cache\u201d, filed on Apr. 15, 1998, now U.S. Pat. No. 6,128,623 by Peter Mattis, John Plevyak, Matthew Haines, Adam Beguelin, Brian Totty, and David Gourley.","The present invention relates to information delivery, and relates more specifically to a cache for information objects that are to be delivered efficiently and at high speed over a network to a client","Several important computer technologies rely, to a great extent, upon rapid delivery of information from a central storage location to remote devices. For example, in the client\/server model of computing, one or more servers are used to store information. Client computers or processes are separated from the servers and are connected to the servers using a network. The clients request information from one of the servers by providing a network address of the information. The server locates the information based on the provided network address and transmits it over the network to the client, completing the transaction.","The World Wide Web is a popular application of the client\/server computing model.  is a simplified block diagram of the relationship between elements used in a Web system. One or more web clients , , each of which is a computer or a software process such as a browser program, are connected to a global information network  called the Internet, either directly or through an intermediary such as an Internet Service Provider, or an online information service.","A web server  is likewise connected to the Internet  by a network link . The web server  has one or more internet network addresses and textual host names, associated in an agreed-upon format that is indexed at a central Domain Name Server (DNS). The server contains multimedia information resources, such as documents and images, to be provided to clients upon demand. The server  may additionally or alternatively contain software for dynamically generating such resources in response to requests.","The clients , and server  communicate using one or more agreed-upon protocols that specify the format of the information that is communicated. A client looks up network address of a particular server using DNS and establishes a connection to the server using a communication protocol called the Hypertext Transfer Protocol (HTTP). A Uniform Resource Locator (URL) uniquely identifies each information object stored on or dynamically generated by the server . A URL is a form of network address that identifies the location of information stored in a network.","A key factor that limits the performance of the World Wide Web is the speed with which the server  can supply information to a client via the Internet . Performance is limited by the speed, reliability, and congestion level of the network route through the Internet, by geographical distance delays, and by server load level. Accordingly, client transaction time can be reduced by storing replicas of popular information objects in repositories geographically dispersed from the server. Each local repository for object replicas is generally referred to as a cache. A client may be able to access replicas from a topologically proximate cache faster than possible from the original web server, while at the same time reducing Internet server traffic.","In one arrangement, as shown in , the cache is located in a proxy server  that is logically interposed between the clients , and the server . The proxy server provides a \u201cmiddleman\u201d gateway service, acting as a server to the client, and a client to the server. A proxy server equipped with a cache is called a caching proxy server, or commonly, a \u201cproxy cache\u201d.","The proxy cache  intercepts requests for resources that are directed from the clients , to the server . When the cache in the proxy  has a replica of the requested resource that meets certain freshness constraints, the proxy responds to the clients , and serves the resource directly. In this arrangement, the number and volume of data transfers along the link  are greatly reduced. As a result, network resources or objects are provided more rapidly to the clients , ","A key problem in such caching is the efficient storage, location, and retrieval of objects in the cache. This document concerns technology related to the storage, location, and retrieval of multimedia objects within a cache. The object storage facility within a cache is called a \u201ccache object store\u201d or \u201cobject store\u201d.","To effectively handle heavy traffic environments, such as the World Wide Web, a cache object store needs to be able to handle tens or hundreds of millions of different objects, while storing, deleting, and fetching the objects simultaneously. Accordingly, cache performance must not degrade significantly with object count. Performance is the driving goal of cache object stores.","Finding an object in the cache is the most common operation and therefore the cache must be extremely fast in carrying out searches. The key factor that limits cache performance is lookup time. It is desirable to have a cache that can determine whether an object is in the cache (a \u201chit\u201d) or not (a \u201cmiss\u201d) as fast as possible. In past approaches, caches capable of storing millions of objects have been stored in traditional file system storage structures. Traditional file systems are poorly suited for multimedia object caches because they are tuned for particular object sizes and require multiple disk head movements to examine file system metadata. Object stores can obtain higher lookup performance by dedicating DRAM memory to the task of object lookup, but because there are tens or hundreds of millions of objects, the memory lookup tables must be very compact.","Once an object is located, it must be transferred to the client efficiently. Modern disk drives offer high performance when reading and writing sequential data, but suffer significant performance delays when incurring disk head movements to other parts of the disk. These disk head movements are called \u201cseeks\u201d. Disk performance is typically constrained by the drive's rated seeks per second. To optimize performance of a cache, it is desirable to minimize disk seeks, by reading and writing contiguous blocks of data.","Eventually, the object store will become full, and particular objects must be expunged to make room for new content. This process is called \u201cgarbage collection\u201d. Garbage collection must be efficient enough that it can run continually without providing a significant decrease in system performance, while removing objects that have the least impact on future cache performance.","Past Approaches","In the past, four approaches have been used to structure cache object stores: using the native file system, using a memory-blocked \u201cpage\u201d cache, using a database, and using a \u201ccyclone\u201d circular storage structure. Each of these prior approaches has significant disadvantages.","The native file system approach uses the file system of an operating system running on the server to create and manage a cache. File systems are designed for a particular application in mind: storing and retrieving user and system data files. File systems are designed and optimized for file management applications. They are optimized for typical data file sizes and for a relatively small number of files (both total and within one folder\/directory). Traditional file systems are not optimized to minimize the number of seeks to open, read\/write, and close files. Many file systems incur significant performance penalties to locate and open files when there are large numbers of files present. Typical file systems suffer fragmentation, with small disk blocks scattered around the drive surface, increasing the number of disk seeks required to access data, and wasting storage space. Also, file systems, being designed for user data file management, include facilities irrelevant to cache object stores, and indeed counter-productive to this application. Examples include: support for random access and selective modification, file permissions, support for moving files, support for renaming files, and support for appending to files over time. File systems are also invest significant energy to minimize any data loss, at the expense of performance, both at write time, and to reconstruct the file system after failure. The result is that file systems are relatively poorly for handling the millions of files that can be present in a cache of Web objects. File systems don't efficiently support the large variation in Internet multimedia object size\u2014in particular they typically do not support very small objects or very large objects efficiently. File systems require a large number of disk seeks for metadata traversal and block chaining, poorly support garbage collection, and take time to ensure data integrity and to repair file systems on restart.","The page cache extends file systems with a set of fixed sized memory buffers. Data is staged in and out of these buffers before transmission across the network. This approach wastes significant memory for large objects being sent across slow connections.","The database system approach uses a database system as a cache. Generally, databases are structured to achieve goals that make them inappropriate for use as an object cache. For example, they are structured to optimize transaction processing. To preserve the integrity of each transaction, they use extensive locking. As a result, as a design goal they favor data integrity over performance factors such as speed. In contrast, it is acceptable for an object cache to lose data occasionally, provided that the cache does not corrupt objects, because the data always can be retrieved from the server that is original source of the data. Databases are often optimized for fast write performance, since write speed limits transaction processing speed. However, in an object cache, read speed is equally important. Further, databases are not naturally good at storing a vast variety of object sizes while supporting streaming, pipelined I\/O in a virtual memory efficient manner. Databases commonly optimized for fixed record size sizes. Where databases support variable record sizes, they contain support for maintaining object relationships that are redundant, and typically employ slow, virtual memory paging techniques to support streaming, pipelined I\/O.","In a cyclonic file system, data is allocated around a circular storage structure. When space becomes full, the oldest data is simply removed. This approach allows for fast allocation of data, but makes it difficult to support large objects without first staging them in memory, suffers problems with fragmentation of data, and typically entails naive garbage collection that throws out the oldest object, regardless of its popularity. For a modest, active cache with a diverse working set, such first-in-first-out garbage collection can throw objects out before they get to be reused.","The fundamental problem with the above approaches for the design of cache object stores is that the solution isn't optimized for the constraints of the problem. These approaches all represent reapplication of existing technologies to a new application. None of the applications above are ideally suited for the unique constraints of multimedia, streaming, object caches. Not only do the above solutions inherently encumber object caches with inefficiencies due to their imperfect reapplication, but they also are unable to effectively support the more unique requirements of multimedia object caches. These unique requirements include the ability to disambiguate and share redundant content that is identical, but has different names, and the opposite ability to store multiple variants of content with the same name, targeted for particular clients, languages, data types, etc.","Based on the foregoing, there is a clear need to provide an object cache that overcomes the disadvantages of these prior approaches, and is more ideally suited for the unique requirements of multimedia object caches. In particular:\n\n","This document concerns technology directed to accomplishing the foregoing goals. In particular, this document describes methods and structures related to the time-efficient and space-efficient storage, retrieval, and maintenance of objects in a large object store. The technology described herein provides for a cache object store for a high-performance, high-load application having the following general characteristics:\n\n","The foregoing needs and other needs are addressed by the present invention, which provides, in one aspect, a mechanism for locating a data object. According to an aspect of the present invention, key values for data objects are generated, each key value may contain a first subkey value and a second subkey value. A mapping associates the first subkey values with storage locations. A particular first subkey value is mapped to storage location that contains second subkeys of a set of key values that correspond to the first subkey value. The storage location also includes additional information that may be used to locate objects associated with the set of key values.","The invention also encompasses an apparatus, computer system, computer program product, and a computer data signal embodied in a carrier wave configured according to the foregoing aspects, and other aspects.","A method and apparatus for caching information objects is described. In the following description, for the purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the present invention. It will be apparent, however, to one skilled in the art that the present invention may be practiced without these specific details. In other instances, well-known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention.",{"@attributes":{"id":"p-0055","num":"0074"},"figref":"FIG. 2","b":["30","30","10","50","30","20","20","10","30"],"i":["a ","a "]},"The incoming request  arrives at an input\/output (I\/O) core  of the proxy . The I\/O core  functions to adjust the rate of data received or delivered by the proxy to match the data transmission speed of the link between the client and the Internet . In a preferred embodiment, the I\/O core  is implemented in the form of a circularly arranged set of buckets that are disposed between input buffers and output buffers that are coupled to the proxy  and the Internet . Connections among the proxy  and one or more clients are stored in the buckets. Each bucket in the set is successively examined, and each connection in the bucket is polled. During polling, the amount of information that has accumulated in a buffer associated with the connection since the last poll is determined. Based on the amount, a period value associated with the connection is adjusted. The connection is then stored in a different bucket that is generally identified by the sum of the current bucket number and the period value. Polling continues with the next connection and the next bucket. In this way, the elapsed time between successive polls of a connection automatically adjusts to the actual operating bandwidth or data communication speed of the connection.","The I\/O core  passes the request  to a protocol engine  that is coupled to the I\/O core  and to a cache . The protocol engine  functions to parse the request  and determine what type of substantive action is embodied in the request . Based on information in the request , the protocol engine  provides a command to the cache  to carry out a particular operation. In an embodiment, the cache  is implemented in one or more computer programs that are accessible to the protocol engine  using an application programming interface (API). In this embodiment, the protocol engine decodes the request  and performs a function call to the API of the cache . The function call includes, as parameter values, information derived from the request .","The cache  is coupled to send and receive information to and from the protocol engine  and to interact with one or more non-volatile mass storage devices -. In an embodiment, the storage devices -are high-capacity, fast disk drives. The cache  also interacts with data tables  that are described in more detail herein.","In the preferred embodiment, the cache  stores objects on the storage devices -. Popular objects are also replicated into a cache. In the preferred embodiment, the cache has finite size, and is stored in main memory or RAM of the proxy .","Objects on disk are indexed by fixed sized locators, called keys. Keys are used to index into directories that point to the location of objects on disk, and to metadata about the objects. There are two types of keys, called \u201cname keys\u201d and \u201cobject keys\u201d. Name keys are used to index metadata about a named object, and object keys are used to index true object content. Name keys are used to convert URLs and other information resource names into a metadata structure that contains object keys for the object data. As will be discussed subsequently, this two-level indexing structure facilitates the ability to associate multiple alternate objects with a single name, while at the same time maintaining a single copy of any object content on disk, shared between multiple different names or alternates.","Unlike other cache systems that use the name or URL of an object as the key by which the object is referenced, embodiments of the invention use a \u201cfingerprint\u201d of the content that makes up the object itself, to locate the object. Keys generated from the content of the indexed object are referred to herein as object keys. Specifically, the object key  is a unique fingerprint or compressed representation of the contents of the object . Preferably, a copy of the object  is provided as input to a hash function , and its output is the object key . For example, a file or other representation of the object  is provided as input to the hash function, which reads each byte of the file and generates a portion of the object key , until the entire file has been read. In this way, an object key  is generated based upon the entire contents of the object  rather than its name. Since the keys are content-based, and serve as indexes into tables of the cache , the cache is referred to as a content-indexed cache. Given a content fingerprint key, the content can easily be found.","In this embodiment, content indexing enables the cache  to detect duplicate objects that have different names but the same content. Such duplicates will be detected because objects having identical content will hash to the same key value even if the objects have different names.","For example, assume that the server  is storing, in one subdirectory, a software program comprising an executable file that is 10 megabytes in size, named \u201cIE4.exe\u201d. Assume further that the server  is storing, in a different subdirectory, a copy of the same file, named \u201cInternet Explorer.exe\u201d. The server  is an anonymous FTP server that can deliver copies of the files over an HTTP connection using the FTP protocol. In past approaches, when one or more clients request the two files, the cache stores a copy of each of the files in cache storage, and indexes each of the files under its name in the cache. As a result, the cache must use 20 megabytes of storage for two objects that are identical except for the name.","In embodiments of the invention, as discussed in more detail herein, for each of the objects, the cache creates a name key and an object key. The name keys are created by applying a hash function to the name of the object. The object keys are created by applying a hash function to the content of the object. As a result, for the two exemplary objects described above, two different name keys are created, but the object key is the same. When the first object is stored in the cache, its name key and object key are stored in the cache. When the second object is stored in the cache thereafter, its name key is stored in the cache. However, the cache detects the prior identical object key entry, and does not store a duplicate object key entry; instead, the cache stores a reference to the same object key entry in association with the name key, and deletes the new, redundant object. As a result, only 10 megabytes of object storage is required. Thus, the cache detects duplicate objects that have different names, and stores only one permanent copy of each such object.",{"@attributes":{"id":"p-0065","num":"0084"},"figref":"FIG. 3A","b":["56","52","10","52","80","56"],"i":"a "},"Directories are the data structures that map keys to locations on disk. It is advisable to keep all or most of the contents of the directories in memory to provide for fast lookups. This requires directory entries to be small, permitting a large number of entries in a feasible amount of memory. Further, because 50% of the accesses are expected not to be stored in cache, we want to determine cache misses quickly, without expending precious disk seeks. Such fast miss optimizations dedicate scarce disk head movements to real data transfers, not unsuccessful speculative lookups. Finally, to make lookups fast via hashing search techniques, directory entries are fixed size.","Keys are carefully structured to be fixed size and small, for the reasons described earlier. Furthermore, keys are partitioned into subkeys for the purposes of storage efficiency and fast lookups. Misses can be identified quickly by detecting differences in just a small portion of keys. For this reason, instead of searching a full directory table containing complete keys, misses are filtered quickly using a table of small subkeys called a \u201ctag table\u201d. Furthermore, statistical properties of large bit vectors can be exploited to create space-efficient keys that support large numbers of cache objects with small space requirements.","According to one embodiment, the object key  comprises a set subkey  and a tag subkey . The set subkey  and tag subkey  comprise a subset of the bits that make up the complete object key . For example, when the complete object key  is 128 bits in length, the subkeys ,  can be 16 bits, 27 bits, or any other portion of the complete key. The subkeys ,  are used in certain operations, which are described below, in which the subkeys yield results that are nearly as accurate as when the complete key is used. In this context, \u201caccurate\u201d means that use of the subkeys causes a hit in the cache to the correct object as often as when the complete key is used.","This accuracy property is known as \u201csmoothness\u201d and is a characteristic of a certain preferred subset of hash functions. An example of a hash function suitable for use in an embodiment is the MD5 hash function, which is described in detail in B. Schneier, \u201cApplied Cryptography\u201d (New York: John Wiley & Sons, Inc., 2d ed. 1996), at pp. 429-431 and pp.436-441. The MD5 hash function generates a 128-bit key from an input data stream having an arbitrary length. Generally the MD5 hash function and other one-way hash functions are used in the cryptography field to generate secure keys for messages or documents that are to be transmitted over secure channels. General hashing table construction and search techniques are described in detail in D. Knuth, \u201cThe Art of Computer Programming: Vol. 3, Sorting and Searching,\u201d at 506-549 (Reading, Mass.: Addison-Wesley, 1973).","Unfortunately, requests for objects typically do not identify requested objects using the object keys for the objects. Rather, requests typically identify requested objects by name. The format of the name may vary from implementation to implementation based on the environment in which the cache is used. For example, the object name may be a file system name, a network address, or a URL.","According to one aspect of the invention, the object key for a requested object is indexed under a \u201cname key\u201d that is generated based on the object name. Thus, retrieval of an object in response to a request is a two phase process, where a name key is used to locate the object key, and the object key is used to locate the object itself.",{"@attributes":{"id":"p-0072","num":"0091"},"figref":"FIG. 3B","b":["62","53","54"]},"Similar to object key , the name key  comprises set and tag subkeys , . The subkeys ,  comprise a subset of the bits that make up the complete name key . For example, when the complete name key  is 128 bits in length, the first and second subkeys ,  can be 16 bits, 27 bits, or any other portion of the complete key.","Preferably, the cache  comprises certain data structures that are stored in the memory of a computer system or in its non-volatile storage devices, such as disks.  is a block diagram of the general structure of the cache . The cache  generally comprises a Tag Table , a Directory Table , an Open Directory table , and a set of pools through , coupled together using logical references as described further below.","The Tag Table  and the Directory Table  are organized as set associative hash tables. The Tag Table , the Directory Table , and the Open Directory table  correspond to the tables  shown in FIG. . For the purposes of explanation, it shall be assumed that an index search is being performed based on object key . However, the Tag Table  and Directory Table  operate in the same fashion when traversed based on a name key .","The Tag Table  is a set-associative array of sets , , through . The tag table is designed to be small enough to fit in main memory. Its purpose is to quickly detect misses, whereby using only a small subset of the bits in the key a determination can be made that the key is not stored in the cache. The designation is used to indicate that no particular number of sets is required in the Tag Table . As shown in the case of set , each of the sets -comprises a plurality of blocks .","In the preferred embodiment, the object key  is 128 bits in length. The set subkey  is used to identify and select one of the sets -. Preferably, the set subkey  is approximately 18 bits in length. The tag subkey  is used to reference one of the entries  within a selected set. Preferably, the tag subkey  is approximately 16 bits in length, but may be as small as zero bits in cases in which there are many sets. In such cases, the tag table would be a bit vector.","The mechanism used to identify or refer to an element may vary from implementation to implementation, and may include associative references, pointers, or a combination thereof. In this context, the term \u201creference\u201d indicates that one element identifies or refers to another element. A remainder subkey \u2032 consists of the remaining bits of the key . The set subkey, tag subkey, and remainder subkey are sometimes abbreviated s, t, and r, respectively.","The preferred structure of the Tag Table , in which each entry contains a relatively small amount of information enables the Tag Table to be stored in fast, volatile main memory such as RAM. Thus, the structure of the Tag Table  facilitates rapid operation of the cache. The blocks in the Directory Table , on the other hand, include much more information as described below, and consequently, portions of the Directory Table may reside on magnetic disk media as opposed to fast DRAM memory at any given time.","The Directory Table  comprises a plurality of sets -. Each of the sets -has a fixed size, and each comprises a plurality of blocks -. In the preferred embodiment, there is a predetermined, constant number of sets and a predetermined, constant number of blocks in each set. As shown in the case of block , each of the blocks -stores a third, remainder subkey value , a disk location value , and a size value . In the preferred embodiment, the remainder subkey value  is a 27-bit portion of the 128-bit complete object key , and the comprises bits of the complete object key  that are disjoint from the bits that comprise the set or tag subkeys , .","In a search, the subkey values stored in the entry  of the Tag Table  matches or references one of the sets -, as indicated by the arrow in  that connects the entry  to the set . As an example, consider the 12-bit key and four-bit first and second subkeys described above. Assume that the set subkey value 1111 matches set of the Tag Table , and the tag subkey value 0000 matches entry  of set . The match of the tag subkey value 0000 indicates that there is a corresponding entry in set of the Directory Table  associated with the key prefix 11110000. When one of the sets -is selected in this manner, the blocks within the selected set are searched linearly to find a block, such as block , that contains the remainder subkey value  that matches a corresponding portion of the object key . If a match is found, then there is almost always a hit in the cache. There is a small possibility of a miss if the first, second and third subkeys don't comprise the entire key. If there is a hit, the referenced object is then located based on information contained in the block, retrieved from one of the cache storage devices -, and provided to the client , as described further below.","Unlike the Tag Table, whose job is to quickly determine rule out misses with the minimal use of RAM memory, each block within Directory Table  includes a full pointer to a disk location. The item referenced by the disk location value  varies depending on the source from which the key was produced. If the key was produced based on the content of an object, as described above, then the disk location value  indicates the location of a stored object  (or a first fragment thereof), as shown in  in the case of block . If the key is a name key, then as shown for block , the disk location value  indicates the location of one or more Vectors of Alternates , each of which stores one or more object keys for the object whose name was used to generate the name key. A single Tag Table  and a single Directory Table  are shown in  merely by way of example. However, additional tables that provide additional levels of storage and indexing may be employed in alternate embodiments.","In the preferred arrangement, when a search of the cache is conducted, a hit or miss will occur in the Tag Table  very quickly. If there is a hit in the Tag Table , then there is a very high probability that a corresponding entry will exist in the Directory Table . The high probability results from the fact that a hit in the Tag Table  means that the cache holds an object whose full key shares X identical bits to the received key, where X is the number of bits of the concatenation of the set and tag subkeys  and . Because misses can be identified quickly, the cache  operates rapidly and efficiently, because hits and misses are detected quickly using the Tag Table  in memory without requiring the entire Directory Table  to reside in main memory.","When the cache is searched based on object key , the set subkey  is used to index one of the sets -in Tag Table . Once the set associated with subkey  is identified, a linear search is performed through the elements in the set to identify an entry whose tag matches the tag subkey .","In a search for an object  requested from the cache  by a client , when one of the sets -is selected using the set subkey , a linear search of all the elements  in that set is carried out. The search seeks a match of the tag subkey  to one the entries. If a match is found, then there is a hit in the Tag Table  for the requested object, and the cache  proceeds to seek a hit in the Directory Table .","For purposes of example, assume that the object key is a 12-bit key having a value of 111100001010, the set subkey comprises the first four bits of the object key having a value of 1111, and the tag subkey comprises the next four bits of the object key having a value of 0000. In production use the number of remainder bits would be significantly larger than the set and tag bits to affect memory savings. The cache identifies set  (1111) as the set to examine in the Tag Table . The cache searches for an entry within that set that contains a tag 0000. If there is no such entry, then a miss occurs in the Tag Table . If there is such an entry, then the cache proceeds to check the remaining bits in Directory Table  for a match.","In one embodiment, the Directory Table  contains multiple sets each composed of a fixed number of elements. Each element contains the remainder tag and a disk pointer. Large caches will contain large numbers of objects, which will require large numbers of elements in the directory table. This can create tables too large to be cost-effectively stored in main memory. For example, if a cache was configured with 128 million directory table elements, and each element was represented by a modest 8 bytes of storage, 1 GByte of memory would be requires to store the directory table, which is more memory than is common on contemporary workstation computers. Because few of these objects will be actively accessed at any time, there is a desire to migrate the underutilized entries onto disk while leaving higher utilized entries in main memory.",{"@attributes":{"id":"p-0088","num":"0107"},"figref":"FIG. 4C","b":["110","111","111","111","111","111","111","1106","11","111","111","111","111","1110","111","111","1106"],"i":["a","b","c","a","c","a ","b","c ","b","c ","b","c "]},"As directory elements are accessed more often, the directory elements are moved to successively higher segment among the segments -of the multi-level directory. Thus, frequently accessed directory elements are more likely to be stored in main memory . The most popular elements appear in the highest and smallest segment the directory, and will all be present in main memory . Popularity of entries is tracked using a small counter that is several bits in length. This counter is updated as described in the section SCALED COUNTER UPDATING. This multi-level directory approximates the performance of in-memory hash tables, while providing cost-effective aggregate storage capacity for terabyte-sized caches, by placing inactive elements on disk.","As discussed, in a preferred embodiment, the Directory Table  is implemented as a multi-level hash table. Portions of the Directory Table may reside out of main memory, on disk. Data for the Directory Table is paged in and out of disk on demand. A preferred embodiment of this mechanism uses direct disk I\/O to carefully control the timing of paging to and from disk and the amount of information that is paged.","Another embodiment of this approach exploits a feature of UNIX-type operating systems to map files directly into virtual memory segments. In this approach, the cache maps the Directory Table into virtual memory using the UNIX mmap( ) facility. For example, a mmap request is provided to the operating system, with a pointer to a file or disk location as a parameter. The mmap request operates as a request to map the referenced file or disk location to a memory location. Thereafter, the operating system automatically loads portions of the referenced file or disk location from disk into memory as necessary.","Further, when the memory location is updated or accessed, the memory version of the object is written back to disk as necessary. In this way, native operating system mechanisms are used to manage backup storage of the tables in non-volatile devices. However, at any given time it is typical that only a portion of the Directory Table  is located in main memory.","In a typical embodiment, the Directory Table and Open Directory are stored using a \u201cstriping\u201d technique. Each set of the tables is stored on a different physical disk drive. For example, set of Directory Table  is stored on storage device , set is stored on storage device , etc. In this arrangement, the number of seek operations needed for a disk drive head to arrive at a set is reduced, thereby improving speed and efficiency of the cache.","It should be noted when paging data between disk and memory certain safeguards are taken to ensure that the information stored in memory is consistent with the corresponding information stored in a non-volatile storage device. The techniques used to provide efficient consistency in object caches are summarized in the context of garbage collection, in the section named SYNCHRONIZATION AND CONSISTENCY ENFORCEMENT.","As mentioned above, it is possible for a single URL to map to an object that has numerous versions. These versions are called \u201calternates\u201d. In systems that do not use an object cache, versions are selected as follows. The client establishes an HTTP connection to the server  through the Internet . The client provides information about itself in an HTTP message that requests an object from the server. For example, an HTTP request for an object contains header information that identifies the Web browser used by the client, the version of the browser, the language preferred by the client, and the type of media content preferred by the client. When the server  receives the HTTP request, it extracts the header information, and selects a variant of the object  based upon the values of the header information. The selected alternate is returned to the client in a response message. This type of variant selection is promoted by the emerging HTTP\/1.1 hypertext transfer protocol.","It is important for a cache object store to efficiently maintain copies of alternates for a URL. If a single object is always served from cache in response to any URL requests, a browser may receive content that is different than that obtained directly from a server. For this reason, each name key in the directory table  maps to one of the vectors of alternates -, which enable the cache  to select one version of an object from among a plurality of related versions. For example, the object  may be a Web page and server  can store versions of the object in the English, French, and Japanese languages.","Each Vector of Alternates -is a structure that stores a plurality of alternate records -. Each of the alternate records -is a structure that stores information that describes an alternative version of the requested object . For example the information describes a particular browser version, a human language in which the object has been prepared, etc. The alternate records also each store a full object key that identifies an object that contains the alternative version. In the preferred embodiment, each of the alternate records -stores request information, response information, and an object key .","Because a single popular object name may map to many alternates, in one embodiment a cache composes explicit or implicit request context with the object name to reduce the number of elements in the vector. For example, the User-Agent header of a Web client request (which indicates the particular browser application) may be concatenated with a web URL to form the name key. By including contextual information directly in the key, the number of alternates in each vector is reduced, at the cost of more entries in the directory table. In practice, the particular headers and implicit context concatenated with the information object name is configurable.","These Vectors of Alternates -support the correct processing of HTTP\/1.1 negotiated content. Request and response information contained in the headers of HTTP\/1.1 messages is used to determine which of the alternate records -can be used to satisfy a particular request. When cache  receives requests for objects, the requests typically contain header information in addition to the name (or URL) of the desired object. As explained above, the name is used to locate the appropriate Vector of Alternates. Once the appropriate Vector of Alternates is found, the header information is used to select the appropriate alternate record for the request.","Specifically, in the cache , the header information is received and analyzed. The cache  seeks to match values found in the header information with request information of one of the alternate records -. For example, when the cache  is used in the context of the World Wide Web, requests for objects are provided to a server containing the cache in the form of HTTP requests.","The cache  examines information in an HTTP request to determine which of the alternate records -to use. For example, the HTTP request might contain request information indicating that the requesting client is running the Netscape Navigator browser program, version 3.0, and prefers German text. Using this information, the cache  searches the alternate records through for response information that matches the browser version and the client's locale from the request information. If a match is found, then the cache retrieves the object key from the matching alternate and uses the object key to retrieve the corresponding object from the cache.","The cache optimizes the object chosen by matching the criteria specified in the client request. The client request may specify minimal acceptance criteria (e.g. the document must be a JPEG image, or the document must be Latin). The client request may also specify comparative weighting criteria for matches (e.g. will accept a GIF image with weight 0.5, but prefer a JPEG image at weight 0.75). The numeric weightings are accumulated across all constraint axes to create a final weighting that is optimized.","The object key is used to retrieve the object in the manner described above. Specifically, a subkey portion of the object key is used to initiate another search of the Tag Table  and the Directory Table , seeking a hit for the subkey value. If there is a hit in both the Tag and Directory Tables, then the block in the Directory Table arrived at using the subkey values will always reference a stored object (e.g. stored object ). Thus, using the Vector of Alternates , the cache  can handle requests for objects having multiple versions and deliver the correct version to the requesting client ","In , only one exemplary Vector of Alternates  and one exemplary stored object  are shown. However, in practice the cache  includes any number of vectors and disk blocks, depending on the number of objects that are indexed and the number of alternative versions associated with the objects.",{"@attributes":{"id":"p-0105","num":"0124"},"figref":"FIG. 4B","b":["122","122"],"i":["a","n"]},"In one of the storage devices -, each of the Vectors of Alternates -is stored in a location that is contiguous to the stored objects -that are associated with the alternate records -represented in the vector. For example, a Vector of Alternates stores alternate records -. The alternate record stores request and response information indicating that a stored object associated with the alternate record is prepared in the English language. Another alternate record stores information indicating that its associated stored object is intended for use with the Microsoft Internet Explorer browser. The stored objects , referenced by the alternate records , are stored contiguously with the Vectors of alternates -","The Size value  within each alternate record indicates the total size in bytes of one of the associated Vectors of Alternates -and the stored object . When the cache  references a Vector of Alternates based on the disk location value , the cache reads the number of bytes indicated by the Size value. For example, in the case of the Vectors of Alternates shown in , the Size value would indicate the length of the Vector of Alternate plus the length of its associated stored object . Accordingly, by referencing the Size value, the cache  reads the vector as well as the stored object. In this way, the cache  \u201creads ahead\u201d of the Vector of Alternates  and retrieves all of the objects  from the storage devices -. As a result, both the Vector of Alternates and the objects  are read from the storage device using a single seek operation by the storage device. Consequently, when there is a hit in the cache , in the majority of cases (where there is a single alternate) the requested object  is retrieved from a storage device using a single seek.","When the disk location value  directly references a stored object , rather than a Vector of Alternates , the Size value  indicates the size of the object as stored in the disk block. This value is used to facilitate single-seek retrieval of objects, as explained further herein.","In one embodiment, the cache  further comprises an Open Directory . The Open Directory  stores a plurality of linked lists -, which are themselves composed of a plurality of list entries -. Each of the linked lists -is associated with one of the sets -in the Directory Table . The Open Directory  is stored in volatile main memory. Preferably, each list entry -of the Open Directory  stores an object key that facilitates associative lookup of an information object. For example, each item within each linked list -stores a complete object key  for an object .","The Open Directory accounts for objects that are currently undergoing transactions, to provide mutual exclusion against conflicting operations. For example, the Open Directory is useful in safeguarding against overwriting or deleting an object that is currently being read. The Open Directory also buffers changes to the Directory Table  before they are given permanent effect in the Directory Table . At an appropriate point, as discussed below, a synchronization operation is executed to move the changes reflected in the Open Directory  to the Directory Table . This prevents corruption of the Directory Table  in the event of an unexpected system failure or crash.","Further, in one embodiment, when an object is requested from the cache , the Open Directory  is consulted first; it is considered the most likely place to yield a hit, because it contains references to the most recently used information objects. The Open Directory in this form serves as a cache in main memory for popular data.","After the Open Directory , Tag Table  and Directory Table  have been accessed to determine the location of a stored object , the object must be read from storage and transmitted to the user that requested the object. To improve the efficiency of read operations that are used to retrieve objects  from the cache , certain data aggregation techniques are used when initially storing the data. When data is initially stored on disk according to the data aggregation techniques described herein, the efficiency of subsequent reads is improved greatly.",{"@attributes":{"id":"p-0113","num":"0132"},"figref":"FIG. 6","b":["80","90","90","90","200","200"],"i":["a","n","a","a","n"]},"Each pool, such as pool , comprises a header  and a plurality of fixed size storage spaces referred to herein as \u201carenas\u201d through . The size of the arenas is preferably configurable or changeable to enable optimization of performance of the cache . In the preferred embodiment, each of the arenas -is a block approximately 512 Kbytes to 2 Mbytes in size.","Data to be written to arenas is staged or temporarily stored or staged in a \u201cwrite aggregation buffer\u201d in memory. This buffer accumulates data, and when full, the buffer is written contiguously, in one seek, to an arena on disk. The write aggregation buffer improves the performance of writes, and permits sector alignment of data, so data items can be directly read from raw disk devices.","The write aggregation buffer is large enough to hold the entire contents of an arena. Data is first staged and consolidated in the write aggregation buffer, before it is dropped into the (empty) arena on disk. The write aggregation buffer also contains a free top pointer that is used to allocate storage out of the aggregation buffer as it is filling, an identifier naming the arena it is covering, and a reference count for the number of active users of the arena.","Each pool header  stores a Magic number, a Version No. value, a No. of Arenas value, and one or more arena headers -. The Magic number is used solely for internal consistency checks. The Version No. value stores a version number of the program or process that created the arenas -in the pool. It is used for consistency checks to ensure that the currently executing version of the cache  can properly read and write the arenas. The No. of Arenas value stores a count of the number of arenas that are contained within the pool.","For each of the arenas in the pool, the pool header  stores information in one of the arena headers -. Each arena header stores two one-bit values that indicate whether the corresponding arena is empty and whether the arena has become corrupted (e.g. due to physical disk surface damage, or application error).","As shown in  in the exemplary case of an arena , each arena comprises one or more data fragments -. Each fragment -comprises a fragment header and fragment data . The fragment data is the actual data for an object that is stored in the cache . The data for an entire stored object may reside within a single fragment, or may be stored within multiple fragments that may reside in multiple arenas. The fragment header stores a Magic number value , a key value and a length value ","The length value represents the length in bytes of the fragment, including both the fragment header and the fragment data . The key value is a copy of the object key, stored in its entirety, of the object whose data is in the fragment. Thus, the key value can be used to look up the directory block that points to the first fragment that holds data of the object whose data is contained in the fragment.","According to one embodiment, the complete object key  is stored in association with the last fragment associated with a particular object. When an object  is stored in the cache  for the first time, the object key  is computed incrementally as object data is read from the originating server . Thus, the final value of the object key  cannot be known until the entire object  is read. The object key  is written at the end of the chain of fragments used to store the object, because the value of the key is not known until the last fragment is written, and because modifying existing data on disk is slow. In alternate embodiments, the fragment header can store other metadata that describes the fragment or object.","The write aggregation buffer contains a \u201cfree top pointer\u201d  indicating the topmost free area of the buffer . The top pointer  identifies the current boundary between used and available space within the buffer . The top pointer  is stored to enable the cache  to determine where to write additional fragments in the buffer. Everything below (or, in , to the left of) the top pointer  contains or has already been allocated to receive valid data. The area of the arena above the top pointer  (to the right in ) is available for allocation for other information objects. Preferably, each fragment includes a maximum of 32 kilobytes of data. Fragments start and end on standard 512-byte boundaries of the storage device . In the context of the World Wide Web, most objects are relatively small, generally less than 32K in size.","Each arena may have one of two states at a given time: the empty state or the occupied state. The current state of an arena is reflected by the Empty value stored in each arena header -. In the occupied state, some portion of the arena is storing usable data. A list of all arenas that are currently empty or free is stored in memory. For example, main memory of the workstation that runs the cache  stores an array of pointers to empty arenas. In alternate embodiments, additional information can be stored in the header -n of each arena. For example, the header may store values indicating the number of deleted information objects contained in the arena, and a timestamp indicating when garbage collection was carried out last on the arena.","Although three fragments are shown in  as an example, in practice any number of fragments may be stored in an arena until the capacity of the arena is reached. In addition, the number of pools and the number of arenas shown in  are merely exemplary, and any number may be used.","The above-described structure of the arenas facilitates certain consistent and secure mechanisms of updating data for objects that are stored in fragments of the arenas.  is a block diagram relating to updating one of the arenas -of FIG. .  shows an arena containing a first information object having a header  and data fragments -. Top pointer  points to the topmost active portion of the arena , which is the end of the data segment . Preferably, the Directory Table is updated only after a complete information object has been written to an arena, including header and data, and only after the top pointer of the arena has been moved successfully. For example, a complete information object is written to the arena above the top pointer , and the top pointer is moved to indicate the new top free location of the arena. Only then is the Directory Table updated.","The delayed updating of the Directory Table is carried out to ensure that the Directory Table remains accurate even if a catastrophic system failure occurs during one of the other steps. For example, if a disk drive or other element of the system crashes before completion of one of the steps, no adverse effect occurs. In such a case, the arena will contain corrupt or incomplete data, but the cache  will effectively ignore such data because nothing in the Directory Table , indexes or hash tables is referencing the corrupt data. In addition, using the Garbage Collection process described herein, the corrupt or incomplete data is eventually reclaimed.","In , the directory table block that is arrived at based on the object key of object  includes a pointer directly to the fragment in which the object  is stored. This assumes that object  has been stored in a single fragment.","However, large objects may not always fit into a single fragment, for two reasons. First, fragments have a fixed maximum size (preferred value is 32 KB). Objects greater than 32 KB will be fragmented. Second, the system must pre-reserve space in the write aggregation buffer for new objects. If the object store does not know the size of the incoming object, it may guess wrong. The server may also misrepresent the true (larger) size of the object. In both cases, the object store would create a chain of fragments to handle the overflow.","Therefore, a mechanism is provided for tracking which fragments contain data from objects that are split between fragments.  is a block diagram of a preferred structure for keeping track of related fragments.","For the purpose of explanation, it shall be assumed that an object X is stored in three fragments , and on storage devices -. Using the object key for object X, the cache traverses the Tag Table to arrive at a particular block within the Directory Table . Block is the head of a chain of blocks that identify successive fragments that contain the object X. In the illustrated example, the chain is includes blocks , , , and , in that order, and is formed by pointers through ","According to one embodiment, the head block comprises a subkey value  and a block pointer . Preferably, the subkey value  is 96 bits in length and comprises a subset of the value of the object key  for object X. The value of the block pointer references the next block in the chain.","Directory table block comprises a fragment pointer and a block pointer . The fragment pointer references a fragment that stores the first portion of the data for the object X. The block pointer of pointer block references the next pointer block in the chain. Like pointer block , pointer block has a fragment pointer that references a fragment . The block pointer of pointer block references the next pointer block in the chain. Like pointer block , pointer block has a fragment pointer that references a fragment ","The object store needs a mechanism to chain fragments together. Traditional disk block chaining schemes require modifying pre-existing data on disk, to change the previous chain-link pointers to point the new next block values. Modification of pre-existing disk data is time-consuming and creates complexities relating to consistency in the face of unplanned process termination.","According to one embodiment of the invention, the need to patch new fragment pointers into extant fragments is removed by using \u201citerative functional pointers\u201d. Each fragment is assigned a key, and the key of the next fragment is assigned as a simple iterative function of the previous fragment's key. In this manner, fragments can be chained simply by defining the key of the next fragment, rather than by modifying the pointer of the previous fragment.","For example, the block pointer is computed by applying a function to the value of subkey . The block pointer value is computed by applying a function to the value of the block pointer . The function used to compute the pointer values is not critical, and many different functions can be used. The function can be a simple accumulating function such that\n\nkey=key+1\n\nor the function can be a complex function such as the MD5 hash function\n\nkey5(key)\n\nThe only requirement is that the range of possible key values should be sufficiently large, and the iteration should be sufficiently selected, so that the chances of range collision or cyclic looping are small. In the very unlikely event of key collision, the object will be deleted from the cache.\n","The last pointer block in the chain has a block pointer that points to a tail block . The tail block comprises a reference to the first block in the chain. According to one embodiment, the reference contained in the tail block a 96-bit subkey  of the object key of object X. The cache can use the 96-bit subkey  to locate the head block of the chain. The tail block , and the looped pointer arrangement it provides, enables the cache  to locate all blocks in a chain, starting from any block in the chain.","Three fragments , , and are shown in  merely by way of example. In practice, an information object may occupy or reference any number of fragments, each of which would be identified by its own pointer block within the Directory Table .","When the object  is read from the storage device, the last fragment is read first to ensure that the content MD5 key stored there matches the directory key value. This test is done as a \u201csanity check\u201d to ensure that the correct object has been located. If there is no match, a collision has occurred and an exception is raised.",{"@attributes":{"id":"p-0139","num":"0158"},"figref":["FIG. 10A","FIG. 10A"],"b":["640","898","8"]},"Accordingly, in step , an information object that has been requested by a client, but not found in the cache, is looked up and retrieved from its original location. In a networked environment, the origin is a server , a cluster, or a disk. When the object is retrieved, in step  the method tests whether the object is of the type and size that can be stored in the cache, that is, whether it is \u201ccacheable.\u201d","Examples of non-cacheable objects include Web pages that are dynamically generated by a server application, panes or portions of Web pages that are generated by client side applets, objects that are constructed based upon dynamic data taken from a database, and other non-static objects. Such objects cannot be stored in the cache because their form and contents changes each time that they are generated. If such objects were to be stored in the cache, they would be unreliable or incorrect in the event that underlying dynamic data were to change between cache accesses. The process determines whether the object is cacheable by examining information in the HTTP response from the server  or other source of the object.","If the object is cacheable, then in step  the method obtains the length of the object in bytes. For example, when the invention is applied to the World Wide Web context, the length of a Web page can be included in metadata that is carried in an HTTP transaction. In such a case, the cache extracts the length of the information object from the response information in the HTTP message that contains the information object. If the length is not present, and estimate is generated. Estimates may be incorrect, and will lead to fragmented objects.","As shown in block , space is allocated in a memory-resident write aggregation buffer, and the object to be written is streamed into the allocated buffer location. In a preferred embodiment, block  involves allocating space in a write aggregation buffer that has sufficient space and is available to hold the object. In block , the cache tests whether the write aggregation buffer has remaining free space. If so, the allocation and write process is complete and the cache  can carry out other tasks. When the write aggregation buffer becomes full, then the test of block  is affirmative, and control is transferred to block .","In block , the cache writes the aggregation buffer to the arena it is shadowing. In step , the Directory is updated to reflect the location of the new information object.","The foregoing sequence of steps is ordered in a way that ensures the integrity of information objects that are written to the cache. For example, the Directory is updated only after a complete information object has been written to an arena, including header and data. For example, if a disk drive or other element of the system crashes before completion of step  or step , no adverse effect occurs. In such a case, the arena will contain corrupt or incomplete data, but the cache will effectively ignore such data because nothing in the indexes or hash tables is referencing the corrupt data. In addition, using the garbage collection process described herein, the corrupt or incomplete data is eventually reclaimed.",{"@attributes":{"id":"p-0146","num":"0165"},"figref":["FIG. 8A","FIG. 8B","FIG. 8A"],"b":["80","8"]},"1. General Process","In the preferred embodiment, \u201cgarbage collection\u201d generally means a process of scanning target arenas, identifying active fragments or determining whether to delete fragments, writing the active fragments contiguously to new arenas, and updating the Directory Table to reference the new locations of the fragments. Thus, in a very broad sense the method is of the \u201cevacuation\u201d type, in which old or unnecessary fragments are deleted and active fragments are written elsewhere, so that at the conclusion of garbage collection operations on a particular arena, the arena is empty. Preferably, both the target arenas and the new arenas are stored and manipulated in volatile memory. When garbage collection is complete, the changes carried out in garbage collection are written to corresponding arenas stored in non-volatile storage such as disk, in a process called synchronization.","In step , one of the pools -is selected for garbage collection operations. Preferably, for each pool -of a storage device , the cache stores or can access a value indicating the amount of disk space in a pool that is currently storing active data. The cache also stores constant \u201clow water mark\u201d and \u201chigh water mark\u201d values, as indicated by block . When the amount of active storage in a particular pool becomes greater than the \u201chigh water mark\u201d value, garbage collection is initiated and carried out repeatedly until the amount of active storage in the pool falls below the \u201clow water mark\u201d value. The \u201clow water mark\u201d value is selected to be greater than zero, and the \u201chigh water mark\u201d value is chosen to be approximately 20% less than the total storage capacity of the pool. In this way, garbage collection is carried out at a time before the pool overflows or the capacity of the storage device is exceeded.","2. Usage-aware Garbage Collection","In step , one of the arenas is selected as a target for carrying out garbage collection. The arena is selected by a selection algorithm that considers various factors. As indicated by block , the factors include, for example, whether the arena is the last arena accessed by the cache , and the total number of accesses to the arena. In alternate embodiments, the factors may also include the number of information objects that have been deleted from each arena, how recently an arena has been used, how recently garbage collection was previously carried out on each arena, and whether an arena currently has read or write locks set on it. Once the arena is selected for garbage collection, all of the fragments inside the object are separately considered for garbage collection.","In step , one of the fragments within the selected arena is selected for garbage collection. In determining which fragment or fragments to select, the cache  takes into account several selection factors, as indicated by block . In the preferred embodiment, the factors include: the time of the last access to the fragment; the number of hits that have occurred to an object that has data in the fragment; the time required to download data from the fragment to a client; and the size of the object of which the fragment is a part. Other factors are considered in alternate embodiments. Values for these factors are stored in a block -that is associated with the object for which the fragment stores data.","In block , the cache determines whether a fragment should be deleted. In the preferred embodiment, block  involves evaluation of certain performance factors and optimization considerations.","Caches are used for two primary, and potentially conflicting, reasons. The first reason is improving client performance. To improve client performance, it is desirable for a garbage collector to retain objects that minimize server download time. This tends to bias a garbage collector toward caching documents that have been received from slow external servers. The second reason is minimizing server network traffic. To minimize server traffic, it is desirable for a garbage collector to retain objects that are large. Often, these optimizations conflict.","By storing values that identify the time required to download an object, the size of the object, and the number of times the object was hit in cache, the garbage collector can estimate, for each object, how much server download time was avoided and how much server traffic was disabled, by serving the cached copy as opposed to fetching from the original server. This metric measures the inherent \u201cvalue\u201d of the cached object.","The cache administrator then configures a parameter between 0 and 1, indicating the degree to which the cache should optimize for time savings or for traffic savings. The foregoing values are evaluated with respect to other objects in the arena, with respect to the amount of space the object is consuming, and with respect to objects recently subjected to garbage collection. Based on such evaluation, the cache  determines whether to delete the fragment, as shown in step .","If the fragment is to be deleted, then in step  it is deleted from the arena by marking it as deleted and overwriting the data in the fragment. When an object  is stored in multiple fragments, and the garbage collection process determines that one of the fragments is to be deleted, then the process deletes all fragments associated with the object. This may involve following a chain of fragments, of the type shown in , to another arena or even another pool.","If the fragment is not to be deleted, then in step  the fragment is written to a new arena. , which is discussed below, shows preferred sub-steps involved in carrying out step .","After the fragment is deleted or moved to another arena, in step  the Directory Table  is updated to reflect the new location of the fragment. Step  involves using the value of the key in the fragment header associated with a fragment to be updated to look up a block -that is associated with the fragment. When the correct Directory Table block -is identified, the disk location value  in the block is updated to reflect the new location of the fragment. If the fragment has been deleted, then any corresponding Directory Table entries are deleted.","Step  indicates that the method is complete after the Directory Table  is updated. However, it should be understood that the steps of  are carried out for all pools, all arenas within each pool, and all fragments within each arena.","3. Writing Fragments to New Arenas",{"@attributes":{"id":"p-0162","num":"0181"},"figref":"FIG. 8B","b":"810"},"In step , the directory tables are updated to reflect the change in location of the fragment. In the preferred embodiment, step  involves writing update information in the Open Directory  rather than directly into the Directory Table . At a later time, when the process can verify that the fragment data has been successfully written to one of the storage devices -, then the changes reflected in the Open Directory  are written into or synchronized with the Directory Table .","This process is used to ensure that the integrity of the Directory Table  is always preserved. As noted above, buffered storage is used for the fragments; thus, when a fragment is updated or a new fragment is written, the fragment data is written to a buffer and then committed to a disk or other storage device at a future time. Thus, during garbage collection, it is possible that a fragment that has been moved to a new arena is not actually written on one of the storage devices when the garbage collection process is ready to update the Directory Table. Therefore, information about the change is stored in the Open Directory  until the change is committed to disk.","In step , the original arena is examined to test whether it has other fragments that might need to be reclaimed or moved to a new arena. If other objects are present, then control returns to step  of , so that the next object can be processed. If no other objects are present in the current arena, then in step , the top pointer of the current arena is reset.","4. Buffering","In the preferred embodiment, read and write operations carried out by the cache  and the garbage collection process are buffered in two ways.","First, communications between the cache  and a client that is requesting an object from the browser are buffered through a flow-controlling, streaming, buffering data structure called a VConnection. In the preferred embodiment, the cache  is implemented in a set of computer programs prepared in an object-oriented programming language. In this embodiment, the VConnection is an object declared by one of the programs, and the VConnection encapsulates a buffer in memory. Preferably, the buffer is a FIFO buffer that is 32 Kbytes in size.","When a client -connects to the cache , the cache assigns the client to a VConnection. Data received from the client is passed to the cache  through the VConnection, and when the cache needs to send information to the client , the cache writes the information to the VConnection. The VConnection regulates the flow of data from the cache  to match the data transmission speed used by the client to communicate with the cache. In this way, use of the VConnection avoids an unnecessary waste of main memory storage. Such waste would arise if an object being sent to the client was copied to memory in its entirety, and then sent to the client; during transmission to a slow client, main memory would be tied up unnecessarily. Buffered I\/O using these mechanisms tends to reduce the number of sequential read and write operations that are carried out on a disk.","5. Synchronization and Consistency Enforcement","Regularly during the garbage collection process and during operation of the cache , a synchronization process is carried out. The synchronization process commits changes reflected in the Open Directory  to the Directory Table  and to stable storage, such as non-volatile storage in one or more of the storage devices -. The goal is to maintain the consistency of the data on disk at all times. That is, at any given instant the state of the data structures on disk is 100% consistent and the cache can start up without requiring checking. This is accomplished through careful ordering of the writing and synchronization of data and meta-data to the disk.","For the purposes of discussion, in this section, \u2018data\u2019 refers to the actual objects the cache is being asked to store. For instance, if the cache is storing an HTML document, the data is the document itself. \u2018Meta-data\u2019 refers to the additional information the cache needs to store in order to index the \u2018data\u2019 so that it can be found during a subsequent lookup( ) operation as well as the information it needs to allocate space for the \u2018data\u2019. The \u2018meta-data\u2019 is comprises the directory and the pool headers. The directory is the index the cache uses for associating a key (a name) with a particular location on disk (the data). The cache uses the pool headers to keep track of what disk space has been allocated within the cache.","The cache uses two rules to maintain the consistency of the data structures on disk. The first rule is that meta-data is always written down after the data it points to. The rationale for the first rule is that the cache has no \u201cpermanent\u201d knowledge of an object being in the cache until the meta-data is written. If the cache were to write down the meta-data before the data and then crash, the meta-data would associate an object name with invalid object data on disk. This is undesirable, since the cache would then have to use heuristics to try and determine which meta-data points to good data and which points to bad.","The second rule is that a pool arena cannot be marked as empty in the pool header until all the directory meta-data that points to the arena has been deleted and written to disk. This is necessary so that a crash cannot cause an empty arena to exist for which directory meta-data points to it. The problem this can cause is that the empty arena can become filled with new data, since it is empty and therefore it is available for new data to be written into it. However, \u201cold\u201d directory meta-data points to the same location as the new data. It is possible for accesses to the old directory meta-data to return the new data instead of either returning the old data or failing.",{"@attributes":{"id":"p-0175","num":"0194"},"figref":"FIG. 8C","b":["820","822","822","824","826"]},"The steps of blocks  through \u2032 are carried out periodically. As indicated in block , for each piece of meta-data in the open directory table, a determination is made whether the data that the metadata points to is already synchronized to disk, as shown in block . If so, then in block , the cache copies the metadata that points to the stable data from the Open Directory to the Directory Table. In block , the changes are synchronized to disk.","In block , garbage collection is carried out on an arena. Block  may involve the steps shown in FIG. A. Alternatively, garbage collection generally involves the steps shown in block , block , and block \u2032. As shown in block , for each fragment in the arena, the cache deletes the directory metadata that points to the segment, and writes the directory metadata to disk. In block , the pool header is modified in memory such that the arena is marked as empty. In block \u2032, the pool header is written and synced to disk.","The steps that involve writing information to disk preferably use a \u201cflush\u201d operation provided in the operating system of the workstation that is running the cache . The \u201cflush\u201d operation writes any data in the buffers that are used to store object data to a non-volatile storage device -","Using the foregoing methods, the Directory Table is not updated with the changes in the Open Directory until the data that the changes describe is actually written to disk or other non-volatile storage. Also, the cache  postpones updating the arenas on disk until the changes undertaken by the garbage collection process are committed to disk. This ensures that the arenas continue to store valid data in the event that a system crash occurs before the Directory Table is updated from the Open Directory.","6. Re-validation","In the preferred embodiment, the cache provides a way to re-validate old information objects in the cache so that they are not destroyed in the garbage collection process.",{"@attributes":{"id":"p-0182","num":"0201"},"figref":"FIG. 12","b":["1202","1204","1206","1208"]},"If the Read Counter value is high, then the information object has been loaded recently. In that case, in block  the cache sends a positive response message to the requesting process. Otherwise, as indicated in block , the information object has not been loaded recently. Accordingly, as shown in block , the cache sends a negative responsive message to the calling program or process. In block , the cache updates an expiration date value stored in association with the information object to reflect the current date or time. By updating the expiration date, the cache ensures that the garbage collection process will not delete the object, because after the update it is not considered old. In this way, an old object is refreshed in the cache without retrieving the object from its origin, writing it in the cache, and deleting a stale copy of the object.",{"@attributes":{"id":"p-0184","num":"0203"},"figref":["FIG. 10B","FIG. 10B","FIG. 10B","FIG. 10B","FIG. 10B"],"b":["112","112","3"],"i":["a","n "]},"In the preferred embodiment, each of the Read Counter values stored in blocks -is stored in three bit quantities. During operation of the cache , when a block is accessed, the Read Counter value of the block is incremented by one. The highest decimal number that can be represented by a three-bit quantity is 7. Accordingly, a Read Counter could overflow after being incremented seven times. To prevent counter overflow, while enabling the counters to track an unlimited number of operations that increment them, the method of  is periodically executed.","The following discussion of the steps of  will be more clearly understood with reference to Table 1:",{"@attributes":{"id":"p-0187","num":"0206"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"SUCCESSIVE COUNTER VALUES"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"140pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"COUNTERS"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"14pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"63pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"EVENT","A","B","C"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},"1: Start","1","1","1"]},{"entry":[{},"2: Increment","2","1","1"]},{"entry":[{},"3: Increment","7","3","1"]},{"entry":[{},"4: Decrement","6","2","0"]},{"entry":[{},"5: Reclaim","6","2","\u2014"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}]}}},"In Table 1, the EVENT column identifies successive events affecting a set of counter values, and briefly indicates the nature of the event. The COUNTERS heading indicates three counter values A, B, and C represented in separate columns. Each of the counter values A, B, C corresponds to a counter value that is stored in a different block -of the Directory Index . Thus, each row of Table 1 indicates the contents of three counter values at successive snapshots in time.","Event 1 of Table 1 represents an arbitrary starting point in time, in which the hash table entries containing the counter values A, B, C each have been accessed once. Accordingly, the value of each counter A, B, C is one. At event 2, the cache has accessed the hash table entry that stores counter value A. Accordingly, counter A has been incremented and its value is 2; the other counters B, C are unchanged. Assume that several other hash table entry accesses then occur, each of which causes one of counters A, B, or C to be incremented. Thereafter, at event 3, the values of the counters A, B, C are 7, 3, and 1 respectively. Thus, counter A is storing the maximum value it can represent, binary 111 or decimal 7, and will overflow if an attempt is made to increment it to a value greater than 7.","At this point, the method of  is applied to the counters A, B, C. In step , the value of all the counters is read. In step , the sum of all the counter values is taken. In the case of Table 1, the sum is given by 7+3+1=11. In step , the maximum sum that can be represented by all the counters is computed based upon the length in bits of the counter values. In the case of a three-bit value, the maximum value of one counter is 7 and the maximum value for the sum of three three-bit counters is 7\u00d73=21. Alternatively, step  can be omitted; the maximum value can be stored as a constant that is available to the scaled counter method  and simply retrieved when needed.","In step , the method computes the value (maximum_value\/2), truncating any remainder or decimal portion, and compares it to the sum of all the counters. In the example above, the relationship is\n\nSum=11\n\nMaximum_Value=21\n\nMaximum_Value\/2=10\n\n(Sum>Maximum_Value\/2)=TRUE\n\nSince the result is true, control is transferred to step , in which all the counter values are decremented by 1. The state of counters A, B, C after this step is shown by Event 4, \u201cDecrement.\u201d Note that counter C, which represents the least recently used hash table entry, has been decremented to zero. At this point, least recently used hash table entries can be reclaimed or eliminated by scanning the corresponding counter values and searching for zero values. The result of this step is indicated in Event 5 of Table 1, \u201cReclaim.\u201d The values of counters A and B are unchanged, and the value of counter C is undefined because its corresponding hash table entry has been deleted from the hash table.\n","When the method of  is repeated periodically and regularly, none of the plurality of counter values will overflow. Also, least recently used entries are rapidly identified by a counter value of zero, and can be easily eliminated from the cache. Counter values can be maintained in few bits even when hash table entries are accessed millions of times. Thus, the method of  provides a fast, efficient way to eliminate least recently used entries from a list.","In the preferred embodiment, the cache  is implemented in one or more computer programs that are accessible to external programs through an API that supports read and write operations. The read and write operations are carried out on the Open Directory , which is the only structure of the cache  that is \u201cvisible\u201d to external programs or processes. The read operation is invoked by an external program that wants to locate an object in the cache. The write operation is invoked by a program that wants to store an object in the cache. Within the programs that make up the cache , operations called lookup, remove, checkout, and checkin are supported. The lookup operation looks up an object in the Open Directory based upon a key. The remove operation removes an object from the Open Directory based upon a key. The checkout operation obtains a copy of a block from the Directory Table  in an orderly manner so as to ensure data consistency. The checkin operation returns a copy of a block (which may have been modified in other operations) to the Directory Table . In other embodiments, a single cache lookup operation combines aspects of these operations.","1. LOOKUP","In an alternate embodiment, a LOOKUP operation is used to determine whether a particular object identified by a particular name is currently stored in the cache .  is a flow diagram of steps carried out in one embodiment of the LOOKUP operation, which is generally designated by reference numeral . The LOOKUP operation is initiated by a command from the protocol engine  to the cache  when a request message from a client seeks to retrieve a particular object from the server . The request message from the client identifies the requested object by its name.","When the process is applied in the context of the World Wide Web, the name is a Uniform Resource Locator (URL). In step , the cache  converts the name of the object to a key value. In the preferred embodiment, the conversion step is carried out as shown in FIG. B. The object name  or URL is passed to a hash function, such as the MD5 one-way has function. The output of the hash function is an object name key . The object name key  can be broken up into one or more subkey values , .","In step , the cache  looks up the request key value in the Open Directory . The Open Directory is consulted first because it is expected to store the most recently requested objects and therefore is likely to contain the object in the client request. Preferably, step  involves using one of the subkey values as a lookup key. For example, a 17-bit or 18-bit subkey value can be used for the lookup.","In step , the cache  tests whether the subkey value has been found in the Open Directory. If the subkey value has been found in the Open Directory, then in step  the cache  retrieves the object from one of the storage devices, and delivers the object to the client. The retrieval sub-step involves the sub-steps described above in connection with locating objects in pools, arenas, and fragments of non-volatile storage in the storage devices -. The delivery sub-step involves constructing an HTTP response to the client that includes data of the object, opening an HTTP connection to the client, and sending the HTTP request to the client.","If the subkey value is not found in the Open Directory, then in step , the cache  looks up the request subkey value in the Tag Table . In step , the cache  tests whether the subkey value was found in the Tag Table . If no match was found, then in step  the cache  stores information about the fact that no match occurred, for later use as described below. The information can be a bit indicating that a miss in the Tag Table  occurred.","In step , the cache  looks up the subkey value in the Directory Table. If the test of step  was affirmative, then the cache  retrieves a subkey value matching the request subkey value from one of the entries  of the tag Table . Its value is used as a key to look up the request key value in the Directory Table. In step , the cache  tests whether the request key value was found in the Directory Table. If a hit occurs, and there was a miss in the Tag Table as indicated by the information stored in step , then in step  the cache  updates the Open Directory with information related to the Directory Table hit. Control is then passed to step  in which the object is obtained and delivered to the client in the manner described above.","If the test of step  is negative, then the requested object is not in the cache, and a cache miss condition occurs, as indicated in step . In response to the miss condition, in step  the cache  obtains a copy of the requested object from the server that is its source. For example, in the Web context, the cache  opens an HTTP connection to the URL provided in the client's request, and downloads the object. The object is then provided to the client and stored in the cache for future reference.","In a preferred embodiment, the LOOKUP operation is implemented as a method of an object in an object-oriented programming language that receives a key value as a parameter.","2. Cache Open Read Process",{"@attributes":{"id":"p-0204","num":"0223"},"figref":["FIG. 9E","FIG. 9E","FIG. 9E"],"b":["80","130","9"]},"In step , the process checks out a Vector of Alternates so that alternates in the vector can be read. Preferably, step  involves invoking the checkout_read process described herein in connection with , providing a key derived from the object name as a parameter. Checking out a vector involves checking out a block from the Open Directory that has a pointer to the vector, and reaching the block from the cache.","If the checkout operation is successful, then in step  the process uses the request information to select one of the alternates from among the alternates in the vector. This selection is carried out in the manner described above in connection with the Vector of Alternates . In an embodiment, the selection operation is carried out by another program or programmatic object that returns a success\/failure indication depending upon whether a suitable alternate is located. If the selection is successful, then in step  the process checks the Vector of Alternates back in. In step , the process reads the object that is pointed to by the selected alternate.","If step  or step  results in failure, then the requested document does not exist in the cache. Accordingly, in step  the process returns a \u201cno document\u201d error message to the calling program or process.","3. Cache Open Write Process",{"@attributes":{"id":"p-0209","num":"0228"},"figref":["FIG. 9F","FIG. 9E","FIG. 9F"],"b":["80","62","3"]},"The write process is initiated when a client has requested an object  from the cache  that is not found in the cache. As a result, the cache  opens an HTTP transaction with the server  that stores the object, and obtains a copy of the object from it. The request information that is provided to the cache write process is derived from the HTTP request that came from the client. The response information is derived from the response of the server  to the cache  that supplies the copy of the object.","In step , the process checks out a Vector of Alternates. This step involves computing a key value based upon the object name, looking up a set and a block in the Open Directory that map to the key value, and locating a Vector of Alternates, if any, that corresponds to the block. If no vector exists, as shown in step , a new vector is created","If a vector is successfully checked out or created, then in step  the process uses the request information to define a new alternate record -within the current alternate. The new alternate record references the location of the object, and contains a copy of the request information and the response information. The new alternate is added to the Vector of Alternates. Duplicate alternate records are permitted; the Vector of Alternates can contain more than one alternate record that contains the same request and response information. Testing existing alternate records to identify duplicates is considered unnecessary because only a small incremental amount of storage is occupied by duplicate alternate records.","In step , the modified vector is checked into the cache using the steps described above. In step , the object is written to one of the data storage devices -in the manner described above, using the key value. If the key is found to be in use during step , then the write operation fails. This avoids overwriting an object identified by a key that is being updated.","4. Cache Update Process",{"@attributes":{"id":"p-0215","num":"0234"},"figref":"FIG. 9G","b":["70","80","52","10","70","40","52","52","40","70","52","80"],"i":"a"},"If the server  responds affirmatively that the object  has changed since its expiration date or time in the cache , then the update process is not invoked. Instead, the server  returns a copy of the updated object  along with a new expiration date and other response information. In that case, the protocol engine  invokes the cache write process and the create processes described above to add the new object  to the cache .","As shown in , the update process receives input parameters including an object name, an \u201cold\u201d identifier, request information, and response information. The object name is a URL or a key derived from a URL. The request information and response information are derived from the client's HTTP request for the object  from the cache , and from the response of the server  when the cache obtains an updated copy of the object from the cache.","The \u201cold\u201d identifier is a value that uniquely identifies a pair of request information and response information. In the preferred embodiment, when a cache miss causes the cache  to write a new object into the cache, information from the client request is paired with response information from the server that provides a copy of the object. Each pair is given a unique identifier value.","In step , the process checks out a Vector of Alternates corresponding to the object name from the cache. Preferably, this is accomplished by invoking the checkout_write process described herein. This involves using the object name or URL to look up an object in the Open Directory, the Tag Table, and the Directory Index, so that a corresponding Vector of Alternates is obtained. If the checkout step fails, then in step  the process returns an appropriate error message.","If the checkout is successful, then in step  a copy or clone of the vector is created in main memory. A request\/response identifier value is located within the vector by matching it to the Old Identifier value received as input to the process. The old identifier value is removed and a new identifier is written in its place. The new identifier uniquely identifies the new request and response information that is provided to the process as input.","In step , the new vector is written to one of the storage devices -, and in step  the new vector is checked in to the cache. In carrying out these steps, it is desirable to completely write the clone vector to the storage device before the vector is checked in. This ensures that the writing operation is successful before the directory tables are modified to reference the clone vector. It also ensures that the old vector is available to any process or program that needs to access it.","5. Directory Lookup",{"@attributes":{"id":"p-0223","num":"0242"},"figref":["FIG. 9C","FIG. 9C"],"b":["130","62","70","70"]},"In step , the process attempts to check out one or more blocks that are identified by the subkey from the Directory Index. The block checkout step preferably involves invoking the checkout_read process described herein. Thus,","If the checkout attempt results in a failure state, then in step  the process returns an error message to the program or process that called it, indicating that a block matching the input subkey was not found in the cache. Control is passed to step  in which the process concludes.","If the checkout attempt is successful, then a copy of a block becomes available for use by the calling program. In step , the block that was checked out is checked in again. In step , the process returns a message to the calling program indicating that the requested block was found. Processing concludes at step .","Thus, a cache search operation involves calling more primitive processes that seek to check out a block identified by a key from the Open Directory. If the primitives do not find the block in the Open Directory, the Directory Index is searched.","When a block is found, it is delivered to the client. For example, when the invention is applied to the World Wide Web context, the data block is delivered by opening an HTTP connection to the client and transmitting the data block to the client using an HTTP transaction. This step may involve buffering several data blocks before the transaction is opened.","6. Cache Remove Process",{"@attributes":{"id":"p-0230","num":"0249"},"figref":"FIG. 9D","b":["958","962","948","954","952","9","960","938","944","9"]},"7. Checkout Read Operation",{"@attributes":{"id":"p-0232","num":"0251"},"figref":"FIG. 8D","b":["110","110","110"]},"As indicated in , the checkout_read operation receives a key value as input. In the preferred embodiment, the input key value is a subkey portion of a name key  that corresponds to an object name.","Because the object store will be modifying portions of memory and disk data structures, it needs to guarantee a brief period of mutual exclusion to a subset of the cache data structures in order to achieve consistent results. The cache data structures are partitioned into 256 virtual \u201cslices\u201d, selected by 8 bits of the key. Each slice has an associate mutex lock. In step , the process seeks to obtain the lock for the input key. If a lock cannot be obtained, the process waits the brief time until it becomes available. A lock can be unavailable if another transaction is modifying the small about of memory state associated with a key that falls in the same slice.","When a lock is obtained, the input key becomes unavailable for use by other processes. In step , the process determines which set -of the Directory Table  corresponds to the key. The process then locates one of the block lists , of the Open Directory  that corresponds to the set of the Directory Table , by associating the value of a subkey of the input key with one of the block lists. In step , the process scans the blocks in the selected block list of the Open Directory , seeking a match of the input key to a key stored in one of the blocks.","If a match is found, then in step  the process tests whether the matching block is currently in the process of being created or destroyed by another process. If the matching block is currently in the process of being created or destroyed, then in step  an error message is returned to the protocol engine  indicating that the current block is not available.","On the other hand, if the matching block is not currently in the process of being created or destroyed, then the block can be used. Accordingly, in step  the process increments a read counter. The read counter is an internal variable, associated with the block, that indicates the number of processes or instances of programmatic objects that are reading the block. Such processes or objects are called \u201creaders.\u201d In step , the process obtains a copy of the block, and returns it to the calling program or process.","If a match is not found in the scan of step , then in step , the process invokes a search of the Directory Table, seeking a match of the key to a set and block of the Directory Table using a process that is described further herein. If no match of the key is found in the search, then in step  the process returns an error message to the calling program or process, indicating that the requested object does not exist in the cache. Although the specific response to such a message is determined by the calling program or process, in the World Wide Web context, generally the proxy  contacts the server  that stores the object using an HTTP request, and obtains a copy of the requested object.","If a match is found during the Directory Index lookup of step , then in step  a corresponding block is added to the Open Directory. This is carried out by creating a new Open Directory block in main memory; initializing the block by copying information from the corresponding Directory Index block; and adding a reference to the new block to the corresponding list of blocks , ","8. Checkout Write Operation",{"@attributes":{"id":"p-0241","num":"0260"},"figref":"FIG. 8E","b":["130","130","130"]},"As indicated in , the checkout_write process receives a key value as input. In the preferred embodiment, the input key value is a subkey portion of a name key  that corresponds to an object name. In step , the process seeks to obtain a lock on the designated key. If a lock cannot be obtained, the process waits until one is available.","When a lock is obtained, the key becomes unavailable for use by other processes. In step , the process determines which set -of the Directory Table  corresponds to the key. The process then locates one of the block lists , of the Open Directory  that corresponds to the set of the Directory Table . In step , the process scans the blocks in the selected block list of the Open Directory , seeking a match of the input key to a key stored in one of the blocks.","If a match is found, then in step  the process tests whether the matching block is currently in the process of being created or destroyed by another process. If so, then in step  an error message is returned to the protocol engine  or cache  indicating that the current block is not available. If the matching block is not currently in the process of being created or destroyed, then the block can be used. Accordingly, in step  the process increments a write counter. The write counter is an internal variable, stored in association with the block, that indicates the number of processes or programmatic objects that are writing the block. In step , the process obtains a copy of the block, returns it to the calling program or process, and also marks the copy as being modified. The marking ensures that any changes made to the block will be reflected in the Directory Index when the Open Directory is synchronized to the Directory Index.","If a match is not found in the scan of step , then in step , the process invokes a search of the Directory Index using a process that is described further herein. If no match is found in the search, then in step  the process returns an error message to the calling program or process, indicating that the requested object does not exist in the cache. In the World Wide Web context, typically the calling program would contact the originating server that stores the object using an HTTP request, and obtain a copy of the requested object.","If a match is found during the Directory Index lookup of step , then in step  a corresponding block is added to the Open Directory. This is carried out by creating a new Open Directory block in main memory; initializing the block by copying information from the corresponding Directory Index block; and adding a reference to the new block to the corresponding list of blocks , . Control is then passed to step , in which the write count is incremented and the process continues as described above in connection with steps -.","9. Checkout Create Operation",{"@attributes":{"id":"p-0248","num":"0267"},"figref":"FIG. 8F","b":["130","130","130","130"]},"As indicated in , the checkout_create process receives a key value as input. In the preferred embodiment, the input key value is a subkey portion of a name key  that corresponds to an object name. In step , the process seeks to obtain a lock on the designated key. If a lock cannot be obtained, the process waits until one is available.","When a lock is obtained, the key becomes unavailable for use by other processes. In step , the process determines which set -of the Directory Table  corresponds to the key. The process then locates the set of the Open Directory  that corresponds to the set of the Directory Table , using the set subkey bits of the input key. In step , the process scans the blocks in the selected block list of the Open Directory , seeking a match of the input key to a key stored in one of the blocks.","If a match is found, then an attempt is being made to create a block that already exists. Accordingly, in step  the process tests whether the matching block has been marked as deleted, and currently has no other processes reading it or writing it. If the values of both the reader counter and the writer counter are zero, then the block has no other processes reading it or writing it. If the values of either the reader counter or the writer counter are nonzero, or if the matching block has not been marked as deleted, then the block is a valid previously existing block that cannot be created. In step  an error message is returned to the protocol engine  or cache  indicating that the current block is not available to be created.","If the matching block is deleted and has no writers or readers accessing it, then the process can effectively create a new block by clearing and initializing the matching, previously created block. Accordingly, in step  the process clears the matching block. In step  the process initializes the cleared block by zeroing out particular fields and setting the block's key value to the key. In block , the process increments the writer counter associated with the block, and marks the block as created. In step , the process returns a copy of the block to the calling process or programmatic object, and marks the block as being modified.","If a match is not found in the scan of step , then no matching block currently exists in the Open Directory . In step , the process carries out a search of the Directory Index using a process that is described further herein. If a match occurs, then in step , the process returns an error message to the calling program or process, indicating that the block to be created already exists in the cache and cannot be deleted.","If no match is found in the search, then no matching block currently exists in the entire cache. In step , the process creates a new Open Directory block, and adds a reference to that block to the list , associated with the set value computed in step . Control is passed to step , in which the processing continues as described above in connection with steps -.","10. Checkin Process",{"@attributes":{"id":"p-0256","num":"0275"},"figref":["FIG. 9B","FIG. 9B","FIG. 9B"],"b":["80","130"]},"In step , the process attempts to get a lock for the key associated with the block. If no lock is available, then the process enters a wait loop until a lock is available. When a lock is available, in step  the process tests whether the block is being checked in after the block has been modified. If so, then in step  the writer count for the block is decremented, indicating that a process has completed writing the block.","In step , the process tests whether the check-in process has been carried out successfully. If this test is affirmative, then in step  the process copies the information in the current block to the corresponding original block in the Open Directory. In this way, the Open Directory is updated with any changes that were carried out by the process that modified the copy of the block that was obtained in the checkout process. Thereafter, and if the test of step  is negative, the process tests whether a delete check-in flag is set. The delete check-in flag indicates that the block is to be deleted after check-in. The delete flag is an argument to the checkin operation. If the flag is set, then in step  the process marks the block as deleted. Processing concludes at step .","If the test of step  is negative, then the block is not being modified. As a result, the only other possible state is that the block has been read. Accordingly, in step , the reader count is decremented.","In the preferred embodiment, the methods described herein are carried out using a general-purpose programmable digital computer system of the type illustrated in FIG. . Each of the methods can be implemented in several different ways. For example, the methods can be implemented in the form of procedural computer programs, object-oriented programs, processes, applets, etc., in either a single-process or multi-threaded, multi-processing system.","In a preferred embodiment, each of the processes is independent and re-entrant, so that each process can be instantiated multiple times when the cache is in operation. For example, the garbage collection process runs concurrently with and independent of the allocation and writing processes.",{"@attributes":{"id":"p-0262","num":"0281"},"figref":"FIG. 11","b":["1100","1100","1102","1104","1102","1100","1106","1102","1104","1106","1104","1100","1108","1102","1104","1110","1102"]},"Computer system  may be coupled via bus  to a display , such as a cathode ray tube (CRT), for displaying information to a computer user. An input device , including alphanumeric and other keys, is coupled to bus  for communicating information and command selections to processor . Another type of user input device is cursor control , such as a mouse, a trackball, or cursor direction keys for communicating direction information and command selections to processor  and for controlling cursor movement on display . This input device typically has two degrees of freedom in two axes, a first axis (e.g., x) and a second axis (e.g., y), that allows the device to specify positions in a plane.","The invention is related to the use of computer system  for caching information objects. According to one embodiment of the invention, caching information objects is provided by computer system  in response to processor  executing one or more sequences of one or more instructions contained in main memory . Such instructions may be read into main memory  from another computer-readable medium, such as storage device . Execution of the sequences of instructions contained in main memory  causes processor  to perform the process steps described herein. In alternative embodiments, hard-wired circuitry may be used in place of or in combination with software instructions to implement the invention. Thus, embodiments of the invention are not limited to any specific combination of hardware circuitry and software.","The term \u201ccomputer-readable medium\u201d as used herein refers to any medium that participates in providing instructions to processor  for execution. Such a medium may take many forms, including but not limited to, non-volatile media, volatile media, and transmission media. Non-volatile media includes, for example, optical or magnetic disks, such as storage device . Volatile media includes dynamic memory, such as main memory . Transmission media includes coaxial cables, copper wire and fiber optics, including the wires that comprise bus . Transmission media can also take the form of acoustic or light waves, such as those generated during radio-wave and infra-red data communications.","Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, or any other magnetic medium, a CD-ROM, any other optical medium, punch cards, paper tape, any other physical medium with patterns of holes, a RAM, a PROM, and EPROM, a FLASH-EPROM, any other memory chip or cartridge, a carrier wave as described hereinafter, or any other medium from which a computer can read.","Various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to processor  for execution. For example, the instructions may initially be carried on a magnetic disk of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to computer system  can receive the data on the telephone line and use an infrared transmitter to convert the data to an infrared signal. An infrared detector coupled to bus  can receive the data carried in the infrared signal and place the data on bus . Bus  carries the data to main memory , from which processor  retrieves and executes the instructions. The instructions received by main memory  may optionally be stored on storage device  either before or after execution by processor .","Computer system  also includes a communication interface  coupled to bus . Communication interface  provides a two-way data communication coupling to a network link  that is connected to a local network . For example, communication interface  may be an integrated services digital network (ISDN) card or a modem to provide a data communication connection to a corresponding type of telephone line. As another example, communication interface  may be a local area network (LAN) card to provide a data communication connection to a compatible LAN. Wireless links may also be implemented. In any such implementation, communication interface  sends and receives electrical, electromagnetic or optical signals that carry digital data streams representing various types of information.","Network link  typically provides data communication through one or more networks to other data devices. For example, network link  may provide a connection through local network  to a host computer  or to data equipment operated by an Internet Service Provider (ISP) . ISP  in turn provides data communication services through the world wide packet data communication network now commonly referred to as the \u201cInternet\u201d . Local network  and Internet  both use electrical, electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on network link  and through communication interface , which carry the digital data to and from computer system , are exemplary forms of carrier waves transporting the information.","Computer system  can send messages and receive data, including program code, through the network(s), network link  and communication interface . In the Internet example, a server  might transmit a requested code for an application program through Internet , ISP , local network  and communication interface . In accordance with the invention, one such downloaded application provides for caching information objects as described herein.","The received code may be executed by processor  as it is received, and\/or stored in storage device , or other non-volatile storage for later execution. In this manner, computer system  may obtain application code in the form of a carrier wave.","Accordingly, an object cache has been described having distinct advantages over prior approaches. In particular, this document describes an object cache that offers high performance, as measured by low latency and high throughput for object store operations, and large numbers of concurrent operations. The mechanisms described herein are applicable to a large object cache that stores terabytes of information, and billions of objects, commensurate with the growth rate.","The object cache takes advantage of memory storage space efficiency, so expensive semiconductor memory is used sparingly and effectively. The cache also offers disk storage space efficiency, so that large numbers of Internet object replicas can be stored within the finite disk capacity of the object store. The cache is alias free, so that multiple objects or object variants, with different names, but with the same content identical object content, will have the object content cached only once, shared among the different names.","The cache described herein has support for multimedia heterogeneity, efficiently supporting diverse multimedia objects of a multitude of types with size ranging over six orders of magnitude from a few hundred bytes to hundreds of megabytes. The cache has fast, usage-aware garbage collection, so less useful objects can be efficiently removed from the object store to make room for new objects. The cache features data consistency, so programmatic errors and hardware failures do not lead to corrupted data.","The cache has fast restartability, so an object cache can begin servicing requests within seconds of restart, without requiring a time-consuming database or file system check operation. The cache uses streaming I\/O, so large objects can be efficiently pipelined from the object store to slow clients, without staging the entire object into memory. The cache has support for content negotiation, so proxy caches can efficiently and flexibly store variants of objects for the same URL, targeted on client browser, language, or other attribute of the client request. The cache is general purpose, so that the object store interface is sufficiently flexible to meet the needs of future media types and protocols.","The foregoing advantages and properties should be regarded as features of the technical description in this document; however, such advantages and properties do not necessarily form a part of the invention, nor are they required by any particular claim that follows this description.","In the foregoing specification, the invention has been described with reference to specific embodiments thereof and with reference to particular goals and advantages. It will, however, be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention. The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings and in which like reference numerals refer to similar elements and in which:",{"@attributes":{"id":"p-0027","num":"0046"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0028","num":"0047"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0029","num":"0048"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0030","num":"0049"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0031","num":"0050"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0032","num":"0051"},"figref":"FIG. 4B"},{"@attributes":{"id":"p-0033","num":"0052"},"figref":"FIG. 4C"},{"@attributes":{"id":"p-0034","num":"0053"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0035","num":"0054"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0036","num":"0055"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0037","num":"0056"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0038","num":"0057"},"figref":"FIG. 8B"},{"@attributes":{"id":"p-0039","num":"0058"},"figref":"FIG. 8C"},{"@attributes":{"id":"p-0040","num":"0059"},"figref":"FIG. 8D"},{"@attributes":{"id":"p-0041","num":"0060"},"figref":"FIG. 8E"},{"@attributes":{"id":"p-0042","num":"0061"},"figref":"FIG. 8F"},{"@attributes":{"id":"p-0043","num":"0062"},"figref":"FIG. 9A"},{"@attributes":{"id":"p-0044","num":"0063"},"figref":"FIG. 9B"},{"@attributes":{"id":"p-0045","num":"0064"},"figref":"FIG. 9C"},{"@attributes":{"id":"p-0046","num":"0065"},"figref":"FIG. 9D"},{"@attributes":{"id":"p-0047","num":"0066"},"figref":"FIG. 9E"},{"@attributes":{"id":"p-0048","num":"0067"},"figref":"FIG. 9F"},{"@attributes":{"id":"p-0049","num":"0068"},"figref":"FIG. 9G"},{"@attributes":{"id":"p-0050","num":"0069"},"figref":"FIG. 10A"},{"@attributes":{"id":"p-0051","num":"0070"},"figref":"FIG. 10B"},{"@attributes":{"id":"p-0052","num":"0071"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0053","num":"0072"},"figref":"FIG. 12"}]},"DETDESC":[{},{}]}
