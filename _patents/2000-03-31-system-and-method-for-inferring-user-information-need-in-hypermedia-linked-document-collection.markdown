---
title: System and method for inferring user information need in hypermedia linked document collection
abstract: The present invention provides a system and method for inferring information need in a collection of hypermedia documents that is based on the observation that a user's hypertext link traversal decisions are typically based on the nature of that user's information need. The system identifies the hypermedia linkage structure among the plurality of documents in the collection. The documents include content items that may be relevant to a user information need. The system then accepts a user path item that represents a user's hypermedia link traversal history and applies a network flow model to the user path item in the hypermedia link information in order to create a document vector. The system also determines the distribution of the content items in the document collection, and then compares the document vector to the content item distribution in order to determine an inferred information need.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07017110&OS=07017110&RS=07017110
owner: Xerox Corporation
number: 07017110
owner_city: Stamford
owner_country: US
publication_date: 20000331
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCES TO RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["The present application is related to commonly assigned U.S. Pat. No. 6,671,711, entitled \u201cSystem and Method For Predicting Web User Flow by Determining Association Strength of Hypermedia Links\u201d, which was filed concurrently with the present application.","The present invention relates to the field of analysis and design of hypermedia linked collections of documents, and in particular to a method for inferring user information need from observed web usage information.","The users of hypertext linked documents such as the World Wide Web, typically forage for information by navigating from document to document by selecting hypertext links. A piece of information such as a snippet of text is typically associated with each hypertext link. The snippet of text provides the user with information about the content of the document at the other end of the link. When the link leads the user to a document that is relevant to his information need, the user comes closer to satisfying his information need, thus reducing the amount of time that he will continue to forage for information. However, if the link leads the user to a document that is not relevant, then the user will continue foraging for information.","The structural linkage topology of collections of hypermedia linked documents is similar to a highway system. In a highway system, a traveler begins at some origin point and travels along the roads of the highway system in order to reach a desired destination. Along the way, the traveler may see signs that indicate which roads he should take to reach his desired destination. For example, a traveler who wishes to go from his home to the local airport might travel along the roadways until seeing a sign with the words \u201cinternational airport\u201d or a sign with a picture of an airplane. Either sign could give traveler information about which highway ramp to take in order to reach the airport. If the signs do not exist or if they are confusing, the traveler would probably not be able to find his destination.","Similarly, a user on the Web might start from one web page and select links based on whether they look like they might lead the user to another web page that might satisfy his information need. The links are analogous to roadways that can take the user to his destination, the information need. How well these links will lead users to their desired destinations depends on a complex interaction of user goals, user behaviors, and Web site designs.","Designers and researchers who want to know how users will interact with the Web develop hypotheses about these complex interactions. In order to evaluate these hypotheses rapidly and efficiently, tools need to be created to deal with the complexity of these interactions. Existing approaches to evaluate these hypotheses include extracting information from usage data such as Web log files, and applying metrics such as the number of unique users, the number of page visits, reading times, session links, and user paths. The degree of reliability of these approaches varies widely based upon the different heuristics used. For example, most existing Web log file analysis programs provide little insight into user Web interactions because they merely provide simple descriptive statistics on where users have been.","One shortcoming of existing approaches is that they focus on the destination of the user's visit, and not on the user's true information goal. Thus, there is a need for a system and method for inferring user information need in a hypermedia linked document collection.","An embodiment of the present invention provides a system and method for inferring information need in a collection of hypermedia documents. The system and method of the present invention make use of the observation that a user's hypertext link traversal decisions are typically based on the nature of that user's information need. The system identifies the hypermedia linkage structure among the plurality of documents in the collection, where the documents include content items that may be relevant to a user information need. The system then accepts a user path item that represents a user's hypermedia link traversal history. The system then applies the network flow model to the user path item in the hypermedia link information in order to create a document vector. The system also determines the distribution of the content items in the document collection, and then compares the document vector to the content item distribution in order to determine an inferred information need.","The present invention provides a system and method for inferring user information need in a collection of hypermedia linked documents. The system operates on the principle that a user's hypertext link traversal decisions are typically based on the nature of that user's information need. For example, at any point in the user's traversal through the collection of documents, the user has expressed her interest in various pieces of information by her decision to select certain links. The user information need is inferred by analyzing the list of documents representing a user's traversal history in the context of a collection of hypermedia linked documents.","Structure of a Hypermedia Linked Document Collection",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1","b":["100","0","1","2","3","4","5","6","102","104","106","108","110","112","114","0","6","120","122","124","126","128","130","132","0","6","102","114","140","154","0","6"]},"Method for Inferring Information Need",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 2","b":["200","202","206"]},"The user path item may be expressed as a vector with the more recent documents weighted more heavily, based on the assumption that the more recently accessed documents are closer to the user's information need. A network flow model is applied to the user path item, step , resulting in a list of documents that represent the information need. A decision, step , may be made to apply another iteration of the network flow model, step , or to stop processing and move on to step , in which the distribution of the content items in the document collection is determined. The distribution of the content items may be determined by standard information retrieval techniques such as TF.IDF (defined as \u201cterm frequency inverse document frequency\u201d weighting scheme) to weight the content items by a frequency in the document collection, as discussed in \u201cFoundations of Statistical Natural Language Processing\u201d, C. Manning and H. Schuetze, 1999, MIT Press, p. 542, which is incorporated by reference herein. A variety of other weighting schemes may also be used. The result is a list of content items, for example a list of keywords, which represent an inferred information need.",{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 3","FIG. 1","FIG. 5A","FIG. 1","FIG. 1","FIG. 5A","FIG. 1"],"b":["300","302","100","0","6","102","104","106","108","110","112","114","304","502","100","502","0","6","502","504","120","0","102","1","104","502"]},"Referring again to , unique ID numbers are assigned to the content items in the document collection, step , in order to identify them. For example, in , there are eight unique items: \u201cJava\u201d  (contained in documents P, P, P and P), \u201cAPI\u201d  (contained in document P), \u201cSun\u201d  (contained in document P), \u201cHome\u201d  (contained in documents P and P), \u201ccoffee\u201d  (contained in document P), \u201csupport\u201d  (contained in document P), \u201cPetes\u201d  (contained in document P) and \u201cTea\u201d  (contained in document P). These eight content items, as shown in indexed content item list  in , are indexed as follows: 0: Java, 1: API, 2: Sun, 3: Home, 4: Coffee, 5: Support, 6: Petes and 7: Tea.","With continued reference to , a user path item is obtained as input, step . The user path item is a list of documents that have been traversed by a user via the hypermedia links. The user path item is then expressed as a document vector showing document accessed by the user, step . For example, a document vector such as Q=[1 2 0 3 0 0 0] indicates that documents P, P and P have been accessed and document P has been weighted the most heavily, followed by documents P and P. Typically, documents that have been accessed more recently are weighted more heavily based on the assumption that the user comes closer to meeting his information need as he continues to traverse the hyperlinks in the document collection.","A network flow model is applied musing the document vector, at step . Any traditional network flow model may be used. A spreading activation algorithm may be used, for example as discussed in \u201cSystem for Predicting Documents Relevant to Focus Documents by Spreading Activation Through Network Representations of a Linked Collection of Documents\u201d, U.S. Pat. No. 5,835,905 by Pirolli, et al., which is incorporated by reference herein. Spreading activation can be characterized as a process that identifies knowledge predicted to be relevant to some focus of attention. Spreading activation techniques are based on representations of Web pages as nodes in graph networks representing usage, content, and hypertext relations among Web pages. Conceptually, activation is pumped into one or more of the graph networks at nodes representing some starting set of Web pages (i.e. focal points) and it flows through the arcs of the graph structure, with the amount of flow modulated by the arc strengths (which might also be thought of as arc flow capacities). The asymptotic pattern of activation over nodes will define the degree of predicted relevance of Web pages to the starting set of Web pages.","The spreading activation technique used for relevance prediction assumes that one may identify a pattern of input activation that represents a pattern or focus of attention. For instance, the focus may be a specific Web page or a prototype of a category. Activation from this focus point(s) spreads through one or more of the three graphs and eventually settles into a stable pattern of activation across all nodes. The activation values are assumed to be the predicted relevance to the input focus. Activation is pumped into one or more of the graph networks at nodes representing some starting set of focus Web pages. The activation flows through the arcs of the graph structure, with the amount of flow modulated by the arc strengths (which might also be thought of as arc flow capacities). The asymptotic pattern of activation over nodes will define the degree of predicted relevance of Web pages t the starting set of focus Web pages. The set of source nodes of activation being pumped into the network is represented by a vector.","With reference again to , a decision, step , may be made to continue and apply another iteration of the network flow model, step , or to continue processing at step , which is described below. The decision to continue may be based on a number of factors, including iterating for a predetermined number of steps, iterating based on a proportion of users who continue to select hypermedia links, or comparing the total number of users to a predetermined threshold. The proportion of users who continue to select hypermedia links may be determined by the function \u03b1(L), which is also known as \u201cthe law of surfing\u201d, as described in P. Pirolli and J. E. Pitkow, \u201cDistributions of surfers' paths through the World Wide Web: Empirical characterization\u201d, 1999, World Wide Web (2): pp. 29\u201345 and Huberman, B. A., P. Pirolli, J. Pitkow, R. Lukose, \u201cStrong regularities in World Wide Web surfing\u201d, 1999, Science 280: pp. 95\u201397, which are incorporated by reference herein.","In step , a word\u00d7document matrix is created to reflect the frequency of occurrence of content items in the document collection. The resulting weighting matrix represents the distribution of the content items in the document collection. An example of a weighting matrix W  is shown in . The distribution of the content items may be determined by standard information retrieval techniques such as TF.IDF to weight the content items by a frequency in the document collection, as discussed in \u201cFoundations of Statistical Natural Language Processing\u201d, C. Manning and H. Schuetze, 1999, MIT Press, p. 542, which is incorporated by reference herein. A variety of other weighting schemes may also be used.","With continued reference to , the weighting matrix W  () and the document vector are used in step  to look up a list of content items that represent an inferred information need. For example, starting with document vector Q=[1 2 0 3 0 0 0], described above, and taking the exponential in accordance with Luce's Theorem, a list of content items (in this case, keywords) may be represented by A(1)=Q=[2.7183 7.3891 1 20.0855 1 1 1]. Multiplying weighting matrix W  by A(1) gives R1=W*A(1)=[29.47 20.09 2.72 10.11 1 1 1 1]. The top two values, 29.47 and 20.09, followed by a third value 10.11, correspond to items 0, 1 and 3 in the indexed content item list  of . Content item 0 is \u201cJava\u201d , content item 1 is \u201cAPI\u201d, and content item 3 is \u201cHome\u201d. Thus, the top two keywords are \u201cJava\u201d and \u201cAPI\u201d, followed by the word \u201cHome\u201d. These keywords are the content items that represent the inferred user information need based on the input user path. Note that the network flow model may be applied again, as described above.","System for Inferring Information Need","A system for inferring information need in a plurality of hypermedia linked documents in an embodiment of the present invention, is shown in block diagram  of . The system includes an identification component . Identification component  responds to a hypermedia linked document collection input , and identifies the hypermedia links of a plurality of documents. Identification component  may be used to perform method steps  in FIG.  and \u2013 in . The identified links  and a user path item input  are acted upon by simulation component  to produce a document vector .","The simulation component  applies a network flow model. The network flow model may be any suitable traditional network flow model, for example a spreading activation algorithm as described above. The simulation component may operate in successive iterations and then stop when a particular condition is satisfied. For example, the simulation may continue for a predetermined number of steps or link traversals. The simulation may continue until a proportion of users who continue exceeds, reaches or drops below a desired level, as determined by the function \u03b1(L), as described above. Alternatively, the simulation may continue until a total number of users to continue drops below a predetermined threshold \u03b5.","Simulation component  may be used to perform method step  of  and step  of . Comparison component  compares document vector  to weighted distribution item  obtained from the distribution component . Distribution component  responds to hypermedia linked document collection  and produces weighted distribution item . Distribution component  may be used to perform method step  of  and step  of . The output of comparison component  is an inferred information need . Comparison component  may be used to perform method step  of  of .","It should be appreciated that the description herein is merely illustrative, and should not be read to limit the scope of the invention nor the claims hereof."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIGS. 5A","b":["5","5"]}]},"DETDESC":[{},{}]}
