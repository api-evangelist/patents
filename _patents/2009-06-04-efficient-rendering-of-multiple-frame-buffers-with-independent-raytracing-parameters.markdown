---
title: Efficient rendering of multiple frame buffers with independent ray-tracing parameters
abstract: One embodiment of the present invention sets forth a technique for rendering a plurality of images from a graphics scene in one rendering pass. Each image from the plurality of images may include or preclude certain scene objects and shading effects associated with the scene objects, as specified by a set of rules associated with a corresponding frame buffer that is configured to store the image. During the rendering pass, a ray-tracing application performs at least one complete ray casting operation, which is concluded according to the set of rules. At each stage in the ray casting operation, individual rules for each frame buffer determine whether results from that stage should be saved in the frame buffer. The plurality of images may represent different segments of a final rendered image, and may be combined arbitrarily in a compositing phase to generate the final rendered image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08368694&OS=08368694&RS=08368694
owner: AUTODESK, Inc
number: 08368694
owner_city: San Rafaelca
owner_country: unknown
publication_date: 20090604
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["1. Field of the Invention","Embodiments of the present invention relate generally to rendering graphics images and more specifically to efficient rendering of multiple frame buffers with independent ray-tracing parameters.","2. Description of the Related Art","High-quality graphics rendering applications are commonly used to generate highly refined images, such as photorealistic graphics images, from mathematical models of three-dimensional (3D) graphics scenes. A graphics scene typically comprises scene objects with material properties, light sources with associated properties, camera positions, and other relevant data configured within a scene database of a modeling application. The modeling application conventionally generates a render database from the scene database. The high-quality rendering application traverses the render database to render a highly refined image from the graphics scene represented within the render database.","The high-quality graphics rendering application typically invokes a plurality of shaders, each configured to impart various physically and visually significant effects on objects within the graphics scene. A shaded pixel in a final image may comprise contributions, organized as contribution types, from the plurality of shaders. Each type of shader, such as a material shader, may generate shading results based on results from other shaders, such as lighting shaders. For example, a material shader may generate shading results for a pixel based on specular lighting and diffuse lighting for a point on a scene object, whereby each source of lighting is computed from a corresponding lighting shader. Each shader may save data for a corresponding contribution type in a separate frame buffer. A plurality of frame buffers may be combined in a compositing step to generate a final image.","Because the goal of rendering images with a high-quality rendering application is to produce final images to the highest technical and artistic standards, users oftentimes generate and store a plurality of rendered images, each including different scene segments for a given scene. Users can then perform adjustments to certain parameters of specific segments within the rendered images in order to optimize a given final image. For example, a user may adjust how bright a specular highlight appears on a certain object to establish an aesthetic relationship of the object to other scene objects. Such adjustments may be performed as part of a posterior compositing step used to generate final images by combining rendered images stored in corresponding frame buffers.","In order to generate the plurality of coherent rendered images in a set of corresponding frame buffers, high-quality rendering applications conventionally perform a render pass for each image within the plurality of rendered images. However, each render pass typically requires significant computation independent of specific shader computations. Therefore, superfluous computations are conventionally required within the high-quality rendering application to generate each additional rendered image, leading to inefficiency in the high-quality rendering application. Because the computational load related to a high-quality rendering application typically accounts for a majority of an overall computational load for a given rendered end product, this inefficiency can be very costly to users.","As the foregoing illustrates, what is needed in the art is a technique for improving efficiency in rendering multiple scene segments using high-quality rendering applications.","One embodiment of the present invention sets forth a computer-implemented method for rendering a plurality of pixels into a corresponding plurality of frame buffers for display. The method includes the steps of selecting a point to render within a viewport, where the point represents a common location for each pixel within the frame buffer corresponding to the pixel, initializing a plurality of data structures, where each data structure is associated with a different one of the frame buffers in the plurality of frame buffers, and attaching each data structure to a ray-trace state associated with the point. The method also includes the steps of casting a ray based on the ray-trace state to render shading results, storing the shading results in one or more compositing stacks residing within the data structures, generating one of more samples for each of the pixels based on the shading results, combining the one or more samples for each of the pixels to generate the plurality of pixels, and storing each pixel in the frame buffer corresponding to the pixel.","One advantage of the disclosed method is that sets of associated samples are generated and then combined to produce a plurality of pixels, which are stored in associated frame buffers. Importantly, with such an approach, each image stored in each frame buffer may be rendered within the same rendering pass, thereby improving overall processing efficiency.","In the following description, numerous specific details are set forth to provide a more thorough understanding of the present invention. However, it will be apparent to one of skill in the art that the present invention may be practiced without one or more of these specific details. In other instances, well-known features have not been described in order to avoid obscuring the present invention.",{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1","b":["100","100","130","110","134","120","132","136","140","142","144","146","148"]},"The CPU  communicates with the system memory  via the memory bridge , which may be, e.g., a Northbridge device or subsystem. System memory  is configured to store application programs, as well as data used by or generated by the CPU . System memory  is coupled to the memory bridge  via a system memory bus . The memory bridge  is coupled to the GPU  via a GPU system bus . The GPU system bus  may comprise any technically feasible data interconnect, such as the well known personal computer interconnect (PCI) express bus. The memory bridge  is also coupled to the device bridge  using an interconnect system such as PCI. The GPU  conventionally incorporates real time image rendering means for rendering both three-dimensional (3D) and two-dimensional (2D) images. The GPU  delivers pixel data to display device , which may comprise a conventional CRT or LCD display. The GPU  is coupled to the GPU memory  using a GPU memory bus . The GPU memory  may be configured to store data used by or generated by the GPU . Data stored within the GPU memory  passes through the GPU  and the memory bridge  when accessed by the CPU . In some embodiments, the integrated circuit implementing the CPU  may incorporate additional functional blocks, such as the memory bridge  and the device bridge . In alternative embodiments, the integrated circuit implementing the GPU  may incorporate additional functional blocks, such as the memory bridge  and the device bridge .","The device bridge  is coupled to a hard drive , a network interface , a mouse , and a keyboard . The hard drive  provides mass storage of programs and data. The network interface  provides network connectivity to other computers using a local area network (LAN) interface using any suitable technology, such as Ethernet. The mouse  and keyboard  provide user input. Other components (not explicitly shown), including USB or other port connections, CD drives, DVD drives, film recording devices, and the like, may also be connected to I\/O bridge . Communication paths interconnecting the various components in  may be implemented using any suitable protocols, such as PCI (Peripheral Component Interconnect), PCI Express (PCI-E), AGP (Accelerated Graphics Port), HyperTransport, Quick Path Interconnect, or any other bus or point-to-point communication protocol(s), and connections between different devices may use different protocols as is known in the art.","In one embodiment, system memory  is configured to store a graphics modeling application , a graphics rendering application , a compositing application , an editor -, and a compiler -. The graphics rendering application  should include at least one shader module. The shader module may communicate with the rendering engine using any technically feasible means, such as a rendering application programming interface (API). System memory  is also configured to store a plurality of frame buffers , which may be configured to store scene segments rendered by the rendering engine, and an image generated by the compositing application . The compositing application  combines segments according to a contribution value for each segment to generate a composite image. For example, the rendering application  may render segments stored in frame buffers - through -, and the compositing application  may combine the segments to generate a composite image, such as a final image, stored in frame buffer -. The rendering application  uses shader functions within a customized shader program - to compute color samples, such as color, transparency, and other aspects of pixels or fragments in a graphics scene.","The editor - is used to generate and modify source code files stored in persistent memory, such as on the hard disk . The compiler - is configured to read in and parse certain source code files to generate, or \u201ccompile\u201d executable code. For example, the editor - may be used to modify source code file  and the compiler - may compile source code file  to generate the customized shading program -. The customized shading program - should be compiled to include housekeeping functionality for shading operations embodied in a shader application -, and specific shading functions included in a shader template -. The source code file  may include a source code representation of the shader template - and related shader modules. The rendering application  may be coupled to the customized shading program - to incorporate modifications made by the editor -. In one embodiment the customized shading program - is incorporated into the rendering application .","In an alternative embodiment, a first computer system includes a modeling application, and may include a compositing application. Additionally, a set of one or more computer systems may include at least one instance of the rendering application. In this scenario, the set of one or more computer systems is configured to communicate via a computer network. In this embodiment, the first computer system includes software configured to cause each computer system in the set of one or more computer systems to independently render and store scene segments.",{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 2","b":["200","200","236","230","232","234","200","238","210","212","200","212","200","200"]},"To compute a color of a pixel in the viewport , at least one eye ray - is projected from the camera , through the pixel sample in the viewport , and into the graphics scene  until the eye ray - intersects with an object within the graphics scene . The location of the camera  comprises a ray starting point for the eye ray -. A spatial location for the corresponding pixel in the viewport , in combination with the ray starting point, establishes an eye ray direction into the graphics scene. In this scenario, the eye ray - intersects object  at eye ray intersection  on the surface of object . Each intersection comprises a new starting point, and object geometry and material properties determine a ray direction for a subsequently cast ray. In this scenario, the light ray - is traced from light source , potentially imparting various forms of illumination from light source  on object  at the eye ray intersection . Each pixel of the viewport  is similarly sampled by projecting a corresponding eye ray from the camera  through the viewport . Persons skilled in the art will recognize that multiple samples may be generated and combined to generate each pixel in viewport .","Other objects in the graphic scene  may include a plurality of well known and custom attributes. For example, object  may be semi-transparent and semi-reflective (such as a piece of glass), and therefore include attributes describing transparency properties and reflectivity properties. Eye ray - may reflect off a surface of object  and intersect with object  along ray -. Eye ray - may also refract through object  and continue along ray - until intersecting object . Importantly, object  may be visible via a plurality of paths, each involving different material properties and different shaders.","In one usage scenario of the invention, a user may wish to generate a scene segment including, for example, only object  in isolation regardless of projection paths from camera , or only reflections of object , or only portions of graphics scene  that include a certain minimum level of refraction. Importantly, each attribute of each item within graphic scene  may be used to determine if a given ray intersection and associated shading operations should be included in a particular frame buffer. As each ray intersection is computed in the graphic scene , associated shader results are selectively stored within a plurality of compositing stacks stored within a corresponding set of frame buffer state structures. A decision to selectively store a certain shader result in a specific compositing stack within a particular frame buffer state structure is based on a compositing rule set specified by the user. Each compositing rule set specifies which scene elements and shading effects are then represented in a rendered image stored in an associated frame buffer. A termination rule set may be generated according to a combination of compositing rule sets and, optionally, additional user rules.","After each ray cast operation is completed for a given pixel location in the viewport , each compositing stack includes independently stored shading data needed to generate a corresponding pixel in each frame buffer. For a given pixel within viewport , a ray cast operation is completed once no further ray casts are needed to compute the pixel value. However, because each frame buffer may include different sets of requirements, efficient completion of a given ray cast operation should be determined by a termination rule set that accommodates each compositing rule set. For example, one frame buffer state structure may specify a compositing rule set requiring only first incident eye rays -, -. This first compositing rule set only stores shading results from first incident eye rays to compute a pixel value for a first associated frame buffer. Any additional ray casting beyond first incident rays with respect to this first frame buffer is therefore superfluous. At the same time, a second frame buffer state structure may specify a compositing rule set requiring all ray casts up to a depth of five trace levels. This second compositing rule set would include first incident rays - and -, as well as rays -, -, -, and any other rays cast meeting other compositing rules up to a depth of five trace levels. In this scenario, a termination rule set should accommodate completing computations associated with rays - and -, and any other rays up to a depth of five trace levels, prior to ending computation associated with eye ray -. Importantly, the termination rule set determines when a ray cast operation is complete and, separately, each compositing rule set determines which results should be stored in a respective compositing stack.",{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 3","FIG. 2"],"b":["300","350","114","210","352","352"]},"At each intersection, individual shading results  may or may not be added to a given compositing stack , as determined by an associated compositing rule set and, potentially, the termination rule set. A compositing rule set  for each frame buffer state  determines whether a given result  should be stored in a corresponding compositing stack  within a frame buffer state . For example, compositing rule set - may be used to determine which of individual shading results  should be stored in compositing stack -. As shown, individual shading results - and - are stored in compositing stack -, whereas individual shading results - and - may be stored in compositing stack -. Only individual shading results - is stored in compositing stack -. In this scenario, only results - and - are used to compute a corresponding pixel in a frame buffer associated with frame buffer state -, and only result - is used to compute a corresponding pixel in a frame buffer associated with frame buffer state -. This mechanism of using arbitrary compositing rule sets to determine which shading results are used to compute pixel values in individual frame buffers may be used to efficiently generate a plurality of highly-specific scene segments in one rendering pass.","A given compositing rule set may use object visibility within a scene, illumination sources, or certain ray-tracing options to determine whether a given shading result should be stored in a corresponding compositing stack. Shading attributes from ray-tracing that may be used to determine whether a given set of shading results should be stored in the corresponding compositing stack include transparency, holdouts, refraction levels, reflection levels, shadow casting, and whether invisible objects: cast shadows, produce reflections, produce refractions, are visible in reflections, or are visible in refractions. Thresholds for certain shading attributes may be used, including a minimum threshold for the refraction level, a minimum threshold for the reflection level, a maximum threshold for the refraction level, a maximum threshold for the reflection level, or a maximum global trace level.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 4","b":["410","412","410","412","405","410","412","410","0","412","0","410","1","412","1","410","0","410","2","412","2","410","3","405","412"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 5A","FIGS. 1"],"b":["500","3","4"]},"The method begins in step , where a ray-tracing application selects a point on a viewport, such as viewport  of , to render. Selecting a point may, for example, comprise performing a progressive raster scan of pixels within the viewport. In step , one or more frame buffer data structures are initialized. Each frame buffer should include a pixel corresponding to the selected point, and each frame buffer should comprise a resolution corresponding to the viewport . Each frame buffer data structure should include a frame buffer state, such as a frame buffer state  of , and an associated compositing rule set, such as a compositing rule set . Each compositing stack within each frame buffer state should be initialized in preparation for new shading result values. In one embodiment, the compositing stack comprises a fixed-size array of entries, with a valid entry variable indicating which entries within the array are valid. The valid entry variable may be cleared during initialization to indicate the compositing stack is empty. In step , the frame buffer data structures are attached to a ray-trace state for a pending ray within the ray-tracing application. By augmenting the ray-trace state to include independent compositing stacks associated with independent frame buffers to separately store compositing results, the ray-tracing application is able store shading results in each independent frame buffer according to compositing rules for the frame buffer. In this way, the ray-tracing application may render different scene segments in each frame buffer.","In step , the ray-tracing application casts a ray corresponding to the selected point on the viewport. This step, illustrated in greater detail in , populates the compositing stack with shading results. In step , the ray-tracing application combines shading results for each compositing stack to generate and store a set of samples, corresponding to the shading results in each compositing stack. Each compositing stack and each corresponding sample is associated with a frame buffer. Each set of shading results may be combined using any technically feasible technique. For example, each shading result entry within the compositing stack may be combined based on back to front composition techniques, where the most recent compositing stack entry corresponds to the backmost item for compositing and the least recent compositing stack entry corresponds to the front most item for compositing. A similar front to back compositing means may also be used. In both cases, sequential shading results are blended together based on transparency attributes of each shading result. Importantly, only shading results that satisfy an associated compositing rule set are present in a particular compositing stack. In this way, only desired objects and effects are represented by shading results stored in the compositing stack. In one embodiment, a set of samples is stored within a frame buffer state associated with the frame buffer. If, in step , the sample is not the last sample associated with a pixel in the viewport, then the method proceeds to step . Each pixel in a frame buffer may comprise multiple samples, and each sample may be computed by casting a ray. Each sample, computed according to an associated compositing rule set, should be offset within a given pixel geometry in the viewport to effect a spatial sampling of the graphics scene. The samples comprising the spatial sampling are used to generate an anti-aliased pixel, which may be saved to a respective frame buffer.","Returning to step , if the current sample is the last sample associated with a pixel in the viewport, then the method proceeds to step , where the ray-tracing application combines the samples into pixels and saves each pixel to a respective frame buffer. If, in step , the last required ray is cast then rendering is done and the method terminates in step .","Returning to step , if the last required ray is not cast, then rendering is not done and the method proceeds to step .",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 5B","FIG. 5B","FIG. 5A","FIGS. 1"],"b":["502","516","3","4"]},"The method begins in step , where the ray-tracing application receives a ray and computes an intersecting object for the ray. A new ray cast may begin with an eye ray projected from the camera  of  through the viewport , such as eye ray - or -. The intersecting object should be the first object encountered by following a ray cast. For example, object  is the first object encountered by eye ray -, and therefore is the intersected object for eye ray -. A point at which the cast ray intersects an object is an intersection point, such as eye ray intersection .","In step , the ray-tracing application calls one or more shaders associated with the intersecting object to compute shader results for the intersection point. The shaders may compute material properties, lighting properties, reflection properties, refraction properties, or any other technically feasible rendering attribute. The one or more shaders may be called in response to certain attributes for the intersecting object, and certain shading requirements specified by compositing rules for the frame buffers. Each object should include a set of attributes specifying which shaders should be called to render a sample corresponding to an intersection point on the object. The set of attributes may additionally specify shading parameters for the object used by shaders specified for the object. For example, object transparency may be specified as a shading parameter. Each shader may use related parameters in shading intersection points on the object.","In step , the ray-tracing application selects a frame buffer and tests associated compositing rules to determine which, if any, shading results should be stored in the frame buffer compositing stack. In step , the ray-tracing application stores shading results identified by compositing rules in a corresponding frame buffer compositing stack. If, in step , results for the last frame buffer were not yet processed, then the method proceeds to step .","Returning to step , if results for the last frame buffer were processed, then the method proceeds to step . If, in step , the ray-tracing application needs to cast a child ray, then the method proceeds to step . Persons skilled in the art will recognize that certain ray-tracing conditions may require recursively casting child rays. For example, when a semi-transparent, semi-reflective object is the intersected object. Reflections are rendered by casting a child ray along a path of reflection, while transparencies are rendered by casting a ray along a refraction path. Because a child ray may require further child rays, the process may be viewed as recursive. After a relatively small number of reflections (levels), the visual significance of each further reflection is highly limited. In fact, ten levels is generally adequate for most ray-tracing applications. In step , the ray-tracing application pushes a current ray-tracing context into a context data structure in preparation for casting a child ray. In one embodiment, the process of casting a child ray substantially replicates method steps  as a recursive process. At each recursive level, shading results may be placed in one or more compositing stack, according to corresponding compositing rules. Persons skilled in the art will recognize that this step is analogous to performing a recursive function call. Upon completing step , the method proceeds to step  to begin processing a new child ray using a new ray-tracing context for the child ray.","Returning to step , if the ray-tracing application does not need to cast a child ray, then the method proceeds to step . If, in step , ray-tracing for a sample in progress is not complete, then the method proceeds to step .","Returning to step , if ray-tracing for the sample in progress is complete, then the method proceeds to step . If, in step , the current ray is not a child ray, then the method terminates in step .","Returning to step , if the current ray is a child ray, then the method proceeds to step , where a ray-tracing context is popped from the context data structure to return ray-tracing context to the parent of the current child ray. The compositing stacks are popped and the frame buffer contributions registered by the child ray are composited into those of the parent ray. Persons skilled in the art will recognize this step as being analogous to returning from a recursive function call. Upon completing step , the method proceeds to step .","In sum, a technique is disclosed for generating a plurality of images using ray-tracing to render certain aspects of a graphic scene. Each image represents a scene segment, comprising a specified set of objects and shading attributes for the objects. Each image comprises a set of pixels, which may, in turn, comprise a plurality of samples. As the ray-tracing application casts individual rays through the graphics scene, shading results are accumulated in a plurality of compositing stacks, according to a set of compositing rules. The shading results in the plurality of compositing stacks are combined to generate a plurality of associated samples, each with an associated frame buffer. Sets of associated samples are combined to generate a plurality of pixels, which may be stored in associated frame buffers. Importantly, each image stored in each frame buffer is rendered within the same rendering pass, improving overall efficiency.","While the forgoing is directed to embodiments of the present invention, other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example, aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a program product for use with a computer system. The program(s) of the program product define functions of the embodiments (including the methods described herein) and can be contained on a variety of computer-readable storage media. Illustrative computer-readable storage media include, but are not limited to: (i) non-writable storage media (e.g., read-only memory devices within a computer such as CD-ROM disks readable by a CD-ROM drive, flash memory, ROM chips or any type of solid-state non-volatile semiconductor memory) on which information is permanently stored; and (ii) writable storage media (e.g., floppy disks within a diskette drive or hard-disk drive or any type of solid-state random-access semiconductor memory) on which alterable information is stored. Such computer-readable storage media, when carrying computer-readable instructions that direct the functions of the present invention, are embodiments of the present invention.","In view of the foregoing, the scope of the present invention is determined by the claims that follow."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["So that the manner in which the above recited features of the present invention can be understood in detail, a more particular description of the invention, briefly summarized above, may be had by reference to embodiments, some of which are illustrated in the appended drawings. It is to be noted, however, that the appended drawings illustrate only typical embodiments of this invention and are therefore not to be considered limiting of its scope, for the invention may admit to other equally effective embodiments.",{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5B"}]},"DETDESC":[{},{}]}
