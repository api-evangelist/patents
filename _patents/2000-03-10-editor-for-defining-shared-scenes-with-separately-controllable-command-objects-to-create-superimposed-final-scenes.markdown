---
title: Editor for defining shared scenes, with separately controllable command objects, to create superimposed final scenes
abstract: An information processing apparatus for creating content information according to a predetermined specification includes a shared scene definer operable to define a shared scene as editing material. The editing material is processed in the apparatus. The shared scene is created by a shared scene creator and is a virtual scene usable by a plurality of scenes. A shared scene setter sets a specific shared scene to be used by each of plurality of scenes to form content information, a shared object setter sets the shared object to be used in the specific shared scene and a control-information describer describes the control information for controlling the utilization of the shared objects in accordance with the predetermined specification and in dependence on the set specific shared scene.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07757157&OS=07757157&RS=07757157
owner: Sony Corporation
number: 07757157
owner_city: 
owner_country: JP
publication_date: 20000310
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT"],"p":["The present invention relates to an information processing apparatus used as the so-called authoring tool for creating broadcast contents such as MHEG (Multimedia Hypermedia Information Coding Expert Group) contents to be broadcasted along with video information.","In recent years, digital satellite broadcasting has become popular. In comparison with the contemporary analog broadcasting, for example, digital satellite broadcasting is better at preventing noise and fading, hence, is capable of transmitting a signal with a high quality. In addition, the frequency utilization rate is improved and a multi-channel transmission can also be embraced. To put it concretely, in the case of digital satellite broadcasting, several hundreds of channels can be preserved by using one satellite. In such digital satellite broadcasting, it is possible to provide a number of special channels such as channels for sports, movies, music and news. Programs for special plans and contents of the channels are broadcasted through their respective channels.","By utilizing such a digital broadcasting system, the user is capable of downloading musical data such as a piece of music. There also has been proposed a system, called television shopping, that allows the user to make a purchasing contract to buy some products while watching a broadcast screen. That is to say, the digital satellite broadcasting system broadcasts additional data services at the same time as an ordinary broadcast program.","In the case of an operation to download musical data, for example, the broadcasting station broadcasts the musical data by multiplexing the data so as to synchronize the data with a broadcast program or video information. In addition, the user is capable of carrying out downloading operations interactively while watching a displayed GUI (Graphical User Interface) screen which serves as a downloading operation screen. Data for displaying such a GUI screen is also broadcasted by multiplexing.","Then, the user owning a reception apparatus selects a desired channel to display a GUI screen for downloading musical data by carrying out a predetermined operation on the reception apparatus. The user then carries out an operation on the GUI screen typically to supply the musical data to a digital audio apparatus connected to the reception apparatus. Typically, the musical data is recorded in the digital audio apparatus.","Incidentally, with regard to a GUI screen for downloading musical data described above, partial picture data and text data which are used as elements to form the GUI screen and unit data (or files) such as audio data to be output as a sound in accordance with a predetermined operation are each handled as an object. The output format of an object is controlled by a scenario description according to a predetermined system. That is to say, by broadcasting the so-called multimedia contents, a GUI screen described above is implemented.","It should be noted that a GUI screen for implementing a function to achieve a certain objective by prescription of described information is referred to as a \u201cscene\u201d. A scene also includes an output such as a sound. An \u201cobject\u201d is defined as unit information such as a picture, a sound or a text with an output format thereof prescribed on the basis of described information. In addition, during transmission, a data file of described information itself is also handled as one of the objects.","For example, as a system to prescribe a description of a content for broadcasting a GUI screen like the one described above, adoption of an MHEG system is conceivable.","In an MHEG prescription, one MHEG content or one MHEG application file typically comprises one or more scenes. A script is described to prescribe transitions between scenes and outputs which are synchronized with typically broadcast pictures of the scenes. In addition, a scene is controlled by a description of a script so that one or more objects of the scene are displayed in a predetermined display format.","In the broadcasting station, the MHEG content described above is created in accordance with broadcast contents by using typically a personal computer. On the personal computer, application software used as the script creation tool or an authoring tool is activated. Such application software is referred to hereafter as an MHEG authoring tool, a generic name given to the software.","Editing work is carried out typically in scene units by using the MHEG authoring tool described above. In general, objects to be displayed for a scene are selected and the editor writes a description of a scenario so as to display the selected objects in desired display formats in the scene. As an alternative, a GUI screen is used as the authoring tool to create a scene and editing results are described as a script.","Incidentally, a concept known as a shared object is prescribed in an MHEG application.","A shared object is a file used as an object which is shared among scenes.","With the contemporary MHEG authoring tool, however, there is provided only a function of merely selecting whether to use or not use a shared object for an MHEG application unit. To put it in detail, it is possible only to select an option to display or not to display a shared object as an object common to all scenes comprising an MHEG application.","Consider an attempt to effectively utilize a shared object. In this case, it is desirable to set any arbitrary shared object to be used or not to be used in each of scenes comprising an MHEG application.","If any arbitrary shared object is to be assigned to a scene instead of being assigned to an MHEG application, the option of using or the option of not using a shared object in a scene must be set by using typically description of an action to turn on or off individual objects created for the object.","In order to set the option by using a description of such a script, it is necessary for the editor to sufficiently understand the description language. Thus, setting the option is a difficult job for the editor. In the end, it is quite within the bounds of possibility that the editor writes an incorrect description. For this reason, almost no editors use such a description to assign any arbitrary shared object to a scene in place of an MHEG application.","In consequence, shared objects are not utilized effectively in the present state of the art. As a result, there are hindrances to diversification of display formats of MHEG contents.","It is therefore an object of the present invention to address the problems described above by providing effective utilization of a shared object so as to allow the shared object to be handled with ease typically in creation of MHEG contents.","In accordance with an aspect of the present invention, there is provided an information processing apparatus for creating content information according to a predetermined specification wherein the content information includes a scene having an object for creating the content information and at least control information for controlling an output format of a scene or an object. The content information defines a shared object which can be shared among a plurality of scenes. The information processing apparatus includes a shared-scene definer operable to define a shared scene as an editing material processible in the information processing apparatus where a shared scene is a virtual scene usable as a scene common to a plurality of scenes, a shared-scene creator operable to create the shared scene by using any arbitrary objects in accordance with a definition generated by the shared-scene definer, a shared-scene settor operable to set a specific shared scene to be used for each of the scenes forming the content information wherein the specific shared scene is selected among shared scenes created by the shared-scene creator, a shared-object settor operable to set an object used in the specific shared scene as a shared object and a control-information describer operable to describe control information for controlling a state of utilization of shared objects in each of the scenes in accordance with the predetermined specification and in dependence on a result of setting the specific shared scene carried out by the shared-scene setting means.","According to the configuration described above, the information processing apparatus functions as an authoring tool for creating content information conforming to a predetermined specification and defines a shared scene which is a virtual scene using a shared object usable as an object common to scenes. During scene editing, an edit operation to set a shared scene to be used for scenes is carried out to allow an object shared by a plurality of scenes to be handled.","Then, after an object used in a shared scene has been set as a shared object, control information for controlling a utilization state of a shared object to be used for scenes in accordance with results of setting the shared scene for each scene is described in a format conforming to the predetermined specification described above.","The present invention will become more apparent from a careful study of the following detailed description of a preferred embodiment with reference to accompanying diagrams.","An information processing apparatus provided by the present invention is used in a system which allows a program to be broadcasted by means of digital satellite broadcasting and information such as musical data or audio data related to the program to be downloaded on the receiver side.","To be more specific, the information processing apparatus provided by the present invention is an authoring system for creating contents used by the broadcasting station as GUI data for typically a downloading operation screen as data appended or synchronized to a program (or video information) using digital satellite broadcasting.","In addition, an authoring system implemented by this embodiment is a system for creating MHEG contents.","It should be noted that the description is given hereafter in the following order:","1 Digital Satellite Broadcasting System","1-1 Overall Configuration","1-2 Operations for a GUI Screen","1-3 Ground Station","1-4 Transmission Format","1-5 IRD","2 Authoring System","2-1 Structure of an MHEG Content","2-2 Concept of a Shared Scene","2-3 Configuration of the MHEG Authoring System","2-4 Typical GUI Screens Displayed as Part of MHEG Authoring Software","2-5 Processing Operations","1 Digital Satellite Broadcasting System","1-1 Overall Configuration","First of all, before explaining an MHEG authoring system implemented by this embodiment, a digital satellite broadcasting system using MHEG contents created by using this MHEG authoring system is explained.",{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 1","b":["1","6","7","8","9"]},"The television program material server  is a server for providing material of an ordinary broadcast program. A musical broadcast transmitted by the television program material server  includes moving pictures and sounds. In the case of a musical broadcasting program, for example, a material of moving pictures and sounds broadcasted by the television program material server  are used as moving pictures and sounds typically for promotion of new songs.","The musical data material server  is a server for providing an audio program by using an audio channel. The material of an audio program is limited to sounds. The musical data material server  transmits materials of audio programs by way of a plurality of audio channels.","In program broadcasting through audio channels, a particular piece of music is broadcasted repeatedly at unit time intervals. Audio channels are independent of each other. A variety of ways to use the audio channels is conceivable. For example, an audio channel is used for broadcasting a number of most recent Japanese pop songs repeatedly at fixed intervals while another audio channel is used for broadcasting a number of most recent foreign pop songs repeatedly at fixed intervals.","The audio additional information server  is a server for providing information on timing of music provided by the musical data material server .","The GUI data server  provides GUI data (or broadcasting content data) for forming a GUI screen used in conjunction with operations carried out by the user. In the case of formation of a GUI screen for downloading music as will be described later, for example, the GUI data server  provides, among other information, picture data and text data used for creating a list page and an information page of pieces of music transmitted from the GUI data server  and data for creating a still picture of an album jacket. In addition, the GUI data server  also provides EPG (Electrical Program Guide) data used for displaying a program in a reception facility .","It should be noted that GUI data conforms to typically the MHEG (Multimedia Hypermedia Information Coding Experts Group) system. The MHEG system is an international standard of scenario description for creation of a GUI screen. According to the MHEG system, multimedia information, procedures, operations and their combination are each taken as an object and, after each object has been coded, a title (such as a GUI screen) is created. In the case of this embodiment, the MHEG-5 system is adopted.","The ground station  transmits pieces of information received from the television program material server , the musical data material server , the audio additional information server  and the GUI data server  by multiplexing the pieces of information with each other.","In this embodiment, video data and audio data received from the television program material server  have been subjected to a compression encoding process according to the MPEG2 (Moving Picture Experts Group 2) system and the MPEG2 audio system respectively. On the other hand, audio data received from the musical data material server  has been subjected to a compression encoding process according to typically either the MPEG2 audio system or the ATRAC (Adoptive Transform Acoustic Coding) system depending on the audio channel.","In the multiplexing process of the pieces of data in the ground station , the data is encrypted by using a key received from a key information server .","It should be noted that a typical internal configuration of the ground station  will be described later.","A signal transmitted by the ground station  by way of a satellite  is received by the reception facility  of every home. The satellite  includes a plurality of transponders mounted thereon. A transponder has a typical transmission power of 30 Mbps. The reception facility  installed in a home comprises a parabola antenna , an IRD (Integrated Receiver Decoder) , a storage device  and a monitor unit .","A remote controller  shown in the figure is used to remotely operate the IRD .","The parabola antenna  receives a signal transmitted by the ground station  by way of the satellite . The received signal is converted into a signal having a predetermined frequency by an LNB (Low Noise Block Down Converter)  installed on the parabola antenna . The signal generated by the LNB  is supplied to the IRD .","General operations carried out by the IRD  include selection of a signal transmitted as a predetermined audio signal among signals received by the parabola antenna  and demodulation of the selected signal to extract video data and audio data as a program and output the video and audio data as video and audio signals respectively. The IRD  also outputs a GUI screen based on GUI data received as multiplexed data in a program. The monitor unit  displays a picture of a program and outputs sounds of the program which have been selected by the IRD . In addition, the monitor unit  is also capable of displaying a GUI screen in accordance with an operation carried out by the user as will be described later.","The storage device  is used for storing audio data (or musical data) downloaded by the IRD . Not specially limited to a particular storage type, the storage device  can be implemented by an MD (Mini Disc) recorder\/player, a DAT recorder\/player and a DVD recorder\/player. In addition, the storage device  can also be implemented by a personal computer, which is capable of storing audio data in recordable media such as the representative CD-ROM, besides a hard disc.","Furthermore, the reception facility  provided by this embodiment may also employ an MD recorder\/player A () as the storage device  shown in . As shown in , the MD recorder\/player A has a data interface conforming to IEEE1394 data transmission specifications.","The IEEE1394 MD recorder\/player A shown in  is connected to the IRD  by an IEEE1394 bus . Thus, audio data such as music received by the IRD  in this embodiment, that is, downloaded data, can be recorded directly with its compressed\/encoded state of the ATRAC system sustained as it is. In addition, with the IEEE1394 MD recorder\/player A connected to the IRD  by an IEEE1394 bus , it is also possible to record jacket data (or still-picture data) of the album and text data such as lyrics besides the audio data.","The IRD  is capable of communicating with an accounting server  through typically a telephone line . An IC card for recording various kinds of information as will be described later is inserted into the IRD . When audio data of music is downloaded, for example, history information on the audio data is recorded onto the IC card. The history information recorded on the IC card is transmitted to the accounting server  at predetermined times and with predetermined timing by way of the telephone line . The accounting server  carries out charging by setting a transmission fee according to the history information received from the IRD . The transmission fee is then charged to the user.","The ground station  transmits video and audio data used as a material of a musical program broadcast from the television program material server , audio data used as a material of the audio channel from the musical data material server , audio data from the audio additional information server  and GUI data from the GUI data server  by multiplexing the pieces of data with each other.","Then, when this broadcast is received by the reception facility  of a home, a program of a selected channel can be watched typically on a monitor unit . In addition, an EPG (Electrical Program Guide) screen is displayed as a GUI Screen to allow the user to search the screen for a program. In the second place, by carrying out necessary operations for an EPG screen for a special service the user is capable of receiving a service other than ordinary programs presented by the broadcasting system to the user.","By carrying out an operation for a displayed GUI screen for providing a service of downloading audio (or musical) data, for example, the user is capable of downloading the audio data of a desired piece of music and storing and keeping the data in the storage device .","It should be noted that this embodiment exhibits interactivity in a data service broadcasting system for rendering special services other than the ordinary program broadcasts given in response to operations carried out for a GUI screen like the one described above. Such an interactive data service broadcasting system is called an interactive broadcasting system.","1-2 Operations for a GUI Screen","The following description briefly explains an example of the interactive broadcasting system and typical operations to be carried out for a GUI screen, with reference to . In particular, downloading of musical data (or audio data) is explained.","The description begins with an explanation of operation keys on a remote controller  for use by the user to remotely carry out an operation on the IRD  with reference to . Specifically, main keys are explained.",{"@attributes":{"id":"p-0079","num":"0078"},"figref":"FIG. 3","b":["64","101","102","103","104","105","106"]},"The power-supply key  is operated to turn the power supply of the IRD  on and off. A numeric key  is operated to specify a channel or enter a digit of a number to typically a GUI screen when a numeric input is required.","The screen display switching key  is operated typically for switching the monitor display from an ordinary broadcast screen to an EPG screen and vice versa. Assume that an EPG screen is called by operating the screen display switching key . With the EPG screen displayed, a key provided on the EPG key panel unit  is operated to search the EPG screen for a program using a display screen of an electronic program guide. An arrow key provided in the EPG key panel unit  can be operated also for moving a cursor on the GUI screen for rendering services to be described later.","The interactive switching key  is operated for switching the monitor display from an ordinary broadcast screen to an GUI screen for rendering a service appended to a broadcast program and vice versa.","The channel key  is operated to increase or decrease the number of a channel selected by the IRD .","It should be noted that the remote controller  provided in this embodiment has a configuration that allows a variety of operations to be carried out against the monitor unit  and includes a variety of keys for the operations. However, description of the keys to be operated for the monitor unit  is omitted.","Next, an example of operations carried out for a GUI screen is explained by referring to .","When a broadcast is received by the reception facility  and a desired channel is selected, a display screen like one shown in  appears on the monitor unit . As shown in the figure, the screen displays a moving picture based on program material received from the television program material server . That is to say, the contents of an ordinary program are displayed. In this example, a musical program is displayed. In addition, appended to this musical program is an interactive broadcast to render a service of downloading audio data of music.","With the musical program displayed on the screen, assume for example that the user operates the interactive switching key  of the remote controller . In this case, the monitor display is switched to a GUI screen like one shown in  for downloading audio data.","In the first place, in a television program display area A on the left top corner of this GUI screen, a reduced picture of video data of  received from the television program material server  is displayed.","In addition, on the right top corner of the GUI screen, a list B of pieces of channel music broadcasted through audio channels is displayed. The left bottom corner of the GUI screen is allocated as a text display area C and a jacket display area D. On the right side of the GUI screen, a lyrics display button , a profile display button , an information display button , a reservation-recording button , a completed-reservation-table display button , a recording-history-display button  and a download button  are displayed.","While looking at the names of the pieces of music on the list B, the user searches the list B for a piece of music which the user is interested in. If the user finds a piece of music of interest, the user moves the cursor to the display position of the piece of music of interest using the arrow key and carries out an enter operation typically by pressing the center position of the arrow key . Such an operation, including moving the cursor to a displayed position and carrying out an enter operation, is hereafter referred to simply as an operation to press the button or pressing the button.","By doing so, the user is capable of listening to the piece of music indicated by the cursor on a trial basis. Since the same music is broadcasted repeatedly during a predetermined unit period of time through any audio channel, it is possible to output the sound of the music of an audio channel selected by operating the IRD  and to listen to the selected music by switching the monitor display from an original screen to the GUI screen with the original screen kept in the television program area A as it is. At that time, the still picture of the CD jacket of the selected music is also displayed on the jacket display area D as well.","In addition, if the user presses the lyrics display button , the lyrics of the selected music are displayed in the text display area C with timing synchronized to the audio data. By the same token, if the profile display button  is pressed, the profile of an artist for the music is displayed in the text display area C. Likewise, if the information display button  is pressed, information on the music such as a concert for the music is displayed on the text display area C. In this way, the user is capable of knowing what music is broadcasted at the present time and, furthermore, detailed information on each of the pieces of music.","When the user wants to buy the piece of music of interest to the user, the user presses the download button . As the download button  is pressed, the audio data of the selected music is downloaded and stored in the storage device . It is also possible to download other information such as the lyrics, the profile of the artist and the still picture of the jacket along with the audio data of the music.","Each time the audio data of music is downloaded in this way, its history information is stored in an IC card inserted into the IRD . Information stored in the IC card is transmitted to the accounting server  typically once a month to be used for computing a fee for data services rendered to the user. In this way, the copyright for the downloaded music can be protected.","When the user wants to make an advance reservation for downloading, the user presses the reservation recording button . As the reservation recording button  is pressed, the monitor display is switched from the GUI screen to a screen fully used for displaying a list of all pieces of music which can be reserved. The list comprises pieces of music obtained as a result of a search operation carried out typically at hourly or weekly intervals and for each channel. The user then selects a piece of music to be subjected to reserved downloading from the list. Its related information is stored in the IRD . When the user wants to confirm a piece of music already subjected to reserved downloading, the user presses the completed-reservation-table display button  to use the entire screen for displaying a table of pieces of music already subjected to reserved downloading. A piece of music subjected to reserved downloading as described above is downloaded to the IRD  and stored in the storage device  at a reserved time.","The user is also capable of confirming a piece of music already downloaded. In this case the user presses the recording history button  to use the entire screen for displaying a list of already downloaded pieces of music.","As described above, in the reception facility  of the system to which the present invention is applied, a list of pieces of music is displayed on the GUI screen of the monitor unit . Then, by selecting a piece of music from the list displayed on the GUI screen, the user is capable of listening to the selected music and viewing the lyrics and the profile of the artist of the music on a trial basis. The user is also capable of displaying a history of reserved downloading showing a list of pieces of music to be downloaded and a list of pieces of music already downloaded.","A change may be made to the display on a GUI screen and a sound output may be programmed in response to an operation carried out by the user for the GUI screen. Such changes or modifications are implemented by prescribing a relation among objects through a scenario based on the MHEG system described earlier. In this case, an object is picture data serving as parts corresponding to the buttons or material data displayed in the display areas displayed in .","In addition, in this specification, a scene is an environment in which a format to output information to achieve a certain purpose such as the display of a picture or an operation to output a sound is implemented by prescription of a relation among objects through description of a scenario. A file containing the description of a scenario itself is also handled as one of the objects forming a scene.","As described above, in a digital satellite broadcasting system to which the present invention is applied, a broadcast program is distributed by communication. In addition, audio data of music is also broadcasted through a plurality of audio channels. The user is allowed to search a list of distributed pieces of music for a desired one and to store the audio data of the desired music in the storage device  with ease.","It should be noted that a variety of conceivable implementations of services other than the service of providing programs in the digital satellite broadcasting system are not limited to the service of downloading of musical data described above. As a conceivable example of such implementation, there is provided the so-called television shopping whereby a products-introducing program is broadcasted and a GUI screen is used to make a purchasing contract.","1-3 Ground Station","An overview of the digital satellite broadcasting system implemented by an embodiment of the present invention has been described so far. The following description explains the system in more detail. The description begins with an explanation of the configuration of the ground station  with reference to .","The explanation given thereafter is based on the following assumption.","In the transmission of data from the ground station  to the reception facility  by way of the satellite  in this embodiment, a DSM-CC (Digital Storage Media-Command and Control) protocol is adopted.","As is already known, the DSM-CC (MPEG-part ) system prescribes commands or a control system for retrieving an MPEG-encoded bit stream stored in DSM (Digital Storage Media) or storing such a stream in the DSM typically by way of some networks. In this embodiment, the DSM-CC system is adopted as a transmission standard in the digital satellite broadcasting system.","In order to transmit a content (that is, a set of objects) of a data broadcasting service such as a GUI screen in accordance with the DSM-CC system, it is necessary to define the description format of the content. In this embodiment, for definition of this description format, the MHEG system explained earlier is embraced.","In the configuration of the ground station  shown in , a television program material cataloging system  catalogs material data obtained from the television program material server  in an AV server . The material data is supplied to a television program output system  in which video data is compressed in accordance with typically the MPEG2 system while audio data is converted into packets conforming to typically the MPEG2 audio system. Data output by the television program output system  is supplied to a multiplexer .","A musical data material cataloging system  receives material data, or audio data, from the musical data material server land supplies the material data, to an MPEG2 audio encoder A and an ATRAC audio encoder B. In the MPEG audio encoder A, the audio data is subjected to an encoding process or, to be more specific, a compression-encoding process, before being cataloged in an MPEG audio server A. By the same token, in the ATRAC audio encoder B, the audio data is subjected to an encoding process or, to be more specific, a compression-encoding process, before being cataloged in an ATRAC audio server B.","The MPEG audio data cataloged in the MPEG audio server A is then supplied to an MPEG audio output system A to be converted into packets before being supplied to the multiplexer . Likewise, the ATRAC audio data cataloged in the ATRAC audio server B is then supplied to an ATRAC audio output system B as quadruple-speed ATRAC data to be converted into packets before being supplied to the multiplexer .","An audio additional information cataloging system  catalogs material data, that is, audio additional information, received from the audio additional information server  into an audio additional information data base . The audio additional information cataloged in the audio additional information data base  is then supplied to an audio additional information output system  to be converted into packets before being supplied to the multiplexer .","A GUI material cataloging system  catalogs material data, that is, GUI data, received from the GUI data server  into a GUI material data base .","The GUI material data cataloged in the GUI material data base  is then supplied to a GUI authoring system  for carrying out processing to convert the GUI material data into data of a format that can be output as a GUI screen, such as the scene described earlier in .","That is to say, if the scene is a GUI screen for downloading music, for example, data supplied to the GUI authoring system  is still picture data of an album jacket, text data of lyrics or the like or sound data to be output in accordance with an operation.","The pieces of data cited above are called monomedia data. In the GUI authoring system , an MHEG authoring tool is used to encode the pieces of monomedia data so as to allow them to be handled as objects.","Then, an MHEG-5 content is created along with a scenario description file (referred to as a script) prescribing a relation among objects so as to obtain a display format of a scene (that is, a GUI screen) like the one explained earlier by referring to  and a format of picture sounds output in response to an operation.","As shown in , the GUI screen also displays picture\/sound data comprising MPEG video data based on material data received from the television program material server  and MPEG audio data based on musical material data received from the musical data material server  in an output format according to an operation.","Thus, as the aforementioned scenario description files, the GUI authoring system  handles picture\/sound data based on material data received from the television program material server , MPEG audio data based on musical material data received from the musical data material server  and audio additional information received from the audio additional information server  as objects when necessary and creates an MHEG script for prescribing the relation among the objects.","It should be noted that data of an MHEG content transmitted by the GUI authoring system  includes script files, a variety of still-picture data files each handled as object and text files (and audio data files). The still picture data is data of 720 pixels\u00d7480 pixels compressed in accordance with the JPEG (Joint Photograph Experts Group) system whereas the text data is a file with a size not exceeding typically 800 characters.","Data containing MHEG content obtained in the GUI authoring system  is supplied to the DSM-CC encoder .","The DSM-CC encoder  converts the data received from the GUI authoring system  into a transport stream with a format that can be multiplexed into a data stream of video and audio data in MPEG2 format. The transport stream (TS) is made into a packet and supplied to the multiplexer .","The multiplexer  multiplexes video and audio packets received from the television program output system , audio packets received from the MPEG audio output system A, quadruple-speed audio packets received from the ATRAC audio output system B, audio additional information packets received from the audio additional information output system  and GUI data packets received from the GUI authoring system  along the time axis and encrypts them in accordance with key information output by the key information server  shown in .","The multiplexed data output by the multiplexer  is supplied to a wave output system  which typically carries out processing such as addition of error correction codes, and modulation and frequency transformation before supplying the multiplexed data to the satellite  by way of an antenna.","1-4 Transmission Format","The following description explains a transmission format which is adopted by this embodiment and prescribed on the basis of the DSM-CC system.",{"@attributes":{"id":"p-0124","num":"0123"},"figref":["FIG. 6","FIG. 6"],"b":["1","2","1","2"]},"As shown in , in the event between the points of time t and t, a program having predetermined contents A is broadcasted as a broadcast of an ordinary moving-picture program. In an event starting at the point of time t, contents A are broadcasted. In this ordinary program, a moving picture and sounds are broadcasted.","In this example, 10 channels, namely, CH to CH, are provided to serve as MPEG audio channels () to (). Through each of the audio channels CH, CH, CH, - - - , CH, the same music is transmitted repeatedly during the broadcasting time of an event. To be more specific, during the period of the event between the points of time t to t, music B, music C and so on are transmitted repeatedly through audio channels CH, CH and so on respectively. Through the last audio channel CH, music K is transmitted repeatedly. The repeated transmission described is also carried out through each of quadruple-speed ATRAC audio channels () to ().","That is to say, an MPEG audio channel indicated by a number enclosed in parentheses ( ) as shown in the timing diagram of  is used for transmitting the same music as a quadruple-speed ATRAC audio channel indicated by the same number enclosed in parentheses ( ). In addition, audio additional information indicated by a channel number enclosed in parentheses ( ) is added to audio data transmitted through an audio channel indicated by the same number enclosed in parentheses ( ). Furthermore, still-picture data and text data transmitted as GUI data are also formed for each audio channel. As shown in , pieces of still-picture data and text data are multiplexed in transmitted MPEG2 transport packets on a time-division basis. As shown in , the packets are demultiplexed in the IRD  to reconstruct the original GUI data based on header information of each of the packets.","There is at least GUI data among pieces of transmitted data shown in  to H. As previously discussed, this GUI data is used in data services, such as broadcasting or interactive broadcasting of MHEG contents synchronized with TV broadcasting or audio broadcasting. This GUI data is logically formed in accordance with the DSM-CC system as follows. The formation of the GUI data is exemplified only by data of a transport stream output by the DSM-CC encoder .","As shown in , files to be transmitted in a data broadcasting service in this embodiment in accordance with the DSM-CC system are all included in a root directory named Service Gateway. Types of objects contained in the Service Gateway include directories, files, streams and stream events.","Files are individual data files for storing, among other information, a still picture, a sound, a text and a script described in conformity with the MHEG system.","A stream typically includes information linked to another data service and an AV stream such as MPEG video data used as a TV program material, audio data, MPEG audio data used as a musical material and ATRAC audio data.","A stream event includes links and time information.","A directory is a folder which is a collection of pieces of data related to each other.","As shown in , in the DSM-CC system, these pieces of unit information and the Service Gateway itself are each handled as a unit known as an object which is converted into a format referred to as a BIOP message.","It should be noted that, in the explanation of the present invention, the classification of objects into files, streams and stream events is not essential. Thus, in the following description, the file is used as a representative object.","In addition, in the DSM-CC system, a data unit known as a module shown in  is generated. The module comprises one or more objects which are each converted into a BIOP message as shown in . The module is a variable-length data unit including an additional BIOP header. This data unit is a buffering unit of data received on the reception side to be described later.","The DSM-CC system does not specially prescribe nor limit a relation among objects in the case of a module formed from a plurality of objects. In other words, in an extreme case, a module can be formed from 2 or more objects in scenes not related to each other at all without violating a prescription based on the DSM-CC system.","In order to transmit data in the form of sections prescribed by an MPEG2 format, the module is split into data units each basically having a fixed length as shown in . This data unit is referred to as a mechanical block. It should be noted, however, that the last block in the module is not necessarily required to have a fixed length. The reason why the module is split into blocks in this way is that, in the MPEG2 format, there is a prescription stating that 1 section shall not exceed 4 KB.","In this case, what is meant by a section is a data unit defined as a block as described above.","As shown in , a block obtained as a result of division of a module described above is converted into a message known as a DDB (Download Data Block) to which a header is added.","Concurrently with the conversion of a block into a DDB described above, control messages called a DSI (Download Server Initiate) and a DII (Download Indication Information) are generated.","The DSI and the DII are information required to acquire a module from data received by the IRD  on the reception side. The DSI includes mainly an identifier of a data transmission system known as a carousel () or module and information on the carousel as a whole, including the time the carousel takes to make 1 rotation and a time-out value of the carousel rotation. The information may also include data on the location of the root directory (Service Gateway) of the data services in the case of an object carousel system.","The DII is information corresponding to each module included in a carousel. To be more specific, the DII is information such as the size and the version of each module and the time-out value of the module.","Then, as shown in , the 3 types of messages, namely, the DDB, the DSI and the DII, are output periodically and repeatedly by associating the messages with data units. In this way, the receiver is capable of receiving a module including an object required to obtain typically the desired GUI screen (or scene) at any time.","In this specification, the transmission system is called a carousel system if we compare the system with a merry-go-round. The data transmission technique represented by a model shown in  is known as a carousel.","A carousel may include a plurality of modules. For example, a plurality of modules required in a data service can be transmitted by using a carousel.","In addition, the carousel system is divided into levels, namely, a data carousel system and an object carousel system. The object carousel system is capable of handling a directory structure wherein an object having an attribute of a file, a directory, a stream, a service gateway or the like is transmitted as data using a carousela significant difference from the data carousel system. In the system implemented by this embodiment, the object carousel system is embraced.",{"@attributes":{"id":"p-0148","num":"0147"},"figref":"FIG. 9"},"Normally, an MHEG application file serving as an entrance to a service domain is always a file called app\/startup placed right below the Service Gateway.","Basically, beneath the service domain (Service Gateway), application directories app, app, - - - , appN exist. Beneath each of the application directories, an application file called startup and directories of scenes composing the application exist. The directories of scenes are scene, scene and so on. Beneath each of the scene directories, an MHEG scene file and content files composing the scene exist.","In addition, broadcast data including GUI data transmitted by using a carousel as described above, that is, data produced by the multiplexer  shown in , is output in the form of a transport stream which has a typical structure like one shown in .",{"@attributes":{"id":"p-0152","num":"0151"},"figref":"FIG. 10A"},"Each of the transport packets is shown in . As shown in the figure, a transport packet comprises a header, an adaptation field for including additional information in this particular individual packet and a payload (or a data area) representing contents of the packet including video and audio data.","In actuality, the header is typically 4 bytes in length. As shown in , the header always includes a synchronization byte at the beginning. At predetermined positions behind the synchronization byte, there are stored a PID (Packet_ID) serving as identification information of the packet, scramble control information indicating absence\/presence of a scramble and adaptation field control information indicating, among others, absence\/presence of the subsequent adaptation field and the payload.","The reception apparatus carries out a descrambling process based on these pieces of control information in packet units. Then, a demultiplexer can be used for separating and extracting needed packets such as video and audio data. In addition, it is also possible to reproduce time information used as a reference of a synchronous playback operation of video and audio data.","As is obvious from the description given so far, a transport stream comprises multiplexed packets of audio and video data pertaining to a plurality of channels. In addition, a signal called PSI (Program Specific Information) for implementing selection of a station, information (EMM\/ECM) required for limited reception and SI (Service Information) for implementing services such as an EPG are also multiplexed at the same time in the transport stream. The limited reception is a reception function for determining whether or not it is possible to receive data through a fee-charging channel in dependence on the condition of a contract made with an individual.","The PSI which comprises 4 tables is explained by referring to . Each of the tables is expressed in a format conforming to an MPEG system known as a section format.",{"@attributes":{"id":"p-0158","num":"0157"},"figref":"FIG. 11A"},"The same contents of the NIT are multiplexed for the entire carrier. The NIT includes transmission parameters such as a plane of polarization, a carrier frequency and a convolution rate as well as a list of channels superposed thereon. The PID of the NIT is set at 0x0010.","The same contents of the CAT are also multiplexed for the entire carrier. The CAT includes the PID of an EMM (Entitlement Management Message) packet which is individual data such as contract information and an identification of the limited-reception system. The PID of the CAT is set at 0x0001.",{"@attributes":{"id":"p-0161","num":"0160"},"figref":"FIG. 11B"},{"@attributes":{"id":"p-0162","num":"0161"},"figref":"FIG. 11C"},"PMTs with contents varying from channel to channel are multiplexed. For example, the PID of a PMT shown in  is specified by a PAT. As shown in the figure, the PMT includes components (such as video and audio data) composing the channel and the PID of an ECM (Encryption Control Message) packet required for descrambling.","The SI (not shown) is a table with a section format like the PSI. The table includes information on an EPG. On the IRD side, necessary information is extracted from the table and displayed on a screen.","Representative tables of the PSI are an SDT (Service Description Table) and an EIT (Event Information Table).","The SDT represents information on a channel including the number, the name and contents of the channel. Its PID is set at 0x0011.","On the other hand, the EIT represents information on a program including the name, the start time, the outline of the program and a genre. Its PID is set at 0x0012.","1-5 IRD","Next, a typical configuration of the IRD  provided in the reception facility  is explained by referring to .","In the IRD  shown in the figure, a signal is received by an input terminal T, being supplied to a tuner\/front-end unit . The signal has been subjected to a predetermined frequency-transformation process in the LNB  of the parabola antenna .","The tuner\/front-end unit  also receives a setting signal including transmission parameters from the CPU (Central Processing Unit) . The setting signal is used to determine the frequency of a carrier to be received. The tuner\/front-end unit  then carries out processing such as bitabi demodulation and error correction to obtain a transport stream.","The transport stream obtained by the tuner\/front-end unit  is supplied to a descrambler . In addition, the tuner\/front-end unit  also acquires a PSI packet from the transport stream to update its information on selection of a station. The tuner\/front-end unit  supplies the component PID of each channel obtained from the transport stream to typically the CPU  which uses the PID for processing the received signal.","The descrambler  receives descrambler-key data stored in an IC card  by way of the CPU . A PID is set by the CPU . Then, the descrambler  carries out descramble processing based on this descramble key data and the PID, supplying a result of the descramble processing to a transport unit .","The transport unit  comprises a demultiplexer  and a queue  which is typically implemented by a DRAM or the like. The queue  is an array of a plurality of memory areas each corresponding to a module unit. In the case of this embodiment, for example, the array comprises 32 memory areas. Thus, information of up to 32 modules can be stored in the queue .","The operation of the demultiplexer  is explained briefly as follows. In accordance with a filter condition set by a DeMUX driver  employed in the CPU , a necessary transport packet is extracted from the transport stream received from the descrambler  and, if necessary, the queue  is used as a work area to obtain pieces of data with formats like the ones shown in . The pieces of data are then supplied to their respective functional circuits requiring them.","The MPEG video data and the MPEG audio data are separated by the demultiplexer  and supplied to an MPEG2 video decoder  and an MPEG audio decoder  respectively. Individual packets of the separated video and audio data are supplied to their respective decoders in a format known as a PES (Packet Elementary Stream).","As for data of MHEG contents in the transport stream, the demultiplexer  separates and extracts the data from the transport stream in transport-packet units and stores them in appropriate memory areas in the queue  so as to collect the data for each module. The data of MHEG contents collected for each module is then written into a DSM-CC buffer  of a main memory  to be stored there by way of a data bus under control executed by the CPU .","In addition, also in the case of the quadruple-speed ATRAC data (that is, compressed audio data) in a transport stream, necessary data is separated and extracted by the demultiplexer  typically in transport-packet units which are then output to an IEEE1394 interface . In addition to audio data, video data and a variety of command signals or the like can also be output by way of the IEEE1394 interface .","The MPEG video data having a PES format supplied to the MPEG2 video decoder  is subjected to a decoding process according to the MPEG2 format with a memory A used as the work area. The decoded video data is then supplied to a display processing unit .","In addition to the decoded video data received from the MPEG2 video decoder , the display processing unit  also receives video data such as a GUI screen for data services obtained from an MHEG buffer  of the main memory  as will be described later. In the display processing unit , the video data received thereby is subjected to necessary signal processing for converting the data into an analog audio signal conforming to a predetermined television system. The analog audio signal is then output to an analog video output terminal T.","By connecting the analog video output terminal T to a video input terminal of the monitor unit , a screen like the one shown in  can be displayed on the monitor unit .","The PES MPEG audio data supplied to the MPEG2 audio decoder  is subjected to a decoding process according to the MPEG2 format with the memory A used as a work area. The decoded video data is supplied to a D\/A converter  and an optical digital output interface .","In the D\/A converter , the decoded video data received thereby is converted into an analog audio signal which is then supplied to a switch circuit . The switch circuit  switches the signal path so as to supply the analog audio signal to either an analog audio output terminal T or an analog audio output terminal T.","The analog audio output terminal T is connected to an audio input terminal of the monitor unit . On the other hand, the analog audio output terminal T is a terminal for outputting downloaded music as an analog signal.","In addition, the optical digital output interface  converts digital audio data received thereby into an output optical digital signal. In this case, the optical digital output interface  conforms typically to the IEC 958.","The main memory  is used as a work area in various kinds of control processing carried out by the CPU . In this embodiment, the main memory  includes areas used as the DSM-CC buffer  and the MHEG buffer  described earlier.","The MHEG buffer  is a work area used for creating picture data (such as picture data of a GUI screen) generated in accordance with a script conforming to the MHEG system. The picture data generated by using the MHEG buffer  is supplied to the display processing unit  by way of a bus line.","The CPU  executes overall control in the IRD . Thus, the CPU  also controls the separation and the extraction of data in the demultiplexer .","The CPU  also decodes data of MHEG contents acquired thereby in order to form a GUI screen (or a scene) in accordance with described contents of a script and output the screen.","In order to accomplish the functions described above, the CPU  employed in this embodiment is typically provided with at least the DeMUX driver , a DSM-CC decoder block  and an MHEG decoder block  in addition to a control processing unit . In this embodiment, among components of the CPU , at least the DSM-CC decoder block  and the MHEG decoder block  are implemented by software.","The DeMUX driver  sets a filter condition in the demultiplexer  on the basis of the PID of an input transport stream.","The DSM-CC decoder block  functions as a DSM manager, reconstructing data of MHEG contents for a module unit stored in the DSM-CC buffer . In addition, the DSM-CC decoder block  also carries out processing related to a necessary DSM-CC decoding process in accordance with accesses from the MHEG decoder block .","The MHEG decoder block  carries out decode processing for outputting a scene by accessing data of MHEG contents in the DSM-CC buffer  obtained by the DSM-CC decoder block , that is, data of an MHEG content obtained in the DSM-CC buffer . That is to say, the MHEG decoder block  creates a scene by implementing a relation among objects prescribed by a script file of the MHEG content. In the creation of a GUI screen used as the scene, the MHEG buffer  is used to generate data of the GUI screen in accordance with the contents of the script file.","As an interface between the DSM-CC decoder block  and the MHEG decoder block , a U-U API (DSM-CC U-U API (Application Portability Interface)) is adopted.","The U-U API is an interface used by a client (the MHEG decoder block ) for allowing access to a DSM Manager object which is an object for implementing a DSM function (the DSM-CC decoder block ). To be more specific, the U-U API is an API for allowing structural access to treat objects each having an attribute like a file system. Examples of such objects are the Service Gateway, directories, files, streams and stream events which are included in the carousel.","Thus, access to an object included in the carousel can be made through the API by merely specifying a bus name without the necessity for a program (or a client) using the carousel to be concerned with a carousel reception operation.","In addition, the U-U API is a set of interfaces prescribed to be usable without regard to a data transfer system at a low layer. Thus, a program utilizing this API has a merit of an ability to use this API in any data transfer system providing the U-U API.","The following description explains a typical operation to extract a desired object required for creation of a scene from a transport stream in accordance with control executed by the CPU .","In the DSM-CC protocol, an IOR (Interoperable Object Reference) is used for indicating the location of an object in a transport stream. An IOR includes an identifier corresponding to a carousel for finding the object, an identifier of a module including the object (hereinafter \u201cmodule id\u201d), an identifier for identifying the object in the module (hereinafter \u201cobject key\u201d) and a tag for identifying a DII having information on the module including the object (hereinafter \u201cassociation tag\u201d).","The DII having information on the module includes the module id and the association tag for each module.","After an IOR extracted from a transport stream is identified by the CPU , the following processes are carried out for receiving and separating objects indicated by the IOR.","1. An ES (elementary stream) loop of the PMT in a carousel is searched for an elementary stream having the same value as the associationtag of the IOR to obtain a PID. The ES having this PID includes a DII.","2. This PID and a tableidextension are set in the demultiplexer  as a filter condition. Under this condition, the demultiplexer  then separates the DII and outputs it to the CPU .","3. In the DII, an associationtag of a module indicated by a moduleid included in the IOR is set.","4. The ES loop of the PMT is searched for an ES having the same value as the associationtag described above and a PID is obtained. The target module is included in an ES having this PID.","5. The demultiplexer  carries out filtering using the PID and the moduleid as a filter condition. A transport packet separated and extracted in accordance with this filter condition is stored in a proper memory area (an array) in the queue  to eventually form a target module.","6. A target object corresponding to an objectkey included in the aforementioned IOR is taken out from the target module. The target object is written into a predetermined area of the DSM-CC buffer .","Typically, the above operation is carried out repeatedly to collect target objects and store them in the DSM-CC buffer . In this way, an MHEG content for creating a required scene is obtained.","A man-machine interface  receives a command signal transmitted by a remote controller , supplying the signal to the CPU . The CPU  then carries out necessary control processing to accomplish an apparatus operation according to the command signal received from the man-machine interface .","An IC card  is inserted into the IC card slot . The CPU  writes and reads out information into and from the IC card .","The modem  is connected to the accounting server  by a telephone line  and controlled by the CPU  to allow the IRD  to communicate with the accounting server .","The following description complementarily explains the flow of a signal serving as a video\/audio source in the IRD  with reference to the display format explained earlier by referring to .","In processing to output an ordinary program shown in , MPEG video data and MPEG audio data required for the program are extracted from an input transport stream and then subjected to their respective decoding processes. Subsequently, the MPEG video data and the MPEG audio data are output to the analog video output terminal T and the analog audio output terminal T respectively to have the monitor unit  display a picture and generate sounds of the broadcast program.","In processing to output a GUI screen shown in , on the other hand, data of an MHEG content required for the GUI screen (or a scene) is separated and extracted by a transport unit  from an input transport stream and supplied to the DSM-CC buffer . Then, the DSM-CC decoder block  and the MHEG decoder block  function to create picture data of the scene (the GUI screen) in the MHEG buffer  by using the extracted data. Subsequently, the picture data is supplied to the analog video output terminal T by way of a display processing unit  to display the GUI screen on the monitor unit .","Assume that a piece of music is selected from the musical list B displayed on the GUI screen shown in  and the audio data of the selected music is listened to by the user on a trial basis. In this case, the MPEG audio data of the selected music is generated by the demultiplexer . The MPEG audio data is then output to the monitor unit  as an analog audio signal by way of an MPEG audio decoder , a D\/A converter , a switch circuit  and the analog audio output terminal T.","Assume that the download button  displayed on the GUI screen shown in  is pressed to download musical audio data. In this case, the musical audio data to be downloaded is extracted by the demultiplexer  and supplied to the analog audio output terminal T, the optical digital output interface  or the IEEE1394 interface .","Assume that an MD recorder\/player A of  conforming to the IEEE1394 specifications is connected to the IEEE1394 interface . In this particular case, the demultiplexer  extracts quadruple-speed ATRAC data of the downloaded music and outputs the data to the IEEE1394 interface  to be recorded onto a disc mounted on the MD recorder\/player A. At the same time, the demultiplexer  also extracts still picture data of the album jacket and text data such as the lyrics and the profile of an artist from the transport stream, and supplies the data to the MD recorder\/player A by way of the IEEE1394 interface . It should be noted that the data in the transport stream has been compressed in accordance with typically the JPEG system. The still picture data and the text data are recorded into a predetermined area in a disc mounted on the MD recorder\/player A.","2 Authoring System","2-1 Structure of MHEG Content","Next, an MHEG authoring system provided by this embodiment is explained.","In the case of , the MHEG authoring system of this embodiment explained below corresponds to the GUI authoring system . It should be noted, however, that since a personal computer is actually used for creating or obtaining GUI material data (such as a text file or a picture used as an object) in order to carry out authoring work, functionally, the GUI material cataloging system  and the GUI material data base  can be included in addition to the GUI authoring system .",{"@attributes":{"id":"p-0219","num":"0218"},"figref":"FIGS. 13 and 14"},"To be more specific,  is a diagram showing 3 scenes, namely, MHEG scene  to MHEG scene . Each of the scenes is formed as a combination of objects pasted on a picture area with a size of typically one picture.","It should be noted that an MHEG scene is a scene conforming to the MHEG system. In this specification, a scene is referred to as an MHEG scene in some cases in order to distinguish it from a shared scene to be described later. Conversely speaking, in the following description, by a scene, an MHEG scene is meant.","As described earlier, an object is interpreted as, among other things, picture information such as a JPEG or GIF still-picture file, text information, a part picture file such as an operation button and an audio data file. In the case of this embodiment, the monitor display is switched from one scene to another in synchronization with typically a TV broadcast or switched by an operation of the switch button. In this embodiment, switching of the monitor display from one scene to another is referred to as a transition.","Assume for example that the 3 scenes, namely MHEG scene  to MHEG scene , are related to each other in accordance with a consistent relation such as a relation allowing a transition to occur between any two of them. The relation among them is arranged into a scenario unit (or MHEG application unit).","The scenario used in this case has a meaning different from a description file used as a script. That is to say, a scenario implies a content unit at a hierarchical layer of an MHEG application. A scenario unit is typically provided with pieces of information such as a data type, customized info, a scene number and information called an ES name, which is the name of the elementary stream to which the present scenario is output, and is formed to include 1 or more MHEG scenes. It should be noted that the datatype is the data type of the present scenario. An example of the data type is \u201cmheg\u201d. The customizedinfo is customized information and the scenenumber is the number of scenes included in the scenario.","A set of scenarios which are each an arrangement of scenes forms an MHEG content as shown in .","In an example shown in the figure, the MHEG content comprises 3 scenarios, namely, scenarios SC, SC and SC. Scenario SC comprises 3 scenes, namely, scenes ,  and . The remaining scenarios SC and SC comprise MHEG scenes  and  respectively.","As shown in , objects are used for creating a scene. According to MHEG specifications, a shared object can also be used.","A shared object is an object that can be used by being shared among a plurality of scenes forming an MHEG application.","An example of shared objects is shown in . As shown in the figure, 1 MHEG application comprises 2 scenes, namely, MHEG scenes  and . The MHEG content includes 6 prepared objects, namely, objects  to  and  to  in addition to 3 shared objects, namely, shared objects  to .","Objects  to  are used for creating only MHEG scene  while objects  to  are used for creating only MHEG scene .","On the other hand, shared objects  to  are each an object that can be set as an object usable and sharable by both MHEG scenes  and .","Thus, in the case of the example shown in , MHEG scene  can be created by using objects  to  and shared objects  to  while MHEG scene  can be created by using objects  to  and shared objects  to .","As explained earlier in the description of the conventional apparatus, the interface of the contemporary MHEG authoring tool allows the user to carry out only editing work of setting a flag indicating whether or not a shared object is to be used for all of a plurality of scenes constituting an MHEG application even if a shared object can be set.","In the case of the example shown in , if shared objects  to  are set for use, for instance, it is possible to obtain only states in which shared objects  to  are always used and displayed for MHEG scenes  and . If shared objects  to  are set for no use, on the other hand, it is possible to obtain only states in which shared objects  to  are not displayed for both MHEG scenes  and .","Conversely speaking, it is impossible to set usage of objects in which, for example, shared objects  and  are selected for MHEG scene  whereas shared object  is selected for MHEG scene . In an attempt to carry out editing work using a shared object with a high degree of freedom, it becomes necessary to write a script for controlling the shared objects themselves. For this reason, the editor must be proficient in the script language as has been described earlier.","As will be described below, the MHEG authoring tool provided by this embodiment is configured to provide a simple interface which can be used by anybody but allows a shared object to be set for a scene with a high degree of freedom.","2-2 Concept of a Shared Scene","A shared scene is prescribed in the editing process based on an internal format of the MHEG authoring tool provided by this embodiment.","A shared scene is a virtual scene which is created by using one or more arbitrary objects. A shared scene is handled as a layer-like edit material to be used or displayed by superposition on a prepared MHEG scene. In addition, a shared scene is used by being shared among MHEG scenes forming one MHEG application.",{"@attributes":{"id":"p-0239","num":"0238"},"figref":"FIGS. 16A to 16F"},"Assume that shared scenes  and  shown in  have been created and prepared by using the MHEG authoring tool provided by this embodiment. In this case, shared scene  is created into a state in which object ob is displayed at a position shown in the figure. Object ob shown in shared scene  is a partial picture of an operation button marked with \u201cNext\u201d. On the other hand, shared scene  is created into a state in which object ob is displayed at a position shown in the figure. Object ob shown in shared scene  is a partial picture of an operation button marked with \u201cReturn\u201d.","It should be noted that a shared scene can be created by carrying out necessary editing operations using a material comprising a variety of objects in an environment of the MHEG authoring tool provided by this embodiment.","Shared scenes  and  are set so that they can be used in an MHEG content provided with 4 scenes, namely, MHEG scenes  to  as shown in  respectively. MHEG scenes  to  are edited to display the operation buttons \u201cNext\u201d and\/or \u201cReturn\u201d so as to allow transitions described later to take place as shown in .","MHEG scene  shown in  is a scene serving as a base point of the transitions. That is why only the Next operation button is displayed thereon. MHEG screen  is prescribed so that, when this Next button is operated, a transition from MHEG scene  to MHEG scene  takes place.","MHEG scene  shown in  displays both the Next and Return operation buttons. MHEG screen  is prescribed so that, when the Next button is pressed, a transition from MHEG scene  to MHEG scene  takes place and, when the Return button is pressed, on a transition from MHEG scene  back to MHEG scene  takes place.","By the same token, MHEG scene  shown in  displays both the Next and Return operation buttons. MHEG screen  is prescribed so that, when the Next button is pressed, a transition from MHEG scene  to MHEG scene  takes place and, when the Return button is pressed, a transition from MHEG scene  back to MHEG scene  takes place.","MHEG scene  shown in  is a scene serving as the last scene of the transitions. That is why only the Return operation button is displayed thereon. MHEG screen  is prescribed so that, when the Return button is pressed, a transition from MHEG scene  back to MHEG scene  takes place.","It should be noted that, in actuality, each of MHEG scenes  to  generally displays scene objects at the same time too. In this case, however, only objects included in shared scenes are displayed for the sake of clarity. In addition, a shared scene provided by this embodiment may be created in general to use a plurality of objects. In this example, however, shared scenes  and  include only 1 object for clarity of expression.","As described above, MHEG scenes  to  are edited to include the operation buttons \u201cNext\u201d and\/or \u201cReturn\u201d so as to allow the transitions to take place. In order to display either or both of the operation buttons, a relation among MHEG scenes and shared scenes needs to be described.","First of all, when MHEG scene  is edited, shared objects  and  are set at ON (RUN) and OFF (STOP) states respectively as shown at the bottom of MHEG scene  of . In these states, only shared object ob is selected and used in MHEG scene . That is to say, the editing work results in a state in which MHEG scene  displays shared object ob but not shared object ob as shown in .","Then, when MHEG scene  is edited, shared objects ob and ob are both set at an ON (RUN) state as shown at the bottom of MHEG scene  of . In this state, both shared objects ob and ob are selected and used in MHEG scene . That is to say, the editing work results in a state in which MHEG scene  displays both shared object ob and shared object ob as shown in . By the same token, when MHEG scene  is edited, shared objects ob and ob are both set at an ON (RUN) state as shown at the bottom of MHEG scene  of . In this state, both shared objects ob and ob are selected and used in MHEG scene . That is to say, the editing work results in a state in which MHEG scene  displays both shared object ob and shared object ob as shown in .","Finally, when MHEG scene  is edited, shared objects ob and ob are set at ON (RUN) and OFF (STOP) states respectively as shown at the bottom of MHEG scene  of . In these states, only shared object ob is selected and used in MHEG scene . That is to say, the editing work results in a state in which MHEG scene  displays shared object ob but not shared object ob as opposed to the display of MHEG scene .","As described above, a shared scene is a virtual scene which can be used by being shared among MHEG scenes constituting an MHEG content. As a result, an object used for such a shared scene is an object used by being shared among MHEG scenes constituting an MHEG content. That is to say, an object used for such a shared scene is the same as a shared object defined in the MHEG specifications.","In other words, shared objects are not controlled individually in this embodiment. Instead, shared objects are each controlled as an object included in a shared scene.","If a plurality of shared scenes are used for 1 MHEG scene in this embodiment, an order of superposition of the shared scenes on the MHEG scene should be specified. As a rule, when a plurality of shared scenes are used for 1 MHEG scene in this embodiment, the shared scenes are superposed on each other in a specified order to create a picture which is then placed in front of or on the picture of the MHEG scene.",{"@attributes":{"id":"p-0255","num":"0254"},"figref":"FIGS. 17A to 17D"},"In the example shown in the figure, 2 shared scenes, namely, shared scenes  and , are prepared as shown in  respectively. Shared scene  is formed to include object ob of an ON button picture displayed at a position shown in the figure. On the other hand, shared scene  is formed to include object ob of an OFF button picture displayed at a position shown in the figure. The position of object ob on shared scene  coincides with the position of object ob on shared scene .","Shared scenes  and  are both put in an ON (RUN) state and shared by MHEG scenes  and .  is a diagram showing MHEG scene  using shared scenes  and . On the other hand,  is a diagram showing MHEG scene  using also the 2 shared scenes, namely shared scenes  and .","As shown at the bottom of , in the order of superposition of shared scenes  and , shared scenes  and  are superposed on MHEG scene  with shared scene  put at the front end and shared scene  put at the rear end.","As a result, only object ob representing the ON button picture is visible on MHEG scene  as shown in . On the other hand, object ob representing the OFF button picture is concealed behind object ob and, hence, invisible.","Thus, MHEG scene  is a GUI screen whereby when the ON button is pressed. MHEG a transition takes place to replace MHEG scene  by MHEG scene .","In the case of MHEG scene , on the other hand, in the order of superposition of shared scenes  and , shared scenes  and  are superposed on MHEG scene  with shared scene  put at the front end and shared scene  put at the rear end as shown at the bottom of .","As a result, only object ob representing the OFF button picture is visible on MHEG scene  as shown in . On the other hand, object ob representing the ON button picture is concealed behind object ob and, hence, invisible.","Thus, MHEG scene  is a GUI screen whereby when the OFF button is pressed a transition takes place to replace MHEG scene  by MHEG scene .","Thus, when the user looks at the real GUI screen, the screen is switched from a display of the ON button picture to a display of the OFF button picture or vice versa each time the ON or OFF button is operated respectively.","As described above, shared objects are handled in the MHEG authoring tool provided by this embodiment in a configuration wherein the shared objects are controlled by shared scenes. Thus, by setting whether or not to use a shared scene in an MHEG scene as described by referring to , shared objects for each MHEG scene can be selected for use in the MHEG scene. In addition, by specifying an order of superposition of shared scenes as described earlier by referring to , it is possible to provide an editing effect wherein, while shared objects are used by being shared among a plurality of MHEG scenes, the display is capable of transiting from one scene to another.","In an attempt to carry out editing work for displays of objects like ones shown in  given earlier in an authoring tool without introducing the concept of a shared scene, for example, first of all, it is necessary to set objects ob and ob each as a shared object and, then, to describe a script prescribing that objects ob and ob are properly placed at positions in MHEG scenes  to  as shown in  respectively.","The editing work shown in  is carried out in a similar way. That is to say, first of all, objects ob and ob are each prescribed as a shared object. Then, it is necessary to prescribe a script including an order of superposition of shared objects ob and ob for MHEG scene  so as to give a display state like the one shown in . By the same token, it is necessary to prescribe a script including an order of superposition of shared objects ob and ob for MHEG scene  so as to give a display state like the one shown in .","In order to carry out such editing work, it is necessary for the editor to have sufficient knowledge of a script language that enables the editor to do editing work of shared objects. Thus, a result of the editing work much relies on the skill owned by the editor. For this reason, the editor is capable of creating only a simple scene using shared objects due to, for example, the fact that the editor is capable of describing only a very simple script. In another case, a script is described incorrectly due to the fact that the editor is not familiar with the script language.","The present authoring tools only have the functionality of turning a shared object on and off simultaneously for all scenes. Thus it is difficult to utilize a shared object effectively.","In the case of this embodiment, on the other hand, the editor carries out editing work by, first of all, creating a shared scene using selected objects each as a shared object and, creating an image obtained as a result of superposition of the shared scene on an MHEG scene. As a result, the editing work creates a visual image with ease.","2-3 Configuration of the MHEG Authoring System","Next, the configuration of an MHEG authoring system provided by this embodiment is explained.","As described above, the MHEG authoring system provided by this embodiment is capable of editing MHEG contents defining shared scenes. However, processing carried out by the MHEG authoring tool including the editing work using such a shared scene can be conceptually configured into a typical MHEG authoring tool as shown in .","Processing carried out by the MHEG authoring tool is classified into 2 large categories, namely, editing work shown in  and conversion work shown in . The editing work is carried out in accordance with an internal format in this MHEG authoring tool to create an MHEG application file or an MHEG content. On the other hand, the conversion work is carried out to convert an MHEG content created by the editing work carried out in accordance with the internal format in this MHEG authoring tool into data of the so-called MHEG-IS format conforming to the actual MHEG specifications.","The MHEG-IS format is the format of an MHEG content with substances conforming to MHEG specifications. In this case, the MHEG-IS format is a format for outputting contents for data broadcasting.","That is to say, the MHEG authoring tool provided by this embodiment has a configuration wherein editing processing is carried out in accordance with an internal format in the MHEG authoring tool, shared scenes and the like which do not exist in the actual MHEG specifications are defined and editing processing using the defined shared scenes and the like can be implemented. Conversely speaking, operations can be typically carried out in a GUI-like interface so as to allow the editor to perform advanced editing by carrying out simpler operations without the need for doing sophisticated work such as writing a script conforming to the MHEG specifications.","It should be noted, however, that the substance of an edit of an MHEG content (that is, a description such as a definition statement) conforming to the internal format of the MHEG authoring tool is valid only in the MHEG authoring tool. Thus, in order to allow the contents of the description conforming to the internal format to be decoded and displayed on the receiver side, it is necessary to convert the contents of the description into a description with contents conforming to the MHEG specifications. Thus, the configuration of MHEG authoring tool is designed to such that the description created by the edit processing according to the internal format as shown in  is converted into a description with contents conforming to the MHEG-IS format by the conversion processing shown in .","Using the above description as a basis, the following detailed description explains the concept of processing in the MHEG authoring tool provided by this embodiment to do editing work using shared scenes with reference to .","As shown in , in the MHEG authoring tool, editing work is carried out on an MHEG content comprising 2 scenes, namely, MHEG scene  and MHEG scene . Three files, namely, shared-object files ,  and  are created and prepared each as a shared object that can be used by MHEG scene  and MHEG scene . Shared-object file  is created by using objects  and  whereas shared-object file  is created by using objects  and . As for creation of shared-object file , objects  and  are used.","Here, assume that the editor edits scenes in an environment of the MHEG authoring tool. In this case, MHEG scene  is edited by using shared-scene files  and  to produce its desired display format whereas MHEG scene  is edited by using a shared-scene file  to produce its desired display format.","Then, in the MHEG authoring tool, a shared-scene definition statement  of shared-scene files  and  is formed as \u201cauthoring control information\u201d in accordance with actual results of the editing for MHEG scene  whereas a shared-scene definition statement  of shared-scene file  is formed as other \u201cauthoring control information\u201d in accordance with the actual results of the editing for MHEG scene .","Here, the concept of a shared scene is prescribed in the MHEG authoring tool provided by this embodiment. However, the prescription itself is not included in the brief description of the MHEG-IS format. On the other hand, the MHEG-IS system prescribes a description format indicating how individual shared objects are used for each MHEG scene.","For this reason, in the processing to output a result of editing by using a shared scene in the MHEG authoring tool provided by this embodiment as described above, that is, the processing to output a description of authoring control information (or shared-scene definition statements) in the MHEG-IS format, it is necessary to convert the description into description contents of a script (or control information) used in executing control of individual shared-object units in accordance with the MHEG description outline.","Thus, in the MHEG authoring tool provided by this embodiment, the description is converted into an output with the MHEG-IS format as shown in .","In this conversion, first of all, objects  to  used in shared-scene files ,  and  as shown in the left-hand-side diagram of  are prescribed in an MHEG content (or an MHEG application file) as shared objects  to  and controlled as a set of shared objects.","Then, for MHEG scene , a link for controlling shared objects  to  is described in a description file which is provided to the MHEG application file as shown in the right-hand-side diagram of .","By the same token, for MHEG scene , a link for controlling shared objects  and  is described in a description file which is provided to the MHEG application file.","Then, the MHEG application file converted into the MHEG-IS format as described above is output as a content for a data broadcast multiplexed in a digital satellite broadcast. If the configuration of the ground station  shown in  is taken as an example, the MHEG application file converted into the MHEG-IS format is data output from the MHEG authoring tool  to the DSM-CC encoder .","In the reception facility , for example, the digital satellite broadcast with the content for a data broadcast multiplexed therein is received by the IRD  and subjected to processing such as an MHEG decoding process in the CPU  so as to allow the display of a GUI screen to be controlled in accordance with the MHEG system.","The MHEG contents of the MHEG scenes shown in  are edited by using the MHEG authoring tool shown in  and broadcasted as a data broadcast. In this case, the IRD  outputs and displays an MHEG picture in display formats as shown in .",{"@attributes":{"id":"p-0290","num":"0289"},"figref":"FIG. 19"},"In actuality, the MHEG authoring tool  typically comprises a personal computer  and MHEG authoring software  activated in the personal computer .","As shown in the figure, the personal computer  of the MHEG authoring tool  physically includes hardware .","The hardware  comprises a CPU (Central Processing Unit) , a RAM (Random-Access Memory) , a ROM and an interface . The CPU executes various kinds of control and carries out a variety of operations. The RAM is used for storing information such as an application program executed by the CPU and data generated as a result of processing carried out by the CPU . The ROM is used for storing information required for operations of the personal computer . The interface is provided for facilitating exchanges of information between the hardware  and external equipment and external operation units to be described later.","It should be noted that the hardware  may include a variety of other devices.","A basic program is executed on this hardware  as an operating system  to provide an environment that allows MHEG authoring software of this embodiment to be executed.","The external equipment and the external operation units connected to the personal computer  shown in the figure include a display unit , a mouse , a keyboard , a speaker , a storage device  and a video unit .","The display unit  displays a picture output by the personal computer . Specifically, in this embodiment, a GUI screen for editing work using the MHEG authoring software  to be described later is also displayed.","The mouse  and the keyboard  each serve as an operator unit used by the editor for entering operation information to the personal computer .","The speaker  is provided for outputting an audio signal generated by the personal computer  to the outside.","The storage device  stores information required by the personal computer . Examples of such information are the operating system  and predetermined application software including the MHEG authoring software  provided by this embodiment. In the case of this embodiment, the stored information also includes MHEG contents themselves and objects used for forming each of the MHEG contents such as picture files, sound files and text files. The MHEG authoring software  is executed to create files of these objects to be stored in the storage device  and to carry out editing work by using the files of these objects.","It should be noted that, it is desirable to use a storage unit capable of accommodating a relatively large amount of data as the storage device , for example, a hard-disc drive.","A typical video unit  is a VTR which is capable of recording and playing back video information onto and from a video tape or a video disc.","An example of an MHEG content is a scene change synchronized with a broadcast program comprising pictures and sounds. In processing to edit an MHEG content synchronized with such a broadcast program, the video unit  can be used typically for playing back the broadcast program comprising pictures and sounds.","Next, the MHEG authoring software  is explained.","As described earlier, the MHEG authoring software  is an application software operating on the personal computer . The program is stored in the storage device .","After being read out from the storage device  for activation as a program, the MHEG authoring software  can be represented as functional blocks shown in the figure.","It should be noted that, the MHEG authoring software  has a configuration (not shown) in which information is exchanged between the functional blocks to allow required functions of the MHEG authoring software  to be executed.","In the MHEG authoring software , an object creation module  is a functional block comprising programs used for creating a file used as an object. For example, the editor may use the keyboard , the mouse  and other components in conjunction with the programs of the object creation module  or a GUI screen displayed on the display unit  to create a file used as an object. If the object created is a picture, for example, the editor is capable of creating the object by rendering a picture file using functions of the object creation module . In addition to a picture file, according to the prescription, the created object may be a text file or a sound file. In this case, of course, the object creation module  can be used for forming a text or sound file. An object file created by using the object creation module  can be stored and retained in the storage device .","A shared-scene creation module  comprises programs for creating a shared scene by utilizing object files created by using the object creation module .","In this case, for example, the editor is capable of creating any arbitrary number of shared scenes as long as the number is smaller than an upper limit prescribed by the MHEG authoring software . Much like an object file, a shared scene is created by operating the keyboard , the mouse  and other components which are used in conjunction with the programs of the shared-scene creation unit  to select any arbitrary number of object files created so far.","An MHEG-scene creation module  is a functional block comprising programs used for creating an MHEG scene. The programs of the MHEG-scene creation module  are used for selecting an object file created by using the object creation module  and the selected object file is used for creating an MHEG scene.","Programs of a shared-scene processing module  are executed to perform processing to edit a relation between an MHEG scene and a shared scene in accordance with an operation carried out by the editor for the GUI screen thereof. Specifically, the shared-scene processing module  is programmed for editing work such as setting a shared scene on an MHEG scene as shown in  and specifying an order of superposing a plurality of shared scenes to be used on an MHEG scene as shown in .","Details of an MHEG content creation module  are not explained. Briefly speaking, the MHEG content creation module  is used for creating a scenario explained earlier by referring to  in accordance with a result of editing predetermined contents of typically a scene.","The MHEG-application creation module  integrates results of editing work carried out by using the object creation module , the shared-scene creation module , the MHEG-scene creation module , the MHEG content creation module  and the shared-scene processing module  described so far to create an MHEG-application file (or an MHEG content) controlled in accordance with an internal format. In order to implement this function, in the MHEG-application creation module  provided by this embodiment, a description file containing \u201cauthoring control information\u201d also shown earlier in  is generated and the MHEG content is controlled in accordance with the internal format. Here, the authoring control information also includes a shared-scene definition statement created on the basis of an editing result produced by the shared-scene processing module  and a description file of a scenario created by using the MHEG content creation module . In addition, transitions among scenes can also be controlled in accordance with the internal format by using the authoring control information described by using the MHEG-application creation module .","Furthermore, control information for the synchronization of a scene output in the broadcasting time of a broadcast program is also described as authoring control information. When the authoring control information is converted into the MHEG-IS format, the contents of the description of the control information for synchronization are also converted and output.","Information obtained as an MHEG content created by using the MHEG-application creation module  as described above is handled in accordance with an internal format by the MHEG authoring software as explained earlier by referring to .","Then, in this embodiment, an MHEG application file created in accordance with the internal format can be output to the external by processing carried out by an internal-format-file output control module  as an internal-format file with the internal format remaining unchanged as it is.","For example, an internal-format file of an MHEG application output by the internal-format-file output control module  can be stored and retained in the storage device . By doing so, the internal-format file stored in the storage device  can be transferred later to the personal computer  which is capable of changing editing contents by execution of the MHEG authoring software .","An MHEG-script output control module  receives data of an MHEG-application file created by the MHEG-application creation module  in the internal format, converts the data into a description of a script (or control information) conforming to the actual MHEG specifications and outputs, outputting the description to the external. That is to say, the MHEG-script output control module  outputs a regular MHEG (MHEG-IS) application file.","Typically, the output of the MHEG-script output control module  is supplied to the DSM-CC encoder  shown in .","It should be noted that an MHEG application file of the MHEG-IS format produced by the MHEG-script output control module  can be stored and retained in the storage device . In actuality, an application file of the MHEG-IS format stored and retained in the storage device  is supplied to the DSM-CC encoder  employed in the ground station  when required.","In comprising the configuration of the MHEG authoring software explained so far with the processing shown in , the functional circuit blocks of the software correspond to the processing according to the internal format of the MHEG authoring tool shown in . As described earlier, the functional circuit blocks are the object creation module , the shared-scene creation module , the MHEG scene creation module , the MHEG content creation module , the MHEG application creation module , the shared-scene processing module  and the internal-format file output control module .","In addition, the object creation module  corresponds to the processing shown in  to convert MHEG application information expressed in the internal format into an MHEG-IS output.","2-4 Typical GUI Screens Displayed as Part of MHEG Authoring Software","As described above, the MHEG authoring software  provided by this embodiment is application software running on the personal computer . The MHEG authoring software  is also capable of carrying out command-line editing typically for describing a script conforming to the MHEG specifications. In order to allow a variety of editing operations to be carried out as visually as possible, mainly including the editing of a shared scene described earlier, the MHEG authoring software  has an operation style embracing the GUI. That is to say, much like various kinds of software developed in recent years for personal computers, the MHEG authoring software  allows the editor to carry out editing operations by operating the mouse  and the keyboard  while looking at an operation screen appearing on the display unit .","It should be noted that an operation on an interface such as the GUI can be implemented with ease by typically carrying out edit processing according to the internal format in the MHEG authoring software  as described earlier.",{"@attributes":{"id":"p-0326","num":"0325"},"figref":"FIGS. 20A and 20B","b":"210"},"In particular,  is a diagram showing a typical basic display format of a GUI screen for creating an MHEG application file. The picture of the GUI screen is displayed typically on the display unit .","As shown in , the screen displays an MHEG application window WD and a shared-scene control window WD.","The MHEG application window WD is a window for visually displaying the structure of an MHEG application created by the editor. For example, the window has a title of \u201cMHEG Application\u201d.","In the first place, on the left side of the MHEG application window WD, a column with a title of \u201cScene\u201d is displayed for presenting a list of MHEG scenes constituting this MHEG application. In this example, the scene column displays 5 MHEG scenes, namely MHEG scenes  to .","It should be noted that, in case there are too many MHEG scenes constituting the MHEG application so that all the MHEG scenes can not be accommodated in the display area of the MHEG application window WD, the MHEG application window WD can be displayed, for example, in a format that allows the window to be scrolled.","In the second place, on the right side of the MHEG application window WD, a column with a title of \u201cShared-Scene Setting Status\u201d is displayed for visually displaying the present setting status of the MHEG scenes. The setting status of an MHEG scene shows which shared scenes are used and, if a plurality of shared scenes are in use, the status specifies what order the shared scenes are to be superposed in.","On the \u201cShared-Scene Setting Status\u201d column, 1 shared scene is expressed by an icon which is referred to as a shared-scene icon Ish. A shared-scene icon Ish is denoted by notation shsN where N is a natural number, that is, a positive integer denoting the number of a file of the shared scene.","Take MHEG scene  as an example. In this case, the status shows that only one shared-scene icon Ish marked with \u201cshs\u201d is displayed to indicate that only shared scene  is used to create MHEG scene . Likewise, in the case of MHEG scene , only shared scene  is used to create MHEG scene .","Similarly, in the case of MHEG scene , the status shows that only one shared-scene icon Ish marked with \u201cshs\u201d is displayed to indicate that only shared scene  is used to create MHEG scene . By the same token, in the case of MHEG scene , the status shows that only one shared-scene icon Ish marked with \u201cshs\u201d is displayed to indicate that only shared scene  is used to create MHEG scene .","In the case of MHEG scene , on the other hand, the status shows that two shared-scene icons Ish marked with \u201cshs\u201d and \u201cshs\u201d are set to indicate that two shared scenes  and  are used to create MHEG scene . The fact that shared scene  is placed first on the row to be followed by shared scene  indicates that shared scene  denoted by shs is to be displayed first on MHEG scene  to be followed by shared scene  denoted by shs. That is to say, the status specifies an order of superposition in which shared scene  is placed on the front side and shared scene  is placed on the rear side.","As described above, the shared-scene control window WD is displayed on the right side adjacent the MHEG application window WD.","The shared-scene control window WD has a title of \u201cShared Scenes\u201d to indicate that this window shows a list of shared scenes created and prepared by the editor. In this example, the shared-scene control window WD presently displays 6 shared scenes, namely, shared scenes  to .","The shared scenes set on the \u201cShared-Scene Setting Status\u201d column of the MHEG application window WD described above for each MHEG scene are selected arbitrarily from the shared scenes on the list displayed on the shared-scene control window WD.","There are a variety of possible operations to select a shared scene from the list. In an example of the possible operations, a shared scene arbitrarily selected from the list on the shared-scene control window WD is moved to the position of a shared-scene icon for any arbitrary MHEG scene on the \u201cShared-Scene Setting Status\u201d column on the MHEG application window WD by carrying out a drag-and-drop operation.","In addition, the specification of an order of superposition for an MHEG scene on the \u201cShared-Scene Setting Status\u201d column on the MHEG application window WD can be changed by carrying out a drag-and-drop operation cited above.","Assume for example that, with the screen of  displayed, any arbitrary one of MHEG scenes  to  is selected by using typically a pull-down menu which is not shown in the figure. Then, a predetermined operation is carried out to call an edit screen (or a window) for the selected MHEG scene.  is a diagram showing a typical scene edit screen.","Assume for example that the scene edit screen shown in  is a screen for MHEG scene . In this case, the scene edit screen displays the picture of MHEG scene  which uses shared scene . In this figure, an object included in shared scene  is shown as a hatched ellipse.","2-5 Processing Operations","The following description explains a variety of processing operations carried out by a CPU employed in the hardware  shown in  by execution of the MHEG authoring software  provided by this embodiment. The processing operations are exemplified by processing to edit a shared scene which is a characteristic of the embodiment.",{"@attributes":{"id":"p-0345","num":"0344"},"figref":"FIG. 21","b":["212","215","210"]},"As shown in the figure, the processing begins with step S at which a shared scene is created in accordance with operations carried out by the editor.","In order to create a shared scene, a shared scene creation screen is presented as a GUI screen in a format like a typical one shown in . The editor then creates a picture to be used as a shared scene by pasting objects selected arbitrarily from already prepared objects such as picture and text files on the shared-scene creation screen.","At step S, display control processing is carried out to change the appearance of the GUI screen in accordance with such an operation to create a shared scene described above. In addition, an operation to create a shared scene also causes information on a temporary shared scene to be controlled in accordance with an internal format.","In this embodiment, a variety of editing results for an MHEG application typically including shared scenes are controlled in the MHEG-application creation module  by being described as authoring control information according to the internal format.","Then, at step S, a description according to contents of the shared scene created at step S is written as the authoring control information according to the internal format.","Subsequently, at step S, the shared scene created at step S is controlled as a file and stored and retained in the storage device . It should be noted, however, that information contained in the stored file of the shared scene also conforms to the internal format.","The processing up to this point is carried out to create a certain shared scene which can be stored as a file conforming to the internal format. Then, this procedure (or processing) is carried out for each shared scene so as to allow shared-scene files required for creation of an MHEG scene to be prepared. It should be noted that a directory of shared-scene files stored in this way is controlled as authoring control information in the MHEG-application creation module .",{"@attributes":{"id":"p-0353","num":"0352"},"figref":"FIG. 22","b":["216","215"]},"At a stage prior to the processing shown in , MHEG scenes and shared scenes are prepared to create the MHEG content. It should be noted that the creation of an MHEG scene itself is not described before. The creation of an MHEG scene is implemented by displaying the MHEG-scene creation screen and having the editor create the MHEG scene on the screen using the MHEG-scene creation module .","As shown in , the processing begins with step S at which processing to set shared scenes for each MHEG scene is carried out in accordance with an operation performed by the editor.","That is to say, in accordance with an operation to set shared scenes for an MHEG scene as described earlier, processing is carried out, for among other purposes, to output a GUI picture like the one shown in  as a result of editing. In the operation to set shared scenes for an MHEG scene, shared scenes to be used for the MHEG scene and an order of superposition of the shared scenes are specified.","Then, when shared scenes are set for a certain MHEG scene as described above, the setting of the shared scenes for the MHEG scene is described as authoring control information at step S. To put it concretely, a shared-scene definition statement explained earlier by referring to  is created.","In actuality, the processing shown in  is carried out for each MHEG scene. Then, the setting of shared scenes for each MHEG scene obtained as a result of operations carried out by the editor during such processing is described by the MHEG-application creation module  as authoring control information.","The steps of processing shown in  are thus processing carried out by execution of the MHEG authoring software  in accordance with an internal format to edit an MHEG application provided by this embodiment by creation of shared scenes and setting the shared scenes for each MHEG scene.","It should be noted that authoring control information created in the steps shown in  can be stored in the storage device  as information on an MHEG application according to the internal format along with typically a variety of files used mainly as objects through processing of the internal-format-file output control module . It is worth noting, however, that operations of the processing of the internal-format-file output control module  are not shown explicitly in .","In order to output the MHEG application conforming to the internal format as described above as a data content for broadcasting, that is, in order to output content information controlled by authoring control information as a broadcasting data content, it is necessary to convert the format of the MHEG application into an MHEG-IS format as has been described earlier by referring to . In the following description, description contents of a script conforming to the MHEG-IS format is referred to as an MHEG-IS script. The following description explains processing to convert information on an MHEG application from the internal format into the MHEG-IS format of an MHEG script with reference to . This conversion processing is carried out in an environment where the MHEG authoring software  is executed.","It should be noted, however, that the explanation of the conversion processing is limited in this case to a shared scene or a shared object which is a characteristic of this embodiment.","In addition, the processing described below is carried out by executing programs of the MHEG-script output control module .",{"@attributes":{"id":"p-0364","num":"0363"},"figref":["FIG. 23","FIG. 24"]},"As shown in , the processing begins with a step S to fetch information on an MHEG application described in the internal format of the MHEG authoring software . Shared objects are controlled in authoring control information as objects forming a shared scene.","Then, at next step S, the contents of the MHEG application fetched at step S are analyzed to acquire all shared scenes which are included in this MHEG application and set for use in MHEG scenes of the MHEG application.","Subsequently, at step S, processing is carried out to set all the objects used in the shared scenes obtained at step S in the MHEG application (or the MHEG script) as shared objects.","To put it concretely, the following MHEG script is described in this processing.","In the MHEG script, a shared object is defined by a description of a \u201cShared\u201d parameter which represents an attribute of the object as follows.","Shared=True","indicates that the object is prescribed as a shared object.","On the other hand,","Shared=False","indicates that the object is prescribed to be not a shared object.","Thus, at step S, the attribute of each object used in the shared scenes obtained at the step S is described as follows:","Shared=True","By describing the attribute in this way, all the objects are each treated as a shared object.","Another parameter of an object, Initially Active is defined as a parameter set to indicate whether the object is active or inactive in an initial state in an MHEG scene or an MHEG application.","Initially Active=True","indicates that the object is active initially.","On the other hand,","Initially Active=False","indicates that the object is inactive initially.","Finally, at step S, for each of the shared objects set at step S, this parameter is set as follows.","Initially Active=False","That is to say, each of the shared objects is inactive initially.","Next, processing shown in  is explained.","As shown in the figure, the processing begins with step S at which the preparatory processing explained earlier by referring to  is carried out.","When the preparatory processing is completed, the processing flow goes on to step S.","At step S, a fetched MHEG application is examined to determine whether or not one or more MHEG scenes are set and used in the MHEG application. Typically, the judgment is formed by referring to authoring control information conforming to the internal format.","If it is determined that MHEG scenes to be used are not set in the MHEG application, no processing is specially required for sharedscenes and, the processing is ended. If it is determined that MHEG scenes to be used are set in the MHEG application, on the other hand, the flow of the processing goes on to step S.","At step S, the MHEG application is checked to determine whether or not there is still an unselected MHEG scene which remains to be subjected to convert a shared scene into a shared object. Thus, when the flow goes on from step S to step S for the first time, the determination formed ate step S certainly indicates that there is an MHEG scene to be subjected to such conversion processing. In this case, the flow of the processing proceeds to step S.","At step S, one of presently set MHEG scenes is selected and the authoring control information of the selected MHEG scene is fetched as an object of processing. Typically, an MHEG scene is selected sequentially according to an MHEG-scene sequence number.","It should be noted that MHEG scenes once selected before at step S are no longer subjected to the subsequent processing.","At step S, a link is described as an MHEG script to indicate that all shared objects are to be stopped (turned off) at activation of this MHEG scene. To put it concretely, for all shared objects included in the MHEG application, an MHEG script regarding shared objects for this MHEG scene is described as follows:","Initially Active=False","The prescription obtained as an actual editing result thus indicates that, in this MHEG scene, shared objects are not used at all.","At step S, the authoring control information (or shared-scene definition statements) of the selected MHEG scene fetched at step S is referred to in order to determine whether or not there is a shared scene set for the MHEG scene.","If it is determined that there is no shared scene set for the MHEG scene, the flow of the processing goes back to step S.","If it is determined S indicated that there is a shared scene set for the MHEG scene, on the other hand, the flow of the processing goes on to step S.","At step S, the MHEG scene is checked to determine whether or not there is still an unselected shared scene which remains to be processed to convert the shared scene into a shared object. Thus, when the flow goes on from step S to step S for the first time, it has been determined at step S that there is a shared scene to be subjected to such conversion processing. In this case, the flow of the processing proceeds to step S.","At step S, one of unselected MHEG scenes remaining as an object of the conversion processing is selected. To put it in detail, processing is carried out to select and fetch the description contents such as a shared-scene definition statement on a shared scene which has been placed at the rearmost end.","It should be noted that shared scenes once selected before at step S are no longer subjected to the subsequent processing.","Next, at step S, processing is carried out to describe a link as an MHEG script to run or turn on shared objects included in the shared scene fetched at step S at activation of the MHEG scene fetched at step S as a current processing object. In order to describe a link to run shared objects, typically, the following is described for each of the shared objects.","If initially Active=True,","the MHEG script prescribes that the shared objects serving as a material of the shared scene fetched at step S be put in an active state at activation of the MHEG scene and displayed at proper positions on the display screen.","As the processing of step S is completed, the flow goes back to step S. If determination formed ate step S indicates that there is a shared scene to be subjected to such conversion processing, the flow of the processing proceeds to step S to carry out the processing of step S and the subsequent processing.","The pieces of processing of steps S to S are carried out repeatedly for a selected and fetched MHEG scene as many times as the number of shared scenes set for the MHEG scene.","By carrying out steps S to S repeatedly, it is possible to obtain description contents of an MHEG script specifying utilization of shared objects in a certain MHEG scene in accordance with results of work carried out earlier by the editor to edit shared scenes. At the same time, it is also possible to obtain description contents of an MHEG script specifying an order of superposition of the shared objects.","As described above, steps S to S are carried out repeatedly for an MHEG scene as many times as the number of shared scenes set for the MHEG scene. When no more shared scenes remain, the flow of the processing goes back to step S.","When the flow of the processing returns to step S from step S or S and it is determined in step S that there is an MHEG scene left as an object of the conversion processing, the flow goes on to step S to carry out the processing of step  and the subsequent processing.","Thus, steps S to S are carried out repeatedly for an MHEG application file (or an MHEG content) as many times as the number of MHEG scenes created for the MHEG content.","After steps S to S have been completed, step S indicates that the processing is ended.","In this way, at the stage the processing carried out so far is ended, an internal-format result of editing work performed by using the MHEG authoring software in accordance with operations carried out by the editor has been converted into description contents of an MHEG script conforming to the MHEG-IS format.","It should be noted that  show the processing of the MHEG-script output control module  to convert the internal format of a description of an MHEG content into the MHEG-IS format.","Thus, in actuality, processing to convert the internal format into the MHEG-IS format for an editing result of an MHEG content other than the shared scene is carried out concurrently with the processing shown in .","In addition, the pieces of processing shown in  are each typical processing to the bitter end. There are other conceivable processing procedures for converting description contents with the internal format of the MHEG authoring software using the concept of shared scenes into description contents with the MHEG-IS format based on the concept of shared objects.","The above embodiment is exemplified by a case in in the digital satellite broadcasting system created in accordance with the MHEG specifications. In addition, a content created by the present invention can also be used in media other than the digital satellite broadcasting system. As for the media, a recording medium such as a CD-ROM can also be used in addition to distribution through a broadcasting system and a network.","Furthermore, while the embodiment is exemplified by a case in which an MHEG content is edited, the present invention can also be applied to applications other than the MHEG system provided that the other applications conform to specifications for creating an interface picture (a content) introducing a concept similar to, for example, the concept of a shared object.","As described above, the present invention defines a shared scene that can be created by using any arbitrary objects as a virtual scene usable as a scene common to scenes instead of directly handling the shared object on an authoring tool in editing work to create a content conforming to typically the MHEG specifications. In addition, the present invention is used for editing scenes in shared-scene units. Then, the edited work using the shared scene is finally converted into description contents for controlling a shared object itself in accordance with specifications for a content for broadcasting.","With such a configuration, an editor creating a content is capable of handing a shared object by carrying out operations to combine shared scenes created arbitrarily for a scene at an editing-operation stage using the authoring tool. Conversely speaking, it is not necessary for the editor to have advance knowledge of the MHEG script.","Thus, by virtue of the present invention, the editor is capable of editing a scene using a shared object with ease and with a high degree of accuracy even if the editor is not familiar with rules of an MHEG script, for example. As a result, the present invention provides an effect to give the editor a capability of creating a scene in a number of display formats through editing operations which are easy to understand.","In addition, as described above, the present invention provides a system of editing operations in which a shared object is handled for each shared scene and, in addition, an order of superposition of shared scenes can be specified. As a result, it is possible to simplify a comparatively complicated edit operation of specifying an order of superposition of objects."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIGS. 4A and 4B"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIGS. 7A to 7H"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIGS. 8A to 8F"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIGS. 10A to 10C"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIGS. 11A to 11D"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIGS. 16A to 16F"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIGS. 17A to 17D"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIGS. 18A and 18B"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIGS. 20A and 20B"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 24"}]},"DETDESC":[{},{}]}
