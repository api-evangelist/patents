---
title: Data processing apparatus and data processing method
abstract: From structure description data with a structure of media contents described therein is generated representation description data expressive of representation order, representation timing, and synchronization information of media segments described in the structure description data, whereby media segments are capable of being represented under various added restrictions.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07765468&OS=07765468&RS=07765468
owner: Panasonic Corporation
number: 07765468
owner_city: Osaka
owner_country: JP
publication_date: 20010611
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS","First Embodiment","Second Embodiment","Third Embodiment","Fourth Embodiment","Fifth Embodiment","Sixth Embodiment","Seventh Embodiment","Eighth Embodiment","Ninth Embodiment","Tenth Embodiment","Eleventh Embodiment","Twelfth Embodiment","Thirteenth Embodiment","Fourteenth Embodiment","Fifteenth Embodiment","Sixteenth Embodiment","Seventeenth Embodiment","Eighteenth Embodiment"],"p":["1. Field of the Invention","The present invention relates to a data processing apparatus and data processing method for converting a description on a structure of media contents into a description for representation of the contents, in order to perform representation and distribution of the contents suitable for user preference and terminal capability in watching and listening, representing, and distributing the media contents that are continuous visual and audio information such as moving picture, image and audio.","2. Description of the Related Art","Conventionally, media contents are stored for each file, and representation and distribution of the media contents are performed for each file storing the media contents.","When the media contents are digitized by a plurality of different systems and are stored in a plurality of files, decoding processing is required in representing the media contents. A processing amount of the decoding processing varies with the digitizing method. Therefore, when the media contents are selected, it is necessary to select the media contents that are digitized by a digitizing method suitable for a processing capability of a terminal that represents the media contents. In this case, a user selects for each file the media contents suitable for the capability of a terminal that the user uses, and thereby selects the media contents to be displayed according to the capability of the terminal device.","As a method for representing only a specific scene in a moving picture distribution using World Wide Web, there is known a method described in Japanese Laid-Open Patent Publication HEI10-111872. FIG. 50 illustrates a configuration of a moving picture distributing apparatus described in Japanese Laid-Open Patent Publication HEI10-111872, which will be described below.","In the moving picture distributing apparatus, scene information inputting section  inputs in advance a scene number, time codes of start\/end frames, key word relating to a scene, and moving picture file name to scene information storing section . Using a retrieval condition input from scene information inputting section , scene retrieving section  retrieves scene information stored in scene information storing section . Scene retrieving section  extracts the scene number of a retrieved desired scene to store as a scenario in scenario storing section .","Scenario editing section  changes the order of extracted scenes and deletes an unnecessary scene when necessary. Moving picture transferring section  transfers moving picture data stored in moving picture file storing section , in the order of the scene number stored as the scenario that is edited by scenario editing section , to represent. Moving file storing section  receives as its input a moving picture from moving picture file inputting section .","However, in the conventional method for representing the contents for each file, the contents with files stored therein should be all represented. Accordingly, it is impossible to see an outline that is a summary of the contents. Another problem is that it is required to refer to the contents starting from the first portion even in retrieving a highlight scene composed of extracted part of the contents or retrieving a scene that a user wants to watch.","Further, according to the method of Japanese Laid-Open Patent Publication HEI10-111872, since it is possible to designate the representation order of scene cut, it is not required to refer to the contents starting from the first portion. However, this method only provides the order of representing scenes as the scenario, and does not provide processing except rearranging the order of representing scenes. Accordingly, there arise a problem that it is not possible to perform complicated representation, such as, representing a plurality of media in relation to each other.","It is an object of the present invention to generate representation description data for representing media segments described in structure description data while adding various restrictions from the structure description data expressive of a structure of the media contents.","In order to achieve the object, in the present invention, from the structure description data with the structure of media contents described therein is generated the representation description data expressive of the representation order, representation timing and synchronization information of media segments described in the structure description data.","Thus, a few media segments are selected from the structure description data to be converted into the representation description data expressive of the representation order, representation timing and synchronization information of the media segments, whereby it is possible to obtain display aspects of an outline, highlight scenes, and a scene collection suiting user's preference. Further, by providing the representation description data with the representation order, representation timing and synchronization information, it is possible to relate a plurality of media to each other to represent data.","Further in the present invention, the structure description data is provided with a set of alternative data to media segments, and is converted into the representation description data expressive of the representation order, representation timing and synchronization information of at least one of the media segments or the alternative data.","It is thereby possible to switch between the media segments and alternative data to represent corresponding to a capacity and traffic amount of a network that distributes the media contents and a capability of a terminal that represents the media contents. In other words, it is possible to distribute and represent the contents using media suitable for, for example, the capability of a terminal that represents the contents.","Furthermore in the present invention, a media selecting section is provided that selects the media segments or alternative data to represent in representing the media segments expressed in the structure description data.","The media segments or alternative data is thereby capable of being automatically selected by the media selecting section corresponding to the capability of a terminal, without a user selects the media segments or alternative data corresponding to the capability of a terminal.","Still furthermore in the present invention, in the structure description data is described a score based on context contents of each media segment.","It is thereby possible to generate, for example, highlight scene collections with different representation time periods, and to represent and distribute the collections easily. Further, setting a score based on a viewpoint indicated by a keyword enables designating the keyword to represent and distribute only scenes suiting user's preference.","The first embodiment of the present invention will be described below with reference to accompanying drawings. A structure of a data processing system according to the first embodiment of the present invention will be described first with reference to .  is a conceptual diagram of the data processing system according to the first embodiment.","The data processing system according to the first embodiment is composed of metadata database , summary engine , description converter , representation unit , and media contents database . In , \u201c\u201d denotes a content description that is metadata, \u201c\u201d denotes a selection condition, \u201c\u201d, denotes a summary content description that is a summary result, \u201c\u201d denotes a representing method description for providing an instruction to representation unit , and \u201c\u201d denotes media contents data.","The metadata is data indicative of additional information on media contents including bibliographic items such as a title and date and time of creation, contents, and scene structure of the media contents. Database  is indicative of a database of such metadata.","Summary engine  receives as its input content description  that is structure description data expressive of the contents and structure of the media contents from among metadata stored in database . Summary engine  selects only scenes suitable for selection condition  inputted by a user from the input content description . Summary engine  generates summary content description  with only data left associated with the scenes selected from content description  and with the other data deleted to output.","Content description  and summary content description  are structure description data expressive of the contents and structure of media contents, and have a different number of described scenes from each other and the same format as the other.","Description converter  receives as its input summary content description , and generates and outputs representing method description  that is representation description data in which representation aspects of media are described such as the representation order, timing for starting the representation and synchronization information in representing a scene described in summary content description .","Representation unit  receives as its inputs representing method description , and according to representing method description , media contents data  that is data to be represented from media contents database . Then, representation unit  represents media contents data  according to the representation order, timing for starting the representation, synchronization information, etc. described in representing method description .","Since summary content description  and content description  have the same format, description converter  is capable of similarly generating a representing method description (representation description data) corresponding to content description .","The structure description data used in content description  and summary content description  will be described next with reference to , B and .",{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 2A","FIG. 2B","FIG. 3"],"b":"1"},"In this embodiment, Extensible Markup Language (XML) is used as an example of the aspect for expressing the structure description data on a computer.","XML is a data description language standardized by World Wide Web Consortium (W3C), and Ver.1.0 thereof was recommended on Feb. 10, 1998. The specification of XML ver.1.0 is available at http:\/\/www.w3.org\/TR\/REC-xml.","Using , Document Type Definition (DTD) that is a definition for describing the structure description data with XML will be first described.","As illustrated by \u201c\u201d in the figure, a \u201ccontents\u201d element is composed of a \u201cpar\u201d element and a \u201cmediaObject\u201d element. Further as illustrated by \u201c\u201d in the figure, the \u201ccontents\u201d element has a \u201ctitle\u201d attribute indicated by character data.","The \u201cmediaObject\u201d element is expressive of media. As illustrated by \u201c\u201d, in the figure, the \u201cpar\u201d element is composed of a plurality of \u201cmediaObject\u201d elements each is a child element. When the \u201ccontents\u201d element is composed of a plurality of \u201cmediaObject\u201d elements such as audio and video, the \u201cpar\u201d element is expressive of synchronizing a plurality of \u201cmediaObject\u201d elements as child elements with each other to represent.","As illustrated by \u201c\u201d in the figure, the \u201cmediaObject\u201d element is composed of a \u201csegment\u201d element expressive of a media segment. As illustrated by \u201c\u201d in the figure, in the \u201cmediaObject\u201d element a type of media is designated by a \u201ctype\u201d attribute. In this example, examples designated as the type of media are \u201caudio\u201d that is audio information, \u201cvideo\u201d that is moving picture information, \u201cimage\u201d that is still picture information, \u201caudiovideo\u201d that is multiplexed audio and moving picture information, and \u201caudioimage\u201d that is audio and still picture information. When the \u201ctype\u201d attribute is not designated in particular, the \u201ctype\u201d attribute is set to \u201caudiovideo\u201d as default.","As illustrated by \u201c\u201d in the figure, in the \u201cmediaObject\u201d element a format of media such as MPEG1 and MPEG2 is designated by a \u201cformat\u201d attribute. As illustrated by \u201c\u201d in the figure, in the \u201cmediaObject\u201d element a location where data is stored is designated by an \u201csrc\u201d attribute. Designating Uniform Resource Locator (URL) by the \u201csrc\u201d attribute enables the designation of a location where the data is stored.","As illustrated by \u201c\u201d in the figure, the \u201csegment\u201d element has a \u201cstart\u201d attribute and \u201cend\u201d attribute. The \u201cstart\u201d and \u201cend\u201d attributes are respectively indicative of a start time and end time of the \u201csegment\u201d element. The \u201cstart\u201d and \u201cend\u201d attributes each indicate a time inside the media designated by the \u201cmediaObject\u201d element. In other words, by the \u201cstart\u201d and \u201cend\u201d attributes, the \u201csegment\u201d element is assigned to a corresponding portion of the media designated by the \u201cmediaObject\u201d element.","In addition, in this embodiment, the time information on the media segment is designated by a pair of start time and end time, however, such time information may be expressive of a pair of start time and duration.","An example of the structure description data for media contents with multiplexed moving picture and audio will be described below using MPEG  as an example with reference to .","In the structure description data illustrated in , a title of \u201cMovie etc\u201d is designated in the \u201ccontents\u201d element. In the \u201cmediaObject\u201d element, \u201caudiovideo\u201d is designated as the type, MPEG1 is designated as the format, and http:\/\/mserv.com\/MPEG\/movie0.mpg is designated as the storing location. The \u201cmediaObject\u201d element has the \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00, the \u201csegment\u201d element with the time information of time 00:01:00 to 00:02:00, the \u201csegment\u201d element with the time information of time 00:03:00 to 00:04:00, and the \u201csegment\u201d element with the time information of time 00:04:00 to 00:05:00. In other words, the \u201cmediaObject\u201d element is indicative of a description without time 00:02:00 to 00:03:00.","An example of the structure description data of media contents with moving picture and audio in different media will be described below using .","In the structure description data illustrated in , a title of \u201cMovie etc\u201d is designated in the \u201ccontents\u201d element. In the example of , the \u201ccontents\u201d element is composed of the \u201cmediaObject\u201d element with the type of \u201cvideo\u201d and the \u201cmediaObject\u201d element with the type of \u201caudio\u201d. Accordingly, by the \u201cpar\u201d element, the \u201cmediaObject\u201d element of \u201cvideo\u201d type is synchronized with the \u201cmediaObject\u201d element of \u201caudio\u201d type.","In the element \u201cmediaObject\u201d of \u201cvideo\u201d type, MPEG  is designated as the format, and http:\/\/mserv.com\/MPEG\/movie0v.mpv is designated as the storing location.","The \u201cmediaObject\u201d element of \u201cvideo\u201d type has the \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00, the \u201csegment\u201d element with the time information of time 00:01:00 to 00:02:00, the \u201csegment\u201d element with the time information of time 00:03:00 to 00:04:00, and the \u201csegment\u201d with the time information of time 00:04:00 to 00:05:00. In other words, the \u201cmediaObject\u201d element of \u201cvideo\u201d type is indicative of a description without time 00:02:00 to 00:03:00.","In the \u201cmediObject\u201d element of \u201caudio\u201d type, MPEG  is designated as the format, and http:\/\/mserv.com\/MPEG\/movie0a.mp2 is designated as the storing location. The \u201cmediaObject\u201d element of \u201caudio\u201d type has the segment with the time information of time 00:00:00 to 00:01:00, the segment with the time information of time 00:01:00 to 00:02:00, the segment with the time information of time 00:03:00 to 00:04:00, and the segment with the time information of time 00:04:00 to 00:05:00. In other words, the \u201cmediaObject\u201d element of \u201caudio\u201d type is indicative of a description without time 00:02:00 to 00:03:00.","When the contents are composed of a plurality of media, it is necessary to control representation timing and synchronization between media segments. Then in this embodiment, description converter  converts summary content description  described with the structure description data into representing method description  described with representation description data capable of expressing the representation order, representation timing and synchronization information of media segments.","In this embodiment, Synchronized Multimedia Integration Language (SMIL) is used as the representation description data. SMIL is a description language standardized by W3C for the purpose of describing timewise behavior of representation and layout on a display screen with respect to a plurality of media. Ver.1.0 of SMIL was recommended on Jun. 15, 1998. The specification of SMIL ver.1.0 is available at http:\/\/www.w3.org\/TR\/REC-smil.","Thus using standardized SMIL as the representation description data enables the use of preexisting and\/or developing SMIL player programs, and therefore increases the generality.","With reference to , the processing will be described below for converting the structure description data described with XML into the representation description data expressive of representation aspects such as the representation order, representation timing and synchronization information of media segments.  is a flowchart indicative of procedures for the description converter according to the first embodiment to convert the structure description data into SMIL.","When the processing is started (step S), at step S, description converter  examines whether or not the \u201cpar\u201d element is present in summary content description  described with the structure description data. When description converter  judges at step S that the \u201cpar\u201d element is present, the converter shifts to the processing of step S, while when the converter judges at step S that the \u201cpar\u201d element is not present, the converter shifts to the processing of step S.","At step , description converter  acquires, in the \u201cmediaObject\u201d element of summary content description  described with the structure description data, a type of the media from the \u201ctype\u201d attribute, format of the media from the \u201cformat\u201d attribute, and URL of the media data from the \u201csrc\u201d attribute. Description converter  next functions as an analyzer by acquiring at step S the time information of a media segment from the \u201cstart\u201d attribute and \u201cend\u201d attribute of each \u201csegment\u201d element to store. The converter  generates at step  representing method description  described with the SMIL document using the format of the media, URL of the media data, and time information of media segments acquired at steps  and  to output.","Meanwhile, description converter  acquires at step S the \u201cmediaObject\u201d element at the head of the \u201cpar\u201d element. The converter  next acquires at S in the acquired \u201cmediaObject\u201d element a type of the media from the \u201ctype\u201d attribute, format of the media from the \u201cformat\u201d attribute, and URL of the media data from the \u201csrc\u201d attribute. The converter  next acquires at step S the time information of a media segment from the \u201cstart\u201d attribute and \u201cstop\u201d attribute of each \u201csegment\u201d element to store.","Description converter  examines at step S whether or not a \u201cmediaObject\u201d element that has not been examined is still present in the \u201cpar\u201d element. When there is a \u201cmediaObject\u201d element that has not been examined, the converter  acquires the first one at step S, and shifts to the processing of step S. Meanwhile when there is no \u201cmediaObject\u201d element that has not been examined, the converter  shifts to the processing of step S.","At step S, description converter  groups together segments belonging to different \u201cmediaObject\u201d elements and overlapping timewise using the stored time information of the \u201csegment\u201d elements. Then the converter  generates at step S representing method description  described with the SMIL document using the format of the media, URL of the media data, and time information of media segments acquired at steps S and S to output.","With reference to , the processing at step S will be described below where when summary content description  of structure description data does not has the \u201cpar\u201d element, description converter  outputs representing method description  of SMIL document from summary content description .  is a flowchart for the description converter according to the first embodiment to output the representing method description that is the SMIL document from the summary content description that is the structure description data.","First, description converter  outputs a header of SMIL (step S).","The SMIL document is, as illustrated in , composed of header  and body . Header  is described in a \u201chead\u201d element, while body  is described in a \u201cbody\u201d element. That is, header  is indicated by a portion enclosed by <head> and <\/head>, while body  is indicated by a portion enclosed by <body> and <\/body>.","Examples described in the header are information such as a creator and creation data, and layout such as where to display an image and text on a screen. The header is capable of being omitted.","Description converter  encloses the entire media segments by <seq> and <\/seq> (step S). These are \u201cseq\u201d elements, and are indicative of representing or displaying the media segments enclosed by <seq> <\/seq> in the order in which the segments are described.","Description converter  next performs the following processing for each of the media segments enclosed by <seq> <\/seq>.","First, according to the media type, description converter  selects a corresponding element from the \u201caudio\u201d element, \u201cvideo\u201d element, \u201cref\u201d element and \u201cimg\u201d element of SMIL. (step S). In addition, the \u201cref\u201d element is defined as a description not to specify media of a source. The \u201cref\u201d element is assigned either of audio, moving picture, still picture and multiplexed moving picture and audio.","Description converter  next sets values of a \u201cclip-begin\u201d attribute and \u201cclip-end\u201d attribute of the element selected at step S as described below. That is, description converter  sets values of the \u201cclip-begin\u201d attribute and \u201cclip-end\u201d attribute of SMIL respectively at a value of the \u201cstart\u201d attribute and a value of the \u201cend\u201d attribute of the corresponding \u201csegment\u201d element of summary content description  (step S). In addition, \u201cclip\u201d is indicative of a timewise interval.","Description converter  next sets a value of the \u201csrc\u201d attribute of the element selected at step S at a value of the \u201csrc\u201d attribute of the \u201cmediaObject\u201d element that is a parent element of the corresponding \u201csegment\u201d element of summary content description . Then, the converter  outputs the description of the element selected at step S.","Thus, description converter  generates representing method description  that is representation description data written in SMIL from summary content description  that is the structure description data.",{"@attributes":{"id":"p-0119","num":"0118"},"figref":["FIG. 7","FIG. 2B","FIG. 7"],"b":"1003"},"In the example of document illustrated in , the processing is performed to the information of time 00:00:00 to 00:01:00 of http:\/\/mserv.com\/MPEG\/movie0.mpg, the information of time 00:00:01 to 00:02:00 of http:\/\/mserv.com\/MPEG\/movie0.mpg, the information of time 00:03:00 to 00:04:00 of http:\/\/mserv.com\/MPEG\/movie0.mpg, and the information of time 00:04:00 to 00:05:00 of http:\/\/mserv.com\/MPEG\/movie0.mpg in this order. In addition, in the example illustrated in , a header is omitted.","It may be also possible to add processing for putting together timewise successive clips into one to output the SMIL document illustrated in .","In the example of document illustrated in , the processing is performed to the information of time 00:00:00 to 00:02:00 of http:\/\/mserv.com\/MPEG\/movie0.mpg, and the information of time 00:03:00 to 00:05:00 of http:\/\/mserv.com\/MPEG\/movie0.mpg in this order. In other wise, the document illustrated in  is to execute the same processing as in the example of document illustrated in .","With reference to , the processing of step S will be described below that description converter  outputs representing method description  that is the SMIL document from summary content description  when summary content description  that is the structure description data has the \u201cpar\u201d element.  is a flowchart for the description converter according to the first embodiment to output the representing method description that is the SMIL document from the summary content description that is the structure description data.","Description converter  first outputs a header of SMIL (step S). The converter  next encloses the entire media segments with <seq> an <\/seq> (step S). Then the converter  encloses a group of media segment by <par> and <\/par> of SMIL in the order in which the time is fast (step S).","Description converter  next judges whether there is another media segment belonging to the same \u201cmediaObject\u201d element (step S), and when there is another media segment, encloses it by <seq> and <\/seq> (step S). Then, the converter  performs the following processing for each media segment enclosed by <seq> and <\/seq>.","First, according to the media type, description converter  selects a corresponding element from the \u201caudio\u201d element, \u201cvideo\u201d element, \u201cref\u201d element and \u201cimg\u201d element and so on of SMIL (step S). The converter  next sets values of the \u201cclip-begin\u201d attribute and \u201cclip-end\u201d attribute of the selected element. That is, the converter  sets values of the \u201cclip-begin\u201d attribute and \u201cclip-end\u201d attribute of SMIL respectively at a value of the \u201cstart\u201d attribute and a value of the \u201cend\u201d attribute of the corresponding \u201csegment\u201d element of summary content description  (step S). The converter  next sets a value of the \u201csrc\u201d attribute of the selected element at a value of the \u201csrc\u201d attribute of the \u201cmediaObject\u201d element that is a parent element of the corresponding \u201csegment\u201d element of summary content description  (step S). Then, the converter  outputs the description of the selected element.","Meanwhile, when there is no media segment belonging to the same \u201cmediaObject\u201d element, description converter  does not perform the processing of enclosing by <seq> and <\/seq>, and performs the same processing as the above-described processing performed for each media segment.","Thus, even when summary content description  of structure description data is composed of a plurality of media, description converter  generates representing method description  of representation description data for processing a plurality of media in synchronism with each other.",{"@attributes":{"id":"p-0129","num":"0128"},"figref":["FIG. 10","FIG. 3","FIG. 10"]},"In the example of document illustrated in , the processing is performed for synchronizing the information of time 00:00:00 to 00:01:00 of http:\/\/mserv.com\/MPEG\/movie0v.mpv that is video and the information of time 00:00:00 to 00:01:00 of http:\/\/mserv.com\/MPEG\/movie0a.mp2 that is audio, synchronizing the information of time 00:01:00 to 00:02:00 of http:\/\/mserv.com\/MPEG\/movie0v.mpv that is video and the information of time 00:01:00 to 00:02:00 of http:\/\/mserv.com\/MPEG\/movie0a.mp2 that is audio, synchronizing the information of time 00:03:00 to 00:04:00 of http:\/\/mserv.com\/MPEG\/movie0v.mpv that is video and the information of time 00:03:00 to 00:04:00 of http:\/\/mserv.com\/MPEG\/movie0a.mp2 that is audio, synchronizing the information of time 00:04:00 to 00:05:00 of http:\/\/mserv.com\/MPEG\/movie0v.mpv that is video and the information of time 00:04:00 to 00:05:00 of http:\/\/mserv.com\/MPEG\/movie0a.mp2 that is audio, and further processing the synchronized information in the order in which the information is described.","Further, as illustrated in , it may be possible to output the SMIL document added processing for putting together timewise successive clips into one.","In order to synchronize a plurality of clips in the \u201cpar\u201d element of the SMIL document to each other, a case sometimes arises that it is necessary to made a representation start time of a clip differ from a representation start time of another clip. For example, there is considered a case that audio and video are present in different media objects, a clip of video is indicative of an interval at which a person appears, and that a clip of audio is indicative of a speech that the person speaks. In this case, it is necessary to represent the audio starting from a timing at which the person starts speaking, in accordance with a picture of a motion of the mouse of the person included in the video.","In other words, it is necessary to calculate a representation start time of each clip, and to represent the clip when the time reaches the calculated time. In SMIL, for such a purpose, a \u201cbegin\u201d attribute indicative of delay information is prepared in the \u201caudio\u201d element, \u201cvideo\u201d element, \u201cimg\u201d element, and \u201cref\u201d element.",{"@attributes":{"id":"p-0134","num":"0133"},"figref":["FIG. 12","FIG. 12"]},"By thus shifting the representation times of a plurality of media included in the structure description data using the \u201cbegin\u201d attribute, it is possible to acquire the synchronization between the plurality of media.","As described above, according to the first embodiment, it is possible to convert the structure description data expressive of a structure of media contents into representation description data expressive of representation aspects of the media contents. It is thereby possible to generate distribution data suitable for a user's preference and terminal capabilities by processing or selecting properly the structure description data in distributing the media contents.","Further according to the first embodiment, even when the structure description data is composed of a plurality of media, it is possible to acquire the synchronization between the media. The synchronization between the media is also acquired by shifting the representation timing between the plurality of media.","The first embodiment explains the case that description converter  converts the structure description data expressive of a structure of media contents into the representation description data expressive of representation aspects the media contents, however, it may be possible to program the processing that description converter  performs so that a computer reads the program to execute.","Furthermore, it may be possible to store in a storage medium the program for a computer to execute the processing that description converter  performs.","The second embodiment is, in order to represent and distribute media content suitable for a terminal capability, to describe media segments and alternative data to those in structure description data, and to convert the structure description data into the representation description data expressive of representation aspects of the media segments or alternative data. It is thereby possible to convert the structure description data with a set of alternative data such as representative image of a media segment of moving picture described therein into the representation description data of the alternative data. The second embodiment will be described below.",{"@attributes":{"id":"p-0141","num":"0140"},"figref":["FIGS. 13 to 15","FIG. 13","FIG. 14","FIG. 15"],"b":"1"},"Using , Document Type Definition (DTD) that is a definition for describing the structure description data with XML will be first described.","As illustrated by \u201c\u201d in the figure, a \u201ccontents\u201d element is composed of a \u201cpar\u201d element and a \u201cmediaObject\u201d element. Further as illustrated by \u201c\u201d in the figure, the \u201ccontents\u201d element has a \u201ctitle\u201d attribute indicated by character data. As illustrated by \u201c\u201d in the figure, the \u201cpar\u201d element is composed of a plurality of \u201cmediaObject\u201d elements each is a child element.","As illustrated by \u201c\u201d in the figure, the \u201cmediaObject\u201d element is composed of a \u201csegment\u201d element. As illustrated by \u201c\u201d in the figure, in the \u201cmediaObject\u201d element a type of media is designated by a \u201ctype\u201d attribute. In this example, examples designated as the type of media are \u201caudio\u201d that is audio information, \u201cvideo\u201d that is moving picture information, \u201cimage\u201d that is still picture information, \u201caudiovideo\u201d that is information with multiplexed audio and moving picture, and \u201caudioimage\u201d that is audio and still picture information. When the \u201ctype\u201d attribute is not designated in particular, the \u201ctype\u201d attribute is set to \u201caudiovideo\u201d as default.","As illustrated by \u201c\u201d in the figure, in the \u201cmediaObject\u201d element a format of media such as MPEG1 and MPEG2 is designated for the moving picture, or the format such as gif and jpeg is designated for a still picture, by the \u201cformat\u201d attribute. As illustrated by \u201c\u201d in the figure, in the \u201cmediaObject\u201d element a location where data is stored is designated by an \u201csrc\u201d attribute. Designating Uniform Resource Locator (URL) by the \u201csrc\u201d attribute enables the designation of a location where data is stored.","As illustrated by \u201c\u201d in the figure, by a \u201cstart\u201d attribute, a time inside the media designated by the \u201cmediaObject\u201d element is designated corresponding to the start time of the \u201csegment\u201d element. By an \u201cend\u201d attribute, a time inside the media designated by the \u201cmediaObject\u201d element is designated corresponding to the end time of the \u201csegment\u201d element.","In addition, in this embodiment, the time information on the media segment is designated by a pair of start time and end time, however, such time information may be expressive of a pair of start time and duration.","As illustrated by \u201c\u201d in the figure, the \u201csegment\u201d element has an \u201calt\u201d element. The \u201calt\u201d element is expressive of alternative data to a corresponding media segment. As illustrated by \u201c\u201d in the figure, in the \u201calt\u201d element a type of media such as image and audio is designated by the \u201ctype\u201d attribute. In the \u201calt\u201d element a format of media such as gif and jpeg is designated for a still picture by the \u201cformat\u201d attribute. In the \u201calt\u201d element a location where data is stored is designated by the \u201csrc\u201d attribute.","It is assumed that each segment is capable of being assigned a plurality of \u201calt\u201d elements, and that in the same media, the plurality of \u201calt\u201d elements are represented in the order in which the element appears.","The \u201calt\u201d element has a \u201cpos\u201d element that is a child element. The \u201calt\u201d element is assigned to a corresponding interval of the data designated by the \u201csrc\u201d attribute. The \u201cstart\u201d and \u201cend\u201d attributes of the \u201cpos\u201d element respectively indicate the start time and end time inside the media designated by the \u201csrc\u201d attribute.","In addition, in this embodiment, the time information is designated by a pair of start time and end time, however, may be expressive of a pair of start time and duration.","An example of structure description data for media contents with multiplexed moving picture and audio will be described below using MPEG  as an example with reference to .","In the structure description data illustrated in , a title of \u201cMovie etc\u201d is designated in the \u201ccontents\u201d element. In the \u201cmediaObject\u201d element, \u201caudiovideo\u201d is designated as the type, MPEG1 is designated as the format, and http:\/\/mserv.com\/MPEG\/movie0.mpg is designated as the storing location. The \u201cmediaObject\u201d element has the \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00, the \u201csegment\u201d element with the time information of time 00:01:00 to 00:02:00, the \u201csegment\u201d element with the time information of time 00:03:00 to 00:04:00, and the \u201csegment\u201d element with the time information of time 00:04:00 to 00:05:00. In other words, the \u201cmediaObject\u201d element is indicative of a description without time 00:02:00 to 00:03:00.","The \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00 is instructed by the \u201calt\u201d element that is the alternative data to audiovideo. The \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00 is composed of the \u201calt\u201d element with the type of \u201cimage\u201d, the format of \u201cjpeg\u201d, and the storing location of http:\/\/mserv.com\/IMAGE\/s0.jpg, and the \u201calt\u201d element with the type of \u201caudio\u201d, the format of \u201cmpeg1\u201d, the storing location of http:\/\/mserv.com\/MPEG\/movie0.mp2, and the time information of time 00:00:00 to 00:01:00.","The \u201csegment\u201d element with the time information of time 00:01:00 to 00:02:00 is composed of the \u201calt\u201d element with the type of \u201cimage\u201d, the format of \u201cjpeg\u201d, and the storing location of http:\/\/mserv.com\/IMAGE\/s1.jpg, and the \u201calt\u201d element with the type of \u201caudio\u201d, the format of \u201cmpeg1\u201d, the storing location of http:\/\/mserv.com\/MPEG\/movie0.mp2, and the time information of time 00:01:00 to 00:01:30.","The \u201csegment\u201d element with the time information of time 00:03:00 to 00:04:00 is composed of the \u201calt\u201d element with the type of \u201cimage\u201d, the format of \u201cjpeg\u201d, and the storing location of http:\/\/mserv.com\/IMAGE\/s3.jpg, and the \u201calt\u201d element with the type of \u201caudio\u201d, the format of \u201cmpeg1\u201d, the storing location of http:\/\/mserv.com\/MPEG\/movie0.mp2, and the time information of time 00:03:00 to 00:03:30.","The \u201csegment\u201d element with the time information of time 00:00:40 to 00:05:00 is composed of the \u201calt\u201d element with the type of \u201cimage\u201d, the format of \u201cjpeg\u201d, and the storing location of http:\/\/mserv.com\/IMAGE\/s4.jpg, and the \u201calt\u201d element with the type of \u201caudio\u201d, the format of \u201cmpeg1\u201d, the storing location of http:\/\/mserv.com\/MPEG\/movie0.mp2, and the time information of time 00:04:00 to 00:05:00.","An example of structure description data of media contents with moving picture and audio in different media will be described below using .","In the structure description data illustrated in , a title of \u201cMovie etc\u201d is designated in the \u201ccontents\u201d element. In the example of , the \u201ccontents\u201d element is composed of the \u201cmediaObject\u201d element with the type of \u201cvideo\u201d and the \u201cmediaObject\u201d element with the type of \u201caudio\u201d. Accordingly, by the \u201cpar\u201d element, the \u201cmediaObject\u201d element of \u201caudio\u201d type is synchronized with the \u201cmediaObject\u201d element of \u201cvideo\u201d type.","In the \u201cmediaObject\u201d element of \u201cvideo\u201d type, MPEG 1 is designated as the format, and http:\/\/mserv.com\/MPEG\/movie0v.mpv is designated as a storing location. The \u201cmediaObject\u201d element of \u201cvideo\u201d type has the \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00, the \u201csegment\u201d element with the time information of time 00:01:00 to 00:02:00, the \u201csegment\u201d element with the time information of time 00:03:00 to 00:04:00, and the \u201csegment\u201d element with the time information of time 00:04:00 to 00:05:00. In other words, the \u201cmediaObject\u201d element of \u201cvideo\u201d type is indicative of a description without time 00:02:00 to 00:03:00.","The \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00 is instructed by the \u201calt\u201d element that is the alternative data to video. The \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00 is instructed by the \u201calt\u201d element with the type of \u201cimage\u201d, the format of \u201cjpeg\u201d, and the storing location of http:\/\/mserv.com\/IMAGE\/s0.jpg. The \u201csegment\u201d element with the time information of time 00:01:00 to 00:02:00 is instructed by the \u201calt\u201d element with the type of \u201cimage\u201d, the format of \u201cjpeg\u201d, and the storing location of http:\/\/mserv.com\/IMAGE\/s1.jpg. The \u201csegment\u201d element with the time information of time 00:03:00 to 00:04:00 is instructed by the \u201calt\u201d element with the type of \u201cimage\u201d, the format of \u201cjpeg\u201d, and the storing location of http:\/\/mserv.com\/IMAGE\/s3.jpg. The \u201csegment\u201d element with the time information of time 00:00:40 to 00:05:00 is instructed by the \u201calt\u201d element with the type of \u201cimage\u201d, the format of \u201cjpeg\u201d, and the storing location of http:\/\/mserv.com\/IMAGE\/s4.jpg.","Further, in the \u201cmediObject\u201d element of \u201caudio\u201d type, MPEG 1 is designated as the format, and http:\/\/mserv.com\/MPEG\/movie0a.mp2 is designated as the storing location. The \u201cmediaObject\u201d element of \u201caudio\u201d type has the \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00, the \u201csegment\u201d element with the time information of time 00:01:00 to 00:02:00, the \u201csegment\u201d element with the time information of time 00:03:00 to 00:04:00, and the \u201csegment\u201d element with the time information of time 00:04:00 to 00:05:00. In other words, the \u201cmediaObject\u201d element of \u201caudio\u201d type is indicative of a description without time 00:02:00 to 00:03:00.","The \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00 is instructed by the \u201calt\u201d element that is the alternative data to audio. The \u201csegment\u201d element with the time information of time 00:00:00 to 00:01:00 is instructed by the \u201calt\u201d element with the type of \u201caudio\u201d, the format of \u201cmpeg1\u201d, the storing location of http:\/\/mserv.com\/MPEG\/movie0.mp2, and the time information of time 00:00:00 to 00:01:00. The \u201csegment\u201d element with the time information of time 00:01:00 to 00:02:00 is instructed by the \u201calt\u201d element with the type of \u201caudio\u201d, the format of \u201cmpeg1\u201d, the storing location of http:\/\/mserv.com\/MPEG\/movie0.mp2, and the time information of time 00:01:00 to 00:01:30. The \u201csegment\u201d element with the time information of time 00:03:00 to 00:04:00 is instructed by the \u201calt\u201d, element with the type of \u201caudio\u201d, the format of \u201cmpeg1\u201d, the storing location of http:\/\/mserv.com\/MPEG\/movie0.mp2, and the time information of time 00:03:00 to 00:03:30. The \u201csegment\u201d element with the time information of time 00:00:40 to 00:05:00 is instructed by the \u201calt\u201d element with the type of \u201caudio\u201d, the format of \u201cmpeg1\u201d, the storing location of http:\/\/mserv.com\/MPEG\/movie0.mp2, and the time information of time 00:04:00 to 00:05:00.","Also in this embodiment, SMIL is used as the representation description data as in the first embodiment. The SMIL document is output to represent each media segment as in the first embodiment.","The processing will be described below that is performed by description converter  to output the SMIL document for representing alternate data. Such processing is the same as in the flowchart of  in the first embodiment except the processing of steps S and S for outputting the SMIL document, which will be only described. Thus, the processing different from that in the first embodiment is explained. First, the processing corresponding to step S will be described using .","Description converter  outputs a header of SMIL (step S). The converter  next encloses the entire media segments by <seq> and <\/seq> (step S). Then, for each of the enclosed media segments, the converter  judges whether there is alternative data with different media types (step S).","When description converter  judges at S that there is no alternative data with different media types, the converter  further examines whether there is a plurality of items of alternative data (step S). When there is a plurality of items of alternative data, description converter  encloses the plurality of items of alternative data by <seq> and <\/seq> (step S). Meanwhile, when there is one item of alternative data, the converter  does not enclose the alternative data by <seq> and <\/seq>, and executes the following processing for each alternative data.","In accordance with the type of the alternative data, description converter  selects a corresponding element from the \u201caudio\u201d element, \u201cvideo\u201d element, \u201cimg\u201d element and so on of SMIL (step S). When the \u201cstart\u201d attribute and \u201cend\u201d attribute are designated in a \u201cpos\u201d element as a child element of the \u201calt\u201d element, description converter  sets \u201cclip-begin\u201d and \u201cclip-end\u201d of SMIL respectively at a value of the \u201cstart\u201d attribute and a value of the \u201cend\u201d attribute (step S). Then, the converter  sets the \u201csrc\u201d attribute indicative of a storing location for each alternative data (step S).","Meanwhile, when description converter  judges at S that there is alternative data with different media types, the converter  groups together the alternative data with the same media type (step S).","Description converter  next needs to examine alternative data with the longest duration in order to acquire synchronization among the groups in finishing the representation. Therefore, the converter  calculates the duration for each group from the values of \u201cstart\u201d and \u201cend\u201d attributes of the alternative data (step S). In addition, when the media type is still picture (\u201cimage\u201d) or the \u201cstart\u201d and \u201cend\u201d attributes are not designated, the duration of the alternative data is set to 0.","Description converter  sets an \u201cendsync\u201d attribute of the \u201cpar\u201d element of SMIL so as to synchronize the representation end timing with that of the group with the longest duration (step S), and encloses the entire group by <seq> and <\/seq> to perform the processing of S for each group of each media type.","The \u201cendsync\u201d attribute is for use in a case where the duration is different between media in representing\/displaying in parallel a plurality of media enclosed by <par> and <\/par>. In other words, the \u201cendsync\u201d attribute is to designate in such a case media to which all other media are synchronized in finishing the representation\/display. There are a few methods for designating media in the \u201cendsync\u201d attribute, and this embodiment uses a method for designating media using \u201cid\u201d thereof. Specifically, \u201cid\u201d, which is an identification, is assigned to the attribute of media of a type. Then, by setting the \u201cendsync\u201d attribute=\u201cid\u201d, media belonging to the same group as the media assigned the \u201cid\u201d are synchronized and finished in accordance with the end time of the media assigned the \u201cid\u201d.","Thus, with respect to media with no duration such as a still picture and\/or media in which its display time is not designated by an attribute such as \u201cdur\u201d, it is possible to make the representation end time of such media the same as that of the media assigned \u201cid\u201d. For example, it is possible to continue to display a still picture during the time the media of audio is represented.",{"@attributes":{"id":"p-0174","num":"0173"},"figref":["FIG. 17","FIG. 14"]},"A plurality of groups, i.e., groups  to  are described in the SMIL document in . The group denoted by \u201c\u201d is composed of the alternative data with the type of \u201cimage\u201d, the format of \u201cjpeg\u201d, and the storing location of http:\/\/mserv.com\/IMAGE\/s0.jpg, and the alternative data with the type of \u201caudio\u201d, the format of \u201cmpeg1\u201d, the storing location of http:\/\/mserv.com\/MPEG\/movie0.mp2, and the time information of time 00:00:00 to 00:01:00. Further, the alternative data of \u201caudio\u201d type is assigned (a0) as the \u201cid\u201d attribute. In the group , the \u201cendsync\u201d, attribute is set to \u201cid(a0)\u201d. Thereby, the representation end time of the alternative data included in the group  is synchronized to that of the alternative data of \u201caudio\u201d type. In other words, the alternative data of \u201cimage\u201d type is being represented continuously during the time the alternative data of \u201caudio\u201d type is being represented.","In addition, explanations of groups  to  are omitted.","The processing corresponding to step S is next explained using . Description converter  first outputs a header of SMIL (step S). The converter  next encloses the entire media segments by <seq> and <\/seq> (step S).","Description converter  groups together alternative data belonging to the same \u201cmediaObject\u201d element in the order in which the time is fast in the group of the media segment (step S), and calculates the duration for each group from values of \u201cstart\u201d and \u201cend\u201d attributes (step S). In the case where the media type is still picture (\u201cimage\u201d), or \u201cstart\u201d and \u201cend\u201d attributes are not designated, the duration of the alternative data is set to 0.","Description converter  sets the \u201cendsync\u201d attribute of the \u201cpar\u201d element of SMIL so as to synchronize the representation end timing with that of the group with the longest duration, and encloses the entire portion with <par> and <\/par> (step S).","Description converter  next examines whether there is a plurality of items of alternative data (step S). When there is a plurality of items of alternative data, the converter  encloses the plurality of items of alternative data by <seq> and <\/seq> (step S). Meanwhile, when there is one item of alternative data, the converter  does not enclose the alternative data by <seq> and <\/seq>, and executes the following processing for each alternative data.","In accordance with the type of the alternative data, description converter  selects a corresponding element from the \u201caudio\u201d element, \u201cvideo\u201d element, \u201cimg\u201d element and so on of SMIL (step S). When the \u201cstart\u201d attribute and \u201cend\u201d attribute are designated in the \u201cpos\u201d element as a child element of the \u201calt\u201d element, description converter  sets \u201cclip-begin\u201d and \u201cclip-end\u201d of SMIL respectively at a value of the \u201cstart\u201d attribute and a value of the \u201cend\u201d attribute (step S). Then, the converter  sets the \u201csrc\u201d attribute indicative of a storing location for each alternative data (step S).","In addition, the SMIL document output by the processing illustrated in  using the structure description data illustrated in  is the same as that in .","There is a case that requires to change the representation start time in order to synchronize between clips in the \u201cpar\u201d element in the SMIL document. In this case, it is necessary to calculate the representation start time of each clip, and to start the representation at the calculated time.","In SMIL, for such a purpose, the \u201caudio\u201d, \u201cvideo\u201d, \u201cimg\u201d, and \u201cref\u201d elements are each provided with a \u201cbegin\u201d attribute, and using those enables the achievement.","As described above, according to the second embodiment, it is possible to convert the structure description data in which the structure of the entire or part of the media contents is described with time information of media segments and a set of alternative data which, for example, is indicative of a representative image when the media segment is of moving picture into representation description data that expresses the representation order, representation timing and synchronization information of the media segments or the alternative data to the segments described in the structure description data.","It is thereby possible to generate the information on the representation of display media suitable for a terminal capability, from the information on the structure of media contents. As a result, it is possible to generate distribution data suitable for a terminal capability in distributing media contents.","In the third embodiment, in order to perform representation and distribution of media contents suitable for a terminal capability, in the structure description data are described media segments, alternative data to the segments, and data for switching between the media segments and alternative data corresponding to the terminal capability. Then, the structure description data is converted into the representation description data for switching between the media segments and alternative data corresponding to the terminal to express.","The third embodiment of the present invention will be described below. In the representation description data of the third embodiment, two cases, i.e., a case of representing media segments and another case of representing the alternative data, are described in one SMIL document to be output. Examples used as the structure description data are as illustrated in .","Both cases of representing media segments and of representing the alternative data are described in the representation description data output in this embodiment. When the media contents are represented based on the representation description data, it is necessary to select either a case of representing media segments or another case of representing the alternative data to represent. Therefore, in the representation description data is described a condition for the selection.","Since a condition for the selection is capable of being described with a \u201cswitch\u201d element in SMIL, the representation description data in this embodiment also uses the SMIL document. The \u201cswitch\u201d element is for use in selecting one meeting the condition from among a plurality of media. In the selection, media are evaluated in the order in which those are described in the content of the \u201cswitch\u201d element, and the media that meets the condition for the first time is selected. The condition is provided in an attribute of the media described in the content of the \u201cswitch\u201d element, and examples are a \u201csystem-bitrate\u201d attribute, \u201csystem-caption\u201d attribute and so on.","In this embodiment, the condition is assumed to be a connection bit rate of a network that distributes media contents. Specifically, it is assumed to represent media contents when the connection bit rate is equal to or more than 56 kbps, while representing the alternative data when the connection bit rate is less than 56 kbps.","The processing will be described below that is performed by description converter  to output the SMIL document for representing media segments or alternate data. Such processing is the same as in the flowchart of  in the first embodiment except part of the processing of steps S and S for outputting the SMIL document. Thus, the processing corresponding to the step S or step S will be only described using .","Description converter  outputs a header of SMIL (step S). The converter  next encloses the entire media by <switch> and <\/switch> (step S). Then, the converter  next encloses the media segment by <seq> and <\/seq> (step S), and sets a \u201csystem-bitrate\u201d attribute of the \u201cseq\u201d element at 56000, i.e., \u201csystem-bitrate\u201d=56000 (step S).","The \u201csystem-bitrate\u201d attribute is used in condition evaluation in the \u201cswitch\u201d element, and is to designate a band available for the system with the number of bits per second. When a value is obtained that is equal to or more than the value of \u201csystem-bitrate\u201d, the \u201cswitch\u201d element is judged to meet the condition. In the above example, when the bit rate is equal to or more than 56000 bps, it is judged to meet the condition. Then, when the condition is satisfied for the first time in the \u201cswitch\u201d element, media with the condition first satisfied is selected.","Description converter  executes the processing of S to S illustrated in  or the processing of S to S (step S), and thereby outputs the SMIL document for representing the media segments.","In this case, by neglecting the \u201calt\u201d element expressive of the alternative data, it is possible to use the processing procedure of the step S or S in the first embodiment.","Next, description converter  does not set the \u201csystem-bitrate\u201d attribute of the \u201cseq\u201d element, but encloses the alternative data by <seq> and <\/seq> (step S), and executes the processing of S to S in  or the processing of S to S in  illustrated in the second embodiment (step S). The converter  thereby outputs the SMIL document for representing the alternative data.","The SMIL document is thus generated that enables the selection on whether to represent the media segments or alternative data.",{"@attributes":{"id":"p-0199","num":"0198"},"figref":["FIG. 20","FIG. 20"],"b":["2000","2001","2002","2001","2002","2001","2001","2002"]},"The \u201cseq\u201d element  is a portion indicative of representing the media segments, while the \u201cseq\u201d element  is a portion indicative of representing the alternative data. Accordingly, when the bit rate available in the system is equal to or more than 56000 bps, the media segments are represented, while when the bit rate available in the system is less than 56000 bps, the alternative data is represented.","In addition, in this embodiment, as a condition for the selection on whether to represent the media segments or alternative data, a connection bit rate of a system is used, but, other conditions may be used. Such a case, however, may include a condition disabling the use of \u201cswitch\u201d element of SMIL, and therefore needs to define the representation description data with the \u201cswitch\u201d element of SMIL extended.","Otherwise, as illustrated in , \u201calt\u201d in the structure description data is extended to have a child element called \u201ccondition\u201d in which a condition for using the alternative data designated therein is described, and according to the condition designated in \u201ccondition\u201d, either case is selected.",{"@attributes":{"id":"p-0203","num":"0202"},"figref":["FIG. 21B","FIG. 21B"]},"In order to synchronize between clips in the \u201cpar\u201d element in the SMIL document, there arises a case that needs to differ the representation start time. In this case, the representation start time of each clip is calculated, and the representation is started at the calculated time.","In SMIL, for such a purpose, the \u201caudio\u201d element, \u201cvideo\u201d element, \u201cimg\u201d element, and \u201cref\u201d element each is provided with a \u201cbegin\u201d attribute, and using those enables the achievement.","As described above, according to the third embodiment, it is possible to convert the structure description data in which the structure of the entire or part of the media contents is described with time information of media segments and a set of alternative data which, for example, is indicative of a representative image when the media segment is of moving picture into the representation description data that expresses information indicative of the representation orders, representation timing and synchronization information of the media segments and of the alternative data to the segments described in the structure description data and further indicative of selecting the media segments or the alternative data to represent. It is thereby possible to generate the information on the representation including the selection of the media segments or alternative data from the information on the structure of the media contents corresponding to a terminal.","In the fourth embodiment, with respect to continuous audio visual information (media contents) in which image information and audio information are synchronized, in order to represent and distribute only a representative part of the media contents such as an outline and highlight scene, inputs are the structure description data with the structure of the media contents expressed by a set of portions (media segments) obtained by dividing the media contents, with time information of each media segment, and with an importance degree based on the context content of the media segment, and a threshold of the importance degree based on the context content, and only media segments each with the importance degree not less than the threshold are selected from the structure description data. Then, the structure description data on the selected media segments is converted into representation description data expressive of the representation order and representation timing of the selected media segments as representation aspects, and the resultant data is output.","Only the media segments with high importance degrees are thus selected from the information on the structure of the media contents, whereby it is possible to select only the media segments composing an outline or highlight scene and to convert the structure data into the representation description data on the representation of only the selected media segments.","The fourth embodiment of the present invention will be described below. The fourth embodiment relates to a structure where the alternative data to a media segment is not designated.  illustrates a block diagram of a data processing apparatus in the fourth embodiment. In , \u201c\u201d denotes a summary engine as a selector, \u201c\u201d denotes a description converter as converting means, \u201c\u201d denotes a content description that is of input data and structure description data, \u201c\u201d denotes a selection condition, and \u201c\u201d denotes a representing method description that is of output data and representation description data.",{"@attributes":{"id":"p-0210","num":"0209"},"figref":["FIG. 23","FIG. 23","FIG. 2A"],"b":"2301"},{"@attributes":{"id":"p-0211","num":"0210"},"figref":"FIG. 24","b":"1503"},"As illustrated by \u201c\u201d in the figure, each segment is assigned the \u201cscore\u201d attribute indicative of the importance degree.","In the fourth embodiment, the importance degree of a media segment is used as selection condition . Summary engine  selects a media segment under the condition that the importance degree of the media segment is equal to or more than a threshold. The processing of summary engine  as selecting means will be described below with reference to the flowchart in .","At step S, summary engine  fetches a first media segment described in content description , in other words, the first one in the \u201csegment\u201d element. At step S, summary engine  fetches the \u201cscore\u201d attribute of the \u201csegment\u201d element indicative of a score of the fetched media segment, and examines whether the \u201cscore\u201d attribute is not less than the threshold. When the \u201cscore\u201d attribute of the first segment is equal to or more than the threshold, summary engine  shifts to the processing of step S, while shifting to the processing of step S when the \u201cscore\u201d attribute of the first media segment is less than the threshold.","At step S, summary engine  outputs to description converter  as converting means values of the \u201cstart\u201d and \u201cend\u201d attributes of the \u201csegment\u201d element that are respectively expressive of start time and end time of the corresponding media segment.","At step S, summary engine  examines whether there is any unprocessed media segment. When there is an unprocessed media segment, summary engine  shifts to the processing of step S, while finishing the processing when there is no unprocessed media segment.","At step S, summary engine  fetches a first \u201csegment\u201d element in the unprocessed media segment, and shifts to the processing of step S.","The processing of description converter  as converting means is the same as that of the procedures for converting the structure description data into SMIL in  explained in the first embodiment, and the detailed explanation is omitted.","The fourth embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.",{"@attributes":{"id":"p-0220","num":"0219"},"figref":["FIG. 26","FIG. 23"],"b":"1503"},"As can be seen form \u201c\u201d in the figure, in the intermediate type of structure description data, media segments with the score equal to or more than 4 are only selected and described.","The selection condition is that the importance degree of a media segment is equal to or more than a threshold, however, another condition may be that the sum total of representation time periods of the selected media segments is equal to or less than a threshold. In this case, summary engine  is set for the processing of sorting all the media segments in descending order of importance degree, and of selecting media segments starting from the first one in sorting so that the sum total of the representation time periods is equal to or less than the threshold and the greatest. Another condition may be obtained by combining the condition on the importance degree of a media segment and the condition on the representation time periods.","As described above, according to the fourth embodiment, media segments are selected by using the importance degree based on the context content of the media segments, whereby it is possible to compose an outline, highlight scene collection and the like and to generate the representation description data thereon. It is thereby possible to represent and distribute the media contents of only a portion that a user desires.","In addition, it may be possible to generate a summary content description with the representation time period of a segment changed corresponding to the importance degree of the segment.","In contrast to the fourth embodiment limiting a media object to one with image information and audio information, the fifth embodiment includes a case that a plurality of media objects are synchronized to be composed.","The fifth embodiment of the present invention will be described below. The fifth embodiment relates to a structure where the alternative data to a media segment is not designated. A block diagram of a data processing apparatus in the fifth embodiment is the same as that illustrated in .","Also in the fifth embodiment, as DTD for structure description data , the same DTD as illustrated in  is used.  illustrates an example of content description  that is the structure description data in the fifth embodiment.","In content description  illustrated in  are described \u201cmediaObject\u201d element  with the type of \u201cvideo\u201d, and \u201cmediaObject\u201d element  with the type of \u201caudio\u201d. As illustrated by \u201c\u201d in the figure, in the segment of \u201cmediaObject\u201d element  with the type of \u201cvideo\u201d is described the \u201cscore\u201d attribute indicative of the importance degree. Also as illustrated by \u201c\u201d in the figure, in the segment of \u201cmediaObject\u201d element  with the type of \u201caudio\u201d is described the \u201cscore\u201d attribute indicative of the importance degree.","Also in the fifth embodiment, it is assumed that selection condition  is that the importance degree of a segment is equal to or more than a threshold. Summary engine  as a selector performs the processing thereof in the fourth embodiment for each \u201cmediaObject\u201d element.\u2014",{"@attributes":{"id":"p-0230","num":"0229"},"figref":"FIG. 28","b":"1501"},"At step S, summary engine  fetches a first \u201cmediaObject\u201d element. At step S, summary engine  fetches a first \u201csegment\u201d element among the media segments that are the contents of the fetched \u201cmediaObject\u201d element. At step S, summary engine  fetches a value of the \u201cscore\u201d attribute of the \u201csegment\u201d element indicative of a score of the fetched media segment, and examines whether the value is not less than the threshold. When the score of the fetched media segment is equal to or more than the threshold, summary engine  shifts to the processing of step S, while shifting to the processing of step S when the score of the fetched media segment is less than the threshold. At step S, summary engine  outputs to description converter  values of the \u201cstart\u201d and \u201cend\u201d attributes of the \u201csegment\u201d element that are respectively start time and end time of the corresponding media segment.","At step S, summary engine  examines whether there is any unprocessed media segment. When there is an unprocessed media segment, summary engine  shifts to the processing of step S, while shifting to the processing of step S when there is no unprocessed media segment.","Meanwhile, at step S, summary engine  examines whether any unprocessed \u201cmediaObject\u201d element is still left, and shifts to the processing of step S when an unprocessed \u201cmediaObject\u201d element is still left, while finishing the processing when no unprocessed \u201cmediaObject\u201d element is left. At step S, summary engine  fetches a first \u201cmediaObject\u201d element in the unprocessed \u201cmediaObject\u201d element, and shifts to the processing of step S.","Description converter  as converting means in the fifth embodiment also performs, for each \u201cmediaObject\u201d element, the processing the same as that of the procedures for converting the structure description data into SMIL in  explained in the first embodiment.","The fifth embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.",{"@attributes":{"id":"p-0236","num":"0235"},"figref":["FIG. 29","FIG. 27"],"b":"1503"},"As can be seen form \u201c\u201d in the figure, in the \u201cmediaObject\u201d element with the type of \u201cvideo\u201d, media segments with the score equal to or more than 4 are only selected and described. Also, as can be seen form \u201c\u201d in the figure, in the \u201cmediaObject\u201d element with the type of \u201caudio\u201d, media segments with the score equal to or more than 4 are only selected and described.","With respect to each clip in the \u201cpar\u201d element in the SMIL document, there arises a case that needs to differ the representation start time to synchronize between clips. In this case, the representation start time of each clip is calculated, and the representation is started at the calculated time.","In SMIL, for such a purpose, the \u201caudio\u201d element, \u201cvideo\u201d element, \u201cimg\u201d element, and \u201cref\u201d element are each provided with a \u201cbegin\u201d attribute, and using those enables the achievement.","As described above, according to the fifth embodiment, media segments are selected by using the importance degree based on the context content of the media segments, whereby it is possible to compose an outline, highlight scene collection and the like and to generate the representation description data thereon. It is thereby possible to represent and distribute the media contents of only a portion that a user desires.","The sixth embodiment of the present invention will be described below. In contrast to the fourth embodiment where alternative data to a media segment is not designated, in the sixth embodiment, the alternative data to a media segment is designated. Further, the sixth embodiment relates to a configuration where the summary engine does not perform the selection on whether to represent a media segment or alternative data.","A block diagram of a data processing apparatus in the sixth embodiment is the same as that illustrated in .",{"@attributes":{"id":"p-0243","num":"0242"},"figref":["FIG. 30","FIG. 30","FIG. 13"],"b":"3001"},{"@attributes":{"id":"p-0244","num":"0243"},"figref":["FIG. 31","FIG. 31"],"b":"1503"},"The processing of summary engine  as selecting means in the sixth embodiment is the same as that of the summary engine in the fourth embodiment. In addition, summary engine  as selecting means in the sixth embodiment outputs the \u201calt\u201d element that is a child element as well as the \u201cstart\u201d attribute and \u201cend\u201d attribute of the \u201csegment\u201d element in outputting the selected media segment.","The processing of description converter  as converting means in the sixth embodiment is the same as that of the procedures for converting the structure description data into SMIL in  explained in the first to third embodiments.","This embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.",{"@attributes":{"id":"p-0248","num":"0247"},"figref":["FIG. 32","FIG. 31"],"b":"1503"},"In the structure description data illustrated in , segments each with a value of the \u201cscore\u201d attribute indicative of the importance degree equal to or more than 4 and alternative data to the segments are only selected and described.","The seventh embodiment of the present invention will be described. In contrast to the fifth embodiment where alternative data to a media segment is not designated, in the seventh embodiment, the alternative data to a media segment is designated. Further, the seventh embodiment relates to a configuration where the alternative data to a media segment is designated, and the summary engine does not perform the selection on whether to represent a media segment or the alternative data.","A block diagram of a data processing apparatus in the seventh embodiment is the same as that illustrated in .","Also in the seventh embodiment, the same DTD as illustrated in  is used as DTD for content description  that is the structure description data.  illustrates an example of content description  that is the structure description data in the seventh embodiment.","The processing of summary engine  as selecting means in the seventh embodiment is the same as that of summary engine  in the fifth embodiment. However, summary engine  according to the seventh embodiment outputs the \u201calt\u201d element that is a child element as well as the \u201cstart\u201d attribute and \u201cend\u201d attribute of the \u201csegment\u201d element in outputting the selected media segment.","The processing of description converter  in the seventh embodiment is the same as that of the procedures for converting the structure description data into SMIL in  explained in the first, second or third embodiment.","This embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.","The structure description data illustrated in  is an example of the intermediate type of structure description data generated from content description  in  with the threshold of 4.","In the structure description data illustrated in , segments each with a value of the \u201cscore\u201d attribute indicative of the importance degree equal to or more than 4 and alternative data to the segments are described for each type of media.","The eighth embodiment is intended to represent and distribute, with display media suitable for a terminal capability, only a representative part of media contents such as an outline and highlight scene of continuous audiovisual information (media contents) in which image information and audio information are synchronized. That is, with respect to media contents, inputs are the structure description data with the structure of the media contents expressed by a set of portions (media segments) obtained by dividing the media contents, with time information of each media segment, and with an importance degree based on the context content of the media segment, and a threshold of the importance degree based on the context content, and only media segments each with the importance degree not less than the threshold are selected from the structure description data. Then, either the media segments or alternative data is selected as a representation aspect of the selected media segments, the structure description data on the selected one is converted into representation description data expressive of the representation order and representation timing of selected one, and the resultant data is output.","Only the media segments with high importance degrees are thus selected from the information on the structure of the media contents, whereby it is possible to select only the media segments composing an outline or highlight scene and to convert the structure data into the representation description data on the representation of only the selected media segments. Accordingly, it is possible to achieve the selection of media corresponding to a capability of a terminal for representing the media contents and a condition of a network that distributes the media contents.","The eighth embodiment of the present invention will be described. In contrast to the sixth embodiment where the alternative data to a media segment is designated, and the selection on whether to represent the media segment or alternative data is not performed, in the eighth embodiment, the alternative data to a media segment is designated, and the selection on whether to represent the media segment or alternative data is performed. In the eighth embodiment, the selecting means is divided into media segment selecting means and representation media selecting means. Further, the selection condition is divided into a segment selection condition and representation media selection condition.",{"@attributes":{"id":"p-0261","num":"0260"},"figref":["FIG. 35","FIG. 35"],"b":["2801","2800","2800","2802","2803"]},"\u201c\u201d, denotes a content description that is of input data and structure description data, \u201c\u201d denotes a segment selection condition, \u201c\u201d denotes a representation media selection condition, and \u201c\u201d denotes a representing method description that is of output data and representation description data.","In the eighth embodiment, content description  that is the structure description data is the same as content description  in the sixth embodiment. That is, content description  uses DTD illustrated in , and one example thereof is illustrated in . Segment selection condition  is the same as selection condition  in the fourth embodiment or sixth embodiment. In this case, the processing of summary engine  as the media segment selecting means is the same as that of summary engine  in the sixth embodiment.","The processing of representation media selecting section  is next explained. Representation media selecting section  uses as representation media selection condition  a connection bit rate of a network for distributing media contents. That is, it is assumed that representation media selecting section  represents media segments when the connection bit rate is equal to or more than 56 kbps, while representing the alternative data when the connection bit rate is less than 56 kbps. Representation media selecting section  examines the connection bit rate, judges which is represented, and notifies the result to converting section .","Converting section  receives its inputs elements of the media segments selected by summary engine  as the media segment selecting means and the result selected by representation media selecting section , and based on the result of representation media selecting section , outputs representing method description  that is the representation description data by SMIL.","The processing performed by converting section  to convert content description  into SMIL is the same as that of procedures for converting the structure description data into SMIL in  explained in the first or second embodiment.","In addition, this embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.","Further, a bit rate of a network is used as representation media selection condition , however, other conditions may be used such as a capability of a representation terminal and a request from a user.","The ninth embodiment of the present invention will be described. In contrast to the eighth embodiment where the alternative data to a media segment is designated, and the selection on whether to represent the media segment or alternative data is not performed, in the ninth embodiment, the alternative data to a media segment is designated, and the selection on whether to represent the media segment or alternative data is performed. Further, the ninth embodiment relates to a configuration where the selecting means performs the selection on whether to represent the media segment or alternative data.","Also in the ninth embodiment as in the eighth embodiment, the selecting means is divided into media segment selecting means and representation media selecting means. Further, the selection condition is divided into a segment selection condition and representation media selection condition. Accordingly, a block diagram of a data processing apparatus in this embodiment is the same as that illustrated in .","In the ninth embodiment, content description  that is the structure description data is the same as content description  in the seventh embodiment. That is, content description  uses DTD illustrated in , and an example of content description  is illustrated in . Segment selection condition  is the same as in the eighth embodiment. Accordingly, the processing of summary engine  is the same as that of summary engine  in the seventh embodiment.","The processing of representation media selecting section  according to the ninth embodiment is the same as that described in the eighth embodiment.","Converting section  receives its inputs elements of the media segment selected by summary engine  and the result selected by representation media selecting section , and based on the result of representation media selecting section , outputs representing method description  that is the representation description data by SMIL. The processing performed by converting section  to convert the structure description data into SMIL is the same as that of procedures for converting the structure description data into SMIL in  explained in the first or second embodiment.","In addition, this embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.","Further, a bit rate of a network is used as representation media selection condition , however, other conditions may be used such as a capability of a representation terminal and a request from a user.","The tenth embodiment is intended to perform representation and distribution of only a representative part of media contents suitable for user's preference with respect to continuous audio visual information (media contents) in which image information and audio information are synchronized. That is, in the tenth embodiment, with respect to the media contents, inputs are the structure description data with the structure of the media contents expressed by a set of portions (media segments) obtained by dividing the media contents, with time information of each media segment, and with an importance degree of each media segment based on a viewpoint represented by a keyword, the viewpoint meeting user's preference, and a threshold of the importance degree, and only media segments each with the importance degree not less than the threshold are selected. Then, as a representation aspect of the selected media segments, the structure description data is converted into representation description data expressive of the representation order and representation timing of the media segments, and the resultant data is output. Thus, only the media segments with importance degrees based on the viewpoint not less than the threshold are selected from the information on the structure of the media contents, and the data conversion is performed only on the representation description data on the representation of only the selected media segments. As a result, it is possible to compose a highlight scene collection and the like suiting user's preference by using the importance degree based on the viewpoint, and to represent and distribute only that part.","The tenth embodiment of the present invention will be described below. The tenth embodiment relates to a configuration where the alternative data to a media segment is not designated. A data processing apparatus in the tenth embodiment is the same as that illustrated in .",{"@attributes":{"id":"p-0278","num":"0277"},"figref":["FIG. 36","FIG. 36","FIG. 2A"],"b":"3601"},"Further, as illustrated by \u201c\u201d in the figure, the \u201cpointOfView\u201d element expresses a viewpoint by a \u201cviewPoint\u201d attribute, and further expresses the importance degree based on the viewpoint indicated in the \u201cviewPoint\u201d attribute by the \u201cscore\u201d attribute. It is assumed that the importance degree is expressed by a positive integer, and that its lowest value is 1. It is possible to provide one \u201csegment\u201d element with a plurality of \u201cpointOfView\u201d elements.  illustrates an example of content description  that is structure description data used in the tenth embodiment.","As can be seen from , for each \u201csegment\u201d element, the \u201cpointOfView\u201d element, and the \u201cviewPoint\u201d attribute and the \u201cscore\u201d attribute thereof are described.","In the tenth embodiment, it is assumed that selection condition  is that the importance degree based on a viewpoint of a media segment is equal to or more than a threshold. The number of viewpoints used in selection condition  is at least one.  illustrates a flowchart of the processing performed by summary engine  as the selecting means in this case.","At step S, summary engine  fetches a \u201csegment\u201d element that is the first media segment. At step S, summary engine  examines all the \u201cpointOfView\u201d elements that are the contents of the \u201csegment\u201d element that is the fetched media segment. Then, summary engine  examines whether there is any \u201cviewPoint\u201d attribute of the examined \u201cpointOfView\u201d element which is assigned a viewpoint designated by selection condition .","When there is a \u201cviewPoint\u201d attribute assigned the viewpoint designated by selection condition , summary engine  shifts to the processing of step S so as to compare the importance degree based on the viewpoint designated by selection condition  with the threshold. Meanwhile, when there is no \u201cviewPoint\u201d attribute assigned the viewpoint designated by selection condition , since there is no importance degree based on the viewpoint designated by selection condition , summary engine  shifts to the processing of step S.","At step , summary engine  examines whether the importance degree based on the viewpoint designated by selection condition  is equal to or more than the threshold. When the importance degree based on the viewpoint designated by selection condition  is equal to or more than the threshold, summary engine  shifts to the processing of step S, while performing the processing of step S when the importance degree based on the viewpoint designated by selection condition  is less than the threshold.","At step S, summary engine  outputs to description converter  values of the \u201cstart\u201d and \u201cend\u201d attributes of the \u201csegment\u201d element that are respectively expressive of start time and end time of the corresponding media segment. At step S, summary engine  examines whether there is any unprocessed media segment, and when there is an unprocessed media segment, shifts to the processing of S. Meanwhile, when there is no unprocessed media segment, summary engine  finishes the processing.","At step S, summary engine  fetches a first \u201csegment\u201d element in the unprocessed media segment, and shifts to the processing of S.","The processing of description converter  is the same as that of the procedures for converting the structure description data into SMIL in  explained in the first embodiment.","The tenth embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.","The selection condition is that the importance degree associated with a viewpoint of a media segment is equal to or more than a threshold, however, another condition may be that the sum total of representation time periods of the selected media segments is equal to or less than a threshold. In this case, summary engine  performs the processing for sorting all the media segments in descending order of importance degree associated with a designated viewpoint, and for selecting media segments starting from the first one in sorting so that the sum total of the representation time periods is equal to or less than the threshold and the greatest.","When there is a plurality of designated viewpoints, summary engine  may use the largest one among importance degrees associated with the designated viewpoints to sort with the value, or may calculate the sum total or average of the importance degrees to sort with the value.","Another condition may be obtained by combining the condition on the importance degree associated with a viewpoint of a media segment and the condition on the representation duration.","As described above, according to the tenth embodiment, only media segments interesting a user are selected by using the importance degree based on a viewpoint represented by a keyword, whereby it is possible to compose an outline, a highlight scene collection and the like suiting user's preference and to generate the representation description data thereon. It is thereby possible to represent and distribute the media contents of a portion that a user desires.","The eleventh embodiment of the present invention will be described below. In contrast to the tenth embodiment which is not provided with a plurality of types of media, the eleventh embodiment relates to a configuration where a plurality of types of media is provided and alternative data to a media segment is not designated. A data processing apparatus in the eleventh embodiment is the same as that illustrated in .","Also in the eleventh embodiment, the same DTD as illustrated in  is used as DTD for content description  that is the structure description data.  illustrates an example of content description  that is structure description data in the eleventh embodiment.","As can be seen from , the structure description data illustrated in  has \u201cmediaObject\u201d elements of different types, and for each \u201csegment\u201d element, the \u201cpointOfView\u201d element, and the \u201cviewPoint\u201d attribute and the \u201cscore\u201d attribute thereof are described.","Also in this embodiment, selection condition  is the same as in the tenth embodiment and is assumed to be that the importance degree based on a viewpoint of a media segment is equal to or more than a threshold. The number of viewpoints used in selection condition  is at least one. In this case, summary engine  performs the processing thereof in the tenth embodiment for each \u201cmediaObject\u201d element.  illustrates a flowchart of the processing performed by summary engine  in the eleventh embodiment.","At step S, summary engine  fetches a first \u201cmediaObject\u201d element. At step S, summary engine  fetches a \u201csegment\u201d element that is the first media segment in the contents of the fetched \u201cmediaObject\u201d element. At step S, summary engine  examines all the \u201cpointOfView\u201d elements that are the contents of the \u201csegment\u201d element that is the fetched media segment, and further examines whether there is any \u201cviewPoint\u201d attribute of the examined \u201cpointOfView\u201d element which is assigned a viewpoint designated by selection condition .","When there is a \u201cviewPoint\u201d attribute of the examined \u201cpointOfView\u201d element which is assigned the viewpoint designated by selection condition , summary engine  shifts to the processing of step S so as to compare the importance degree based on the viewpoint designated by selection condition  with the threshold. Meanwhile, when there is no \u201cviewPoint\u201d attribute of the examined \u201cpointOfView\u201d element which is assigned a viewpoint designated by selection condition , since there is no importance degree based on the viewpoint designated by selection condition , summary engine  shifts to the processing of step S.","At step , summary engine  examines whether the importance degree based on the viewpoint designated by selection condition  is equal to or more than the threshold. When the importance degree based on the viewpoint designated by selection condition  is equal to or more than the threshold, summary engine  shifts to the processing of step S, while shifting to the processing of step S when the importance degree based on the viewpoint designated by selection condition  is less than the threshold.","At step S, summary engine  outputs to description converter  values of the \u201cstart\u201d and \u201cend\u201d attributes of the \u201csegment\u201d element that are respectively expressive of start time and end time of the corresponding media segment. At step S, summary engine  examines whether there is any unprocessed media segment, and when there is an unprocessed media segment, shifts to the processing of step S. When there is no unprocessed media segment, summary engine  shifts to the processing of step S.","At step S, summary engine  examines whether any unprocessed \u201cmediaObject\u201d element is left, and when an unprocessed \u201cmediaObject\u201d element is left, shifts to the processing of step S. When no unprocessed \u201cmediaObject\u201d element is left, summary engine  finishes the processing.","At step S, summary engine  fetches a first \u201cmediaObject\u201d element in the unprocessed \u201cmediaObject\u201d elements, and shifts to the processing of S.","Description converter  in the eleventh embodiment performs the same processing as that of the procedures for converting the structure description data into SMIL in  explained in the first embodiment, except that the converter  performs the processing for each \u201cmediaObject\u201d element.","The eleventh embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.","With respect to each clip in the \u201cpar\u201d element in the SMIL document, there arises a case that needs to differ the representation start time to synchronize between clips. In this case, the representation start time of each clip is calculated, and the representation is started at the calculated time.","In SMIL, for such a purpose, the \u201caudio\u201d element, \u201cvideo\u201d element, \u201cimg\u201d element, and \u201cref\u201d element are each provided with a \u201cbegin\u201d attribute, and using those enables the achievement.","The twelfth embodiment of the present invention will be described. In contrast to the tenth embodiment where alternative data to a media segment is not designated, in the twelfth embodiment, the alternative data to a media segment is designated. Further, the twelfth embodiment relates to a configuration where selecting means does not perform the selection on whether to represent a media segment or the alternative data. A block diagram of a data processing apparatus in the twelfth embodiment is the same as that illustrated in .",{"@attributes":{"id":"p-0308","num":"0307"},"figref":["FIG. 41","FIG. 41","FIG. 42"],"b":"1503"},"As can be seen from the figure, in the content description data illustrated in , the \u201cpointOfView\u201d is added to the \u201csegment\u201d element of DTD to be a child element. In the \u201cpointOfView\u201d element are described the \u201cviewPoint\u201d attribute and the \u201cscore\u201d attribute.","The processing of summary engine  in the twelfth embodiment is the same as that of summary engine  in the tenth embodiment. In addition, summary engine  in the twelfth embodiment outputs the \u201calt\u201d element that is a child element as well as the \u201cstart\u201d attribute and \u201cend\u201d attribute of the \u201csegment\u201d element in outputting the selected media segment.","The processing of description converter  in the twelfth embodiment is the same as that of the procedures for converting the structure description data into SMIL in  explained in the first, second or third embodiment.","This embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.","The thirteenth embodiment of the present invention will be described. In contrast to the eleventh embodiment where alternative data to a media segment is not designated, in the thirteenth embodiment, the alternative data to a media segment is designated. Further, the thirteenth embodiment relates to a configuration where selecting means does not perform the selection on whether to represent a media segment or the alternative data. A block diagram of a data processing apparatus in the thirteenth embodiment is the same as that illustrated in .","Also in the thirteenth embodiment, the same DTD as that illustrated in  is used as DTD for content description .  illustrate examples of content description  that is structure description data in the thirteenth embodiment.","As can be seen from the figure, the structure description data in the thirteenth embodiment has \u201cmediaObject\u201d elements of different types, and has \u201csegment\u201d elements for each \u201cmediaObject\u201d element. Further, for each \u201csegment\u201d element, the \u201cpointOfView\u201d element, and the \u201cviewPoint\u201d attribute and the \u201cscore\u201d attribute thereof are described.","The processing of summary engine  in the thirteenth embodiment is the same as that of summary engine  in the eleventh embodiment. In addition, summary engine  in the thirteenth embodiment outputs the \u201calt\u201d element that is a child element as well as the \u201cstart\u201d attribute and \u201cend\u201d attribute of the \u201csegment\u201d element in outputting the selected media segment.","The processing of description converter  in the thirteenth embodiment is the same as that of the procedures for converting the structure description data into SMIL in  explained in the first, second or third embodiment.","The thirteenth embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.","The fourteenth embodiment of the present invention will be described. In contrast to the twelfth embodiment where selecting means does not perform the selection on whether to represent the media segment or alternative data, in the fourteenth embodiment, selecting means performs selection on whether to represent the media segment or alternative data. In the fourteenth embodiment, the selecting means is divided into media segment selecting means and representation media selecting means. Further, the selection condition is divided into a segment selection condition and representation media selection condition. Accordingly, a block diagram of a data processing apparatus in the fourteenth embodiment is the same as that illustrated in .","In the fourteenth embodiment, content description  is the same as content description  in the twelfth embodiment. That is, content description  of the fourteenth embodiment uses DTD illustrated in , and an example of content description  of the fourteenth embodiment is illustrated in .","Segment selection condition  is the same as selection condition  in the tenth or twelfth embodiment. In this case, the processing of summary engine  is the same as that of summary engine  in the twelfth embodiment.","The processing of representation media selecting section  is next explained. Representation media selecting section  uses as representation media selecting condition  a connection bit rate of a network for distributing media contents. In other words, representation media selecting section  represents media segments when the connection bit rate is equal to or more than 56 kbps, while representing the alternative data when the connection bit rate is less than 56 kbps. Representation media selecting section  examines the connection bit rate, judges which is represented, and notifies the result to converting section .","Converting section  receives its inputs elements of the media segments selected by summary engine  as the media segment selecting means and the result selected by representation media selecting section , and based on the result of representation media selecting section , outputs representing method description  that is the representation description data by SMIL.","The processing performed by converting section  to convert content description  into SMIL is the same as that of procedures for converting the structure description data into SMIL in  explained in the first or second embodiment.","In addition, this embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.","Further, a bit rate of a network is used as representation media selection condition , however, other conditions may be used such as a capability of a representation terminal and a request from a user.","The fifteenth embodiment of the present invention will be described. In contrast to the thirteenth embodiment where selecting means does not perform the selection on whether to represent the media segment or alternative data, in the fifteenth embodiment, selecting means performs selection on whether to represent the media segment or alternative data. Also in the fifteenth embodiment, in the same as in the eighth embodiment, the selecting means is divided into media segment selecting means and representation media selecting means. Further, the selection condition is divided into a segment selection condition and representation media selection condition. Accordingly, a block diagram of a data processing apparatus in this embodiment is the same as that illustrated in .","In the fifteenth embodiment, content description  is the same as content description  in the thirteenth embodiment. That is, content description  of the fifteenth embodiment uses DTD illustrated in , and examples of the content description  of the fifteenth embodiment are illustrated in .","Segment selection condition  in the fifteenth embodiment is the same as selection condition  in the fourteenth embodiment. Accordingly, the processing of summary engine  is the same as that of summary engine  in the thirteenth embodiment.","The processing of representation media selecting section  according to the fifteenth embodiment is the same as that of representation media selecting section  described in the fourteenth embodiment.","Converting section  of the fifteenth embodiment receives its inputs elements of the media segments selected by summary engine  and the result selected by representation media selecting section , and based on the result of representation media selecting section , outputs representing method description  that is the representation description data by SMIL.","The processing performed by converting section  of the fifteenth embodiment to convert content description  into SMIL is the same as that of procedures for converting the structure description data into SMIL in  explained in the first or second embodiment.","In addition, this embodiment has a configuration in which summary engine  outputs the contents of the element of the selected media segment to description converter , and the converter  performs the processing using the contents, however, it may be possible that summary engine  generates the structure description data with selected media segments only left therein, i.e., an intermediate type of the data, and description converter  receives as its input the intermediate type of structure description data to perform the processing.","Further, a bit rate of a network is used as representation media selection condition , however, other conditions may be used such as a capability of a representation terminal and a request from a user.","The sixteenth embodiment of the present invention will be described.  illustrates a block diagram of a data processing apparatus in the sixteenth embodiment. In , \u201c\u201d denotes a structure description data database, \u201c\u201d denotes a selecting section, \u201c\u201d denotes a converting section, \u201c\u201d denotes a representing section, \u201c\u201d denotes a media contents database, \u201c\u201d denotes structure description data, \u201c\u201d denotes selection condition, \u201c\u201d denotes summary content description data, \u201c\u201d, denotes representation description data, and \u201c\u201d denotes media contents data.","Selecting section , converting section , structure description data  and representation description data  are respectively the same as those illustrated in any one of the fourth to fifteenth embodiments. Summary structure description data  corresponds to the intermediate type of structure description data with only the selected media segments left explained in any one of the fourth to fifteenth embodiments. Selecting section  and converting section  are achieved by executing a corresponding program on a computer.","As representing section , since representation description data  is expressed by SMIL, a SMIL player is capable of being used. The SMIL player is achieved by executing a corresponding program on a computer, and as SMIL player software, for example, free software such as Real Player of Real Networks is circulated.","In addition, in the sixteenth embodiment, selecting section  outputs summary structure description data , however, as illustrated in any one of the fourth to fifteenth embodiment, a configuration may be possible where the section  outputs selected media segments instead of outputting summary structure description data .","A sever client system according to the seventeenth embodiment of the present invention will be described with reference to . In the seventeenth embodiment, selecting section  and converting section  are provided on a side of sever , and representing section  is provided on a side of client . Then in the seventeenth embodiment, converting section  and representing section  are connected over network . The seventeenth embodiment thereby provides the sever client system for communicating representation description data  through the network.","The processing contents that each processing section executes are described as corresponding programs executable by a computer, and stored in storage media on sides of sever  and client  to be executed.","In addition, it may be possible to use metadata database  instead of structure description database , summary engines ,  and  instead of selecting section , description converters ,  and  instead of converting section , representation unit  instead of representing section , and media contents database  instead of media contents database .","Further, as illustrated in , the seventeenth embodiment may have a configuration where sever is provided with media contents database , and transmits media contents data  to client through network .","A server client system according to the eighteenth embodiment of the present invention will be described.","The eighteenth embodiment is explained using . In the eighteenth embodiment, selecting section  is provided on a side of sever , and converting section  and representing section  are provided on a side of client . Then in the eighteenth embodiment, selecting section  and converting section  are connected over network . The eighteenth embodiment thereby provides the sever client system for communicating summary structure description data  through the network.","The processing contents that each processing section executes are described as corresponding programs executable by a computer, and stored in storage media on sides of sever  and client  to be executed.","In addition, it may be possible to use metadata database  instead of structure description database , summary engines ,  and  instead of selecting section , description converters ,  and  instead of converting section , representation unit  instead of representing section , and media contents database  instead of media contents database .","Further, as illustrated in , the eighteenth embodiment may have a configuration where sever is provided with media contents database , and transmits media contents data  to client through network .","As explained above, according to the present invention, it is possible to convert structure description data with the structure of media contents composed of media segments described therein into representation description data expressive of an aspect for representing the media contents. It is thereby possible to add conditions such as representation timing and synchronization information to each media segment in representing the media contents.","Further, according to the present invention, the alternative data to the media segments is described in the structure description data, whereby it is possible to select whether to represent the media segments themselves or the alternative data. It is thereby possible to distribute and represent the contents by media suiting a capacity and traffic amount of a network that distributes the media contents and a capability of a terminal that represents the media contents.","Furthermore, according to the present invention, a score based on the context content of each media segment is further described in structure description data, whereby it is possible to easily perform the representation and distribution of, for example, highlight scene collections with different representation time periods. Moreover, by setting the score based on a viewpoint indicated by a keyword, designating the keyword enables only a scene suiting user's preference to be represented and distributed.","The present invention is not limited to the above described embodiments, and various variations and modifications may be possible without departing from the scope of the present invention.","This application is based on the Japanese Patent Applications No. 2000-177955 filed on Jun. 14, 2000 and No. 2001-159409 filed on May 28, 2001, entire content of which is expressly incorporated by reference herein."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The above and other objects and features of the invention will appear more fully hereinafter from a consideration of the following description taken in connection with the accompanying drawing wherein one example is illustrated by way of example, in which;",{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 2B"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 21A"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 21B"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 31"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 37"},{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 38"},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 39"},{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 40"},{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 41"},{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 42"},{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 43"},{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 44"},{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 45"},{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 46"},{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 47"},{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 48"},{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 49"},{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 50"}]},"DETDESC":[{},{}]}
