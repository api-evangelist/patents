---
title: Systems and methods for multiprocessor scalable write barrier
abstract: Systems and methods providing a multiprocessor scalable write barrier to a main memory card table are described. The main memory is divided into multiple cards bit-mapped by the card table. In one aspect, an application store operation (reference) associated with one of the cards is detected. Responsive to detecting the reference, card table bit(s) that are mapped to the card are evaluated. Responsive to determining that the bit(s) have already been marked as dirty, the card table bit(s) are not again marked. This technique effectively reduces the probability of more than a single overlapping write operation to a card table cache line by two or more processors in the system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06973554&OS=06973554&RS=06973554
owner: Microsoft Corporation
number: 06973554
owner_city: Redmond
owner_country: US
publication_date: 20030423
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The invention pertains to memory management.","Automatic memory management is one of the services Common Language Runtime (CLR) provides to an application during execution. Such memory management includes, for example, garbage collection (GC) to manage the allocation and release of memory for an application. GC implementations, such as the CLR GC, are often generational, based on a notion that newly generated objects are short-lived, tend to be smaller, and are accessed often. To this end, a generational GC (GGC) keeps track of object references from older to younger (i.e., object generations) so that younger objects can be garbage-collected without inspecting every object in older generation(s). For instance, generation zero (G) contains young, frequently used objects that are collected often, whereas Gand Gare used for larger, older objects that are collected less frequently.","To facilitate GGC, an application's memory heap is divided into multiple equally sized cards that are usually bigger than a word and smaller than a page. The GGC uses a \u201ccard table\u201d, which is typically a bitmap, to map each card to one or more respective bits, usually a byte. At every reference (i.e., store instruction) to a card that creates or modifies a pointer from an older to a newer object, the GGC records\/marks the card being written into by setting the card's corresponding card table bits. Subsequently, when scanning an older generation to identify intergenerational references for garbage collection (i.e., when collecting a younger generation), only the cards (in the old generation) identified by corresponding marked card table bits are scanned.","Card-marking is also a well known technique to implement \u201cwrite barrier\u201d. In particular, a write barrier call is inserted by the compiler in places where there is a store object reference instruction. This write barrier stores the object reference and also marks the card corresponding to the location of the store. Such card marking is required to be atomic with respect to other processors\/threads to ensure that one thread does not undue another thread's work. Although such thread synchronization maintains data integrity, it also typically slows down thread execution, and thereby, overall system performance.","In view of this, certain programming techniques may be used to reduce the probability that more than a single thread will compete for access to any particular object at any one time. Such techniques generally involve storing each object in its own cache line (i.e., an object will not share a same cache line with any other object). This technique effectively reduces competition by multiple threads for a same cache line during object store operations. Unfortunately, this programming technique does not alleviate problems caused when multiple threads compete for a same cache line in the card table, wherein each card of a system's main memory is represented with one or more bits, during card marking operations. To make matters worse, such conventional programming techniques are not realistically transferable to the card table because prohibitive amounts of memory would be required to represent each of the card table's atomic values (one or more bits mapped to a card) with its own cache line.","In view of this, systems and methods to improve system performance during card marking\/write barrier operations are greatly desired.","Systems and methods providing a multiprocessor scalable write barrier to a main memory card table are described. The main memory is divided into multiple cards bit-mapped by the card table. In one aspect, an application store operation (reference) associated with one of the cards is detected. Responsive to detecting the reference, card table bit(s) that are mapped to the card are evaluated. Responsive to determining that the bit(s) have already been marked as dirty, the card table bit(s) are not again marked. This technique effectively reduces the probability of more than a single overlapping write operation to a card table cache line by two or more processors in the system.","Overview","Systems and methods are described to reduce the potential that two or more processors in a multiprocessor environment will compete for overlapped access to a same card table cache line during program store operations. To achieve this reduction, card marking operations read (e.g., check or evaluate) the one or more bits corresponding to the particular card into which a thread is going to store a value. If the one or more bits are already set (not clear), then the card is not re-marked. Otherwise, if the card has not been marked, the card marking operations write (an atomic operation) to the one or more bits to mark the card. Once a card has been set it is not again (repeatedly) set by running program threads. (When the GC collects the data from the card (releases or frees data\/an object), the corresponding card table bit(s) are cleared).","In light of this, for each unmarked card in main memory, there is a probability of at most only a single instance of thread contention to a cache line corresponding to a card table during card marking operations. This is especially advantageous in multiprocessing environments, wherein triggered data coherency operations between different processor threads generally result in substantial degradation of multiprocessor system operating performance.","In one implementation, the described card marking techniques are scalable across multiprocessor and single processor computing environments. To this end, when two or more processors are detected, the novel card mark checking operations are compiled in a CLR by well known Just-in-Time (JIT) compiling techniques or precompiled, and executed during card marking operations. This streamlines data coherency operations in the multiprocessing environment. When only a single processor system is detected, the card mark checking operations are not compiled (i.e., bypassed or skipped), therefore streamlining program execution (e.g., via reduced code size and reliance on single processor pre-emption of threads) for the single processor system.","Exemplary Operating Environment","Turning to the drawings, wherein like reference numerals refer to like elements, the invention is illustrated as being implemented in a suitable computing environment. Although not required, the invention is described in the general context of computer-executable instructions, such as program modules, being executed by a personal computer. Program modules generally include routines, programs, objects, components, data structures, etc., that perform particular tasks or implement particular abstract data types.",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 1","b":["120","120","120","120"]},"The methods and systems described herein are operational with numerous other general purpose or special purpose computing system environments or configurations. Because the following describes systems and techniques scale write barrier operations across both multiprocessor and single processor systems, examples of well known computing systems, environments, and\/or configurations that may be suitable include, but are not limited to, include hand-held devices, symmetrical multi-processor (SMP) systems, microprocessor based or programmable consumer electronics, network PCs, minicomputers, mainframe computers, portable communication devices, and the like. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote memory storage devices.","As shown in , computing environment  includes a general-purpose computing device in the form of a computer . In one implementation, the components of computer  includes two or more processors - through -N, a system memory , and a bus  that couples various system components including system memory  to processor . In another implementation, wherein the scalable nature of GC write barrier operations are configured for optimal operation on a single-processor system, the computer  includes only one processor , for example, -. Bus  represents one or more of any of several types of bus structures, including a memory bus or memory controller, a peripheral bus, an accelerated graphics port, and a processor or local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnects (PCI) bus also known as Mezzanine bus.","Computer  typically includes a variety of computer readable media. Such media may be any available media that is accessible by computer , and it includes both volatile and non-volatile media, removable and non-removable media. In , system memory  includes computer readable media in the form of volatile memory, such as random access memory (RAM) , and\/or non-volatile memory, such as read only memory (ROM) . A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between elements within computer , such as during start-up, is stored in ROM. RAM typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processor(s) - through -N.","Computer  may further include other removable\/non-removable, volatile\/non-volatile computer storage media. For example,  illustrates a hard disk drive  for reading from and writing to a non-removable, non-volatile magnetic media (not shown and typically called a \u201chard drive\u201d), a magnetic disk drive  for reading from and writing to a removable, non-volatile magnetic disk  (e.g., a \u201cfloppy disk\u201d), and an optical disk drive  for reading from or writing to a removable, non-volatile optical disk  such as a CD-ROM\/R\/RW, DVD-ROM\/R\/RW\/+R\/RAM or other optical media. Hard disk drive , magnetic disk drive  and optical disk drive  are each connected to bus  by one or more interfaces .","The drives and associated computer-readable media provide nonvolatile storage of computer readable instructions, data structures, program modules, and other data for computer . Although the exemplary environment described herein employs a hard disk, a removable magnetic disk  and a removable optical disk , it should be appreciated by those skilled in the art that other types of computer readable media which can store data that is accessible by a computer, such as magnetic cassettes, flash memory cards, digital video disks, random access memories (RAMs), read only memories (ROM), and the like, may also be used in the exemplary operating environment.","A number of program modules may be stored on the hard disk, magnetic disk , optical disk , ROM , or RAM , including, e.g., an operating system (OS)  to provide a runtime environment, one or more application programs , other program modules , and program data . In one implementation, wherein the computer  comprises two or more (i.e., \u201cN\u201d) multiple processors - through -N, the (OS) supports N-way symmetric multiprocessing (SMP) between the N processors, and other services (e.g., Internet and network operating system (NOS) services, load balancing, etc).","A user may provide commands and information into computer  through input devices such as keyboard  and pointing device  (such as a \u201cmouse\u201d). Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, serial port, scanner, camera, etc. These and other input devices are connected to the processing unit(s)  through a user input interface  that is coupled to bus , but may be connected by other interface and bus structures, such as a parallel port, game port, or a universal serial bus (USB).","A monitor  or other type of display device is also connected to bus  via an interface, such as a video adapter . In addition to monitor , personal computers typically include other peripheral output devices (not shown), such as speakers and printers, which may be connected through output peripheral interface .","Computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . Remote computer  may include many or all of the elements and features described herein relative to computer . Logical connections shown in  are a local area network (LAN)  and a general wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet.","When used in a LAN networking environment, computer  is connected to LAN  via network interface or adapter . When used in a WAN networking environment, the computer typically includes a modem  or other means for establishing communications over WAN . Modem , which may be internal or external, may be connected to system bus  via the user input interface  or other appropriate mechanism.","Depicted in , is a specific implementation of a WAN via the Internet. Here, computer  employs modem  to establish communications with at least one remote computer  via the Internet .","In a networked environment, program modules depicted relative to computer , or portions thereof, may be stored in a remote memory storage device. Thus, e.g., as depicted in , remote application programs  may reside on a memory device of remote computer . It will be appreciated that the network connections shown and described are exemplary and other means of establishing a communications link between the computers may be used.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 2","FIG. 1","FIG. 2","FIG. 1"],"b":["134","160","164","202","204"]},"In this implementation, one or more host application(s)  host the CLR  (hereinafter also referred to as the \u201cruntime\u201d) by loading the runtime into the host application process when the process is executed. Once the runtime has been loaded into the process, the host uses a well known exposed application programming interface (API)  to access CLR managed memory management functionality, for example, via the novel GC module . The GC module implements generational garbage collection (GGC) techniques such that younger objects are collected without inspecting every object in older generation(s).","The program data  portion of the system memory  includes, for example, a main memory heap  that is shared by one or more processor(s) - through -N (). The main memory heap is divided into multiple cards  (i.e., cards - through -N) of a configurable size (e.g., from a word to less than a page in size). Hosting application(s)  store respective application data into respective application domain(s) in the main memory heap. Such application data includes, for example, static and global objects, local variable\/parameters object pointers, pointers to objects in the memory heap (CPU stack), etc. One application domain card size may be different than another application domain card size; however, card size within an application domain is the same.","The main memory heap  further includes a card table  for GC module  multiprocessor scalable card marking\/write barrier operations. The card table represents each card  in the main memory heap with one or more bits.","The program data  further includes processor-specific cache(s)  and other data  such as application data, intermediate values, configuration data, and\/or the like. As discussed above, whenever a processor - through -N () references (a store operation) a cache line from the main memory heap , the processor must load the entire cache line into its processor-specific cache. To this end, there will be an equivalent number of processor-specific caches as there are processors in the system. For example, for 1-N processors there are 1-K processor caches such as processor  cache - through processor N cache -K, wherein N=K.","An Exemplary Procedure",{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 3","FIGS. 1 and 2","FIG. 2","FIG. 2"],"b":["300","202","204","206"]},"At block , the CLR  () determines the number of processors - through -N () being used in system  (). Techniques to determine the number of processors on a computing system are well known. If the system includes two or more processors such as in a symmetrical multiprocessor (SMP) system, operations continue at block . At block , the scalable multiprocessor write barrier code functionality incorporated in the GC module  () is compiled. The compilation operation of block  can be performed during GC module  execution, for instance, by a JIT compiler, or precompiled prior to GC module execution. For purposes of this discussion one or more code compilers are represented in  as respective portions of \u201cother program modules\u201d  of .","As described below in reference to block , such card mark checking code is not compiled in a single processor implementation of system  (). Techniques such as setting conditional statements around pre-compiled code as a function of compile\/execution-time (e.g., JIT compiling) circumstances are well known. Such conditional compilation of card table  () card mark checking operations of block  provide substantially optimal single to multiprocessor scalability (reduced execution code size and conditional operations in the case of a single processor system\u2014see, block ) of write barrier functionality of the GC module  ().","At block , responsive to a GC module  () detection of a processor - through -N () reference to a location in a card  (i.e., one of the cards - through -N), the GC module reads the one or more bits in the card table  that are bit-mapped to the card. At block , the GC module determines whether the referenced card is already marked (i.e., set) as a result of being written into. (Once a card has been collected any corresponding card table bit(s) are cleared; set to zero). If the card table bit(s) are clear (not marked), the procedure continues at block , wherein the GC module performs an atomic write operation (store) to the card table bits. At this point, the card has been marked, indicating that the card includes at least one pointer to an object for subsequent GC module collection operations. If the operations of block  determine that the referenced card has already been marked, the card's corresponding card table bit(s) are not again marked, meaning that an atomic write operation is not again (repeatedly) performed, and the write barrier\/card marking procedure ends.","In this manner, the described systems  of  and methods of  provide microprocessor scalable write barrier\/card marking techniques that avoid repeated writing into the card's corresponding card-table cache line after it has already been set (i.e., dirtied). This eliminates the situation where two or more processors write the same card-table cache line repeatedly (i.e., as typically occurs during write barrier operations of conventional systems described in the background section). In light of this, for each unmarked card in the multi-processor system's main memory heap  (), there is a probability of at most only a single processor-to-processor atomic write operation during GC card module  () marking operations. This provides a substantial increase in multiprocessor system operating performance as compared to when conventional multiprocessor system GC card marking operations are utilized.","Conclusion","The described systems and methods provide a multiprocessor scalable write barrier. Although the systems and methods have been described in language specific to structural features and methodological operations, the subject matter as defined in the appended claims are not necessarily limited to the specific features or operations described. Rather, the specific features and operations are disclosed as exemplary forms of implementing the claimed subject matter."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The following detailed description is described with reference to the accompanying figures. In the figures, the left-most digit of a component reference number identifies the particular figure in which the component first appears.",{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"}]},"DETDESC":[{},{}]}
