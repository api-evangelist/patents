---
title: Advanced anti-aliasing with multiple graphics processing units
abstract: A method and apparatus for performing multisampling-based antialiasing in a system that includes first and second graphics processing unit (GPUs) that reduces the amount of data transferred between the GPUs and improves the efficiency with which such data is transferred. The first GPU renders a first version of a frame using a first multisampling pattern and the second GPU renders a second version of a frame in the second GPU using a second multisampling pattern. The second GPU identifies non-edge pixels in the second version of the frame. The pixels in the first version of the frame are then combined with only those pixels in the second version of the frame that have not been identified as non-edge pixels to generate a combined frame.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08199164&OS=08199164&RS=08199164
owner: ATI Technologies ULC
number: 08199164
owner_city: Ontario
owner_country: CA
publication_date: 20090922
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This application is a divisional of U.S. Non-Provisional application Ser. No. 11\/429,078 filed May 8, 2006, now allowed. U.S. Non-Provisional application Ser. No. 11\/429,078 is incorporated herein by reference.","1. Field of the Invention","The invention is generally related to graphics processing systems. In particular, the present invention is related to a method for performing an anti-aliasing operation in a graphics processing system that implements multiple graphics processing units (GPUs).","2. Background","A known method for increasing the processing power of a graphics processing system is to operate multiple graphics processing units (GPUs) or video processing units (VPUs) in parallel, wherein each processing unit communicates with the other(s) over a common bus. Herein, the terms GPU and VPU are used interchangeably. One advantage of a multi-GPU system is that it can leverage existing microprocessor technology to achieve increased performance, thereby providing a less expensive alternative to investing in a new, faster GPU. A multi-GPU system achieves increased performance by performing calculations on multiple graphics elements in parallel.","One example of the use of a graphics processing system that utilizes multiple GPUs to provide improved performance is described in commonly-owned, co-pending U.S. patent application Ser. No. 11\/140,156, entitled \u201cAntialiasing Method and System\u201d to Preetham et al., filed May 27, 2005, the entirety of which is incorporated by reference herein. The aforementioned application describes, in part, a graphics processing system in which multiple GPUs are operated in parallel to perform antialiasing on the same graphics frame.","Aliasing is a well-known effect created by the appearance of undesired artifacts of the rendering process in a displayed frame. Edge aliasing is a particular type of aliasing that creates stair steps in an edge that should look smooth. An existing antialiasing technique for alleviating the effect of edge aliasing is multisampling. Multisampling addresses edge aliasing by obtaining multiple samples of pixels that are used to generate intermediate points between pixels. The samples (or \u201csub-pixels\u201d) are averaged to determine the displayed pixel color value. The displayed edge in the multisampled image has a softened stair step effect.","The aforementioned U.S. patent application Ser. No. 11\/140,156 describes a graphics processing system in which two GPUs each apply a different multisampling pattern to the same frame. That is, each GPU uses different sampling locations for sampling and rendering pixels in the same frame. The results of this sampling\/rendering are then transferred across a bus (for example, a PCI-Express bus) from one GPU to the other, where the results are blended to generate a frame to be displayed. The end result is that the antialiasing sampling factor for the frame to be displayed is effectively doubled. For example, if each GPU performs 2\u00d7 multisampling, the frame to be displayed includes 4\u00d7 multisampling.","In regard to the foregoing method, the step in which the results are transferred across a bus from one GPU to another can create a bottleneck due to the limited amount of bandwidth available on the bus connecting the two GPUs. For example, in an implementation in which the bus is a PCI Express (PCIE) bus, bandwidth may be limited to about 1 Gigabit per second (Gb\/sec). However, the amount of data being transferred across the bus in a system that implements this method is quite significant, particularly when the frame to be displayed is a high-resolution frame consisting of a large number of pixels. Furthermore, the foregoing method is inherently inefficient because, although multisampling-based antialiasing is a technique for edge enhancement, a significant amount of the data that is transferred between the two GPUs is not associated with edge pixels at all.","What is desired then is an improved method and apparatus for performing antialiasing in a graphics processing system that uses multiple GPUs. The improved method and apparatus should reduce the amount of data transferred between the multiple GPUs and\/or improve the efficiency with which such data is transferred. The improved method and apparatus should further provide a means by which to distinguish between data that is associated with edge pixels and data that is not associated with edge pixels.","The present invention provides an improved method and apparatus for performing antialiasing in a graphics processing system that uses multiple GPUs. The improved method and apparatus reduces the amount of data transferred between the multiple GPUs and improves the efficiency with which such data is transferred. The present invention also provides a means by which to distinguish between edge pixels and non-edge pixels in a rendered image.","A method in accordance with a particular embodiment of the present invention may be used to perform multisampling-based antialiasing in a system that includes a first GPU and a second GPU. The method includes rendering a first version of a frame in the first GPU using a first multisampling pattern and rendering a second version of the frame in the second GPU using a second multisampling pattern. Edge pixels are then identified in the second version of the frame. Pixels in the first version of the frame are then combined with only those pixels in the second version of the frame that have been identified as edge pixels to generate a combined frame.","A system in accordance with a particular embodiment of the present invention includes a first GPU configured to render a first version of a frame using a first multisampling pattern, a second GPU configured to render a second version of the frame using a second multisampling pattern, and a bus connecting the first GPU and the second GPU. The second GPU is further configured to identify edge pixels in the second version of the frame and to transfer only those pixels in the second version of the frame that have been identified as edge pixels over the bus to the first GPU. The first GPU is further configured to combine the pixels in the first version of the frame with the pixels transferred from the second GPU to generate a combined frame.","A method in accordance with a particular embodiment of the present invention may be used for identifying edge pixels in a rendered image that consists of a plurality of tiles, each of the plurality of tiles consisting of a plurality of pixels. The method includes accessing data to determine whether a selected tile in the plurality of tiles is fully compressed, identifying the selected tile as including only non-edge pixels responsive to a determination that the selected tile is fully compressed, and identifying the selected tile as including one or more edge pixels responsive to a determination that the selected tile is not fully compressed.","A method in accordance with a particular embodiment of the present invention may be used for performing multisampling-based antialiasing in a system that includes a first GPU and a second GPU. The method includes rendering a first version of a frame in the first GPU using a first multisampling pattern and rendering edge pixels associated with a second version of a frame in the second GPU using a second multisampling pattern. The edge pixels are then transferred from the second GPU to the first GPU. The edge pixels transferred from the second GPU are then combined with pixels in the first version of the frame to generate a combined frame.","Further features and advantages of the invention, as well as the structure and operation of various embodiments of the invention, are described in detail below with reference to the accompanying drawings. It is noted that the invention is not limited to the specific embodiments described herein. Such embodiments are presented herein for illustrative purposes only. Additional embodiments will be apparent to persons skilled in the relevant art(s) based on the teachings contained herein.","The features and advantages of the present invention will become more apparent from the detailed description set forth below when taken in conjunction with the drawings, in which like reference characters identify corresponding elements throughout. In the drawings, like reference numbers generally indicate identical, functionally similar, and\/or structurally similar elements. The drawing in which an element first appears is indicated by the leftmost digit(s) in the corresponding reference number.","A. Method for Performing Antialiasing in a Graphics Processing System that Includes Multiple GPUs","Flowchart  of  illustrates one method of performing antialiasing in a graphics processing system that includes multiple GPUs. In , the left hand side of the flowchart represents processing steps performed by a first GPU, denoted \u201cGPU \u201d, while the right hand side represents processing steps performed by a second GPU, denoted \u201cGPU \u201d. For the purposes of this example, it is assumed that each GPU has access to its own local memory for buffering data such as sample data that is used during the rendering process.","The first three processing steps performed by GPU  will now be described. First, at step , GPU  sets up a first pattern for multisampling each pixel in a frame to be drawn, wherein the pattern is denoted \u201cmultisampling pattern A\u201d. Second, at step , GPU  draws the frame, wherein drawing the frame includes storing multiple samples corresponding to each pixel in a multisample antialiasing (AA) buffer local to GPU . As used herein, the phrase \u201cstoring samples\u201d refers to storing data, such as color values, associated with each of the samples. The multiple sampling locations for each pixel are selected based on the multisampling pattern A. Third, at step , GPU  resolves each set of multiple samples stored in the AA buffer to a single sample which is stored in a draw buffer local to GPU , denoted \u201cDraw Buffer A\u201d. One method of resolving multiple samples to a single sample entails averaging the multiple samples in a linear space.","The first three processing steps performed by GPU  (steps ,  and ) are performed in parallel to the first three processing steps performed by GPU  and are essentially the same, except that a different multisampling pattern, denoted \u201cmultisampling pattern B\u201d, is used for drawing the frame, the sets of multiple samples are stored in an AA buffer that resides in memory local to GPU , and the frame is resolved to a draw buffer, denoted \u201cDraw Buffer B\u201d, which also resides in memory local to GPU .","At step , GPU  copies the contents of Draw Buffer B to a temporary buffer in local memory of GPU , denoted \u201cTemp Buffer A\u201d. At step , a compositor resident on the same graphics card as GPU  performs linear blending of each pixel represented in Draw Buffer A with a corresponding pixel represented in Temp Buffer A to generate a frame to be displayed. Alternatively, this linear blending may be performed by a compositor that is not resident on a graphics card, but is an independent component with which both GPU  and GPU  communicate. At step , the frame to be displayed is output to a display device. The frame has effectively twice the amount of multisampling as applied by each individual GPU.","In regard to the foregoing method, step  (in which the contents of Draw Buffer B are copied to Temp Buffer A) can create a bottleneck due to the limited amount of bandwidth available on the bus connecting GPU  to GPU . For example, in an implementation in which the bus is a PCI Express (PCIE) bus, bandwidth may be limited to about 1 Gigabit per second (Gb\/sec). However, the amount of data being transferred across the bus in a system that implements the method of flowchart  is quite significant, particularly when the frame to be displayed is a high-resolution frame consisting of a large number of pixels. Furthermore, the foregoing method of flowchart  is inherently inefficient because, although multisampling-based antialiasing is a technique for edge enhancement, a significant amount of the data that is transferred between the two GPUs is not associated with edge pixels at all.","The following describes an improved method and apparatus for performing antialiasing in a graphics processing system that uses multiple GPUs. The improved method and apparatus reduces the amount of data transferred between the multiple GPUs and improves the efficiency with which such data is transferred. The improved method and apparatus further provide a means by which to distinguish between data that is associated with edge pixels and data that is not associated with edge pixels.","B. Graphics Processing System in Accordance with an Embodiment of the Present Invention",{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 2","b":["200","200","202","204","206","208","210","230","200"]},"As shown in , system  includes an application . Application  is an end user application that requires graphics processing capability, such as a video game application. Application  communicates with API . Several APIs are available for use in the graphics processing context. APIs were developed as intermediaries between application software, such as application , and graphics hardware on which the application software runs. With new chipsets and even entirely new hardware technologies appearing at an increasing rate, it is difficult for application developers to take into account, and take advantage of, the latest hardware features. It is also becoming impossible to write applications specifically for each foreseeable set of hardware. APIs prevent applications from having to be too hardware-specific. The application can output graphics data and commands to the API in a standardized format, rather than directly to the hardware. Examples of available APIs include DirectX\u00ae or OpenGL\u00ae. API  can be any one of the available APIs for running graphics applications.","API  communicates with a driver . Driver  is typically written by the manufacturer of the graphics hardware, and translates standard code received from the API into a native format understood by the graphics hardware. The driver also accepts input to direct performance settings for the graphics hardware. Such input may be provided by a user, an application or a process. For example, a user may provide input by way of a user interface (UI), such as a graphical user interface (GUI), that is supplied to the user along with driver . One performance setting that is of particular relevance to the embodiment described herein is a multisampling factor that the graphics hardware uses for performing antialiasing.","The graphics hardware includes two graphics processing units, GPU A  and GPU B . In this embodiment, GPU A  and GPU B  are graphics cards that each include a graphics processor and other associated hardware, although the invention is not so limited. Rather, as used herein, the term GPU broadly refers to any device, collection of devices, or subset of a device (e.g., a processing core within an integrated circuit chip) that is configured to perform graphics processing tasks.","Driver  issues commands and data to both GPU A  and GPU B . GPU A  and GPU B  receive the commands and data from driver  through respective ring buffers A  and B . The commands instruct GPU A  and GPU B  to perform a variety of operations on the data in order to ultimately produce a rendered frame for output to a display . As shown in , GPU A  and GPU B  each have access to a respective local graphics memory A  and B  for performing such operations. In addition, driver , GPU A , and GPU B  each have access to a shared memory . Communication between the GPUs and shared memory  is carried out over a PCI Express (PCIE) bus . In addition, GPU A  and GPU  B can communicate directly with each other using a peer-to-peer protocol over PCIE bus .","As will be described in more detail herein, the operations performed by GPU A  and GPU B  under the direction of driver  include a multisampling-based antialiasing operation. In accordance with this operation, each of GPU A  and GPU B  processes in parallel the same frame to be displayed. In particular, GPU A  and GPU B  each render a different version of the same frame through the respective application of different multisampling patterns, wherein the different multisampling patterns are selected by driver . In this embodiment, driver  is programmable to direct GPU A  and GPU B  to perform multisampling by a selectable multiplying factor.","In further accordance with this multisampling-based antialiasing operation, frame data resulting from the rendering process carried out by GPU B  is transferred to GPU A  over PCIE bus . A compositor, which is a component of an interlink module (IM)  resident on GPU A , operates to combine the frame data transferred from GPU B  with frame data generated by GPU A  via linear blending to obtain a final frame to be displayed. In the frame to be displayed, the multisampling factor is effectively multiplied by the number of GPUs. For example, if each GPU performs 2\u00d7 multisampling, the frame to be displayed includes 4\u00d7 multisampling.","As will be described in more detail herein, prior to transferring the frame data resulting from the rendering process over PCIE bus , GPU B  first performs an operation to identify edge pixels and non-edge (or \u201cinterior\u201d) pixels within the rendered frame. When the frame data is transferred from GPU B  to GPU A , sample data associated with edge pixels is transferred but sample data associated with non-edge pixels is not. Sample data associated with non-edge pixels can be excluded because the multisampling operations described herein are used for edge enhancement and thus impact the appearance of edge pixels only. As a result, the non-edge pixels in the frame rendered by GPU A  will be identical to the non-edge pixels in the frame rendered by GPU B . Consequently, there is no need to transfer and combine the data associated with these pixels.","The foregoing technique of transferring sample data associated with edge pixels from GPU B  to GPU A  but excluding sample data associated with non-edge pixels will be described in more detail below. The technique is advantageous because it operates to reduce the amount of data to be transferred across PCIE bus , thereby increasing the speed of the transfer operation such that that operation does not become a processing bottleneck. Additionally, by reducing the amount of data to be transferred across PCIE bus , more bandwidth is available for other components sharing the same bus.","It should be noted that example graphics processing system  has been described by way of example and is not intended to limit the present invention. Based on the teachings provided herein, persons skilled in the art will readily appreciate that the present invention can be implemented in any system in which multiple GPUs are in communication with each other and are used for performing antialiasing. Various systems of this type are described in detail in commonly-owned, co-pending U.S. patent application Ser. No. 11\/140,156, entitled \u201cAntialiasing System and Method\u201d to Preetham et al, filed May 27, 2005, the entirety of which is incorporated by reference herein. Based on the teachings provided herein, a person skilled in the art would be capable of modifying each of the systems described in that application to perform the antialiasing techniques described herein.","C. Antialiasing Method in Accordance with an Embodiment of the Present Invention",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 3","FIG. 2","FIG. 3"],"b":["300","300","200","208","210"]},"The first four processing steps performed by GPU A  will now be described. At step , GPU A  sets up a first pattern for multisampling each pixel in a frame to be drawn, wherein the pattern is denoted \u201cmultisampling pattern A\u201d.  illustrates an example multisampling pattern  that may be used as multisampling pattern A. Multisampling pattern  provides for 2\u00d7 multisampling of a pixel that consists of 12\u00d712 sample locations. In , the center of the pixel is represented as a solid black box, and the sample locations selected for 2\u00d7 multisampling are filled with slanted lines. Persons skilled in the art will readily appreciate a wide variety of other pixel dimensions and sample locations may be used.","At step , GPU A draws the frame, wherein drawing the frame includes storing the selected samples for each pixel in a multisample antialiasing (AA) buffer within local graphics memory A. As used herein, the phrase \u201cstoring a sample\u201d encompasses storing data such as color data associated with a sample.","At step , GPU A  resolves each set of multiple samples stored in the AA buffer to a single sample in a draw buffer located within local graphics memory A , denoted \u201cDraw Buffer A\u201d. One method for resolving multiple samples to a single sample entails averaging the multiple samples in a linear space, although the invention is not so limited. More details of this operation are provided in commonly-owned, co-pending U.S. patent application Ser. No. 11\/140,156, entitled \u201cAntialiasing Method and System\u201d to Preetham et al., filed May 27, 2005, the entirety of which is incorporated by reference herein.","At step , GPU A  performs an operation to identify which pixels represented in Draw Buffer A are edge pixels. A particular method for performing this operation will be described in detail below with reference to , A and B, although the invention is not limited to this particular method. The output of this operation is a set of data, referred to herein as an \u201cedge pixel mask\u201d, that is stored in local graphics memory A  and identifies which pixels within the frame stored in Draw Buffer A are edge pixels. As used herein, the phrase \u201cidentifying edge pixels\u201d may encompass either identifying edge pixels on a pixel-by-pixel basis or identifying a rectangular block or \u201ctile\u201d of pixels that includes at least one edge pixel.","The first four processing steps performed by GPU B  will now be described. Preferably, these first four steps are performed substantially in parallel with the first four processing steps performed by GPU A , although the invention is not so limited.","The first three processing steps performed by GPU B  (steps ,  and ) are essentially the same as the first three processing steps performed by GPU A  (steps ,  and ), except that a different multisampling pattern, denoted \u201cmultisampling pattern B\u201d, is used for drawing the frame, the selected samples for each pixel are stored in an AA buffer which resides within local graphics memory B , and the frame is resolved to a draw buffer, denoted \u201cDraw Buffer B\u201d, which resides in local graphics memory B .  illustrates an example multisampling pattern  that may be used as multisampling pattern B. Multisampling pattern  provides for 2\u00d7 multisampling of a pixel that consists of 12\u00d712 sample locations. In , the center of the pixel is represented as a solid black box, and the sample locations selected for 2\u00d7 multisampling are filled with a checkerboard pattern.","At step , GPU B  performs an operation to identify which pixels represented in Draw Buffer B are edge pixels. A particular method for performing this operation will be described in detail below with reference to , A and B, although the invention is not limited to this particular method. The output of this operation is an edge pixel mask that is stored in local graphics memory B  and identifies which pixels within the frame stored in Draw Buffer B are edge pixels.","At this point, GPU A  has generated an edge pixel mask that identifies which pixels within the frame stored in Draw Buffer A are edge pixels and GPU B  has generated an edge pixel mask that identifies which pixels with in the frame are stored in Draw Buffer B are edge pixels. At step , GPU A  transfers its edge pixel mask to GPU B  and, at step , the edge pixel mask from GPU A  is combined with the edge pixel mask from GPU B  in local memory to generate a combined edge pixel mask. This combined edge pixel mask is the union (as opposed to the intersection) of the individual edge pixel masks in that it identifies a pixel as an edge pixel if it has been identified as an edge pixel by either GPU A  or GPU B . In a preferred embodiment, the combination is carried out by overlaying the edge pixel mask transferred from GPU A  directly onto the edge pixel mask stored in local memory by GPU B , such that steps  and  are essentially combined into a single step.","At step , GPU A  stores a copy of the contents of Draw Buffer A in a temporary buffer (denoted \u201cTemp Buffer A\u201d) located within local graphics memory A . At step , GPU B  transfers a copy of only those pixels in Draw Buffer B identified as edge pixels by the combined edge pixel mask across PCIE bus  to be overlaid onto the data stored in Temp Buffer A. In effect, GPU B  excludes or \u201cmasks out\u201d from this transfer data corresponding to non-edge pixels as specified by the combined edge pixel mask. The net result of this processing step is that Temp Buffer A holds a complete representation of the frame rendered by GPU B . This is so because the non-edge pixels rendered by GPU A , a copy of which are present in Temp Buffer A and are not overlaid during step , are identical to the non-edge pixels rendered by GPU B , since the multisampling\/resolve operation only alters the color of edge pixels.","The final two steps performed by GPU A  will now be described. At step , the compositor portion of IM , resident on the same graphics card as GPU A , performs linear blending of each pixel represented in Draw Buffer A with a corresponding pixel represented in Temp Buffer A to generate a frame to be displayed. At step , the frame to be displayed is output to display device . The frame has effectively twice the amount of multisampling as applied by each GPU. This is illustrated in , which shows the 4\u00d7 multisampling pattern  that results from combining a pixel that uses 2\u00d7 multisampling pattern  with a pixel that uses 2\u00d7 multisampling pattern .","Because method  does not transfer sample data associated with non-edge pixels from GPU B  to GPU A , it advantageously reduces the amount of data to be transferred across PCIE bus . As a result, the speed of the transfer operation is increased such that the operation does not become a processing bottleneck. Furthermore, this method makes more bandwidth available for other components sharing the same bus.","D. Method of Identifying Edge Pixels in Accordance with an Embodiment of the Present Invention","As discussed above in reference to the flowchart  of , GPU A  performs an operation at step  to identify edge pixels in the frame stored in Draw Buffer A and GPU B  performs an operation at step  to identify edge pixels in the frame stored in Draw Buffer B. In an embodiment, GPU A  and GPU B  each perform this operation using a memory internal to a graphics processor, referred to herein as a Tile Format Table (TFT), that keeps track of whether sample color data associated with each pixel in the frame to be displayed is fully compressed, partially compressed, or uncompressed. A full description of this compression scheme and the use of the TFT is set forth in commonly-owned, co-pending U.S. patent application Ser. No. 10\/672,707, entitled \u201cMethod and Apparatus for Compression of Multi-Sampled Anti-Aliasing Color Data\u201d, filed Sep. 26, 2003, which is incorporated by reference as if fully set forth herein.","1. Sample Color Data Compression in Accordance with an Embodiment of the Present Invention",{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 7","b":"700"},"As shown in , a graphics processor  is communicatively connected to a cache , which in turn is communicatively connected to a main memory . During the process of rendering a frame for display, pixel data is transferred from main memory  to cache  for use by graphics processor . As set forth in U.S. patent application Ser. No. 10\/672,707, pixel data is transferred as rectangular blocks or \u201ctiles\u201d of multiple adjacent pixels. In the example shown in , the pixels are transferred in 2\u00d72 tiles of adjacent pixels, wherein the pixels are denoted A, B, C and D. However, as will be apparent to persons skilled in the art, other size tiles may be used.","Each pixel in the tile has been multisampled, and thus the data associated with each pixel includes a color value corresponding to each of the samples within the pixel. In one example set forth in U.S. patent application Ser. No. 10\/672,707, each pixel includes four samples, and each sample is associated with a color value. The color value may be one word in length.","During the transfer from main memory  to cache , each tile is evaluated and, based on the results of the evaluation, color data associated with each pixel in the tile may be compressed. In accordance with an embodiment described in application Ser. No. 10\/672,707, an evaluated tile may be handled in one of three ways: it may be \u201cfully compressed\u201d, \u201cpartially compressed\u201d, or it may remain uncompressed.","Full compression is selected if all the samples in each multisampled pixel are the same color. This may occur, for example, if the tile is wholly covered by a single triangle. When a tile is fully compressed, only a single color value is stored for each pixel in the tile.","Partial compression is selected if all the samples in each multisampled pixel are one of only two colors. This may occur, for example, if the tile is covered by no more than two triangles. When a tile is partially compressed, two color values are stored for each pixel in the tile and a pointer is used to encode the compression.  illustrates the bits of an example pointer for a partially compressed 2\u00d72 tile of 4\u00d7 multisampled pixels A, B, C and D. Each bit in the pointer is either a \u201c0\u201d, which means that a first color for that pixel is used (termed \u201cthe original color\u201d), or a \u201c1\u201d, which means that a second color for that pixel is used (termed \u201cthe replacement color\u201d). For example, in pixel A, all four samples are of the original color for pixel A. Hence all four bits are encoded \u201c0\u201d. In pixel C, the first three samples are of the original color for pixel C. Thus the first three bits are encoded \u201c0\u201d. The last bit is encoded \u201c1\u201d to indicate that the fourth sample of pixel C is using the replacement color. The same logic applies for pixels B and D. Using this pointer, only two color values per pixel need to be stored, with one color value for the original color value and another for the replacement color.","Color data remains uncompressed if the sub-pixels in any of the multisampled pixels can be more than two colors. For example, this may occur if the tile is covered by more than two triangles. In this instance, a single color value is stored for each sample in each pixel in the tile.","In accordance with the teachings of application Ser. No. 10\/627,707, graphics processor  includes an on-chip memory referred to as Tile Format Table (TFT) , to keep track of the format of the tile data stored in cache . Tiles stored in cache  are transferred to graphics processor  as needed for processing. The tiles need not be decompressed at graphics processor , because graphics processor  uses TFT  to keep track of the format of the incoming tiles. Graphics processor  can operate on the tile in its compressed format and thus speed up overall operation.","In one embodiment, there is a entry in TFT  for every tile in a given frame. Each entry has a two-bit compression encoding to indicate the format of the particular tile. In one embodiment, the two bits encode the following four states:","1. clear","2. fully compressed","3. partially compressed","4. uncompressed.","The two-bit compression encoding in the TFT alerts the processor as to the format of tile data coming from the cache. The first state indicates a state in which the cache is set to a \u201cclear value\u201d that corresponds to a default empty data state. The second, third and fourth states of the TFT entry describe the aforementioned three levels of compression for the tile: fully compressed, partially compressed, and uncompressed. With the two-bit encoding, graphics processor  can appropriately process the tile data received from cache .","As noted above, both GPU A  and GPU B  in the embodiment depicted in  perform a resolve operation to combine multiple samples together to arrive at a single representative sample for a given pixel (see, for example, steps  and  in  and associated text). Put another way, during the resolve operation, data is pulled out from local memory and then written back into local memory with the result that only pixel data remains for each pixel (i.e., no sub-pixel or sample data remains).","Using the compression scheme described above, the resolve operation is performed more efficiently. The manner in which the resolve operation is performed depends on the level of compression of the tiles. First, if the tiles are fully compressed, i.e., there is already only one color per pixel, nothing needs to be done and each pixel in the tile is simply written back into memory. Second, if the tiles are partially compressed or uncompressed, i.e., there are different color samples within each pixel, then the samples are combined to resolve to the final pixel color. In one embodiment, samples with the same colors are only processed once. For example, for the tile represented by the pointer of , pixel C has three samples of one color and one sample of another color. The resolve operation will multiply the single color value associated with the first three samples by three and combine it with one times the color value of the remaining sample. Then, the combined value is divided by four to obtain the final pixel color value. This saves the process from having to read the same color value multiple times. For an uncompressed tile, the color values associated with each sample are added together and the result is divided by the number of samples in the traditional manner.","2. Use of Tile Format Table (TFT) and Resolve Operation to Distinguish Edge and Non-Edge Pixels in Accordance with an Embodiment of the Present Invention","In an embodiment of the present invention, at least one GPU in a multi-GPU system leverages the TFT and resolve operation discussed in the foregoing section to distinguish between edge and non-edge pixels in a frame to be displayed. This distinction allows a GPU to avoid sending data associated with non-edge pixels to another GPU when performing multi-GPU based antialiasing operations as described elsewhere herein.","TFT  contains information about tiles in the frame to be displayed that are fully compressed, partially compressed, or uncompressed. When a tile is fully compressed, it is guaranteed that all of the pixels in that tile are interior or non-edge pixels. In contrast, when a tile is only partially compressed or uncompressed, this means that at least some of the pixels in that tile are edge pixels. Therefore, the information stored in TFT  can assist in determining whether a tile contains only non-edge pixels or contains one or more edge pixels. However, because TFT  is implemented as an on-chip memory of graphics processor , it is difficult to read directly.",{"@attributes":{"id":"p-0080","num":"0079"},"figref":["FIG. 9","FIG. 2","FIG. 2"],"b":["900","704","900","208","314","300","210","316","300"]},"At step , an \u201cedge detect\u201d anti-aliasing (AA) buffer is populated in local graphics memory. The edge detect AA buffer is not populated with data representing the actual frame to be displayed (which is instead stored in Draw Buffer A or Draw Buffer B). Rather, the edge detect AA buffer is populated with predefined multisampled pixel data that, when resolved in accordance with data stored in TFT , will result in a certain color value if a tile entry in TFT  indicates a tile is fully compressed and will result in a different color value if a tile entry in TFT  indicates that a tile is partially compressed or uncompressed. Because the edge detect AA buffer does not contain data representing the actual frame to be displayed, it may also be thought of as a \u201cdummy\u201d buffer.","In accordance with an embodiment of the present invention, a 2-sample edge detect AA buffer is used that has the same dimensions and depth as the frame to be displayed. For each pixel in the 2-sample edge detect AA buffer, a \u201c0\u201d is stored in the first sample location and a \u201c1\u201d is stored in the second sample location. A 2-sample edge detect AA buffer can be used regardless of the sample depth of the Draw Buffer B in which the frame to be displayed is stored. Although a 2-sample edge detect AA buffer has been described by way of example herein, such description is not intended to limit the present invention and persons skilled in the art will appreciate that an edge detect AA buffer having a different sample depth (e.g., a 4-sample edge detect AA buffer) may also be used.","At step , GPU B  resolves the edge detect AA buffer using the data stored in TFT  to a temporary buffer, which resides in local graphics memory. To better explain this step,  illustrates the application of the resolve operation to a 2\u00d72 tile of pixels  in the 2-sample edge detect AA buffer described above, wherein an entry in TFT  indicates that a corresponding tile in the frame to be displayed is fully compressed. As shown in , each pixel A, B, C and D in the 2\u00d72 tile  has 2 sample locations, wherein the first of the two sample locations has an assigned color value of \u201c0\u201d and the second of the two sample locations has an assigned color value of \u201c1\u201d. After application of the resolve operation, each pair of samples is resolved into a corresponding representative sample in a resolved 2\u00d72 tile  within the temporary buffer. Because TFT  indicates that the corresponding tile in the frame to be displayed is compressed, graphics processor  applies the resolve command by assuming that the color value associated with the first sample location is also the color value for the second sample location, and thus the resolved sample color for each pixel is zero.","In contrast,  illustrates the application of the resolve operation to a 2\u00d72 tile of pixels  in the 2-sample edge detect AA buffer described above, wherein the relevant entry in TFT  indicates that a corresponding tile in the frame to be displayed is partially compressed or uncompressed. Just like tile  of , each pixel A, B, C, and D in tile  has 2 sample locations, wherein the first of the two sample locations has an assigned color value of \u201c0\u201d and the second of the two sample locations has an assigned color value of \u201c1\u201d. After application of the resolve operation, each pair of samples is resolved into a corresponding representative sample in a resolved 2\u00d72 tile  within the temporary buffer. Because TFT  indicates that the corresponding tile in the frame to be displayed is partially compressed or uncompressed, the application of the resolve command by graphics processor  involves averaging the color value associated with the first sample location with the color value for the second sample location. As a result, at least one of the resulting color values for each pixel in resolved tile  will be non-zero.  illustrates one example in which each of the pixels in the corresponding tile in the frame to be displayed is an edge pixel. As a result, each color value for each pixel in resolved tile  is non-zero.","At step , the data stored in the temporary buffer is used as an edge pixel mask. As described above in reference to , each of GPU A  and GPU B  generate such an edge pixel mask. The edge pixel mask generated by GPU A  is combined with the edge pixel mask generated by GPU B  by overlaying the former edge pixel mask onto the latter one. The combined edge pixel mask is then used for copying tiles from the frame stored in Draw Buffer B onto Temp Buffer A located in local graphics memory A . If a tile in the combined edge pixel mask has all zero color values, then a corresponding tile in Draw Buffer B is \u201cmasked out,\u201d or excluded, from copying from Draw Buffer B onto Temp Buffer A. In contrast, if a tile in the combined edge pixel mask has at least one non-zero color value, then the corresponding tile in Draw Buffer B is \u201cpassed through\u201d or copied from Draw Buffer B onto Temp Buffer A. The net result of this step is that only tiles within Draw Buffer B that include one or more edge pixels or that correspond to tiles within Draw Buffer A that include one or more edge pixels are copied from Draw Buffer B onto Temp Buffer A. Note that in an embodiment in which TFT  does not include an entry for each tile in the frame to be displayed, tiles without entries should be treated as if they encompass edge pixels and should be transferred in their entirety from Draw Buffer B onto Temp Buffer A.","As noted above, an implementation of the present invention allocates a 2-sample edge detect AA buffer of the dimensions and depth of the render target. However, such an implementation could consume a significant amount of memory resources. Accordingly, an alternate implementation uses a 2-sample edge detect AA buffer having smaller dimensions than the render target. For example, the 2-sample edge detect AA buffer may be only 128\u00d7128 pixels. In accordance with such an implementation, step  is repeated multiple times, effectively sliding the resolve \u201cwindow\u201d to generate each 128\u00d7128 portion of the temporary buffer. Another alternative implementation uses a small 2-sample edge detect AA buffer and memory mapping hardware is used to map this buffer onto the larger resolve buffer (i.e., the temporary buffer).","In a particular embodiment of the present invention, to reduce the amount of data sent between GPU A  and GPU B  in step  of flowchart  of , the edge pixel masks generated by GPU A  and GPU B  are placed in a highly-compressed data format. For example, assume that the temporary buffer that stores the edge pixel mask for GPU A  is 32 bits per pixel (bpp). In accordance with an example implementation that uses 2\u00d72 tiles, and in which the graphics hardware cannot easily tell which pixel(s) within each 2\u00d72 tile is (are) the edge pixel(s), this buffer is downsampled so that each 2\u00d72 tile is represented by a single pixel. Pixels that are black will then correspond to 2\u00d72 tiles that include no edge pixels. While downsampling, a format conversion is also be carried out from 32 bpp to 8 bpp to conserve bandwidth later. A second downsampling is then be performed so that a single pixel now corresponds to a 4\u00d74 tile in the original edge pixel mask. This is desirable in an implementation in which compression is carried out on 4\u00d74 tiles and pixels within a single tile are all encoded in a similar manner in the original AA buffer. This doubly-downsampled and converted buffer is then used as the edge pixel mask that is transferred from GPU A  to GPU B  in step . Of course, only pixels that are non-zero are transferred as such non-zero pixels represent 4\u00d74 tiles having edges. The target of this transfer is a temporary buffer that contains GPU B 's own doubly-downsampled and converted edge pixel mask such that GPU A 's edges are added to GPU B 's edges. This overlaying results in the combined edge pixel mask that is used to transfer color data from GPU B  to GPU A  in step  of flowchart  of .","It should be noted that the usefulness of the aforementioned method of distinguishing edge pixels from non-edge pixels is not limited to performing multisampling-based antialiasing in a multi-GPU system. For example, the method may be advantageously used in any image processing system that seeks to efficiently identify and enhance edges in a rendered image. Furthermore, the method could be used to collect statistics concerning the number of edges in a given frame. These examples are not intended to be limiting, and other applications of the aforementioned method will by readily apparent to persons skilled in the art.","E. Example Computer System Implementation",{"@attributes":{"id":"p-0089","num":"0088"},"figref":"FIG. 11","b":["1100","1100","1100"]},"As shown in , example computer system  includes a processor  for executing software routines. Although a single processor is shown for the sake of clarity, computer system  may also comprise a multi-processor system. Processor  is connected to a communication infrastructure  for communication with other components of computer system . Communication infrastructure  may comprise, for example, a communications bus, cross-bar, or network.","Computer system  further includes a main memory , such as a random access memory (RAM), and a secondary memory . Secondary memory  may include, for example, a hard disk drive  and\/or a removable storage drive , which may comprise a floppy disk drive, a magnetic tape drive, an optical disk drive, or the like. Removable storage drive  reads from and\/or writes to a removable storage unit  in a well known manner. Removable storage unit  may comprise a floppy disk, magnetic tape, optical disk, or the like, which is read by and written to by removable storage drive . As will be appreciated by persons skilled in the relevant art(s), removable storage unit  includes a computer usable storage medium having stored therein computer software and\/or data.","In an alternative implementation, secondary memory  may include other similar means for allowing computer programs or other instructions to be loaded into computer system . Such means can include, for example, a removable storage unit  and an interface . Examples of a removable storage unit  and interface  include a program cartridge and cartridge interface (such as that found in video game console devices), a removable memory chip (such as an EPROM or PROM) and associated socket, and other removable storage units  and interfaces  which allow software and data to be transferred from the removable storage unit  to computer system .","Computer system  also includes at least one communication interface . Communication interface  allows software and data to be transferred between computer system  and external devices via a communication path . In particular, communication interface  permits data to be transferred between computer system  and a data communication network, such as a public data or private data communication network. Examples of communication interface  can include a modem, a network interface (such as Ethernet card), a communication port, and the like. Software and data transferred via communication interface  are in the form of signals which can be electronic, electromagnetic, optical or other signals capable of being received by communication interface . These signals are provided to the communication interface via communication path .","As shown in , computer system  includes an audio interface  for performing operations for playing audio content via associated speaker(s) .","Computer system  further includes a graphics processing system  which performs operations for rendering images to an associated display . Graphics processing system  may include the graphics hardware elements described above in reference to , such as a first GPU A  and a second GPU B , although the invention is not so limited. In an embodiment, graphics processing system  is configured to perform the features of the present invention, such as the steps of flowchart  of  and\/or the steps of flowchart  of . Graphics processing system  may perform these steps under the direction of computer programs being executed by processor  and\/or under the direction of computer programs being executed by one or more graphics processors within graphics processing system .","As used herein, the term \u201ccomputer program product\u201d may refer, in part, to removable storage unit  or removable storage unit . A computer useable medium can include magnetic media, optical media, or other recordable media. These computer program products are means for providing software to computer system .","Computer programs (also called computer control logic) may be stored in main memory , secondary memory , or in a memory within graphics processing system . Computer programs can also be received via communication interface . Such computer programs, when executed, enable the computer system , and in particular graphics processing system , to perform one or more features of the present invention as discussed herein. In particular, the computer programs, when executed, enable the computer system , and in particular graphics processing system , to perform features of the present invention. Accordingly, such computer programs represent controllers of the computer system .","Software for implementing the present invention may be stored in a computer program product and loaded into computer system  using removable storage drive , hard disk drive , or interface . Alternatively, the computer program product may be downloaded to computer system  over communications path . The software, when executed by the processor  and\/or by components within graphics processing system , causes those elements to perform functions of the invention as described herein.","F. Conclusion","While various embodiments of the present invention have been described above, it should be understood that they have been presented by way of example only, and not limitation. It will be understood by those skilled in the relevant art(s) that various changes in form and details may be made therein without departing from the spirit and scope of the invention as defined in the appended claims. Accordingly, the breadth and scope of the present invention should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS\/FIGURES","p":["The accompanying drawings, which are incorporated herein and form part of the specification, illustrate the present invention and, together with the description, further serve to explain the principles of the invention and to enable a person skilled in the relevant art(s) to make and use the invention.",{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIGS. 10A and 10B"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
