---
title: User-assistance information at least partially based on an identified possible non-imaged portion of a skin
abstract: Described embodiments include a system, method, and program product. A described system includes a circuit that determines a substantial correspondence between a human-perceivable feature included in a border region segment of a selected medical skin image and a human-perceivable feature included in each other medical skin image of a plurality of medical skin images. A circuit gathers the determined substantial correspondences. A circuit generates data indicative of a border region-overlap status of the selected medical skin image. A circuit adds the data to an omitted-coverage list. A circuit iteratively designates a next medical skin image as the selected digital image, and initiates a processing of each of the iteratively designated next medical skin images. A circuit identifies a possible non-imaged portion of the region of interest. A circuit outputs user-assistance information based on the identified possible non-imaged portion of the skin.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08644615&OS=08644615&RS=08644615
owner: Elwha LLC
number: 08644615
owner_city: Bellevue
owner_country: US
publication_date: 20111207
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","RELATED APPLICATIONS","SUMMARY","DETAILED DESCRIPTION"],"p":["The present application is related to and claims the benefit of the earliest available effective filing date(s) from the following listed application(s) (the \u201cRelated Applications\u201d) (e.g., claims earliest available priority dates for other than provisional patent applications or claims benefits under 35 USC \u00a7119(e) for provisional patent applications, for any and all parent, grandparent, great-grandparent, etc. applications of the Related Application(s)).","For purposes of the USPTO extra-statutory requirements, the present application constitutes a continuation-in-part of U.S. patent application Ser. No. 13\/374,002, entitled INFORMATIONAL DATA INDICATIVE OF A POSSIBLE NON-IMAGED PORTION OF A REGION OF INTEREST, naming Roderick A. Hyde, Jordin T. Kare, Eric C. Leuthardt, Erez Lieberman, Dennis J. Rivet, Elizabeth A. Sweeney, Lowell L. Wood, Jr., as inventors, filed Dec. 7, 2011, which is currently co-pending, or is an application of which a currently co-pending application is entitled to the benefit of the filing date.","For purposes of the USPTO extra-statutory requirements, the present application constitutes a continuation-in-part of U.S. patent application Ser. No. 13\/374,000, entitled REPORTING INFORMATIONAL DATA INDICATIVE OF A POSSIBLE NON-IMAGED PORTION OF A REGION OF INTEREST, naming Roderick A. Hyde, Jordin T. Kare, Eric C. Leuthardt, Erez Lieberman, Dennis J. Rivet, Elizabeth A. Sweeney, Lowell L. Wood, Jr., as inventors, filed Dec. 7, 2011, which is currently co-pending, or is an application of which a currently co-pending application is entitled to the benefit of the filing date.","For purposes of the USPTO extra-statutory requirements, the present application constitutes a continuation-in-part of U.S. patent application Ser. No. 13\/374,005, entitled REPORTING INFORMATIONAL DATA INDICATIVE OF A POSSIBLE NON-IMAGED PORTION OF A SKIN, naming Roderick A. Hyde, Jordin T. Kare, Eric C. Leuthardt, Erez Lieberman, Dennis J. Rivet, Elizabeth A. Sweeney, Lowell L. Wood, Jr., as inventors, filed Dec. 7, 2011, which is currently co-pending, or is an application of which a currently co-pending application is entitled to the benefit of the filing date.","The United States Patent Office (USPTO) has published a notice to the effect that the USPTO's computer programs require that patent applicants reference both a serial number and indicate whether an application is a continuation or continuation-in-part. Stephen G. Kunin, Benefit of Prior-Filed Application, USPTO Official Gazette Mar. 18, 2003. The present Applicant Entity (hereinafter \u201cApplicant\u201d) has provided above a specific reference to the application(s) from which priority is being claimed as recited by statute. Applicant understands that the statute is unambiguous in its specific reference language and does not require either a serial number or any characterization, such as \u201ccontinuation\u201d or \u201ccontinuation-in-part,\u201d for claiming priority to U.S. patent applications. Notwithstanding the foregoing, Applicant understands that the USPTO's computer programs have certain data entry requirements, and hence Applicant is designating the present application as a continuation-in-part of its parent applications as set forth above, but expressly points out that such designations are not to be construed in any way as any type of commentary or admission as to whether or not the present application contains any new matter in addition to the matter of its parent application(s).","All subject matter of the Related Applications and of any and all parent, grandparent, great-grandparent, etc. applications of the Related Applications is incorporated herein by reference to the extent such subject matter is not inconsistent herewith.","An example of an embodiment of environment  of  in use may include determining whether the plurality of digital images  covers the entire region of interest  of the surface , or whether there are any possible non-imaged portions of the region of interest that are not covered by the plurality of digital images. This may be useful when a surface has been imaged from several different locations rather than imaged from a relatively fixed or known location such as by satellite or aerial photography. Examples of imaging a surface from several different locations may include examining a surface of an object for perceivable defects, such as missing protective tiles on a spacecraft, or when examining the skin of a person or the surface of an internal organ of a person for diseases, conditions, or changes over time. It is anticipated that a person or machine examining a surface would like to know whether the plurality of digital images covers the entire region of interest of the surface, or whether there are possible non-imaged portions of the region of interest. It is further anticipated that a person or machine examining such a surface would like to know where any possible non-imaged portions of the region of interest are located so that the examination may be adjusted for that fact, or so that additional digital images of possible non-imaged portions of the region of interest may be acquired.","This example of the environment  in use includes, without limitation, an embodiment of the system  in use. In this example, the system includes an image receiver circuit  configured to receive the plurality of digital images . The plurality of digital images each includes a respective portion of the region of interest  of the surface . See . For example, the surface may include the skin of a person's back, or the lining of a person's stomach. To lay the ground work for determining whether there is possible non-imaged portion  of the region of interest of the surface in the plurality of digital images, the system finds at least one respective perceivable feature located anywhere in the field of view for each of the plurality of digital images, including the border regions of the digital images. To this end, the system includes a feature-detection circuit  configured to extract at least one perceivable feature included in each digital image of the plurality of digital images. For example, where the surface is the skin, an extracted perceivable feature may include a mole, a wrinkle, a fold, a human-vision perceivable discontinuity, a hair pattern, or a vein. The system includes a border region detection circuit  configured to detect a border region segment of a digital image. The dimensions of the border region segment may be selected for example as is appropriate for the resolution of digital images included in the plurality of digital images and the processing power of the system.","In this example of the system  in use, the system looks to see if there is a common perceivable feature included in both a border region segment of a selected digital image and in another digital image of the plurality of digital images. If there is no common perceivable feature, the system reports a possible non-imaged portion of the region of interest. For example, see . In this regard, a feature-matching circuit  of the system looks for a common perceivable feature in both a border region segment of a selected digital image and anywhere in the field of view of another digital image of the plurality of digital images. The system accomplishes this by determining if a substantial correspondence exists between (x) a perceivable feature included in a border region segment of the selected digital image of the plurality of digital images and (y) at least one respective perceivable feature included in each digital image of the plurality of digital images other than the selected digital image. For example, the feature matching circuit may output a \u201c0\u201d if no substantial correspondence is found, and output a \u201c1\u201d if a substantial correspondence is found. In an embodiment, the system proceeds around the several border regions of the selected digital image and similarly determine a substantial correspondence for each respective feature included in the several border regions with respect to each digital image of the plurality of digital images other than the selected digital image. The system includes a data collection circuit  configured to gather the determined substantial correspondence in the form of \u201c1\u201d and \u201c0\u201d for the perceivable feature included in the border region segment of the selected digital image.","In this example of the system  in use, the system includes a reporting circuit  configured to output informational data indicative of a possible non-imaged portion of the region of interest adjacent to the selected digital image. The informational data is responsive to an absence of a determined substantial correspondence (all 0's) between the perceivable feature included in the border region segment of the selected digital image and at least one respective perceivable feature included in each digital image of the plurality of digital images other than the selected digital image. For example, the system in generating the informational data treats a determination of an absence of substantial correspondence (all 0's) for the perceivable feature of the border region segment of the selected digital image as an indication that there likely is no border region overlap with any other feature of the remaining digital images and outputs that there is a possible adjacent non-imaged portion. For example, the system in generating the informational data treats a determination of a substantial correspondence (at least a single 1) for the perceivable feature of the border region segment of the selected digital image as an indication that there likely is a possible border region overlap with at least one detected border region feature of the remaining digital images, concludes the adjacent portion is likely imaged, and does not output that there is a possible adjacent non-imaged portion.","For example, and without limitation, an embodiment of the subject matter described herein includes a system. In this embodiment, the system includes a feature-detection circuit configured to extract at least one respective human-perceivable feature included in each medical image of a plurality of medical images of the skin of an individual human (hereafter \u201cmedical skin images\u201d). The each medical image of plurality of medical skin images includes a respective portion of a region of interest of a surface of the skin of the individual human, and was acquired by a handheld digital image acquisition device. The system includes a feature matching circuit configured to determine a substantial correspondence between (x) an extracted human-perceivable feature included in a border region segment of a selected medical skin image of the plurality of medical skin images and (y) an extracted at least one respective human-perceivable feature included in the each medical skin image of the plurality of medical skin images other than the selected medical skin image. The system includes a data collection circuit configured to gather the determined substantial correspondences for the extracted human-perceivable feature included in the border region segment of the selected medical skin image. The system includes an overlap-analysis circuit configured to generate data indicative of a border region-overlap status of the selected medical skin image. The data is generated at least partially in response to the determined substantial correspondences. The system includes a list management circuit configured to add the data indicative of the determined border region-overlap status for the border region segment of the selected medical skin image to an omitted-coverage list. The system includes an iteration control circuit configured to iteratively designate a next medical skin image from the plurality of medical skin images as the selected medical skin image until each medical skin image of the plurality of medical skin images has been designated. The iteration control circuit is also configured to initiate a processing of each of the iteratively designated next medical skin images by the feature-matching circuit, the data collection circuit, the overlap-analysis circuit, and the list management circuit. The system includes a coverage-analysis circuit configured to identify a particular portion of the skin surface as likely not included in the plurality of medical skin images (hereafter \u201cpossible non-imaged portion of the region of interest\u201d). The identifying the possible non-imaged portion of the region of interest at least partially based on the omitted-coverage list. The system also includes (h) a reporting circuit configured to output user-assistance information at least partially based on the identified possible non-imaged portion of the skin.","In an embodiment, the system includes an image receiver circuit configured to receive the plurality of medical skin images. In an embodiment, the system includes a border region detection circuit configured to detect a border region segment of a medical skin image of the plurality of medical skin images. In an embodiment, the system includes computer-readable media configured to maintain the user-assistance information corresponding to the identified possible non-imaged portion of the region of interest and to the signpost medical skin image. In an embodiment, the system includes a communications device configured to display a particular human-perceivable depiction of the user-assistance information.","For example, and without limitation, an embodiment of the subject matter described herein includes a method implemented in a computing device. In this embodiment, the method includes an operation (a) extracting at least one respective human-perceivable feature included in each medical image of a plurality of medical images of the skin of an individual human (hereafter \u201cmedical skin images\u201d). The each medical image of plurality of medical skin images includes a respective portion of a region of interest of a surface of the skin of the individual human, and was acquired by a handheld digital image acquisition device. The method includes an operation (b) determining a substantial correspondence between (x) an extracted human-perceivable feature included in a border region segment of a selected medical skin image of the plurality of medical skin images and (y) an extracted at least one respective human-perceivable feature included in each medical skin image of the plurality of medical skin images other than the selected medical skin image. The method includes an operation (c) gathering the determined substantial correspondences for the human-perceivable feature included in the border region segment of the selected medical skin image. The method includes an operation (d) generating data indicative of a border region-overlap status of the selected medical skin image. The data is generated at least partially in response to the determined substantial correspondences. The method includes an operation (e) adding the data indicative of the determined border region-overlap status for the border region segment of the selected medical skin image to an omitted-coverage list. The method includes an operation (f) iteratively designating a next medical skin image from the plurality of medical skin images as the selected medical skin image until each medical skin image of the plurality of medical skin images has been designated. The method includes an operation (g) processing of each of the iteratively designated next medical skin images, the processing includes operations (b), (c), (d), and (e). The method includes an operation (h) identifying a particular portion of the skin surface as likely not included in the plurality of medical skin images (hereafter \u201cpossible non-imaged portion of the skin\u201d). The identifying the possible non-imaged portion of the skin is at least partially based on the omitted-coverage list. The method includes an operation (i) outputting user-assistance information at least partially based on the identified possible non-imaged portion of the skin.","In an embodiment, the method includes receiving the plurality of medical skin images. In an embodiment, the method includes detecting a border region segment of a medical skin image of the plurality of medical skin images. In an embodiment, the method includes maintaining the user-assistance information in computer-readable storage media.","For example, and without limitation, an embodiment of the subject matter described herein includes a computer program product. In this embodiment, the computer program product includes computer-readable media bearing program instructions. The program instructions, when executed by a processor of a computing device, cause the computing device to perform a process. The process includes an operation (i) extracting at least one respective human-perceivable feature included in each medical image of a plurality of medical images of the skin of an individual human (hereafter \u201cmedical skin images\u201d). The each medical image of plurality of medical skin images includes a respective portion of a region of interest of a surface of the skin of the individual human, and was acquired by a handheld digital image acquisition device. The process includes an operation (ii) determining a substantial correspondence between (x) an extracted human-perceivable feature included in a border region segment of a selected medical skin image of the plurality of medical skin images and (y) an extracted at least one respective human-perceivable feature included in each medical skin image of the plurality of medical skin images other than the selected medical skin image. The process includes an operation (iii) gathering the determined substantial correspondences for the human-perceivable feature included in the border region segment of the selected medical skin image. The process includes an operation (iv) generating data indicative of a border region-overlap status of the selected medical skin image. The data is generated at least partially in response to the determined substantial correspondences. The process includes an operation (v) adding the data indicative of the determined border region-overlap status for the border region segment of the selected medical skin image to an omitted-coverage list. The process includes an operation (vi) iteratively designating a next medical skin image from the plurality of medical skin images as the selected medical skin image until each medical skin image of the plurality of medical skin images has been designated. The process includes an operation (vii) processing of each of the iteratively designated next medical skin images, the processing includes operations (ii), (iii), (iv), and (v). The process includes an operation (viii) identifying a particular portion of the skin surface as likely not included in the plurality of medical skin images (hereafter \u201cpossible non-imaged portion of the skin\u201d). The identifying the possible non-imaged portion of the skin is at least partially based on the omitted-coverage list. The process includes an operation (ix) outputting user-assistance information at least partially based on the identified possible non-imaged portion of the skin.","In an embodiment, the process includes receiving the plurality of medical skin images. In an embodiment, the process includes detecting a border region segment of a medical skin image of the plurality of medical skin images. In an embodiment, the process includes displaying the user-assistance information. In an embodiment, the process includes maintaining the user-assistance information in computer-readable storage media. In an embodiment, the computer-readable media includes tangible computer-readable media. In an embodiment, the computer-readable media includes communications media.","For example, and without limitation, an embodiment of the subject matter described herein includes a system. In this embodiment, the system includes (a) means for extracting at least one respective human-perceivable feature included in each medical image of a plurality of medical images of the skin of an individual human (hereafter \u201cmedical skin images\u201d). The each medical image of plurality of medical skin images includes a respective portion of a region of interest of a surface of the skin of the individual human, and was acquired by a handheld digital image acquisition device. The system includes (b) means for determining a substantial correspondence between (x) an extracted human-perceivable feature included in a border region segment of a selected medical skin image of the plurality of medical skin images and (y) an extracted at least one respective human-perceivable feature included in each medical skin image of the plurality of medical skin images other than the selected medical skin image. The system includes (c) means for gathering the determined substantial correspondences for the extracted human-perceivable feature included in the border region segment of the selected medical skin image. The system includes (d) means for generating data indicative of a border region-overlap status of the selected medical skin image. The data is generated at least partially in response to the determined substantial correspondences. The system includes (e) means for adding the data indicative of the determined border region-overlap status for the border region segment of the selected medical skin image to an omitted-coverage list. The system includes (f) means for iteratively designating a next medical skin image from the plurality of medical skin images as the selected medical skin image until each medical skin image of the plurality of medical skin images has been designated. The system includes (g) means for initiating a processing of each of the iteratively designated next medical skin images, the processing includes operations at means (b), (c), (d), and (e). The system includes (h) means for identifying a particular portion of the skin surface as likely not included in the plurality of medical skin images (hereafter \u201cpossible non-imaged portion of the skin\u201d). The identifying the possible non-imaged portion of the skin is at least partially based on the omitted-coverage list. The system includes (i) means for outputting user-assistance information at least partially based on the identified possible non-imaged portion of the skin.","The foregoing summary is illustrative only and is not intended to be in any way limiting. In addition to the illustrative aspects, embodiments, and features described above, further aspects, embodiments, and features will become apparent by reference to the drawings and the following detailed description.","In the following detailed description, reference is made to the accompanying drawings, which form a part hereof. In the drawings, similar symbols typically identify similar components, unless context dictates otherwise. The illustrated embodiments described in the detailed description, drawings, and claims are not meant to be limiting. Other embodiments may be utilized, and other changes may be made, without departing from the spirit or scope of the subject matter presented here.","Those having skill in the art will recognize that the state of the art has progressed to the point where there is little distinction left between hardware, software, and\/or firmware implementations of aspects of systems; the use of hardware, software, and\/or firmware is generally (but not always, in that in certain contexts the choice between hardware and software can become significant) a design choice representing cost vs. efficiency tradeoffs. Those having skill in the art will appreciate that there are various vehicles by which processes and\/or systems and\/or other technologies described herein can be effected (e.g., hardware, software, and\/or firmware), and that the preferred vehicle will vary with the context in which the processes and\/or systems and\/or other technologies are deployed. For example, if an implementer determines that speed and accuracy are paramount, the implementer may opt for a mainly hardware and\/or firmware vehicle; alternatively, if flexibility is paramount, the implementer may opt for a mainly software implementation; or, yet again alternatively, the implementer may opt for some combination of hardware, software, and\/or firmware. Hence, there are several possible vehicles by which the processes and\/or devices and\/or other technologies described herein may be effected, none of which is inherently superior to the other in that any vehicle to be utilized is a choice dependent upon the context in which the vehicle will be deployed and the specific concerns (e.g., speed, flexibility, or predictability) of the implementer, any of which may vary. Those skilled in the art will recognize that optical aspects of implementations will typically employ optically-oriented hardware, software, and or firmware.","In some implementations described herein, logic and similar implementations may include software or other control structures suitable to operation. Electronic circuitry, for example, may manifest one or more paths of electrical current constructed and arranged to implement various logic functions as described herein. In some implementations, one or more media are configured to bear a device-detectable implementation if such media hold or transmit a special-purpose device instruction set operable to perform as described herein. In some variants, for example, this may manifest as an update or other modification of existing software or firmware, or of gate arrays or other programmable hardware, such as by performing a reception of or a transmission of one or more instructions in relation to one or more operations described herein. Alternatively or additionally, in some variants, an implementation may include special-purpose hardware, software, firmware components, and\/or general-purpose components executing or otherwise invoking special-purpose components. Specifications or other implementations may be transmitted by one or more instances of tangible transmission media as described herein, optionally by packet transmission or otherwise by passing through distributed media at various times.","Alternatively or additionally, implementations may include executing a special-purpose instruction sequence or otherwise invoking circuitry for enabling, triggering, coordinating, requesting, or otherwise causing one or more occurrences of any functional operations described below. In some variants, operational or other logical descriptions herein may be expressed directly as source code and compiled or otherwise invoked as an executable instruction sequence. In some contexts, for example, C++ or other code sequences can be compiled directly or otherwise implemented in high-level descriptor languages (e.g., a logic-synthesizable language, a hardware description language, a hardware design simulation, and\/or other such similar mode(s) of expression). Alternatively or additionally, some or all of the logical expression may be manifested as a Verilog-type hardware description or other circuitry model before physical implementation in hardware, especially for basic operations or timing-critical applications. Those skilled in the art will recognize how to obtain, configure, and optimize suitable transmission or computational elements, material supplies, actuators, or other common structures in light of these teachings.","In a general sense, those skilled in the art will recognize that the various embodiments described herein can be implemented, individually and\/or collectively, by various types of electro-mechanical systems having a wide range of electrical components such as hardware, software, firmware, and\/or virtually any combination thereof; and a wide range of components that may impart mechanical force or motion such as rigid bodies, spring or torsional bodies, hydraulics, electro-magnetically actuated devices, and\/or virtually any combination thereof. Consequently, as used herein \u201celectro-mechanical system\u201d includes, but is not limited to, electrical circuitry operably coupled with a transducer (e.g., an actuator, a motor, a piezoelectric crystal, a Micro Electro Mechanical System (MEMS), etc.), electrical circuitry having at least one discrete electrical circuit, electrical circuitry having at least one integrated circuit, electrical circuitry having at least one application specific integrated circuit, electrical circuitry forming a general purpose computing device configured by a computer program (e.g., a general purpose computer configured by a computer program which at least partially carries out processes and\/or devices described herein, or a microprocessor configured by a computer program which at least partially carries out processes and\/or devices described herein), electrical circuitry forming a memory device (e.g., forms of memory (e.g., random access, flash, read only, etc.)), electrical circuitry forming a communications device (e.g., a modem, communications switch, optical-electrical equipment, etc.), and\/or any non-electrical analog thereto, such as optical or other analogs. Those skilled in the art will also appreciate that examples of electro-mechanical systems include but are not limited to a variety of consumer electronics systems, medical devices, as well as other systems such as motorized transport systems, factory automation systems, security systems, and\/or communication\/computing systems. Those skilled in the art will recognize that electro-mechanical as used herein is not necessarily limited to a system that has both electrical and mechanical actuation except as context may dictate otherwise.","In a general sense, those skilled in the art will also recognize that the various aspects described herein which can be implemented, individually and\/or collectively, by a wide range of hardware, software, firmware, and\/or any combination thereof can be viewed as being composed of various types of \u201celectrical circuitry.\u201d Consequently, as used herein \u201celectrical circuitry\u201d includes, but is not limited to, electrical circuitry having at least one discrete electrical circuit, electrical circuitry having at least one integrated circuit, electrical circuitry having at least one application specific integrated circuit, electrical circuitry forming a general purpose computing device configured by a computer program (e.g., a general purpose computer configured by a computer program which at least partially carries out processes and\/of devices described herein, or a microprocessor configured by a computer program which at least partially carries out processes and\/or devices described herein), electrical circuitry forming a memory device (e.g., forms of memory (e.g., random access, flash, read only, etc.)), and\/or electrical circuitry forming a communications device (e.g., a modem, communications switch, optical-electrical equipment, etc.). Those having skill in the art will recognize that the subject matter described herein may be implemented in an analog or digital fashion or some combination thereof.","Those skilled in the art will further recognize that at least a portion of the devices and\/or processes described herein can be integrated into an image processing system. A typical image processing system may generally include one or more of a system unit housing, a video display device, memory such as volatile or non-volatile memory, processors such as microprocessors or digital signal processors, computational entities such as operating systems, drivers, applications programs, one or more interaction devices (e.g., a touch pad, a touch screen, an antenna, etc.), control systems including feedback loops and control motors (e.g., feedback for sensing lens position and\/or velocity; control motors for moving\/distorting lenses to give desired focuses). An image processing system may be implemented utilizing suitable commercially available components, such as those typically found in digital still systems and\/or digital motion systems.","Those skilled in the art will likewise recognize that at least some of the devices and\/or processes described herein can be integrated into a data processing system. Those having skill in the art will recognize that a data processing system generally includes one or more of a system unit housing, a video display device, memory such as volatile or non-volatile memory, processors such as microprocessors or digital signal processors, computational entities such as operating systems, drivers, graphical user interfaces, and applications programs, one or more interaction devices (e.g., a touch pad, a touch screen, an antenna, etc.), and\/or control systems including feedback loops and control motors (e.g., feedback for sensing position and\/or velocity; control motors for moving and\/or adjusting components and\/or quantities). A data processing system may be implemented utilizing suitable commercially available components, such as those typically found in data computing\/communication and\/or network computing\/communication systems.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIGS. 1 and 2","FIG. 1","FIG. 2"],"b":["19","20","100","110"]},{"@attributes":{"id":"p-0062","num":"0061"},"figref":["FIG. 1","FIG. 1"],"b":["19","20","50"]},"The thin computing device  includes a processing unit , a system memory , and a system bus  that couples various system components including the system memory  to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. The system memory includes read-only memory (ROM)  and random access memory (RAM) . A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between sub-components within the thin computing device , such as during start-up, is stored in the ROM . A number of program modules may be stored in the ROM  or RAM , including an operating system , one or more application programs , other program modules  and program data .","A user may enter commands and information into the computing device  through one or more input interfaces. An input interface may include a touch-sensitive display, or one or more switches or buttons with suitable input detection circuitry. A touch-sensitive display is illustrated as a display  and screen input detector . One or more switches or buttons are illustrated as hardware buttons  connected to the system via a hardware button interface . The output circuitry of the touch-sensitive display  is connected to the system bus  via a video driver . Other input devices may include a microphone  connected through a suitable audio interface , or a physical hardware keyboard (not shown). Output devices may include the display , or a projector display .","In addition to the display , the computing device  may include other peripheral output devices, such as at least one speaker . Other external input or output devices , such as a joystick, game pad, satellite dish, scanner or the like may be connected to the processing unit  through a USB port  and USB port interface , to the system bus . Alternatively, the other external input and output devices  may be connected by other interfaces, such as a parallel port, game port or other port. The computing device  may further include or be capable of connecting to a flash card memory (not shown) through an appropriate connection port (not shown). The computing device  may further include or be capable of connecting with a network through a network port  and network interface , and through wireless port  and corresponding wireless interface  may be provided to facilitate communication with other peripheral devices, including other computers, printers, and so on (not shown). It will be appreciated that the various components and connections shown are examples and other components and means of establishing communication links may be used.","The computing device  may be primarily designed to include a user interface. The user interface may include a character, a key-based, or another user data input via the touch sensitive display . The user interface may include using a stylus (not shown). Moreover, the user interface is not limited to an actual touch-sensitive panel arranged for directly receiving input, but may alternatively or in addition respond to another input device such as the microphone . For example, spoken words may be received at the microphone  and recognized. Alternatively, the computing device  may be designed to include a user interface having a physical keyboard (not shown).","The device functional elements  are typically application specific and related to a function of the electronic device, and are coupled with the system bus  through an interface (not shown). The functional elements may typically perform a single well-defined task with little or no user configuration or setup, such as a refrigerator keeping food cold, a cell phone connecting with an appropriate tower and transceiving voice or data information, a camera capturing and saving an image, or communicating with an implantable medical apparatus.","In certain instances, one or more elements of the thin computing device  may be deemed not necessary and omitted. In other instances, one or more other elements may be deemed necessary and added to the thin computing device.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIG. 2","FIG. 2"],"b":["100","100","110","120","130","121","120","121"]},"The computing system environment  typically includes a variety of computer-readable media products. Computer-readable media may include any media that can be accessed by the computing device  and include both volatile and nonvolatile media, removable and non-removable media. By way of example, and not of limitation, computer-readable media may include computer storage media. By way of further example, and not of limitation, computer-readable media may include a communication media.","Computer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules, or other data. Computer storage media includes, but is not limited to, random-access memory (RAM), read-only memory (ROM), electrically erasable programmable read-only memory (EEPROM), flash memory, or other memory technology, CD-ROM, digital versatile disks (DVD), or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage, or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by the computing device . In a further embodiment, a computer storage media may include a group of computer storage media devices. In another embodiment, a computer storage media may include an information store. In another embodiment, an information store may include a quantum memory, a photonic quantum memory, or atomic quantum memory. Combinations of any of the above may also be included within the scope of computer-readable media.","Communication media may typically embody computer-readable instructions, data structures, program modules, or other data in a modulated data signal such as a carrier wave or other transport mechanism and include any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communications media may include wired media, such as a wired network and a direct-wired connection, and wireless media such as acoustic, RF, optical, and infrared media.","The system memory  includes computer storage media in the form of volatile and nonvolatile memory such as ROM  and RAM . A RAM may include at least one of a DRAM, an EDO DRAM, a SDRAM, a RDRAM, a VRAM, or a DDR DRAM. A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between elements within the computing device , such as during start-up, is typically stored in ROM . RAM  typically contains data and program modules that are immediately accessible to or presently being operated on by the processor . By way of example, and not limitation,  illustrates an operating system , application programs , other program modules , and program data . Often, the operating system  offers services to applications programs  by way of one or more application programming interfaces (APIs) (not shown). Because the operating system  incorporates these services, developers of applications programs  need not redevelop code to use the services. Examples of APIs provided by operating systems such as Microsoft's \u201cWINDOWS\u201d\u00ae are well known in the art.","The computing device  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media products. By way of example only,  illustrates a non-removable non-volatile memory interface (hard disk interface)  that reads from and writes for example to non-removable, non-volatile magnetic media.  also illustrates a removable non-volatile memory interface  that, for example, is coupled to a magnetic disk drive  that reads from and writes to a removable, non-volatile magnetic disk , or is coupled to an optical disk drive  that reads from and writes to a removable, non-volatile optical disk , such as a CD ROM. Other removable\/nonremovable, volatile\/non-volatile computer storage media that can be used in the example operating environment include, but are not limited to, magnetic tape cassettes, memory cards, flash memory cards, DVDs, digital video tape, solid state RAM, and solid state ROM. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface, such as the interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable non-volatile memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in  provide storage of computer-readable instructions, data structures, program modules, and other data for the computing device . In , for example, hard disk drive  is illustrated as storing an operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from the operating system , application programs , other program modules , and program data . The operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that, at a minimum, they are different copies.","A user may enter commands and information into the computing device  through input devices such as a microphone , keyboard , and pointing device , commonly referred to as a mouse, trackball, or touch pad. Other input devices (not shown) may include at least one of a touch sensitive display, joystick, game pad, satellite dish, and scanner. These and other input devices are often connected to the processor  through a user input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port, or a universal serial bus (USB).","A display , such as a monitor or other type of display device or surface may be connected to the system bus  via an interface, such as a video interface . A projector display engine  that includes a projecting element may be coupled to the system bus. In addition to the display, the computing device  may also include other peripheral output devices such as speakers  and printer , which may be connected through an output peripheral interface .","The computing system environment  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device, or other common network node, and typically includes many or all of the elements described above relative to the computing device , although only a memory storage device  has been illustrated in . The network logical connections depicted in  include a local area network (LAN) and a wide area network (WAN), and may also include other networks such as a personal area network (PAN) (not shown). Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet.","When used in a networking environment, the computing system environment  is connected to the network  through a network interface, such as the network interface , the modem , or the wireless interface . The network may include a LAN network environment, or a WAN network environment, such as the Internet. In a networked environment, program modules depicted relative to the computing device , or portions thereof, may be stored in a remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on memory storage device . It will be appreciated that the network connections shown are examples and other means of establishing communication link between the computers may be used.","In certain instances, one or more elements of the computing device  may be deemed not necessary and omitted. In other instances, one or more other elements may be deemed necessary and added to the computing device.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 3","b":["200","201","205","210","220","292","294","296"]},{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIGS. 4-5","FIG. 4","FIG. 4"],"b":["210","210","1","210","210","1","210","1","210","1","210","1","211","1","211","2","212","210","1","210","1"]},{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 5","b":["210","1","210","4","210","210","2","210","4","210","4","210","2"]},{"@attributes":{"id":"p-0084","num":"0083"},"figref":["FIG. 6","FIG. 6","FIG. 6","FIG. 6"],"b":["210","1","210","8","210","210","1","210","8","202","201","218","202","201","210","3","210","5","210","6","210","7","210","6","218","216","210","6"]},"Returning to , the system  includes a feature-detection circuit . The feature detection circuit is configured to extract at least one respective perceivable feature included in each digital image of the plurality of digital images . The each digital image of the plurality of digital images includes a respective portion of a region of interest of a surface a respective portion of the region of interest  of the surface . An example circuit or system configured to extract at least one respective perceivable feature included in each digital image of the plurality of digital images is provided by Photomodeler and PhotoModeler Scanner products by PhotoModeler \u00ae of Vancouver, BC, Canada.","For example, a perceivable feature may include a discernable shape. For example, a perceivable feature may be discernable under natural lighting or under a particular lighting, such as infrared lighting. For example, a perceivable feature may be a static perceivable feature of the surface. For example, where the surface is a surface of a human skin, a perceivable feature may include a hair, wrinkle, surface, color, structure, or texture variation. For example, a perceivable feature may include a color and\/or texture change and\/or shift in skin or tissue pigments (e.g., melanoma or other tumor borders, burns, scar tissue, necrotic tissue). For example, a perceivable feature may include a perceivable surface vascular feature of a cavity or lumen. For example, a perceivable feature may include a perceivable surface anomaly. For example, a perceivable feature may include a perceivable surface anatomical feature. For example, a perceivable feature may include a perceivable surface vascular feature. For example, a perceivable feature may include a perceivable surface vessel, blood vessel, vascular structure, or a pattern presented by one or more blood vessels of a surface of a human or animal. For example, a perceivable feature may include a perceivable physical structure, void, border, component, tissue, structural feature, or density variation of a surface. For example, a perceivable feature may include a perceivable pattern presented by one or more features. For example, a perceivable feature may include a perceivable fiducial formed by one or more structures, colors, or shapes of a surface. For example, a perceivable feature may include a perceivable relative size or spatial relationship of two or more perceivable physical structures, voids, borders, components, tissues, structural features, or density variations of a surface. For example, a perceivable feature may include a perceivable normal surface feature. For example, a perceivable feature may include a perceivable usual, regular, or typical surface feature. For example, perceivable feature may include a perceivable abnormal surface feature. For example, a perceivable abnormal feature may include perceivable unusual, irregular, or disease state. For example, a perceivable abnormal feature may include perceivable scar tissue, healed lesion, nodule, or encapsulated foreign object. For example, a perceivable feature may include a perceivable feature of a surface that is machine distinguishable from another surface feature. For example, a perceivable feature may include a perceivable surface feature that is machine differentiable from another perceivable surface feature. For example, a computing machine may be able to differentiate between first surface feature and second surface feature, but may not be able to distinguish or discern why they are not the same. For example, where the surface is a surface of an object, the perceivable feature may include a structural element, or a surface variation. For example, a surface color variation may include a red rust spot on a blue car. For example a surface texture variation may include a rust corrosion spot on an otherwise intact surface.","In an embodiment, the perceivable feature includes a human-vision perceivable feature. For example, a human-vision perceivable feature may include a feature that is visible to the naked eye or using natural human vision, including corrective lenses. In an embodiment, the perceivable feature includes an augmented human-vision perceivable feature, such as a feature visible to the naked eye as a result of computer implemented enhancement, or computer augmented vision. In an embodiment, the perceivable feature includes a machine-vision perceivable feature.","Continuing with reference to , the system  includes a feature matching circuit . The feature matching circuit is configured to determine a substantial correspondence between (x) an extracted perceivable feature included in a border region segment of a selected digital image of the plurality of digital images and (y) an extracted at least one respective perceivable feature included in the each digital image of the plurality of digital images other than the selected digital image (i.e., the plurality digital images minus the selected digital image). For example, if the feature matching circuit determines a substantial correspondence, it may be configured to output a \u201c1\u201d, and if the feature matching circuit does not determine a substantial correspondence, it may be configured to output a \u201c0\u201d. With reference to  for example, if the selected digital image is digital image ., the feature matching circuit would find a substantial correspondence between (x) the perceivable feature A included in a border region segment of the digital image . and (y) the perceivable feature A included in the digital image ., and would thus output a \u201c1\u201d. The feature matching circuit would not find a substantial correspondence between (x) the perceivable feature A included in the border region segment of the selected digital image . and (y) any of the other the perceivable features included in the digital images . and ., and would respectively output a \u201c0\u201d in response to at least one respective perceivable feature included in each digital image of the plurality of digital images .-.. For example, with reference to , the feature matching circuit would not find a substantial correspondence between (x) the perceivable feature C included in another border region segment of the selected digital image . and (y) any of the other the perceivable features included in the digital images .-., and would respectively output a \u201c0\u201d in response to at least one respective perceivable feature included in each digital image of the digital images .-..","Continuing with reference to , the system  also includes a data collection circuit  configured to gather the determined substantial correspondences for the extracted perceivable feature included in the border region segment of the selected digital image. With reference to the example of  described above, in an embodiment, the data collection circuit would gather the \u201c1\u201d and \u201c0\u201d outputted by the feature matching circuit . With reference to the perceivable feature A included in a border region segment of the selected digital image ., the gathered outputs would be a single \u201c1\u201d for the digital image . and at least one \u201c0\u201d for digital images . and ., i.e. [1,0,0]. With reference to the perceivable feature C included in a border region segment of the selected digital image ., the gathered outputs would be all \u201c0\u201d for digital images .-., i.e. [0,0,0].","The system  also includes a reporting circuit . The reporting circuit is configured to output informational data indicative of a possible non-imaged portion of the region of interest  of the surface . For example, the informational data may be indicative of the possible non-imaged portion  of the region of interest  of the surface  illustrated in . The informational data is responsive to an absence of a determined substantial correspondence between the extracted perceivable feature included in the border region segment of the selected digital image and the extracted at least one respective perceivable feature included in the each digital image of the plurality of digital images other than the selected digital image. With reference to the example of  described above, the data collection circuit  would have gathered an absence of a determined substantial correspondence [0,0,0] between the perceivable feature C included in a border region segment of the selected digital image . and at least one respective perceivable feature included in each digital image of the plurality of digital images .-. other than the selected digital image. In an embodiment, the reporting circuit interprets an absence of a determined substantial correspondence as indicia of a possible non-imaged portion of the region of interest adjacent to the selected digital image.","In an embodiment of the system, each digital image of the plurality of digital images includes an indication of a position or location relative to the region of interest of the surface. In an embodiment, the plurality of digital images respectively includes a plurality of medical images of a portion of a region of interest of a surface of an individual mammal. In an embodiment, each medical image of the plurality of medical images respectively includes a portion of a region of interest of an internal surface of an individual mammalian body part. In an embodiment, the plurality of medical images of an internal surface of an individual mammalian body part was acquired by a body-insertable device. In an embodiment, the plurality of medical images of an internal surface of an individual mammalian body part were acquired by an ex vivo device. In an embodiment, each medical image of the plurality of medical images respectively includes a portion of a region of interest of an external surface of an individual mammal. In an embodiment, each digital image of the plurality of digital images respectively includes a portion of a region of interest of a surface of an object. For example, the object may include the earth or planetary surface, a planetary body, ocean floor, a product, an aircraft, a machine, or a boat. In an embodiment, each digital image of the plurality of digital images includes a respective identifier. For example, an identifier may include an alpha-numeric identifier. In an embodiment, the identifier may be used to identify a digital image adjacent to the possible non-imaged portion of the region of interest. In an embodiment, each digital image of the plurality of digital images includes a respective identifier assigned by a receiver circuit operatively coupled to the system. In an embodiment, each digital image of the plurality of digital images includes a respective identifier assigned by the system. In an embodiment, each digital image of the plurality of digital images includes a respective identifier assigned by the system after receipt by an image receiver circuit. In an embodiment, each digital image of the plurality of digital images includes a respective identifier assigned by another system.","In an embodiment, the feature matching circuit  includes a feature matching circuit configured to determine a substantial correspondence between (x) an extracted perceivable feature included in a border region segment of a selected digital image of the plurality of digital images and (y) an extracted at least one respective perceivable feature of a border region segment of the each digital image of the plurality of digital images other than the selected digital image. For example, this may be thought of as edge-feature to edge-feature correspondence or matching. In this embodiment, the feature matching circuit is matching with respect to perceivable features in border region segments of both images. In an embodiment, the feature matching circuit includes a feature matching circuit configured to determine a substantial correspondence between (x) an extracted perceivable feature included in a border region segment of a selected digital image and (y) an extracted at least one respective perceivable feature of a field of view of each digital image of the plurality of digital images other than the selected digital image.","In an embodiment, the system  includes an image receiver circuit configured to receive the plurality of digital images. In an embodiment, the system includes a border region detection circuit  configured to detect a border region segment of a digital image. In an embodiment, the border region detection circuit includes a border region detection circuit configured to select a length and\/or a width parameter of the border regions. The border region detection circuit is also configured to detect a border region segment having the selected length and\/or width. For example, the length and\/or a width parameter of the border regions may be a percentage of a dimension of the image, or may be a specific length, or a specific number of pixels. For example, the length and\/or a width parameter of the border regions may be dynamically varied depending on a result of the feature matching, or depending on speed and processing horsepower available to the system. For example, the length and\/or a width parameter of the border regions may be dynamically varied to provide an increased resolution in transition regions. In an embodiment, the border region detection circuit includes a border region detection circuit configured to receive a selected length and\/or a width parameter of the border regions. The border region detection circuit is also configured to detect a border region segment of a digital image having the selected length and\/or width parameter. In an embodiment, the feature-matching circuit  includes a feature-matching circuit configured to determine a substantial correspondence between (x) a perceivable feature included in the detected border region segment of a selected digital image of the plurality of digital images and (y) at least one respective perceivable feature included in each digital image of the plurality of digital images other than the selected digital image.","In an embodiment, the feature-matching circuit  includes a feature-matching circuit configured to (i) determine a substantial correspondence between (x) a perceivable feature included in a border region segment of a selected digital image of the plurality of digital images and (y) at least one respective perceivable feature included in each digital image of the plurality of digital images other than the selected digital image. The feature-matching circuit is also configured to (ii) iteratively designate a next perceivable feature included in a next border region segment of the selected digital image. The feature matching circuit is further configured to (iii) initiate a determination of a substantial correspondence of the iteratively designated next perceivable feature included in the next border region segment pursuant to element (i). With reference to  for example, this embodiment will step through at least two iterations by looking for substantial correspondence for perceivable feature A and perceivable feature B. In an embodiment, the data collection circuit  includes a data collection circuit configured to gather the determined substantial correspondences for the respective perceivable feature included in the respective border region segments of the selected digital image. In an embodiment, the reporting circuit  includes a reporting circuit configured to output informational data indicative of a possible non-imaged portion of the region of interest of the surface. The informational data is responsive to an absence of a determined substantial correspondences between the extracted respective perceivable feature included in the respective border region segments of the at least two border region segments of the selected digital image and the extracted at least one respective perceivable feature included in the each digital image of the plurality of digital images other than the selected digital image.","In an embodiment, the system  includes an overlap-analysis circuit  configured to generate data indicative of a border region-overlap status of the selected digital image. The data is generated at least partially in response to the determined substantial correspondence between the extracted perceivable feature included in the border region segment of the selected digital image and the extracted at least one respective perceivable feature included in the each digital image of the plurality of digital images other than the selected digital image. For example, a determined absence of a substantial correspondence for perceivable feature in one border region segment of the selected digital image may result in generation of data indicative on a \u201cborder region not overlapped\u201d status. With reference to the example of  described above, and in reference to the perceivable feature C included in a border region segment of the selected digital image .; where the gathered determined substantial correspondences for perceivable feature C are all \u201c0\u201d (i.e. [0,0,0]), the overlap-analysis circuit generates data indicative of a \u201cborder region not overlapped\u201d status for the border region segment of the digital image . that includes perceivable feature C. For example, a determined a substantial correspondence for a perceivable feature in one detected border region segment of the selected digital image may result in generation of data indicative of a \u201cborder region overlapped\u201d status. With reference to the example of  described above, and in reference to the perceivable feature A included in a border region segment of the selected digital image .; where the gathered determined substantial correspondences for the perceivable feature A include a \u201c1\u201d with respect to digital image ., the overlap-analysis circuit generates data indicative of a \u201cborder region overlapped\u201d status for the border region segment of the digital image . that includes perceivable feature A. In an embodiment, the reporting circuit  includes a reporting circuit configured to output informational data indicative of the border region-overlap status of the selected digital image. The informational data is at least partially based on the data indicative of a border region-overlap status of the selected digital image.","In an embodiment, the overlap-analysis circuit  includes an overlap-analysis circuit configured to generate data indicative of a possible non-imaged portion of the region of interest adjacent to the selected digital image. In an embodiment, the reporting circuit  includes a reporting circuit configured to output informational data indicative of the possible non-imaged portion of the region of interest adjacent to the selected digital image. The informational data is at least partially based on the data indicative of the possible non-imaged portion of the region of interest adjacent to the selected digital image. In an embodiment, the overlap-analysis circuit includes an overlap-analysis circuit configured to generate data indicative of a possible non-imaged portion of the region of interest adjacent to both the selected digital image and another selected digital image. In an embodiment, the overlap-analysis circuit includes an overlap-analysis circuit configured to generate data indicative of a predicted possible non-imaged portion of the region of interest adjacent to the selected digital image. In an embodiment, the prediction may be based on filtering or applying a prediction algorithm.","Continuing with , in an embodiment, the overlap-analysis circuit  includes an overlap-analysis circuit configured to generate data indicative of a possible imaged portion of the region of interest adjacent to the selected digital image. In an embodiment, the overlap-analysis circuit  includes an overlap-analysis circuit configured to generate data indicative of a possible non-imaged portion of the region of interest adjacent to the selected digital image and indicative of a spatial relationship between the possible non-imaged portion of the region of interest and the feature. In an embodiment, the spatial relationship may be indicated with respect to a site, center, or quadrant of the border region segment of the selected digital image.  provides a partial illustration of this embodiment. The embodiment provides data indicative of a spatial relationship  between the possible non-imaged portion  of the region of interest  and the perceivable feature included in the border region segment (although  illustrates a situation where the perceivable feature W is not included in the border region). In an embodiment, the overlap-analysis circuit  includes an overlap-analysis circuit configured to generate data indicative of a possible non-imaged portion of the region of interest adjacent to the selected digital image; and indicative of a spatial relationship between the possible non-imaged portion of the region of interest and the feature included in a border region segment of the selected digital image. The spatial relationship is indicated by a line anchored by a feature, site, center, or quadrant of the selected digital image.  provides an illustration of this embodiment. The data of this embodiment provides an indication of the spatial relationship  between the possible non-imaged portion  that is anchored by the perceivable feature W. In an embodiment, the determined spatial relationship is indicated by a line anchored by a feature, site, center, or quadrant of the selected digital image and substantially perpendicular to an edge of the field of view of the digital image.","In an embodiment, the overlap-analysis circuit  includes an overlap-analysis circuit configured to generate data indicative of a possible non-imaged portion of the region of interest adjacent to the selected digital image and indicative of a spatial relationship between the possible non-imaged portion of the region of interest and a human-perceivable feature included in the border region segment of the selected digital image. The determined spatial relationship indicated by a line anchored by a feature, site, center, or quadrant of the selected digital image.","In an embodiment, the reporting circuit  includes a reporting circuit configured to output informational data indicative of a possible non-imaged portion of the region of interest adjacent to the selected digital image of the surface. For example, the informational data may include an identification number assigned to the selected digital image, or location information associated with the selected digital image. In an embodiment, the reporting circuit includes a reporting circuit configured to output informational data indicative of a possible non-imaged portion of the region of interest of the surface. The informational data is responsive to (i) an absence of a determined substantial correspondence between the extracted perceivable feature included in the border region segment of the selected digital image and a first extracted perceivable feature included in a first digital image of the plurality of digital images other than the selected digital image, and to (ii) an absence of a determined substantial correspondence between the extracted perceivable feature included in the border region segment of the selected digital image and a second extracted perceivable feature included in a second digital image of the plurality of digital images other than the selected digital image.","In an embodiment, the system  includes computer-readable media  configured to maintain the informational data. In an embodiment, the computer-readable media may be managed by a computer storage device . In an embodiment, the computer-readable media may include a computer-readable media configured to maintain and to provide access to the informational data. In an embodiment, the computer-readable media may include a tangible computer-readable media. In an embodiment, the computer-readable media may include a communications media. In an embodiment, the system includes a communication device configured to provide a notification at least partially based on the informational data to at least one of a human, computer, or system. For example, the communications device may be incorporated into the system, as illustrated by the communication device . In another example, the communication device may be a third-party device in communication with the system as illustrated by the computing device  having the screen . In an embodiment, the communication device is configured to display a human-perceivable depiction of the informational data. In an embodiment, the communication device is configured to output a signal usable in displaying a human-perceivable depiction of the informational data. For example, the human-perceivable depiction may include a visual or an audio human-perceivable depiction of the informational data.","In an embodiment, the system  includes a processor . In an embodiment, the processor may be at least substantially similar to the processing unit  described in conjunction with . In an embodiment, the processor may be at least substantially similar to the processor  described in conjunction with .",{"@attributes":{"id":"p-0102","num":"0101"},"figref":"FIG. 3","b":["200","228","232","236"]},{"@attributes":{"id":"p-0103","num":"0102"},"figref":["FIG. 7","FIG. 3","FIG. 3","FIG. 3","FIG. 3"],"b":["300","330","224","340","228","350","232","370","236"]},{"@attributes":{"id":"p-0104","num":"0103"},"figref":["FIG. 8","FIG. 7"],"b":["300","310","320","380","310","320","320","322","324","322","324","380","382","384","386","388","382","382","330","340","350","384","386","388"]},{"@attributes":{"id":"p-0105","num":"0104"},"figref":["FIG. 9","FIG. 7"],"b":["300","360","360","364","364","370","372","374","376","378","372","374","376","378"]},{"@attributes":{"id":"p-0106","num":"0105"},"figref":["FIG. 7","FIG. 3","FIG. 3","FIG. 3"],"b":["300","340","228","350","232","370","236"]},{"@attributes":{"id":"p-0107","num":"0106"},"figref":"FIG. 10","b":["400","410","420"]},"In an alternative embodiment, the process (d) outputting informational data includes  transforming the informational data into a particular visual depiction of a possible non-imaged portion of the region of interest of the surface, and outputting the transformed informational data. In an embodiment, the process may include  (e) providing a notification at least partially based on the informational data to at least one of a human, computer, or system. In an embodiment, the computer-readable media includes a tangible computer-readable media . In an embodiment, the computer-readable media includes a communications media .",{"@attributes":{"id":"p-0109","num":"0108"},"figref":"FIG. 11","b":["500","510","520","530","540"]},"In an alternative embodiment, the system may include means  for detecting a border region segment of the selected digital image. In an alternative embodiment, the system may include means  for generating data indicative of a border region-overlap status of the selected digital image. The data is generated at least partially in response to the determined substantial correspondence between the extracted perceivable feature included in the border region segment of the selected digital image and the extracted at least one respective perceivable feature included in the each digital image of the plurality of digital images other than the selected digital image. In an alternative embodiment, the system may include means  for displaying the informational data.",{"@attributes":{"id":"p-0111","num":"0110"},"figref":"FIG. 12","b":["600","201","205","210","620","292","294","296"]},"The system  includes a feature-detection circuit  configured to extract at least one respective perceivable feature included in each digital image of a plurality of digital images . The each digital image of the plurality of digital images includes a respective portion of the region of interest  of the surface . The system includes a feature-matching circuit  configured to determine a substantial correspondence between (x) an extracted perceivable feature included in a border region segment of a selected digital image of the plurality of digital images and (y) an extracted at least one respective perceivable feature included in each digital image of the plurality of digital images other than the selected digital image. The system includes a data collection circuit  configured to gather the determined substantial correspondences for the extracted perceivable feature included in the border region segment of the selected digital image. The system includes an overlap-analysis circuit  configured to generate data indicative of a border region-overlap status of the selected digital image. The data is generated at least partially in response to the gathered determined substantial correspondences. The system includes a list management circuit  configured to add the data indicative of the determined border region-overlap status for the border region segment of the selected digital image to an omitted-coverage list. For example, in an embodiment, the determined border region-overlap status may include \u201clikely not overlapped,\u201d or \u201clikely overlapped.\u201d","The system  includes  an iteration control circuit configured to iteratively designate a next digital image from the plurality of digital images as the selected digital image until each digital image of the plurality of digital images has been designated. The iteration control circuit is also configured to initiate a processing of each of the iteratively designated next digital images by the feature-matching circuit , the data collection circuit , the overlap-analysis circuit , and the list management circuit . In an alternative embodiment, the iteration circuit is also configured to initiate a processing of each of the iteratively designated next digital images by a border region detection circuit . The system includes a coverage-analysis circuit  configured to identify a particular portion of the region of interest of a surface as likely not included in the plurality of digital images (hereafter \u201cpossible non-imaged portion of the region of interest\u201d). The identification of the possible non-imaged portion of the region of interest is at least partially based on the omitted-coverage list. In an embodiment, the coverage-analysis circuit is configured to at least one of determine, classify, find, or locate a possible non-imaged portion of the region of interest. The system includes a reporting circuit  configured to output informational data indicative of the possible non-imaged portion of the region of interest. In an embodiment, the informational data includes an indication that the possible non-imaged portion of the region of interest may be adjacent to a particular digital image of the plurality of digital images.","In an alternative embodiment, the system  includes an image receiver circuit  configured to receive a plurality of digital images. In an alternative embodiment, the system includes a border region detection circuit  configured to detect a border region segment of a digital image of the plurality of digital images. In an alternative embodiment, the feature matching circuit  includes a feature-matching circuit configured to determine a substantial correspondence between (x) an extracted perceivable feature included in a detected border region segment of a selected digital image of the plurality of digital images and (y) an extracted at least one respective perceivable feature included in each digital image of the plurality of digital images other than the selected digital image.","In an alternative embodiment, the data collection circuit  includes a data collection circuit configured to gather and assemble the determined substantial correspondences for the extracted perceivable feature included in the border region segment of the selected digital image. In an alternative embodiment, the data collection circuit includes a data collection circuit configured to gather the determined substantial correspondences for a respective perceivable feature included in each respective border region segment of the selected digital image.","In an alternative embodiment, the coverage-analysis circuit  includes a coverage-analysis circuit configured to identify a particular portion of the region of interest of a surface as likely not included in the plurality of digital images (hereafter \u201cpossible non-imaged portion of the region of interest\u201d) and to identify at least one digital image of the plurality of digital images (hereafter \u201csignpost digital image\u201d) as spatially proximate to the possible non-imaged portion of the region of interest. The identification of the possible non-imaged portion of the region of interest and the identification of the signpost digital image is at least partially based on the omitted-coverage list. With reference to the example of  described above, the coverage-analysis circuit may identify for example at least one of images ., ., ., and . as the signpost digital image spatially proximate to the possible non-imaged portion of the region of interest . In an alternative embodiment, for example, if the digital image . included a readily perceivable feature such as a mole, the coverage-analysis circuit may identify the digital image . as the signpost digital image adjacent to the possible non-imaged portion of the region of interest  even though the digital image . is not immediately adjacent. Continuing with , in an alternative embodiment, reporting circuit  includes a reporting circuit configured to output informational data indicative of the possible non-imaged portion of the region of interest adjacent to the selected digital image and of the signpost digital image.","In an alternative embodiment, the coverage-analysis circuit  includes a coverage-analysis circuit configured to identify a particular portion of the region of interest of a surface as likely not included in the plurality of digital images (hereafter \u201cpossible non-imaged portion of the region of interest\u201d). The identification of the possible non-imaged portion of the region of interest is at least partially based on application of a filter or a template to the omitted-coverage list. For example, the filter may include a threshold requirement that a certain minimum number of adjacent border region segments of the selected digital image have a \u201clikely not overlapped\u201d determined border region-overlap status before identification of a particular portion of the region of interest of a surface as likely not included in the plurality of digital images.",{"@attributes":{"id":"p-0118","num":"0117"},"figref":["FIG. 13","FIG. 6","FIG. 13","FIG. 13","FIG. 12"],"b":["648","210","648","218","202","201","210","3","210","5","210","6","210","7","652","210","3","210","5","210","6","210","7","652","218","219","210","1","210","2","210","4","654","210","1","210","2","210","4","654","219","636"]},{"@attributes":{"id":"p-0119","num":"0118"},"figref":"FIG. 13","b":["648","202","201","210","218","219","218","219"]},"In this embodiment, the coverage-analysis circuit  is also configured (iii) if the identified \u201ctentative non-imaged portion\u201d likely does not include an outer periphery of the region of interest  included in the plurality of digital images , to classify the \u201ctentative non-imaged portion\u201d as a \u201cpossible non-imaged portion of the region of interest.\u201d Continuing with the above example, since the first \u201ctentative non-imaged portion,\u201d illustrated by the first possible non-imaged portion , would be determined as likely does not include an outer periphery of the region of interest included in the plurality of digital images, the coverage-analysis circuit will classify it as a \u201cpossible non-imaged portion of the region of interest.\u201d The reporting circuit  will output informational data indicative of the possible non-imaged portion  of the region of interest. Continuing with the above example, since the second \u201ctentative non-imaged portion,\u201d illustrated by the second possible non-imaged portion , would be determined as likely does include an outer periphery of the region of interest included in the plurality of digital images, the coverage-analysis circuit will not classify it as a \u201cpossible non-imaged portion of the region of interest.\u201d As a result, the reporting circuit will not output informational data indicative of the possible non-imaged portion of the region of interest . An advantage of this embodiment is that the reporting circuit will not output informational data indicative of \u201cpossible non-imaged portions of the region of interest\u201d lying on the outer periphery of the plurality of digital images. Since the plurality of digital images only describe a part of the surface , these unbounded regions may be beyond the desired region of interest of the surface and are in effect winnowed out of the reporting.","Continuing with reference to , in an embodiment, the reporting circuit  includes a reporting circuit configured to output a rendering of the informational data in a form facilitating a human-perceivable representation of the informational data. For example, the reporting circuit may be configured to output a rendering of the informational data optimized in a form facilitating a human-perceivable representation of the informational data on a portable display, such as a display device associated with the communication device , or the screen  associated with the computing device . For example, the reporting circuit may be configured to output the informational data in a format facilitating a human-viewable representation of the informational data.","In an embodiment, the feature-detection  circuit includes a feature-detection circuit configured to extract at least one surface feature included in a digital image of the plurality of digital images . In an embodiment, the feature-detection circuit includes a feature-detection circuit configured to extract at least one surface feature included in a border region segment of a digital image of the plurality of digital images. See the border region segment . of  for an example of a surface feature included in a border region segment. In an embodiment, the feature-detection circuit includes a feature-detection circuit configured to extract at least one human-perceivable feature included in a digital image of the plurality of digital images. In an embodiment, the feature-detection circuit includes a feature-detection circuit configured to extract at least one human vision perceivable feature included in a digital image of the plurality of digital images. In an embodiment, the feature-detection circuit includes a feature-detection circuit configured to extract at least one feature included in a border region segment of a digital image of the plurality of digital images. In an embodiment, the feature-detection circuit includes a feature-detection circuit configured to extract at least one feature included in the field of view of a digital image of the plurality of digital images. In an embodiment, the feature-detection circuit includes a feature-detection circuit configured to detect and extract at least one feature included in a digital image of the plurality of digital images. In an embodiment, the feature-detection circuit includes a feature-detection circuit configured to detect and extract a human-perceivable feature included in a digital image of the plurality of digital images.","In an embodiment, the iteration control circuit  includes an iteration control circuit configured to iteratively designate a next digital image from the plurality of digital images  as the selected digital image (hereafter \u201citeratively designed selected digital image\u201d) until each digital image of the plurality of digital images has been designated. The iteration control circuit is configured to initiate a generation of data indicative of a border region-overlap status for each iteratively designated selected digital image. The iteration control circuit is configured to add the data indicative of a determined border region-overlap status for each iteratively designated selected digital image to the omitted-coverage list. In an embodiment, the system  further includes computer-readable media  configured to maintain the informational data.",{"@attributes":{"id":"p-0124","num":"0123"},"figref":"FIG. 12","b":["620","628","632","634","644","646","648","636"]},{"@attributes":{"id":"p-0125","num":"0124"},"figref":["FIG. 14","FIG. 12","FIG. 12","FIG. 12","FIG. 12","FIG. 12","FIG. 12","FIG. 12","FIG. 12","FIG. 12"],"b":["700","730","624","740","628","750","632","760","634","765","644","770","646","775","740","750","760","765","646","780","648","790","636"]},{"@attributes":{"id":"p-0126","num":"0125"},"figref":["FIG. 15","FIG. 14"],"b":["700","710","720"]},{"@attributes":{"id":"p-0127","num":"0126"},"figref":["FIG. 16","FIG. 14"],"b":["700","790","792","794","792","794","700","795","796","797","798","796","797","798"]},{"@attributes":{"id":"p-0128","num":"0127"},"figref":"FIG. 17","b":["800","810","820"]},"In an embodiment, the (i) outputting informational data includes  (i) transforming the informational data into a particular visual depiction of a possible non-imaged portion of the region of interest and outputting the transformed informational data. In an embodiment, the process further includes  (j) outputting informational data includes providing a notification at least partially based on the informational data to at least one of a human, computer, or system. In an embodiment, the computer-readable media  includes a tangible computer-readable media . In an embodiment, the computer-readable media includes a communications media .",{"@attributes":{"id":"p-0130","num":"0129"},"figref":"FIG. 18","b":["900","910","920","930","940","950","960","970","920","930","940","950","980","990"]},{"@attributes":{"id":"p-0131","num":"0130"},"figref":"FIG. 19","b":["1200","1201","1203","1205","1210","1220","292","294","296"]},"The system  includes a feature-detection circuit  configured to extract at least one respective human-perceivable feature included in each medical image of a plurality of medical images  of the surface of the skin  of an individual human  (hereafter \u201cmedical skin images\u201d). The each medical image of plurality of medical skin images includes a respective portion of a region of interest  of the surface of the skin of the individual human, and was acquired by the handheld digital image acquisition device . The system includes a feature-matching circuit  configured to determine a substantial correspondence between (x) an extracted human-perceivable feature included in a border region segment of a selected medical skin image of the plurality of medical skin images and (y) an extracted at least one respective human-perceivable feature included in the each medical skin image of the plurality of medical skin images other than the selected medical skin image. The system includes a data collection circuit  configured to gather the determined substantial correspondences for the human-perceivable feature included in the border region segment of the selected medical skin image. The system includes a reporting circuit  configured to output informational data indicative of a possible non-imaged portion of the region of interest of the skin of the individual human adjacent to the selected medical skin image. The informational data is responsive to an absence of a determined substantial correspondence between the extracted human-perceivable feature included in the border region segment of the selected medical skin image and the extracted at least one respective feature included in the each medical skin image of the plurality of medical skin images other than the selected medical skin image. In an embodiment, the system includes a processor . In an embodiment, the processor may be at least substantially similar to the processing unit  described in conjunction with . In an embodiment, the processor may be at least substantially similar to the processor  described in conjunction with .","For example, a \u201cmedical skin image\u201d may include a digital image of the skin of the individual human  selected or captured by a health care provider during a medical procedure or examination, or by the individual  during self-examination. The region of interest may have been selected for any reason, including a possible disease state, or cosmetic reasons. Alternatively, the region of interest may have been selected by a machine. For example, a \u201cmedical skin image\u201d may be of an exterior skin surface, or an interior skin surface, such as the interior skin surface of a colon or stomach. For example, a \u201cmedical skin image\u201d may include an image created using a technique or process for clinical purposes or medical science. For example, \u201ca medical skin image\u201d may include an image produced using a technique or process involving light in the visible, infrared, or ultraviolet spectrums. For example, a \u201cmedical skin image\u201d may include an image that was acquired using at least two wavelength energies and rendered visible to the human eye using an enhancement or augmentation technique. For example, the wavelength energies may include visible light, near infrared, infrared, or ultrasound.","For example, a perceivable feature may include a human-vision perceivable feature. For example, a human-vision perceivable feature may include a feature that is visible to the naked eye or using natural human vision, including corrective lenses. In an embodiment, a perceivable feature may include an augmented human-vision perceivable feature, such as a feature visible to the naked eye as a result of computer implemented enhancement, or computer augmented vision.","In an embodiment, the system  includes an image receiver circuit  configured to receive the plurality of medical skin images . In an embodiment, the image receiver circuit includes an image receiver circuit configured to retrieve the plurality of medical skin images acquired by the handheld digital image acquisition device  from a memory and\/or storage device of a handheld digital image acquisition device. For example, the image receiver circuit may be configured to pull the plurality of medical skin images from a memory and\/or storage device of the handheld digital image acquisition device. In an embodiment, the image receiver circuit includes an image receiver circuit configured to import from third-party device the plurality of medical skin images acquired by the handheld digital image acquisition device. In an embodiment, the image receiver circuit includes an image receiver circuit configured to receive a push of the plurality of medical skin images from the handheld digital image acquisition device. In an embodiment, the plurality of medical skin images were acquired during an imaging session by the handheld digital image acquisition device. For example, an imaging session may be a single session, or a combination of multiple sessions.","In an embodiment, the handheld digital image acquisition device  includes a handheld digital imaging device configured to capture the plurality of medical skin images. In an embodiment, the handheld digital image acquisition device includes a handheld digital image acquisition device held by the individual human. In an embodiment, the handheld digital image acquisition device includes a handheld digital image acquisition device held and operated by a third-party human, illustrated as the human .","In an embodiment, the reporting circuit  includes a reporting circuit configured to output the informational data in substantially real-time. In an embodiment, the reporting circuit includes a reporting circuit configured in cooperation with the feature-detection circuit , the feature matching circuit , and the data collection circuit  to output the informational data in substantially real-time. In an embodiment, substantially real-time includes while the handheld digital image acquisition device is in motion acquiring the plurality of medical skin images. For example, in this embodiment, the system  outputs the informational data while additional medical skin images are being acquired. Substantially real-time informational data is anticipated to timely inform the user of the handheld digital image acquisition device during an image acquisition session of a possible non-imaged portion of the region of interest of the skin, and allow the user to position the handheld digital image acquisition device and acquire a medical skin image of the possible non-imaged portion before terminating the image acquisition session. In an embodiment, substantially real-time includes less than approximately 30 minutes after the plurality of medical skin images are received by the system. In an embodiment, substantially real-time includes less than approximately 15 minutes after the plurality of medical skin images are received by the system. In an embodiment, substantially real-time includes less than approximately 6 minutes after the plurality of medical skin images are received by the system. In an embodiment, substantially real-time includes less than approximately 2 minutes after the plurality of medical skin images are received by the system. In an embodiment, substantially real-time includes less than approximately 1 minute after the plurality of medical skin images are received by the system. In an embodiment, substantially real-time includes less than approximately 30 seconds after the plurality of medical skin images are received by the system.","In an embodiment, the system  includes a border region detection circuit  configured to detect a border region segment of a medical skin image of the plurality of medical skin images. In an embodiment, the feature matching circuit  includes a feature-matching circuit configured to determine a substantial correspondence between (x) an extracted human-perceivable feature included in a detected border region segment of a selected medical skin image of the plurality of medical skin images and (y) an extracted at least one respective human-perceivable feature included in the each medical skin image of the plurality of medical skin images other than the selected medical skin image.",{"@attributes":{"id":"p-0139","num":"0138"},"figref":"FIG. 20","b":"1205"},"The handheld digital image acquisition device  includes a computing device (not shown), such as for example, the thin computing device  described in conjunction with FIG. , that is operable to interact with functional elements of the handheld digital image acquisition device. The handheld digital image acquisition device also includes a plurality of user interfaces . The plurality of interfaces  includes a display . In alternative embodiments, the display may provide a textual, a visual display, and\/or a graphical display. In a further embodiment, the display may include touch screen functionality operable to accept a user input. The plurality of user interfaces of the camera also includes a microphone , a speaker , and a plurality of tangible or virtual buttons A-E. One or more of the tangible or virtual buttons may include a light emitter, such as a light emitting device A. Further, one or more of the tangible or virtual buttons A-E may include a vibrator operable to provide a tactile display. The display  and the tangible or virtual buttons A-E may have any functionality appropriate to the handheld digital image acquisition device. For example, the button E may be assigned to operate a camera element, such as a shutter function. The button A may be assigned an \u201center\u201d function, and buttons B and C may be respectively assigned a scroll up and scroll down function relative to a menu displayed on the display . The button D may be assigned to operate another camera element, such as a lens zoom function. The handheld digital image acquisition device also includes context sensors , which may be selected, for example, to produce relevant information about an environment extrinsic to the handheld digital image acquisition device. The context sensors are illustrated as an external temperature sensor  and a light intensity sensor . The handheld digital image acquisition device further includes a USB port , a network port , and\/or a wireless port (not shown).","In addition, the handheld digital image acquisition device  includes a lens (not shown) and an image acquisition module (not shown). The image acquisition module controls the lens, a shutter, an aperture, and\/or other elements as necessary to capture an image through the lens. In an embodiment, capturing images using a handheld digital image acquisition device may be equated with photography as performed by conventional digital cameras. A captured image may be processed, stored, viewed, and\/or distributed by the handheld digital image acquisition device. The handheld digital image acquisition device also includes a system memory (not shown), such as the system memory  of the thin computing device  of . The system memory includes saved operating systems and programs necessary to operate the handheld digital image acquisition device. In addition, the handheld digital image acquisition device may include a computer readable media (not shown). The handheld digital image acquisition device may be configured to capture still images, to capture streaming images, or to capture both still and streaming images.","The handheld digital image acquisition device  includes operability to receive a user input through an interface of the plurality of interfaces . For example, in an embodiment, detecting a user touch to the button D may be received as an instruction and\/or a selection. Another detected user touch to another user interface of the plurality of user interfaces  may be received as another instruction and\/or a selection. The user touch may be detected by a user interface physically incorporated in the handheld digital image acquisition device . In an alternative embodiment, a user input may be received by detecting a signal responsive to a sound or voice received by the microphone . For example, a detection and recognition of a signal responsive to a spoken command to the microphone  may be received as an instruction to activate a program associated with the handheld digital image acquisition device. Further, a detection of a signal responsive to a sound or voice may be received by the microphone .","Returning to , in an embodiment, the system  includes an overlap-analysis circuit  configured to generate data indicative of a border region-overlap status of the selected medical skin image. The data is generated at least partially in response to the gathered determined substantial correspondences between the extracted perceivable feature included in the border region segment of the selected medical skin image and the at least one respective perceivable feature included in the each medical skin image of the plurality of medical skin images other than the selected medical skin image. In an embodiment, the reporting circuit includes a reporting circuit configured to output informational data indicative of the border region-overlap status of the selected medical skin image. The informational data is at least partially based on the data indicative of a border region-overlap status of the selected medical skin image.","In an embodiment, the system  is a standalone system, and not physically incorporated within the handheld digital image acquisition device . In an embodiment, the standalone system is configured to wirelessly communicate with the handheld digital image acquisition device. In an embodiment, the system  is physically incorporated within the handheld digital image acquisition device , for example within the embodiment of the handheld digital image acquisition device  as illustrated in .","In an embodiment, the system  includes computer-readable media  configured to maintain the informational data indicative of the possible non-imaged portion of the region of interest adjacent to the selected medical skin image. In an embodiment, the system includes a communication device configured to provide a notification at least partially based on the informational data to at least one of a human, computer, or system. For example, the communications device may be incorporated into the system as illustrated by the communication device . In another example, the communication device may be a third-party device in communication with the system as illustrated by the computing device  having the screen . In an embodiment, the system includes a communication device configured to display a human-perceivable depiction of the informational data. In an embodiment, the system includes a communication device configured to output a signal usable in displaying a human-perceivable depiction of the informational data. For example, the human-perceivable depiction may include an audio depiction of the informational data or a visual depiction of the informational data.",{"@attributes":{"id":"p-0146","num":"0145"},"figref":["FIG. 21","FIG. 19","FIG. 19","FIG. 19","FIG. 19"],"b":["1500","1530","1224","1540","1228","1550","1232","1560","1236"]},{"@attributes":{"id":"p-0147","num":"0146"},"figref":["FIG. 22","FIG. 21"],"b":["1500","1510","1520","1575","1575","1575","1530","1540","1550","1580","1582","1584","1586","1582","1584","1586"]},{"@attributes":{"id":"p-0148","num":"0147"},"figref":["FIG. 23","FIG. 21"],"b":["1500","1570","1570","1570","1572","1572"]},"In an embodiment, the reporting operation  may include at least one additional operation. The at least one additional operation may include an operation , an operation , an operation , an operation , or an operation . The operation  includes outputting informational data in substantially real time. The informational data is indicative of a possible non-imaged portion of the region of interest of the skin of the individual human adjacent to the selected medical skin image. The operation  includes outputting informational data is indicative of a possible non-imaged portion of the region of interest of the skin of the individual human adjacent to the selected medical skin image. The informational data is at least partially based on the data indicative of a border region-overlap status of the selected medical skin image. The operation  includes outputting informational data indicative of a possible non-imaged portion of the region of interest adjacent to the selected medical skin image. The informational data is at least partially based on the data indicative of a possible non-imaged portion of the region of interest adjacent to the selected medical skin image. The operation  includes outputting informational data usable in displaying a human-perceivable indication of a possible non-imaged portion of the region of interest of the surface. The operation  includes transforming the informational data into a particular visual depiction of a possible non-imaged portion of the region of interest of the surface, and outputting the transformed informational data. For example, the particular visual depiction may include a depiction of a location of the possible non-imaged portion of the region of interest or a bearing of the possible non-imaged portion of the region of interest relative to a determinable location.",{"@attributes":{"id":"p-0150","num":"0149"},"figref":["FIG. 24","FIG. 21"],"b":["1500","1590","1590","1591","1593","1596","1598","1591","1560","1593","1596","1598"]},"In an embodiment, the operation  may include at least one additional operation, such as an operation . The operation  includes determining a substantial correspondence between (x) an extracted human-perceivable feature included in a border region segment of the follow-on medical skin image and (y) an extracted at least one respective human-perceivable feature included in the each medical skin image of the plurality of medical skin images.",{"@attributes":{"id":"p-0152","num":"0151"},"figref":"FIG. 25","b":["1600","1610","1620"]},"In an embodiment, the computer-readable media includes a tangible computer-readable media . In an embodiment, the computer-readable media includes a communications media .",{"@attributes":{"id":"p-0154","num":"0153"},"figref":["FIG. 26","FIG. 24"],"b":["1600","1622","1624","1626","1628"]},{"@attributes":{"id":"p-0155","num":"0154"},"figref":"FIG. 27","b":["1700","1710","1720","1730","1740"]},{"@attributes":{"id":"p-0156","num":"0155"},"figref":"FIG. 28","b":["1800","1201","1205","1210","1820","292","294","296"]},"The system  includes a feature-detection circuit  configured to extract at least one respective human-perceivable feature included in each medical image of a plurality of medical images  of the surface of the skin  of an individual human  (hereafter \u201cmedical skin images\u201d). The each medical image of plurality of medical skin images includes a respective portion of the region of interest  of a surface of the skin of the individual human, and was acquired by the handheld digital image acquisition device . The system includes a feature matching circuit  configured to determine a substantial correspondence between (x) an extracted human-perceivable feature included in a border region segment of a selected medical skin image of the plurality of medical skin images and (y) an extracted at least one respective human-perceivable feature included in the each medical skin image of the plurality of medical skin images other than the selected medical skin image. The system includes a data collection circuit  configured to gather the determined substantial correspondences for the extracted human-perceivable feature included in the border region segment of the selected medical skin image.","The system  includes an overlap-analysis circuit  configured to generate data indicative of a border region-overlap status of the selected medical skin image. The data is generated at least partially in response to the determined substantial correspondences. The system includes a list management circuit  configured to add the data indicative of the determined border region-overlap status for the border region segment of the selected medical skin image to an omitted-coverage list. The system includes an iteration control circuit  configured to iteratively designate a next medical skin image from the plurality of medical skin images as the selected medical skin image until each medical skin image of the plurality of medical skin images has been designated. The iteration control circuit is also configured to initiate a processing of each of the iteratively designated next medical skin images by the feature-matching circuit , the data collection circuit , the overlap-analysis circuit , and the list management circuit . The system includes a coverage-analysis circuit  configured to identify a particular portion of the skin surface as likely not included in the plurality of medical skin images (hereafter \u201cpossible non-imaged portion of the region of interest\u201d). The identification of the possible non-imaged portion of the region of interest  is at least partially based on the omitted-coverage list. The system includes a reporting circuit  configured to output user-assistance information at least partially based on the identified possible non-imaged portion of the skin.","In an embodiment, the system  includes an image receiver circuit  configured to receive the plurality of medical skin images . In an embodiment, the system includes a border region detection circuit  configured to detect a border region segment of a medical skin image of the plurality of medical skin images.","In an embodiment, the coverage-analysis circuit  includes a coverage-analysis circuit configured to identify a particular portion of the surface of the skin  as likely not included in the plurality of medical skin images  (hereafter \u201cpossible non-imaged portion of the skin\u201d) and to identify at least one medical skin image of the plurality of medical skin images as spatially proximate to the possible non-imaged portion of the region of interest  (hereafter \u201csignpost medical skin image\u201d). The identification of the possible non-imaged portion of the skin and the identification of the signpost medical skin image is at least partially based on the omitted-coverage list. In an embodiment, the reporting circuit  includes a reporting circuit configured to output user-assistance information indicative of the possible non-imaged portion of the region of interest adjacent to the selected medical skin image and indicative of the signpost medical skin image.","In an embodiment, the coverage-analysis circuit  includes a coverage-analysis circuit configured to identify a particular portion of the region of interest  as likely not included in the plurality of medical skin images  (hereafter \u201cpossible non-imaged portion of the region of interest\u201d). The identification of the possible non-imaged portion of the region of interest at least partially based on the omitted-coverage list. The coverage-analysis circuit is configured to identify at least three medical skin images of the plurality of medical skin images immediately adjacent to the possible non-imaged portion of the region of interest. The identification of the at least three medical skin images is at least partially based on the omitted-coverage list. The coverage analysis circuit is configured to define a substantially simple closed curve. The coverage-analysis circuit is configured to determine whether the possible non-imaged portion of the region of interest lies inside or outside of the region of interest, The determination is at least partially based on the positions of the identified at least three medical skin images relative to the closed curve. For example, see description in conjunction with . Continuing with reference to , in an embodiment, the reporting circuit  includes a reporting circuit configured to output user-assistance information indicative of the identified possible non-imaged portion of the region of interest and indicative of the determination whether the possible non-imaged portion of the region of interest lies inside or outside of the region of interest.","In an embodiment of the system , the user-assistance information includes a user-assistance corresponding to a location of the possible non-imaged portion of the region of interest . In an embodiment of the system, the user-assistance information includes user-assistance information corresponding to spatially orientating the handheld digital image acquisition device  in an alignment to acquire a medical skin image of the possible non-imaged portion of the region of interest. In an embodiment of the system, the user-assistance information includes user-assistance information corresponding to selecting a parameter facilitating an acquisition of a medical skin image of the possible non-imaged portion of the region of interest. For example, the parameter may include a magnification, orientation, alignment, or lighting facilitating an acquisition of a medical skin image. In an embodiment of the system, the user-assistance information includes user-assistance corresponding to initiating an acquisition by a user-held digital image acquisition device of a medical skin image. In an embodiment, the user-assistance information includes user instructions corresponding to operating the user-held digital image acquisition device in acquiring a medical skin image. In an embodiment, the user-assistance information includes user-assistance responsive to a request entered by the user in conjunction with acquiring a medical skin image of the possible non-imaged portion of the region of interest. For example, the request entered by the user may be based upon a menu of available user-assistances.","In an embodiment, the system  includes computer-readable media  configured to maintain the user-assistance information corresponding to the identified possible non-imaged portion of the region of interest  and to the signpost medical skin image.","In an embodiment, the reporting circuit  includes a reporting circuit configured to output user-assistance information in substantially real-time. The user-assistance information is at least partially based on the identified possible non-imaged portion of the surface of the skin . In an embodiment, the reporting circuit includes a reporting circuit configured to output user-assistance information usable in displaying a human-perceivable indication of the possible non-imaged portion of the region of interest of the surface. In an embodiment, the reporting circuit includes a reporting circuit configured to output a rendering of the user-assistance information in a form facilitating a human-perceivable representation of the user-assistance information. For example, the rendering may include a pre-rendered user-assistance information. For example, the rendering may include an optimized representation of the user-assistance information. For example, the rendering may include a rendering of the user-assistance information structured in a format facilitating a human-perceivable representation of the user-assistance information. For example, the rendering may include a rendering of the user-assistance information in a form facilitating a human-vision perceivable representation or an augmented human-vision perceivable representation of the user-assistance information.","In an embodiment, the system  includes the computer-readable media  configured to maintain the user-assistance information corresponding to the identified possible non-imaged portion of the region of interest  and to the signpost medical skin image. In an embodiment, the system includes a communications device configured to display a particular human-perceivable depiction of the user-assistance information. For example, the communication device may include the communications device . For example, the communications device may include a display of the handheld digital image acquisition device . For example, the communication device may be a third-party device in communication with the system as illustrated by the computing device  having the screen . For example, the human-perceivable depiction may include a visual or an audio human-perceivable depiction of the user-assistance information. In an embodiment, the system includes a processor . In an embodiment, the processor may be at least substantially similar to the processing unit  described in conjunction with . In an embodiment, the processor may be at least substantially similar to the processor  described in conjunction with .",{"@attributes":{"id":"p-0166","num":"0165"},"figref":["FIG. 29","FIG. 28","FIG. 28","FIG. 28"],"b":["1900","1930","1824","1940","1828","1950","1832"]},"An overlap-analysis operation  includes generating data indicative of a border region-overlap status of the selected medical skin image. The data is generated at least partially in response to the determined substantial correspondences. In an embodiment, the overlap-analysis operation may be implemented using the overlap-analysis circuit  described in conjunction with . A list management operation  includes adding the data indicative of the determined border region-overlap status for the border region segment of the selected medical skin image to an omitted-coverage list. In an embodiment, the list management operation may be implemented using the list management circuit  described in conjunction with . A next-image selection operation  includes iteratively designating a next medical skin image from the plurality of medical skin images as the selected medical skin image until each medical skin image of the plurality of medical skin images has been designated. In an embodiment, the next-image selection operation may be implemented using the iteration control circuit  described in conjunction with . An iteration operation  includes processing of each of the iteratively designated next medical skin images by operations , , , and . In an embodiment, the iteration operation may also be implemented using the iteration control circuit  described in conjunction with .","A coverage-analysis operation  includes identifying a particular portion of the skin surface as likely not included in the plurality of medical skin images (hereafter \u201cpossible non-imaged portion of the skin\u201d). The identifying the possible non-imaged portion of the skin is at least partially based on the omitted-coverage list. In an embodiment, the coverage-analysis operation may be implemented using the coverage-analysis circuit  described in conjunction with . A reporting operation  includes outputting user-assistance information at least partially based on the identified possible non-imaged portion of the skin. In an embodiment, the reporting operation may be implemented using the reporting circuit  described in conjunction with . The operational flow includes an end operation.",{"@attributes":{"id":"p-0169","num":"0168"},"figref":["FIG. 30","FIG. 29","FIG. 28"],"b":["1900","1910","1910","1920","1920","1985","1986","1987","1988","1986","1987","1988","1990","1990","239"]},{"@attributes":{"id":"p-0170","num":"0169"},"figref":"FIG. 31","b":["2000","2010","2020"]},"In an embodiment, the computer-readable media  includes tangible computer-readable media . In an embodiment, the computer-readable media includes communications media .",{"@attributes":{"id":"p-0172","num":"0171"},"figref":["FIG. 32","FIG. 31"],"b":["2000","2022","2024","2026","2028","2029"]},{"@attributes":{"id":"p-0173","num":"0172"},"figref":"FIG. 33","b":["2100","2110","2120","2130","2140","2150","2160","2170","2120","2130","2140","2150","2180","2190"]},"In an alternative embodiment, the means  includes means  for outputting user-assistance information in substantially real-time and at least partially based on the identified possible non-imaged portion of the skin.","All references cited herein are hereby incorporated by reference in their entirety or to the extent their subject matter is not otherwise inconsistent herewith.","In some embodiments, \u201cconfigured\u201d includes at least one of designed, set up, shaped, implemented, constructed, or adapted for at least one of a particular purpose, application, or function.","It will be understood that, in general, terms used herein, and especially in the appended claims, are generally intended as \u201copen\u201d terms. For example, the term \u201cincluding\u201d should be interpreted as \u201cincluding but not limited to.\u201d For example, the term \u201chaving\u201d should be interpreted as \u201chaving at least.\u201d For example, the term \u201chas\u201d should be interpreted as \u201chaving at least.\u201d For example, the term \u201cincludes\u201d should be interpreted as \u201cincludes but is not limited to,\u201d etc. It will be further understood that if a specific number of an introduced claim recitation is intended, such an intent will be explicitly recited in the claim, and in the absence of such recitation no such intent is present. For example, as an aid to understanding, the following appended claims may contain usage of introductory phrases such as \u201cat least one\u201d or \u201cone or more\u201d to introduce claim recitations. However, the use of such phrases should not be construed to imply that the introduction of a claim recitation by the indefinite articles \u201ca\u201d or \u201can\u201d limits any particular claim containing such introduced claim recitation to inventions containing only one such recitation, even when the same claim includes the introductory phrases \u201cone or more\u201d or \u201cat least one\u201d and indefinite articles such as \u201ca\u201d or \u201can\u201d (e.g., \u201ca receiver\u201d should typically be interpreted to mean \u201cat least one receiver\u201d); the same holds true for the use of definite articles used to introduce claim recitations. In addition, even if a specific number of an introduced claim recitation is explicitly recited, it will be recognized that such recitation should typically be interpreted to mean at least the recited number (e.g., the bare recitation of \u201cat least two chambers,\u201d or \u201ca plurality of chambers,\u201d without other modifiers, typically means at least two chambers).","In those instances where a phrase such as \u201cat least one of A, B, and C,\u201d \u201cat least one of A, B, or C,\u201d or \u201can [item] selected from the group consisting of A, B, and C,\u201d is used, in general such a construction is intended to be disjunctive (e.g., any of these phrases would include but not be limited to systems that have A alone, B alone, C alone, A and B together, A and C together, B and C together, or A, B, and C together, and may further include more than one of A, B, or C, such as A, A, and C together, A, B, B, C, and Ctogether, or Band Btogether). It will be further understood that virtually any disjunctive word or phrase presenting two or more alternative terms, whether in the description, claims, or drawings, should be understood to contemplate the possibilities of including one of the terms, either of the terms, or both terms. For example, the phrase \u201cA or B\u201d will be understood to include the possibilities of \u201cA\u201d or \u201cB\u201d or \u201cA and B.\u201d","The herein described aspects depict different components contained within, or connected with, different other components. It is to be understood that such depicted architectures are merely examples, and that in fact many other architectures can be implemented which achieve the same functionality. In a conceptual sense, any arrangement of components to achieve the same functionality is effectively \u201cassociated\u201d such that the desired functionality is achieved. Hence, any two components herein combined to achieve a particular functionality can be seen as \u201cassociated with\u201d each other such that the desired functionality is achieved, irrespective of architectures or intermedial components. Likewise, any two components so associated can also be viewed as being \u201coperably connected,\u201d or \u201coperably coupled,\u201d to each other to achieve the desired functionality. Any two components capable of being so associated can also be viewed as being \u201coperably couplable\u201d to each other to achieve the desired functionality. Specific examples of operably couplable include but are not limited to physically mateable or physically interacting components or wirelessly interactable or wirelessly interacting components.","With respect to the appended claims the recited operations therein may generally be performed in any order. Also, although various operational flows are presented in a sequence(s), it should be understood that the various operations may be performed in other orders than those which are illustrated, or may be performed concurrently. Examples of such alternate orderings may include overlapping, interleaved, interrupted, reordered, incremental, preparatory, supplemental, simultaneous, reverse, or other variant orderings, unless context dictates otherwise. Use of \u201cStart,\u201d \u201cEnd,\u201d \u201cStop,\u201d or the like blocks in the block diagrams is not intended to indicate a limitation on the beginning or end of any operations or functions in the diagram. Such flowcharts or diagrams may be incorporated into other flowcharts or diagrams where additional functions are performed before or after the functions shown in the diagrams of this application. Furthermore, terms like \u201cresponsive to,\u201d \u201crelated to,\u201d or other past-tense adjectives are generally not intended to exclude such variants, unless context dictates otherwise.","While various aspects and embodiments have been disclosed herein, other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting, with the true scope and spirit being indicated by the following claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 9","FIG. 7"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":["FIG. 13","FIG. 6"]},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 15","FIG. 14"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":["FIG. 16","FIG. 14"]},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":["FIG. 22","FIG. 21"]},{"@attributes":{"id":"p-0042","num":"0041"},"figref":["FIG. 23","FIG. 21"]},{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIG. 24","FIG. 21"]},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 26","FIG. 25"]},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":["FIG. 30","FIG. 29"]},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 31"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":["FIG. 32","FIG. 31"]},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 33"}]},"DETDESC":[{},{}]}
