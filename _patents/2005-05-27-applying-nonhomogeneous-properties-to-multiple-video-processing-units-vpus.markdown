---
title: Applying non-homogeneous properties to multiple video processing units (VPUs)
abstract: A system and method for applying non-homogeneous properties to multiple video processing units (VPUs) in a multiple VPU system are described. Respective VPUs in the system cooperate to produce a frame to be displayed. In various embodiments, data output by different VPUs in the system is combined, or merged, or composited to produce a frame to be displayed. In load balancing modes, each VPU in the system performs different tasks as part of rendering a same frame, and therefore typically executes different commands. In various embodiments, efficiency of the system is enhanced by forming a single command buffer for execution by all of the VPUs in the system even though each VPU may have a different set of commands to execute in the command buffer.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08054314&OS=08054314&RS=08054314
owner: ATI Technologies, Inc.
number: 08054314
owner_city: Markham, Ontario
owner_country: CA
publication_date: 20050527
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE","TECHNICAL FIELD","BACKGROUND","INCORPORATION BY REFERENCE","DETAILED DESCRIPTION"],"p":["This application is related to the following United States patent applications:","Antialiasing Method and System, U.S. application Ser. No. 11\/140\/156, invented by Arcot J. Preetham, Andrew S. Pomianowski, and Raja Koduri, filed concurrently herewith;","Multiple Video Processing Unit (VPU) Memory Mapping, U.S. application Ser. No. 11\/139,917, invented by Philip J. Rogers, Jeffrey Gongxian Cheng, Dmitry Semiannokov, and Raja Koduri, filed concurrently herewith;","Frame Synchronization in Multiple Video Processing Unit (VPU) Systems, U.S. application Ser. No. 11\/140,114, invented by Raja Koduri, Timothy M. Kelley, and Dominik Behr, filed concurrently herewith;","Synchronizing Multiple Cards in Multiple Video Processing Unit (VPU) Systems, U.S. application Ser. No. 11\/139,741, invented by Syed Athar Hussain, James Hunkins, and Jacques Vallieres, filed concurrently herewith;","Compositing in Multiple Video Processing Unit (VPU) Systems, U.S. application Ser. No. 11\/140,165, invented by James Hunkins and Raja Koduri, filed concurrently herewith;","Dynamic Load Balancing in Multiple Video Processing Unit (VPU) Systems, U.S. application Ser. No. 11\/139,893, invented by Jonathan L. Campbell and Maurice Ribble, filed concurrently herewith; and","Computing Device with Flexibly Configurable Expansion Slots, and Method of Operation, U.S. application Ser. No. 11\/140,040, invented by Yaoqiang (George) Xie and Roumen Saltchev, filed May 27, 2005.","The invention is in the field of graphics and video processing.","Graphics and video processing hardware and software continue to become more capable, as well as more accessible, each year. Graphics and video processing circuitry is typically present on an add-on card in a computer system, but is also found on the motherboard itself. The graphics processor is responsible for creating the picture displayed by the monitor. In early text-based personal computers (PCs) this was a relatively simple task. However, the complexity of modern graphics-capable operating systems has dramatically increased the amount of information to be displayed. In fact, it is now impractical for the graphics processing to be handled by the main processor, or central processing unit (CPU) of a system. As a result, the display activity has typically been handed off to increasingly intelligent graphics cards which include specialized coprocessors referred to as graphics processing units (GPUs) or video processing units (VPUs).","In theory, very high quality complex video can be produced by computer systems with known methods. However, as in most computer systems, quality, speed and complexity are limited by cost. For example, cost increases when memory requirements and computational complexity increase. Some systems are created with much higher than normal cost limits, such as display systems for military flight simulators. These systems are often entire one-of-a-kind computer systems produced in very low numbers. However, producing high quality, complex video at acceptable speeds can quickly become prohibitively expensive for even \u201chigh-end\u201d consumer-level systems. It is therefore an ongoing challenge to create VPUs and VPU systems that are affordable for mass production, but have ever-improved overall quality and capability.","Another challenge is to create VPUs and VPU systems that can deliver affordable, higher quality video, do not require excessive memory, operate at expected speeds, and are seamlessly compatible with existing computer systems.","All publications and patent applications mentioned in this specification are herein incorporated by reference to the same extent as if each individual publication or patent application was specifically and individually indicated to be incorporated by reference.","An improved system and method for video processing is described herein. Embodiments include a video processing system with at least one graphics processing unit (GPU) or video processing unit (VPU). As used herein, GPU and VPU are interchangeable terms. In various embodiments, rendering tasks are shared among the VPUs in parallel to provide improved performance and capability with minimal increased cost. Respective VPUs in the system cooperate to produce a frame to be displayed. In various embodiments, data output by different VPUs in the system is combined, or merged, or composited to produce a frame to be displayed. In one embodiment, the system is programmable such that various modes of operation are selectable, including various compositing modes, and various modes of task sharing or load balancing between multiple VPUs. In load balancing modes, each VPU in the system performs different tasks as part of rendering a same frame, and therefore typically executes different commands. In various embodiments, efficiency of the system is enhanced by forming a single command buffer for execution by all of the VPUs in the system even though each VPU may have a different set of commands to execute in the command buffer. This avoids inefficiencies and overhead associated with forming and managing a separate command buffer for each VPU. For example, if it was necessary to build two command buffers for each VPU in the system according to traditional methods, the effective available command buffer space would be divided by the number of VPUs. Another disadvantage is that the command buffer usage would also be effectively multiplied by the same number. Embodiments also provide faster performance by reducing the amount of writing by the driver by a factor related to the number of VPUs. Another advantage of the embodiments described is that cache misses will usually be reduced. For example, it is not necessary to switch command buffer for each unique command, as would be the case if the driver were building different command buffers for each VPU. Rather, the driver works continually on one command buffer as if the system had only one VPU.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 1","b":["100","100","102","102","102","104","102"]},"The API  can be any one of the available APIs for running video applications. The API  communicates with a driver . The driver  is typically written by the manufacturer of the video hardware, and translates the standard code received from the API into a native format understood by the hardware. The driver allows input from, for example, an application, process, or user to direct settings. Such settings include settings for selecting modes of operation, including modes of operation for each of multiple VPUs, and modes of compositing frame data from each of multiple VPUs, as described herein. For example, a user can select settings via a user interface (UI), including a UI supplied to the user with video processing hardware and software as described herein.","In one embodiment, the video hardware includes two video processing units, VPU A  and VPU B . In other embodiments there can be less than two or more than two VPUs. In various embodiments, VPU A  and VPU B  are identical. In various other embodiments, VPU A  and VPU B  are not identical. The various embodiments, which include different configurations of a video processing system, will be described in greater detail below.","The driver  issues commands to VPU A  and VPU B . The commands issued to VPU A  and VPU B  at the same time are for processing the same frame to be displayed. VPU A  and VPU B  each execute a series of commands for processing the frame. The driver  programmably instructs VPU A  and VPU B  to render frame data according to a variety of modes. For example, the driver  programmably instructs VPU A  and VPU B  to render a particular portion of the frame data. Alternatively, the driver  programmably instructs each of VPU A  and VPU B  to render the same portion of the frame data.","When either of VPU A  and VPU B  finishes executing the commands for the frame, the frame data is sent to a compositor . The compositor  is optionally included in an interlink module , as described more fully below. VPU A  and VPU B  cooperate to produce a frame to be displayed. In various embodiments, the frame data from each of VPU A  and VPU B  is combined, or merged, or composited in the compositor  to generate a frame to be rendered to a display . As used herein, the terms combine, merge, composite, mix, or interlink all refer to the same capabilities of the IM  and\/or compositor  as described herein.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 2","b":["200","200","202","204","205","202","202","204","204"]},"The API  communicates with a driver . The driver  is written specifically for the system , and translates the standard code received from the API  into a native format understood by the VPU components, which will be explained more fully below.","In one embodiment, the system  further includes two VPUs, VPU A  and VPU B . The invention is not limited to two VPUs. Aspects of the invention as described herein would be workable with one VPU with modifications available to one of ordinary skill in the art. However, in most instances the system would be less efficient with one VPU than with more than one VPU. Various embodiments also include more than two VPUs. Systems with more than two are workable with modifications available to one of ordinary skill in the art, and in most instances would provide better efficiency than a system with two VPUs. In various embodiments VPU A  and VPU B  can be on one or more video cards that each includes a video processor and other associated hardware. As will be explained further below, the invention is not so limited. For example, more than one VPU can be resident on one card or board. However, as referred to herein a VPU is intended to include at least a video processor.","VPU A  and VPU B  receive commands and data from the driver  through respective ring buffers A , and B . The commands instruct VPU A  and VPU B  to perform a variety of operations on the data in order to ultimately produce a rendered frame for a display .","The driver  has access to a shared memory . In one embodiment, the shared memory , or system memory , is memory on a computer system that is accessible to other components on the computer system bus, but the invention is not so limited.","In one embodiment, the shared memory , VPU A  and VPU B  all have access to a shared communication bus , and therefore to other components on the bus . In one embodiment, the shared communication bus  is a peripheral component interface express (PCIE) bus, but the invention is not so limited.","The PCIE bus is specifically described in the following documents, which are incorporated by reference herein in their entirety:","PCI Express\u2122, Base Specification, Revision 1.1, Mar. 28, 2005;","PCI Express\u2122, Card Electromechanical Specification, Revision 1.1, Mar. 28, 2005;","PCI Express\u2122, Base Specification, Revision 1.a, Apr. 15, 2003; and","PCI Express\u2122, Card Electromechanical Specification, Revision 1.0a, Apr. 15, 2003.","The Copyright for all of the foregoing documents is owned by PCI-SIG.","In one embodiment, VPU A  and VPU B  communicate directly with each other using a peer-to-peer protocol over the bus , but the invention is not so limited. In other embodiments, there may be a direct dedicated communication mechanism between VPU A  and VPU B .","VPU A  and VPU B  each have a local video memory  and , respectively, available. In various embodiments, one of the VPUs functions as a master VPU and the other VPU functions as a slave VPU, but the invention is not so limited. In other embodiments, the multiple VPUs could be peers under central control of another component. In one embodiment, VPU A  acts as a master VPU and VPU B  acts as a slave VPU.","In one such embodiment, various coordinating and combining functions are performed by an interlink module (IM)  that is resident on a same card as VPU A . This is shown as IM  enclosed with a solid line. In such an embodiment, VPU A  and VPU B  communicate with each other via the bus  for transferring inter-VPU communications (e.g., command and control) and data. For example, when VPU B  transfers an output frame to IM  on VPU A  for compositing (as shown in  for example), the frame is transferred via the bus .","In various other embodiments, the IM  is not resident on a VPU card, but is an independent component with which both VPU A  and VPU B  communicate. One such embodiment includes the IM  in a \u201cdongle\u201d that is easily connected to VPU A  and VPU B . This is indicated in the figure by the IM  enclosed by the dashed line. In such an embodiment, VPU A  and VPU B  perform at least some communication through an IM connection . For example, VPU A  and VPU B  can communicate command and control information using the bus  and data, such as frame data, via the IM connection .","There are many configurations of the system  contemplated as different embodiments of the invention. For example,  as described below illustrate just some of these embodiments.",{"@attributes":{"id":"p-0060","num":"0059"},"figref":["FIG. 3","FIG. 3"],"b":["300","200","302","304","305","306","390","308","310","306","308","310"]},"VPU A  and VPU B  each have respective command processors CP A  and CP B . CPs  and  fetch and interpret command sequences in the command buffer . Each CP is a combination of dedicated, fixed function hardware for command processing, and software program-based execution. There is a set of microcode for each CP, as well as a small microengine (ME), or execution engine, that executes a sequence of microcode that is preloaded by the driver . The microcode determines what code is executed for a command packet (for example, via a jump table based on an OPCODE), and it also includes the sequence of operations or code executed in order to interpret the data in the command. Commands are executed by respective video pipelines  and  as directed by CPs  and . In various modes of system operation, the outputs of the VPU A  and the VPU B  are composited in a compositor  as described further herein.","Embodiments as described herein are not limited to a microcode-based processing engine implementation. For example, embodiments also include fixed function logic on silicon.","The microcode is loaded as part of an initialization step of the VPU. Conventionally, for each identical VPU, the same microcode image is loaded. That is, for any two identical VPUs in an identical operating environment, the same microcode image is loaded. In contrast to the conventional practice, embodiments as described herein include loading differing ME microcode images on each VPU in the system  that allows each VPU's CP ME to distinguish itself from other VPUs (or groups of VPUs).","An ME has the ability to ignore a programmable number of data elements (e.g., 32-bit DWORDs in a command buffer) by treating these as NOPs (non-operations, or no operation).","In another aspect of the system and method, an algorithm is implemented in the microcode that can determine whether a given command sequence is relevant to the VPU executing the microcode. Further, the algorithm can process the command sequence if it is relevant, or ignore it if it is not relevant. That is, the algorithm provides a means for each VPU's ME to process a command sequence in a predicated manner based on a predication result specific to the VPU.","In yet another aspect of the system and method, an algorithm implemented in the driver allows the construction of a single command sequence consisting of general (non-VPU specific) commands together with commands that are intended to be processed by one or more specific VPUs but not others. That is, an algorithm provides for the driver  to construct a predicated command sequence with the predication based on the driver's selection of one or more targeted VPUs.","Various embodiments of a system and method for applying non-homogeneous properties to multiple video processing units (VPUs) in a multiple VPU system are contemplated. Two embodiments will be described in more detail. One of these embodiments will now be described with reference to . The driver  builds a command buffer  that consists of packets. The packets include commands and\/or data information of DWORD granularity. A DWORD is a 32-bit data element.","As the driver  builds the command buffer , it determines which commands are predicated commands. Just before one or more predicated commands that are intended for one or more specific VPUs, the driver  places a specific \u201cpredicated execution command\u201d. This command is also referred to as the PRED_EXEC command. The PRED_EXEC command includes: a bit field that represents a VPU select; and 2) the length of the predicated command sequence to follow. When the CP A  or the CP B  encounters the PRED_EXEC, it compares the VPU select in that command with a preprogrammed VPU ID that is unique to the VPU. If the VPU select matches its VPU ID, the VPU will process the commands that follow and execute them. If, however, the VPU select does not match its VPU ID, it \u201cskips\u201d the next N commands, where N is programmed in a packet header. The next N DWORDS of data are ignored. The length is programmed into the packet, so it will ignore the subsequent packet up to the length specified in the PRED_EXEC packet.","In an embodiment, the device ID is present in the specific microcode image that is loaded to each CP, but the invention is not so limited. In other embodiments, the device ID is not used to identify which VPU is to execute the predicated commands. Rather some other data or value could be used to identify which VPU is to execute the predicated commands. The data or value may be stored anywhere in the system .","The PRED_EXEC command tells the VPU how many 32 bit data elements (DWORDs) to ignore. This translates into how many commands to ignore in an embodiment in which commands are variable sized, but have a granularity of one DWORD. It is also possible to count commands, for example. However, because the commands are variable of length it may simplify operation of the CP if DWORDs are counted.","Table 1 shows the format of a PRED_EXEC packet according to an embodiment.",{"@attributes":{"id":"p-0072","num":"0071"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"119pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Ordinal","Field Name","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","[ HEADER ]","Header field of the packet."]},{"entry":["2","[DEVICE_SELECT |","DEVICE_SELECT: [31:24] - bitfield"]},{"entry":[{},"EXEC_COUNT]","to select one or more devices upon"]},{"entry":[{},{},"which the subsequent predicated"]},{"entry":[{},{},"packets will be executed"]},{"entry":[{},{},"EXEC_COUNT: [22:0] - total number"]},{"entry":[{},{},"of DWORDs of subsequent"]},{"entry":[{},{},"predicated packets. This count wraps"]},{"entry":[{},{},"the packets that will be predicated"]},{"entry":[{},{},"by the device select."]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"The PRED_EXEC packet includes the VPU select (DEVICE_SELECT) and the command length that follows (EXEC_COUNT). The particular VPU select in the packet is compared with the VPU ID of the VPU. If there is a match, then effectively that PRED_EXEC command is terminated, and the subsequent commands are allowed to be executed. If the VPU ID and the VPU select match, then the command length that follows in the PRED_EXEC packet is ignored in the PRED_EXEC packet interpretation by the VPU so that the next DWORD in the command sequence, which is a new command header, is interpreted and executed.","However, if the VPU ID and the VPU select do not match, then the command length provided in the PRED_EXEC packet effectively lengthens the PRED_EXEC packet; it is treated as a NOP, and the number of subsequent DWORDs that is specified in EXEC_COUNT is thrown away. The number corresponds to the number of DWORDs in the subsequent command sequence that is specific to one VPU or another.","In one embodiment in which the device ID is a device mask in the microcode image in the CP, up to eight different devices are supported because there are eight bits in both the device mask microcode image and the DEVICE_SELECT field of the PRED_EXEC packet. The microcode performs a bitwise AND of the DEVICE_SELECT bitfield and the device mask bitfield. If the result of the AND operation is non-zero, the PRED_EXEC packet ends normally to allow the subsequent packets to be executed.","If the result of the AND operation is zero, the microcode loads an ME register with EXEC_COUNT-. This causes the ME to treat the subsequent packets as part of the current PRED_EXEC packet. The microcode then treats these EXEC_COUNT DWORDs as NOPs.",{"@attributes":{"id":"p-0077","num":"0076"},"figref":"FIG. 4","b":["411","413","417","421"]},"If the device ID does not match the DEVICE_SELECT at , the CP of the VPU reads the EXEC_COUNT at . The CP then causes the VPU to ignore the number of commands specified by EXEC_COUNT, as shown at . As previously described this is actually a number of DWORDs in an embodiment. The CP then fetches the next packet at .","The driver  knows there are several VPUs, and it knows which operations the driver want to execute on each VPU based on a variety of factors. For example, the driver directs load balancing among the VPUs as described herein. When the driver is placing commands in the command buffer sequence that are common to all the VPUs, the driver does not have to do any additional work beyond constructing the command buffer in a normal way. If instead the driver targets a given operation, or set of attributes to a particular VPU, the driver, builds a command buffer as described now with reference to . If a command is predicated, as indicated at , the driver places a PRED_EXEC header into the command stream before the predicated command or commands as shown at . In some circumstances the driver knows the number of DWORDs affected by the predication. If, at , the number of DWORDs is known, the driver places the command length, as EXEC_COUNT, in the PRED_EXEC packet at . If, at , the number of DWORDs is not known, the driver continues to add predicated commands to the command stream in the buffer at . The driver determines whether there are more predicated commands for a particular VPU at . If there are more such commands, the driver continues to add predicated commands to the command stream in the buffer at . If there are no more such commands, the driver determines the number of DWORDs involved at . Then the driver places the command length, as EXEC_COUNT, in the PRED_EXEC packet at . The process returns to  to determine whether the next command is predicated, and the process repeats.","There may be multiple sequences within a given command buffer that alternate between common commands, commands distinct to VPU A and commands distinct to VPU B, including both state data and operations like drawing or rendering. When the command buffer is complete, the driver submits this same command buffer to both VPUs (or to each VPU in the system). The driver still tracks when each VPU completes the command buffer. The driver does not need to track two different command buffers for the same set of operations. Rather, the same command buffer causes a different set of behaviors on different VPUs.","The application  directs when the command buffers are formed and what is in them. The driver  starts building the command buffers based on what is coming from the application . The driver  can build command buffers ahead of execution. The submission of command buffers is done into a ring buffer (as shown for example, in ) so the driver  can \u201cget ahead\u201d and submit command buffers to be executed before the previous command buffer is finished being executed.",{"@attributes":{"id":"p-0082","num":"0081"},"figref":"FIG. 6A","b":"306"},{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 6B","FIG. 6A","FIG. 6C","FIG. 6A"]},"Another embodiment will now be described with reference to . In this embodiment and variants thereof, a specific predicated packet type is defined for each VPU. The packet is recognized by the VPU for which it is intended. Different microcode is loaded on each VPU to interpret a packet header as preceding either a NOP or a \u201creal operation\u201d, such as a register write. Table 2 summarizes two such packets named DEVICE0_REGISTER_WRITE and DEVICE1_REGISTER_WRITE.",{"@attributes":{"id":"p-0085","num":"0084"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["Packet Name","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["DEVICE_0_REGISTER_WRITE","Write one or more"]},{"entry":[{},"consecutive registers to device 0."]},{"entry":[{},"On device 0, the register writes"]},{"entry":[{},"will occur. On device 1, the"]},{"entry":[{},"register writes will be ignored"]},{"entry":["DEVICE_1_REGISTER_WRITE","Write one or more"]},{"entry":[{},"consecutive registers to device 1."]},{"entry":[{},"On device 1, the register writes"]},{"entry":[{},"will occur. On device 0,"]},{"entry":[{},"the register writes will be ignored"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"DEVICE0_REGISTER_WRITE is interpreted by a device 0 as executable commands, and interpreted by device 1 as NOPs to be ignored. Similarly, DEVICE1_REGISTER_WRITE is interpreted by a device 1 as executable commands, and interpreted by device 0 as NOPs to be ignored.","Table 3 shows the format for a DEVICE_REGISTER_WRITE packet according to an embodiment.",{"@attributes":{"id":"p-0088","num":"0087"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 3"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Ordinal","Field Name","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","[ HEADER ]","Header field of the packet."]},{"entry":[{},"[#DWORDS]","Contains DWORD count."]},{"entry":["2","[BASE_INDEX[12:0]]","Typically, this DWORD is the"]},{"entry":[{},{},"packet header for the device-"]},{"entry":[{},{},"specific register write to perform."]},{"entry":[{},{},"The BASE_INDEX[12:0]"]},{"entry":[{},{},"correspond to byte address"]},{"entry":[{},{},"bits [14:2]. So the"]},{"entry":[{},{},"BASE_INDEX is the DWORD"]},{"entry":[{},{},"Memory-mapped address."]},{"entry":[{},{},"The BASE_INDEX field width"]},{"entry":[{},{},"supports up to DWORD address:"]},{"entry":[{},{},"0x7FFF."]},{"entry":["3","REG_DATA_1","The bits correspond to those"]},{"entry":[{},{},"defined for the relevant register."]},{"entry":[{},{},"Note the suffix x of"]},{"entry":[{},{},"REG_DATA_x"]},{"entry":[{},{},"stands for an integer"]},{"entry":[{},{},"ranging from 1 to N."]},{"entry":". . ."},{"entry":["N+2","REG_DATA_N"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}}}},"The header includes information that tells how long the packet is (how many DWORDs). The header is followed by a VPU address, or register offset in the hardware, that indicates the first register to write to in that packet. There is then a sequence of one or more DWORDs of data. The first DWORD of the data is written to the base address, or the offset of the register. The next DWORD is written to the next offset register, and so on for as many DWORDs of data as follow.","If the VPU does not \u201cmatch\u201d, then the ME skips up to N+2 DWORDS by \u201cignoring\u201d them as NOPs.",{"@attributes":{"id":"p-0091","num":"0090"},"figref":"FIG. 7","b":["711","713","717","718","719","721","713","723","718"]},"If the device determines from the OPCODE at  that the packet was not for device 0, the DWORD count is read at . Assuming the DWORD count=X, the next X DWORDS are ignored by the device, and the next packet is fetched at .",{"@attributes":{"id":"p-0093","num":"0092"},"figref":["FIG. 8","FIG. 7","FIG. 8"],"b":["811","813","815","817","811","813","815"],"sub":["\u2014","\u2014"]},{"@attributes":{"id":"p-0094","num":"0093"},"figref":"FIG. 9","b":["900","900","952","954","952","908","954","910","908","910","934","934","935","908","910","935","908","910","935","908","910","935","937","908","910","937"]},"The master VPU card  includes an IM . In an embodiment in which VPU A  and VPU B  communicate via the bus , each VPU processes frame data as instructed by the driver. As an example in , the system  is performing video processing in a \u201cscissoring\u201d load balancing mode as described below. Master VPU A  generates an output  and slave VPU B  generates an output . The outputs  and  are input to the IM  for compositing, as described further below. In one embodiment, the slave VPU B  transfers its output  to the IM  via the buses  and  as shown by the dotted path . In one embodiment, the slave VPU B  transfers its output  to the IM  via the dedicated intercard connection  as shown by the dotted path . The IM  combines the outputs  and  to produce a frame for display. This frame is output to a display  by the IM  via a connector .","The master VPU card  includes connectors  and . The slave VPU card  includes connectors  and . Connectors , ,  and  are connectors appropriate for the purpose of transmitting the required signals as known in the art. For example, the connector  is a digital video in (DVI) connector in one embodiment. There could be more or less than the number of connectors shown in the  .","In one embodiment, the various configurations described herein are configurable by a user to employ any number of available VPUs for video processing. For example, the system  includes two VPUs, but the user could choose to use only one VPU in a pass-through mode. In such a configuration, one of the VPUs would be active and one would not. In such a configuration, the task sharing or load balancing as described herein would not be available. However, the enabled VPU could perform conventional video processing. The dotted path  from VPU card B  to the display  indicates that slave VPU B  can be used alone for video processing in a pass-through mode. Similarly, the master VPU A  can be used alone for video processing in a pass-through mode.",{"@attributes":{"id":"p-0098","num":"0097"},"figref":["FIG. 10","FIG. 9"],"b":["1000","1000","1052","1054","1052","1008","1054","1010"]},"The master VPU card  also includes a receiver  and a transmitter  for receiving and transmitting, in one embodiment, TDMS signals. A dual connector  is a DMS connector in an embodiment. The master card further includes a DVI connector  for outputting digital video signals, including frame data, to a display. The master VPU card  further includes a video digital to analog converter (DAC). An interlink module (IM)  is connected between the VPU A  and the receivers and transmitters as shown. The VPU A  includes an integrated transceiver (labeled \u201cintegrated\u201d) and a digital video out (DVO) connector.","The slave VPU card  includes two DVI connectors  and . The slave VPU B  includes a DVO connector and an integrated transceiver. As an alternative embodiment to communication over a PCIE bus (not shown), the master VPU card  and the slave VPU card  communicate via a dedicated intercard connection .",{"@attributes":{"id":"p-0101","num":"0100"},"figref":["FIGS. 11-14","FIG. 11"],"b":["1100","1100","1156","1156","1108","1110","1156","1112","1108","1110","1135","1134"]},"The system  includes all of the multiple VPU (also referred to as multiVPU) functionality described herein. For example, the master VPU A  processes frame data as instructed by the driver, and outputs processed frame data  to the IM . The slave VPU B  processes frame data as instructed by the driver, and outputs processed frame data , which is transferred to the IM  for combining or compositing. The transfer is performed via the PCIE bus  or via a dedicated inter-VPU connection (not shown), as previously described with reference to . In either case, the composited frame is output from the IM  to a display .","It is also possible to disable the multiVPU capabilities and use one of the VPUs in a pass-through mode to perform video processing alone. This is shown for example by the dashed path  which illustrates the slave VPU B  connected to a display  to output frame data for display. The master VPU A  can also operate alone in pass-through mode by outputting frame data on path .",{"@attributes":{"id":"p-0104","num":"0103"},"figref":"FIG. 12","b":["1200","1200","1258","1258","1208","1210","1258","1212","1208","1210","1234","1281"]},"The system  includes all of the multiVPU functionality described herein. For example, the master VPU A  processes frame data as instructed by the driver, and outputs processed frame data  to the IM . The slave VPU B  processes frame data as instructed by the driver, and outputs processed frame data , which is transferred to the IM  for combining or compositing. The transfer is performed via the PCIE bus  or via a dedicated inter-VPU connection (not shown), as previously described with reference to . In either case, the composited frame is output from the IM  to a display (not shown).","It is also possible to disable the multiVPU capabilities and use one of the VPUs in a pass-through mode to perform video processing alone. This is shown for example by the dashed path  which illustrates the slave VPU B  connected to an output for transferring a frame for display. The master VPU A  can also operate alone in pass-through mode by outputting frame data on path .",{"@attributes":{"id":"p-0107","num":"0106"},"figref":"FIG. 13","b":["1300","1300","1360","1362","1360","1308","1362","1310","1308","1310","1308","1310","1308","1310","1335","1334","1308","1310","1312","1312","1360","1362","1312","1312","1308","1310","1330"]},{"@attributes":{"id":"p-0108","num":"0107"},"figref":["FIG. 14","FIG. 14"],"b":["1400","1400","1300","1400","1460","1462","1460","1408","1462","1410","1408","1410","1408","1410","1408","1410","1435","1434","1408","1410","1412","1412","1460","1462","1412","1412","1408","1410","1430"]},"The configurations as shown herein, for example in , are intended as non-limiting examples of possible embodiments. Other configurations are within the scope of the invention as defined by the claims. For example, other embodiments include a first VPU installed on or incorporated in a computing device, such as a personal computer (PC), a notebook computer, a personal digital assistant (PDA), a TV, a game console, a handheld device, etc. The first VPU can be an integrated VPU (also known as an integrated graphics processor, or IGP), or a non-integrated VPU. A second VPU is installed in or incorporated in a docking station or external enclosed unit. The second VPU can be an integrated VPU or a non-integrated VPU.","In one embodiment, the docking station is dedicated to supporting the second VPU. The second VPU and the first VPU communicate as described herein to cooperatively perform video processing and produce an output as described. However, in such an embodiment, the second VPU and the first VPU communicate via a cable or cables, or another mechanism that is easy to attach and detach. Such an embodiment is especially useful for allowing computing devices which may be physically small and have limited video processing capability to significantly enhance that capability through cooperating with another VPU.","It will be appreciated by those of ordinary skill in the art that further alternative embodiments could include multiple VPUs on a single die (e.g., two VPUs on a single die) or multiple cores on a single silicon chip.",{"@attributes":{"id":"p-0112","num":"0111"},"figref":"FIG. 15","b":["1512","1512"]},"The IM  includes a master input port that receives a DVO stream from a master VPU. The master VPU input can be from a TDMS receiver in a \u201cdongle\u201d configuration such as those shown in . The master VPU input can alternatively come from a master VPU on a master VPU card in a multi-card configuration, as shown for example in . A synchronization register  receives the DVO data from the master VPU.","The IM  further includes a slave input port that receives a DVO stream from a slave VPU. The slave VPU input can be from a TDMS receiver in a \u201cdongle\u201d configuration such as those shown in  or a card configuration as in . The slave VPU input can alternatively come from a slave VPU on a \u201csuper\u201d VPU card configuration, as shown for example in . The IM  includes FIFOs  on the slave port to help synchronize the input streams between the master VPU and the slave VPU.","The input data from both the master VPU and the slave VPU are transferred to an extended modes mixer  and to a multiplexer (MUX) . The IM  is configurable to operate in multiple compositing modes, as described herein. When the parts of the frame processed by both VPUs are combined, either by the extended modes mixer , or by selecting only non-black pixels for display, as further described below, the entire frame is ready to be displayed.","Control logic determined which compositing mode the IM  operates in. Depending on the compositing mode, either the extended modes mixer or the MUX will output the final data. When the MUX is used, control logic, including a black register  and a MUX path logic and black comparator , determines which pixel (master or slave) is passed through the MUX. Data is output to a TDMS transmitter  or a DAC .","The black register is used to allow for software to set a final black value that has been gamma adjusted.","In one embodiment, the inter-component communication among the VPUs and the IM  includes I2C buses and protocols.","Operating modes, including compositing modes, are set through a combination of I2C register bits  and TMDS control bits  as shown in Table 4.",{"@attributes":{"id":"p-0120","num":"0119"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"343pt","align":"center"}},"thead":{"row":{"entry":"TABLE 4"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Operational Modes and Control Bits"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Category",{},{},{},{}]},{"entry":["Main","Sub","I2C Bits","TMDS Cntr Bits","Notes"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}},{"entry":["Passthru","Slave","INTERLINK_ENABLE = 0","n\/a","Uses 1I2C access to"]},{"entry":[{},{},"CONTROL_BITS_2: Bit",{},"determine path"]},{"entry":[{},{},"3 = x"]},{"entry":["Passthru","Master","INTERLINK_ENABLE = 0","n\/a","Uses 1I2C access to"]},{"entry":[{},{},"CONTROL_BITS_2: Bit",{},"determine path"]},{"entry":[{},{},"3 = x"]},{"entry":["Interlink","AFR_MANUAL","INTERLINK_ENABLE = 1","AFR_MAN_ON* = 0","xAFR_MAS state"]},{"entry":[{},{},"CONTROL_BITS_2: Bit","AFR_AUTO* = 1","changes controls the next"]},{"entry":[{},{},"3 = 0",{},"data path"]},{"entry":["Interlink","AFR_AUTO","INTERLINK_ENABLE = 1","AFR_MAN_ON* = 0"]},{"entry":[{},{},"CONTROL_BITS_2: Bit","AFR_AUTO* = 0"]},{"entry":[{},{},"3 = 0"]},{"entry":["Interlink","BLACKING","INTERLINK_ENABLE = 1","AFR_MAN_ON* = 1","Uses black pixels to"]},{"entry":[{},{},"CONTROL_BITS_2: Bit","AFR_AUTO* = x","determine data path"]},{"entry":[{},{},"3 = 0"]},{"entry":["Interlink","Super AA","INTERLINK_ENABLE = x","n\/a","CONTROL_BITS_2: Bit"]},{"entry":[{},{},"CONTROL_BITS_2: Bit",{},"4\u20137 determines extended"]},{"entry":[{},{},"3 = 1",{},"mode"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"There are two separate data paths through the IM  according to an embodiment. The two input pixel streams from the respective VPUs are either processed through the MUX  (in pass-through mode, or \u201cstandard\u201d interlink modes), or through the mixer  in extended modes. In one embodiment, the extended modes include a super antialiasing mode, or \u201cSuperAA mode\u201d, as described in copending U.S. patent application Ser. No. 11\/140,156, titled \u201cAntialiasing System and Method\u201d, which is hereby incorporated by reference in its entirety.","In the MUX , just one pixel from either VPU A or VPU B is selected to pass through, and no processing of pixels is involved. In the extended modes mixer , processing is done on a pixel by pixel basis. In the SuperAA mode, for example, the pixels are processed, averaged together, and reprocessed. In one embodiment, the processing steps involve using one or more lookup tables to generate intermediate or final results.","The selection between the MUX  path and the mixer  path is determined by I2C register bits and control bits. For example, the mixer  path is selected if:",{"@attributes":{"id":"p-0124","num":"0123"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ENABLE_INTERLINK = 1 (I2C register)"]},{"entry":["\u2003\u2003\u2003\u2003\u2003\u2003and","CONTROL_BITS_2 : Bit 3 and Bit 4 = 1 (ExtendedModes and"]},{"entry":"SuperAA)"},{"entry":"\u2003\u2003\u2003(else MUX)."},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"In one embodiment, the IM has three ports, two input ports and one output port.","The output port configuration is split into two parts. The DAC is driven across a 24 bit single data rate (SDR) interface. The TMDS is driven with a double data rate (DDR) interface; a 12 pin interface for TMDS single link, and a 24 pin interface for TMDS dual link. The I2C control bit registers determines this configuration.","There are three primary pixel clock domains. Both the master and slave inputs come in on their own separate domains. The IM uses the DVO clock domain for all internal paths and the final output. The DVO clock is generated by the active input port in pass-through mode and from the master input clock in interlink mode.","The master input bus (data and control) goes through a synchronizer as it passes into the DVO clock domain, imparting a 2-4 clock delay. The slave input bus (data and control) goes into a FIFO which is synchronized on its output to the DVO clock domain. The outputs of both paths are routed to a MUX or extended modes mixer, which then outputs a single bus width data output.","In slave pass-through mode the slave FIFO is set into pass-through mode, while in interlink mode, it is used as a standard FIFO. For slave pass-through mode, the control bits go through the FIFO with the pixel data. In interlink mode, sAFR_MAS goes through with the data, and the control bits are ignored from the slave input port.","I\/Os that use DDR clocking are split into double wide buses (e.g., 12-bit DDR input becomes 24 bits internally). This is to avoid having to run the full clock speed through the IM.","In one embodiment, there is one FIFO on the IM, located on the slave channel. 24 bits of pixel data flow through the FIFO in single TMDS mode, and 48 bits of data flow through the FIFO in dual TMDS mode. The slave port's control bits are also carried through this FIFO when in pass-through mode, slave path. When in interlink mode, the control bits are ignored, and instead of the control bits the sAFR_MAS bit is carried through in parallel with the pixel data.","When in single link TMDS mode (CONTROL_BITS: Dual_Link_Mode bit=0), the extra 24 bits of data for dual link are not clocked to conserve power.","On power up the FIFOs should be set to empty. FIFOs are also cleared when the ENABLE_INTERLINK bit toggles to 1 or if the CONTROL_ONESHOTS: FIFO_Clear bit is set to 1.","The slave FIFO has two watermarks (registers FIFO_FILL, FIFO_STOP). The IM drives the SlavePixelHold pin depending on how full the FIFO is and the values in these registers. If the slave FIFO has FIFO_FILL or fewer entries in use, the SlavePixelHold should go low. If the slave FIFO has FIFO_STOP or more entries in use, the SlavePixelHold should go high.","\u201cLoad balancing\u201d refers to how work is divided by a driver for processing by multiple system VPUs. In various embodiments, the processed data output by each VPU is composited according to one of multiple compositing modes of the IM , also referred to herein as \u201cinterlinking modes\u201d and \u201ccompositing modes\u201d. The IM  supports numerous methods for load balancing between numerous VPUs, including super-tiling, scissoring and alternate frame rendering (\u201cAFR\u201d), all of which are components of \u201cBlacking\u201d. These modes are described below.  is a diagram illustrating various load balancing modes performed by the system as described. Frame data from various VPUs in the system is processed according to a load balancing mode and composited in a compositor  (for example, as shown in ), as described herein, to generate a displayable frame.","For Super-Tiling, software driver control determines the tile size and alternates between image data and black tiles so that, between the master and slave VPUs, each frame is fully painted. The IM  passes through the non-black pixels (image data) creating a super tiling-type split between the master and slave inputs. The tile sizes can be dynamically adjusted every pair of master and slave frames if desired. Super-Tiling may divide a display screen into a chess board pattern for which each square\/tile is 32\u00d732, pixels for example. The image tiles are rendered on a first VPU of a multi-VPU system while the black tiles are rendered on a second VPU. Super-Tiling provides fine grain load sharing for pixel processing within a frame of rendering, a more even distribution of pixel load relative to other load balancing methods, and less complex driver implementation.","Scissoring divides a display screen into two parts, and this division can be horizontal or vertical. While a horizontal split may be more convenient when considering software implementation and data transfer flexibility, a vertical split may provide better load balancing. In the context of multiple VPUs, scissoring provides optimization opportunities in the direction of parallelizing data transfers with 3D rendering. Scissoring also supports methods in which the slave VPU (which performs the majority of data transfers) does less work than the master VPU, thereby facilitating dynamic load balancing schemes between the master and the slave VPUs.","Scissoring includes both Vertical Split Screen Blacking Control and Horizontal Split Screen Blacking Control. With Vertical Split Screen Blacking Control, the drivers determine which side of a frame are output from the master and slave VPU, so that between the two VPUs every frame is completely painted. The part of a frame that each VPU does not handle is cleared to black by the drivers. The IM  then interlinks the two frames as a vertical split between the master and slave VPU. The split does not have to be an even split of the screen (e.g., 50% rendered by each VPU) and can be dynamically adjusted for every pair of master and slave frames.","Under Horizontal Split Screen Blacking Control, the software drivers determine which upper or lower section of a frame are output from the master and slave VPU. The drivers then clear to black the portions that will not hold valid frame buffer data and the IM  mixes the inputs as a horizontal split of the inputs. The split does not have to be an even split of the screen (e.g., 50% rendered by each VPU) and can be dynamically adjusted for every pair of master and slave frames.","Alternate Frame Rendering (\u201cAFR\u201d) performs load balancing at a frame level. A \u201cframe\u201d as referred to herein includes a sequence of rendering commands issued by the application before issuing a display buffer swap\/flip command. AFR generally passes each new frame through to the output from alternating inputs of the IM . One VPU renders the even-numbered frames and the other VPU renders the odd-numbered frames, but the embodiment is not so limited. The AFR allows performance scaling for the entire 3D pipeline, and avoids render-to-texture card-to-card data transfers for many cases.","The IM  of an embodiment may perform AFR under Manual Control, Manual Control with automatic VSync switching, or Blacking Control. When using Manual Control, the drivers manually select an input of the IM  for a frame after the next VSync. Using AFR using Manual Control with VSync switching, and following a next vertical blank, the IM  chooses the input coupled to the master VPU as the output source and then automatically toggles between the master and slave VPU inputs on every VSync. Using Blacking Control, the drivers alternate sending a fully painted frame versus a cleared-to-black frame from the master and slave VPUs; the IM  toggles between the master and slave frames as a result.","Other compositing strategies are available and are not limited by the IM . For example, extended interlink modes are also available that go beyond the load sharing usage of the Manual AFR and Blacking modes. These modes, while not the standard interlinking used for pure speed gains by sharing the processing between multiple VPUs, enhance the system quality and\/or speed by offloading functionality from the VPUs to the IM . As one example of an extended mode, the IM  of an embodiment supports the \u201cSuperAA\u201d mode previously referred to in addition to the Manual AFR and Blacking modes.","Referring again to , the IM  supports multiple input modes and single or dual link TMDS widths, depending on the input connectivity. The IM  also includes counters that monitor the phase differences between the HSyncs and VSyncs of the two inputs. The counters may include a pixel\/frame counter to assist in matching the clocks on the two input streams.","Referring to Table 5, in one embodiment, the IM  has three counters . Each counter increments the master pixel clock and uses one of the VSyncs for latching and clearing.","If a read of an I2C counter is occurring, the update to that register is held off until after the read is completed. If a write of the register is occurring, then the read is delayed until the write is completed. Read delays are only a few IM internal clocks and therefore are transparent to software.",{"@attributes":{"id":"p-0146","num":"0145"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"273pt","align":"center"}},"thead":{"row":{"entry":"TABLE 5"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"IM Counters"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Counter Name","Bits","Clock","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["CLKS_PER_FRAME_CTR","22","Master","Number of master clocks per 1 slave"]},{"entry":[{},{},"Pixel","frame"]},{"entry":[{},{},{},"uses slave VSync to determine frame"]},{"entry":[{},{},{},"edges"]},{"entry":[{},{},{},"every slave VSync latches the count to"]},{"entry":[{},{},{},"CLKS_PER_FRAME and resets this"]},{"entry":[{},{},{},"counter"]},{"entry":["S2M_VSYNC_PHASE_CTR","11","Master","Number of lines displayed between slave"]},{"entry":[{},{},"Pixel","VSync and master VSync"]},{"entry":[{},{},{},"latched to S2M_VSYNC_PHASE every"]},{"entry":[{},{},{},"master VSync"]},{"entry":[{},{},{},"resets the count to 0 every slave VSync"]},{"entry":["S2M_HSYNC_PHASE_CTR","12","Master","Number of pixels displayed between"]},{"entry":[{},{},"Pixel","slave HSync and master HSync"]},{"entry":[{},{},{},"latched to S2M_HSYNC_PHASE every"]},{"entry":[{},{},{},"master HSync"]},{"entry":[{},{},{},"resets the count to 0 every slave HSync"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]}}]}}},"The IM  may be used in a number of configurations as described above. In one configuration, referred to herein as a \u201cdongle\u201d, the IM  receives two separate TMDS outputs, one each from two separate VPUs, and brings them onto the dongle through two TMDS receivers. The separate receivers then output two DVO streams directly into the IM  of the dongle. The IM  mixes the two received inputs into a single output stream. The output DVO signals from the IM  are then fed either to a TMDS transmitter or through a DAC, both of which drive out through a standard DVI-I connector on the dongle.","In another configuration, referred to herein as an \u201con-card\u201d configuration, the IM  receives two streams of DVO signals directly from two VPUs that reside on the same card as the IM . This on-card configuration does not use TMDS transmitters or receivers between the VPUs and the IM , in contrast to the dongle configuration. The IM  mixes the two received inputs into a single output stream. The output DVO signals from the IM  are then fed either to a TMDS transmitter or through a DAC, both of which drive out through a standard DVI-I connector for example.","The input streams received at the IM  inputs are referred to herein as the \u201cmaster input\u201d and the \u201cslave input\u201d, and are received from the master and slave VPUs, respectively. The master and slave VPUs may be on two separate cards or on a single \u201csuper\u201d card. Either VPU can function as the master or slave VPU.","The master VPU is used as the primary clock to which the slave is synchronized (\u201csynced\u201d). The master clock is not adjusted or tuned other than the normal card initialization process. The slave VPU is adjusted to run slightly ahead of the master VPU to allow for synchronization and FIFO latencies. The slave VPU uses a larger FIFO in order to compensate for variances between the pixel clock rates of the two VPUs, while the master VPU path uses a shallow FIFO only to synchronize the master input clock domain to the internal DVO clock domain. Flow control between the master and slave VPUs includes initial synchronization of the two VPUs and then ongoing adjustments to the slave VPU to match the master VPU. The flow control includes clock adjustments via a pixel hold off signal generated by the IM  or driver action in response to counters within the IM .","The IM  as described above supports numerous operational modes, including Pass-through Mode and various Interlink Modes, as illustrated in Table 1. These operational modes are set through a combination of I2C register bits and the TMDS Control Bits as described herein.","Pass-through Mode is a mode in which an input of the IM  is passed directly through to the output (monitor). The input port used is chosen at power-up by the initial toggling of an I2C clock. The path can be changed again by switching the ENABLE_INTERLINK register from \u201c1\u201d back to \u201c0\u201d and then toggling the I2C clock of the desired port.","Interlink Modes include numerous modes in which the IM  couples inputs received from the master and slave VPUs to an output in various combinations. Dual VPU Interlink Modes of an embodiment include but are not limited to Dual AFR Interlink Mode and Dual Blacking Interlink Mode.","Dual VPU Interlink Modes are modes in which both VPUs are being used through manual AFR control or through blacking modes. Both IM  ports are output continuously during operations in these modes.","Dual AFR Interlink Mode includes modes in which the source of the IM  output is alternated between the two input ports. It can either be done manually by the IM  drivers or automatically once started based on VSync. Control of the Dual AFR Interlink Mode includes use of the following bits\/states: AFR_MAN_ON*=low; AFR_AUTO*=high or low; AFR_MAS (used to control which card is outputting at the time or to set the first card for the Auto switch).",{"@attributes":{"id":"p-0156","num":"0155"},"figref":"FIG. 17"},"Dual Blacking Interlink Mode includes modes in which both VPUs output in parallel and the IM  forms an output by selecting pixels on a pixel-by-pixel basis by transmitting black pixel values for any pixel of any VPU that should not be output. Control of the Dual Blacking Interlink Mode includes use of the following bit\/state: AFR_MAN ON*=high.","AFR_MAN_ON* is sent across the master TMDS Control Bit bus on bit no . It is clocked in with mClk, one clock before the rising edge of mDE after the rising edge of mVSync. The action in response to it takes place before the first pixel of this mDE active period hits the MUX. Other than this specific time, there is no direct response to AFR_MAN_ON*.","When AFR_MAN_ON* is active (LOW) and ENABLE_INTERLINK is set to 1 and the ExtendedModes bit is 0, then the path set by the pixel MUX is controlled by the xAFR_MAN bits as described below.","The I2C register reflects the result after the resulting action occurs. It does not directly reflect the clocked in bit.","AFR_AUTO* is sent across the slave TMDS Control Bit bus on bit no . It is clocked in with sClk timings and then synced to mClk. It is latched in the clock before mDE goes high after the rising edge of mVSync. The action in response to it then occurs before the first pixel associated with the active mDE hits the MUX and only if AFR_MAN_ON* is low on the same latching point.","When AFR_AUTO* and AFR_MAN_ON* are active and ENABLE_INTERLINK is set to 1 and extended interlink modes are not active, then the path set by the pixel MUX is initially set to the master path. The path is then automatically toggled on every rising edge of mDE after the rising edge of mVSync until AFR_AUTO* is deasserted.","The I2C register reflects the result after the resulting action occurs. It does not directly reflect the clocked in bit.","The mAFR_MAS is set from the master port on mLCTL[1] and sAFR_MAS is set from the slave port on sLCTL[1]. These two bits control which path is set by the pixel MUX when in Interlink mode, manual AFR control.","The mAFR_MAS is clocked directly in with mCLK. The sAFR_MAS is clocked in with sCLK and then synced to mCLK. The bits are latched on the rising clock edge before the rising edge of mDE. Both latched bits then go into a logic block which detects a bit changing state. Depending on an I2C register bit, either after the rising edge of a VSync or an HSync, if a bit is detected as having its state changed, the logic sets the pixel MUX when in AFR_MANUAL Interlink mode to match the path of the toggled bit. The MUX will not change during AFR_MANUAL interlink mode at any other time.","If both bits toggle in the same updating time frame, then the master path is set.","Unlike the other control bits, the I2C register reflects the individual synchronized bits going into the MUX control logic block clocked in with MClk and not the bits after the sync state.","Regarding data and control paths in the IM  of an embodiment, the Dual VPU Interlink Mode works in routing modes that include pass-through, dual\/single input AFR Manual interlink, and dual input Blacking Interlink. These routing modes describe which of the data and control lines from the two receivers get transmitted out of the IM  via the transmitter or DAC. Table 6 shows the data, control, and clock routing by routing mode of the IM , under an embodiment.","The clock is the pixel clock, the internal control lines are the lines that connect between the TMDS transmitter and receivers (and IM ), and the external control lines are lines that are not processed by the TMDS circuitry such as I2C and Hot Plug. The Slave pixel hold off signal goes directly between the IM  and the Slave DVI VSync pin.",{"@attributes":{"id":"p-0170","num":"0169"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"6"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"6","colwidth":"63pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 6"},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}},{"entry":["Routing",{},"Internal","ByPass",{},{}]},{"entry":["Mode","Clock","Control","Control","Data","Notes"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Pass-","Master","Master","Master","Master","set by first I2C"]},{"entry":["Through","or","or Slave","or Slave","or Slave","clock toggling"]},{"entry":[{},"Slave"]},{"entry":["AFR","Master","Master","Master","Master","set by AFR_MAN"]},{"entry":["Manual","or","or Slave","or","or Slave","control bit"]},{"entry":[{},"Slave",{},"Slave"]},{"entry":["Blacking","Master","Master","Master","Master","Data is interlinked"]},{"entry":[{},{},{},{},"and","depending on"]},{"entry":[{},{},{},{},"Slave","black pixels"]},{"entry":{"@attributes":{"namest":"1","nameend":"6","align":"center","rowsep":"1"}}}]}}}}},"Pass-Through occurs when using the IM  in single-VPU Mode and before the drivers set up the IM  and VPUs for the dual-VPU mode. At power up, the IM  defaults the MUX to pass all data and control lines directly from the master VPU to the output of the IM . As soon as the IM  sees one of the input TMDS I2C clocks toggling, it sets the MUX to pass that specific channel to the output. This includes the clock and all control signals, whether it is from the master or slave VPU. This allows the IM  to connect the default video card of the system directly through to the monitor during power-up BIOS operation, even before the drivers are aware of existence of the IM .","In the Dual VPU Interlink Mode, once the drivers are loaded, the drivers can detect if the IM  exists and if there are one or two connections to the IM . The detection is done by reading the I2C ID register of the IM  through the port of each VPU. The drivers can determine which discovered connection is the master and which is the slave by the value of bit  of the IM  ID register read on each port.","If only one connection is found, the IM  is left in Pass-through mode. If two connections are found to the IM , the driver then takes over the screen control, setting the MUX of the IM  to output from the master port, with the VPU connected to the master port as the master VPU. The clock is driven from this port until the power is lost or one of the input connections to the IM  is broken.","The MUX of an embodiment is set by mechanisms that include Pass-Through initial states, AFR Manual Control, and Blacking Control. These modes and the particular controls for each are set through the TMDS CNTR bits, with the IM  responding on the next vertical blanking period. The master\/slave switch (AFR_MAS) can latch in\/occur on either the next HSync or the next VSync depending on the I2C control bits setting.","In addition to using TDMS control registers, the drivers also control and monitor the IM functionality using I2C control registers.","I2C registers are used for control and monitoring that does not need to happen every frame or faster. The registers can be available through both the master and slave ports of the IM.","For more dynamic control, the I2C control registers are used to set different multiVPU modes and to manually switch the IM data path.","In one embodiment of a video processing system, inter-integrated circuit communication for the IM is accomplished using an Inter-Integrated Circuit (I2C) bus. I2C is a bus typically used to connect integrated circuits (ICs). I2C is a multi-master bus, which means that multiple ICs can be connected to the same bus and each one can act as a master by initiating a data transfer.",{"@attributes":{"id":"p-0179","num":"0178"},"figref":"FIG. 18","b":["1812","1870","1870","1812","1812"]},"The two input I2C buses each feed through the DVI master and slave input ports into the dongle  and directly into the IM  on two separate channels.",{"@attributes":{"id":"p-0181","num":"0180"},"figref":"FIG. 19","b":["1512","1512","1512"]},"Either of VPU A or VPU B can access the ID registers directly through respective input ports without concern for I2C bus ownership.","The IM  has one set of registers which are I2C accessible at a particular I2C device address. All other addresses are passed through the IM  onto the I2C output port.","The master ID register and the slave register each have the same internal address, but are accessible only from their own respective I2C buses (slave or master).","Other than an IM_xxx_ID registers (offset 0) and the I2C_Reset register, the I2C bus is arbitrated on an I2C cycle-by-cycle basis, using a first-come, first-served arbitration scheme.","For read cycles of the multi-byte registers, the ownership is held until the last byte is read. Software drivers insure that all bytes are fully read in the bottom to top sequence. If all bytes are not fully read in the bottom to top sequence, the bus may remain locked and the behavior may become undefined.","For accesses that are passed through the IM  to external devices, the IM  does not understand page addressing or any cycle that requires a dependency on any action in a prior access (cycles that extend for more than one I2C stop bit). Therefore a register bit (CONTROL_BITS_: Bit : I2C_LOCK) is added. The software sets this register bit if a multi-I2C access is needed. When this register bit is set, the bus is given to that port specifically until the bit is unset, at which time the automatic arbitration resumes. In a case where both ports try to set this bit, then the standard arbitration method determines which gets access, and a negative acknowledgement (NACK) signal is sent to let the requester know it was unsuccessful.","A specific I2C_Reset register is used in a case of the I2C bus becoming locked for some unexpected reason. Any read to this register, regardless of I2C bus ownership, will always force the I2C state machines to reset and free up the I2C bus ownership, reverting back to the automatic arbitration.","For the other I2C registers, the I2C bus ownership is dynamically arbitrated for on a first-come, first-served fashion. The input port accessing the other registers first with a clock and start bit gets ownership for the duration of the current I2C cycle (that is, until the next stop bit). For multiple-byte read registers (counters) on the IM , the ownership is maintained from the first byte read until the final byte of the register has been read.","If an I2C access starts after the bus has been granted to another input port, then a negative acknowledgement (NACK) signal is sent in response to the access attempt. The data for a read is undefined and writes are discarded.","The IM  supports single non-page type I2C accesses for accesses off of the IM . To allow for locking the I2C bus during multiple dependent type I2C cycles, if an input port sets an I2C_LOCK bit (I2C_CONTROL_: bit ) to 1, the I2C bus is held in that port's ownership until the same port sets the same bit back to 0. This register follows the same first-come, first-served arbitration protocol.","If the I2C_RESET register is read from either port (no arbitration or ownership is required), then the I2C state machine is reset and any I2C ownerships are cleared.",{"@attributes":{"id":"p-0193","num":"0192"},"figref":["FIG. 20","FIG. 11"],"b":["2012","2052","2052","2052","2008","2012","2012"]},"All IM  I2C registers are available to either the slave or master I2C ports. Standard NACK responses are used if the I2C bus is currently in use by the other path. An IM  device ID is an exception and can be accessed by either port at the same time.","In order to optionally verify that an I2C cycle has completed successfully, all write registers are readable back. Since the I2C registers on the IM  do not time out, this matches the current method of I2C accesses used on various conventional video cards. The read back should not be necessary to verify writes.","The IM  I2C resets its state machine (not shown) every time it gets a stop bit. This occurs at the start and end of every I2C cycle, according to known I2C protocol.","A CONTROL_ONESHOTS register (not shown) has a different behavior from the other read\/write registers. Once written to, the IM  latches its results to internal control bits. The CONTROL_ONESHOTS registers themselves are cleared on the next read of this register (allowing for confirmation of the write).","The internal copies of the CONTROL_ONESHOTS bits are automatically cleared by the IM  once the IM  has completed the requested function and the CONTROL_ONESHOTS register corresponding bits are cleared. The IM  does not re-latch the internal versions until the I2C versions are manually cleared.","The IM has one set of registers which are I2C accessible. The IM_MASTER_ID and IM_SLAVE_ID registers have the same internal address but are accessible only from their own I2C bus (e.g., slave or master).","The rest of the registers are only accessible from one side (master or slave) at a time.","In order to verify that an I2C cycle has completed successfully, all write registers must also be readable back to verify the updated values. Since the I2C registers on the IM do not time out, this is consistent with conventional methods of I2C accesses used on various existing video cards. If needed, the read back should not be necessary to verify the writes.","The IM I2C also resets its state machine every time it gets a stop bit. This happens as per I2C protocol at the start and end of every I2C cycle.","The CONTROL_ONESHOTS register has a different behavior from the other read\/write registers. Once written to, the IM latches its results to internal control bits. The CONTROL_ONESHOTS are cleared on the next read of this register (allowing for confirmation of the write).","The internal copies of the CONTROL_ONESHOTS bits are automatically cleared by the IM once the IM has completed the requested f unction and the CONTROL_ONESHOTS register corresponding bits are cleared.","In a dongle configuration, such as in , for example, the TMDS control bits are transmitted through the TMDS interface into the IM. The software (driver) sets the registers within the VPU for the desired control bit values and the results arrive at the TMDS receivers on the dongle and are latched into the IM. The AFR_MAN_ON* and AFR_AUTO* are latched on the rising edge of the TMDS VSync. No pixel data is being transmitted at this time. AFR_MAS is latched in on the rising edge of either HSync or VSync, depending on the setting in the I2C Control_Bits register, bit .","If the interlink_mode is not enabled (I2C register set), then the bits will be ignored until it is enabled and will take place on the next VSync.","If the interlink_mode is enabled, then the affect occurs on the very next pixel data coming out of the IMs after the VSync or HSync as is appropriate.","If in pass-through modes, the Syncs used are from the active path. If in AFR_MANual or blacking interlink modes, then the Syncs used are always from the master path.","Aspects of the invention described above may be implemented as functionality programmed into any of a variety of circuitry, including but not limited to programmable logic devices (PLDs), such as field programmable gate arrays (FPGAs), programmable array logic (PAL) devices, electrically programmable logic and memory devices and standard cell-based devices, as well as application specific integrated circuits (ASICs) and fully custom integrated circuits. Some other possibilities for implementing aspects of the invention include: microcontrollers with memory (such as electronically erasable programmable read only memory (EEPROM)), embedded microprocessors, firmware, software, etc. Furthermore, aspects of the invention may be embodied in microprocessors having software-based circuit emulation, discrete logic (sequential and combinatorial), custom devices, fuzzy (neural) logic, quantum devices, and hybrids of any of the above device types. Of course the underlying device technologies may be provided in a variety of component types, e.g., metal-oxide semiconductor field-effect transistor (MOSFET) technologies like complementary metal-oxide semiconductor (CMOS), bipolar technologies like emitter-coupled logic (ECL), polymer technologies (e.g., silicon-conjugated polymer and metal-conjugated polymer-metal structures), mixed analog and digital, etc.","Unless the context clearly requires otherwise, throughout the description and the claims, the words \u201ccomprise,\u201d \u201ccomprising,\u201d and the like are to be construed in an inclusive sense as opposed to an exclusive or exhaustive sense; that is to say, in a sense of \u201cincluding, but not limited to.\u201d Words using the singular or plural number also include the plural or singular number respectively. Additionally, the words \u201cherein,\u201d \u201chereunder,\u201d \u201cabove,\u201d \u201cbelow,\u201d and words of similar import, when used in this application, refer to this application as a whole and not to any particular portions of this application. When the word \u201cor\u201d is used in reference to a list of two or more items, that word covers all of the following interpretations of the word: any of the items in the list, all of the items in the list and any combination of the items in the list.","The above description of illustrated embodiments of the invention is not intended to be exhaustive or to limit the invention to the precise form disclosed. While specific embodiments of, and examples for, the invention are described herein for illustrative purposes, various equivalent modifications are possible within the scope of the invention, as those skilled in the relevant art will recognize. The teachings of the invention provided herein can be applied to other systems, not only for the system including graphics processing or video processing as described above.","For example, a video image produced as described herein may be output to a variety of display devices, including computer displays that display moving pictures and printers that print static images.","The various operations described may be performed in a very wide variety of architectures and distributed differently than described. As an example, in a distributed system a server may perform some or all of the rendering process. In addition, though many configurations are described herein, none are intended to be limiting or exclusive. For example, the invention can also be embodied in a system that includes an integrated graphics processor (IGP) or video processor and a discrete graphics or video processor that cooperate to produce a frame to be displayed. In various embodiments, frame data processed by each of the integrated and discrete processors is merged or composited as described. Further, the invention can also be embodied in a system that includes the combination of one or more IGP devices with one or more discrete graphics or video processors.","In other embodiments not shown, the number of VPUs can be more than two.","In other embodiments, some or all of the hardware and software capability described herein may exist in a printer, a camera, television, handheld device, mobile telephone or some other device. The video processing techniques described herein may be applied as part of a process of constructing animation from a video sequence.","The elements and acts of the various embodiments described above can be combined to provide further embodiments. These and other changes can be made to the invention in light of the above detailed description.","All of the U.S. patent applications cited herein are hereby incorporated by reference in their entirety.","In general, in the following claims, the terms used should not be construed to limit the video processing method and system to the specific embodiments disclosed in the specification and the claims, but should be construed to include any processing systems that operate under the claims to provide video processing. Accordingly, the video processing method and system is not limited by the disclosure, but instead the scope of the video processing method and system is to be determined entirely by the claims.","While certain aspects of the method and apparatus for video processing are presented below in certain claim forms, the inventors contemplate the various aspects of the method and apparatus for video processing in any number of claim forms. For example, while only one aspect of the method and apparatus for video processing may be recited as embodied in computer-readable medium, other aspects may likewise be embodied in computer-readable medium. Accordingly, the inventors reserve the right to add additional claims after filing the application to pursue such additional claim forms for other aspects of the method and apparatus for video processing."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 5","FIG. 4"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 6B","FIG. 6A"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":["FIG. 6C","FIG. 6A"]},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 8","FIG. 7"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 10","FIG. 8"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 20"}]},"DETDESC":[{},{}]}
