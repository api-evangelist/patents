---
title: Method for selecting and extracting an eye diagram opening for subsequent processing
abstract: Measurements for an eye diagram of signal of interest are placed in a data structure that is examined to locate an eye opening of interest. The eye opening of interest is normalized into figure of merit units related to the operational voltage and timing requirements of the data receiver for that signal. The locations within the normalized eye opening may be taken as center locations for trial symmetric shapes that start out small and are enlarged until they first include locations not part of the normalized eye opening. The center of a largest such shape is mapped back into the units of the original eye diagram as optimum sampling parameters for data analysis equipment that uses the receiver to sample the signal once per unit interval to discover logical value. An alternative is to repeatedly remove the ‘outer layer’ of the normalized eye opening until only one location remains.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07411999&OS=07411999&RS=07411999
owner: Agilent Technologies, Inc.
number: 07411999
owner_city: Santa Clara
owner_country: US
publication_date: 20050224
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["REFERENCES TO INCORPORATED PATENTS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DESCRIPTION OF A PREFERRED EMBODIMENT"],"p":["The subject matter of the present Application pertains to the application of eye diagrams in general, and is especially well suited for use with one existing eye diagram measurement technique in particular, although it is by no means limited to use with only that technique. An implementation of that technique is the subject matter of a U.S. Pat. No. 6,785,622 entitled METHOD AND APPARATUS FOR PERFORMING EYE DIAGRAM MEASUREMENTS filed on 29 Oct. 2001 and issued 31 Aug. 2004. Some extensions of that technique are also of interest. One is described in a U.S. Pat. No. 6,810,346 entitled COMPOSITE EYE DIAGRAMS filed 31 Jan. 2002 and issued 26 Oct. 2004. Another is described in a U.S. Pat. No. 6,804,633 entitled FAST EYE DIAGRAM ANALYZER USES NEAREST NEIGHBOR TRAVERSE TO QUICKLY DISCOVER BASIC EYE DIAGRAMS filed 31 Jan. 2003 and issued 12 Oct. 2004. Still another is described in a U.S. Pat. No. 6,760,676 entitled ON-SCREEN TOOLS FOR EYE DIAGRAM MEASUREMENTS filed on 31 Jul. 2002 and issued 6 Jul. 2004. Because the topics described in those Patents are either points of departure for the present invention, or describe techniques of interest for manipulating data structures that contain eye diagram data, and for the sake of brevity in the present application, each of \u201cMETHOD AND APPARATUS FOR PERFORMING EYE DIAGRAM MEASUREMENTS,\u201d \u201cCOMPOSITE EYE DIAGRAMS,\u201d \u201cFAST EYE DIAGRAM ANALYZER USES NEAREST NEIGHBOR TRAVERSE TO QUICKLY DISCOVER BASIC EYE DIAGRAMS\u201d and \u201cON-SCREEN TOOLS FOR EYE DIAGRAM MEASUREMENTS\u201d are hereby expressly incorporated herein by reference.","Digital systems have signals with abrupt transitions and whose time variant analog behavior represents boolean (two-state logical) values described as ONE or ZERO, TRUE or FALSE, or perhaps HIGH or LOW. The \u2018real\u2019 information content carried by such signals is encoded within sequences or combinations of these logical values. Nevertheless, it will be remembered that when signals are sent from one place (component or assembly) to another, or from one entire system to another, they rely on their analog properties to do so. That is, it is their underlying voltage or current (or light) that makes the journey, while it is some observable property such as magnitude or polarity that is subsequently interpreted as representing one or the other of the possible logical values.","Very often it is the magnitude of a voltage that determines the logical value to be understood. The abrupt transitions are constrained to occur at particular times indicated by a clock signal, and the stable or asserted regions between transitions are compared against a threshold to ascertain the logical value. The nominal shortest period of time between transitions for a signal is called a UI (Unit Interval), and its phase and duration is either supplied by a clock signal accompanying the data, or is derived from the data.","Logic analyzers are members of a class of electronic test equipment that observes collections of digital signals, converts them to instances of corresponding logic values along a time axis, and reports on and analyzes their (logical) activity. This class of test equipment, which we may call data analysis equipment, generally samples only once within each consecutive UI, takes the sampled value as indicative of the logical value for that UI, and does not attempt to reconstruct the underlying analog waveform. A clock signal is either re-constructed from the data or is supplied as a separate signal, and transitions in the clock signal are used to delimit the UI. As the speeds of digital systems increase into the Gigabit per second region the issues of exactly where within the UI to make the threshold decision for a data signal, and with what threshold voltage, become increasingly problematic. Quite aside from how the SUT (System Under Test) itself performs these tasks, the logic analyzer has to perform them as well, and do so correctly if the measurement of the data is to have any utility. It is conventional for both the threshold and the delay relative to the onset of the UI (as indicated by a transition in the clock signal) to be adjustable by the operator of the logic analyzer. Hereinafter, we shall collectively refer to these as \u2018sampling parameters\u2019 and to their individual elements as \u2018threshold\u2019 and \u2018sample position,\u2019 respectively. Some logic analyzers even attempt to automate the process of selecting these sampling parameters. These prior art techniques for setting threshold and sample position each have certain associated disadvantages.","An eye diagram is a stylized representation of a signal's behavior. An eye diagram can be made by superimposing a large number of time domain trace segments that each correspond to just an individual UI (that's exactly how a \u2018scope would make a basic eye diagram). Implicit in this idea is the notion that satisfaction of some clock signal-related trigger event allows the correct registration of each segment on the other. This will display both rising and falling edges, and asserted regions (whether HIGH or LOW) each in their same relative horizontal locations, for perhaps a million (or more) cycles of the signal. The result is (hopefully) a central empty opening called an \u2018eye\u2019 (on account of its shape) that is free of any traced activity, since during that time any signal will be either already HIGH or already LOW. At each edge of an eye for a typical (non-pulse) signal is an X-shaped boundary produced by rising and falling transitions, with straight lines above and below the Xs produced by the various consecutive ONEs and consecutive ZEROs in the data. And while it is then possible to discern if in that collection of cycles there were instances of overshoot, slow rise or fall times, or inappropriate asserted voltage levels, knowledge about which cycle(s) is(are) at fault is generally lost. That is a minor price to pay for an easily viewed presentation that gives valuable information about overall margins (the size and shape of the eye). Once any such violations of margins are confirmed, their location in the data (if such information is needed) and their causes can be sought using other test techniques. Often, two or three consecutive UIs are treated as a unit collection, and superimposed on other such unit collections to create an eye diagram having two or three eyes. There are other ways to actually create eye diagrams besides the brute force 'scope technique alluded to above, and some of these are quite a bit faster than the 'scope's method for the number of signal cycles that are typically of interest. They, too, incorporate the notion of triggering from a clock signal as the reference for registering events occurring at the same general location along the UI but measured during different cycles of the data.","For data analysis equipment, such as logic analyzers, that capture the logical values once per UI (as opposed to a 'scope that densely samples the actual analog waveform), it is conventional to use the \u2018X crossing\u2019 voltage of an eye diagram as the threshold for a data receiver (comparator), and to delay the capture of the comparison output from the associated clock so as to locate the sample position midway between consecutive crossings. However, this may not actually be an optimum set of sampling parameters.","Recently, some data analysis equipment, including logic analyzers, have begun to support the ability to perform eye diagram measurements, and new techniques are thus possible within such test equipment (such as logic analyzers) to allow it to automatically recommend or decide the best time within the UI, and with what threshold, to \u2018sample\u2019 an incoming signal to decide its logical value. Such automatic selection (or a recommendation) should take the behavior of the data receiver into account and can be of benefit to the internal operation of the logic analyzer when used in its traditional logic analysis capacity (it is desirable that it not mis-sample the data . . . ). In addition, such recommended information (not necessarily obtained from a logic analyzer, but perhaps from a 'scope that also does eye diagrams) can also be of use to persons responsible for setting the sampling parameters for the receivers that belong to\/are part of the SUT itself, and that are not part of any external test equipment, such as logic analyzer.","Furthermore, the conventional notion that the best threshold voltage is at the \u2018X\u2019 crossing of an eye diagram, and that midway between the Xs is the best sample position, while often not a poor combination of choices, may not actually be the best combination. Another way to define the degree to which a combination of sampling parameters is satisfactory is to take into account certain performance requirements of the receiver that is in use, and choose a location that offers equal margins in all directions (i.e, for both directions in each of voltage and in time). This sounds harmless enough, but can be difficult to accurately visualize, particularly if the eye diagram for the signal of interest differs significantly from an ideal or nominally correct shape.","There are various reasons for this. Consider first the matter of threshold voltage. Unlike its brother the DSO (Digital Sampling Oscilloscope) that simply digitizes a waveform and reconstructs it afterward, the Logic Analyzer relies upon a threshold comparator (often called a \u2018receiver\u2019) to decide what the logic value is. So does the SUT. The behavior of the threshold comparator\/receiver is of interest, and has an effect on margins. It is instructive to dwell on this topic for a moment.","Suppose that the threshold was one volt. Applied signals higher than one volt are reported as HIGH, while those less than one volt are reported as LOW. The threshold is supplied as an analog reference voltage, as we will assume that our one volt is as good as it gets (or at least a good as it needs to be), and remove it from consideration. However, we can ask certain embarrassing question, such as \u201cWell, what happens if the reference voltage itself is applied to the data input?\u201d It is a fair question, but one that ought never to happen as a steady state condition, since we expect the input signal to vary abruptly between two values on either side of that one volt. So, we might give an evasive answer, such as \u201cWell, you get whatever logical output that you had before . . . \u201d The next question is: \u201cSuppose an evil demon raised the input voltage to one tenth of a micro-volt above one volt. Then what?\u201d At this point we confess the existence of hysteresis, and explain that it takes a rising signal going from LOW to HIGH an extra 100 mv above the threshold to cause a change in the receiver's output, and likewise another 100 mv below the threshold for falling transitions in the other direction. So we answer that there are two thresholds, 1.10V for rising signals and 0.900V for falling signals. Then we add that these numbers are exemplary only, and that they might not even be the same for the two directions of transition.","Question: \u201cThat is all well and good, but the demon is not so easily fooled. He raises the input from below 0.900 V to one micro-volt above 1.10V. Now what?\u201d","Answer: \u201cMaybe it'll switch, and maybe it won't. There is this noise floor . . . .\u201d","Question: \u201cI see. Then how about a millivolt above the upper threshold?\u201d","Answer: \u201cIt'll probably switch, but it won't do so very quickly.\u201d","Question: \u201cHmm, you mean that there is delay from when the input actually changes to when the output has the proper value?\u201d","Answer: \u201cUnfortunately, yes.\u201d","Question: \u201cEven if the one millivolt change had a really short rise time itself?\u201d","Answer: \u201cProbably so.\u201d","Question: \u201cThis delay ends up in my measurement, and I don't like that. But I can live with it if it is well behaved, say, as a common mode effect that cancels out. I suppose then that falling signals have the same delay?\u201d","Answer: \u201cThey have a delay, but it is generally not the same as for rising signals . . . .\u201d","Question: \u201cThis is disgusting. I had no idea that comparators were so fussy. Suppose I supply more \u0394V. Will that help?\u201d","Answer: \u201cYes, especially if it has a respectable dv\/dt to go with it.\u201d","Question: \u201cAlright, you've got me at a disadvantage. My real job is hunting demons, and I've got to get on with it. What's it going to take to get good performance?\u201d","Answer: \u201cGive us at least a nice snappy 250 mv and you are in business.\u201d","Question: \u201cThat's rather pricey. Seems like a King's ransom. I suppose that for such a handsome effort there are essentially no delays?\u201d","Answer: \u201cNo, there are still delays, but they are fairly short, and what is more, they are essentially equal for both rising and falling signals.\u201d","Comment: \u201cTWO HUNDRED AND FIFTY!?\u201d","Reply: \u201cWell, this IS a published specification for production parts in commerce. We have to keep the cost under control here, since we suspect that you are secretly building a Logic Analyzer and are not interested in just one signal, and that something like sixty-four channels is more likely to be the case. Probably most of the comparators will actually work well with half that specified value, but there is no guarantee . . . .\u201d","This imaginary conversation could be repeated using the idea of a minimum pulse width that needs to be applied before the output will reliably switch from one state to the other. Half a nanosecond is a reasonable example value for minimum signal duration. So, when we consider where in an eye opening to locate sampling parameters for best Logic Analyzer operation (or more generally, for best operation of a particular data receiver in whatever kind of equipment) we ought to keep the minimum voltage excursion \u0394Vand its minimum duration \u0394Tin mind. Particularly so, if the shape of the eye opening for the applied signal is less than ideal.","Say, for example, the signals of interest arrive over transmission lines that are beset with reflections. This condition can give the eye opening a stepped contour, and to maximize the ability of the Logic Analyzer to sample correctly we may wish to deliberately move, say, the location of the sample position within the time duration of the UI. Or, perhaps the eye opening is not stepped, but is instead both sloped and not very high, or has ringing at one end. We may be tempted to slide the sample position over some to gain better access to the needed quarter of a volt or so change required by the comparator. The presence of jitter is another factor that affects the situation. But we realize that in changing the sample position we are trading increased voltage margin for a decrease in margin for pulse width. It is not so easy to tell by simple observation where the gain in one parameter's margin begins to erode the minimum margin needed for the other. This is particularly so if the eye diagram is for a pulse-type signal, or for a regular signal that has reflections, or, if for any kind of a clocked digital signal there are indicated signal occurrences for regions INTERIOR to the nominal eye opening (i.e, the signal violates the rule that the only time it is allowed to have a value between the asserted extremes is during a transition at the end\/beginning of a UI, and that those transitions should be abrupt). This last business of signal activity indicated within the nominal eye opening, when combined with different rate of margin consumption versus changes in the sampling parameters, can REALLY complicate the task of finding suitable sampling parameters.","Thus, we see that there are various issues that can arise, and that should be taken into consideration if an automated mechanism is to be reliable in its recommendation or selection of an optimum set of sampling parameters, and is to avoid being flummoxed by various extreme signal behaviors. What to do?","Overview","An eye diagram is made for a signal that is applied to a comparator whose minimum voltage excursion \u0394Vand minimum pulse width \u0394Tare known. The eye diagram data exists in an original eye diagram data structure indexed by combinations of (time, voltage) that were measured with convenient original granularities. The voltage axis of the eye diagram is re-scaled by dividing it by \u0394V, and the time axis is re-scaled by dividing it by \u0394T. This makes each axis appear as a figure of merit. The eye diagram data of the original granularities is re-sampled through interpolation techniques to new granularities where each axis has in a normalized eye diagram data structure the same number of indexed locations per unit of figure of merit. A normalized description of the eye opening of interest is obtained. According to one preferred embodiment a shape symmetric about its center is expanded about different trial centers within the normalized eye opening. The center of the largest shape that \u2018fits\u2019 is a location that represents optimum sampling parameters when mapped back into the original time and voltage coordinates. Suitable symmetric shapes include squares and circles. Discrete representational techniques akin to mechanical models are used in the main, as opposed to formal analysis pursued through trigonometry or analytic geometry. Symmetric shapes are appropriate because the normalization produces a coordinate system where a step along one axis represents the same increase or decrease in margin along that axis as does a step along the other axis. Thus the trade-off in performance between steps along the time and voltage axes is one-to-one.","According to another preferred embodiment the normalized eye opening is reduced in size by removal of successive layers of locations until only one central location remains. As before, that location represents optimum sampling parameters when mapped back into the original time and voltage coordinates.","In the case where a Logic Analyzer is connected to a System Under Test the Logic Analyzer can make the eye diagram for each signal it is sent and use the above described techniques to set sampling parameters for its own internal threshold comparators\/data receivers (since it is previously informed about the minimum voltage excursion \u0394Vand minimum pulse width \u0394Tof its own receivers).","In the case where the optimum sampling parameters are desired for a data receiver that is part of another system, the eye diagram for the signal applied to that receiver may be obtained by the use of suitable test equipment, such as a Digital Sampling Oscilloscope. The eye diagram can then be normalized according to supplied performance data (\u0394Vand \u0394T) for the receiver of interest, and the above described techniques for finding the optimum sampling parameters applied to that normalized eye diagram.","Eye Opening Identification","We shall assume that the data analysis equipment has created an eye diagram for the signal whose sampling parameters are of interest. While that eye diagram might be displayed for an operator to consider, the data analysis equipment, say, a logic analyzer, does not have a vision system and cannot simply look at the display and say \u201cHere is the eye opening that ought to be used for deciding sampling parameters.\u201d After the fashion described in the incorporated Applications, that eye diagram exists inside the data analysis equipment as entries within a data structure, and the data analysis equipment will need to proceed based upon an examination of the content of that data structure. So, we have a symbolic description of an eye diagram, and we intend to operate on an eye opening found in that diagram. The trouble is, an eye diagram can have several openings, some of which may not be genuine eye openings (they may instead be upper or lower parts of an X at the ends of an eye opening.) Our first task is to locate an actual eye opening in the eye diagram.","This may be done by picking a trial point in voltage that is at the midpoint within the observed signal swing, and at some point in time. There is no guarantee that the point in time lies within the actual eye. Locations belonging to a potential eye share the property that they have never been visited by the signal. That is, they do not lie on a boundary line that outlines the eye when the eye diagram is drawn, nor are they an inclusion within the eye (an isolated collection of one or more visited locations disconnected from the boundary and enclosed by it). If the trial location has already been visited during eye diagram data collection, then a new location in time is selected, and the process begins again. If the trial location has never been visited, then a recursive investigation finds all adjacent non-visited locations in the data structure that are related by sequences of horizontal and vertical steps (i.e., all locations within what might be an actual eye). We keep track of how many contiguous non-visited locations we discovered.","When all contiguous non-visited locations have been found, it is possible that this collection is an actual eye opening. However, it might be the case that a vertical line at the selected location in time passes through the center of an X, or nearly so. If such were the case then we may accumulate the area of a false eye (say, a region above or below an X). If any of these were the case then trial starting locations with different locations in time will eventually reveal (if it hasn't already happened) a contiguous region that is larger than one for a false eye. We continue to step across the span of the eye diagram measurement, until a suitable number of trial starting locations have been tried. At the end of this we will have discovered some number of \u2018empty\u2019 regions that are candidates for being the actual eye. So, we pick the largest of these regions if there is but one, or choose between the largest if there are more than one. Pulses have peculiar eye diagrams that need special rules, and the case where a typical signal produces an eye diagram that has a single X in the middle and two incomplete eye regions on either side also needs special rules. In each case the same special rule overcomes the problem, without interfering with the standard cases. The special rule is that the edge of the \u2018box\u2019 containing the eye diagram (i.e., at the time and voltage limits) is construed as a visited location on the eye diagram.","In any event, the discovered actual eye opening might not be accepted as such until it also passes certain other sanity tests, such as having reasonable minimum openings in time and voltage.","An alternative to the automatic discovery of an eye opening is to simply prompt the user to position the mouse pointer within the eye opening of interest and click. That would be taken as a definitive trial location whose contiguous collection of non-visited locations is THE eye opening of interest.","Normalization","An eye diagram opening as discovered above can be used to determine a set of sampling parameters by first producing a re-scaled version of the eye opening that is expressed in terms of the minimum time sensitivity \u0394Tand the minimum voltage sensitivity \u0394Vthat apply to the data receiver for which the sampling parameters are sought. (We divide the scale of the original ordinate by \u0394Vand scale of the original abscissa by \u0394T.) This amounts to a re-drawing or re-enumeration of the axes as figures of merit. However, the data for those axes is already quantized into \u2018pigeon holes\u2019 defined by the tic marks along the original axes. Those tic marks represent the granularity with which the data was actually sampled and subsequently stored. That is, we have a discrete representation of some relationship on hand, and the only way we can do anything with it directly is to honor the original granularity (degree of quantization). So, if we simply change the axes without re-quantizing the stuff they describe we will need to keep the tic marks where they were, which means that they will have some inconvenient number associated with them. (You can neither store or retrieve something from half-way or a third of the way between two consecutive addresses of an addressable structure\u2014we have no way to store in a memory of discrete locations an event that was originally quantized according to an increment along the axis that is no longer implemented.) Accordingly then, we also re-sample (by interpolation) the captured and stored data (we do not re-measure it) so that it is stored in another data structure that has, for each axis, a new (whole) number of indexable locations per unit of merit. (One might object that we have to interpolate no matter what, so why not simply leave the data stored as it is and interpolate it as needed when it is read out. Our reply is that if we interpolate it while storing it in another data structure we only have to do it once, whereas we would otherwise have to do it for each of however many read operations. Once is better. Besides, it is conceptually nicer to implement.)","What is more, we arrange that in the process of re-sampling there be THE SAME NUMBER of such interpolated locations per unit of merit along each axis. We say that this represents a \u2018normalized\u2019 eye opening. A normalized eye opening data structure has the interesting property that ANY SINGLE STEP in either axis represents the SAME DEGREE OF CHANGE with respect to the unit for those figures of merit. This gives us an easy way to cope with the task of trading off margin in one axis while keeping informed about the margin remaining for the other. We shall see that this allows us to fit symmetrical shapes such as squares and circles into the normalized eye opening to find central locations that are \u2018furthest away\u2019 from the worst margins (i.e., are the best, or safest, locations for sampling parameters).","Sampling Parameter Selection","The locations in the normalized eye opening data structure describe a \u2018normalized eye\u2019 of just the unvisited locations within the opening itself but enclosed within an imposed \u201cpicture frame\u201d perimeter of locations marked as visited (whether they really were or not!). The space between an irregular shape of the eye opening and the bounding frame is taken up with segments from the original boundary lines. In accordance with a first preferred method, each unvisited location within the normalized eye is taken as a starting location, or seed, for expanding a square that starts small and by iterations grows uniformly larger about its center (the seed) until a comparison of locations that are in or on the square with those that belong to the normalized eye reveal that the square extends beyond the normalized eye. The last iteration for which all the locations of the square are also found in the normalized eye opening data structure is the maximum size for that square, and which, it will be noted, determines a \u2018terminal area\u2019 for that square. (That rule always produces sizes that are perfect squares. An alternative is to apply one more iteration and count as the terminal area the total number of unvisited locations within that larger square. This aids in tie breaking.) The terminal area for each seed (location within the normalized eye) is recorded in a suitable data structure, and after all terminal areas have been found (a square has been expanded for each location in the normalized eye), the largest one(s) of these terminal areas are found. The associated seed(s), when converted back to the corresponding voltage and time units of the original eye diagram are then worthy of being called \u2018optimal\u2019 by virtue of being simultaneously midway between the available limits of the eye in each of the voltage and time dimensions as each is influenced by changes in the other (via the shape of the boundary). In addition, because of the normalization and the choice of a square, equal weight is given to changes in margins for variations in sample position and threshold voltage. If there should be more than one set of optimal sampling parameters discovered, it may be desirable to pick one from among those according to a set of secondary criteria.","A similar technique uses expanding circles instead of expanding squares. However, whereas the locations within a square are easily discovered within an integer Cartesian coordinate system, the locations defining the circumference a circle of increasing diameter involve some ugly compromises (stair-step pixelation) and a great deal of calculation. Instead, we settle for finding the smallest distance that each unvisited location experiences to all the visited locations in a layer bounding the eye opening (touching it) or contained within it. Among these the largest would be the largest complete circle that can be drawn in the eye. There might be more than one winning center location, and as before, secondary selection criteria can be applied.","An alternative to expanding a square or circle about the seed is to iteratively remove the outer boundary of locations in the normalized eye opening until only a single location remains. (Think of dissolving a fizzy tablet in water.) The last location that would be removed is in some real sense the center, and may be taken as an optimum location when mapped back into the original eye diagram. This operation may be accomplished in discrete layers one location deep. If the eye opening were hour glass shaped (two bulges connected by a narrow waist) the removal might easily remove the connecting waist to produce two separated bulges. This is easily accommodated without the need for special detection, and the process continues for each. Multiple potential optimum sampling locations (a plurality of simultaneous \u2018survivors\u2019) are handled according to secondary criteria, as for the expanding square and circle techniques.","The actual mechanics of these various techniques involve selecting some initial location on the edge of the normalized eye opening (for boundary finding) or within it, by inspection of its data structure. Then that location is marked as \u2018tested\u2019 or perhaps \u2018to be removed,\u2019 and a search in undertaken for adjoining locations, each of which is also marked, and so on. It is essentially an exercise in traversing the normalized eye opening data structure according to certain rules. Steering for the traverse might be aided by applied marks stored within the data structure itself, or either instead of that or in addition to that, by the use of lists to keep track of locations having certain attributes.","Alternatives","We could proceed as set out above, which might be described as Measure (an eye diagram), Identify (an eye opening), Separate (that eye opening), Normalize (the separated region) and then Process (the normalized region for some purpose, such as sampling parameter identification). Alternatively, we could Measure, Normalize (the whole eye diagram!), Identify, Separate, and then Process.","Refer now to , wherein is shown a simplified representation of an eye diagram  for a typical data signal (not itself shown) whose logical values are sampled relative to the falling edge of a reference clock signal , and for whose receiver we are interested in finding optimum sampling parameters. We include this figure, not with the expectation that anyone will be greatly surprised at what is shown there, but mostly to serve as a point of departure from which we can identify and label certain tasks and circumstances that will be of interest as we proceed. We have shown an eye diagram that contains in its middle section two complete eye openings (, ), along with a partial eye opening  on the left and a partial eye opening  on the right. We shall assume (as is usual) that the (expected) signal swing is reasonably large compared to the (vertical) voltage resolution (think: number of samples along the voltage axis\u2014granularity), so that the eye opening is high enough to be useful for the signal under consideration. We shall also assume that the time (horizontal) resolution is sufficient to reveal any interesting detail in the signal's time variant voltage behavior (again, this refer to the granularity of the samples taken). These parameters are typically under the control of the user, and we may assume that she is competent and has selected reasonable values for the measurement of the eye diagram , or that she has invoked an \u201cAUTO SCALE\u201d operation offered by the data analysis equipment, and, that it has chosen those parameters.","Also, we would prefer, although it is not absolutely necessary, that the eye diagram of interest be made using a technique that is the same as, or similar to, the one set out in the incorporated \u201cMETHOD AND APPARATUS FOR PERFORMING EYE DIAGRAM MEASUREMENTS.\u201d In any event, we do expect that the measured eye diagram data is left in a suitable eye diagram data structure so that it may be examined and variously manipulated, after the general fashion described in several of the incorporated Patents, say, \u201cFAST EYE DIAGRAM ANALYZER USED NEAREST NEIGHBOR TRAVERSE TO QUICKLY DISCOVER BASIC EYE DIAGRAMS\u201d and \u201cON-SCREEN TOOLS FOR EYE DIAGRAM MEASUREMENTS.\u201d We are not implying that any of the particular manipulations described therein are to be used in the operations to be described herein (although they might be if such were useful), only that the general manner in which such manipulations are made possible through examination and alteration of the content of a data structure containing eye diagram data is a known conventional technique, as well as being one of interest. In summary, if the eye diagram of interest is obtained according to the method taught in \u201cMETHOD AND APPARATUS FOR PERFORMING EYE DIAGRAM MEASUREMENTS\u201d then it is already represented by a suitable data structure. If it is made according to other means, then its representation may need to be converted to such a data structure, or to something that is comparable.","The actual number of eye openings represented by the eye diagram data structure (and we haven't shown the actual data structure, only a rendition of what a displayed version of its contents might look like) is more a function operator preference and of how much memory is to be devoted to that eye diagram data structure and how much time the system is to be allowed to spend filling it. Also, just as with a digital oscilloscope, the size of the acquisition record and the amount thereof displayed are often different, owing to panning and zooming selected by the operator. For our purposes, we can assume that the eye diagram  is a faithful representation of the entire content of the eye diagram data structure, and unconcern ourselves about the issues of panning and zooming.","To return to the actual eye diagram  in , besides the incomplete partial eye openings  and , it includes several \u201cfalse\u201d eye openings (, , ), such as the regions above or below the Xs (, , ), as well as voids in what appears to be the trace that outlines the various openings and that is otherwise thought to be the \u201cdiagram\u201d portion of the eye diagram. (No such voids are visible in , but there are some in .) Of course, the Xs (-) are formed by the overlapping of samples for rising and falling edges, and these Xs often convey useful information about signal behavior.","To conclude our discussion of , it will be appreciated that we plan to operate on the information represented by one of the complete eye openings, such as either  or . But first we have to find it. As mentioned in the SUMMARY, unless the user is prompted to click on one of them to give us a head start, we shall have to find it ourselves by inspection of the eye diagram data structure's content, as will be described in due course. However, before we undertake that explanation, there are some complications that we should set out ahead of time. These involve either poor hygiene within the signal's environment or signals that might be termed \u2018pulse-like,\u2019 and these complications are the subject matter of .","Turning now to , it will be noted that they each depict an eye diagram obtained from a different type of pulse waveform, as individually described by annotations in those figures. To be sure, these are not the typical eye diagrams that people think of when the consider eye diagrams, and it is doubtful if eye diagram equipment would enjoy the reputation for utility it has today if it were limited to use on such signals. What is more, these pulse-like data signals create some exceptions in the way we expect things to work concerning the automated discovery of optimum sampling parameters. However, as designers and purveyors of quality eye diagram measurement and data analysis equipment, we want to ensure that our equipment has the widest possible application, and have included some additional rules of eye diagram interpretation that we now identify. (Their utility will become clear in due course, as will an appreciation that they do not conflict with conventional eye diagram interpretation.)","A significant problem with the eye diagrams of  is that many regions that ought to have the \u2018partial\u2019 or \u2018false\u2019 status (such as in ) don't even rise to that level, owing to the lack of an enclosing boundary. It turns out that we are going to rely on the existence of a perimeter boundary that encloses a region to find such a region and its size, so the lack of such a boundary is an issue. For example, the \u2018eye diagram\u2019 of  appears to be just a \u2018square wave\u2019 trace with some voids in it. What ought to be the eye openings are not enclosed by the \u2018square wave\u2019 trace. The top of  have the same issue, except it is for enclosing regions that ought to be \u2018false\u2019 eyes.","To ward off evil during the processing that is to be described, we add the following rule: the nominal (average) limits of a signal's excursion are taken as visited locations in the eye diagram data structure. This is where the dotted lines  and  come from in . Their effect is to make regions  and  be interior regions that will be identifiable and behave like ordinary eye openings. In the same spirit we add dotted lines  and  to , respectively. We can add these to the eye diagram data structure upon being told by the user to expect pulses of one type or another, or, after an inspection of the eye diagram data itself to determine that it is necessary. A simpler way, and one that is largely free of unwanted side effects, is to add it whether it is needed or not, as would be the case for the bottom of the eye diagram of . (Or, for both the tops and bottoms of the \u2018regular\u2019 eye diagram  in , for that matter!)","Such an implementation is fairly straightforward. First, identify the voltage levels at which the \u2018dotted line\u2019 is to be added. This amounts to discovering the average values of the signal's excursions. Second, modify the data structure's content to indicate that for each location in time there has been a visitation to the cells that represent those voltages. To be sure, we have \u2018synthesized\u2019 an eye diagram that wasn't strictly speaking measured, but to do so comports with our purpose, so we proceed.","Now, while we are at this sort of thing, we might as well fix up the related issue of the unenclosed partial eye openings that arise because the extent of the eye diagram data structure is finite along the time axis. Accordingly, we add vertical dotted lines to the left and right ends of the eye diagrams. These are  on the left and  on the right for , and likewise  and  for  and  for . The eye diagram data structure is modified in much the same way for the addition of the horizontal lines: we simply mark as visited all those cells that are at the extremes of the time axis.","And, to return very briefly to , we do the same thing(s) for the data in the eye diagram data structure that represents the eye diagram . That is where the vertical dotted lines  and  come from, and what they mean. We don't show any horizontal dotted lines, as to do so would clutter the figure considerably, but you should assume that they are there (even if they are \u2018not needed\u2019 because of the nature of the signal). It doesn't hurt to put 'em in, anyway!",{"@attributes":{"id":"p-0075","num":"0074"},"figref":["FIGS. 2D and 2E","FIG. 2E"]},"Now consider the more realistic (typical, non-pulse) eye diagram  in . We shall use it as an example in describing how to find and identify the complete eye opening , which will also serve as a starting place for what to do with it once it has been found.","Our immediate goal in  is to locate and distinguish the complete eye opening  in eye diagram  from the partial ones (, ) at the ends. Recall that we have to do this by an inspection and analysis of the content of the associated eye diagram data structure, and will assume that in this case the operator has not helped us out by positioning the mouse cursor within region  and then clicking. (In response, presumably, to some prompt to do so that is provided by the controlling system, so that the system understands what such an operation means and deals with it appropriately.) By the same token, we can assume that the process we are about to describe is undertaken in response to the controlling system having been placed in some state where that process is the next task. Say, the operator clicked on a button in a user interface within the data analysis equipment that means \u201cAutomatically find optimum sampling parameters.\u201d We have not shown such a user interface, as its particulars would be outside the scope of this disclosure.","To continue, then, we examine the data in the eye diagram data structure and identify the voltage V. It can be found as a separate activity according to specified rules of interpretation (maximal excursion, minimal excursion, average excursion, time weighted average excursion, etc.), or, it can simply be the difference between what we earlier said would be the added horizontal lines for nominal excursions. The practical differences between these various choices is probably almost always very small. In any event, we find Vso that we can use V\/2 () as an offset from one end of what is used to find Vand establish a voltage level indicated by the dotted line . The idea is that the voltage level  is almost certainly well within and near the \u2018middle\u2019 of the vertical opening of an eye.","Next, we pick a series of time locations T, T, T, . . . T. The value of k is reasonable, and is arrived at by considering what time resolution was used to create the eye diagram data. Presumably, the user has selected a time resolution value that allows a gracefully displayed rendition of the eye diagram without relying too heavily on Nyquist. So we trust the user and pick the interval between the Tto be five or ten times, or perhaps thirty times, the time resolution that was used. (On the other hand, there could well be occasions where the Tare properly very dense, with perhaps T\/2 used as the step size for the T.) We have shown that Tdoes not fall right on the far left end of the eye diagram data, and moving it over some (or not) is an implementation detail. (Note also that Tdoes not fall on the far right end. To let Tand Tfall on the ends would be to waste them . . . .) The intersection of T(I varies from 1 to k, and the dotted line  moves to accommodate the current value of I) with dotted line  is indicated by a heavy cross . Cross  represents an initial trial location, of which there will eventually be k-many in number.","Now, before proceeding we wish to remind the reader that the eye diagram  of  is NOT one that need be actually rendered as a nicely displayed trace with dotted lines, a cursor and a complementary graticule within a box (although all that would be possible\u2014it simply is not necessary). We have depicted the figure in the way we have in order to help the reader better visualize what is to go on and allow the simplification of an otherwise rather messy flow chart (). In doing so we may run the risk of creating the impression that eye diagram  is DISPLAYED as depicted in . Nope; it probably is not, as the operations we are performing using this figure will be over in a very short time and before the corresponding rendered trace could even be appreciated . . . .","To continue, the plan is to engage in the investigatory process depicted in  at each of the trial locations (i.e., at the locations of cross  as I varies). Briefly, the idea is to find out if an initial trial location is at an unvisited location in the eye diagram data structure, and if it is, discover how many other such unvisited locations are horizontally or vertically contiguous with it (i.e., how large is the opening?). A record of the discovered size is kept, after which I is incremented. If the initial trial location is one that has already been visited by the signal, then we move it over by some delta T or delta V and try again, perhaps more than once; the idea being that we don't want to discard this attempt to enter the region solely because we landed on a solitary visited location (such as one of locations -). If we really have landed on a well visited region, such as Tis going to do (it hits part of an X), then we will eventually give up and increment I. (We probably needn't worry too much about missing a non-visited region, since it is likely that open regions of any size will be entered with more than one value of I, anyway.) This continues until I has been tried with a value of k. Now we look at the records kept for the size of the discovered regions of contiguous non-visited locations. The largest one wins; it is declared to be the complete eye opening of interest. If there is tie for largest, then some secondary criteria can be used to select which is chosen, although this might not be necessary, as some of these results might actually represent the same open region, reached with different values for I. If desired, the discovered regions could be checked for substantial overlap or similarity of extent in time, which would imply that they are identical and allow a reduced and non-redundant description.","With that as an introduction, consider . It is an overview flowchart  of the process of discovering the various eye openings that are associated with the sequence of initial trial locations described in connection with . We shall say that if a non-zero size is found then there is an eye opening of some sort, and will store its associated seed (initial trial location\/location) and discovered size in a table called REGION_LIST (). Size in this context means the number of horizontally and vertically contiguous non-visited locations in the eye diagram data structure that were found to include the initial trial location. The notion of \u2018contiguous\u2019 is here limited to left-right top-down adjacent and excludes diagonal locations. The reason for that can be understood from this scenario. Suppose that there were a \u2018thread\u2019 of non-visited locations that consisted entirely of diagonally related locations. Suppose also that there was a similar thread of visited locations. The two threads could cross each other without either being broken by the other. This means that a non-visited region could be inside an enclosing boundary of visited regions, pass through it and still be connected, even though part of it is now, by all common sense, outside(!). Allowing diagonal relationships to be considered is a real can of worms, and we will get perfectly reasonable answers if we exclude diagonals. So, we do just that.","The first step  in  is to flush the QUEUE  and set all locations in the eye diagram data structure to indicate a \u2018NOT CHECKED\u2019 condition. It also sets the FIND_REGION_SIZE () process to operate in the \u2018Discovery Mode\u2019 (as opposed to a \u2018Separation Mode\u2019). We shall have more to say about these modes and their use in due course.","The QUEUE is a first-in first-out list whose length is adjusted as is needed. The items in the list are initial trial locations to be checked. That is, an item in the QUEUE is a (time, voltage) pair that indexes a location in the eye diagram data structure. To flush the QUEUE is to reduce its length to just one entry that contains a value of NULL, which all using software will construe as meaning the QUEUE is empty (contains no valid entries). One end of the QUEUE is called the TOQ (Top Of Queue), while the other is called the BOQ (Bottom Of Queue). When data is added to the QUEUE it is added on at a new BOQ, making the QUEUE one entry longer than before. TOQ is the entry presented by the QUEUE for use. After it is no longer of interest it can be removed, and the entries in the QUEUE shift forward one step to produce a new TOQ, while the length of the QUEUE goes down by one. A new entry added at BOQ after it has been flushed will also become the TOQ. The QUEUE itself can be a software managed list in Read\/Write memory that is accessed by means of calls to suitable functions or subroutines, depending upon the programming environment. A QUEUE of this nature is conventional, and well known to the systems programming community, and we therefore omit further description of its internal details.","As mentioned in various ones of the incorporated Patents, an indexed location in the eye diagram data structure might (and in this case will) consist of several related individual items of information. For sure, there is an item for storing the number of HITs for the signal versus the indexing time-offset (X) and threshold voltage (Y). If that item is zero we understand that the location has not been visited; a HIT IS a visit. Another of those individual items within an indexed location is one we can use as a flag to indicate that we have \u2018CHECKED\u2019 (investigated) this indexed location for signal visits (HITs), as in \u201cfind out if the eye diagram trace has visited this location in the eye diagram . . . \u201d. Thus, one of the things step  does is clear all of the CHECKED flags in the eye diagram data structure.","That done, the next action () is to repeat a sequential pair of steps  and  k-many times, with an index I going from 1 to k. We omit any detailed flow of control details as conventional and uninteresting on the one hand, and quite dependent on the programming environment on the other. What step  does is to add an initial trial location from the environment of  onto the QUEUE at the BOQ so that it will serve as a seed for finding contiguous non-visited locations. That process will be further examined in connection with .","Step  is the invocation of a FIND_REGION_SIZE process, about which we shall have a fair amount to say in connection with . For now, it is sufficient to say that it is responsive to the TOQ to know what location to be checking for horizontally and vertically contiguous neighbors, that it is self-contained as far as such checking is concerned, and that it counts the number of contiguous non-visited and non-CHECKed locations found and records the number (and perhaps other stuff) in REGION_LIST . We may summarize the FIND_REGION_SIZE process by saying that it does not immediately follow chains of contiguous locations on its own, counting as it goes; instead, it checks the TOQ, counts it if it looks good, and then adds its (typical, or nice) neighbors to the QUEUE. Those neighbors will get checked when they reach the TOQ. (Neighbors might not be typical\u2014too near certain limits\u2014and won't be added to the QUEUE.) When those tasks are complete, it asks for the next TOQ and goes again. This repeats until TOQ is NULL, which occurs only after all eligible neighbors have been found and checked. (In general, it is not a dearth of contiguous locations that ends the process, but encounters with an enclosing boundary formed of visited locations and a limited supply of non-visited interior locations.) It is upon the imminent conclusion of the FIND_REGION_SIZE process that REGION_LIST gets its next entry. At this location an instance of the process  is complete, and control is again assumed by the FOR I=1 TO k construct of step  (i.e., steps  and  may be re-invoked for the next value of I).","The final step in the simplified flow chart  is step , where the largest entry (open region) is selected from among the entries placed into REGION_LIST. This selected open region is the one we will use to discover the optimal sampling parameters (a task described in due course and in connection with subsequent figures).","It will thus be appreciated that  describes a mechanism for applying the process of  that might be described as quasi-recursive, or automatically iterative. It is not a genuinely recursive arrangement because the process  never calls itself, and (as shown by the flow of control in ) is not written in a re-entrant manner. It could be, though, if that degree of elegance were highly valued. In this implementation, however, the QUEUE bears the burden of storing up the nested circumstances that would otherwise be the substance of the recursion.","We now consider the simplified flow chart  of . It describes the task of putting an initial trial location into the QUEUE. This seemingly straightforward task has a exception case that must be dealt with: what happens if the initial trial location is not a non-visited location? It turns out that if we added such a location to the QUEUE it would not crash the process: such is likely to happen anyway (recall Tin ). But suppose such a previously visited initial trial location were a solitary location, or a member of a just a small cluster of visited locations. Why waste an attempted instance of Ton account of that? The same question arises if it turns out that the supplied initial trial location has already been marked as CHECKed. Well, we try not to waste it, and if qualifier  determines that the originally provided initial trial location is indeed already been visited or CHECKed, it transfers control to loop  that identifies close neighbors of that already visited or CHECKed location. Each next close neighbor, in some order, is checked for being either already visited or previously checked (qualifiers  and ). As soon as one is found a NO result at qualifier  leads to step  where that neighbor is taken in place of the originally supplied location, and is then added onto the QUEUE as a new BOQ. No further close neighbors need (or should) be considered: one replacement is sufficient (and safe\u2014we don't want to start a region search with two seeds in the QUEUE that might be in different regions . . . !!). On the other hand, if qualifier  determined that the original (T, V) is both not visited and not CHECKed, then step  adds it to the QUEUE as a new BOQ. In either case the next step is the FIND_REGION_SIZE process , which is the subject matter of .","Now peruse the flow chart  of . It describes the FIND_REGION_SIZE process step  of , and is not as bad as it looks. It begins at step  with setting a variable REGION_SIZE to zero. REGION_SIZE is used to accumulate the number of horizontally and vertically contiguous non-visited locations that are found in a region whose seed is the initial trial location supplied from . The seed (TOQ) is also saved for future use.","Following step , qualifier  asks if the TOQ is NULL. Initially it normally won't be, because the process was entered with an actual seed (initial trial location, or location). However, there is a corner case where  fails to find a non-visited seed, and enters FIND_REGION_SIZE with TOQ being NULL. This hurts nothing, and the result is to simply exit the process. So we normally expect an initial NO at qualifier , and branch to qualifier , where we ask if the TOQ location is one that has already been CHECKed. If it has, we wish to skip it and go to the next entry in the QUEUE. This is done by branching to step , where the QUEUE is shifted forward one entry to produce a new TOQ. We treat this as if it were a new seed, by returning to qualifier . On the other hand, if the answer is NO at qualifier , then we need to find out if that location has already been visited. This is checked with qualifier , and if the answer is YES, we typically discard this location also by a subsequent \u2018NO\u2019 branch through qualifier  (TOQ's location has been \u2018frequently\u2019 visited) to step  (just as for the case where the TOQ's location was CHECKed). If, however, the location for the TOQ is one that has been infrequently visited, then we can at qualifier  treat it as if it were actually non-visited. Say, for example, a location records two or three HITs out of 500,000 or so clock cycles. The idea is for qualifier  to effectively ask \u201cIs the \u2018density\u2019 or the actual number of HITs less than or equal to some threshold?\u201d The notion of density is set out in the incorporated Applications, and is a ratio of HITs to trials. For either method, a threshold of zero would enforce a strict standard of \u201cnon-visited means NO visits whatsoever!\u201d while a positive non-zero number (either an integer or a fractional density) would allow a more lenient standard by allowing the YES branch of qualifier  to produce the same result as the NO branch from qualifier . Any other result at qualifier  allows the YES branch from qualifier  to lead directly to step . It will be appreciated that the ability to set a threshold for qualifier  allows infrequently occurring embedded HITs within an eye opening to be ignored, as well as infrequently occurring HITs around the border of the eye opening.","The usual significance of a NO answer at qualifier  (or a YES at qualifier ) is that the location indexed by TOQ is a non-visited and non-CHECKed location that is also contiguous with (or else it would not have been in the QUEUE!!) the seed with which this instance of the process  was entered. (Note also that the initial entry seed gets here, too, and needs to be counted, even though it might turn out that it is not contiguous with any other locations!\u2014That is, there will be no further entries added to the QUEUE.) Under these conditions we need to increment REGION_SIZE to record this event, which is accomplished at step (for the \u2018Discovery Mode\u2019).","\u201cNow,\u201d you ask, \u201cjust how is it that a supply of subsequent-to-the-seed contiguous locations GOT INTO the QUEUE in the first place?!\u201d Well, that comes next.","Recall that we went to some trouble to make sure the initial seed upon entry was both not visited and not CHECKed. So we can expect IT to drop though to step The next section of the flow chart finds the four (above, below, left, right) locations that are contiguous to the present TOQ. Given the nature of the checks we just went through to get to step it would basically not matter if those four locations were CHECKed or not, or visited nor not; we would add them to the QUEUE as candidates to be investigated. One the other hand, there are issues related to the TOQ location being close to the eye opening limits, and also, there is no purpose in putting a location into the QUEUE that is known to be a left or right scan limit, and in fact, we would like, as mentioned earlier, to treat those locations as marked visited (whether they actually are, or not), so as to \u2018close off\u2019 the end of an otherwise open partial eye.","We address these issues as follows. Step  will always add to the QUEUE at new BOQs the vertically above and vertically below contiguous neighbors to the location corresponding to the TOQ. We can always do this, since the initial seed was not at a limit, and any subsequent replacement TOQ has just been checked (at ) for having been visited\u2014so we won't be crossing into a boundary by adding a neighbor to a location already on the boundary, which would be bad. (And, if a location we are adding at step  is the perimeter of a boundary, it is already marked as visited and will eventually be discarded by qualifier , and its neighbors will not be added.) The outcome of all this reasoning is that it is always safe to add vertical contiguous neighbors to a location that has just been counted. They are only potential contributors, and when their turn at TOQ comes they will not be counted if they are not part of the interior of the eye diagram. They should be added to the QUEUE so that they DO get investigated.","What remains, then, is to add to the QUEUE the horizontally left and right contiguous neighbors. In a preferred implementation we do not do this without some further qualification. To appreciate the rationale for qualifiers  and , return briefly to  and notice the \u2018hole\u2019  in the bottom of the eye opening boundary. It leads into a long thin horizontal open region . The question is: \u201cShould open region  be construed as part of the eye opening ?\u201d This case might not be so bad if there were limits on how goofy an eye diagram could get. But cases have been observed where a region such as  even extends under the Xs!! And, there are the various pulse-type signals: their eye diagrams can contain this sort of mischief in abundance. Thus, on balance, in a preferred embodiment we exclude locations in regions like  from being counted as belonging to a central eye opening, such as region . So now the question becomes: \u201cOKAY, how DO we exclude such mischief??\u201d","The solution is to decline to add the horizontal contiguous neighbors to a location that is too close to an upper or lower edge of the present eye opening. That exact criteria is perhaps a bit difficult to implement, but we can approximate it by testing to see if the TOQ location is \u2018too close\u2019 to the previously observed upper and lower eye limits shown in . The condition \u2018too close\u2019 could be, say, within five or ten percent of V(). Qualifiers  and  check for that \u2018too close\u2019 condition, and if it is met, branch around the addition of horizontal neighbors to the QUEUE. So, the vertical projection of a hole such as  will get into the QUEUE and will get counted as part of opening , but not the horizontal portions on either side that are the bulk of region .","Qualifiers  and  deal with the cases where the TOQ location is on a horizontal scan limit boundary. If it is on the far left, then it is still proper to add to the QUEUE a horizontal neighbor to the right, or one on the left if on the far right boundary. These additions are performed by steps  and , respectively.","If the answer to all of the qualifiers , ,  and  is NO, then none of the worrisome conditions are present, and it is safe to add both the left and right horizontal neighbors to the TOQ location. That is done with step .","Subsequent to a YES answer at either of qualifiers  or , steps ,  or , the next step is the optional one of updating a record of the furthest leftward and rightward excursions represented by all of the TOQ locations experienced so far. This optional information is not critical for identifying and sizing an eye opening, but may be useful in subsequent processing.","Finally, step  is reached, where the next TOQ is obtained, and the process continues as described until TOQ equals NULL, whereupon qualifier  will branch to step If the FIND_REGION_SIZE process is in the \u2018Discovery Mode\u2019, then at step the seed we started with, the count in REGION_SIZE (and any optional furthest excursions) are written to REGION_LIST, otherwise these things are not written and REGION_LIST is left undisturbed. After that, or if instead the \u2018Separation Mode\u2019 is in effect, the process exits back to its calling environment.","After the activities of  have been accomplished we can decide which seed (initial trial location) produced the eye opening we are interested in. Repeatedly running the FIND_REGION_SIZE process in the \u2018Discovery Mode\u2019 with the various T(different seeds), as was just described, allows us to decide which seed produced the largest opening. If that largest opening passes any other desired tests, then we can declare that to be the eye opening of interest that is to be used for choosing optimum sampling parameters. However, the overall eye diagram data structure we have been investigating remains a merger of all openings, and we don't have that selected eye opening available as an isolated collection of separately identified locations. To get that, and advance toward further processing of that data is what the \u2018Separation Mode\u2019 of the FIND_REGION_SIZE process is for.","If the FIND_REGION_SIZE process is being operated in the \u2018Separation Mode\u2019 then step will be executed in place of step and will un-MARK the appropriate locations (for the various TOQs) in a previously fully MARKed eye opening data structure (very similar to the eye diagram data structure, perhaps even identical to it). The intent is for FIND_REGION_SIZE to unload (remove from) an eye-diagram-like data structure MARKs so as to leave only those MARKs that indicate the boundary for the region that is the selected eye opening. To look ahead, the \u2018Separation Mode\u2019 will do just that if we run it one time while re-using the seed associated with the selected eye opening. If we can make the selection, the REGION_LIST table () will give us back the seed to use so that FIND_REGION_SIZE (now in the \u2018Separation Mode\u2019) will re-traverse the eye diagram data structure exactly as it did before (visiting all the locations in the selected region), while un-MARKing a MARKed copy of the data structure instead of counting up contiguous locations. The result is an eye opening data structure that contains only the un-MARKed eye opening of interest surrounded by MARKs defining its boundary (and, of course, retaining any MARKed inclusions within the un-MARKed eye).","The activities of the preceding two paragraphs are the subject matter of the flow chart  in . At step  (essentially the same as step  in ) a region is selected from REGION_LIST (). This selection may be a simple as finding the largest region size, or may also involve secondary criteria, say, involving shape or limits in voltage. For reasonably well behaved typical signals it is often sufficient to simply take the region that has the largest size. In any event, once the region has been selected we take note of the seed that is associated with it. This is easily done from a simple inspection of the content of REGION_LIST (that's what tables are for . . . ).","At step  the QUEUE  is flushed and all locations in the eye diagram data structure are again set to \u2018NOT CHECKED\u2019 (just as was done at step  of , and with essentially the same intent). This time, however, we set the FIND_REGION_SIZE process to operate in the \u2018Separation Mode\u2019 in anticipation of extracting the region selected in step  and copying it (and only it!) in isolation into an eye opening data structure ().","At step  all locations in the eye opening data structure are set to \u2018MARKED\u2019 in anticipation of the copying that will be performed by FIND REGION_SIZE. The pattern of MARKS removed during the \u2018Separation Mode\u2019 will define the copied region.","At step  the seed noted above in connection with step  (i.e., the one associated with the selected eye opening region) is placed onto the bottom of the QUEUE. Now all that remains is to re-invoke FIND_REGION_SIZE and await its finish; it will re-traverse the eye diagram data structure exactly as it did before for the instance that produced the region size selected in step . When its run is complete the eye opening data structure  will contain a pattern of marks that corresponds to the boundary of the selected eye opening. It is that (now un-MARKed) eye opening data structure that will now be normalized to produce a normalized eye opening data structure, which in turn will be used to find an optimal set of sampling parameters.","With that in mind, consider the eye diagram illustration  of . The enclosing rectangle  represents the limits of the values that index the eye diagram data structure that contains the data for eye diagram . The eye diagram portion itself  and its eye openings - bear a strong resemblance to  that is intentional, although not necessary. We shall assume that the count associated with open region  is unambiguously larger than those for either of partial eye openings  and , and that the open region  has been designated as the selected eye opening of interest (i.e., it was the one selected from the table REGION_LIST) and that will subsequently be extracted into an eye opening data structure by a use of the FIND_REGION_SIZE process in the \u2018Separation Mode.\u2019 Note also the four \u201clocations\u201d - that are included within the eye opening . These each represent a contiguous region of one or more locations that had HITs. We don't know what the shape of the regions are (i.e., if they are clusters of a plurality of contiguous locations), and that does not matter at this time. We shall assume that the \u2018threshold of visitation\u2019 check performed by qualifier  in  is enabled by some non-zero threshold, so that location(s)  are construed as \u2018never visited\u2019 for purposes of extracting eye opening  and finding an optimum set of sampling parameters.","Now on to . It has the same enclosing rectangle , which is to be understood as it was in . We see a pattern  of small dots that fill the outline of the eye diagram opening  of . We are representing with those dots the locations that are to be extracted. The scale of these dots in pattern  (their horizontal and vertical granularity) is the actual horizontal time quantization and vertical voltage quantization that were used to make a trial eye diagram measurement whose results will be used to find optimum sampling parameters. We shall assume that the horizontal and vertical sensitivities that were used to make  were arrived at through an AUTO SCALE operation or informed operator choice concerning his understanding of the circumstances surrounding the measurement of his signal and the amount of time and memory that can be devoted to the task.","The normalization process is going to re-scale the axes as figures of merit and also re-sample the pattern  of dots into data for a different data structure, as if they had been sampled with different measurement granularities in the first instance. This will be accomplished without an actual second measurement, and will instead involve interpolation upon the data that was measured. Not only that, but we will pick the ratio of the re-sampling in one axis to that of the other so that they each have the same number n of indexable locations per unit of figure of merit, and that n is reasonable: it is neither too small or too large.","Presumably, the original eye diagram measurement (not to be confused with a displayed rendering) was suitably scaled to begin with, so that it had at least a sufficiently dense granularity for good resolution without incurring unnecessary overhead associated with taking and storing results for an excessive number of sampled locations. So, for example, we might expect that there are at least twenty sampled locations along the voltage axis, but probably not more than eighty. The exact number is not a critical issue; the bound for lower numbers of samples is that which retains resolution sufficient to not conceal behavior of interest, while the bound for higher numbers is cost in time and resources. A similar set of observations (with different numbers) applies to the time axis. We note that, while the normalization process will change the manner in which the totality of the stored data is represented, it doesn't particularly change its meaning, if at all. So, if the original measurement had satisfactory granularity, then if we are reasonably careful, the normalized version will, too. This idea is both of interest and comforting to us, since we have declared our intention to fiddle with the normalized representation so that it has n-many indexable steps per unit of figure of merit along each axis.","We first re-scale the two axes by dividing the measuring interval along the voltage axis by \u0394Vand the measuring intervals along the time axis by \u0394T. This re-casts the ordinate (voltage) axis as a Voltage Figure of Merit axis, and the abscissa (time) axis as a Time Figure of Merit axis. In this view of things an eye opening that was one unit high would be one that is of the minimum acceptable V. One that is four units high is more desirable because it has four times the voltage margin. Similar observations apply for extent of duration in the other re-scaled axis. However, it will be appreciated that the new tic marks (for, say, one unit of Figure of Merit, or nice subdivisions thereof such as \u00bd, \u00bc or 1\/10) probably will not correspond to existing addressable location in the data structure.","Once the divisions have been done we can reason as follows. The voltage axis used to have (say, for example) fifty sampled locations over five volts. That's ten sampled locations per volt, or one hundred millivolts per step along the voltage axis fo the data structure. Let's assume that \u0394Vis 250 mv, so the new axis is labeled as twenty units of Voltage Figure of Merit. That's fifty samples for twenty units, or two and a half samples per unit. Clearly, the new tic marks for the re-scaled axis do not align with the existing addressable locations of the data structure. (And these are fairly \u2018nice\u2019 numbers\u2014suppose that \u0394Vwere a really arbitrary number, such as 287 mv . . . .)","Let us further suppose that the corresponding situation for the time axis results in six and a quarter samples per unit of merit. Now what? Well, we re-sample them each to have, say, eight or ten samples per unit of merit. As we will see in connection with , this \u2018breaks big regions into little ones\u2019 with easy rules of inference about how to apportion value or other attributes. What we don't want to do is to go the other direction in granularity, where \u2018little regions are combined into big ones,\u2019 and rules about attribution of properties become muddled. The actual number (n) of steps or locations per unit of figure of merit is otherwise somewhat arbitrary, and is affected by our sense of what is convenient.","Upon reflection, we see that re-scaling provides Voltage and Time Figures of Merit that are commensurable in that their units can be compared with the expectation that each represents the same degree of alteration in margins. We needn't do that comparison at the \u2018whole unit\u2019 level; half-units, quarter units, tenths or any other convenient subdivision is possible and appropriate. It could as easily be an ordinarily odd amount, such as 1\/7 or 1\/9 of a whole unit. However, to avoid the need for continual and ongoing interpolation, once the desired granularity is chosen we re-sample the data in the original data structure so that when it is stored in a new one it is addressed in steps corresponding to that chosen new granularity. We also ensure that we use the same degree of new granularity in both axes. The new granularity could be the denser of the two original granularities of the original axes.","When we say that the eye diagram opening has been \u2018normalized\u2019 we shall mean that the resulting axes are expressed in units that have been selected as just said. In the process; it would still be \u2018normalization\u2019 whether the granularity of the new representation went up, down some, or stayed about the same. But for the case of picking sampling parameters it makes sense to either increase the resolution in both axes, or at least not decrease it.","In  we depict a normalized eye opening data structure  that is shown as being within the extent (, ) of an original eye diagram data structure . The figure shows that the data structure used to store the normalized eye opening data is smaller than the one used to store the overall eye diagram of which is a part (which, frankly, is what we would expect!). Note also that normalized data structure  is rectangular, with axes that are parallel to those of the larger data structure . The size of the smaller normalized data structure  has been selected to be no bigger than (or at least not much bigger than) what is needed to contain its discovered content plus an extra surrounding layer of locations (a \u201cpicture frame\u201d) that are MARKed as visited. The Left and Right Extreme data in the table REGION_LIST can of assistance in setting the size of the normalized eye opening data structure; that data gives the size of a data structure that would be needed to contain the extracted un-normalized eye opening. That information, combined with advance knowledge of how each axis is to be re-scaled and re-sampled to achieve normalization, will closely predict the size needed for the normalized eye opening data structure.","In  the medium density down-and-to-the-right cross hatching  indicates the discovered, separated, (either normalized, or soon to be normalized) and re-copied eye opening region. The denser up-and-to-the-right hatching represents the difference between the extent of the indexing for the eye opening data structure and the eye opening itself, and clearly includes in the figure a complete layer of marked-as-visited locations around the eye opening. We shall have more to say about this, later. Note also that the up-and-to-right hatching also denotes the included interior regions (- of ). They are indicated within the data structure by the same mechanism as the \u2018boundary\u2019: a MARKed location. Finally, the down-and-to-the-right wide hatching simply represents the \u2018difference\u2019 between the eye opening data structure () and the original eye diagram data structure .","The normalized eye opening data structure  has a locating position within the larger eye diagram data structure  that is described by the offsets  and . In this way (and in conjunction with knowing the scale factor\/units change accompanying normalization) a location that is found to be of interest within the eye opening can have its location described in terms of the larger eye diagram data structure. That is, it will be possible to treat the normalized eye diagram data structure as an isolated entity with its own indexing arrangement detached from anything else (say, it is indexed by simple integers in X and Y, with n-many counts per unit of figure of merit) and still correctly map locations found in the smaller and simpler \u201cinterior\u201d data structure for the normalized eye opening back into the coordinate system for the overall eye diagram.","It is appropriate at this point to ward off a misconception that might arise from considering . Namely, that we can arrive at a description of the eye opening (whether normalized or not) simply by drawing the right rectangle around a subset of the content of the overall data structure, and then take that subset as the eye opening. If eye diagrams and their eye openings were always very well behaved there might be some hope for this view. But the reader is reminded of the discovery and extraction process that was described in connection with . That process finds contiguous locations that have not been (or have seldom been) visited, and that collection is NOT obliged to neatly fill some rectangle. It is true we can enclose it in one, as we have shown. But that rectangle is arrived at after the fact, as it were, and even if it were known at the outset, would be of minimal value. That is because the irregular shape of the eye opening means that the rectangle contains locations that are other than the non-visited ones, and we don' t know which ones THEY are until we find the collection that is the non-visited locations. Furthermore, owing to the peculiar shape that eye diagrams can posses, the eye opening discovery process needs to follow rather special rules based on the contiguous property, which also compels us to find the contiguous locations first, and then say \u201cWell, we've found the contiguous non-visited locations, put them into a separate rectangular arrangement, and then identify them to indicate which ones they are. The non-identified ones are not part of the eye opening, even though they are inside the rectangular arrangement.\u201d It just so happens that we have arranged for \u2018not visited\u2019 to map into removal of MARKs within a field of a previously applied MARKs. This effectively replicates the eye opening, while suppressing any information about the enclosing exterior boundary (or an included interior boundary!), save for its shape where it touches the eye opening. So, the reader is urged not to be fooled by the tidy view of things that might be seen in  (e.g., copying a portion of the original within a rectangular template), and remember why we went through all the trouble of .","Now, before passing to a description of the use to which we plan to put the normalized eye opening data structure, we digress briefly to present a short discussion of re-sampling.","Refer now to , and notice the coordinate system formed by the heavy lines. Heavy line  can be taken as an original abscissa, while heavy line  can be taken as an original ordinate. In this example, originally measured data was obtained according to this coordinate system. In an eye diagram setting this means that cells in the original eye opening data structure, such as , contain measured data values describing measured events, of which a number of observed HITs is an example.","In the figure the cells for the coordinate system of the heavy lines have an aspect ratio of about seven wide to five high. If one were drawing this on graph paper and were told that each cell represented seven nanoseconds by five millivolts, this would seem perfectly natural. Of course, nothing says that the actual unit of physical distance along the graph's abscissa per unit of time has to equal the unit of physical distance for the ordinate per unit of voltage; such relationships are selected to be convenient. Accordingly, we place no special significance on the size of the cells formed by the heavy lines, other than to note that, whatever it is, it is a point of departure.","Superimposed on the heavy original coordinate system is one rendered with lighter lines and having a smaller cell size. The smaller cell size corresponds to an increase in resolution, and comports with our plan for finding optimal sampling parameters; the normalization we are about to describe could actually result in larger cells and a decrease in resolution if that were desired (which would be inappropriate for our case). The different smaller cells have been indicated by re-sampled axes  and . The aspect ratio of the re-sampled cells is three wide by four high. This time this idea matters, because what we mean is that the width of a re-sampled cell is 3\/7 that of an original one, independent of how wide they are actually drawn. Likewise, the height of a re-sampled cell is \u2158 that of an original cell. The selection of 3\/7 and \u2158 is driven by what is needed to convert original data taken in an original measurement into re-sampled data that would have been obtained if the measurement were performed over again with different instrument parameters, and in this example those ratios are fanciful, and were selected for ease of illustration.","To continue, we have more tasks on our plate than simply deciding what new coordinates go with what old ones (re-scaling). There is the matter of the quantized measured data stored in the original cells. Since we are not re-measuring to get new data, we have to divide and apportion (re-sample) the old data content of the original cells into the appropriate cells of the new coordinate system. So, for example, note that new cell  is entirely contained within old cell . The implication is that if old cell  had previously been marked as a visited location, then new cell  ought to be marked as visited, also. Indeed, any other new cell adjacent to new cell  that has a non-zero portion lying within old cell  ought to be considered for being marked as visited, also. So, for example, we could pursue a strategy similar to rounding, and mark a new cell only if half or more of it lay within an old cell marked as visited. Or, we could mark for any amount of non-zero overlap, or, require complete overlap.","A related set of circumstances surrounds new cell . It lies partly within each of old cells -. If any one of old cells - is marked as visited, then we need to consider whether to mark new cell .","There is some flexibility in what the rules for marking the new cells are. We prefer these: Since each new cell is smaller or at least not larger in each dimension than each old cell, we adopt the simple rule that content or attribute of the new cell is copied from that of the old cell containing the center of the new cell. If the center falls on a boundary between two old cells, we pick the old cell to the right (or above) the boundary. If the center falls on the intersection of four old cells, we pick the old cell to the upper right of the center.","Those who are familiar with systems that manipulate digitally stored and displayed graphic images will appreciate that the operations described above are similar to and related to those used for processing graphic images. Display and printing of digital photographs, scalable fonts and the resizing of windows and their content in a computer's display all come to mind, as there is a substantial body of related art for this business that we have called \u2018re-sampling.\u2019 Indeed, even in the prior art for eye diagrams, this re-sizing issue for the representation and display of eye diagrams has been addressed. So, for example, the incorporated \u201cCOMPOSITE EYE DIAGRAMS\u201d includes a concluding Appendix that describes useful eye diagram data structure forms, and at Step Three and at Step Four, describes pseudo code for a re-sizing operation in more than one axis and with selectable scale factors, that converts data in one data structure to re-sampled data in another, while correctly distributing an attribute recorded in a source cell (such as number of HITs) to one or more destination cells, and, allow one or more source cells to contribute to a destination cell. In that environment different values for a cell's attribute(s) might result in a different color or intensity (or variation in some other displayed property) at the location in the displayed diagram that corresponds to the cell.","Returning now to our main topic, and with some reflection, we arrive at the following conclusion. First, we could proceed as we have been explaining for the bulk of this description, which might be described as Measure (an eye diagram), Identify (an eye opening), Separate (that eye opening), Normalize (the separated region) and then Process (the normalized region for some purpose). Alternatively, we could Measure, Normalize (the whole eye diagram!), Identify, Separate, and then Process.  is a pair of simplified flow diagrams that illustrate these alternatives.","The two alternatives differ in the location of the normalization step, and in what information it can be expected to preserve. In the first alternative, only an extracted part of the eye diagram is being normalized and we really only need to preserve the notion of VISITED (i.e., MARKed as having been visited). Some fairly simple rules will implement this. In the second alternative we are normalizing the entire eye diagram to be as if it were measured that way to begin with, and must preserve and re-distribute the scalar influence of the counted HITs\u2014which is more complex than simply not allowing a VISITED mark to accidently disappear. Fortunately, if this second alternative is attractive for other reasons (things having to do with collections of normalized eye diagrams?), then \u201cCOMPOSITE EYE DIAGRAMS\u201d shows how to re-sample the data in one eye diagram data structure into another without losing the meaning of the measured data. Of course, \u201cCOMPOSITE EYE DIAGRAMS\u201d construes this as generalized re-sampling, and not as normalization for a particular set of measurement instrument parameters. However, if those parameters were considered as we teach herein, then the re-sampling of \u201cCOMPOSITE EYE DIAGRAMS\u201d could, given the right re-scaling ahead of time, accomplish for an entire eye diagram what we have been calling \u2018normalization.\u2019 It will be appreciated, however, that \u201cCOMPOSITE EYE DIAGRAMS\u201d does not deal with issues concerning eye opening identification and extraction.","For both alternatives, each flow chart ends with the same two steps,  and . Step  ensures that there is an outer layer of marked-as-visited locations along the perimeter of the normalized eye opening data structure. That is, for extreme values of either index (X or Y), the indexed location will be read as MARKed. We will shortly give the reason for this.","Step , \u2018PROCESS EXTRACTED REGION\u2019 is whatever algorithmic operations are carried out on the extracted and normalized eye opening. What we are interested in for this disclosure is finding optimal sampling parameters. There might be other reasons for finding a normalized eye opening.","In any event, we are shortly to begin an explanation of how to find optimal sampling parameters for a data receiver, and that task will involve the use of some programmatic mechanisms that \u2018walk\u2019 the data structure. Such traverses will be seen as algorithmic in nature, and the steering mechanisms are often based on whether an indexed location is MARKed or not. There are many instances of altering the indices X and Y and operating on the addressed value. In general, the maximum value for each of X and Y varies from one instance of the data structure to the next. The (many!) mechanisms that alter X and Y could take this into account (\u2018boundary checking\u2019), as could the operations that discover and steer based on the content of the addressed locations, so as to properly deal with cases where one or both of an attempted X and Y are outside their defined range. In general, we would like such a case to return the value MARKed, but that is much easier said than coded. It is not that it can't be done, but it is considerably simpler to ensure that there is an enclosing boundary of MARKs all the way around the un-MARKed eye opening region, and then steer the traverse on the presence or absence of a MARK, with the assurance that the traverse will never generate an (X, Y) address that \u2018falls off the edge of the universe\u2019 (and into adjacent locations in memory not part of the plan). THAT is the major rationale for steps .","And so we arrive at , which is a fanciful representation  of a normalized eye opening data structure, populated as if for the examples of . It consists of an array of squares that are the elements of the data structure. The empty squares denote the condition NOT MARKED AS VISITED, while the squares containing Xs do denote locations that are MARKed as VISITED. The lower lefthand corner of the array may be taken as an origin, and we may also assume that it is sufficient to simply identify a square (i.e., an element in the data structure) with an (x, y) pair of integers beginning at (1, 1). The value of an indexed element will either be NULL or MARK. Note also that, per steps , there is an unbroken boundary of MARKed locations all along the \u2018perimeter\u2019 of the data structure .","Concerning a related matter, we have often mentioned, and will continue to do so, the data structures we are interested in are all indexed by X and Y. In some cases we expect an indexed location to yield a measured data value, such as the number of HITs or the number of cycles over which a measurement was performed. At other times we expect an indication of MARKed or otherwise. Before we are finished we shall have occasion to describe other indicators whose values vary according to (X, Y) and that are stored in a data structure. It is a matter of programming convenience and design preference whether these mechanisms are implemented as actual different data structures or as different \u2018planes\u2019 in a larger structure. In some programming environments the different planes are thought of as additional dimensions (e.g., X, Y, and Z instead of just X and Y), and the value of Z selects between, say, measured data and housekeeping stuff related to MARKed or not. In more modern environments named arrays indexed by (X, Y) or other pointers are simply used as building blocks combined with other named structures to fashion an appropriate overall arrangement where all the names are suggestive and the data types are appropriate to the task. All these things are well within the province of conventional software engineering, and we shall mostly content ourselves with setting out the algorithmic content of the tasks we have yet to describe, while leaving the details for any particular implementation free to vary as may be needed. Accordingly, in some implementations we might find one larger data structure that encompasses all aspects of measured data storage, eye opening identification, extraction and normalization, as well as navigation flags for the overhead of the various traverses of the structure. On the other hand, in other implementations we might find two or more smaller data structures that are created independently, but whose management and operation are coordinated as part of an overall algorithmic purpose. And, of course, the details of just how the content of a location indexed by (X, Y) is understood as meaning MARKed (or any of some other conditions we shall mention below) is also principally a matter of programming convenience.","In accordance with the discussion of , the populated normalized eye opening data structure  of  could have been arrived at in either of two ways: Measure, Identify, Separate, Normalize; or, Measure, Normalize, Identify, Separate. In either case we arrive at , and now begin with subsequent figures the discussion of how to use such a populated data structure for a normalized eye opening in the task of finding optimized sampling parameters.",{"@attributes":{"id":"p-0138","num":"0137"},"figref":"FIG. 10"},"Pseudo code for the inflation of a square about a seed will be found in APPENDIX \u201cA.\u201d  shows that a seed  (located, for example, in the lower right-hand corner of the normalized eye opening of ) is surrounded by successive layers of additional locations - until the newest of those () includes some locations (, ) that are MARKed. The size of the resulting inflated square can then be recorded as either four complete layers over the seed, or, as eighty-one locations, or perhaps as five layers (one hundred twenty-one locations) diminished by two MARKED locations (, ) in the last layer attempted, for a metric of one hundred nineteen. This latter idea is what the pseudo code in APPENDIX \u201cA\u201d supports.",{"@attributes":{"id":"p-0140","num":"0139"},"figref":["FIG. 11","FIG. 11","FIG. 10"],"b":["108","115"]},"Between the two techniques ( versus ) it might be said that the inflated square of  provides a more graded outcome that is free of asymmetries and lends itself to comparison with other similar measurements, while the spiral square of  is \u2018more abrupt\u2019 in discovering its answer, but sensitive to an asymmetry related to the direction taken to begin the spiral. That is, depending upon the relative locations of the seed and the \u2018obstruction\u2019 that stops the spiral, a greater or lesser portion of the first inner layer of the spiral may contribute to shifting the spiral toward or away from the obstruction. So in the example of , if the initial direction were one step to the left in X instead of one step to the right, the spiral is shifted to the left and down, and a total of one hundred twenty locations are recorded (compared to ninety for before). On balance, we prefer the inflating square over the advancing spiral because of this symmetry issue (or sensitivity to an un-related initial choice), although in practice the difference in outcome may not be particularly significant.","Now consider a somewhat different approach. In , and in conjunction with the flowchart of  and the pseudo code of APPENDIX \u201cC,\u201d we find the largest circle(s) that will fit into the selected eye opening. To do this we first develop a BOUNDARY_LIST that encloses the eye, or that surrounds locations interior to the eye (, , ). The principal requirement for being on the BOUNDARY_LIST is that a location be both MARKed and strongly (left, right, up, down only) adjacent to an un-MARKed location within the eye. The order of the entries in the BOUNDARY_LIST is not important. This process is described as steps  and  in the flowchart  of . A related process of steps  and  adds the locations of the eye opening to an INSIDE_LIST (order is again not important).","Referring now to , (same example seed and eye opening as for ), seed  has its distance (distance squared\u2014d\u2014actually, since we don't really need d and can avoid taking the square root) computed for each member  of the BOUNDARY_LIST. In the figure these are various \u2018radius lines\u2019 -. Of these,  is a longer one, and clearly does not belong to a largest successful circle (because there are shorter radius lines that belong to location that would interfere by being within such a large circle!). Line  is shorter than line , but still too long for the same reason. Line  is a nice short line, but still longer than line . It would appear that line  is the shortest, and that it belongs to the largest circle that can be drawn around seed location . (As an aside, the circularly spaced dots around seed  are not part of any circle we are considering\u2014they are more in the nature of an ellipsis indicating that we have not depicted each and every radius line. The figure is busy enough, as it is.) As part of step  of flowchart  we add the length (squared) of this shortest radius () and its seed (the X-Y pair associated with location ) to a CENTERS_LIST. Then (still as part of step ) we try a different seed, and add its largest circle to the list. After all the seeds have been tried we have a list of largest possible circles and their associated seeds. All things being equal (and sometimes they are not), we are inclined to take the largest one (step ).","The largest circle algorithm has an interesting property that allows us to dispense with normalization if we so choose. Suppose that we knew that the margin in applied pulse width were three times that of applied voltage excursion. We can modify the distance formula used to find dto reflect this, essentially to compute distances (squared) within an ellipse instead of the radius (squared) of a circle. Referring again to , the distance along a line such as  from location  to  is obtained from a \u0394X and a \u0394Y. In the normalized case a count in each of the X and Y indices of the data structure is worth the same: it is a unit, which is to say, the integer number we call \u2018one.\u2019 In this exemplary non-normalized case, three units of \u0394X correspond to one unit of \u0394Y. So we can find each dwith the rule:\n\n+(3)\n\nWe prefer to scale \u0394Y up by multiplication instead of scaling \u0394X down by division, but that is a minor implementation detail, especially since are only interested in relative values for the ds anyway, and not in their actual \u2018real\u2019 values. As a further example, suppose the margins were such that one and a half units of \u0394Y (voltage) were equivalent to one unit of \u0394X (time). Then the formula for (relative\/absolute) dcould be:\n\n=(3)+(2)or +(\u03941.5)\n","It will be appreciated that in either the case of a circle (we normalized) or the scaled ellipse (no normalization), we only ever compute a distance (squared) between a trial location and locations in a list, and never attempt to decide what locations \u2018belong\u2019 to the circle or ellipse, as might be said for the case of the square. THAT exercise would be positively ugly!","The pseudo code of \u201cAPPENDIX C\u201d assumes the normalized case, but is easily modified to reflect a non-normalized case.","The reader may be wondering why we have disclosed the use of both circles and squares as locating shapes within the eye opening. In response, we begin by reminding the reader that the choice of either a circle or of a square (as opposed to an ellipse or a rectangle) arises from the normalization, as explained above. That operation produced an eye opening expressed in units of equal amounts of figure of merit for the axes of the measurement. Circles and squares are symmetrical about their centers, and thus reflect that equality. \u2018Mechanically\u2019 fitting a largest symmetrical shape (such as a square) into the eye opening (by traversing the data structure) is a way of (non-computationally) finding a central location therein that is \u2018furthest\u2019 from the margins in both directions. (It is true we compute a number of ds for the circle, but we have no formula for the center of the largest one . . . . We find it by inspection.) Squares may fit into some eye openings better than circles, especially if edges are sharp, and the eye opening has a peculiar shape. On the other hand, circles have a rounded exterior that may fit well into one end or the middle of a conventional eye-shaped eye opening that has a plurality of obtuse internal angles. Furthermore, circles have the additional property that three points of tangency define the center and the radius. This allows circles to \u2018engage\u2019 either two locations interior to the eye opening and one location along the eye opening boundary, or, two different locations along different portions of the boundary and an interior location, or worse still, locate the location(s) midway between (or nearly so) a collection of interior locations within a less than ideal eye opening. According to this view, the question of squares versus circles is one of having the \u2018right-size wrench,\u2019 and other shapes, such as octagons or other polygons could also be employed. Furthermore, it should be remembered that not all eye openings are of the general shape shown in . There are other families of shapes, such as the ones for pulse-type signals shown in. . Even in the absence of mischiefin the signal and with the aid of rules to assist in the bounding of otherwise open-ended regions, those eye openings can represent complicated circumstances that make it rash to assert ahead of time that only (\u2018inflatable\u2019) circles or only (\u2018inflatable\u2019) squares are the sole tool desired within either a fully automated or a machine assisted discovery of optimal sampling parameters.","There is another, more subtle, difference between circles and squares. We have said that re-scaling provides a convenient way to account for the disparity in how the \u2018size\u2019 of the applied signal results in reductions in margin as the sampling parameters are varied, and that re-scaling allows an equal valuation of both margins as things vary. The underlying belief is, of course, that loss of margin resulting in malfunction is fatal for the veracity of the measurement, regardless of its source. Being nibbled to death by ducks is, in the end, to be just as dead as, say, from the bullets loosed by a firing squad! That said, there is still a qualitative difference in the experience.","When a circle is fitted into an eye opening its center can move according to different rules than the center of a square can. If we think of \u2018optimum\u2019 as \u2018being furthest away from\u2019 then circles and squares give us different rules for exchanging the value of one margin for the other, even though they have been normalized to have the same worth. One rule is that an amount of one margin is ALWAYS worth the same as the same amount of the other margin, no matter what the amount, and that exchange of one for the other is continuous. Another rule is that amounts matter, in that they must be discrete, and that they behave independently. An example is in order.","Consider the distance from (0,0) to (1,1) in a Cartesian coordinate system. We are indoctrinated from about the eighth or ninth grade to believe that the answer is the square root of two, and give thanks to Pythogoras, after whom the relevant theorem is named. But that answer for distance holds only in a world where you are allowed to move simultaneously in both axes. If you are allowed to move only in a stair step fashion, then the distance is two, no matter how many steps you take! You could step first to (0, 1) and then to (1, 1) and the answer is two. Or, you could step over in X by 0.01 and then up in Y by 0.01, doing this one hundred times, and the displacements in X would contribute to progress toward (1, 1) separately from the progress achieved in Y. It would still take a total of \u0394X=1.00 and \u0394Y=1.00 to get to (1, 1), for a total of 2.00 for the distance, as at no time during the journey were you traveling ALONG the STRAIGHT LINE within the XY plane connecting (0, 0) and (1, 1) Your path may have touched it at one hundred and one points, but you never stayed on the line. This holds true no matter how fine the step size, for any definite and non-zero step size. It is a fundamental difference between a continuous world and a discrete one. So, it is possible that a newly discovered \u2018suspected straight\u2019 line between (0, 0) and (1, 0), even if seems quite straight and skinny and of length \u221a{square root over ( )}2, might turn out under sufficient magnification to be an imposter having steps of 10and a length of two!","The conclusion we draw from this line of thought is that the underlying suitability of largest circles versus largest squares probably has more to do with HOW a data receiver internally trades margin in voltage excursion for margin in pulse width: if they influence each other continuously as they happen, then circles may be order, whereas if they are independent, perhaps squares are a better choice. Speculation about the internal workings of particular threshold comparator designs is not appropriate here, and we are content in having provided tools for either extreme.","Of course, it may happen that several squares (or circles) of the same size are produced. Some strategy is needed to select a preferred one whose center will be the winner. One such strategy is to find the normalized (time, voltage) coordinates of the midpoint of the line connecting the crossing points of the two Xs, and then select as the winner the center having the least distance from that midpoint. However, the reader is reminded that not all eye diagrams have Xs; see again the examples in . In the spirit of normalization, and in the absence of such a line, (or, given a reluctance to find out if such a line is there or not!) it is perfectly reasonable to simply select a location that either the minimum distance voltage from the presumed midpoint of Vor the minimum distance in time from the presumed middle of the UI. After all, each of the recommended locations is, by the terms of our dilemma, a reasonable choice anyway. It is not as though we are confronted with two unmarked doors, behind one of which is vast wealth and eternal fame, while behind the other is a horrible death. If we had to, we could simply pick one of the recommendations at random.","There may sometimes be an urge to average possible winning centers. That is a risky plan. Suppose, for example, that the eye opening had a shape similar to that of an of an hour glass laying on its side: a bulge on the left and a bulge on the right. Each bulge produces a center with roughly the same voltage coordinate, but with quite different time coordinates. If the coordinates were averaged the location obtained would likely be right in the middle of the narrow neck connecting the two bulges: exactly a WORST location!","On the other hand, there may be times when averaging does no harm. Suppose that a family of many overlapping circles appears to have centers that lie on a vertical line. Each circle has a time coordinate that is quite close to the others: the variations are a small fraction of the radius. It is as if the same circle could slide up and down in a chimney defined within the eye opening. A family of squares would do the same thing. Perhaps in such a circumstance averaging of the center coordinates would do no harm, but we note that the result is probably not materially different from simply picking the family member in the middle, or simply picking the found center that is of least distance from the midpoint on the line joining the Xs (or some other assumed central location). In any event, it seems unlikely that it is worth the effort to attempt to recognize when averaging is harmless, since it is non-trivial to do so, and since the result is probably not significantly different from more expedient methods. Furthermore, averaging raises the possibility that an answer might be produced that is not exactly one that was an original potential winning choice. Then we are obliged to wonder why, and if taking this different result is actually a dumb thing to do. There might be benign explanations involving arithmetic precision and the granularity of the original measurements. Still, one can't be absolutely sure what an unattended automatic selection mechanism might do under unforeseen circumstances. For these reasons, and since it is not necessary to do it, averaging is not recommended.","In any event, it will of course be borne in mind that once a largest circle or square has been selected, its center is noted and its (X, Y) coordinates transformed back into the non-normalized coordinate system in which the original measurement was performed (recall the offsets  and  of ), to be presented as recommended or used as actual optimal sampling parameters for subsequent measurements by a Logic Analyzer, or perhaps for a receiver in the SUT. The task of transforming normalized coordinates back into the original coordinate system is not difficult: the normalized Time Figure of Merit coordinate is multiplied by \u0394Tand the normalized Voltage Figure of Merit coordinate in multiplied by \u0394V, after which any needed offsets are added back.","We turn now to a final example of how the central location(s) within an eye opening may be found. It is one that takes into account the shape of the opening, and that also accounts for inclusions of VISITED locations. It may be thought of as removing, one layer at a time, those locations describing the normalized eye opening that are in contact with locations MARKed as being part of the boundary or part of an inclusion. At the end of each iteration (layer), locations to be removed have been accumulated in a work list and are simply re-MARKed as VISITED, and the process repeated. It runs until there are no locations remaining, at which time the most recently removed location(s) in the work list is(are) the likely suspect(s). It will be noted that this technique is applicable to cases where the eye opening is hour glass shaped, and the centers of two separated regions are discovered. Unless both are found on the same iteration, the last one found is automatically the winner. Pseudo code for this technique is shown in APPENDIX \u201cD,\u201d and includes secondary selection criteria in the event there is a plurality of locations in the work list at the conclusion of the algorithm.",{"@attributes":{"id":"p-0157","num":"0156"},"figref":["FIG. 14","FIG. 9"]},"In connection with the technique of APPENDIX \u201cD\u201d it will be appreciated that there is also another method of \u201clayer removal\u201d that is similar to peeling a potato. It produces a spiral path of removed locations, forking when it encounters forced choices, with a mechanism for later continuing from the fork (as in traversing a tree-type data structure). It is considerably more complex, and upon investigation was found to have a bad case of the \u2018sensitivity to un-related conditions\u2019 problem that afflicts the spiral square technique of  and APPENDIX \u201cB.\u201d In this case the central location obtained may depend upon where on the normalized eye diagram the \u201cpeeling\u201d was started. So, other than mentioning it here as we have just done, we omit its further description.","Finally, refer now to . It is an example of a screen  showing a display  of a normalized eye diagram  for a signal whose recommended sampling parameters are found according to principles previously described herein. The figure assumes that a signal of interest has been specified and that an original non-normalized eye diagram measurement for it has been performed, perhaps with a DSO or a Logic Analyzer, or even with a dedicated eye diagram analyzer that does nothing but make eye diagram measurements. The screen  of  might be one that is created and displayed on the item of test equipment that made the eye diagram, or, it might be one on an item of test equipment, say a Logic Analyzer, but which was not the item of test equipment that made the eye diagram. In that case the original and non-normalized eye diagram data is imported as the suitably formatted content of an external file, and we proceed as if that Logic Analyzer had indeed made that eye diagram. Who made the original eye diagram and who supplies the information to normalize it (we need \u0394Tand \u0394V) is not a critical issue. Whoever has the original eye diagram and those parameters can normalize the original eye diagram and make recommendations for that environment, even if it is external to the equipment that creates the screen  of .","To continue, the screen  includes various controls that will now be described. Drop down menu box  allows selection of modes that includes NORMALIZED and NON-NORMALIZED. In the NORMALIZED mode (as shown) the eye diagram  is a normalized one, according to the original eye diagram data and the MINIMUM SIGNAL AMPLITUDE and MINIMUM SIGNAL PULSE WIDTH of boxes  and . The operator can either key known or trial values into boxes  and , or, he can check the box  to cause the equipment creating the screen  to use its own internal values (say it were a Logic Analyzer\u2014it would know those values from the factory according to what channel was at issue . . . ). The drop down menu of box  allows the operator to select the method (algorithm) of finding the recommended sampling parameters. The choices can include LARGEST CIRCLE, LARGEST SQUARE and ERODE LAYERS. In the example shown, the normalized eye diagram  is based on the example of , and LARGEST CIRCLE has been selected as the algorithm. A circle  is shown in the display, along with its center, by the location of cursor . If the algorithm were to use a LARGEST SQUARE then a suitable square would be drawn instead, and its center indicated by cursor .","The values for sample position and threshold (the discovered recommended sampling parameters) are indicated in the boxes  and , respectively. If the drop down menu of box  included a MANUAL mode, then if that were selected a user could key in his own idea of what trial sampling parameters might be, just to see where they fall in the display of the normalized eye diagram . Cursor  would move according to the values placed into the boxes  and . Conversely, the user could drag the cursor  to a trial location within the eye diagram and see the corresponding coordinates in boxes  and .","Recalling the example of , and the corresponding result in  and onward, the included HITs  in  are discarded as being too infrequent to take into consideration. This is accomplished by setting a density value in box . Setting a value of zero allows any HIT to be retained as part of the eye diagram.","Box  changes the scale of the presentation of the normalized eye diagram  so that it fits nicely into the viewing area.","Drop down menu box  can include a selection SELECT EYE OPENING which, if chosen allows the user to position a screen pointer (not shown) inside the region of an eye opening of interest and click, to assist\/force the eye opening identification and selection process () to operate on that region.","Finally, it will be appreciated that the screen  may be a GUI (Graphical User Interface) that is created under the control of an embedded system operating inside and controlling some item of data analysis equipment (test equipment) related to the testing of digital signals, such as a DSO or Logic Analyzer. One can assume that at least some minimal keyboard is available and that there is a pointing device for controlling a screen pointer. Alternatively, the screen  may be produced by an application program running on a computer separate from any item of test equipment. Various ones of the incorporated Patents, such as \u201cMETHOD AND APPARATUS FOR PERFORMING EYE DIAGRAM MEASUREMENTS\u201d describe the associated hardware block diagram for the case where the data analysis equipment is a Logic Analyzer, and which, for the sake of brevity, is omitted here.",{"@attributes":{"id":"p-0166","num":"0165"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"center"}},"thead":{"row":[{"entry":"APPENDIX \u201cA\u201d"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"(Pgm. INFLATE_SQUARE)"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"PSEUDO CODE FOR AN INFLATING SQUARE"},{"entry":"\/\/ The following data structure containing the normalized eye opening"},{"entry":"\/\/ data structure is assumed to already exist, and have been previously"},{"entry":"\/\/ populated with 0 ( = NULL, NOT VISITED) and 1 ( = MARK, VISITED)."},{"entry":"DEFINE ARRAY OF INTEGER:\u2003EYE (INTEGER, INTEGER);"},{"entry":"PROGRAM INFLATE_SQUARE;"},{"entry":"\/\/ This program grows a square that starts at a seed location by"},{"entry":"\/\/ iteratively adding \u2018rings\u2019 or layers of indexed locations as an \u2018outer"},{"entry":"\/\/ skin\u2019 around previous iterations. Only newly added locations are"},{"entry":"\/\/ checked for being already MARKed. Non-MARKed locations are"},{"entry":"\/\/ accumulated in OK_COUNT. Layers are always completed, even if they"},{"entry":"\/\/ include MARKed locations. The first layer to include a visited"},{"entry":"\/\/ location is the last layer attempted. The number of MARKed locations"},{"entry":"\/\/ encountered is also accumulated as NG_COUNT. This is done for each"},{"entry":"\/\/ seed location in the array EYE. Bounds checking for limits on array"},{"entry":"\/\/ indices is not needed if an outer layer of MARKed locations has been"},{"entry":"\/\/ applied to the data structure."},{"entry":"\/\/ SQUARE_LIST will be used as a list of square sizes indexed by their"},{"entry":"\/\/ centers (seed). We will assume the existence of some housekeeping"},{"entry":"\/\/ procedures and \/or functions for manipulating SQUARE_LIST. These"},{"entry":"\/\/ include INITIALIZE_SQUARE_LIST that sets all its entries to zero,"},{"entry":"\/\/ ADD_TO_LIST which adds an entry into SQUARE_LIST and"},{"entry":"\/\/ FIND_LARGEST_COUNT that locates the largest count(s) and tells how"},{"entry":"\/\/ many more if more than one instance of that count."},{"entry":"DEFINE ARRAY OF INTEGER:SQUARE_LIST(INTEGER, INTEGER, INTEGER, INTEGER);"},{"entry":"\/\/ Indices mean (X_SEED, Y_SEED, OK_COUNT, # squares with this count)."},{"entry":"BEGIN"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["CALL INITIALIZE_SQUARE_LIST;","\/\/ Set elements of SQUARE_LIST to zero."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"MAX_DELTA := 1 + MIN (UPPER_EYE_LIMIT \u2212 LOWER_EYE_LIMIT, RIGHT_EXTREME \u2212"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"LEFT_EXTREME)\/2;","\/\/ MAX_DELTA is limit on expansion."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["\/\/ For all seeds ...","Limits are from data structure size."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"FOR X_SEED = 1 TO X_LIMIT, STEP 1;"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["FOR Y_SEED = 1 TO Y_LIMIT, STEP 1;","\/\/ Y varies fastest ..."]},{"entry":"{"},{"entry":"OK_COUNT := 0;"},{"entry":"NG_COUNT := 0;"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["IF EYE (X_SEED, Y_SEED) = 0","\/\/ Check the seed location separately ..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"THEN OK_COUNT := OK_COUNT + 1","\/\/ Count a good one ..."]},{"entry":[{},"ELSE NG_COUNT := NG_COUNT + 1;","\/\/ Count a bad one ..."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["FOR DELTA = 1 TO MAX_DELTA, STEP 1;","\/\/ DELTA is the inflation to"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"175pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\/\/ the next layer."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ Bail to next seed when layer has hit a MARKed location."},{"entry":"IF NG_COUNT \u2260 0"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"THEN {CALL ADD_TO_LIST (X_SEED, Y_SEED, OK_COUNT);NEXT Y_SEED};"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ We didn't bail, so check the next layer ..."},{"entry":"FOR J = \u2212(DELTA) TO DELTA, STEP 1;\u2003\/\/ Walk lower left to lower right."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"IF EYE (X_SEED + J, Y_SEED \u2212 DELTA) = 0"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"THEN OK_COUNT := OK_COUNT + 1","\/\/ Counting good ones ..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"ELSE NG_COUNT := NG_COUNT + 1;","\/\/ Counting bad ones ..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ Walk from one above lower right to upper right less one."},{"entry":"FOR J = \u2212(DELTA \u2212 1) TO DELTA \u2212 1, STEP 1;"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"IF EYE (X_SEED + DELTA, Y_SEED + J) = 0"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"THEN OK_COUNT := OK_COUNT + 1","\/\/ Counting good ones ..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"ELSE NG_COUNT := NG_COUNT + 1;","\/\/ Counting bad ones ..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ Walk upper right to upper left."},{"entry":"FOR J = DELTA TO \u2212(DELTA), STEP \u22121;"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"IF EYE (X_SEED + J, Y_SEED + DELTA) = 0"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"THEN OK_COUNT := OK_COUNT + 1","\/\/ Counting good ones ..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"ELSE NG_COUNT := NG_COUNT + 1;","\/\/ Counting bad ones ..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ Walk from one below upper left to lower left less one."},{"entry":"FOR J = DELTA \u2212 1 TO \u2212(DELTA \u2212 1), STEP \u22121;"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"287pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"IF EYE (X_SEED \u2212 DELTA, Y_SEED + J) = 0"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"THEN OK_COUNT := OK_COUNT + 1","\/\/ Counting good ones ..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"98pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"ELSE NG_COUNT := NG_COUNT + 1;","\/\/ Counting bad ones ..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"NEXT DELTA;"},{"entry":"};"},{"entry":"IF NG_COUNT = 0 THEN CALL ADD_TO_LIST (X_SEED, Y_SEED, OK_COUNT);"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ Delta maxed out and no MARKed locations were encountered."]},{"entry":[{},"\/\/ Save this square."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"NEXT Y_SEED;"},{"entry":"NEXT X_SEED;"},{"entry":"CALL FIND_LARGEST_COUNT (X_LOC, Y_LOC, BIG_COUNT, NUM_MORE);"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"273pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\/\/ Find the largest count in SQUARE_LIST and the seed"]},{"entry":[{},"\/\/ used to create that square."]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"301pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"END"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0167","num":"0166"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0","pgwide":"1"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"center"}},"thead":{"row":[{"entry":"APPENDIX \u201cB\u201d"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"(Pgm. SPIRAL_SQUARE)"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"PSEUDO CODE FOR A SQUARE SPIRAL"},{"entry":"\/\/ The following data structure containing the normalized eye opening"},{"entry":"\/\/ data structure is assumed to already exist, and -- and has been"},{"entry":"\/\/ previously populated with 0 (=NULL) and 1 (=MARK)."},{"entry":"DEFINE ARRAY OF INTEGER: EYE (INTEGER, INTEGER);"},{"entry":"PROGRAM SPIRAL_SQUARE;"},{"entry":"\/\/ This program propagates an advancing spiral layer around a square"},{"entry":"\/\/ that starts at a seed location by iteratively adding indexed"},{"entry":"\/\/ locations along a CCW path that starts by one move to the right and"},{"entry":"\/\/ is followed by moving up, then to the left and finally down. Newly"},{"entry":"\/\/ added locations are checked for being already MARKed. Non-MARKed"},{"entry":"\/\/ locations are accumulated in OK_COUNT. The first MARKed location"},{"entry":"\/\/ encountered ends the advance of the spiral. This is done for each"},{"entry":"\/\/ seed location in the array EYE. Bounds checking for \u2002limits on"},{"entry":"\/\/ array indices is not needed if an outer layer of MARKed locations has"},{"entry":"\/\/ been applied to the data structure."},{"entry":"\/\/ SQUARE_LIST will be used as a list of square sizes indexed by their"},{"entry":"\/\/ centers (seed). We will assume the existence of some housekeeping"},{"entry":"\/\/ procedures and \/or functions for manipulating SQUARE_LIST. These"},{"entry":"\/\/ include INITIALIZE_SQUARE_LIST that sets all its entries to zero,"},{"entry":"\/\/ ADD_TO_LIST which adds an entry into SQUARE_LIST and"},{"entry":"\/\/ FIND_LARGEST_COUNT that locates the largest count(s) and tells how"},{"entry":"\/\/ many more if more than one instance of that count."},{"entry":"DEFINE ARRAY OF INTEGER:SQUARE_LIST(INTEGER, INTEGER, INTEGER, INTEGER);"},{"entry":"\/\/ Indices mean (X_SEED, Y_SEED, OK_COUNT, # squares with this count)."},{"entry":"BEGIN"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["CALL INITIALIZE_SQUARE_LIST;","\/\/ Set elements of SQUARE_LIST to zero."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["\/\/ For all seeds ....","Limits are from data structure size."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"FOR X_SEED = 1 TO X_LIMIT, STEP 1;"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["FOR Y_SEED = 1 TO Y_LIMIT, STEP 1;","\/\/ Y varies fastest ..."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["{","\/\/ New seed, new spiral."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["NEW_X := X_SEED;","\/\/NEW_X and NEW_Y walk the spiral's layers."]},{"entry":"NEW_Y := Y_SEED;"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["OK_COUNT := 0;","\/\/ Reset the good location count for each new seed."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["STOP_COUNT := \u2018FALSE\u2019;","\/\/ STOP_COUNT is the exit flag for an"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\/\/ instance of a spiral."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["WHILE STOP_COUNT = \u2018TRUE\u2019;","\/\/ Grow a spiral around the seed."]},{"entry":"{"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"\/\/ Check seed first, since SPIRAL advances before checking."}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["CALL CHECK_LOCATION;","\/\/Increments OK_COUNT or sets STOP_COUNT."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["L := 1;","\/\/ L is the \u2018radius\u2019 of the spiral, 1 is starting"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"224pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\/\/ iteration value for going around the seed itself."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ From the present location, step RIGHT until edge of layer is reached."},{"entry":"UNTIL ((NEW_X = X_SEED + L) OR (STOP_COUNT = \u2018TRUE\u2019);"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["{NEW_X := NEW_X + 1;","\/\/ Step RIGHT by one."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["CALL CHECK_LOCATION};","\/\/ Increments OK_COUNT or sets STOP_COUNT."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ From the present location, step UP until edge of layer is reached."},{"entry":"UNTIL ((NEW_Y = Y_SEED + L) OR (STOP_COUNT = \u2018TRUE\u2019);"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["{NEW_Y := NEW + 1;","\/\/ Step RIGHT by one."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["CALL CHECK_LOCATION};","\/\/ Increments OK_COUNT or sets STOP_COUNT."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ From the present location, step LEFT until edge of layer is reached."},{"entry":"UNTIL ((NEW_X = X_SEED \u2212 L) OR (STOP_COUNT = \u2018TRUE\u2019);"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["{NEW_X := NEW_X \u2212 1;","\/\/ Step RIGHT by one."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["CALL CHECK_LOCATION};","\/\/ Increments OK_COUNT or sets STOP_COUNT."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\/\/ From the present location, step DOWN until edge of layer is reached."},{"entry":"UNTIL ((NEW_Y = Y_SEED \u2212 L) OR (STOP_COUNT = \u2018TRUE\u2019);"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["{NEW_Y := NEW_Y \u2212 1;","\/\/ Step RIGHT by one."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["CALL CHECK_LOCATION};","\/\/ Increments OK_COUNT or sets STOP_COUNT."]},{"entry":"IF STOP_COUNT = \u2018FALSE\u2019"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"THEN L := L + 1;","\u2003\/\/ Increment size of spiral."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"266pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"ELSE CALL ADD_TO_LIST (NEW_X, NEW_Y, OK_COUNT);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"}\u2003\/\/ End of WHILE for STOP_COUNT =\u2018TRUE\u2019 (i.e., this spiral's growth)."}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"259pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["}","\/\/ Have disposed of old spiral, start a new one."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"NEXT Y_SEED;"},{"entry":"NEXT X_SEED;"},{"entry":"\/\/All seeds have been tried."},{"entry":"CALL FIND_LARGEST_COUNT (X_LOC, Y_LOC, BIG_COUNT, NUM_MORE);"},{"entry":"\/\/ Find the largest count in SQUARE_LIST and the seed used to create"},{"entry":"\/\/ that square."},{"entry":"END"},{"entry":"PROCEDURE CHECK_LOCATION;"},{"entry":"BEGIN"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"126pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":["IF EYE (NEW_X, NEW_Y) = 0;","\/\/ Is the current location MARKed or not?"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"133pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"THEN OK_COUNT := OK_COUNT + 1;","\/\/ Not MARKed, bump good count."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"112pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"ELSE STOP_COUNT := 'TRUE';","\/\/ MARKed! Set the QUIT-SPIRAL flag."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"294pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"RETURN;"},{"entry":"END"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0168","num":"0167"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"APPENDIX \u201cC\u201d"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"(Pgm. LARGEST_CIRCLES)"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"(SIMPLE) PSEUDO CODE FOR LARGEST CIRCLES FINDER"},{"entry":"PROGRAM LARGEST_CIRCLES;"},{"entry":"BEGIN"},{"entry":"MAX_DIST_SQD := \u22121;"},{"entry":"X_LOC := \u22121;"},{"entry":"Y_LOC := \u22121;"},{"entry":"FOR EACH (X_IN, Y_IN) OF INSIDE_LIST;"},{"entry":"FOR EACH (X_BOUND, Y_BOUND) OF BOUNDARY_LIST;"},{"entry":"NEW_DIST_SQD := (X_IN \u2212 X_BOUND)*(X_IN \u2212 X_BOUND) +"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"(Y_IN \u2212 Y_BOUND)*(Y_IN \u2212 Y_BOUND);"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":"IF NEW_DIST_SQD > MAX_DIST_SQD THEN"}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"{MAX_DIST_SQD := NEW_DIST_SQD; = X_LOC = X_IN;"]},{"entry":[{},"Y_LOC = Y_IN};"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"NEXT (X_IN, Y_IN) OF INSIDE_LIST;"},{"entry":"NEXT (X_BOUND, Y_BOUND) OF BOUNDARY_LIST;"},{"entry":"CALL ADD_TO_CRCLES_LIST (MAX_DIST_SQD, X_LOC,"},{"entry":"Y_LOC);"},{"entry":"CALL FIND_MAX_CIRCLE;"},{"entry":"END"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0169","num":"0168"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":"APPENDIX \u201cD\u201d"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"(ERODE_LAYERS)"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"PSEUDO CODE FOR ERODING AWAY LAYERS OF AN EYE"},{"entry":"OPENING"},{"entry":"Given: A two dimensional array of size (nRows, nCols),"},{"entry":"EYE_OPENING, containing the normalized clear eye"},{"entry":"with a continuous border of marked cells on the outside"},{"entry":"(first and last rows, first and last columns)."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["(1)","Build a list, INSIDE_NEXT, with the coordinates (row, col)"]},{"entry":[{},"of every non-marked cell in EYE_OPENING."]},{"entry":["(2)","While the list INSIDE_NEXT is not empty:"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"(a)","Assign INSIDE_NEXT to another list, INSIDE_PREV."]},{"entry":[{},"(b)","Clear INSIDE_NEXT."]},{"entry":[{},"(c)","Create an empty list of points, TO_BE_MARKED."]},{"entry":[{},"(d)","For each point in INSIDE_PREV:"]},{"entry":[{},{},"Does that point have eight unmarked neighbors (up,"]},{"entry":[{},{},"down, left, right and the four diagnals)?"]},{"entry":[{},{},"Yes: Add the point to INSIDE_NEXT."]},{"entry":[{},{},"No: Add the point to TO_BE_MARKED."]},{"entry":[{},"(e)","For each point in TO_BE_MARKED, mark that position in"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"\u2003EYE_OPENING."]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"At this point, INSIDE_NEXT is empty and INSIDE_PREV has"},{"entry":"the last position(s) that were unmarked before the last"},{"entry":"layer was taken off. The points in INSIDE_PREV are"},{"entry":"the candidates for the answer we seek."}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["(3)","Find the center (by average) of the positions of the points in"]},{"entry":[{},"INSIDE_PREV. Call this CANDIDATE_CENTER."]},{"entry":["(4)","Find the point in INSIDE_PREV closest to"]},{"entry":[{},"CANDIDATE_CENTER. Call this point FIRST_POSSIBILITY."]},{"entry":["(5)","Create a list of points, POSSIBLES, of all points in"]},{"entry":[{},"INSIDE_PREV which are strongly connected (left,"]},{"entry":[{},"right, up, or down only) to FIRST_POSSIBILITY."]},{"entry":["(6)","Find the center (by average) of the positions in POSSIBLES. Call"]},{"entry":[{},"this POSSIBLES_CENTER."]},{"entry":["(7)","Find the point in POSSIBLES closest to POSSIBLES_CENTER."]},{"entry":[{},"Call this ANSWER."]},{"entry":["(8)","Return ANSWER."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIGS. 2A-E"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIGS. 4A-C"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIGS. 6A-C"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0059","num":"0058"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 13","FIG. 12"]},{"@attributes":{"id":"p-0062","num":"0061"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 15"}]},"DETDESC":[{},{}]}
