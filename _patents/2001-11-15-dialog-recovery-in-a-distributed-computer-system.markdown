---
title: Dialog recovery in a distributed computer system
abstract: A distributed computer system comprises an enterprise server and a network server. The distributed computer system utilizes a distributed transmission control protocol (TCP) to establish an off-loaded dialog through the network server. If the off-loaded dialog is interrupted by, e.g., failure of the hosting network server, dialog recovery is performed to move the off-loaded dialog.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08312117&OS=08312117&RS=08312117
owner: Unisys Corporation
number: 08312117
owner_city: Blue Bell
owner_country: US
publication_date: 20011115
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This application is related to U.S. patent application Ser. Nos. 09\/999,550, entitled \u201cManagement of Routing Information in a Distributed Computer System;\u201d No. 10\/000,698, entitled \u201cAcknowledgement Mechanism in a Distributed Computer System;\u201d and No. 09\/999,727, entitled \u201cInput Accumulation in a Distributed Computer System;\u201d all filed on even date herewith and assigned to the same assignee as the present application.","This application is also related to U.S. patent application Ser. Nos. 09\/418,083, filed Oct. 14, 1999; and 09\/310,543, filed Jul. 31, 1998 (now U.S. Pat. No. 6,233,619, issued May 15, 2001); all assigned to the same assignee as the present application.","This invention relates generally to information technology (IT) and, more particularly, to application platforms\/servers in a networking environment.","An applications platform can be constructed from a number of computing environments in which at least one computing environment is different from the others. Such an applications platform is also referred to as a \u201cheterogeneous\u201d platform. One such example is illustrated in U.S. Pat. No. 6,233,619 issued May 15, 2001 to Narisi et al., entitled \u201cVirtual Transport Layer Interface and Messaging Subsystem for High-Speed Communications Between Heterogeneous Computer Systems\u201d and assigned to the same assignee as the present application. In this patent, the heterogeneous application platform is illustrated by a Unisys ClearPath HMP\u00ae enterprise server coupled with a Microsoft Windows NT\u00ae server for network services. (Also, see U.S. patent application Ser. No. 09\/418,083, filed Oct. 14, 1999, assigned to the same assignee as the present application, and entitled \u201cA Distributed Transport Communications Manager with Messaging Subsystem for High-Speed Communications between Heterogeneous Computer Systems.\u201d)","Networking of applications typically involves the use of a network protocol suite such as the popular Transmission Control Protocol\/Internet Protocol (TCP\/IP) stack. In the above-mentioned patent, a local application (running in the enterprise environment) can use either a TCP\/IP stack in the enterprise environment or a TCP\/IP stack in the NT environment to communicate with a remote application.","While the above-described heterogeneous application platform presents some benefits with respect to the ability to utilize the TCP\/IP stack in either computing environment, we have observed that the heterogeneous application platform can be further improved.","In accordance with the invention, a distributed computer system comprises an enterprise server and a network server wherein a dialog is established using the network server; and wherein the enterprise server performs dialog recovery by moving the dialog upon the occurrence of a predefined condition.","In an embodiment of the invention, a distributed computer system comprises an enterprise server and at least two network servers. The distributed computer system utilizes distributed TCP communications to establish an off-loaded dialog through one of the network servers. If the off-loaded dialog is interrupted by, e.g., failure of the hosting network server, dialog recovery is performed to move the off-loaded dialog to the other network server or to a legacy TCP\/IP stack in the enterprise server.","The inventive concept is implemented using conventional programming techniques (including those required to network applications), which will not be described herein. As such, familiarity with networking (e.g., TCP\/IP, etc.) and server platform architectures (e.g., application programming interfaces (API)s, etc.) is assumed. As used herein, the term \u201ccomputer program product\u201d represents any mechanism for storing a computer program, e.g., a floppy diskette; a CD-ROM; a file, or files, in compressed and\/or uncompressed form; etc. The term \u201cmachine\u2019 refers to any stored-program-control processor-based equipment (e.g., the below-described heterogeneous platform, or even a network server). Also, as can be observed from below, data is described as being conveyed in packets. However, the terms \u201cdatagram\u201d or \u201cframe\u201d are also used in the art, e.g., the IP layer provides \u201cdatagrams.\u201d For the purposes of this description, the terms \u201cpacket,\u201d \u201cdatagram\u201d and \u201cframe\u201d are used interchangeably, with the distinction being whether it is a TCP packet, IP packet, input accumulation block, etc.","Before describing the inventive concept, some background information is provided on TCP\/IP. For readers familiar with TCP\/IP, simply skip ahead to the section entitled \u201cOff-loaded Data Path.\u201d","TCP\/IP","The description below is with respect to a TCP\/IP stack in a \u201clocal machine\u201d communicating with a \u201cremote machine.\u201d Obviously, these are relative terms, and the description equally applies to the TCP\/IP stack in the remote machine.","When a local application, on a local machine, communicates with a remote application, on a remote machine, one popular protocol suite to use is TCP\/IP.  shows an illustrative TCP\/IP stack  for use in a local machine, which comprises a TCP portion and an IP portion. (It should also be noted that further processing (not shown) occurs below TCP\/IP stack  at the device level or OSI physical layer, e.g., the partitioning of IP packets into Ethernet packets for transmission over a local area network (LAN).)","The TCP portion provides some connection management functions such as opening and closing connections\/dialogs between applications, sending acknowledgements to verify delivery of data, window adjustments, segmentation, and end-to-end error recovery (such as retransmission of data apparently lost, error detection, etc.). (The TCP portion can also be viewed as providing the transport layer function as defined within the Open Systems Interconnection (OSI) reference model as known in the art.)","In particular, the TCP portion treats data as a stream of bytes, which are packaged into TCP packets for transmission and reception. An illustrative TCP packet  is shown in . TCP packet  comprises a TCP header  and a data portion . The TCP header  comprises a sixteen bit source TCP port number field, a sixteen bit destination TCP port number field, a thirty-two bit sequence number field (described below), a thirty-two bit acknowledgement number field (described below), a sixteen bit window size, etc. While port numbers can range from 1 to 65535, the port numbers 1 through 1024 are reserved for \u201cwell known\u201d applications. For example, a file-transfer-protocol (ftp) server is predefined as being associated with TCP port . Data portion  comprises a sequence of bytes (e.g., from 1 to 64K bytes, where the symbol K denotes 1024 bytes).","As noted above, the TCP portion performs end-to-end error recovery between local and remote endpoints using the above-mentioned sequence number and acknowledgement number fields. Since the TCP portion treats the data as a stream of bytes, the TCP portion logically assigns a sequence number value to each byte being sent using the above-mentioned sequence number field. This allows a corresponding TCP receiver at the remote end to determine where it is in the receive sequence and to detect missing, out of order, or out of window data. Conversely, the acknowledgement number value represents information related to the received data and is an indication to the remote TCP endpoint of the data that, so far, has been correctly received by the local endpoint. The value of the sixteen bit window field supplied in TCP packet  reflects the number of data bytes the remote dialog will accept, relative to the acknowledgement number in the TCP packet (also referred to as a \u201cwindow size update\u201d).","The IP portion also provides some connection management functions, such as performing route determination\u2014i.e., deciding how to route the data between the local machine and the remote machine and IP packet size. The data functions performed by the IP portion include, e.g., the fragmentation of outgoing TCP packets and the re-assembly of incoming TCP packets, and the packaging of data into IP packets for transmission over the network. (The IP portion can also be viewed as providing the network layer as defined within the OSI reference model.)","An illustrative IP packet  is shown in . As can be observed from , the IP portion encapsulates the TCP packet into its own packet and adds, e.g., IP header , some of which is shown in . IP header  comprises a thirty two bit source IP address field and a thirty two bit destination IP address field. The IP addresses are associated with the IP address of each machine associated with the particular applications. (It should also be noted that TCP may also build the IP packet once the IP routing information and IP packet size is determined by the IP layer.)","When one application (e.g., a local application) needs to establish a connection with another (e.g., a remote application) over a network, the local application sends an \u201copen\u201d request to TCP\/IP stack . (This is also known as a \u201cdirected open.\u201d) Conversely, a corresponding connection, with the local TCP source port matching the destination TCP port of the open request, must be present on the remote system. (This is known as a \u201cpassive open.\u201d) The receipt of a request from a remote application to open a connection begins the TCP open handshake processing. If the connection can be established, TCP\/IP stack  establishes a \u201csocket\u201d identification for the connection. An illustrative socket  is illustrated in . Socket  comprises information representative of the local application, e.g., the source TCP port number associated with the local application and the source IP address of the local machine, along with information concerning the remote application, e.g., the destination IP address of the remote endpoint (machine) and the destination TCP port number that is associated with the remote application on the remote endpoint. In terms of originating a connection, the values comprising this socket information are known a priori by the local application. After a connection is established, the local application sends data to, and, perhaps, receives data from, the remote application\u2014i.e., the local application has a \u201cdialog\u201d with the remote application. (As used herein, the terms \u201cconnection\u201d and \u201cdialog\u201d will be used interchangeably.)","A prior art heterogeneous application platform (also referred to herein as an heterogeneous multiprocessor (HMP)) , such as that described in the above-mentioned U.S. patent of Narisi et al., is illustrated in . HMP  comprises an enterprise environment  (e.g., a Unisys ClearPath HMP\u00ae enterprise server (or enterprise platform)) and at least one network server (or network platform) -(e.g., a Microsoft Windows NT\u00ae server (or box)), where i\u22671. Enterprise environment  supports execution of one, or more, applications\u2014as represented by application . The latter establishes connections with remote applications (not shown) over a network (not shown) using either TCP\/IP stack  (in enterprise environment ) or TCP\/IP stack  (in network server -), via manager . (The particular TCP\/IP stack used is transparent to application .) Paths  and  are representative of lower levels of processing and coupling through appropriate devices (e.g., a network interface card (NIC)) to a transmission network. As such, paths  and  include, e.g., device drivers that translate between particular devices and the network protocols (such as TCP\/IP). It is assumed herein, that the interface between the network protocols and the device drivers conform to the known Network Driver Interface Specification (NDIS). Messaging Subsystem (MSS)  is representative of additional processing needed to communicate both control and data between enterprise environment  and each network server -. MSS presents a common, inter-connect independent interface (e.g., see the above-mentioned U.S. patent of Narisi et al.). The architecture illustrated by HMP  allows an application (e.g., application ) the flexibility, via manager , of using either the \u201clegacy\u201d TCP\/IP stack  or a network server TCP\/IP stack  to communicate with remote applications. It should be noted that devices on path  may be located in a network server -","As noted above, when a local application (e.g., application ) has a connection (as represented by, e.g., socket  of ) with a remote application, whether through TCP\/IP stack  or TCP\/IP stack , application  then has a dialog with the remote application. As part of this dialog, TCP manages the end-to-end error recovery.","If the dialog is through TCP\/IP stack , and the device becomes unavailable, TCP\/IP stack  may perform dialog recovery by selecting, if available, a different device coupled to path . In dialog recovery, the dialog\u2014in effect\u2014is continued using the different device and this is transparent to the applications. It should be noted that this form of dialog recovery merely uses a different route\u2014there is no movement of the dialog (described further below).","However, if the connection is through TCP\/IP stack  and network server -\u201cdisappears\u201d\u2014this connection is lost and any ongoing transaction is terminated. (For example, a hardware failure could cause the NT box that is \u201chosting\u201d the connection to \u201cdisappear\u201d from the viewpoint of application .) Such a failure of the network server then requires application  to start over, i.e., re-establish the connection to the remote application through, e.g., a different one of the i network servers, and re-initiate the dialog. In addition, such a failure probably causes application  to have to re-send data already received by the remote application as if the earlier dialog had never happened. In other words, the TCP portion of TCP\/IP stack  does not provide any form of dialog recovery if the hosting network server fails\u2014or if the connection fails and there is no available device with the hosting network server.","Off-Loaded Data Path (ODP)","An HMP in accordance with the invention is shown in . Other than the inventive concept, the elements shown in  are well known and will not be described in detail. Further, the inventive concept is implemented using conventional programming techniques, which as such, will not be described herein. (Similarly, exception handling will become apparent from the below descriptions of the various flow charts and, as such, is not described herein.) Also, like numbers from previously described figures indicate like elements and will not be described further.","HMP  comprises enterprise environment  (e.g., a Unisys ClearPath HMP\u00ae enterprise server) and at least one network server -, where i\u22671, (e.g., a Microsoft Windows NT\u00ae server (or box)). Enterprise environment  supports execution of one or more applications\u2014as represented by application . The latter establishes connections with remote applications (not shown) over a network (not shown) using either TCP\/IP stack  (in enterprise environment ) or through Off-loaded Data Path (ODP) element .","It should be observed from , that network server -also comprises TCP\/IP stack . (Applications running in network server -may use TCP\/IP stack .) Like , paths  and  are representative of lower levels of processing and coupling through appropriate devices (e.g., a network interface card (NIC)) to a transmission network. As such, paths  and  include, e.g., device drivers that translate between particular devices and the network protocols. It is assumed herein, that the interface between the network protocols and the device drivers conform to NDIS. It should also be observed that path  interfaces to both ODP  and to TCP\/IP stack . In this context, path  represents, as known in the art, a \u201cshared adapter\u201d and allows associated devices\u2014as represented by path \u2014to be used by either ODP  or TCP\/IP stack  of each network server -(e.g., see the above-mentioned U.S. patent application Ser. No. 09\/418,083). The architecture illustrated by HMP  allows an application (e.g., application ) the flexibility of using either the \u201clegacy\u201d TCP\/IP stack  or ODP  to communicate with remote applications. (In effect, legacy TCP\/IP stack  and management module  co-exist in enterprise environment , while ODP  and TCP\/IP stack  coexist in network server -.) It should be observed that Distributed TCP\/IP Communications Manager (DTCM) Server  is shown for completeness. DTCM Server  manages any distinctions between offloaded dialogs (further described below) and dialogs using Virtual Transport (not described herein, e.g., see the above-mentioned U.S. patent issued to Narisi et al.).","The \u201cOff-Loaded Data Path\u201d is shown in more detail in . As represented in , and other than the inventive concept, the \u201cOff-Loaded Data Path\u201d provides at least standard TCP\/IP functionality\u2014albeit now in two different environments. In particular, a TCP\/IP stack  is functionally divided so that the management functions are substantially performed in enterprise environment  via management module  while data functions are substantially performed in a network server -via ODP element . This is also referred to herein as \u201cdistributed TCP communications.\u201d (This is a variation of the approach described in the above-mentioned U.S. patent application Ser. No. 09\/418,083, in which the TCP\/IP management functions are also executed in the network server -.) Management module  comprises a TCP\u2032 element and an IP\u2032 element, both of which primarily represent management-type functions. For example, TCP\u2032 handles, \u201copen,\u201d \u201cclose,\u201d and \u201cend-to-end error recovery,\u201d while IP\u2032 handles routing management. In a complementary fashion, ODP element  comprises a TCP\u2033 element and an IP\u2033 element, both of which primarily represent data-type functions. For example, TCP\u2033 provides TCP packets; while IP\u2033 provides IP packets. In addition, other than as noted below, TCP\u2033 performs handshaking with the remote peer. Since, in this architecture, connection management functions are performed in one processing environment while data functions are performed in (i.e., offloaded to) another processing environment\u2014this is referred to as an \u201coff-loaded data path.\u201d","It is assumed for the purposes of this description that network information is maintained in, or accessible by, enterprise environment  (e.g., in memory (not shown) of enterprise environment ). This network information is determined a priori and\/or updated in real-time. Illustrative network information  is shown in . Network information  comprises a table of information relating local applications, remote applications\u2014as represented by socket , of FIG. \u2014and associated TCP\/IP paths within HMP . It should be noted that this network information may include preference information. For example, network information  indicates a preference to use (via the numerals (1) and (2)), ODP  (if possible) before using the legacy TCP\/IP stack . (Although not shown in , if an ODP  preference is indicated, there is additional information relating to the available network servers -that may be used to access a particular remote IP address.) As such, when application  initiates a connection with a remote application, enterprise environment  selects (e.g., as represented by manager  of ) the TCP\/IP path from network information .","Turning now to , an illustrative flowchart is shown for use in establishing a dialog (or data session) through ODP , i.e., establishing an off-loaded dialog. (Again, it is assumed that selection of ODP  for connection to a particular remote application is predetermined as described above.) In step , application  opens a dialog with a remote application through ODP . As part of this process, a TCP control block (TCB)  is created and stored in a memory (not shown) of enterprise environment . TCB  is associated with this dialog and exists for the life of this dialog (as such, there is a table of dialogs and associated TCBs). An illustrative TCB  for this dialog is shown in . TCB  comprises socket , and other routing information , which includes, e.g., within HMP , the network server being used, and, external to HMP , the \u201cnext hop\u201d (if any) needed to route packets to the remote IP address (which, as known in the art, is identified in socket ). In addition, TCB  also comprises additional data , which comprises, e.g., the current value of bytes sent and bytes received (synchronization and acknowledgement information) and IP packet size.","An illustrative message flow for opening a connection between the local and remote applications is shown in . As can be observed from , this is a \u201cdirected open.\u201d Application  sends an open message (including the information represented by socket ) to management module . (Other than the inventive concept, the notion of a message exchange between, e.g., software modules, is well known and not described herein.) Management module  creates the above-mentioned TCB  (also described further below) and sends a \u201cSyn\u201d message to the remote peer. (For simplicity, the corresponding remote TCP\/IP stack and remote application are show as one entity\u2014the \u201cremote peer.\u201d Those in the art appreciate that some messages will terminate at the remote TCP\/IP stack and that some messages are exchanged between the remote TCP\/IP stack and the remote application.) Management module  then waits for receipt of a \u201csyn-ack\u201d message from the remote peer. (Syn and syn-ack messages are known in the art for establishing a TCP dialog between two applications.) Upon receipt of the syn-ack message, which indicates the availability of the remote application, management module  sends an open endpoint message to ODP element  for this dialog. The open endpoint message includes TCB  information (which is used by ODP element  to build TCP packets and IP packets). ODP element  then generates an acknowledgement (ACK) message to the remote peer, completing the handshake for opening the dialog. To indicate the completion of the open process at HMP , ODP element  then sends an open endpoint response message to management module , which provides an open response message to application .","It should be observed, in accordance with the off-loaded data path architecture, that management module  initiated the opening of the dialog (via the syn\/syn-ack message exchange), while ODP element  performed the handshaking once it was determined that the dialog could be opened. For comparison purposes, a passive open is illustrated in . Again, management module  manages the creation of the dialog (via receipt of the syn message). Management module  sends an open endpoint message to ODP element , which\u2014since the dialog has been created\u2014provides the syn-ack message to the remote peer. Upon receipt of the ACK from the remote peer, ODP element  sends an open endpoint response message to management module , which provides an open response message to application . (Other message sequence illustrations, described below, further highlight the partitioning of the various TCP\/IP related functions between management module  and ODP element .)","Returning to , upon successfully opening the dialog to the remote application, application  has an off-loaded dialog with the remote application, i.e., data is communicated between application  and the remote application in step  using distributed TCP communications in HMP . Illustrative message sequences for data sent to, and received from, the remote peer are shown in , respectively.","In , application  sends data to management module , which delivers the data to ODP element . The latter forms packets for transmission to the remote peer. For each dialog, management module  comprises a transmission window of a predefined size (e.g., 64K bytes) as represented by output data buffer  (which is stored within enterprise environment ). Management module  continues to accept data from the dialog for transmission to the remote peer until output buffer  is filled up with un-acknowledged (un-ACKed) data. At this point, management module  provides a not ready message to application . As indicated in , management module  maintains an un-ACKed list  of what data is still waiting for an acknowledgement. Generally speaking (unlike what is shown in ), once ODP element  receives an ACK message from the remote peer indicating the successful receipt of some of the data at the remote endpoint, this information is passed up to management module . (A more detailed explanation of the ACK sequence between ODP element  and management module , as illustrated in , is provided below.) Upon receipt of ACK information from ODP element , management module  deletes the acknowledged data from output buffer  and updates un-acked list . (As known in the art, an ACK message includes sequence numbers that are used to track what data has been correctly received. TCP is a byte-stream oriented protocol and the sequence number is used to track the corresponding byte in output buffer  that has been successfully transmitted.) At this point, management module  provides a ready message to application  and management module  again accepts data into output buffer  for transmission.","For data received from the remote application, an illustrative message sequence is shown in . As can be observed from , ODP element  receives packets from the remote peer and, after accumulating a predefined number of packets destined for application  (described further below), delivers data to management module . The latter provides a data received message to application , which then retrieves the data. ODP element  provides a Demand Window Acknowledgement (DWACK) for unacknowledged (Un-ACKed) data to management module . In response, management module  then provides a ManyACK message to ODP element , which provides an ACK message to the remote peer. (The acknowledgement mechanism shown in  is described further below.)","Returning to , at the end of the dialog, the dialog is closed in step . An illustrative message flow for closing a dialog between the local and remote applications is shown in . Application  sends a close message (including the information represented by socket ) to management module . The latter sends a close endpoint message to ODP element , which sends a FIN message to the remote peer. Upon receiving an ACK to FIN message from the remote peer, ODP element  passes this information along to management module  via a close endpoint response message. Upon receipt of a subsequent FIN message, ODP element  provides a message indicating a disconnect of the dialog to management module , which replies with a disconnect response message. ODP element  then provides an ACK to FIN message to the remote peer. (FIN and ACK to FIN messages are known in the art for terminating a dialog.)","Dialog Recovery","As noted earlier, a dialog supported by TCP\/IP stack , of a network server -of HMP  of , cannot be recovered if the network server itself fails. However, the use of ODP element  of  now enables off-loaded dialog recovery. This feature is illustrated in . During the off-loaded dialog it is possible that the network server becomes unavailable as illustrated by line . In other words, communication with the remote peer is lost unexpectedly (e.g., the respective network server has failed, or an element in the physical layer of the connection has failed, etc.).","When the management module  is informed that a network server is unavailable (via messages from networking management software resident in enterprise environment  (not shown)), dialog recovery is attempted in step  (described further below). If offload dialog recovery is successful, the dialog continues in step . If offload dialog recovery is unsuccessful, the dialog is recovered as a legacy dialog (i.e., the dialog is moved to legacy TCP\/IP stack ) and the dialog continues in step . (If the legacy dialog fails to send unacked or new data because a legacy device is unavailable, the dialog will eventually timeout and reset\/terminate. Also, it should be observed that although dialog recovery is illustrated in  in the context of a directed open, dialog recovery is applicable in a similar fashion for a passive open.)","Turning now to , an illustrative flow chart for dialog recovery is shown. (Reference can also be made to , which shows an illustrative message sequence.) In step , management module  of enterprise environment  checks if an off-load capable device is available in HMP . As noted above, it is assumed that networking information is available within HMP  as to which network servers can be used to connect to particular IP addresses. In this context, in step , the network information is searched for a network server -that can both access the remote IP address for the existing dialog and support an ODP. If an off-load capable device is not available (e.g., a network server is available but it does not support an ODP element ), then the connection is recovered as a legacy dialog and the dialog is moved to TCP\/IP stack  (steps  and ) and the process returns to step  of . Similarly, if neither a legacy or offload capable network server are available, the dialog is recovered as a legacy dialog and will attempt to resend data per TCP protocol specification. However, if an off-load capable device (e.g., a network server -) is available in step , then, in step , management module  sends an open endpoint recover message (including the information in TCB ) to ODP element  of the network server -selected in step . ODP element  of network server -then sends a \u201ckeep alive\u201d message as known in the art to the remote peer (to synchronize data transfer information with the remote peer). ODP element  also provides an open endpoint response message to management module  acknowledging that the dialog has been moved to network server -. The keep-alive exchange sent by ODP element  performs data synchronization with the remote peer exchanging current sequence number and window information to determine what data has been successfully received by the remote peer and read by the remote application (send\/resend message sequence shown in ). In step , data previously transmitted but indicated as un-ACKed by the remote peer, is resent by management module , and any ACKed data is deleted from output buffer  (described earlier). (There is no \u201crequest for retransmission\u201d of received data. If incoming data is lost due to a failure, it will be resent by the remote dialog (via TCPIP retransmission logic) due to the fact that it has not yet been acknowledged by the receiving (local) dialog.) After the data has been synchronized with the remote peer, the dialog between application  and the remote application continues in step  of . (In effect, by maintaining a copy of the previously transmitted data in output buffer , it is possible to continue the dialog at the point when the network server went down.) Consequently, application  keeps the existing socket (here, represented by socket ) but is able to use a different network server for the same dialog. (It should be noted that although dialog recovery was illustrated in the context of the original network server failing, it may be the case that a problem occurs, e.g., at a physical layer of the connection between application  and the remote application. In this case, an attempt can be made within step  to check if another off-load capable device is available within the same network server, e.g., network server -. If another offload capable interface within the same network server is available, the dialog recovery mechanism is not initiated as there is no need to move the dialog. Instead, an IP route update notification message (described below) is sent to ODP element  to indicate that a different network interface on the same network server should be used for the dialog.)","As described above, a dialog recovery capability was described for HMP  for an illustrative application . However, it should be noted that an HMP may have hundreds, if not thousands, of dialogs going on through the same NT device. (Different dialogs can exist between the same IP source and destination endpoints.) Consequently, should the network server fail, attempting dialog recovery for each and every dialog could create a performance bottleneck for the HMP. Therefore, \u201crecovery as needed\u201d is performed. In \u201crecovery as needed,\u201d dialog recovery is only attempted for those off-loaded dialogs that are active, i.e., that attempt to send\/receive data subsequent to the failure. Recovery is not attempted for those off-loaded dialogs that are idle. This is illustrated in  with the addition of step , which checks on a per-dialog basis if the off-loaded dialog is active or idle. If the off-loaded dialog is active, (e.g., new data or unacked data is available for transmission or new input is received), dialog recovery is attempted in step , as described above. If the off-loaded dialog is idle, (e.g., new data or unacked data is not available for transmission or new input is not received), then dialog recovery is delayed, until that off-loaded dialog\/application becomes active. This distributes the workload of re-establishing large numbers of off-loaded dialogs over time.","It should also be noted that additional variations can be performed to the dialog recovery process described above. For example, if the device that originally failed \u201cbecomes available,\u201d then an attempt may be made to move the dialog back to the original device. Additionally, if a dialog is established using the legacy TCP stack because an offload capable device was unavailable when the dialog was initiated, this dialog may be recovered as an offloaded dialog if the offload capable device becomes available during the lifetime of the dialog.","In addition, although described in the context of using ODP element , network server -could equivalently be modified so that TCP\/IP stack  supports the use of existing socket information for recovering a dialog. For example, TCP\/IP stack  could be modified to be responsive to a recover dialog message such as the above described open endpoint recover message.","Input Accumulation","Returning to , an illustrative message flow for the receipt of data from a remote endpoint is shown. This message flow is on a per-dialog basis and is associated with a particular socket. However, if every received TCP packet associated with socket  is forwarded to enterprise environment \u2014the latter also incurs some performance penalty because of the overhead processing associated with each TCP packet. Therefore, \u201cinput accumulation\u201d of data is performed on a per-dialog basis as shown in  (also referred to as \u201cper-socket\u201d or \u201cper TCP connection\u201d). In other words, data from packets associated with the same dialog are accumulated into a larger data unit (or packet). Thus, enterprise environment  receives larger, but fewer, packets, which reduces any performance penalty. This larger data unit is referred to herein as an \u201cInput Accumulation Block\u201d (IAB). (It should be noted, that while an individual IAB may contain the accumulation over several input packets (or frames), an IAB may also contain data from only one received packet, or, in fact, only a portion of a single received packet (described below).)","In accordance with the ODP architecture, this data handling is performed by ODP element  of network server -. A high-level view of input accumulation on a per-dialog basis is shown in the illustrative flow chart of . In step , ODP element  accumulates data from f received TCP packets (or frames), where f\u22671. When f TCP packets have been received (e.g., f=4), then ODP element  forms a larger packet, the IAB, in step  and sends the IAB to management module , of enterprise environment , in step . Thus, enterprise environment  processes one packet (the IAB) for every f TCP frames received by the network server -. This reduces the amount of TCP processing incurred by the enterprise environment. The value for f is determined for each dialog and may change over time.","Another illustration of input accumulation on a per-dialog basis is shown in the flow charts of . As described below, this example of input accumulation attempts to optimize the case in which large amounts of received data are available and, also, not adversely affect cases in which little or no received data is available (e.g., in \u201ctransaction-oriented\u201d dialogs in which the normal traffic flow is alternating messages from one side of the dialog to the other.) It should be noted that the degree of optimization is dependent on many factors, including characteristics of the underlying interconnect, the arrival rate of incoming data from the remote endpoint, the segment size of the incoming link layer, and, of course, the algorithm used to accumulate data for delivery to enterprise environment . For example, consider the case of a LAN connection (approximately 1500 bytes of data per segment), if 21 LAN segments are accumulated from the remote endpoint\u2014this results in a block of 32K bytes of received data.","The following definitions are made.\n\n","It is assumed that the following information\/parameters are maintained for each dialog by, e.g., ODP element .\n\n","Turning now to , in step , data for the dialog is received from the remote endpoint. This received data is stored in a receive buffer (not shown). In step , the MRWU value is updated, if appropriate (described below). In step , a check is made if an IAB exists for this dialog (e.g., Current_IAB is \u201ctrue\u201d). If one does not exist, ODP element  creates an IAB for this dialog in step . If a maximum size (other than MAX_ACCUM_LEN) must be determined for an IAB at allocation time (for example, when an independent data buffer must be allocated), that size can be determined by consideration of the dialog's current MRWU value (rounding MRWU up to a multiple of MTU is suggested). In either event (whether an IAB already existed or had to be created), execution proceeds to step , where the received data is transferred from the receive buffer to the IAB (i.e., data is added to the IAB, or, equivalently, data is bundled into the IAB). The amount of data transferred to the IAB is the minimum of the amount of data received but not yet transferred and the amount of data that will fit into the IAB.","Turning now to , in step , a check is made by ODP element  if the IAB is now full (i.e., the value of MAX_ACCUM_LEN or the maximum size determined at IAB allocation). If the IAB is full, the IAB is forwarded to enterprise environment  in step  (and the dialog has no associated IAB (e.g., Current_IAB is now \u201cfalse\u201d)). If the IAB is not full, or if the IAB has just been forwarded to enterprise environment , a check is made if all received data in the receive buffer has been transferred in step . If all the received data has not been transferred, execution proceeds to step , of , where a new IAB is created, to which data is added in step , etc. This sequence (creating IABs, filling them up with data, sending them to enterprise environment , etc.) is repeated until all received data has been transferred from the receive buffer. It should be noted that, based on the suggested maximum size of IABs, the sequence should allocate at most one IAB.","Once all received data has been transferred, execution proceeds to step  of , where a check is made if an IAB still exists (but is not full of received data). If an IAB does not exist, then execution ends until more data is received from the remote endpoint for this dialog. However, if a partially full IAB does exist, then execution proceeds to step , which checks if other criteria (described below) are met to determine if the partially full IAB should be forwarded at this point to enterprise environment , or if ODP element  should wait till more data is subsequently received from the remote endpoint. If it is determined that the other criteria are met, the IAB is forwarded to enterprise environment  in step  (and the dialog has no current IAB). Otherwise, the partially full IAB is not forwarded, and a check is made in step  to determine if a timer (IA_Timer) is running for this IAB. If IA_Timer is not running, one is started in step . Otherwise, execution ends and awaits the arrival of additional data from the remote endpoint. (When IA_Timer expires, the IAB is forwarded. This time-out is illustrated in step  of . In addition, the MRWU of the dialog and\/or input accumulation timer time-out period may be adjusted at this point (described below).) It should be noted that whenever an IAB is forwarded to enterprise environment , the associated IA_Timer is canceled if it is currently running.","In terms of the above-mentioned \u201cother criteria\u201d of step , satisfaction of any of the following conditions will result in ODP element  forwarding the IAB to enterprise environment .\n\n","Finally, in terms of exception handling, when an action is taken, or an event occurs, such that it is not valid for the connection to receive additional data, the IAB for that dialog is forwarded immediately to the application. Examples of such occurrences are:\n\n","With respect to the above-mentioned MRWU and step  of , values for the MRWU are preferably selected to maximize the size of an IAB. Unfortunately, one side effect of this approach is that the sending protocol stack (e.g., in the remote endpoint) will often run out of window for sending data, thus introducing periods in which no data transfer occurs. As such, it may be beneficial, e.g., to limit the size of an IAB to one-half of the MRWU in order to keep data transfer active. (It should be noted that the MRWU cannot simply be equated to the normal protocol receive window size granted by the local protocol stack to the remote protocol stack. This is due to the fact that the remote protocol stack may have additional criteria limiting the amount of data it will send before waiting for an acknowledgement. For example, the remote protocol stack may limit the amount of data accepted for the remote application in order to limit its usage of available output buffers.)","Illustratively, the MRWU value is initialized to one when a connection is created. This is the lower limit of the MRWU value; the upper limit is the maximum receive window size used by the local protocol stack (which is determined at connection setup as known in the art). Preferably, all updates to the MRWU value are done such that the effect of any given incremental change (sample) is smoothed, i.e., such that any individual sample value does not dramatically affect the original MRWU value. The value of each MRWU for a dialog is maintained independently by ODP element  as follows.\n\n","Turning now to the input accumulation timer, this is used to ensure that pending received data is not delayed indefinitely. While the above-described input accumulation process, as a whole, attempts to limit timeout occurrences, some amount of timeouts are inevitable for many types of dialogs. Ideally, a value for the timeout period is selected such that an IAB is not forwarded unnecessarily early (i.e., when more to-be-received data could have been included in order to reach the optimal IAB size). Additionally, since any timeouts that do occur may introduce unnecessary delays in data transfer, it is also desirable to limit these delays by limiting the timeout period value.","As with the MRWU, the illustrative implementation attempts to adjust the IA_Timer timeout period so as to maximize the size of an IAB. As such, other implementations may modify the timeout period adjustment logic for alternative effects. The IA_Timeout_Value for each dialog is maintained independently as follows (note that all adjustments ensure that the new value is limited by the MIN_ACCUM_TIMEOUT and MAX_ACCUM_TIMEOUT parameters described earlier):\n\n","As described above, and referring briefly back to , the ODP requires some IP processing be performed in enterprise environment  as indicated by IP\u2032 of . A portion of  is redrawn in . In particular, IP\u2032 maintains a routing table  for storing routing information to various remote endpoints. (Routing information in routing table  is collected by using one, or more, of a number of existing techniques, e.g., the \u201croute information protocol\u201d (RIP), the \u201caddress resolution protocol\u201d (ARP), the Internet Control Message Protocol (ICMP), etc.) When TCP\u2032 of management module  requests to open a connection\/dialog to a remote endpoint, IP\u2032 accesses routing table  as a function of the destination IP address associated with the remote endpoint to determine the route to use in sending packets to the remote endpoint. Upon finding route information, this information is provided to TCP\u2032 for inclusion in the above-described TCB . (Including the routing information in TCB  eliminates the necessity of re-determining the route for each and every packet subsequently transmitted after the dialog is established.) This routing information (a part of the above-mentioned \u201cother routing information\u201d  of TCB ) may include physical device information (e.g., a media access control (MAC) address). In addition, routing table  also includes the above-mentioned networking information available within HMP  as to which network servers\/devices can be used to connect to particular IP addresses. Changes to routing information are detected in any number of ways, e.g., via the above-mentioned RIP. After a dialog is established using a particular network interface, if this interface becomes unavailable, the dialog can continue on a different network interface in the same network server. This condition requires an IP route update notification message to be sent to the affected ODP element  of HMP  as indicated in . When a change is detected, suitable modifications (changes, deletions, additions) are made to routing table . Since the routing function of the IP layer is performed in enterprise environment , the associated TCB information of a particular dialog must be provided to ODP element  of a network server in order to correctly build the packets for transmission. As described above, this TCB information is initially provided during an open via the open endpoint message (or open endpoint recover message) to ODP element . This is illustrated in , via TCB \u2033 within TCP\u2033. It should be noted enterprise server  only delivers dialog-specific routing information to that network server -hosting that dialog. As such, enterprise server  is the manager of routing information for many dialogs that may be split over several servers.","Although a particular route to a remote endpoint typically stays the same during the life of the dialog, it may be the case that a routing change is detected (as noted above) by IP\u2032. In this case, IP\u2032 must update the affected routing information by sending an \u201cIP route update notification message\u201d to each affected ODP element  of HMP  as indicated in . As shown in , IP\u2033 maintains its own routing table . A corresponding method for performing a route update is shown in . In step , if IP\u2032 detects a route change\/update, IP\u2032 determines, in step , the affected TCBs and network servers -(e.g., by examining routing information tables stored within IP\u2032 (not shown)). In step , IP\u2032 sends the route update to the affected network servers -. It should be noted that one route update notification message is sent for each affected destination IP address. As such, multiple dialogs (TCBs) to the same destination IP address have their routing information updated at the same time via one route update notification message.","In terms of routing information, ARP is used to resolve the next hop physical (or MAC) address associated with a remote IP address. If a route is not available an error is returned to the TCP\u2032 module. If a route is available but the next hop physical address is unknown, the routing information is passed from IP\u2032 to IP\u2033 with a null next hop physical address and IP\u2032 invokes ARP to broadcast an ARP Request message to the network. The route information is also returned to the TCP\u2032 module and processing continues. If data is sent on a dialog associated with a route that has a null next hop physical address, \u201cP\u201d queues the data in network server -and issues an ARP Request Notification message (e.g., see ) to IP\u2032 to invoke ARP processing. IP\u2032 maintains tables (not shown) that allow it to know what ARP Requests are currently outstanding for various network servers and issues a broadcast ARP Request message as needed. When the ARP Reply message is received by IP\u2032, it issues a new IP Route Update Notification message indicating that the route has been updated and including the next hop physical address received in the ARP Reply message. Upon receipt of the IP Route Update Notification message, IP\u2033 sends any queued data associated with that route. If the ARP Reply is not received within the ARP retry limit, IP\u2032 issues an IP Route Update Notification message indicating that the route should \u201cdiscard\u201d any queued data. Upon receipt of this notification, IP\u2033 purges any queued data on the route and new data sent on the route will again be queued.","A similar technique is used when TCP\u2033 notifies IP\u2033 of \u201cNegative Advice,\u201d that is when a dialog using a particular route has retransmitted passed its threshold. IP\u2033 issues a Negative Advice notification message to IP\u2032 to invoke status checking on the current route. IP\u2032 uses ICMP to determine if the current route is still alive. If the route is still alive, an IP\u2032 route update notification message is issued to IP\u2033 with no new information, signifying that the current route is still alive. Otherwise, if IP\u2032 discovers the current route to be dead, IP\u2032 performs a new route lookup and sends an IP\u2032 route update notification message with the new information if available.","Accumulated Acknowledgements","As can be observed from , there is a flow of ACK messages with respect to both the outgoing and incoming data streams for a single dialog. However, there may be hundreds (if not thousands) of dialogs running on enterprise environment . In this context, enterprise environment  will spend time processing individual ACK messages for incoming and outgoing data. For example, if 15 ACK messages (associated with 10 different dialogs) are received by ODP element  from remote peers, then management module  must individually process each of these 15 ACK messages. Therefore, and as described below, a \u201cMany ACK\u201d message is created for accumulating individual ACK messages whereby processing overhead in enterprise environment  may be significantly reduced. (It should also be observed that use of a \u201cMany ACK\u201d message may cause significant performance improvement due to the reduction in messaging that will occur between enterprise environment  and a network server -.) Continuing with the above example, a \u201cMany ACK\u201d message incorporates the accumulated ACK messages for the 10 dialogs\u2014thus requiring management module  to only process 1 ACK message\u2014not 15. In other words, a single ACK message is now representative of several ACK messages received for each dialog listed in the single ACK message.","An illustrative flow chart for use in providing a \u201cMany ACK\u201d message with respect to previously sent (i.e., outgoing) data packets to a remote peer is shown in . ODP element  maintains a Many ACK list  (this is initially cleared). Many ACK list  identifies individual dialogs (e.g., using the source IP address, destination IP address, source TCP port and destination TCP port from the received ACK) and, for each identified dialog, the current accumulated acknowledgement information for data previously sent by HMP . In step , ODP element  receives an ACK message from the remote peer, the ACK message identifying the dialog and acknowledging data received by the remote peer. In step , ODP element  checks if the identified dialog is on ManyACK list  (e.g., by scanning the stored information in ManyACK list ). If the identified dialog is not on the list, ODP element  adds the dialog to ManyACK list  in step . In either event, ODP element  then saves the acknowledgment information found in the received ACK as the most update acknowledgement in step . In step , ODP element  checks to see if ManyACK list  is full, i.e., has reached a predefined number of dialogs, e.g., 10 dialogs. If ManyACK list  is not full, execution ends till the next received ACK message. However, if ManyACK list  is full, then ODP element  sends to, or exchanges with, management module  a \u201cManyACK\u201d message in step . As determined from ManyACK list , the \u201cManyACK\u201d message lists each dialog and the current amount of data acknowledged for that dialog by the remote peer. In step , ODP element  clears Many ACK list . It should also be noted in step , that a \u201cMany ACK\u201d message is sent if a \u201csignificant ACK\u201d is received from a remote peer for one of the dialogs indicated in ManyACK list . A \u201csignificant ACK\u201d may typically be defined so as to allow the continuous flow of data from the enterprise environment to the network server.","Although ODP element  can continue to accumulate acknowledgement information until ManyACK list  is full, time delays should also be considered\u2014i.e., management module  should not have to wait too long before receiving acknowledgements being held up by ODP element . These data acknowledgements affect the status of any transmission windows and may cause management module  to issue a \u201cnot ready\u201d message to a particular dialog (as illustrated in ). In this context, the flow chart of  illustrates a time-out mechanism. An illustrative value for this timer is 5 seconds. When the time-out occurs, ODP element  executes steps  and  as shown. Thus, management module  receives a \u201cMany ACK\u201d message either when ManyACK list  is full, a significant acknowledgement is received for a dialog or upon the occurrence of a time-out. (It should be noted that when the timer expiration occurs, all the dialogs in ManyACK list  are not necessarily sent up to enterprise environment . In particular, only those dialogs that have been on the list for the timeout interval are sent. So, if a dialog was just newly added to Many ACK list  and the timer expires, that dialog is not included.)","As noted above, the general principle for a \u201cMany ACK\u201d message is to bundle together numerous single ACK messages into one, thereby reducing the message processing overhead incurred by management module  in enterprise environment . However, it may be the case that a dialog between a local application in enterprise environment  and a remote application is transactional in nature, i.e., not only is data being sent from the local application to the remote peer (which then provides the above-described ACK messages), but the remote peer is also sending data to the local application. In this case, a data packet is provided to management module  (it should be noted that input accumulation may also occur as described above). Since management module  must process the data packet (whether it contains accumulated data or not)\u2014any accumulated acknowledgements for that dialog are \u201cpiggy-backed\u201d into the data packet at that time. An illustrative flow chart is shown in . In step , ODP element  receives a data packet for a particular dialog (as indicated by the respective IP source and destination addresses). In step , ODP element  checks if this particular dialog is already listed on ManyACK list . If this particular dialog is not listed in ManyACK list , ODP element  sends data to management module  in step . (As noted above, input accumulation may occur, in which case the data packet sent in step  represents the accumulation of data from one or more received packets.) It should be noted that if any acknowledgement information is already contained within a received packet\u2014this is merely forwarded to management module  in step  (with suitable modifications, if necessary, in the case of an accumulated data packet (as described above)). However, if this particular dialog is listed on ManyACK list , then, in step , ODP element  deletes this particular dialog from ManyACK list . In step , ODP element  piggy-backs the accumulated acknowledgement information into the data packet, which is sent to management module  in step . (It should be noted that since data is being received from the remote endpoint, this flow chart may be modified to support the DWACK processing described below.)","The description above dealt with acknowledgements of data, where the data was sent by HMP  to the remote peer. It has been observed that implementation of the Many ACK mechanism for data sent by remote peers introduces processing overhead in the enterprise environment. This overhead is related mainly to the necessity to implement exclusive access (e.g., via an operating system provided locking mechanism) to Many ACK related information (e.g. the ManyAck list) at several execution points in processing both input and output data. In addition to executing the exclusive access mechanisms, delays may be introduced as Many ACK related processing for one dialog must wait for Many ACK related processing for another dialog to complete. Thus, an alternate method for utilizing the Many ACK mechanism for data sent by remote peers is illustratively shown in .","Turning first to , in step , ODP element  receives a data packet\u2014associated with a particular dialog\u2014from a remote peer. In step , ODP element  checks DemandWACK list  to determine if this particular dialog already has un-acknowledged data associated with it. (DemandWACK list  comprises those dialogs for which there is data received from the remote peer and not yet acknowledged by enterprise environment .) If this particular dialog is not currently on the list, ODP element  adds the dialog to the list in step . In any event, the received data is pushed on to management module  for storage in a corresponding receive window (buffer) associated with the particular dialog. (As noted above, data packets may first be subject to \u201cinput accumulation,\u201d as described above, before being sent to enterprise environment .)","If the remote peer does not receive an acknowledgment to previously transmitted data within a predefined period of time, T seconds, the remote peer will re-send the data. Consequently, ODP element  implements a time-out mechanism to attempt to ensure that an acknowledgement is sent in a timely fashion to the remote peer. For example, every t seconds (where t<T) a time-out occurs (e.g., t=0.1 milliseconds) and ODP element  performs steps  and  shown in . In step , ODP element  sends a \u201cdemand Window Acknowledgment\u201d (Demand WACK) message to management module , where the \u201cDemand WACK\u201d message requests an acknowledgement for any un-ACKed data as indicated in DemandWACK list . In step , ODP element  clears DemandWACK list . (Since ODP element  is providing a mechanism to prompt management module  for acknowledgements, this frees up processing overhead in enterprise environment  since individual acknowledgements do not have to be asynchronously processed. In addition, this eliminates the need to use an ACK timer, for each dialog, in the enterprise environment (since the network server prompts the enterprise environment when to ack) and, in this case, the network server ACK timer is one timer encompassing all dialogs (not one for each dialog.))","Turning now to , enterprise environment  receives the \u201cDemand WACK\u201d message in step . Enterprise environment  then provides, in step , a \u201cMany ACK\u201d message to ODP element , where the \u201cMany ACK\u201d message comprises ACKs for each dialog indicated in the \u201cDemand WACK\u201d message. In step , ODP element  of the network server receives the \u201cMany ACK\u201d message and, in step , provides individual ACK messages to the corresponding remote peers for the dialogs indicted in the \u201cMany ACK\u201d message.","In a similar fashion to that described for incoming data packets, enterprise environment  may take advantage of data that it is sending to a remote peer for piggy-backing acknowledgement information at that time\u2014instead of waiting to received a \u201cDemand WACK\u201d message. An illustrative flow chart for use in a ODP element  is shown in . In step , ODP element  receives data from management module  for transmission to a remote peer, where the data includes acknowledgement information. In step , ODP element  checks if the received acknowledgement corresponds to a dialog currently on DemandWACK list . If this dialog is on DemandWACK list , then ODP element  processes the acknowledgement in step . In step , ODP element  determines if the dialog should be deleted from DemandWACK list . The dialog is deleted, in step , if the acknowledgement acknowledges all of the data and there is a full window. Whether the dialog is deleted, or not, from DemandWACK list , or if the dialog was not on DemandWACK list , the acknowledgment is piggybacked in step  and sent along with data to the remote peer in step .","It should be noted that a TCP ACK includes both acknowledgement information and window size update information. As such, the description above with respect to accumulation, or bundling, of acknowledgements can be extended in a straightforward manner to include accumulation, or bundling, of window size updates.","The foregoing merely illustrates the principles of the invention and it will thus be appreciated that those skilled in the art will be able to devise numerous alternative arrangements which, although not explicitly described herein, embody the principles of the invention and are within its spirit and scope. For example, although illustrated in the context of physically separate heterogeneous environments, one environment may be emulated in the other, e.g., the enterprise environment may be emulated in software in an NT box. Further, the inventive concept is independent of the operating system of both computing environments and\/or the computing environments can be of the same type. For example, both the enterprise system and the network server may be Windows boxes. In addition, although the invention was illustrated in the context of TCP\/IP, the inventive concept is applicable to other transport and network protocols."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWING","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIGS. 2 and 3"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIGS. 11-15"},"dialog recovery;",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIGS. 16-18"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 19-23"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIGS. 24-25"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIGS. 26-32"}]},"DETDESC":[{},{}]}
