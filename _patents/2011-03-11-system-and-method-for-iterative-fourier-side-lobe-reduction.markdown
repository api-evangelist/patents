---
title: System and method for iterative fourier side lobe reduction
abstract: A method and system for generating images from projection data comprising: at least one processor for processing input data, the input data comprising positional data and image data, the image data comprising frequency data for a pre-determined number k frequencies the at least one processor operating to: a) set the frequency data to zero for a predetermined percentage of the k frequencies to form modified frequency data; b) form a preliminary image comprising an array of retained pixel values based upon first positional data and the modified frequency data; c) set the frequency data to zero for a predetermined percentage of the k frequencies to form modified frequency data; d) form a modified image comprising an array of pixels based upon the positional data and the modified frequency data; e) compare the retained array of pixel values to the pixel values of the modified image formed at step (d); f) retain the minimum pixel value at each pixel location to form an image comprising minimum pixel values; g) repeat steps (c) through (f) for L iterations each time retaining an array of pixel values; h) output the image of retained pixel values.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08665132&OS=08665132&RS=08665132
owner: The United States of America as Represented by the Secretary of the Army
number: 08665132
owner_city: Washington
owner_country: US
publication_date: 20110311
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","STATEMENT OF GOVERNMENT INTEREST","REFERENCE TO PARTIAL COMPUTER PROGRAM LISTING","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS"],"p":["This application is a continuation-in-part of and claims priority to U.S. application Ser. No. 12\/881,364, filed on Sep. 14, 2010, entitled \u201cMethod and System for Forming Very Low Noise Imagery Using Pixel Classification,\u201d and U.S. patent application Ser. No. 12\/331,888, filed on Dec. 10, 2008, now U.S. Pat. No. 7,796,829, entitled \u201cMethod and system for forming an image with enhanced contrast and\/or reduced noise.\u201d Both U.S. patent application Ser. No. 12\/331,888 and U.S. Pat. No. 7,796,829 are hereby incorporated by reference as though fully rewritten herein.","The invention, described herein may be manufactured, used, and licensed by or for the United States Government.","Appendix A contains a partial computer listings adapted for a preferred embodiment of the present invention.","The present invention relates to the generation of images from projection measurements. Examples of images generated from projection measurements include two-dimensional and three-dimensional SAR (synthetic aperture radar) systems. SAR is a form of radar in which the large, highly-directional rotating antenna used by conventional radar is replaced with many low-directivity small stationary antennas scattered over some area near or around the target area. The many echo waveforms received at the different antenna positions are post-processed to resolve the target. SAR can be implemented by moving one or more antennas over relatively immobile targets, by placing multiple stationary antennas over a relatively large area, or combinations thereof. A further example of images generated from projection measurements are ISAR (inverse SAR) systems, which image objects and many features on the ground from satellites, aircraft, vehicles or any other moving platform. SAR and ISAR systems are used in detecting, locating and sometimes identifying ships, ground vehicles, mines, buried pipes, roadway faults, tunnels, leaking buried pipes, etc., as well as discovering and measuring geological features, forest features, mining volumes, etc., and general mapping. For example, as shown in FIG. 1 of U.S. Pat. No. 5,805,098 to McCorkle, hereby incorporated by reference, an aircraft mounted detector array is utilized to take ground radar measurements. Other examples of systems using projection measurements are fault inspection systems using acoustic imaging, submarine sonar for imaging underwater objects, seismic imaging system for tunnel detection, oil exploration, geological surveys, etc., and medical diagnostic tools such as sonograms, echocardiograms, x-ray CAT (computer-aided tomography) equipment and MRI (magnetic resonance imaging) equipment.","Systems which produce images from projection data generally use techniques in the time domain, where a backprojection-type algorithm is used, or frequency domain, where Fourier transforms are used. Since a Fast Fourier Transform (FFT) technique, such as a technique known as the \u201c\u03c9-k\u201d implementation, requires data to be equally spaced, FFT-based techniques produce sub-optimal images when the data source is moving uncontrollably, such as an aircraft buffeted by winds or vehicles in rough terrain. Non-Uniform spacing requires a Discrete Fourier Transform (DFT) which increases computation expense relative to a backprojector technique. Also, two-dimensional FFT's are not well suited to multiprocessor-based supercomputers because they face a corner-turn interprocessor communication bottleneck.","While there are many forms of Fourier-based algorithms for SAR processing, they fall into two broad classes known as \u201cstrip-map\u201d mode and \u201cspot light\u201d mode. The most robust technique is the \u03c9-k technique, also known as seismic migration. The advantage of the \u03c9-k algorithm over the backprojection algorithm is speed. The \u03c9-k algorithm is an order Nlog(N) implementation\u2014much faster than Nfor large images and data sets.","Time domain backprojection-based techniques have been used for numerous applications, including x-ray CAT scans, MRI and sonograms. Historically, medical people have preferred backprojection because its artifact levels were lower than those using fast Fourier transform (FFT) approaches. Efforts in the past to speed up the backprojection process have focused on fast index generation. The algorithm form used by the medical industry (e.g., Star Computers) for x-ray CAT scans requires approximately 2Nadds to form an N by N image from N projections\u2014Nadds for indexing operations, and Nadds for accumulating the projections into the image. Seismologists and people using SAR have also used backprojection.","Synthetic aperture radar systems have been used in applications such as area mapping, surveillance, and target detection. The radar is usually mounted on an aircraft or a vehicle configured with transmitting and receiving antennas to transmit and measure the reflected radar signals from areas of interest. Through signal processing, the reflected radar signals along the flight path are combined to form the SAR imaging for side looking or forward looking surveillance.","SAR imaging is complex for a variety of reasons. First, the data is not inputted at equally distant (or known) points. Instead, data may be inputted in a non-uniform manner from an aircraft that is buffeted by the wind or from a ground vehicle that traverses rough ground. Therefore, motion compensation must be introduced in order to produce sharp images. Second, the subject objects need not be point sources but may be dispersive\u2014where energy is stored and \u201cre-radiated\u201d over time. Ground penetrating SAR adds the complication that the media propagation velocity varies which complicates seismic processing. For many SAR applications, especially for high-resolution, ultra-wide-angle (UWA), ultra-wide-bandwidth (UWB) surveillance systems, the task is particularly problematic because the data sets are large, real-time operation is essential, and the aperture geometry is not controlled. For small aircraft buffeted by the wind can affect SAR data due to significant off-track motion and velocity changes. As a result, the data is not sampled at equally spaced intervals.","Backprojection techniques provide many advantages; including sharper images. Although prior art backprojector implementations may generate image artifacts; they are constrained to be local to the object generating the artifacts and generally lie within the theoretical sidelobes. Side lobes are the lobes of the radiation pattern that are not the main beam or lobe. In an antenna radiation pattern or beam pattern, the power density in the side lobes is generally much less than that in the main beam. It is generally desirable to minimize the sidelobe level (SLL), commonly measured in decibels relative to the peak of the main beam. The concepts of main and side lobes apply to (but are not limited to) for example, radar and optics (two specific applications of electromagnetics) and sonar. The present invention is directed to techniques which minimize the effects of theoretical sidelobes in order to provide enhanced images.","Backprojector techniques also allow for non-uniform spacing of the projection data. The non-uniform spacing is directly accounted for in the index generation, which is important when compensating for aircraft motion.","Conventional time domain image formation, or backprojection, from SAR data, is accomplished by coherently summing the sampled radar returns for each pixel. In this context, coherent summation can be thought of as time-shifting the signal obtained at each aperture position (to align them to a particular pixel) and adding across all aperture positions to integrate the value at that pixel. This time-align-and-sum sequence is repeated for every pixel in the image.","A method and system for forming images by backprojection is explained in U.S. Pat. No. 5,805,098 to McCorkle, hereby incorporated by reference as though fully rewritten herein. Specifically, FIG. 2 of the 1998 patent illustrates antennas at positions 208 along axis 204 in an array that observe pixels 202 in the near field of the array. A relative position of each pixel (q,r) with respect to each antenna position j defines a vector 206. For each pixel (q,r), the disclosed process time-shifts the signals obtained at each aperture position j (to align, or stack, them at a particular pixel location) to correct the signals for propagation time along each vector 206 and then adds across all aperture positions to integrate to the value at the pixel. Thus, signals propagating from that location are in-phase and reinforced, while signals propagating from other locations are not in phase and integrate toward zero. The image is generated by forming such a sum for each pixel as shown in equation (1A) below.","In equation (1A) below, the pixels of the image area are indexed by (q,r) and the aperture positions are indexed by j, where j=0 . . . L\u22121 and L is the number of elements in the aperture. If s(t) represents the range-compensated (Rpropagation loss corrected, where R is range) voltage received at the japerture position as a function of time (t), zis an aperture weighting to shape the sidelobes, for example, with a Hamming window, or to account for the aperture spacing, and Tis the time shift necessary to align the signal received at sensor position j to the pixel at position (q,r) (a function of the round-trip time from sensor phase center to pixel position), then the value of the focused pixel at image position (q,r) is given by:",{"@attributes":{"id":"p-0016","num":"0015"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"f","mrow":{"mi":["q","r"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"munderover":{"mo":"\u2211","mrow":[{"mi":"j","mo":"=","mn":"0"},{"mi":"L","mo":"-","mn":"1"}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["z","i"]},"mo":"\u00b7","mrow":{"mrow":{"msub":{"mi":["s","j"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","msub":{"mi":"T","mrow":{"mi":["q","r","j"],"mo":[",",","]}}}}},"mo":"."}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"\u2062","mi":"a"}}}]}}}}},"Here, t describes how the focused signal at location (q,r) varies with time, and is useful for studying late-time target ringing. This description of backprojection considers the case where t is fixed for the entire image.","Accurately obtaining the time-shifted values s(t+T) requires a time domain interpolation of the sampled received signals. Prior art techniques included the following steps:\n\n","The following references give an overview of the state of the art and are hereby incorporated by reference in their entireties:\n\n","An example of a forward-looking Synchronous Impulse Reconstruction (SIRE) radar that can be vehicle-mounted has been designed and built by the Army Research Lab. A more complete description of the SIRE radar can be found in M. Ressler, L. Nguyen, F. Koenig, D. Wong, and G. Smith, \u201cThe Army Research Laboratory (ARL) Synchronous Impulse Reconstruction (SIRE) Forward-Looking Radar\u201d, Proceedings of SPIE, Unmanned Systems Technology IX, April 2007, hereby incorporated by reference. The SIRE radar has two transmitters and an array of receiving antennas. The two transmitters alternatively transmit wide bandwidth impulses to illuminate the area in front of the vehicle. An array of receiving antennas measures the returned radar signals. The wide bandwidth of transmitted impulses provides the down-range resolution while the array of receiving antennas provides the cross-range resolution. It has been shown that the configuration with two transmitters located at the end of the array is the optimum configuration to achieve cross-range resolution while minimizing the number of required transmitters.","After data is acquired by the radar hardware, it is transferred to a computer for signal processing and image formation. The signal processing stages include a) self-interference extraction, b) removing radar signature distortion due to moving platform, and c) sub-band filtering. The self-interference processing step to extract the interference components from the returned radar signals and the technique to remove the phase and shape distortion in radar signals due to the motion of the radar platform are described in the publication by Lam Nguyen, entitled \u201cSignal Processing Technique to Remove Signature Distortion in ARL Synchronous Impulse Reconstruction (SIRE) Ultra-Wideband (UWB) Radar,\u201d Army Research Laboratory Technical Report, ARL-TR-4404, March 2008, hereby incorporated by reference.","After all the signal processing steps are applied to the returned radar signals, the processed radar range profiles may be used for forming a SAR image. In a preferred embodiment, the back-projection algorithm is utilized for the image formation step. See, John McCorkle and Lam Nguyen, \u201cFocusing of Dispersive Targets Using Synthetic Aperture Radar,\u201d Army Research Laboratory Report, ARL-TR-305, August 1994.",{"@attributes":{"id":"p-0023","num":"0033"},"figref":"FIG. 1A","sub":["R","R","R","T","T","T","T","T","T","R","R","R","k","i ","P","P","P","k ","k","k"],"sup":["2 ","2"]},{"@attributes":{"id":"p-0024","num":"0034"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":"R","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},"mo":"=","mfrac":{"mi":"ct","mn":"2"}}}},"br":{},"sup":"8 "},{"@attributes":{"id":"p-0025","num":"0035"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"K"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["w","k"]},"mo":"\u2062","mrow":{"msubsup":{"mi":["s","k","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","k"],"mo":","}}}}}}}],"mo":"="},{"mn":"1","mo":["\u2264","\u2264"],"mi":["i","N"]}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"1"}}]}}}},"br":{},"sub":["k ","k"]},"The index is computed using the round-trip distance between the transmitting element, the image (pixel), and the receiving element. The transmitting element is located at the coordinate (x(k), y(k), z(k)). The distance between the transmitting element and the image pixel P(i) is:",{"@attributes":{"id":"p-0027","num":"0037"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":"d","mn":"1"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","k"],"mo":","}}},"mo":"=","msqrt":{"mrow":{"msup":[{"mrow":{"mo":["[","]"],"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":{"mi":["x","T"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["x","P"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}],"mo":"-"}}},"mn":"2"},{"mrow":{"mo":["[","]"],"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":{"mi":["y","T"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["y","P"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}],"mo":"-"}}},"mn":"2"},{"mrow":{"mo":["[","]"],"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":{"mi":["z","T"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["z","P"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}],"mo":"-"}}},"mn":"2"}],"mo":["+","+"]}}}},{"mrow":{"mo":["(",")"],"mn":"2"}}]}}}}},"The distance between the receiving element and the image pixel P(i) is",{"@attributes":{"id":"p-0029","num":"0039"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":"d","mn":"2"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","k"],"mo":","}}},"mo":"=","msqrt":{"mrow":{"msup":[{"mrow":{"mo":["[","]"],"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":{"mi":["x","R"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["x","P"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}],"mo":"-"}}},"mn":"2"},{"mrow":{"mo":["[","]"],"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":{"mi":["y","R"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["y","P"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}],"mo":"-"}}},"mn":"2"},{"mrow":{"mo":["[","]"],"mrow":{"mo":["(",")"],"mrow":{"mrow":[{"msub":{"mi":["z","R"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"msub":{"mi":["z","P"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}}],"mo":"-"}}},"mn":"2"}],"mo":["+","+"]}}}},{"mrow":{"mo":["(",")"],"mn":"3"}}]}}}},"br":[{},{},{}],"in-line-formulae":[{},{}],"i":["d","i,k","d","i,k","d","i,k"],"sub":["1","2"]},{"@attributes":{"id":"p-0030","num":"0040"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","k"],"mo":","}}},"mo":"=","mfrac":{"mrow":{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","k"],"mo":","}}},"mi":"c"}}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}}},{"@attributes":{"id":"p-0031","num":"0041"},"figref":["FIG. 1B","FIG. 1A","FIG. 1B","FIG. 1B"],"b":"1"},"The following is a description of the platform  in  as it passes four sequential positions , & located at x-coordinates A, B, C & D, respectively. The formation of the first sub-image begins when platform  is at the coordinate A, 20 meters from the block labeled \u201c1sub-image.\u201d As platform  travels in the x direction (as shown in ), signals emitted from platform  illuminates an entire image area to the right of platform , and the reflected signals are received by an array of 16 physical receiving antennas  positioned on the front of the platform . Formation of the first sub-image ends when platform  reaches coordinate C, at approximately 8 m from the block labeled \u201c1sub-image.\u201d Accordingly, the radar signal data for the first (full-resolution) sub-image is received as radar platform  travels a distance of 12 meters (20 m\u22128 m=12 m) from coordinates A to C, for formation of a two dimensional (2D) aperture.","The distance traveled during the formation of the two-dimensional (2-D) aperture is represented by an arrow in  labeled \u201cAperture .\u201d When the platform  reaches coordinate B, a distance of 2 meters from coordinate A in , the formation of the \u201c2sub-image\u201d begins, and as the platform  travels to coordinate D, it uses the received data to form a second 2-D aperture. The distance traveled by platform  is represented by an arrow in  labeled \u201cAperture .\u201dNote that the two apertures are overlapped by 10 m and the second aperture is \u201cadvanced\u201d by 2 m with respect to the first aperture. Sub-images  and  are formed from the 2-D apertures using the same length of travel (12 meters) of the radar. This process is applied to ensure that image pixels have almost the same (within a specified tolerance) resolution across the entire large area. The sub-images are formed from the radar range profiles using the back-projection algorithm.",{"@attributes":{"id":"p-0034","num":"0044"},"figref":["FIG. 2","FIG. 1A"]},{"@attributes":{"id":"p-0035","num":"0045"},"figref":"FIG. 3"},"The term \u201cnoise\u201d as used herein relates to image noise. There are many sources that cause noise in the resulting image. Noise can be divided into two categories: additive noise and multiplicative noise. System noise, thermal noise, quantization noise, self-interference noise, radio frequency interference (RFI) noise are some examples of the additive noise. Multiplicative noise is much more difficult to deal with since it is data dependent. Some sources that cause multiplicative noise include: timing jitter in data sampling, small aperture size compared to image area, the under-sampling of aperture samples, the non-uniform spacing between aperture samples, errors in position measurement system, etc. Multiplicative noise results in undesired sidelobes that create high noise floor in the image and thus limit the ability to detect targets with smaller amplitudes.","Radar and other imaging systems currently suffer various noise sources that prevent the generation of very high contrast images. As a result, difficult targets (with low amplitudes) are often obscured or even embedded, in the noise level of the image background. Moreover, sidelobes from large targets are mistaken as targets of interest. Recently the ARL has designed and built a new ultra-wideband imaging system for the detection of difficult targets. Currently, there exists a need for an improved signal processing technique which reduces unwanted noise and enhances image reproduction.","Stepped-Frequency radar technology comprises hardware and software subsystems that have attained advanced levels of technological maturity. The popularity of the paradigm attests to both its practicality and its analytic tractability. Stepped-frequency radar systems achieve high resolution in the time domain by effectively measuring the frequency-domain response over a large bandwidth and then transforming from frequency to time. In particular, a series of pulses is transmitted, with each pulse centered at a specific frequency. The reflected waves from a target are coherently sampled, and since the transmitted frequencies are evenly-spaced, a high resolution time-domain, waveform can readily be constructed via a Fast Fourier Transform (FFT). The time-domain resolution of the system is determined by the total bandwidth (i.e. the number of frequency steps and the frequency step size). The duration of the high-resolution signature will be fixed by the pulse width and the frequency step size.","When operating at lower frequencies, it is possible for stepped-frequency radars to interfere with indigenous radio frequency (RF) transmissions, such as television stations, cell phones, and air traffic control. Hence, it becomes necessary for a radar operator to \u201cnotch-out\u201d certain transmit frequencies, thereby producing unwanted artifacts in the final radar signature. These effects are well-documented in the literature, and efforts have been undertaken to mitigate them, with varying degrees of success. 2. STEPPED FREQUENCY RECURSIVE SIDELOBE MINIMIZATION","Non-linear techniques for reducing sidelobe artifacts have existed for several years. For example, non-linear apodization techniques, developed by Stankwitz et al. 6-7, exploit the time- and frequency-domain characteristics of specific weighting windows to reduce sidelobe artifacts in synthetic aperture radar (SAR) imagery. Another recently presented technique, recursive sidelobe minimization (RSM), operates strictly in the time-domain, and it combines concepts from the theories of both apodization and compressive sensing 8-10 to reduce image artifacts. Unfortunately, this restriction of the current RSM formulation to the time domain precludes elimination of artifacts introduced by frequency notching.","The present invention is directed, inter alia, to a procedure for reducing the severity of radar signature artifacts through the incorporation of a non-linear processing technique that suppresses sidelobes introduced by frequency-domain notching. An example of a preferred embodiment technique is referred to as \u201cstepped-frequency recursive sidelobe, minimization\u201d (SFRSM).","The methodology of the present invention comprises, adaptation of the RSM procedure that has been implemented to mitigate the effects of sidelobes introduced by frequency-notching. That is, the randomization introduced as part of the time-domain RSM processing is extended to the frequency domain prior to formation of the high resolution range (HRR) profile. The HRR profile is simply the IFFT of the frequency domain (low range resolution, or LRR) profile.) Hence, in the same way that the user specifies a percentage of the available time-domain samples to retain for RSM image formation, the user also specifies the percentage of the available frequency-domain samples to retain for SFRSM HRR signature formation. Once the SFRSM HRR profile of a preferred embodiment has been created, the normal image-formation processing can proceed via application of a procedure such as time-domain back-projection algorithm of choice.","A block diagram of the processing paradigm as implemented in a synthetic aperture radar (SAR) system is shown in , wherein a dashed box indicates the location of the proposed improvements. A preferred embodiment comprises a pre-processing sidelobe reduction algorithm, a sidelobe reduction post-processing algorithm, and an iterative processing procedure indicated by the L-iteration loop in the diagram. Note that the existing SAR image formation algorithm, indicated by a solid rectangle within the larger dashed rectangle, remains an integral part of the enhanced formulation; hence, the invention could be incorporated into any stepped-frequency SAR image formation process.","When implemented as described, the preferred embodiment technique substantially reduces the severity of sidelobe artifacts due to, the elimination of n of the N frequencies comprising the stepped frequency waveform.","Although the present invention bears some similarity to U.S. Pat. No. 7,796,829 to Nguyen (hereinafter '829 Nguyen patent), the preferred embodiment methodology addresses a problem that is fundamentally different than that addressed in the '829 Nguyen patent. The problem formulation of '829 Nguyen patent concentrated on artifacts observed when the entire transmitted bandwidth is available. The present invention concentrates on, inter artifacts induced by limiting the allowed transmission frequencies to a subset of the available band (i.e. \u201cnotching out\u201d specific frequency steps).",{"@attributes":{"id":"p-0046","num":"0056"},"figref":["FIG. 21","FIG. 21","FIG. 23"]},{"@attributes":{"id":"p-0047","num":"0057"},"figref":["FIG. 24","FIGS. 25"],"b":["26","27","29"]},"A preferred embodiment comprises a system for generating images from projection data comprising: at least one processor for processing input data, the input data comprising positional data and image data, the image data comprising frequency data for a pre-determined number k frequencies the at least one processor operating to: a) set the frequency data to zero for a predetermined percentage of the k frequencies to form modified frequency data; b) form a preliminary image comprising an array of retained pixel values based upon first positional data and the modified frequency data; c) set the frequency data to zero for a predetermined percentage of the k frequencies to form modified frequency data; d) form a modified image comprising an array of pixels based upon the positional data and the modified frequency data; e) compare the retained array of pixel values to the pixel values of the modified image formed at step (d); f) retain the minimum pixel value at each pixel location to form an image comprising minimum pixel values; g) repeat steps (c) through (f) for L iterations each time retaining an array of pixel values; h) output the image of retained pixel values.","These and other aspects of the embodiments of the invention will be better appreciated and understood when considered in conjunction with the following description and the accompanying drawings. It should be understood, however, that the following descriptions, while indicating preferred embodiments of the invention and numerous specific details thereof, are given by way of illustration and not of limitation. Many changes and modifications may be made within the scope of the embodiments of the invention without departing from the spirit thereof, and the embodiments of the invention include all such modifications.","The embodiments of the invention and the various features and advantageous details thereof are explained more fully with reference to the non-limiting embodiments that are illustrated in the accompanying drawings and detailed in the following description. It should be noted that the features illustrated in the drawings are not necessarily drawn to scale. Descriptions of well-known components and processing techniques are omitted so as to not unnecessarily obscure the embodiments of the invention. The examples used herein are intended merely to facilitate an understanding of ways in which the embodiments of the invention may be practiced and to further enable those of skilled in the art to practice the embodiments of the invention. Accordingly, the examples should hot be construed as limiting the scope of the embodiments of the invention.","The terminology used herein is for the purpose of describing particular embodiments only and is not intended to limit the full scope of the invention. As used herein, the singular forms \u201ca\u201d, \u201can\u201d and \u201cthe\u201d are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms \u201ccomprises\u201d and\/or \u201ccomprising,\u201d when used in this specification, specify the presence of stated features, integers, steps, operations, elements, and\/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, and\/or groups thereof.","It will be understood that, although the terms first, second, etc. may be used herein to describe various elements, components, regions, layers and\/or sections, these elements, components, regions, layers and\/or sections should not be limited by these terms. For example, when referring first and second photons in a photon pair, these terms are only used to distinguish one element, component, region, layer or section from another region, layer or section. Thus, a first element, component, region, layer or section discussed below could be termed a second element, component, region, layer or section without departing from the teachings of the present invention.","Furthermore, relative terms, such as \u201clower\u201d or \u201cbottom\u201d and \u201cupper\u201d or \u201ctop,\u201d may be used herein to describe one element's relationship to other elements as illustrated in the Figures. It will be understood that relative terms are intended to encompass different orientations of the device in addition to the orientation depicted in the Figures. For example, if the device in the Figures is turned over, elements described as being on the \u201clower\u201d, side of other elements would then be oriented on \u201cupper\u201d sides of the other elements. The exemplary term \u201clower\u201d, can therefore, encompass both an orientation of \u201clower\u201d and \u201cupper,\u201d depending of the particular orientation of the figure. Similarly, if the device in one of the figures is turned over, elements described as \u201cbelow\u201d or \u201cbeneath\u201d other elements would then be oriented \u201cabove\u201d the other elements. The exemplary terms \u201cbelow\u201d or \u201cbeneath\u201d can, therefore, encompass both an orientation of above and below. Furthermore, the term \u201couter\u201d may be used to refer to a surface and\/or layer that is farthest away from a substrate.","Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this invention belongs. It will be further understood that terms, such as those defined in commonly used dictionaries, should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art and will not be interpreted in an idealized or overly formal sense unless expressly so defined herein.","Disclosed in U.S. Pat. No. 7,796,826 ('826 patent) is a non-linear imaging algorithm that significantly improves the background noise level of the resulting image () without negatively affecting the focus quality (sharpness) as well as the target amplitudes. In the '826 patent, this technique has been denominated as Recursive Sidelobe. Minimization (RSM).","Recursive Sidelobe Minimization (RSM)","As depicted , radar data is collected from a number of positions. For each position, radar data and the positional data are recorded. A \u201cdata point\u201d represents the received signal radar data from each position obtained during an instant or interval in time combined with positional information corresponding to the transmitting and\/or receiving position or location. The data points may be collected by either an array of elements or a single moving element which receives data at points in time, or the combination of both; e.g., a physical array of elements with the elements moving over increments of time. The data collection may be sporadic or at specific intervals of time. As exemplified in , data points are obtained using an array of receiving elements which receive data incrementally. The data points are arranged to form an aperture. As used herein, the term \u201caperture\u201d means the information or data components used to form an image; which may be for example, an array of data points developed from a scanned area, target or scene which can be used to form an image. In the apertures depicted in , each column represents an interval during which the 1-k elements receive data; each data point representing the image data from the signal received combined with the coordinates of the receiving element. After the data points are established in an aperture (or array), as diagrammatically shown in , a substantial portion of data points are removed from the original aperture (array of data points) to form a \u201csubarray.\u201d Conversely, the \u201csubarray\u201d may be formed by the selection of data points within the original aperture. Depending upon the quality of the result desired and the nature of the image being undertaken, the substantial portion of the data points removed or selected may range from as little as one percent to ninety percent. However, one percent removal will result in negligible difference and ninety percent removal will result in drastic reduction of image quality. In general, it is preferred that the percentage of data points subject to removal be within a range of approximately twenty to fifty percent. Using the remaining data points in the aperture, a first preliminary image is formed. During a second interval, the process of removing a different set of twenty to fifty percent of the data points within the original aperture is repeated and a second aperture is formed. In a preferred embodiment, the data points subject to removal are randomly chosen. However, random selection is not necessary to practice the principles of the present invention and some other arbitrary or contrived selection process may be used.","A second preliminary image is formed from the second aperture following the removal of a different set of data points. The first and second preliminary images are then compared. Using the principles of the present invention, the magnitude of the signal at each bit-mapped location of the preliminary images is compared. Any pixel having a greater or equal value is discarded, and only the lesser value is used for each bit-mapped location in the merged image. For each subsequent iteration, approximately twenty to fifty percent of the data points are removed to form an aperture and the preliminary image developed therefrom is compared with the previously merged image. The magnitude of the signal at each pixel or bit mapped location is compared and only the lesser value is retained for each bitmapped location in the combined image. This process is repeated iteratively over a series of iterations, which may be for example ten to several hundred iterations. The result is the substantial elimination of noise from the resulting merged image.","Although the technique is implemented and demonstrated for the ultra wide band forward-looking imaging radar (e.g., ARL SIRE), the technique is suitable for used for other image radar as well. The technique may also be applied for the BoomSAR radar, which is a different radar with different configuration (side-looking). Moreover, this imaging technique is not limited to the formation of radar images as it can be applied to other applications such as CAT scans, magnetic resonance, seismic, sonar, and acoustic imaging.","Use of the Recursive Sidelobe Minimization (RSM) technique results in an improvement of image contrast by reducing system noise by a significant level, significantly improving system performance; and can be adapted for use with existing radar systems. Results include the generation of high contrast images produced by significantly reducing the noise level in the system such that very difficult targets or objects (with low amplitudes) in the image can be detected, which otherwise would be embedded in the system noise.","Generally speaking, in any imaging system, the sidelobes from large objects or noisy spots generated by the system may be mistaken as targets of interest. In accordance with the principles of the present invention, the large sidelobes are substantially virtually eliminated, thus reducing the false alarm objects that would be considered as targets of interest.","Possible uses other than radar imaging include magnetic resonance imaging, CAT scan, sonar imaging, and acoustic imaging.",{"@attributes":{"id":"p-0101","num":"0111"},"figref":["FIG. 4","FIG. 3","FIG. 4","FIG. 3","FIGS. 3 and 4","FIG. 4","FIG. 3"]},"Recursive Sidelobe Minimization Using Compressive Aperture",{"@attributes":{"id":"p-0102","num":"0112"},"figref":["FIG. 5","FIG. 5"]},"Step A\u2014Radar data and its position information is acquired.","Step A\u2014The radar aperture is formed in preparation for image formation. The aperture consists of K elements. Each element in the radar aperture includes the radar receiving position information (x(k), y(k), z(k)), the radar transmitting information (x(k), y(k), z(k)), and the data record s(t) that the radar measures at this location. For side-looking radar, the aperture is usually a linear path with data measured along the path. For the forward-looking radar mentioned above, a 2D radar aperture is generated; formed by the physical antenna array and the forward motion of the radar. Although the terminology \u201c2D\u201d or two dimensional is used to reflect the aperture configuration, the data within the 2D aperture may contain three dimensional information concerning the target area in that the signal data may include the distance at which the target is located relative to the receiving element. In general, the radar aperture may take any of a variety of shapes and those shown are merely examples.","Step A\u2014The imaging grid is formed. In a preferred embodiment a rectangular imaging grid is generated although the imaging grid could be arbitrary defined. Each pixel Pin the imaging grid is located at coordinate (x(i), y(i), z(i)).","Step A\u2014A random compressive aperture is generated using the radar aperture with K elements from step A. The compressive aperture is formed by selecting only L elements from the original aperture for the imaging process. The value for L is\n\n. Where 01\u2003\u2003(6).\n\nAccordingly, only a subset of the aperture positions are used for image formation. The remaining K\u2212L aperture positions are simply discarded for this realization. The typical number that we use for our configuration is p=0.8 (i.e., 80% of the aperture is employed and 20% of the aperture is discarded at each iteration). The value of p that can achieve best result should be examined and optimized for each configuration of geometry and radar data set. In a preferred embodiment, the selection of L aperture positions is completely random for each realization. If Arepresents a vector that contains the indices of aperture positions to be included in the image formation process for lrealization, then:\n\nA=\u03b1, \u03b1, . . . , \u03b1\u2003\u2003(7)\n\nwhere \u03b1, is a random number, 1\u2266\u03b1\u2266K and \u03b1\u2260\u03b1for m\u2260n.\u2003\u2003(8)\n","The technique disclosed in the '829 patent may use, a random number generator that produces random numbers with certain distribution. Those of ordinary skill in the art would readily appreciate that there are Many types of distributions. The two distributions that are widely employed in practice are uniform (in which all values from a finite set of possible values are equally probable) and Gaussian (in which all values from a finite set of possible values follow the Gaussian distribution that has the shape of a bell curve). Although any random number distribution could be used to realize (7) and (8), a uniform distribution random number generator may be employed in this preferred embodiment. There are many different implementations for generating a uniformly distributed random numbers for use in conjunction with the present invention; including those random number generator routines that are usually defined and included in general purpose computer programming languages. For example, in C programming language the two routines srand( ) and rand( ) are used to generate a random number. First, the srand( ) routine is called to initialize the random number generator. Next, the rand( ) routine is called to generate a random number between 0 and a predefined value RAND_MAX. The following code fragment (C language) demonstrates how to generate 100 uniformly distributed numbers that have values from 0 to M=1000.",{"@attributes":{"id":"p-0108","num":"0118"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"175pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["seed=9000;","\/* choose a seed value *\/"]},{"entry":["srand(seed);","\/* initialize random number generator *\/"]},{"entry":["M=1000;","\/* initialize value of M *\/"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"For (i=1; i<100 ; i++)"},{"entry":"{"},{"entry":"\/* random1 is a floating-point number from 0 to 1 (not including 1) *\/"},{"entry":"random1 = ( (double)rand( )\/((double)(RAND_MAX)+(double)(1));"},{"entry":"\/* random2 is a floating-point number from 0 to M (not including M) *\/"},{"entry":"random2=(double)M* random_1;"},{"entry":"\/* random3 is an integer number from 1 to M (including M) *\/"},{"entry":"random3=(int)random2+1;"},{"entry":"}"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"To generate the vector of random number Aas described in (7) and (8), one can use the random number generator as shown in the above code fragment example. Each time a random number is generated, it is compared to the previous ones to ensure that all elements in Aare unique as specified in (8). Otherwise, another random number is generated to satisfy (8).","It can be readily appreciated by those of ordinary skill in the art that the term \u201crandom numbers\u201d as used herein includes numbers generated selectively or arbitrarily. As shown in the foregoing, the selection process may be one of those commonly associated with computer programming, but other number selection processes or arbitrary number selection processes may be utilized to achieve the same or similar results without departing from the principles of the present invention.",{"@attributes":{"id":"p-0111","num":"0121"},"figref":"FIG. 6","sup":["th ","th "]},"Generally speaking, it is not intuitive as to why only a subset of the original radar aperture is used instead of the full aperture for forming image, since gaps introduced in the subset of an aperture would seem to result in inferior performance. In prior art conventional techniques, one generally prefers the full data set and avoids the gapped data set. However, the benefit of this \u201csubset\u201d approach will be examined later in conjunction with step A below.","Step A\u2014The image is formed using the compressive aperture generated from step A. The compressive aperture derived from Awith L elements is then used to form the lrealization of the sub-image using the backprojection method as described above.","This results in the lrealization of the sub-image with I pixels in the down-range direction and J pixels in the cross-range direction, where N=I\u00b7J\n\n(), 1\u2003\u2003(9)\n\nwhere P(i) is computed using equation (1) with modification, reproduced below:\n",{"@attributes":{"id":"p-0115","num":"0125"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"i"}},{"munder":{"mo":"\u2211","mrow":{"mi":"k","mo":"\u2208","msub":{"mi":["A","l"]}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["w","k"]},"mo":"\u2062","mrow":{"msubsup":{"mi":["s","k","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","k"],"mo":","}}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":"\u2062","mi":"b"}}}]}}}},"br":{},"sub":"l "},"Step A\u2014The envelope of the image generated in step A is computed. The image generated in step A can also be written as:\n\n(), 11\u2003\u2003(10)\n\nwhere Pis the jdown-range profile from the lrealization sub-image.\n\nThe corresponding quadrature component of this image down-range profile is computed by applying the Hilbert transform filter to the in-phase component\n\n=Hilbert()\u2003\u2003(11)\n","The Hilbert transform filter has magnitude  at all frequencies and introduces a phase shift of",{"@attributes":{"id":"p-0118","num":"0128"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"-","mfrac":{"mi":"\u03c0","mn":"2"}}}},"br":{}},{"@attributes":{"id":"p-0119","num":"0129"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"+","mfrac":{"mi":"\u03c0","mn":"2"}}}},"br":{}},{"@attributes":{"id":"p-0120","num":"0130"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mfrac":{"mi":"\u03c0","mn":"2"}}},"br":{}},"As disclosed in the '829 patent, in one preferred embodiment using the Hilbert transform filter, the envelope of the jdown-range profile from the lrealization of the image may be computed as\n\n=\u221a{square root over (()+())}{square root over (()+())}. (where the subscript is )\u2003\u2003(12)\n\nThe envelope of this image is simply\n\n(), 11\u2003\u2003(13)\n",{"@attributes":{"id":"p-0122","num":"0132"},"figref":"FIG. 7","sup":["th ","th "]},"Step A\u2014An intermediate resulting image is computed. The minimum operator is applied to two images: 1) the intermediate result from previous iteration (l\u22121)and 2) the image formed from this iteration. For each image pixel, the values of the two images are compared and the minimum value is selected\n\nIm=minI,Im, 2\u2266l\u2266M\u2003\u2003(14)\n\nwhere Imis the intermediate resulting image at (i)iteration. Note that equation (14) is defined for 2\u2266l\u2266M. For the first iteration (l=1), Imis initialized with a very large values, so that the intermediate resulting image Im=minI,Im\u2266I.\n",{"@attributes":{"id":"p-0124","num":"0134"},"figref":["FIG. 8","FIG. 8","FIG. 8"]},"Another performance comparison is shown in , wherein the cross-range profile (horizontal cut) through each image (two input images and one resulting image) is displayed to compare the sidelobe level and the target response from each image. Again, it can be appreciated that the target responses remain substantially the same while the sidelobe level of the resulting image is better (lower) than either input image. By repeating this process for many compressive apertures, the sidelobe level in the resulting image continues to improve (lower) while the target responses remain substantially unchanged.","After step A, the algorithm returns to step A to continue with the next iteration until the Miteration is finished. The intermediate resulting image is also sent to the display routine for visualizing the image.  illustrates the compressive image and the intermediate resulting image generated in the first, three iterations.  shows the results at various iterations. In the resulting image at iteration , the sidelobes are significantly suppressed while the responses of the two targets remained unchanged.",{"@attributes":{"id":"p-0127","num":"0137"},"figref":["FIG. 9","FIG. 9"],"b":["1","2"]},{"@attributes":{"id":"p-0128","num":"0138"},"figref":["FIG. 10","FIG. 11"]},{"@attributes":{"id":"p-0129","num":"0139"},"figref":"FIG. 11","i":"a "},"Although in the '829 patent, the application of the RSM technique for a preferred embodiment configuration (a UWB radar configured in forward-looking imaging mode), this RSM method could be applied to any coherent imaging system where measurements from an aperture of arbitrary geometry (linear, curve, 2-D, or 3-D) are coherently integrated to form a 2D or 3D image.  shows the \u201cbefore\u201d and \u201cafter\u201d images when the RSM technique is applied to the SIRE radar data in forward-looking configuration.  illustrates a comparison of a baseline image (left) with an image (right) from a Recursive Sidelobe Minimization (RSM) preferred embodiment technique using data from another radar (e.g., BoomSAR) with a different geometry (side-looking SAR) and a single transmit antenna and single receive antenna in a pseudo-monostatic configuration.","The '829 patent includes a code listing representative of the RSM algorithm in Appendix A.","Image Formation by Pixel Classification (Based upon Variation of Pixels over Iteration Process)",{"@attributes":{"id":"p-0132","num":"0142"},"figref":["FIG. 15","FIG. 15","FIG. 16","FIG. 17"]},"With reference to , in step  the complete aperture Afor SAR image formation informed. In this step, the system collects the return radar data, the coordinates of the receiver, and the coordinates of the transmitter for each position k along the aperture of N positions.","The radar data at each position is\n\n(), 1\u2003\u2003(1)\n\nThe coordinates of the receiver at each position is\n\n((), (), ()), 1\u2003\u2003(2)\n\nThe coordinates of the transmitter at each position is\n\n((), (), ()), 1\u2003\u2003(3)\n","For monostatic radar that uses the same transmitting and receiving antenna, the coordinates of the receivers (x(k), y(k), z(k)) are identical to the coordinates of the transmitters (x(k), y(k), z(k)). Since the monostatic radar case is a special case of the bistatic radar configuration, the algorithm described here is applicable for both configurations.","The next step in  is to form a baseline image using data from Aperture Agenerated from step  using the standard backprojection algorithm [6]. In order to form an image from the area of interest, we generate an imaging grid that consists of image pixels.","Each pixel from the imaging grid is located at coordinates\n\n((), (), ()), 1\u2003\u2003(4)\n\nThe imaging grid is usually defined as a 2-D or 3-D rectangular shape. In general, however, the image grid could be arbitrary.\n","The backprojection value at jpixel is computed as",{"@attributes":{"id":"p-0139","num":"0149"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"P","mrow":{"mn":"0","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"j"}},"mo":"=","mfrac":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":"w","mrow":{"mn":"0","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"k"}},"mo":"\u2062","mrow":{"msub":{"mi":["s","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","j"],"mo":","}}}}}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":"w","mrow":{"mn":"0","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"k"}}}]}},{"mn":"1","mo":["\u2264","\u2264"],"mi":["j","M"]}],"mo":[",","\u2062",","],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}},"br":[{},{},{},{},{},{},{},{},{}],"sub":["0j ","0","0k ","0k ","0","0k","1","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","T","P","2","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","R","P","1","2"],"sup":["th ","th ","th ","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","th ","th ","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2"],"in-line-formulae":[{},{},{},{},{},{},{},{}],"i":["d","k,j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","d","k,j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","x","k","x","j","+[y","k","y","j","+[z","k","z","j","d","k,j","d","k,j","d","k,j"]},{"@attributes":{"id":"p-0140","num":"0150"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","j"],"mo":","}}},"mo":"=","mfrac":{"mrow":{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","j"],"mo":","}}},"mi":"c"}}},{"mrow":{"mo":["(",")"],"mn":"10"}}]}}}},"br":[{},{}],"sub":["0 ","0","0j"],"in-line-formulae":[{},{}],"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00013","he":"3.56mm","wi":"0.68mm","file":"US08665132-20140304-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00014","he":"3.56mm","wi":"0.68mm","file":"US08665132-20140304-P00002.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}]},"The image Iis a bipolar (contains both positive and negative values) image that includes both amplitude and phase information. The corresponding envelope image Eis computed by computing the Hilbert envelope of I. The procedure to compute the envelope image is described in Nguyen, \u201cSignal and Image Processing Algorithms for the U.S. Army Research Laboratory Ultra-wideband (UWB) Synchronous Impulse Reconstruction (SIRE) Radar,\u201d ARL Technical Report ARL-TR-4784, April 2009.\n\n=|Hilbert()|\u2003\u2003(12)\n","Referring again to , the third step comprises generating a spare aperture from the complete aperture of iv positions Agenerated from the second step.\n\nA, 1\u2266i\u2266L\u2003\u2003(13)\n\nWhere L is the number of iterations that the algorithm computes.\n","The sparse aperture Ais a subset of the complete aperture A. This sparse aperture only consists of K positions that are randomly selected from N positions in A, where K=p. N, and 0<p<1. The typical value for p=0.8. In this example the value of p=0.8 means that instead of using all of the positions from aperture Afor imaging, only 80% of the aperture positions are employed during the imaging process for this iteration. It is beneficial that the selection of K positions from N positions be completely random, since this step is only one out of L iterations that the preferred embodiment pixel characterization technique will perform, as will be explained later.","One approach to implement this sparse aperture is to generate a random vector for this iiteration:\n\nw, 1\u2266k\u2266N\u2003\u2003(13)\n\nwhere the value of wis either 0 or 1. There are K elements of whaving the value of 1, and (N\u2212K) elements of wit having the value of 0.\n","Referring again to , the fourth step comprises forming the magnitude image Eusing data from the sparse aperture A(from step ) and the backprojection algorithm (described in step ).","First, the bipolar image using the data from the sparse aperture is computed as:\n\nI=P\u2003\u2003(14)\n","From equation (5), the backprojection value at jpixel using the sparse aperture Ais computed as",{"@attributes":{"id":"p-0148","num":"0158"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["P","ij"]},"mo":"=","mfrac":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":"w","mrow":{"mn":"1","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"k"}},"mo":"\u2062","mrow":{"msub":{"mi":["s","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["k","j"],"mo":","}}}}}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":"w","mrow":{"mn":"1","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mi":"k"}}}]}},{"mn":"1","mo":["\u2264","\u2264"],"mi":["j","M"]}],"mo":[",","\u2062"],"mstyle":{"mtext":{}}}}}},"Note that equation (15) is the same as equation (5), except that the subscript 0 of Pand win (5) has been replace by i in (15). From equation (15), although the summation is performed from 1 to N, only data from K aperture positions are contributed to the final value of the image pixel since wgenerated from equation (13) only contains K non-zero elements. Also note that the value of the denominator \u03a3win equation (15) represents the number of non-zero elements. This value is used as normalization factor for the final image pixel value.","The magnitude image Eusing data from aperture Ais then computed from the bipolar image Ias described in step .\n\n=|Hilbert()|,\u2003\u2003(12)\n","Referring again to , the fifth step of a preferred embodiment comprises the repeating of the third and fourth steps for L iterations (1\u2266i\u2266L).","Referring again to , the sixth step of a preferred embodiment comprises classifying each pixel in the SAR image based on the statistical distribution of its amplitude across L iterations. There are two possible classes: 1) target class that includes the pixels that are originated from physical objects (main lobes), or 2) noise class that includes the pixels originated from some artifact sources (noise, sidelobes).","For each jpixel in the image grid, the decision statistic is the standard deviation of the amplitudes of the pixel Pacross L iterations, and this standard deviation normalized by the mean value of the amplitudes.",{"@attributes":{"id":"p-0154","num":"0164"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["d","j"]},"mo":"=","mfrac":{"msqrt":{"mrow":{"mfrac":{"mn":"1","mi":"L"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"L"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["P","ij"]},{"mover":{"mi":["P","_"]},"mi":"j"}],"mo":"-"}},"mn":"2"}}}},"msub":{"mover":{"mi":["P","_"]},"mi":"j"}}},{"mn":"1","mo":["\u2264","\u2264"],"mi":["j","M"]}],"mo":[",",",","\u2062"],"mstyle":{"mtext":{}},"mi":"where"}},{"mrow":{"mo":["(",")"],"mn":"13"}}]},{"mtd":[{"mrow":{"mrow":[{"msub":{"mover":{"mi":["P","_"]},"mi":"j"},"mo":"=","mrow":{"mfrac":{"mn":"1","mi":"L"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"L"},"mo":"\u2062","msub":{"mi":["P","ij"]}}}},{"mn":"1","mo":["\u2264","\u2264"],"mi":"j","mrow":{"mi":"M","mo":"."}}],"mo":","}},{"mrow":{"mo":["(",")"],"mn":"14"}}]}]}}},"br":{}},"Referring again to , the seventh step comprises computing the pixel characterization SAR image (both magnitude and complex) based on the decision statistics from step .","First, a binary image is generated based on the decisions statistics computed from equation (13). Each jpixel in the binary image has a value of 0 (to represent non-target pixel) if its decision statistic dis greater than a threshold T, and 1 (to represent target pixel) otherwise.\n\nEb=Pb, 1\u2266j\u2266M\u2003\u2003(16)\n\nwhere\n\n","The resulting magnitude image is computed as\n\nE=P, 1j\u2266M\u2003\u2003(16)\n","where\n\n","Since most of the pixels in the image are classified as non-targets, this would generate a very low noise floor in the resulting SAR image. The remaining pixels are classified as targets. Each of these pixels will have the maximum value across many iterations. Thus, the technique virtually wipes out the noise floor that includes the sidelobes, and maximizes the responses from the targets.","The resulting magnitude image of equation (16) is not a complex image. That means the phase information is not preserved in the image. The amplitude feature is probably the most important one in SAR imaging, especially for the detection of difficult targets in the noisy environment. However, in some cases, it is desirable to exploit the phase information from the targets.","The pixel characterization technique of this preferred embodiment also generates a complex SAR image that includes both amplitude and phase information. From equation (11), the bipolar baseline SAR imagery Iis generated. This is a bipolar SAR image that includes both amplitude and phase information. However, the baseline SAR image Iis contaminated with noise and sidelobes. In the binary image Eb from equation (15), the algorithm classifies each pixel in the image into either non-target class or target class. Using this binary image, we can remove the noise floor in the baseline SAR image I.","The resulting bipolar (complex) SAR image that includes both amplitude and phase information is computed as\n\nI=P, Pb, 1\u2266j\u2266M\u2003\u2003(18)\n\nwhere Pbis the binary pixel as defined in equation (15).\n","The results of the simulation data of the basic concept of SAR imaging show the performance of pixel characterization technique of this preferred embodiment. A simulation data set was generated using the following scenario. The radar travels along a linear path, transmits impulse signals to the side of the vehicle (perpendicular to the path of the vehicle) and captures the return data. Along the path, the radar also records its coordinates at every transmit\/receive cycle. The coordinate measurement also introduces errors in the measurement data. There are four point targets in the scene. The data received by the radar is contaminated with additive white noise that is due to system external RFI sources.",{"@attributes":{"id":"p-0164","num":"0178"},"figref":"FIG. 18"},"There are four simulated point-targets in the SAR image. The three high amplitude targets (1, 2and 3) are obvious in the image. They are located at the pixel coordinates (,), (,), and (,), respectively. There is a fourth point target that exists in the SAR image at the coordinate (,). This coordinate is at the midpoint between 2and 3targets. This fourth target is not visible from the image since its RCS is so low that its response is embedded in the noise floor.","The decision statistic described in equation (13) to classify a pixel is the standard deviation of the pixel amplitudes across all iterations, and normalized by its mean amplitude. Due to the scale property of the standard deviation, equation (13) can also be expressed as the standard deviation of the pixel, amplitudes that are normalized by its mean across all iterations. Thus, it was desirable to examiner the statistical differences of the normalized pixel amplitudes across different iterations between pixels that belong to target class and noise class.  compares the normalized pixel amplitudes of a pixel that belongs to second target (from ) (shown as a blue line in ) and a pixel that belongs to a sidelobe (), shown as a red line in . The distribution, of the normalized amplitudes of the target pixel is much more stable than that of the sidelobe pixel.  shows the same distributions for the second target's (labeled as ) pixel, as shown by a blue line, and a noise pixel (), as shown by a red line. Again, the distribution of the normalized amplitudes of the target pixel is much more stable than that of the noise pixel.  shows a much more challenging case, which compares the normalized pixel amplitudes of a pixel that belongs to target  of  (a very weak target that is embedded in the noise\/sidelobe floor) and a pixel that belongs to a sidelobe () of . Although the normalized amplitudes of 4target are slightly fluctuated, as shown by the blue line in , they are much more stable than the normalized amplitudes of the sidelobe pixel, as shown by the red line in . Similar result is shown in  that compares the normalized amplitudes of 4target (of ) versus a noise pixel () (of ).","The envelope image of equation (16) is shown in . This image shows all four targets, including the 4th target that represents one very challenging case for a SAR imaging system. The noise floor generated by the additive white noise and the sidelobes is completely wiped out from the resulting image.","The IF-PC imaging technique has been shown to work so well on the simulation data. Usually, the application of any technique on real data is much more challenging because of many unknown factors in real systems. In this section, we present results using radar data from the Army Research Lab SAR radar as described in Lam Nguyen, \u201cSignal and Image Processing Algorithms for the U.S. Army Research Laboratory Ultra-wideband (UWB) Synchronous Impulse Reconstruction (SIRE) Radar,\u201d ARL Technical Report ARL-TR-4784, April 2009.",{"@attributes":{"id":"p-0169","num":"0183"},"figref":["FIG. 14A","FIG. 14A","FIG. 14B","FIG. 14B"]},"Applying the pixel characterization imaging formation technique of this preferred embodiment to the same data generated the SAR image of . From , the SAR image is virtually noise-free. All the targets of interest are still preserved in the SAR image that is generated by this preferred embodiment pixel characterization technique. The preferred embodiment provides both amplitude and phase information. A key concept is the classification of each pixel in the image into either a target class (physical objects) or non-target class (noise, sidelobes) based on its statistics from many realizable sparse aperture images. If an image pixel is classified to be associated with a physical object, its value is computed from its statistics. Otherwise, the pixel is assumed to come from a non-physical object (noise source) and its value is simply zero. In general, in the case of noise, fluctuations appear; whereas a physical object exhibits more stability. The value is maximize for stable (physical object) pixels. The present invention enables the detection of very small objects that are embedded in the image noise floor; especially if the targets are located in the proximity of larger objects. The invention may be utilized in conjunction with existing systems.","Examples of potential applications include implementation of practical systems for detecting targets in the most challenging scenarios. Some examples includes 1) the SAR imaging of the ship or building interiors, where the targets of interest have much smaller responses than the structure of the ships or buildings, 2) The detection of buried mines along and on the sides of the road, where the responses of the buried mines are significantly smaller than the man-made, bushes, and trees along the road, 3) the detection of difficult targets (abnormal features, tumors) in medical imaging application.","Iterative Fourier Side Lobe Reduction for Stepped Frequency Synthetic Aperture Radar","Recursive sidelobe minimization (RSM) has been applied extensively to data sets in which no constraints have been placed on the amount of transmitted bandwidth. That is, no frequency notching was required prior to transmission of the waveform. This is an extension of the earlier RSM technique designed to reduce the artifacts introduced by frequency notching. Results obtained applying the technique to both simulated and measured data are described in the accompanying Figures.","A block diagram of a preferred embodiment and processing methodology is implemented in a synthetic aperture radar (SAR) system is shown in , wherein a dashed box indicates the general location of the improved sidelobe reduction pre-processing algorithm, the sidelobe reduction post-processing algorithm, and the iterative processing procedure indicated by the I-iteration loop in the diagram. Note that the SAR image formation algorithm, as described in, inter alia, U.S. Pat. No. 7,796,829, indicated by a solid rectangle 23 within the larger dashed rectangle 10, remains an integral part of the enhanced formulation; hence, the invention could be incorporated into any stepped-frequency SAR image formation process, without departing from the scope and spirit of the invention.","The preferred embodiment methodology substantially reduces the severity of sidelobe artifacts due to the elimination of n of the N frequencies comprising the stepped frequency waveform. It is derived in part from a novel application of concepts from the theories, referenced in H. C. Stankwitz, R. J. Dallaire, and J. R. Fienup, \u201cNonlinear apodization for side lobe control in SAR imagery,\u201d ., Vol. 31, No. 1, pp. 267-279, January 1995, here by incorporated by reference, and Emmanuel Candes, Justin Romberg, and Terence Tao, Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information. (IEEE Trans. on Information Theory, 52(2) pp. 489-509, February 2006), hereby incorporated by reference. Although the present invention bear some similarity to U.S. Pat. No. 7,796,829 to Nguyen (hereinafter '829 Nguyen patent), the preferred embodiment methodology addresses a problem that is fundamentally different than that addressed in the '829 Nguyen patent. The problem formulation of '829 Nguyen patent concentrated on artifacts observed when the entire transmitted bandwidth is available. The present invention concentrates on, inter alia, artifacts induced by limiting the allowed transmission frequencies to a subset of the available band (i.e. \u201cnotching out\u201d specific frequency steps).",{"@attributes":{"id":"p-0175","num":"0189"},"figref":["FIG. 21","FIG. 21"],"b":["10","23"]},"The processing steps denoted as \u201cSidelobe-Reduction\u201d processing in  are described in more detail by the flowchart in .","Referring to , for each value of the loop counter, i, from 0 to L\u22121, the algorithm first selects a random subset of frequencies from those available after notching (k out of N\u2212n). It then calculates HRR profiles for each of the SAR aperture positions, using the k randomly selected frequency samples, and creates a SAR image, denoted \u201cfocused_image.\u201d The complex magnitude of each pixel in focused_image is next compared with the magnitude of the corresponding pixel in minImage. If the pixel value in focused_image is smaller than that in minImage or if the value of i equals 0, then the current pixel value in minImage is replaced by the pixel value in focused_image. The effectiveness of this approach rests on the basic tenet that those contributions to image pixel values due to true objects within the image should remain consistent, regardless of the frequency steps excised. Since certain sidelobe patterns may cause small targets to be overwhelmed by nearby larger targets, the minimum value obtained from several different sidelobe configurations (i.e. several different SFRSM frequency sets) should represent a better estimate of the true underlying image pixel value. Once the extraneous sidelobe energy has been removed, what remains should represent the true underlying image pixel value.",{"@attributes":{"id":"p-0178","num":"0192"},"figref":["FIG. 22","FIG. 21"],"b":["11","12","13"]},"Referring now to , one can see that the preprocessing box depicted in  comprises: (i) random excision of k randomly selected frequency steps from the N\u2212n steps available after transmission restriction, (ii) weighting of the remaining samples (iii) calculation of the high resolution time-domain signature via an FFT. Similarly, the postprocessing box, comprises a pixel-by-pixel comparison of the magnitude of the current image with the minimum value calculated for that pixel up to the current iteration. The smallest value in this comparison becomes the new minimum value stored at those pixel coordinates. Finally, as shown in these figures, the process terminates after L iterations.","Experimental Results","From an analysis of , one can appreciate that the preferred technique illustrated, inter alia, in  (SFRSM) trades processing time for a reduction in sidelobe levels. AS a result, it is rather computationally intensive and time-consuming. In order to better understand the amount of improvement obtained through implementing the system illustrated in , considered are both simulated and measured data, comparing images generated both with and without SFRSM.","Simulated Data","In order to evaluate the benefits realized through the incorporation of the preferred embodiment system of , SAR imagery was first formed using a simulated stepped-frequency system. This system comprised a forward looking antenna array with 16 equally spaced receive antennas, the left-most and right-most of these also serving as transmit antennas. Since it was also intended to replicate the collection geometry of the Army Research Lab's (ARL's) vehicle-mounted Synchronous Impulse Reconstruction (SIRE) radar , the system's antenna array stood 2 m above the ground. The left and right transmitters fired sequentially, each transmitter launching its burst of frequencies while the vehicle remained stationary. In addition, each transmitted burst included all frequencies separated by 5 MHz steps and spanning the band between 5 MHz and 3 GHz inclusive.","At the beginning of the simulation, the center of the antenna array was located at coordinate (0,0,0), and it moved 0.125 m following the transmission of each frequency burst until data had been collected from a 25 m span of along-track vehicle positions. This data collection process yielded a two-dimensional synthetic aperture of data collection locations separated by 0.125 m in both the along-track and cross-track dimensions. Targets were simulated as point responses with elevations all equal to zero, and the positions of these targets within the x-y plane are shown in  for the two configurations considered. All target responses were assumed to be identical and uniform as a function of frequency.","The along-track (or down-range) vehicle positions together with the individual receiver positions (within the array) constituted the two-dimensional synthetic array used to produce focused SAR imagery. After all of the target responses had been simulated for the various radar locations, we proceeded to excise (\u201cnotch\u201d) frequencies within the following bands: 100-200 MHz, 400-450 MHz, 850-1000 MHz, 1150-1250 MHz, and 1900-2050 MHz. During each iteration of the SFRSM algorithm, as indicated by the loop index i in , an additional 20% of the remaining frequencies were randomly eliminated\u2014setting their corresponding entries to zero\u2014before converting to the time domain. When iteratively applied, this randomization provided the key to reducing sidelobe artifacts in the final output image. The first step in producing a focused image involved the creation of the HRR range profiles required by the time-domain backprojection algorithm. This was accomplished by applying a weighting window to the newly formed frequency-domain sequence and then calculating its IFFT. The rest of the processing could then be, performed using the resulting time domain sequence.","Referring now to , preferred embodiment system implements an iterative procedure that achieves results by excising a different set of randomly selected frequencies at each iteration. In what follows, it is assumed that N\u2212n of the available frequencies must be excised due to restrictions from a regulating authority, and (as a result) cannot be transmitted. The k frequencies to be excised by the algorithm are selected from this reduced set. It is noted that during the data collection, restricted frequencies (set by the FCC) are eliminated prior to transmission; i.e., only the \u201callowed\u201d frequencies are received and transmitted. Thus the frequency samples inputted into Box  comprise a received complex signal at each low resolution range gate. In Box , the system initializes the output array (minImage) and the looping variable (i). Note that all pixel values in minImage in Box  are initially set to extremely large values (effectively, +\u221e). In diamond , the number of iterations are set at a number L, and if the iteration count i is not greater than L, the steps in Boxes - are repeated. A larger L results in better output imagery; at the expense of increased computational time. As an example, the value of L may be selected as 20. In Box , k of the available n frequencies are randomly selected and the complex samples collected at these frequencies (at each of the M aperture positions) are set to zero (effectively removed). In Box , the high resolution signature (via the FFT) is formed and the SAR image is created using a suitable focusing algorithm. This yields an (I\u00d7J) complex 2D image. In classical SAR imaging (e.g. airborne collection assets) the aperture is 1D, but it can also be 2D (e.g. an antenna array, mounted on an SUV, that moves forward and creates a radar picture of the road in front of it). In Box , the complex magnitude of each pixel is determined in the newly formed SAR image. These values are compared with the corresponding pixel value in the output array. A value is replaced in the output array if the newly calculated value is smaller than the current output value.","The preferred embodiment processing, as outlined in  continued until 100 iterations had been completed, and the resulting image is included in ).  illustrate simulation results for a target configuration comprising 17 simulated targets.  shows the output image produced without implementing the SFRSM procedure and simply tolerating any artifacts that may be introduced by frequency notching. In both cases, the target emplacement pattern becomes clear from the imagery after consulting the plot of . It is noted note that many non-target regions that exhibited relatively strong sidelobe artifacts (on the order of 20-30 dB below the peak) before the application of SFRSM no longer exhibit these artifacts after SFRSM has been applied. This implies these sidelobe levels have been reduced by at least 10-20 dB.","Measured Data","Artificially notched data was created using existing measurements collected by ARL's SIRE system. It is noted that, because the SIRE system is impulse-based, all of the HRR profiles first had to be converted to the frequency domain. Only then could one apply the necessary notches and perform the necessary SFRSM processing. Hence, each random excision of frequencies required the application of a separately tuned bandpass filter. For this data set attention was restricted to a hypothesized system bandwidth of 1 GHz, comprising all frequencies ranging from 500-1500 MHz. The following frequency bands were notched: 328.6-335.4 MHz, 400-420 MHz, 608-614 MHz, and 960-1215 MHz, and the SFRSM excised 20% of the remaining frequencies. A total of 50 iterations produced the SAR image displayed in . Once again the baseline image was included, created without the assistance of SFRSM, to serve as a reference point. Comparison of  indicates (albeit qualitatively) the benefits of including SFRSM if frequency notching is required within the current data collection environment. Notice the reduction in ambient background level achieved via SFRSM.","Simulations were performed to determine the utility and practicality of this implementation, and the results are shown in  for two different target configurations. The simulated radar system configuration was based on the Army Research Laboratory's Synchronous Impulse Reconstruction (SIRE) radar in that it included 2 transmitters and 16 receivers, all defined to be situated 2 m above the ground. The receivers were equally spaced across a horizontal aperture spanning 2 m, and the transmitters Were co-located with the two outside antennas. The radar collected all frequency steps simultaneously at regular intervals, as the vehicle moved forward. As evident from the figure, the proposed method effectively mitigated many imaging artifacts that are readily apparent in the original imagery.",{"@attributes":{"id":"p-0188","num":"0202"},"figref":["FIG. 25","FIG. 25"],"b":"25"},"Illustrated in  are simulation results for a second target configuration (a) with the new technique and b) without the new technique. There are 17 simulated targets, and the improvement realized via application of the new technique is striking. A procedure using measured data collected with the SIRE system has also been evaluates and the results are shown in  A and B. Again, the image quality is noticeably improved after application of the proposed technique.",{"@attributes":{"id":"p-0190","num":"0204"},"figref":"FIGS. 28A and 28B","b":["28","28"]},"A preferred embodiment system was developed and implemented; the frequency domain analog of the previously documented RSM algorithm. In particular, the system\/algorithm effectively leverages the principles of time-domain RSM to ameliorate the effects of sidelobes introduced in SAR imagery by frequency domain notching of down-range radar signatures. The system of the preferred embodiment improves SAR image quality via an iterative procedure that adapts and extends concepts from the theories of apodization and, compressive sensing. This procedure as described incorporates in some detail the incorporation of into an overall SAR image formation process, and the procedure was evaluated using both simulated and measured radar data sets.","Imagery obtained by processing simulated and measured radar data illustrated clearly\u2014albeit also qualitatively\u2014the potential improvement realizable via the SFRSM processing paradigm. Also observed were reductions in certain sidelobe levels of at least 10-20 dB, representing a significant improvement. These lower sidelobe levels would be required to detect targets with small radar cross section (RCS) in the vicinity of large-RCS targets. In a radio-frequency-transmission environment that requires a radar operator to avoid transmitting within specific frequency bands, such a sidelobe minimization strategy becomes crucial. That is, the SFRSM offers an important capability to the modern day SAR system operator and SAR image analyst. Certain small-RCS targets may now become discernible with the help of the system of the preferred embodiment.","As used herein, the term \u201caperture\u201d means the information or data components used to form an image; which may be for example, an array of data points developed from a scanned area, target or scene which can be used to form an image.","The term \u201cprocessor\u201d as used herein includes multiprocessors, computers, supercomputers, data processor, laptops, signal processors, personal computers, and\/or any component which processes data. The term \u201cimage generator\u201d as used herein includes a processor which generate images and\/or any element or component, including components within a processor, which generate images. The term \u201ccomparator\u201d as used herein means a component within a processor operative to complete a comparison function or a separate processor or component which compares sets of data in order to determine, lesser or equal values.","The present invention may be utilized in radar imaging, magnetic resonance imaging, CAT scans, sonar imaging, acoustical imaging and the like.","The term \u201cbitmap\u201d is derived from a mapped array of bits, and bitmapped and pixmap refer to the similar concept of a spatially mapped array of pixels. The term \u201cbitmapped\u201d as used herein encompasses pixmap. The term \u201cbitmapped\u201d means a set of bits that represents a graphic image, with each bit or group of bits corresponding to a pixel. As used in the following claims, the term \u201cbitmapped\u201d encompasses all images formed using pixels. For example, all images acquired by digital cameras and camcorders, scanners, and screen capture programs are bitmapped images.","As used in the following claims, the term \u201cprocessor\u201d means one or more processing units, central processing units, processor cores, microprocessors, digital signal processors, multiprocessors, computers, and\/or controllers, which may be connected together or to other circuitry in a manner known to those of ordinary skill in the art. As used in the foregoing claims, the terminology \u201carea\u201d includes object(s), person(s), setting, place, or scene. For example, \u201cscanning an area\u201d includes scanning an object or objects, person or persons, place or scene. The terminology positional data includes but is not limited to spatial information relating to location.","As used herein and in the following claims, the terminology \u201cdata point\u201d \u201cdata point\u201d represents the received signal radar data from each position obtained during an instant or interval in time combined with positional information. The positioning information may, for example, correspond to the transmitting and\/or receiving position or location. The data points may be collected by either an array of elements or a single moving element which receives data at points in time, or the combination of both; e.g., a physical array of elements with the elements moving over increments of time. The data collection may be sporadic or at specific intervals of time. As exemplified in , data points are obtained using an array of receiving elements which receive data incrementally. The data points are arranged to form an aperture.","As used herein, the term \u201caperture\u201d means the information or data components used to form an image; which may be for example, an array of data points developed from a scanned area, target or scene which can be used to form an image. In the apertures depicted in , each column represents an interval during which the 1-k elements receive data; each data point representing the image data from the signal received combined with the coordinates of the receiving element.","As used herein and in the following claims, the terminology \u201caperture\u201d refers to the collection of K data records along the path (or aperture) of travel of the emitting radar or signal source. In general, the aperture could be a line, a curve, a circle, or any arbitrary shape. The receiving element k from the aperture is located at the coordinate (x(k), y(k), z(k)). For bistatic radar (the transmitting antenna is separate from the receiving antenna) the transmitting element k from the aperture is located at the coordinate (x(k), y(k), z(k)). For monostatic radar (the transmitting antenna is the same as or co-located with the receiving antenna) the transmitting coordinates (x(k), y(k), z(k)) would be the same as the receiving coordinates (x(k), y(k), z(k)). Since the monostatic radar case is a special case of the bistatic radar configuration, the algorithm described here is applicable for both configurations. The returned radar signal at this receiving element k is s(t). In order to form an image from the area of interest, we form an imaging grid that consists of N image pixels. Each pixel Pfrom the imaging grid is located at coordinate (x(i), y(i), z(i)). The imaging grid is usually defined as a 2-D rectangular shape. In general, however, the image grid could be arbitrary. For example, a 3-D imaging grid would be formed for ground penetration radar to detect targets and structures buried underground. Another example is 3-D image of inside human body.","After the data points are established in an aperture (or array), as, for example, diagrammatically shown in , a substantial portion of data points are removed from the original aperture (array of data points) to form a \u201csubarray.\u201d Conversely, the \u201csubarray\u201d may be formed by the selection of data points within the original aperture.","It should be emphasized that the above-described embodiments are merely possible examples of implementations. Many variations and modifications may be made to the above-described embodiments. All such modifications and variations are intended to be included herein within the scope of the disclosure and protected by the following claims."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The patent or application file contains at least one drawing executed in color. Copies of this patent or patent application publication with color drawing(s) will be provided by the Office upon request and payment of the necessary fee.","A more complete appreciation of the invention will be readily obtained by reference to the following Description of the Preferred Embodiments and the accompanying drawings in which like numerals in different figures represent the same structures or elements. The representations in each of the figures are diagrammatic and no attempt is made to indicate actual scales or precise ratios. Proportional relationships are shown as approximates.",{"@attributes":{"id":"p-0052","num":"0062"},"figref":"FIG. 1A"},{"@attributes":{"id":"p-0053","num":"0063"},"figref":"FIG. 1B"},{"@attributes":{"id":"p-0054","num":"0064"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0055","num":"0065"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0056","num":"0066"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0057","num":"0067"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0058","num":"0068"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0059","num":"0069"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0060","num":"0070"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0061","num":"0071"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0062","num":"0072"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0063","num":"0073"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0064","num":"0074"},"figref":"FIG. 11A"},{"@attributes":{"id":"p-0065","num":"0075"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0066","num":"0076"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0067","num":"0077"},"figref":"FIG. 14A"},{"@attributes":{"id":"p-0068","num":"0078"},"figref":["FIG. 14B","FIG. 14A","FIG. 14B"]},{"@attributes":{"id":"p-0069","num":"0079"},"figref":["FIG. 14C","FIG. 14A"]},{"@attributes":{"id":"p-0070","num":"0080"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0071","num":"0081"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0072","num":"0082"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0073","num":"0083"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0074","num":"0084"},"figref":["FIG. 19A","FIG. 18","FIG. 19A","FIG. 19A"],"b":"5"},{"@attributes":{"id":"p-0075","num":"0085"},"figref":["FIG. 19B","FIG. 19A"],"b":["2","6"]},{"@attributes":{"id":"p-0076","num":"0086"},"figref":["FIG. 20A","FIG. 20A","FIG. 20A"]},{"@attributes":{"id":"p-0077","num":"0087"},"figref":["FIG. 20B","FIG. 18","FIG. 18"],"b":"6"},{"@attributes":{"id":"p-0078","num":"0088"},"figref":"FIG. 20C"},{"@attributes":{"id":"p-0079","num":"0089"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0080","num":"0090"},"figref":["FIG. 22","FIG. 21"],"b":["11","12","13"]},{"@attributes":{"id":"p-0081","num":"0091"},"figref":["FIG. 23","FIG. 21","FIG. 1"],"b":["21","22"]},{"@attributes":{"id":"p-0082","num":"0092"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0083","num":"0093"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0084","num":"0094"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0085","num":"0095"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0086","num":"0096"},"figref":"FIG. 28A"},{"@attributes":{"id":"p-0087","num":"0097"},"figref":"FIG. 28B"},{"@attributes":{"id":"p-0088","num":"0098"},"figref":"FIG. 29","b":["0","0"]}]},"DETDESC":[{},{}]}
