---
title: Processor to message-based network interface using speculative techniques
abstract: Methods and systems are provided for a message network interface unit (a message interface unit), coupled to a processor, that is used for allowing the processor to send messages to a hardware unit. Methods and systems are also provided for a message interface unit, coupled to a processor, that is used for allowing a processor to receive messages from a hardware unit. The message network interface unit described herein may allow for the implementation data-intensive, real time applications, which require a substantially low message response latency and a substantially high message throughput.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09176912&OS=09176912&RS=09176912
owner: ALTERA CORPORATION
number: 09176912
owner_city: San Jose
owner_country: US
publication_date: 20120209
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATION","FIELD OF THE INVENTION","BACKGROUND OF THE DISCLOSURE","SUMMARY OF THE DISCLOSURE","DETAILED DESCRIPTION OF THE INVENTION","APPENDIX A","Transmit API","APPENDIX B","Receive API"],"p":["This application claims the benefit and priority to commonly-assigned U.S. Provisional Patent Application No. 61\/531,950, filed Sep. 7, 2011, which is hereby incorporated by reference herein in its entirety.","This invention relates to integrated circuit devices, and particularly to a such devices having a message network interface unit for high speed message passing.","As data-intensive electronic devices and applications proliferate, data rates continue to increase. To facilitate the use of devices such as programmable logic devices in certain data-intensive, real time applications, hierarchical specialized processing blocks, including lower level specialized processing blocks and a message passing communication structure are increasingly being used. A specialized processing block, such as an intellectual property (IP) block, is a block circuitry, that may be separate from the general-purpose programmable logic of a device on which it is implemented, that is at least partially hardwired to perform a specific function. A specialized processing block (e.g., an IP block) that is at a lower hierarchical level, in terms of the device communications structure, than other specialized processing blocks or circuitry may be referred to as a lower level specialized processing block (e.g., a lower level IP block). Lower level specialized processing blocks are best coordinated using software operating on a processor, which communicates to these specialized processing blocks using a message network. For example, a processor may read and write messages using a memory mapped protocol and messages may be transmitted to or from the lower level specialized processing blocks using a streaming packet based protocol. A very efficient interface may be used between the processor and the message network for use in data-intensive, real time applications.","Message passing networks have come into common use. Many existing message passing networks allow processors or processing blocks (e.g., IP cores) to send and receive messages in order to communicate with each other. For example, network on a chip (NoC) designs have been created and used for communication between IP cores in a system on a chip (SoC). There are also multiple existing interface designs, for use between a processor and the message passing network, that are used by the processor to communicate with specialized processing blocks. As an example of such an interface design, PicaRISC, DPX makes use of a FIFO based message passing mechanism. As another example of an interface design, a processor embedded in a programmable device can send messages by writing the messages directly into the network during a bus write cycle. However, these interface designs have drawbacks. In particular, PicaRISC, DPX tends to be inflexible because of the FIFO requirement, and a design involving writing messages directly into the network tends to be inflexible because the messages need to be contiguously grouped.","Due to the inflexibility of existing message passing networks, there is a need for a fast and efficient interface between a processor and the message passing network.","To address the above and other shortcomings within the art, the present disclosure presents methods and systems for providing a fast and efficient interface between a processor and a message passing network. This interface reduces the latency of sending messages from a processor (i.e., increases message throughput) and the latency of acting on messages received from hardware units (i.e., reduces message response latency).","The message interface reduces these latencies by speculatively creating messages in a scratchpad memory within transmit registers, speculatively queuing the created messages in one or more queues, and later making a decision as to whether or not to send any of the messages and\/or queues of messages.","In particular, the interface reduces the number of processor clock cycles required to send a message because messages can be created during periods when the processor would otherwise be idle, and well ahead of when they are to be sent. The transmit registers and scratchpad memory may be used as a template to allow the processor to create boiler-plate messages and to customize them. An application programming interface (API) is provided to allow close to optimal consumption of processor clock cycles for message creation (i.e. creation of a message at a rate close to 1 message word per processor cycle). One or more queues are used to speculatively queue the created messages.","In addition, the interface described herein reduces the latency of receiving messages and acting on messages received by having one or more individually addressed queues to queue incoming messages. The queues may be associated with a priority level. The priority level may be used to determine in which order to process the messages among the messages in different queues. For example, a message from a queue with the highest priority level may be processed ahead of a message from a queue with a lower priority level. The message network interface described herein may allow for the implementation data-intensive, real time applications, which requires a substantially low message response latency and a substantially high message throughput.","Methods and systems are provided for a message network interface unit (i.e., a message interface unit), coupled to a processor, that is used for allowing the processor to send messages to a hardware unit. In an embodiment, the message interface unit includes transmit registers. The transmit registers, which include a scratchpad memory, store arguments of at least one of the messages, which are speculatively created by the processor. One or more queues are coupled to the transmit registers. The one or more queues may be used to queue the messages. An action may be taken on the one or more queues in response to receiving, at the message interface unit, a message indicating the action to be taken. The action that may be taken on one or more queues includes discarding all of the content in one of the queues in response to receiving a message that indicates that an exception occurred. The action that may be taken on one or more queues includes sending each of the messages stored in one of the queues. In some embodiments, the message interface unit and the processor are located on the same device. Examples of devices include a programmable logic device, an integrated circuit device, or other device. In some embodiments, the message interface unit is used by a video scalar.","Methods and systems are also provided for a message interface unit, coupled to a processor, and used for allowing the processor to receive messages from a hardware unit. In an embodiment, the message interface unit includes one or more queues that may be used to queue the messages. Each of the one or more queues may be assigned a unique address that indicates a priority level for that queue. The unique address is used as a destination address in messages sent by the hardware unit to either the processor or the message interface unit. Receive registers are coupled to the one or more queues. The receive registers are used to store arguments of one or more of the messages. In some embodiments, the receive registers are used to store the arguments of a message in a queue that currently has the highest priority level and this message is processed by the processor prior to messages in other queues, for example, in queues with a lower priority level. In some embodiments, the message interface unit and the processor are located on the same device, such as, for example, a programmable logic device.","To provide an overall understanding of the invention, certain illustrative embodiments will now be described. However, it will be understood by one of ordinary skill in the art that the systems and methods described herein may be adapted and modified as is appropriate for the application being addresses and that the systems and methods described herein may be employed in other suitable applications, and that such other additions and modifications will not depart from the scope hereof.",{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 1","sub":["OO ","OO ","OO ","OO "]},{"@attributes":{"id":"p-0021","num":"0020"},"figref":["FIG. 1","FIG. 1","FIG. 1"],"b":["102","104","106","110","110","112","114","116","118","120","110","112","110","114","116","118"]},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 2A and 2B","b":["200","220","200","202","204","206","208","210","212","214","216","218","220","222","224","224","200","224","200","224"]},"Video upscaling may be performed using four of the hardware pipelines  of system . Each of the hardware pipelines may include four hardware units (in order, a clipper, a line buffer, a scalar, and another clipper), and each of the pipelines may operate on one quarter of the incoming video. Software operating on processor  may control each of hardware pipelines  to process the incoming video by sending messages using message interface unit . In particular, processor  may instruct message interface unit  to send messages to one of more of the hardware units in hardware pipelines . The software operating on processor  may be able to dynamically adapt any of the hardware pipelines to any particular type of incoming video stream by changing the type of messages sent via message interface unit  to the hardware units in hardware pipelines . This way of dynamically adapting hardware pipelines  may allow the pipelines to support multiple configurations and types of input and output video formats without complex hardware control. For example, hardware pipelines  may be able to support the output of one 4K video stream, four 1080p60 video streams, or four 720p60 video streams.","In operation, 1080p60 video may be input, one line of a frame at a time, to CVI unit , which may process and send this information to VIB unit . VIB unit  may packetize and output this information to packet switch , which may output this information to message interface unit  and to kernel creator . Message interface unit  may notify processor  of the incoming line of the frame of video by sending processor  one or more messages. Processor  may also be notified of the incoming line of the frame of video.","Processor  may receive messages corresponding to the incoming lines and frames of video and may process each of these messages. In particular, for 1080p60 video, each of the 60 incoming frames per second may, in effect, cause processor  to receive one message indicating the width and height of the frame. Each input active line of video of the incoming  active lines may, in effect, cause processor  to receive two messages: one message indicating the start of the line and, another message indicating the end of line. Each input active line of video may also, in effect, cause processor  to receive two additional messages, from kernel creator  via packet switch , that contain the required coefficients calculated by the kernel creator for upscaling the input active line of video in order to generate two lines of output video. Each of the preceding messages may be received by processor  via message interface unit  communicating to the processor.","Using message interface unit , processor  may also send messages based on the frames and lines of incoming video to be upscaled. Each input frame may cause processor  to send six messages: two messages to kernel creator , and four messages to each of the line buffers in hardware pipelines . In addition, each input active line of video may cause processor  to send 52 messages, for example, to various components in each of the four hardware pipelines  via packet switch . Message interface unit  may send each of these messages on behalf of processor .","VIB unit  may receive messages sent by message interface unit  and\/or kernel creator  via packet switch . VIB unit  may duplicate video data in these messages and forward the messages to packet switch , which may forward the messages to various components of hardware pipelines . Each of hardware pipelines , which operates on the active lines and frames of incoming video, contain a clipper that may clip a portion of each active line of video it receives, a line buffer to buffer multiple incoming clipped active lines of video, a scalar that scales the buffered and clipped active lines of video from the buffer, and a clipper to clip the scaled, buffered, and clipped video. As discussed above, each of these hardware units in hardware pipelines  may be controlled using control messages that are sent\/forwarded by processor  and\/or message interface unit . After being processed by hardware pipelines , the resulting video may be sent to packet writers  to be written to DDR3 memory block . The use of DDR3 memory block  is exemplary and not intended to limit the scope of the present invention. Other types of memory, for example, any type of random access memory, read-only memory, or flash memory may be used instead or in combination with DDR3 memory block . The resulting video can be read out of DDR3 memory block  at some later time by frame readers , which may each forward the video that it reads to one of the CVO units  to be output from scalar . Frame readers  may each be separately controlled using control messages that are sent\/forwarded by processor  and\/or by message interface unit .","In order to upscale 1080p60 video to be 4K video, a total of (60\u00d71)+(1080\u00d760\u00d74)=259260 messages may be received by the processor every second and a total of (60\u00d76)+(1080\u00d760\u00d752)=3369960 messages may be sent every second. Therefore, in this exemplary embodiment, a total of 259260+3369960=3.6 million messages may either be received or sent every second. Therefore, in this example, upscaling may require a throughput of 3.6 million messages per second.","Message response latency may be defined as the elapsed time between a processor receiving a message until the processor has completed taking appropriate action, which could, for example, include sending out the appropriate message(s) in response. The upscaling 1080p60 video to 4K video may require low message response latency. For real time applications, such as for example upscaling 1080p60 video to 4K video, message response latency may be a substantial factor in the overall latency in the completion of tasks. Thus, upscaling video may not only require a combined throughput of 3.6 million messages to be sent or received every second, but it may also require a substantially low message response latency.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 3","FIG. 3"],"b":["310","312","314","350","300","320","312","300"]},"Processor  may create messages and store these messages in shared memory . For example,  shows seven messages that were created and stored by processor  in shared memory . Processor  may create a DMA transfer description, which refers to the messages in shared memory  that processor  wants to transmit. Processor  may then instruct the DMA controller  to send these messages by transferring the messages to one or more hardware units using memory mapped to message format bridge . Memory mapped to message format bridge  may packetize the messages and transfer the messages to the appropriate hardware unit(s). Although the message interface unit  solution shown in  is a fully functional message interface unit solution, it may not be able to meet the substantially high throughput requirements of certain data-intensive, real time applications. In particular, in the solution shown in , processor  may need to manage access to shared memory  to avoid overwriting messages that are being sent\/transferred, leading to inefficient use of the processor. In addition, this solution may require processor  to create a DMA transfer description for DMA controller  for each message transfer, leading to inefficient use of the processor. Moreover, sending the same message multiple times or with minimal changes to the message using the solution shown in  may be inefficient for processor  because the solution requires processor synchronization with DMA controller . These inefficiencies for the processor may reduce message throughput when using the solution shown in .","The message interface unit  solution in  may also have too high of a message response latency for the proper operation of some data-intensive, real time applications when messages are received by the processor. In particular, in this solution, processor  is required to instruct DMA controller  to copy any incoming message to shared memory , leading to the inefficient use of clock cycles for processor . In addition, in this solution, DMA controller  interrupts processor  when the controller has finished copying any incoming message to shared memory . Processor  is then required to read the message and take appropriate action. The extra steps required for processor to take appropriate action for an incoming message lead to additional inefficiencies due to wasted clock cycles for processor . Thus, receiving a message using message interface unit  of the solution shown in  leads to processor inefficiencies, which may increase message response latency beyond the requirements for certain data-intensive, real time applications.",{"@attributes":{"id":"p-0033","num":"0032"},"figref":["FIG. 4","FIG. 4"],"b":["450","400","450","402","400","400","400","450","450"]},"Message interface unit  may allow processor  to send and to receive messages. Message interface unit  may allow processor  to send and to receive messages at a sufficiently high throughput and sufficiently low message response latency to support data-intensive, real time applications, such as, for example, upscaling 1080p60 video to 4K video, described above. In some embodiments message interface unit  may be included on the same device as processor . In some embodiments, message interface unit  is a separate device (i.e., peripheral) from processor . In some embodiments, message interface unit  is a memory-mapped peripheral that can be attached to any processor. Message interface unit  may be similar to message interface unit  of , and may be used with video scalar  of .","Message interface unit  may include transmit registers , which include several reserved registers (not shown), space_available register , send_queue register , free_queue register , header register , and argument registers . Argument registers  may also be referred to as a scratchpad memory. Processor  may read from or write to transmit registers  by communicating with message interface unit . In some embodiments, transmit registers  may be coupled to one or more queues , which may each be used to queue and send messages (e.g., messages created by the processor). In some embodiments, transmit registers  may be used to send messages without first queuing the messages. In one embodiment, the addresses of transmit registers  and the description with regards to what occurs when processor  either writes to or reads from each of these registers is shown in Table 1.",{"@attributes":{"id":"p-0036","num":"0035"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 1"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Address","Register","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["0","reserved",{}]},{"entry":["1","reserved",{}]},{"entry":["2","reserved",{}]},{"entry":["3","space_available","Read - returns available"]},{"entry":[{},{},"space in queue"]},{"entry":["4","select_queue","Write - sets queue to report"]},{"entry":[{},{},"space available"]},{"entry":["5","send_queue","Write - sends the messages in"]},{"entry":[{},{},"the specified queue"]},{"entry":["6","free_queue","Write - discards the messages"]},{"entry":[{},{},"in the specified queue"]},{"entry":["7","header","Write - sends the message"]},{"entry":[{},{},"Bits 0 to 7 - number of"]},{"entry":[{},{},"arguments used"]},{"entry":[{},{},"Bits 8 to 15 - TID"]},{"entry":[{},{},"Bits 16 to 23 - DID"]},{"entry":[{},{},"Bits 24 to 31 - queue to"]},{"entry":[{},{},"place message in (0 bypasses"]},{"entry":[{},{},"queues)"]},{"entry":["8","arg 0","Message argument 0"]},{"entry":[". . .",{},"Message arguments 1-6"]},{"entry":["15","arg 7","Message argument 7"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"Processor  may achieve a sufficiently high throughput for sending messages for data-intensive, real time applications using message interface unit . In particular, argument registers  (i.e., the scratchpad memory) may be accessed by processor  to speculatively create messages that may later be sent. Processor  may be able to create and send messages at a high rate by making use of the scratchpad memory. Message interface unit  may control any access to the scratchpad memory and stall processor  if it attempts to write to an argument register that is currently being sent (e.g., as a part of a previous message). Otherwise, message interface unit  may allow processor  to write to an argument register during each clock cycle in preparation to send a message. The processor may send identical or similar messages efficiently because only the argument registers corresponding to argument values that change need to be written prior to a message being sent. Once processor  writes to header register , a message that includes the arguments in the scratchpad memory may either be sent or queued in one of queues . In this way, processor , together with message interface unit , may speculatively create and queue messages to be sent in the event that message interface unit  and\/or processor  receive particular messages. Speculative message creation and queuing will be discussed in greater detail below.","Examples of software code that could be used by a processor, such as processor , to send a message or to discard any of the contents of a queue, are shown below. In the example code, the macros that are used are described within Appendix A, incorporated herein.",{"@attributes":{"id":"p-0039","num":"0038"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"182pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003","TX_SELECT_QUEUE (2);"]},{"entry":[{},{},"do {"]},{"entry":[{},{},"\u2003words_available = TX_QUEUE_SPACE ( ); \/\/ optional"]},{"entry":[{},{},"} while (words_available < 3);"]},{"entry":[{},{},"TX_SEND_MSG1 (2, addr1, eid1, msg1_arg0);"]},{"entry":[{},{},"TX_SEND_MSG2 (2, addr2, eid2, msg2_arg0, msg2_arg1);"]},{"entry":[{},{},"\/\/ send message directly (no queue)"]},{"entry":[{},{},"TX_SEND_MSG1 (1, addr1, eid1, msg1_arg0);"]},{"entry":[{},{},"...some time later..."]},{"entry":[{},{},"if (exception_occurs) {"]},{"entry":[{},{},"\u2003TX_FREE_QUEUE (2); \/\/ prediction was wrong,"]},{"entry":[{},{},"\u2003delete messages in queue"]},{"entry":[{},{},"} else {"]},{"entry":[{},{},"\u2003TX_SEND_QUEUE (2); \/\/ prediction was correct,"]},{"entry":[{},{},"\u2003send messages in queue"]},{"entry":[{},{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"Processor  may use argument registers  (i.e., the scratchpad memory), in message interface unit , to speculatively create messages. Processor  may write to header register  to send a message that the processor created (either to a device or to one of queues ). Processor  may use a minimal number of clock cycles to send a message. In particular, the number of clock cycles to send a message may be equal to N writes (to write to the N argument registers  where N is the number of arguments)+1 write (to write to header register ). In addition, a message may be sent without interrupting processor  (i.e., automatically sent by message interface unit  without involvement from processor ). In some embodiments, argument registers  may retain their values so that a subsequent identical message can be sent with only one write to header register . Processor  may perform repeated writes to header register  to send the same message repeatedly.","When sending a message, arguments stored in argument registers  may be read and sent\/forwarded sequentially to allow processor  to update (write to) the arguments registers  for arguments that have already been sent\/forwarded. In order to create a new message rapidly, processor  may write to any one of argument registers  during the clock cycle immediately following the clock cycle during which the argument in that register had been sent\/forwarded. Thus, at the start of the clock cycle following a write to header register , message interface unit  may allow processor  to write to the arg0 argument register (after previously stored argument arg0 has been sent\/forwarded). During the subsequent clock cycle, message interface unit  may allow processor  to write to the arg1 argument register, in the following clock cycle, to the arg2 argument register, and so on.","The transmission databus, which is used to send\/forward messages from transmit registers  to queues  or to other devices, may be a multiple of one argument's width. This may allow multiple arguments to be sent at once on the databus, and it may also allow messages to be created and sent\/forwarded into the system or a queue without stalling processor . This may lead to improved efficiency for processor .","As discussed above, a message may be placed in one of queues  instead of being sent into the system or directly to a hardware unit. All the messages in any one of queues  may be discarded with a single write by processor  to free_queue register . All the messages in any one of queues  may be sent with a single write by processor  to send_queue register . In particular, processor  may speculatively create and queue a message into one of queues . Such speculative message creation and queuing may be performed by the processor in anticipation of expected events that may occur (e.g., an expectation that an incoming message with a new line of video to be upscaled will arrive in the future). Messages may be created (as described above) and queued speculatively during clock cycles during which the processor is idle (e.g., messages, to be sent by the processor in response to receiving a new line of video, may be speculatively created using transmit registers  and queued using queues ). This type of speculative message creation and queuing may allow message interface unit  to achieve a high message throughput because several messages may be speculatively queued and sent rapidly in response to an expected message arriving. In addition, this type of speculative message creation and queuing may allow message interface unit  to achieve a low message response latency by avoiding the use of additional cycles to create messages in response to an expected message arriving. To reduce latency further, message interface unit  may be configured to automatically send or discard any or all of the messages in one of queues  when triggered by a particular message (also referred to as a triggering message) thereby freeing additional clock cycles from processor  to potentially perform other tasks.","As described above, one or more queues  may be used to queue message speculatively. Message interface unit , acting on behalf of processor , or independently, may take action in response to a particular message being received by message interface unit  or processor . The action taken by message interface unit  allows for it to send or discard any message in one of the queues or all of the messages contained within one or more of queues  in response to a particular message being received by message interface unit  or processor . For example, processor  and\/or message interface unit  may discard all of the messages in one of queues  when it receives a message indicating that an exception occurred. Message interface unit  may include configurable triggers (not shown) that allow any or all of the messages contained within any of queues  to be sent or discarded automatically on receipt of a message (i.e., a triggering message). These triggers may effectively allow message interface unit  to act on the receipt of a message (a triggering message) without the involvement of processor , thereby reducing the burden on processor . In some embodiments the configurable triggers may be hardwired or programmed in hardware units within message interface unit . In some embodiments, the configurable triggers may be based in software operating on message interface unit .","Message interface unit  may include receive registers , which include several reserved registers (not shown), select_queue register , fill_level register , get_message register , header register , and argument registers . Processor  may read from or write to transmit registers  via message interface unit . In one embodiment, the addresses of receive registers  and the description with regards to what occurs when processor  either writes to or reads from each of these registers is shown in Table 2.",{"@attributes":{"id":"p-0046","num":"0045"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"105pt","align":"left"}}],"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["Address","Register","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"char","char":"."}},{"@attributes":{"colname":"2","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"105pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["0","reserved",{}]},{"entry":["1","reserved",{}]},{"entry":["2","reserved",{}]},{"entry":["3","fill_level","Read - returns the fill level of"]},{"entry":[{},{},"the queue"]},{"entry":["4","select_queue","Write - sets queue to report"]},{"entry":[{},{},"fill level"]},{"entry":["5","get_message","Write - causes the MIU to get"]},{"entry":[{},{},"the next message (when"]},{"entry":[{},{},"available) from the specified"]},{"entry":[{},{},"queue"]},{"entry":["6","reserved",{}]},{"entry":["7","header","Bits 0 to 7 - number of"]},{"entry":[{},{},"arguments used"]},{"entry":[{},{},"Bits 8 to 15 - EID"]},{"entry":[{},{},"Bits 16 to 23 - source address"]},{"entry":[{},{},"Bit 24 -message valid (set to"]},{"entry":[{},{},"0 if no new messages available"]},{"entry":[{},{},"yet)"]},{"entry":[{},{},"Bits 25 to 31 - reserved"]},{"entry":["8","arg 0","Message argument 0"]},{"entry":[". . .",{},"Message arguments 1-6"]},{"entry":["15","arg 7","Message argument 7"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"Examples of software code that could be used by a processor, such as processor , to receive a message is shown below. In the example code, the macros that are used are described within Appendix B, incorporated herein.",{"@attributes":{"id":"p-0048","num":"0047"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u2003","RX_SELECT_QUEUE (2);"]},{"entry":[{},{},"if (RX_QUEUE_FILL_LEVEL ( ) == 0) { \/\/ optional"]},{"entry":[{},{},"\u2003\/\/ make prediction about what the next message"]},{"entry":[{},{},"\u2003will be"]},{"entry":[{},{},"} else {"]},{"entry":[{},{},"\u2003RX_RECV_MSG (2);"]},{"entry":[{},{},"\u2003do {"]},{"entry":[{},{},"\u2003\u2003header = RX_HEADER"]},{"entry":[{},{},"\u2003} while(header & 0x1000000);"]},{"entry":[{},{},"\u2003eid = (header & 0xFF00) >> 8;"]},{"entry":[{},{},"\u2003switch(eid) {"]},{"entry":[{},{},"\u2003\u2003case TASK_1:"]},{"entry":[{},{},"\u2003\u2003\u2003int result = RX_ARG0 + RX_ARG1;"]},{"entry":[{},{},"\u2003\u2003\u2003..."]},{"entry":[{},{},"\u2003\u2003\u2003break;"]},{"entry":[{},{},"\u2003\u2003case TASK_2: ... break;"]},{"entry":[{},{},"\u2003}"]},{"entry":[{},{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}}}},"Messages may be loaded into argument registers , from one or more of queues , when processor  performs a write operation to get_message register . Processor  may use a minimal number of clock cycles to load\/receive a message. In particular, the number of clock cycles to load\/receive a message may be equal to 1 write (to write to get_message register )+1 read (to read from header register )+N reads (to read from the N argument registers , where N is the number of arguments). In addition, in some embodiments, a message may be loaded\/received without interrupting processor  (i.e., automatically loaded\/received by message interface unit ).","When loading\/receiving a message, argument registers  may be written to and read from sequentially to allow processor  to read arguments from the arguments registers  that have already been written (e.g., via one of queues ) and have recently become available. In order to load a new message rapidly, processor  may read from any one of argument registers  during the clock cycle immediately following the clock cycle during which the argument in that register had been written to via, for example, one of queues . Thus, at the start of the clock cycle following a write to get_message register , message interface unit  may allow processor  to read the arg0 argument register (one clock cycle after argument arg0 has been written to via, for example, one of queues ). During the subsequent clock cycle, message interface unit  may allow processor  to read from the arg1 argument register, in the following clock cycle, from the arg2 argument register, and so on.","The receive databus, which is used to load\/receive messages from queues  to receive registers , may be a multiple of one argument's width. This may allow multiple arguments to be loaded\/received at once on the databus and it may also allow messages to be loaded\/received and read without stalling processor . This may lead to improved efficiency for processor .","Messages sent to processor  or message interface unit  may be placed in one of queues . Each of one or more queues  may have a different unique destination address to allow each of the hardware units to be able to send its message to the appropriate queue. Because processor  may be able to receive messages from any one of queues , this use of dedicated queuing allows particular messages to \u201cjump ahead\u201d and be processed earlier than other messages. Moreover, such use of dedicated queuing allows the system to queue messages according to different priorities. This may be accomplished by assigning a different priority level to each of queues . In such a scheme, the address assigned to each queue may be indicative of and\/or associated with the particular priority level.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 5","FIGS. 2A and 2B"],"b":["500","560","500","560","200","500","570","580","550","540","530","520","510"]},"System  could be used in a wide variety of applications, such as computer networking, data networking, instrumentation, video processing, digital signal processing, or any other application where the advantage of using programmable or reprogrammable logic is desirable. IC  can be used to perform a variety of different logic functions. For example, IC  can be configured as a processor or controller that works in cooperation with processor . IC  may also be used as an arbiter for arbitrating access to a shared resource in system . In yet another example, IC  can be configured as an interface between processor  and one of the other components in system  or another device or hardware unit outside of system . It should be noted that system  is only exemplary, and that the true scope and spirit of the invention should be indicated by the following claims.","It will be understood that the foregoing are only illustrative of the principles of the invention, and that various modifications can be made by those skilled in the art without departing from the scope and spirit of the invention. For example, message interface unit  of  may be similar to message interface unit  of . In addition, message interface unit  may be used interchangeably with message interface unit . One skilled in the art will appreciate that the present invention can be practiced by other than the described embodiments, which are presented for purposes of illustration and not of limitation, and the present invention is limited only by the claims that follow.","TX_SELECT_QUEUE(queue_id)",{"@attributes":{"id":"p-0056","num":"0000"},"ul":{"@attributes":{"id":"ul0001","list-style":"none"},"li":{"@attributes":{"id":"ul0001-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0002","list-style":"none"},"li":["Selects the queue that the TX_QUEUE_SPACE command returns the space available of","If only one queue is used this only needs to be done once at start up","Single write to the MIU\n\nwords_available=TX_QUEUE_SPACE( );\n","Gets the space available in the queue selected by TX_SELECT_QUEUE (in words)","Single read from MIU\n\nTX_ARG(n, value);\n","Sets the nargument of the current message","Single write to MIU\n\nTX_SEND_MSG(queue_id, dst_addr, eid, no_of_arguments);\n","Sets the eid and dst_addr fields of the current message","Causes the MIU to write the current message to the specified queue","Single write to MIU","Queue 0 can be configured as a direct send\n        \n        ","Concise way of sending a single argument message\n        \n        ","TX_SEND_MSG2 to TX_SEND_MSG8 can be used to send multiple argument messages\n        \n        ","Sends all of the messages in the queue out into the system, in the order that they are in the queue","Single write to MIU\n\nTX_QUEUE_FREE(queue_id);\n","Deletes all of the messages in the queue","Single write to MIU"]}}}},"RX_SELECT_QUEUE(queue_id)",{"@attributes":{"id":"p-0057","num":"0000"},"ul":{"@attributes":{"id":"ul0006","list-style":"none"},"li":{"@attributes":{"id":"ul0006-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0007","list-style":"none"},"li":["Selects the queue that the RX_QUEUE_FILL_LEVEL command returns the fill level of","If only one queue is used this only needs to be done once at start up","Single write to the MIU\n\nno_of_messages=RX_QUEUE_FILL_LEVEL( );\n","Gets the number of messages in the queue selected by RX_SELECT_QUEUE","Single read to the MIU\n\nheader=RX_HEADER\n","Gets the message header of the current message","Check bit  to see if the message is valid (0 indicates no messages available yet)\n\narg0=RX_ARG0;\n","Gets the 1argument of the current message","Single read from the MIU","RX_ARG(0 to N) can be used to get the 1to N+1th arguments\n\nRX_RECV_MSG(queue_id);\n","Causes the MIU to update the current message with the next message from the queue","Single read to MIU"]}}}}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Further features of the disclosure, its nature and various advantages will be apparent upon consideration of the following detailed description, taken in conjunction with the accompanying drawings, in which like reference characters refer to like parts throughout, and in which:",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIGS. 2A and 2B"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
