---
title: Method and apparatus for denoising and deverberation using variational inference and strong speech models
abstract: A probability distribution for speech model parameters, such as auto-regression parameters, is used to identify a distribution of denoised values from a noisy signal. Under one embodiment, the probability distributions of the speech model parameters and the denoised values are adjusted to improve a variational inference so that the variational inference better approximates the joint probability of the speech model parameters and the denoised values given a noisy signal. In some embodiments, this improvement is performed during an expectation step in an expectation-maximization algorithm. The statistical model can also be used to identify an average spectrum for the clean signal and this average spectrum may be provided to a speech recognizer instead of the estimate of the clean signal.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06990447&OS=06990447&RS=06990447
owner: Microsoft Corportion
number: 06990447
owner_city: Redmond
owner_country: US
publication_date: 20011115
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS"],"p":["The present invention relates to speech enhancement and speech recognition. In particular, the present invention relates to denoising speech.","In many applications, it is desirable to remove noise from a signal so that the signal is easier to recognize. For speech signals, such denoising can be used to enhance the speech signal so that it is easier for users to perceive. Alternatively, the denoising can be used to provide a cleaner signal to a speech recognizer.","In some systems, such denoising is performed in cepstral space. Cepstral space is defined by a set of cepstral coefficients that describe the spectral content of a frame of a signal. To generate a cepstral representation of a frame, the signal is sampled at several points within the frame. These samples are then converted to the frequency domain using a Fourier Transform, which produces a set of frequency-domain values. Each cepstral coefficient is then calculated as: \n\n\nwhere cis the ith cepstral coefficient, C is a transform, wis a filter associated with the ith coefficient and the kth frequency, and Sis the spectrum for the kth frequency, which is defined as:\n\nS=|{circumflex over (x)}|\u2003\u2003EQ. 2\n\nwhere {circumflex over (x)}is an average sample value for the kth frequency.\n","To perform the denoising in cepstral space, models of clean speech and noise are built in cepstral space by converting clean speech training signals and noise training signals into sets of cepstral coefficient vectors. The vectors are then grouped together to form mixture components. Often, the distribution of vectors in each component is described using a Gaussian distribution that has a mean and a variance.","The resulting mixture of Gaussians for the clean speech signal represents a strong model of clean speech because it limits clean speech to particular values represented by the mixture components. Such strong models are thought to improve the denoising process because they allow more noise to be removed from a noisy speech signal in areas of cepstral space where clean speech is unlikely to have a value.","Although removing noise in the cepstral domain has proven effective, it is limiting in that only the resulting denoised signal can be applied directly to a speech recognition system. As such, removing noise in the cepstral domain does not facilitate providing something other than the denoised cepstral vectors to the recognizer.","In addition, denoising in the cepstral domain is more difficult than removing noise in the time domain or frequency domain. In the time or frequency domains, noise is additive, so noisy speech equals clean speech plus noise. In the cepstral domain, noisy speech is a complicated nonlinear function of clean speech and noise, and the required math becomes intractable and needs to be approximated. This is a separate complication that is independent of the complexity of the models used. Hence, time or frequency domain methods may in theory be able to provide a more accurate denoising since they would not require the approximation found in the cepstral domain.","To overcome these limitations, some systems have attempted to denoise speech signals in the time domain or the frequency domain. However, such denoising systems typically use simple models for the clean speech signal that do not incorporate much information on the structure of speech. As a result, it is difficult to discern noise from clean speech since the clean speech is allowed to take nearly any value.","One common model of clean speech is an auto-regression model that models a next point in a speech signal based on past points in the speech signal. In terms of an equation: \n\n\nwhere xis the nth sample in the speech signal, xis the n-mth sample in the speech signal, aare auto-regression parameters based on a physical shape of a \u201clossless tube\u201d model of a vocal tract and vis a combination of an input excitation and a fitting error.\n","Because the auto-regression model parameters are based on a physical model rather than a statistical model, they lack a great deal of information concerning the actual content of speech. In particular, the physical model allows for a large number of sounds that simply are not heard in certain languages. Because of this, it is difficult to separate noise from clean speech using such a physical model.","Some prior art systems have generated statistical descriptions of speech that are based on AR parameters. Under these systems, frames of training speech are grouped into mixture components based on some criteria. AR parameters are then selected for each component so that the parameters properly describe the mean and variance of the speech frames associated with the respective mixture component.","Under many such systems, the coefficients of the AR model are selected during training and are not modified while the system is being used. In other words, the model coefficients are not adjusted based on the noisy signal received by the system. In addition, because the AR coefficients are fixed, they are treated as point values that are known with absolute certainty.","In another prior art system described in J. Lim, -, IEEE Transactions on Acoustics, Speech, and Signal Processing, Vol. ASSP-26, No. 3, June 1978, a time domain\/frequency domain system is shown in which the AR coefficients are not fixed but instead are modified based on the noisy signal. Under the Lim system, an iteration is performed to alternately update the AR coefficients and then update the denoised signal values. However, even under Lim, the updates to the denoised signal values are based on point values for the AR coefficients that are assumed to be known with certainty.","In reality, the best AR coefficients are never known with certainty. As such, the prior art systems that determine the denoised signal values by using point values for the AR coefficients are less than ideal since they rely on an assumption that is not true.","Thus, a denoising system is needed that operates in the time domain or frequency domain, and that recognizes that parameters of a model description of speech can only be known with a limited amount of certainty. In addition, such a system needs to be computationally efficient.","A probability distribution for speech model parameters, such as auto-regression parameters, is used to identify a distribution of denoised values from a noisy signal. Under one embodiment, the probability distributions of the speech model parameters and the denoised values are adjusted to improve a variational inference so that the variational inference better approximates the joint probability of the speech model parameters and the denoised values given a noisy signal. In some embodiments, this improvement is performed during an expectation step in an expectation-maximization algorithm.","The statistical model can also be used to identify an average spectrum for the clean signal and this average spectrum may be provided to a speech recognizer instead of the estimate of the clean signal.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1","b":["100","100","100","100"]},"The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well-known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, telephony systems, distributed computing environments that include any of the above systems or devices, and the like.","The invention may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices.","With reference to , an exemplary system for implementing the invention includes a general-purpose computing device in the form of a computer . Components of computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","Computer  typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer . Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules , and program data .","The computer  may also include other removable\/non-removable volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in , provide storage of computer readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that, at a minimum, they are different copies.","A user may enter commands and information into the computer  through input devices such as a keyboard , a microphone , and a pointing device , such as a mouse, trackball or touch pad. Other input devices (not shown) may include a joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . In addition to the monitor, computers may also include other peripheral output devices such as speakers  and printer , which may be connected through an output peripheral interface .","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a hand-held device, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on remote computer . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 2","b":["200","200","202","204","206","208","210"]},"Memory  is implemented as non-volatile electronic memory such as random access memory (RAM) with a battery back-up module (not shown) such that information stored in memory  is not lost when the general power to mobile device  is shut down. A portion of memory  is preferably allocated as addressable memory for program execution, while another portion of memory  is preferably used for storage, such as to simulate storage on a disk drive.","Memory  includes an operating system , application programs  as well as an object store . During operation, operating system  is preferably executed by processor  from memory . Operating system , in one preferred embodiment, is a WINDOWS\u00ae CE brand operating system commercially available from Microsoft Corporation. Operating system  is preferably designed for mobile devices, and implements database features that can be utilized by applications  through a set of exposed application programming interfaces and methods. The objects in object store  are maintained by applications  and operating system , at least partially in response to calls to the exposed application programming interfaces and methods.","Communication interface  represents numerous devices and technologies that allow mobile device  to send and receive information. The devices include wired and wireless modems, satellite receivers and broadcast tuners to name a few. Mobile device  can also be directly connected to a computer to exchange data therewith. In such cases, communication interface  can be an infrared transceiver or a serial or parallel communication connection, all of which are capable of transmitting streaming information.","Input\/output components  include a variety of input devices such as a touch-sensitive screen, buttons, rollers, and a microphone as well as a variety of output devices including an audio generator, a vibrating device, and a display. The devices listed above are by way of example and need not all be present on mobile device . In addition, other input\/output devices may be attached to or found with mobile device  within the scope of the present invention.","As shown in the block diagram of , the present invention provides a denoising system  that identifies a denoised signal  from a noisy signal  by generating a probability distribution for speech model parameters that describe the spectrum of a denoised signal, such as auto-regression (AR) parameters, and using that distribution to determine a distribution of denoised values.","Under one embodiment of the present invention, the probability distribution for the speech model parameters, also referred to as spectrum parameters or distribution parameters, is a mixture of Normal-Gamma distributions for AR parameters. Under this embodiment, each mixture component, s, provides a probability of a set of AR parameters, \u03b8, that is defined as: \n\n\nwhere \u03bcis the mean of a normal distribution for a kth parameter, Vis a precision value for the kth parameter, \u03b1and \u03b2are the shape and size parameters, respectively, of the Gamma contribution to the distribution, \u03bd is the error associated with the AR model and \u00e3\u2032is defined as: \n\n\nwhere wis a frequency, and ais the nth AR parameter.\n","Under one embodiment, the hyper parameters (\u03bc, V, \u03b1, \u03b2) that describe the distribution for each mixture component are initially determined by a training unit  and appear as a prior AR parameter model .","Under one embodiment, training unit  receives frequency-domain values from a Fast Fourier Transform (FFT) unit  that describe frames of a clean signal . In one particular embodiment, FFT unit  generates frequency domain values that represent 16 msec overlapping frames that have been sampled by an analog-to-digital converter  at N=256 time points using a 16 kHz sampling rate. Under one embodiment, the clean signal is generated from 10000 sentences of the Wall Street Journal recorded with a close-talking microphone for 150 male and female speakers of North American English.","For each frame, training unit  identifies a set of AR parameters that best describe the signal in the frame. Under one embodiment, an auto-correlation technique is used to identify the proper AR parameters for each frame.","The resulting AR parameters are then clustered into mixture components. Under one embodiment, each frame's parameters are grouped into one of 256 mixture components.","One method for performing this clustering is to convert the AR parameters to the cepstral domain. This can be done by using the sample points that would be generated by the AR parameters to represent a pseudo-signal and then converting the pseudo-signal into cepstral coefficients. Once the cepstral coefficients are formed, they can be grouped using k-means clustering, which is a known technique for grouping cepstral coefficients. The resulting groupings are then translated onto the respective AR parameters that formed the cepstral coefficients.","Once the groupings have been formed, statistical parameters (\u03bc, V, \u03b1, \u03b2) that describe the distribution for each mixture component are determined from the AR training parameters grouped in each component. Techniques for determining these values for a Normal-Gamma distribution given a data set are well known. The resulting statistical parameters are then stored as prior AR parameter model .","Once the prior parameter model has been generated, it can be used to identify denoised signals  from noisy signals . Ideally, this would be done by using the prior model and direct inference to determine a posterior probability that describes the likelihood of a particular clean signal, x, given a noisy signal, y. Such posterior probabilities are commonly calculated for simple models using the inference-based Bayes rule, which states: \n\n\nwhere p(x|y) is the posterior probability, p(y|x) is a likelihood that provides the probability of the noisy signal given the clean signal, and p(x) and p(y) are prior probabilities of the clean signal and noisy signal, respectively.\n","For the present invention, the posterior probability becomes p(s,\u03b8,x|y), which is the joint probability of mixture component s, AR parameters \u03b8, and denoised signal x given noisy signal y. However, attempting to calculate this value using exact inference becomes intractable because it results in a quartic term exp(x\u03b8).","Under one embodiment of the present invention, the intractability of calculating the exact posterior probability is overcome using variational inference. Under this technique, the posterior probability is replaced with an approximation that is then adapted so that the distance between the approximation and the actual posterior probability is minimized. In particular, the approximation, q(s,\u03b8,x|y), to the posterior probability is adapted by maximizing an improvement function defined as: \n\n\nwhere F[q] is the improvement function, q(s,\u03b8,x|y) is the approximation to the posterior probability, and p(s,\u03b8,x,y) is the joint probability of mixture component s, AR parameters \u03b8, denoised signal x, and noisy signal y.\n","To limit the search space for the approximation to the posterior, the approximation is further defined as:\n\n()=()(\u03b8|)()\u2003\u2003EQ. 8\n\nwhere q(s) is the probability of mixture component s, q(\u03b8|s) is the probability of AR parameters \u03b8 given mixture component s, and q(x|s) is the probability of a clean signal x given mixture component s.\n","The approximation is updated by iterating between modifying the distributions that describe q(s) and q(\u03b8|s), and modifying the distributions that describe q(x|s). To begin the iteration, prior AR parameter model  is used by a variational inference calculator  to initialize the statistical parameters associated with q(s) and q(\u03b8|s). In particular, \u03bc, V, \u03b1, \u03b2, which describe the distribution of prior AR parameter model p(\u03b8|s), and \u03c0, which describes the weighting of the mixture components in the prior AR parameter model, are used to initialize q(\u03b8|s) and q(s), respectively.","With the hyper parameters of the AR distribution initialized, a mean, \u03c1, and an N\u00d7N precision matrix, \u039b, that describe q(x|s) are obtained as: \n\n\nwhere \u03c1is the mean of the nth time point in a frame of the denoised signal for mixture component s, \u039b, is the an entry in the precision matrix that provides the covariance of two values at time points n and m, N is the number of frequencies in the Fast Fourier Transform, wis the kth frequency, {tilde over (y)}is Fast Fourier Transform of a frame of the noisy signal at the kth frequency and {tilde over (f)}and {tilde over (g)}are defined as: \n\n{tilde over (g)}=\u03bb|{tilde over (b)}\u2032|+E(v|\u00e3\u2032|)EQ. 12\n\nwhere {tilde over (b)}\u2032and \u03bb are AR parameters of an AR description of noise, \u00e3\u2032is the frequency domain representation of the AR parameters for the clean signal as defined in EQ. 5 above, and E( ) denotes averaging with respect to the distribution of AR parameters q(\u03b8|s).\n","The result of equations 9\u201312 produces an adapted distribution for denoised speech  in . Adapted denoised speech distribution  is then used by variational inference calculator  to update the hyper parameters that describe the distribution of q(\u03b8|s) through:\n\n\u2003\u2003EQ. 13\n\n{circumflex over (\u03bc)}(\u03bc)\u2003\u2003EQ. 14\n",{"@attributes":{"id":"p-0054","num":"0053"},"br":[{},{},{},{}],"in-line-formulae":[{},{}],"sub":["s","s","s ","s ","s","s","s ","s ","s ","s","s","s ","s","s","s","sk ","s ","s ","n","nm","s ","s ","n","n,0","n","s"],"i":"=N+p+\u03b1","maths":[{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"msub":{"mover":{"mi":"\u03b2","mo":"^"},"mi":"s"},"mo":"=","mrow":{"mrow":[{"mfrac":{"mn":"1","mi":"N"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"k"},"mo":"\u2062","mrow":{"msup":[{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mover":{"mi":"a","mo":"~"},"msup":{"mi":["k","\u2032"]}}},"mn":"2"},{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mover":{"mi":"x","mo":"~"},"mi":"k"}},"mn":"2"}],"mo":["\u2062","\u2062"],"msub":{"mi":["E","s"]}}}},{"mfrac":{"mn":"1","mi":"p"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","msup":{"mi":["k","\u2032"]}},"mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":{"msub":[{"mover":{"mi":"\u03be","mo":"~"},"msup":{"mi":["sk","\u2032"]}},{"mover":{"mi":"a","mo":"~"},"msup":{"mi":["k","\u2032"]}}],"mo":"\u2062"},"mo":"-","msub":{"mover":{"mi":"\u03b7","mo":"~"},"msup":{"mi":["sk","\u2032"]}}}},"mn":"2"}}}],"mo":["+","+"],"msub":{"mi":["\u03b2","s"]}}}},{"mstyle":{"mtext":"EQ.\u00a0\u00a016"}}]},{"mtd":[{"mrow":{"msub":{"mover":{"mi":"\u03c0","mo":"^"},"mi":"s"},"mo":"=","mrow":{"mrow":[{"mrow":[{"mo":"-","mfrac":{"mi":"\u03bb","mrow":{"mn":"2","mo":"\u2062","mi":"N"}}},{"munder":{"mo":"\u2211","mi":"k"},"mo":"\u2062","mrow":{"msup":[{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mover":{"mi":"b","mo":"~"},"msup":{"mi":["k","\u2032"]}}},"mn":"2"},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mover":{"mi":"y","mo":"~"},"mi":"k"},{"mover":{"mi":"x","mo":"~"},"mi":"k"}],"mo":"-"}},"mn":"2"}],"mo":["\u2062","\u2062"],"msub":{"mi":["E","s"]}}}],"mo":"\u2062"},{"mfrac":{"mi":"\u03c5","mrow":{"mn":"2","mo":"\u2062","mi":"N"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"k"},"mo":"\u2062","mrow":{"msup":[{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mover":{"mi":"a","mo":"~"},"msup":{"mi":["k","\u2032"]}}},"mn":"2"},{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mover":{"mi":"x","mo":"~"},"mi":"k"}},"mn":"2"}],"mo":["\u2062","\u2062"],"msub":{"mi":["E","s"]}}}},{"mfrac":{"mi":"\u03c5","mrow":{"mn":"2","mo":"\u2062","mi":"p"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","msup":{"mi":["k","\u2032"]}},"mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":{"msub":[{"mover":{"mi":"\u03be","mo":"~"},"msup":{"mi":["sk","\u2032"]}},{"mover":{"mi":"a","mo":"~"},"msup":{"mi":["k","\u2032"]}}],"mo":"\u2062"},"mo":"-","msub":{"mover":{"mi":"\u03b7","mo":"~"},"msup":{"mi":["sk","\u2032"]}}}},"mn":"2"}}},{"mfrac":{"mrow":{"mi":["N","p"],"mo":"+"},"mn":"2"},"mo":["\u2062","\u2062","\u2062"],"mi":["log","\u03c5"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"munder":{"mo":"\u2211","mi":"k"},"mo":"\u2062","mrow":{"mi":"log","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mover":{"mi":"g","mo":"~"},"mi":"sk"}}}],"mo":["-","-","+","-"]}}},{"mstyle":{"mtext":"EQ.\u00a0\u00a017"}}]}]}}},{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msubsup":{"mi":["R","s"],"mrow":{"mi":["n","m"],"mo":","}},"mo":"=","mrow":{"mfrac":{"mn":"1","mi":"N"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"msup":{"mi":"\u2147","mrow":{"mi":"\u2148","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["w","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["n","m"],"mo":"-"}}}}},"mo":"\u2062","mrow":{"msub":{"mi":["E","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msup":{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mover":{"mi":"x","mo":"~"},"mi":"k"}},"mn":"2"}}}}}}}},{"mstyle":{"mtext":"EQ.\u00a0\u00a018"}}]}}}},{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"msubsup":{"mover":{"mi":"V","mo":"^"},"mrow":{"mi":["n","m"],"mo":","},"mi":"s"},"mo":"=","mrow":{"msubsup":{"mi":["V","s"],"mrow":{"mi":["n","m"],"mo":","}},"mo":"+","mrow":{"mfrac":{"mn":"1","mi":"N"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"msup":{"mi":"\u2147","mrow":{"mi":"\u2148","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["w","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["n","m"],"mo":"-"}}}}},"mo":"\u2062","mrow":{"msub":{"mi":["E","s"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msup":{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mover":{"mi":"x","mo":"~"},"mi":"k"}},"mn":"2"}}}}}}}}},{"mstyle":{"mtext":"EQ.\u00a0\u00a020"}}]},{"mtd":[{"mrow":{"msubsup":{"mover":{"mi":"\u03bc","mo":"^"},"mi":["n","s"]},"mo":"=","mrow":{"msubsup":{"mover":{"mi":"V","mo":"^"},"mrow":[{"mi":["s","n"],"mo":","},{"mo":"-","mn":"1"}]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":[{"mfrac":{"mn":"1","mi":"N"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","msup":{"mi":"\u2147","mrow":{"mi":"\u2148","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["w","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}}}},{"msub":{"mi":"V","mrow":{"mi":["s","n"],"mo":","}},"mo":"\u2062","msubsup":{"mi":["\u03bc","n","s"]}}],"mo":"+"}}}}},{"mstyle":{"mtext":"EQ.\u00a0\u00a021"}}]}]}}},{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["E","s"]},"mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mover":{"mi":"x","mo":"~"},"mi":"k"}},"mn":"2"}},{"msup":{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mover":{"mi":"\u03c1","mo":"~"},"mi":"k"}},"mn":"2"},"mo":"+","mfrac":{"mi":"N","msub":{"mover":{"mi":"g","mo":"~"},"mi":"sk"}}}],"mo":"="}},{"mstyle":{"mtext":"EQ.\u00a0\u00a022"}}]},{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["E","s"]},"mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mover":{"mi":"y","mo":"~"},"mi":"k"},{"mover":{"mi":"x","mo":"~"},"mi":"k"}],"mo":"-"}},"mn":"2"}},{"msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mover":{"mi":"y","mo":"~"},"mi":"k"},{"mover":{"mi":"\u03c1","mo":"~"},"mi":"k"}],"mo":"-"}},"mn":"2"},"mo":"+","mfrac":{"mi":"N","msub":{"mover":{"mi":"g","mo":"~"},"mi":"sk"}}}],"mo":"="}},{"mstyle":{"mtext":"EQ.\u00a0\u00a023"}}]}]}}}],"sup":["s ","s","s","s","s "]},"The updates to the AR parameter distribution result in an adapted AR distribution model . The distributions for the AR parameters and the denoised values continue to be adapted in an alternating fashion until the adapted distributions converge on final values. At this point, denoised speech values for time points, n, in the frame can be determined as: \n\n","Under one embodiment of the present invention, the variational inference technique described above forms an E-step in an Expectation-Maximization (EM) algorithm. Under the E-step of a typical EM algorithm, a distribution for a hidden variable is determined, wherein a hidden variable is a variable that cannot be observed directly. Under the present invention, the variational inference is used in the E-step to allow distributions for two different hidden variables to be determined while maintaining the dependence of the two variables to each other.","In particular, by using variational inference, embodiments of the present invention are able to determine a distribution for the AR parameters and a distribution for the denoised values, without assuming that the parameters and the values are independent of each other. The results of this variational inference are a set of distributions for the AR parameters and the denoised values that represent the relationship between the parameters and the denoised values.","In some embodiments, the E-step determination of the distributions for the AR parameters and the denoised values is followed by a maximization step (M-step) in which model parameters used in the E-step are updated based on the distributions for the hidden variables. In particular, the AR parameters, {tilde over (b)}\u2032 and \u03bb, that described a noise model are updated based on the distribution using the following update equations:",{"@attributes":{"id":"p-0059","num":"0058"},"br":[{},{},{}],"in-line-formulae":[{},{}],"sup":"\u22121","maths":[{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"\u03bb","mo":"=","msup":{"mrow":[{"mo":["(",")"],"mrow":{"mfrac":{"mn":"1","msup":{"mi":"N","mn":"2"}},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"k"},"mo":"\u2062","mrow":{"msup":[{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mover":{"mi":"b","mo":"~"},"msup":{"mi":["k","\u2032"]}}},"mn":"2"},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mover":{"mi":"y","mo":"~"},"mi":"k"},{"mover":{"mi":"x","mo":"~"},"mi":"k"}],"mo":"-"}},"mn":"2"}],"mo":["\u2062","\u2062"],"mi":"E"}}}},{"mo":"-","mn":"1"}]}}},{"mstyle":{"mtext":"EQ.\u00a0\u00a026"}}]}}}},{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["Q","nm"]},"mo":"=","mrow":{"mfrac":{"mn":"1","mi":"N"},"mo":"\u2062","mrow":{"munder":{"mo":"\u2211","mi":"k"},"mo":"\u2062","mrow":{"msup":[{"mi":"\u2147","mrow":{"msub":{"mi":["\u2148\u03c9","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["n","m"],"mo":"-"}}}},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mover":{"mi":"y","mo":"~"},"mi":"k"},{"mover":{"mi":"x","mo":"~"},"mi":"k"}],"mo":"-"}},"mn":"2"}],"mo":["\u2062","\u2062"],"mi":"E"}}}}},{"mstyle":{"mtext":"EQ.\u00a0\u00a027"}}]}}}},{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"E","mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mover":{"mi":"y","mo":"~"},"mi":"k"},{"mover":{"mi":"x","mo":"~"},"mi":"k"}],"mo":"-"}},"mn":"2"}},{"munder":{"mo":"\u2211","mi":"s"},"mo":"\u2062","mrow":{"msub":[{"mover":{"mi":"\u03c0","mo":"^"},"mi":"s"},{"mi":["E","s"]}],"mo":["\u2062","\u2062"],"msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mover":{"mi":"y","mo":"~"},"mi":"k"},{"mover":{"mi":"x","mo":"~"},"mi":"k"}],"mo":"-"}},"mn":"2"}}}],"mo":"="}},{"mstyle":{"mtext":"EQ.\u00a0\u00a028"}}]}}}}],"sub":["n","n0 "]},"The M-step can also be used to update a set of filter coefficients, h, that describes the effects of reverberation on the clean signal. In particular, with reverberation taken into consideration, the relationship between a noisy signal sample, y, and a set of clean signal samples, x, becomes: \n\n\nwhere his an impulse filter response and uis additive noise.\n","In embodiments that apply an M-step, the E-step and the M-step are iteratively repeated until the distributions for the estimate of the denoised values converge. Thus, a nested iteration is provided with an outer EM iteration and an inner iteration associated with the variational inference of the E-step.","By using a distribution of possible AR parameters instead of point values to determine the distribution of denoised values, the present invention provides a more accurate distribution for the denoised values. In addition, by utilizing variational inference, the present invention is able to improve the efficiency of identifying an estimate of a denoised signal.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 4","FIGS. 1 and 2","FIG. 4"],"b":["400","401","402","404","406"]},"A-to-D converter  converts the analog signal from microphone  into a series of digital values. In several embodiments, A-to-D converter  samples the analog signal at 16 kHz and 16 bits per sample, thereby creating 32 kilobytes of speech data per second.","The output of A-to-D converter  is provided to a Fast Fourier Transform , which converts 16 msec overlapping frames of the time-domain samples into frames of frequency-domain values. These frequency domain values are then provided to a noise reduction unit , which generates a frequency-domain estimate of a clean speech signal using the techniques described above.","Under one embodiment, the frequency-domain estimate of the clean speech signal is provided to a feature extractor , which extracts a feature from the frequency-domain values. Examples of feature extraction modules include modules for performing Linear Predictive Coding (LPC), LPC derived cepstrum, Perceptive Linear Prediction (PLP), Auditory model feature extraction, and Mel-Frequency Cepstrum Coefficients (MFCC) feature extraction. Note that the invention is not limited to these feature extraction modules and that other modules may be used within the context of the present invention.","Under other embodiments, noise reduction unit  identifies an average spectrum for a clean speech signal instead of an estimate of the clean speech signal. To determine the average spectrum, {\u015c}, equation 24 is modified to: \n\n\nwhere g is defined in equation 12, {\u015c} is the estimate of |x|, i.e. the mean spectrum of the frame, and \u03c1is defined as:\n\n\u03c1={tilde over (f)}{tilde over (y)}\u2003\u2003EQ. 31\n\nwhere {tilde over (f)}is defined in equation 11 above and {tilde over (y)}is the kth frequency component of the current noisy signal frame.\n","The average spectrum is provided to feature extractor , which extracts a feature value from the average spectrum. Note that the average spectrum of EQ. 21 is a different value than the square of the estimate of a denoised value. As a result, the feature values derived from the average spectrum are different from the feature values derived from the estimate of the denoised signal. Under some applications, the present inventors believe the feature values from the average spectrum produce better speech recognition results.","The feature vectors produced by feature extractor  are provided to a decoder , which identifies a most likely sequence of words based on the stream of feature vectors, a lexicon , a language model , and an acoustic model .","In some embodiments, acoustic model  is a Hidden Markov Model consisting of a set of hidden states. Each linguistic unit represented by the model consists of a subset of these states. For example, in one embodiment, each phoneme is constructed of three interconnected states. Each state has an associated set of probability distributions that in combination allow efficient computation of the likelihoods against any arbitrary sequence of input feature vectors for each sequence of linguistic units (such as words). The model also includes probabilities for transitioning between two neighboring model states as well as allowed transitions between states for particular linguistic units. By selecting the states that provide the highest combination of matching probabilities and transition probabilities for the input feature vectors, the model is able to assign linguistic units to the speech. For example, if a phoneme was constructed of states 0, 1 and 2 and if the first three frames of speech matched state 0, the next two matched state 1 and the next three matched state 2, the model would assign the phoneme to these eight frames of speech.","Note that the size of the linguistic units can be different for different embodiments of the present invention. For example, the linguistic units may be senones, phonemes, noise phones, diphones, triphones, or other possibilities.","In other embodiments, acoustic model  is a segment model that indicates how likely it is that a sequence of feature vectors would be produced by a segment of a particular duration. The segment model differs from the frame-based model because it uses multiple feature vectors at the same time to make a determination about the likelihood of a particular segment. Because of this, it provides a better model of large-scale transitions in the speech signal. In addition, the segment model looks at multiple durations for each segment and determines a separate probability for each duration. As such, it provides a more accurate model for segments that have longer durations. Several types of segment models may be used with the present invention including probabilistic-trajectory segmental Hidden Markov Models.","Language model  provides a set of likelihoods that a particular sequence of words will appear in the language of interest. In many embodiments, the language model is based on a text database such as the North American Business News (NAB), which is described in greater detail in a publication entitled CSR-III Text Language Model, University of Penn., 1994. The language model may be a context-free grammar or a statistical N-gram model such as a trigram. In one embodiment, the language model is a compact trigram model that determines the probability of a sequence of words based on the combined probabilities of three-word segments of the sequence.","Based on the acoustic model, the language model, and the lexicon, decoder  identifies a most likely sequence of words from all possible word sequences. The particular method used for decoding is not important to the present invention and any of several known methods for decoding may be used.","The most probable sequence of hypothesis words is provided to a confidence measure module . Confidence measure module  identifies which words are most likely to have been improperly identified by the speech recognizer, based in part on a secondary frame-based acoustic model. Confidence measure module  then provides the sequence of hypothesis words to an output module  along with identifiers indicating which words may have been improperly identified. Those skilled in the art will recognize that confidence measure module  is not necessary for the practice of the present invention.","Although the present invention has been described with reference to AR parameters, the invention is not limited to auto-regression models. Those skilled in the art will recognize that in the embodiments above, the AR parameters are used to model the spectrum of a denoised signal and that other parametric descriptions of the spectrum may be used in place of the AR parameters. For example, one may simply use the spectra themselves, Sfor frequency k, as parameters. This means replacing \u03bd|\u00e3\u2032| in the equations above with 1\/Sand determining a distribution over the S, e.g. a Gamma distribution for each k.","In addition, although the present invention has been described with reference to a computer system, it may also be used within the context of hearing aids to remove noise in the speech signal before the speech signal is amplified for the user.","Although the present invention has been described with reference to preferred embodiments, workers skilled in the art will recognize that changes may be made in form and detail without departing from the spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 4"}]},"DETDESC":[{},{}]}
