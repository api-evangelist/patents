---
title: Bypassing disk I/O operations when porting a computer application from one operating system to a different operating system
abstract: Systems, methods, and computer products that improve the performance of computer-implemented I/O operations for complex applications, such as a database, that are ported to target computer systems that are not tailored to support the high-performance services that may benefit applications. Complex applications, such as a database, often manage I/O access operations by a caching mechanism that is tailored to the needs of the application. When porting an application to a target computer system that does not support certain I/O access features, I/O performance of the application may be limited. The present invention may be implemented by introducing specialized I/O access features that are tailored to enhance I/O access performance for complex applications, such as a database.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07310689&OS=07310689&RS=07310689
owner: International Business Machines Corporation
number: 07310689
owner_city: Armonk
owner_country: US
publication_date: 20040414
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION","TRADEMARKS"],"p":["This patent application is a divisional application of and claims priority to commonly-assigned application No. Ser. 10\/033,810 now U.S. Pat. No. 6,754,734, titled \u201cSystems, Methods, and Computer Program Products to Improve Performance of Ported Applications, Such as a Database\u201d filed on Dec. 18, 2001, by David H. Goode and William E. Malloy, which is incorporated herein by reference in its entirety.","1. Field of the Invention","The present invention is directed to the field of accessing an Input\/Output (I\/O) device, such as a disk volume. It is more particularly directed to improving the performance of computer-implemented I\/O operations that are directed to disk drives and that are associated with ported computer applications, such as a database.","2. Description of the Background Art","Typically complex computer applications, such as a database, are ported to a 25 variety of computer systems. The porting process often includes special changes to the application to enable efficient and complete operation of the application on different computer systems. I\/O operations are a significant factor in the overall performance of a complex computer application. High-performance computer applications, such as a database, may issue asynchronous, direct disk  commands which are not supported on the target system. A \u201ctarget computer system\u201d as used herein refers to a computer system environment consisting of one or more specific programming languages, the application programming interfaces (APIs) available in the programming languages, and the associated file system or file systems. Therefore, changes to I\/O operations may be made during the porting of an application to ensure efficient operation of the application on the computer system. Such a computer system may include the products sold under the trademarks IBM\u00ae S\/390\u00ae (hereinafter S\/390) that includes the IBM\u00ae OS\/390\u00ae (hereinafter OS\/390) operating system and associated disk volumes.","Disk volumes are units of data storage that typically include data and the information used to access and manipulate the data. Disk volumes may be used to store a file system and information necessary to manipulate the file system. For example, when implementing database applications that may include disk  access commands for operation on the IBM OS\/390 that supports UNIX\u00ae System Services (hereinafter OS\/390 UNIX) the facilities of a hierarchical file system (HFS) may be employed. However, file systems, such as the OS\/390 UNIX HFS, may only support queued disk I\/O access and minimal I\/O caching.","I\/O caching is typically managed by either a file system or a disk controller. I\/O caching is the process of storing I\/O data in computer memory that may be accessed more quickly than the disk device. Therefore, I\/O caching may be characterized as temporary storage of data associated with disk I\/O requests in computer memory. Complex applications may implement I\/O caching services for the operation of the application, bypassing the I\/O caching facilities of the general-purpose file system.","More particularly general-purpose file systems, such as the OS\/390 UNIX HFS, may not have an I\/O caching scheme that is tailored to the characteristics of databases. For example, a file system, such as the OS\/390 UNIX HFS, may only support queued disk I\/O access commands and not direct disk I\/O access commands. Queued disk I\/O access performs its own I\/O caching features for proper operation. However, a general-purpose data caching strategy that operates with queued disk I\/O access operations may not be optimal for a given application. Therefore an application, such as a database, may perform its own cache management, bypass the file system, and directly access information on a disk. For example, a database may achieve better I\/O access performance by using direct I\/O access features, available as high-level computer language APIs on many UNIX platforms, in place of queued disk I\/O access operations.","Queued disk I\/O access commands may operate most efficiently with sequential I\/O access operations and not random I\/O access operations. Highly complex software applications, such as a database, often issue random I\/O access requests and the performance of the complex software applications may suffer if I\/O requests are serviced by queued disk I\/O, which may be designed to optimize sequential rather than random access operations. Therefore, high-performance computer applications, such as a database, may issue direct disk I\/O commands that can efficiently process random I\/O requests when accessing disk volumes. If the application being ported is written using asynchronous, direct I\/O APIs not supported on the target computer system, which is the case with the OS\/390 UNIX C Library and the OS\/390 HFS, the performance of the application may suffer because those direct I\/O commands must be rewritten as queued I\/O commands. This may be the case if the computer system is optimized for queued I\/O. Those skilled in the art will appreciate the use of sequential I\/O and random I\/O operations with respect to disk I\/O access.","A general-purpose file system may only be able to service I\/O requests synchronously. Synchronous I\/O operations typically wait for confirmation that the I\/O disk access command has completed before executing another disk I\/O access command. The delay in proceeding with subsequent disk I\/O access commands impacts application I\/O access performance. Asynchronous I\/O access commands typically enable other computer operations to proceed that would otherwise wait until the I\/O operation successfully completes. This allows I\/O operations and other computer operations to overlap and proceed in an asynchronous fashion. Consequently, asynchronous I\/O operations perform more efficiently than synchronous disk I\/O operations for certain high performance applications, such as a database. Therefore, database software applications suffer performance penalties if they are constrained to use high-level language APIs that do not support asynchronous I\/O operations, such as the OS\/390 UNIX C Run-time APIs.","In summary, complex applications, such as databases, often include specialized features that ensure that I\/O requests are properly sequenced. Typically, these features operate via direct disk I\/O operations that facilitate servicing random I\/O requests. Therefore, the application code may bypass the I\/O caching features of the general-purpose file system in favor of the specialized I\/O caching features of the application. When porting the application, limitations of the target computer system may impact the performance of the application. For instance, if a particular UNIX file system supports queued I\/O access commands directed to disk volumes and not direct I\/O access commands, unacceptably poor I\/O access performance for the application may result. Also, if a file system supports synchronous I\/O access to disk volumes and not asynchronous I\/O access, poor performance for the application may result. Further, a general-purpose file system I\/O caching scheme that is optimized for sequential I\/O requests may result in poor performance for an application, such as a database, that issues many random I\/O requests.","From the foregoing it will be apparent that there is a need to improve disk I\/O when porting a complex application that uses asynchronous, direct I\/O commands to a target computer system that does not support those commands.","The invention may be implemented as systems, methods, and computer products that improve the performance of computer-implemented I\/O operations for complex applications, such as a database, that are ported to computer systems that are not tailored to support the high-performance services that may benefit applications. Complex applications, such as a database, often manage I\/O access operations by a caching mechanism that is tailored to the needs of the application. For instance, the application I\/O caching mechanism may operate-in conjunction with direct disk I\/O operations that facilitate servicing random I\/O requests. When porting an application to a target computer system that does not support certain I\/O access APIs, I\/O performance of the application may be limited. For instance, a computer system's high-level language APIs may not support certain I\/O access features. The present invention may be implemented by introducing specialized I\/O access features that are tailored to enhance I\/O access performance for complex applications, such as a database.","For example, the present invention may be implemented so that support for queued disk I\/O access commands is augmented with support for direct disk I\/O access commands. The augmented support is contingent upon the availability in a computer system of synchronous, direct I\/O access to disk volumes. This augmented support ensures that random I\/O requests are handled optimally in addition to sequential I\/O requests by an application. The present invention may be implemented on the IBM OS\/390 that supports UNIX System Services with the HFS. More particularly, the present invention may augment facilities on the IBM OS\/390, such as the high-level language APIs, so that an application that is ported to the IBM OS\/390 UNIX System Services will operate more efficiently. OS\/390 UNIX provides support for APIs and an interactive shell interface. The OS\/390 APIs enable a user or program, such as a database, to request OS\/390 services and OS\/390 UNIX System Services. The shell interface is an execution environment that services interactive requests from users and batch requests that are included in computer programs, such as a database.","Typically, complex applications that issue direct I\/O requests may be associated with an I\/O caching mechanism that is managed by the application. When porting the application for use with a general-purpose file system that does not support direct I\/O access, performance may be degraded. An implementation of the present invention introduces the use of direct I\/O operations with applications ported for operation with general-purpose file systems that do not support direct I\/O operations. The direct I\/O operations used by the present invention and directed to disk volumes enable faster application I\/O operations than queued I\/O operations for certain complex software applications. An implementation of the present invention uses direct I\/O operations to support asynchronous I\/O access to disk volumes instead of synchronous I\/O access to disk volumes, and to optimally process random I\/O requests. Therefore, performance of disk I\/O access operations that service highly complex software applications and that are associated with porting the application to a target computer system that does not support direct I\/O operations, such as the OS\/390 UNIX HFS, is improved by the present invention over past solutions. It will be appreciated that the queued I\/O access operations and the direct I\/O access operations typically manipulate user data.","In the preferred embodiment of the present invention, the I\/O operations that may benefit from the introduced I\/O access operations are identified. More particularly, I\/O access commands in the application that are within a programmatic loop and that are asynchronous direct I\/O commands are identified. That is, the present invention identifies loops in the ordered computer code of the application that generate uninterrupted sequences of asynchronous I\/O requests for which the associated waits are not executed until after execution of the loop completes. Such uninterrupted sequences of asynchronous I\/O requests are commonly found in loops that are associated with applications that handle buffer flushing. While the preferred embodiment of the present invention operates on I\/O access commands that are within a programmatic loop, uninterrupted sequences of asynchronous I\/O requests may alternatively be located in other programmatic constructs.","The preferred embodiment then combines, by chaining, the multiple asynchronous direct I\/O requests into a much smaller number of disk I\/O requests than would otherwise be executed. Those skilled in the art will appreciate that asynchronous I\/O requests are typically not followed immediately by a wait request and may be aggressively scheduled for disk I\/O operations by techniques such as chaining.","Therefore, the preferred embodiment of the present invention operates most efficiently in a computer system that supports chaining of multiple I\/O requests into a single I\/O request, such as the OS\/390. For example, chained I\/O disk requests may be aggregated so that multiple non-contiguous blocks of four thousand ninety-six bytes of information are processed by a single, chained I\/O disk request. Execution time for characteristic test loads managed by the present invention is reduced by as much as 60 percent as compared to queued I\/O operations on the OS\/390 UNIX HFS that does not support combining multiple direct asynchronous I\/O requests.","Also, certain queued I\/O operations that occur prior to a loop are identified. That is, on UNIX systems a file may be initially opened for queued disk I\/O access then closed and reopened for direct disk I\/O access. The preferred embodiment of the present invention identifies such queued disk I\/O access operations and converts them to direct I\/O access operations where appropriate.","The preferred embodiment of the present invention also identifies a terminus point that is located subsequent to the programmatic loop. When the terminus point is reached, any remaining identified asynchronous direct I\/O requests are combined by chaining and the last, possibly partially full, block of chained I\/O requests is submitted.","In the preferred embodiment of the present invention, the I\/O access requests made by the application, which are associated with general-purpose files, are replaced with direct I\/O commands that are associated with high-performance files that support direct I\/O access. Typically, when the application program code is executed, an I\/O access request is transmitted to the general-purpose file system. In an embodiment of the present invention, application-directed I\/O access of OS\/390 UNIX HFS files via queued I\/O commands may be redirected for direct I\/O access to VSAM files. The general-purpose files may be OS\/390 UNIX HFS files and the performance files may be VSAM files. The Virtual Storage Access Method (VSAM) is an access method for direct or sequential processing of fixed-length and varying-length records on disks.","More particularly, an embodiment of the present invention may operate by use of a high-performance improvement code module that accepts lists of buffer addresses and disk addresses, data length values, and aggregation_indicator flags, and issues direct I\/O requests instead of queued I\/O requests. Without this invention, such direct I\/O requests would otherwise be converted to queued I\/O requests. For example, on the OS\/390 a database application may issue direct I\/O access requests during flushing operations in its I\/O cache. Transmission of the data associated with the VSAM file may be enabled by use of the buffer address that is the location of the data in computer memory, the disk address that is the location of the data on a disk, the data length value, and the aggregation_indicator flag. Examples of operations that transmit data to and from a file include reading from a file or writing to a file.","Additionally, the preferred embodiment maintains a \u201cperformance_name\u201d file that contains the name of the associated high-performance file which can be accessed with direct I\/O commands. For example, the performance_name file may be an OS\/390 HFS file that contains the name of an associated VSAM file. Therefore, an association is created between the OS\/390 HFS file that would have been used if direct I\/O were supported by OS\/390 HFS and the VSAM file that is used in its stead. For example, an embodiment of the present invention converts what would otherwise be the queued I\/O requests generated during execution of the application code with direct I\/O access commands that manipulate the VSAM files by associating the I\/O command directed to an OS\/390 UNIX HFS file with a direct I\/O command to the VSAM file.","While on most UNIX platforms general-purpose files support direct I\/O access, the target computer system may lack such support. By creating an association between such general-purpose files and the performance files that support direct I\/O access commands, database administrators may continue accessing some of the information about the general-purpose files while accessing a disk by direct disk I\/O access. Therefore, this reduces the amount of application program code that must be changed to accommodate the computer code introduced in the preferred embodiment of the present invention. This also maintains ease of use for the application users since the translation between the general-purpose files and the performance files is typically transparent to the user. For example by relying on the association between the general-purpose files and the performance files, the computer programs that rely on information in OS\/390 UNIX HFS files to determine characteristics of a file, such as whether the file exists, do not have to be altered to be made aware of the existence of the VSAM files.","An embodiment of the present invention improves the performance of computer-implemented I\/O operations for complex applications, such as a database. More particularly, applications which use asynchronous, direct I\/O commands that are ported to target computer systems which do not support such commands may be enhanced by the present invention to improve I\/O performance. That is, the present invention may be implemented by augmenting general-purpose I\/O access features with specialized I\/O access operations that are tailored to enhance I\/O access performance for complex applications, such as a database.","Other aspects and advantages of the present invention will become apparent from the following detailed description, taken in conjunction with the accompanying drawings, illustrating by way of example the principles of the invention.","In the following detailed description and in the several figures of the drawings, like elements are identified with like reference numerals.","As shown in the drawings and for purposes of illustration, an embodiment of the invention improves the performance of computer-implemented I\/O operations for complex applications, such as a database, that are ported to computer systems that are not tailored to support the high-performance services used by the applications.","Existing systems may not offer the APIs that provide adequate performance of disk I\/O access operations associated with complex computer applications, such as a database, that operate with tailored I\/O caching. General-purpose file systems may not provide sufficient facilities, such as the compiler run-time APIs, to accommodate the performance-related features of complex applications. For example, an application-specific I\/O caching mechanism may operate in conjunction with direct disk I\/O operations that facilitate servicing random I\/O requests, but the general-purpose file system may be unable to accommodate the tailored I\/O caching mechanism of the application. When porting the application to a computer system that does not take advantage of application I\/O caching or support direct I\/O access, I\/O performance of the application may be limited. The present invention may be implemented by substituting I\/O access facilities of a particular file system with I\/O access features that are tailored to enhance I\/O access performance for complex applications, such as a database.","For example, complex software that is ported to OS\/390 UNIX, such as a database, which uses direct I\/O interfaces available in other UNIX environments, will not be able to bypass the inefficient queued I\/O access support of the OS\/390 UNIX HFS in order to use more efficient direct I\/O access operations. The present invention advantageously operates to augment queued I\/O access operations with direct I\/O access operations.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 1","b":"101"},"A complex application  that is being ported, such as a database, may incorporate at least three types of I\/O access code. The I\/O access code may be unmodified and the application  may rely on the facilities of a computer system , such as an operating system . Alternatively, the application  may modify the I\/O access code for a computer system  environment that only supports queued I\/O access, such as IBM OS\/390 UNIX. Finally, the application  may augment general-purpose I\/O access operations with customized direct I\/O access operations that take advantage of any I\/O interfaces that may be provided by the computer system  and that may enhance I\/O performance of the application . It is assumed that a complex application  manages serialization of I\/O requests  in a thread-safe manner. The preferred embodiment of the present invention optimizes I\/O requests  for complex applications  that have already taken on the burden of managing serialization and have, for the files  associated with these I\/O requests , abandoned the I\/O caching scheme typically available via the general-purpose file system . Such a general-purpose file system  may be optimized to support queued I\/O. Those skilled in the art will appreciate that applications  developed for operation on other operating systems  which support application-level I\/O caching and that use direct, asynchronous I\/O, will incorporate program code that performs such serialization. The terms \u201cI\/O request\u201d and \u201cI\/O command\u201d will be used interchangeably herein.","Data sets , or files, that may be associated with application program code , are typically stored by allocating the files  to disk volumes  that reside on particular disks . Applications  are generally able to perform I\/O access operations to data sets  without having much detail about the underlying disk system . A complex application  that manages its own I\/O caching may manage disk I\/O directly. More particularly, the preferred embodiment of the present invention performs I\/O access operations that access a particular disk volume  and data set . It will be appreciated that a user interface  may include user input  or batch input  that may be accepted by the application  and manage data sets  that will support the use of direct I\/O requests . A \u201cdata set\u201d is a file that is a named set of records that are typically used in a database and that are stored or processed as a unit. The terms \u201cdata set\u201d and \u201cfile\u201d will be used interchangeably herein.","When a complex application , which uses asynchronous, direct I\/O commands is ported to a target computer system  that does not support those commands, I\/O performance may be degraded. Therefore, the high-performance improvement code module  advantageously introduces disk I\/O access operations that support the tailored I\/O operations of the complex application . For example, an embodiment of the high-performance improvement code module  does not rely on the queued I\/O access commands  that are typically performed by OS\/390 UNIX but introduces support for direct I\/O access commands  associated with VSAM data sets.","The present invention typically operates in conjunction with an application  that includes a system-dependent code module  that isolates the features that are specific to the target computer system  to facilitate, among other things, the management of I\/O access to a disk device . That is, the application program code  may make general requests to the system-dependent code module  that translates those requests so that they may be processed by the target computer system . Typically the system-dependent code module  will pass I\/O requests  to a general-purpose file system . The general-purpose file system  may simplify I\/O requests  for an operating system  by providing an interface to read and write user data  on a disk . This simplifies the translation of I\/O requests  from the file system , such as those from OS\/390 UNIX HFS, so that an operating system , such as OS\/390 UNIX, may communicate with the disk .","The system-dependent code module  isolates system-specific code to a system-dependent layer. Therefore, when porting a database management tool or other application  to another operation system , such as porting a database from an AIX\u00ae operation system to OS\/390 UNIX, the changes may be isolated to the system-dependent code module . It will be appreciated that the present invention may operate without support of the system-dependent code module  or the low-level direct I\/O interface , of the I\/O subsystem  and may interface directly with the disk volume .","The present invention advantageously operates by use of the high-performance improvement code module  that introduces support for direct I\/O requests . For example, OS\/390 supports direct I\/O requests  to files  while OS\/390 UNIX does not. Therefore applications  that are ported from other UNIX platforms to OS\/390 UNIX may suffer performance degradation if the applications  rely on direct I\/O commands  for optimal I\/O performance. An embodiment of the present invention introduces I\/O operations that support direct I\/O requests  in the absence of such support in the C Run-time Library Interfaces and the underlying OS\/390 HFS file system.","More particularly, the high-performance improvement code module  operates as a component of the system-dependent code module , which receives I\/O requests  from the application program code . Then the high-performance improvement code module  processes buffer addresses  and disk addresses , data length values , and aggregation_indicator flags , that are included in the I\/O requests  of the application  and passes aggregated collections of these I\/O requests  to the low-level direct I\/O interface . The buffer address  is a location identifier for the data  while it is stored in computer memory  (as shown in ). The disk address  is a location identifier for the data  while it is stored on a disk . The data length value  indicates the amount of space the data  requires. The aggregation_indicator flag  indicates that the I\/O request  for data  transmission should be aggregated. More particularly, the high-performance improvement code module  passes information to the low-level direct I\/O interface  that is translated into a form that is suitable for processing by the low-level direct I\/O interface , and that preserves the high-performance characteristics of the I\/O request  as generated by the application . The low-level direct I\/O interface  then transmits the I\/O requests  via the I\/O subsystem  for transmission of the data  to the disk .","The preferred embodiment of the present invention changes some features used in disk I\/O access. For example, in the system-dependent code module , the code responsible for file open and close interfaces now checks for direct I\/O file types. Then a file  is opened or closed and any other operations necessary to support direct I\/O file opening and closing are performed according to the preferred embodiment of the present invention.","As shown in , and in element , an embodiment of the present invention advantageously uses a performance_name file  for I\/O access operations. The performance_name file  creates an association between the general-purpose files  that would typically be used to store data  and performance files  that are used by an embodiment of the present invention. In the preferred embodiment of the present invention, the I\/O access commands  that are critical to disk I\/O access performance are identified. That is, those asynchronous, direct I\/O access commands  that are associated with performance_name files , and that are located within a programmatic loop in the application  are identified. Then the identified I\/O requests  that would otherwise have to be ported as queued I\/O requests  are redirected to a performance file  using direct I\/O commands . For example, the general-purpose file  may be an OS\/390 UNIX HFS file and the performance file  may be an OS\/390 VSAM file. The present invention may also aggregate the identified I\/O access commands  by request chaining. Then the aggregated I\/O access commands  are directed to the performance file  instead of the general-purpose files .","The data  that would typically be stored on a disk drive  in a general-purpose file  is now stored on a disk drive  in a performance file . The preferred embodiment also transforms the general-purpose file , which on other computer platforms would contain application data , into a performance_name file  that contains the name of the performance file  that is used store data . Therefore, by creating an association between the general-purpose files  and the performance file , application administrators may continue accessing the data  and the information associated with the general-purpose files  via the performance_name file  without direct knowledge of the performance_file_name . Also, characteristics of the performance file , such as whether the performance file  is in use may be obtained by accessing the performance_name file  without requiring the user to know the name of the performance file .","The high-performance improvement code module  operates at the behest of the system-dependent code module  to translate I\/O requests  for the low-level direct I\/O interface . The high-performance improvement code module  includes API features to facilitate its use. It will be noted that I\/O requests  that are not identified for translation by the high-performance improvement code module  are passed from the application  to the system-dependent code module  and on to the operating system  without modification. More specifically, the file system  then translates the I\/O requests  so that they may be passed on to the low-level direct  interface . The low-level direct I\/O interface  then passes I\/O requests  to the  subsystem  for transmission to the disk .","In an embodiment of the present invention, the application  cooperates with the high-performance improvement code module  to perform operations that would otherwise rely on UNIX mount point information. That is, the high-performance improvement code module performs operations using \u201cpseudo UNIX mount point information\u201d . When a general-purpose file  is created, a performance file  is obtained and the corresponding performance_name file  is created. The performance_name file  contains a performance_file_name , here the name of the performance file . Therefore, the performance_name file  associates the general-purpose file  with the performance file  that is used to execute direct I\/O commands .","Continuing with another example, when a performance_name file , such as an OS\/390 UNIX HFS file, is deleted the corresponding performance file , such as a VSAM file, is marked as free. For a further example, when a performance_name file  is renamed, the corresponding performance file  does not need to be renamed and may continue to be referenced via the performance_name file . When a performance_name file  is copied, both the performance_name file  and the associated performance file  are created and are associated. All file operations must succeed on both the performance_name file  and the associated performance file  in order to consider the operation successful.","The preferred embodiment of the present invention attempts to recover from failures that occur as a result of accessing performance files . An error recovery code module  may be designated as part of the initialization and definition process associated with the high-performance improvement code module . The error recovery code module  may be driven by any abnormal event and may request a log or a data dump from the operating system . An error exit  may also be designated in conjunction with the high-performance improvement code module  that acquires control in the event of permanent I\/O access errors. Minimally, a report of the occurrence of an error may be provided. Recovery from the error may also be attempted, depending on the type of error.","The embodiment of the present invention also provides other interface features. For example, features such as initialization of asynchronous direct I\/O requests  are provided by the high-performance code module  to facilitate manipulation of performance files .",{"@attributes":{"id":"p-0055","num":"0054"},"figref":["FIG. 3","FIG. 1","FIG. 2"],"b":["302","121","302","108","108","302","208","208","121","208","121","208","208","121","208"]},"The I\/O requests  that are direct and asynchronous are located and are the identified I\/O requests . The preferred embodiment of the present invention operates on uninterrupted sequences of asynchronous I\/O requests  for which the associated waits are not executed until after the sequence is complete. Such uninterrupted sequences of asynchronous I\/O requests  are commonly generated by loops that are associated with applications , such as databases, that handle buffer flushing. The illustration of  is therefore exemplary, as uninterrupted sequences of asynchronous I\/O requests  may be located in an I\/O programmatic loop  or may alternatively be located in other programmatic constructs.","The identified I\/O requests  are aggregated, in the preferred embodiment of the present invention, into aggregated I\/O requests . The aggregated I\/O requests  are manipulated by the high-performance improvement code module  so that they may be used in operations that access performance files  that are stored on the disk . Element  is described with reference to .","The identified I\/O requests  are asynchronous and may be random, that is, referencing non-contiguous disk  locations. Typically, complex applications , such as databases, issue many random I\/O requests . The present invention may operate on I\/O requests  that are either synchronous or asynchronous and that are either random or sequential, although synchronous I\/O requests  will not be aggregated.","As the execution of the I\/O programmatic loop  proceeds, I\/O requests  are bundled into optimal groups which are submitted as single direct I\/O requests  to the low-level direct I\/O interface . When processing of the I\/O programmatic loop  is concluded, a terminus point  is reached and any remaining identified  requests  are aggregated into a final aggregated I\/O request . Then this final, aggregated I\/O request  is transmitted to the low-level direct I\/O interface  for transmission of the data  to the disk . Then the wait programmatic structure  waits for completion of the execution of the identified I\/O requests  in the I\/O programmatic loop . Although the preferred embodiment of the present invention operates to intervene in the processing of asynchronous I\/O requests  in a loop, the waits that are associated with the asynchronous I\/O requests  may be executed anywhere outside of the I\/O programmatic loop  and beyond the terminus point . Wait processing might, for example, be deferred until the buffer used in the request is actually needed. So, waits might be demand driven rather than operating in a simple loop. Elements  and  are described with reference to .","Direct I\/O requests issued by the application  outside of the I\/O programmatic loops  are passed to the low-level direct I\/O interface  immediately and without aggregation. I\/O programmatic loops  must be selected such that queued I\/O requests for a performance file  are not included in the I\/O programmatic loop . Outside of the I\/O programmatic loops  and for a given performance file , the performance file  may be opened or closed, using standard operating system APIs, for specific types of I\/O commands . In particular, a performance file  is often initially opened for queued I\/O. Then, following the issuance of a number of queued I\/O commands , the performance file  may be closed for queued I\/O, then reopened for direct I\/O processing. When a performance file  is open for queued I\/O, the preferred embodiment of the present invention receives queued I\/O commands for a performance file , translates them to direct I\/O commands  that are appropriate for the low-level direct I\/O interface , passes the translated requests to the low-level direct I\/O interface , and then waits for the direct I\/O commands  to complete.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 4","FIGS. 4A","FIG. 4A","FIG. 4B","FIG. 4C","FIG. 2"],"b":["4","4","110","210"]},"As shown in , and in the element , the I\/O access operations associated with the present invention are described. As shown in element , the preferred embodiment of the present invention identifies the ordered computer code having at least one asynchronous direct I\/O access command  and being located in an I\/O programmatic loop . An embodiment of the present invention determines files  that may benefit from direct disk I\/O access operations  by identifying filename suffixes that are typically accessed directly. Those skilled in the art will appreciate that this is one method of determining files  that may benefit from direct disk I\/O access and that other methods may be used. Elements  and  are described with reference to  and element  is described with reference to .","The preferred embodiment of the present invention includes data  that is associated with the identified I\/O commands , as shown in element . Then as shown in element , performance files  are used instead of performance_name files  to access and store the data  that is associated with the identified I\/O commands . For example and as shown in element , the performance_name file  may be an OS\/390 UNIX HFS file and the performance file  may be an OS\/390 VSAM file. Elements , , and  are described with reference to  and element  is described with reference to .","As shown in element  the preferred embodiment executes the I\/O requests  in the application . Then as shown in element , storage space, typically on a disk , is located by the identified I\/O commands . As shown in element , the disk  is directly accessed with the identified I\/O commands . Elements  and  are described with reference to .","As shown in , and in element , the method of the present invention advantageously exploits the performance characteristics of disks  that perform I\/O operations faster when given fewer I\/O requests . That is as shown in element , ordered computer code having at least one asynchronous direct I\/O access command and being located in a loop is identified. Next, in element , loops are processed in the application program code , such as database code, in which a plurality of identified I\/O requests  are executed. The loops are likely to appear in most database applications in the areas of the computer code that are responsible for moving data  from the cache memory  (as shown in ) to the .","Then the present invention combines the identified I\/O requests  into a much smaller number of aggregated I\/O requests  (as shown in ) than would otherwise be executed, as shown in element . It will be appreciated that asynchronous I\/O requests  are typically issued before previous I\/O requests  have completed. For example, asynchronous I\/O requests  are typically not followed immediately by a wait request and may be aggressively scheduled for disk I\/O operations. Therefore, the present invention takes advantage of the asynchronous I\/O requests  to combine the identified I\/O requests . Then as shown in element , a reduced total number of disk I\/O requests  are issued.","The preferred embodiment of the present invention identifies a terminus point  that is ordered in the application subsequent to the I\/O programmatic loop . When the terminus point  is reached, the last identified I\/O requests  are included in the last aggregated I\/O request , as shown in element . Then an embodiment of the present invention uses direct I\/O instead of queued I\/O to access the disk  with the aggregated I\/O commands , as shown in element .","As shown in , and in element , the method of the association between the performance_name file  and the performance file  is described. A performance_file_name  that is associated with a performance file  is identified, as shown in element . The preferred embodiment maintains a performance_name file  that contains the performance_file_name  associated with the performance file , as shown in element . Therefore, the performance_name files  are associated with the performance file  by accessing the performance_name file  having the performance_file_name , as shown in element . Characteristics of the performance file  are determined by accessing the performance_name file , as shown in element . This applies to file manipulation functions such as \u201ccopy,\u201d \u201crename,\u201d and \u201cdelete,\u201d as well as to lower-level routines that schedule I\/O requests  and process wait requests. Elements  and  are described with reference to .",{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIG. 5","FIG. 1A"],"b":["500","500","500","507","515","520","555","558","122","541","540","530","535","545","525","540","555","541","540","500","500","122","545","500","101","545"]},"The central storage , the expanded storage , and the data storage device , are storage components that store data  (as shown in ) and instructions for controlling the operation of the central processor , which may be configured as a single processor or as a plurality of processors. The central processor  executes a program  to perform the methods of the present invention, as described herein. Before processing occurs, a program  and its data  must reside in central storage . Input\/Output operations result in the transfer of information between the central storage  and the user-input device .","While the program  is indicated as loaded into the memory , it may be configured on storage media  for subsequent loading into the data storage device  or the memory  via an appropriate storage media interface . Storage media  can be any conventional storage media such as a magnetic tape or an optical storage media. Alternatively, storage media  can be another type of electronic storage, located on a remote storage system.","Generally, the computer programs  and operating systems  (as shown in ) are all tangibly embodied in a computer-readable device or media, such as the memory , the data storage device , and a computer transmission media, such as the data transmission devices , thereby making an article of manufacture, such as a computer program product, according to the invention. As such, the terms \u201ccomputer program product\u201d as used herein are intended to encompass a computer program accessible from any computer readable device or media.","Moreover, the computer programs  and operating systems  are comprised of instructions which, when read and executed by the exemplary computer system , such as the target computer system , perform the steps necessary to implement and use the present invention. Under control of the operating system , the computer programs  may be loaded from the memory , the data storage device , or the data transmission devices  into the memory  of the exemplary computer system , such as the target computer system .","The user-input device  is a device, such as a keyboard or speech recognition subsystem, for enabling a user to communicate information and command selections to the central processor . The user can observe information generated by the system  via the display  or the printer . The user-input device  may also be a mouse, track-ball, or joy stick, that allows the user to manipulate a cursor on the display  for communicating additional information and command selections to the central processor .","When operating in accordance with one embodiment of the present invention, the exemplary computer system  augments general-purpose I\/O access facilities of a computer system  with specialized I\/O access features that are tailored to enhance I\/O access performance for complex applications  (as shown in ), such as a database. The central processor  and the program  collectively operate to improve the performance of I\/O disk access. It will be appreciated that the present invention offers many advantages over prior art techniques.","The present invention is typically implemented using one or more computer programs, each of which executes under the control of an operating system  and causes the exemplary computer system , such as the computer system , to perform the desired functions as described herein. Thus, using the present specification, the invention may be implemented as a machine, process, method, system, or article of manufacture by using standard programming and engineering techniques to produce software, firmware, hardware or any combination thereof.","It should be understood that various alternatives and modifications can be devised by those skilled in the art. However, these should not be viewed as limitations upon the practice of these teachings, as those skilled in the art, when guided by the foregoing teachings, may derive other suitable characteristics of a similar or different nature. The present invention is intended to embrace all such alternatives, modifications and variances that fall within the scope of the appended claims","IBM is a trademark or registered trademark of International Business Machines Corporation in the United States and other countries.","AIX is a trademark or registered trademark of International Business Machines Corporation in the United States and other countries.","S\/390 is a trademark or registered trademark of International Business Machines Corporation in the United States and other countries.","OS\/390 is a trademark or registered trademark of International Business Machines Corporation in the United States and other countries.","UNIX is a trademark or registered trademark of Unix System Laboratories, Inc."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 4B"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 4C"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
