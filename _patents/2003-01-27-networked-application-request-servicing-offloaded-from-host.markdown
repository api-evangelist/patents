---
title: Networked application request servicing offloaded from host
abstract: Offloading application level communication functions from a host processor. The offloading apparatus can be configured as either a pre-processor or as a co-processor. An interface is provided for receiving a network message sent to the host. An engine performs processing of the network message above OSI level 4. In one embodiment, in a fast-path, a response to the message is sent back to the network without any involvement by the host, providing a complete offload. For other messages, certain pre-processing can be performed, such as parsing of a header, message authentication, and look-up of meta-data. The results of the look-up are then passed to the host with the processed header, simplifying the tasks the host needs to perform. The messages and data are transferred to the host using control and data buffers.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07596634&OS=07596634&RS=07596634
owner: 
number: 07596634
owner_city: 
owner_country: 
publication_date: 20030127
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCES TO RELATED APPLICATIONS","STATEMENT AS TO RIGHTS TO INVENTIONS MADE UNDER FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT","REFERENCE TO A \u201cSEQUENCE LISTING,\u201d A TABLE, OR A COMPUTER PROGRAM LISTING APPENDIX SUBMITTED ON A COMPACT DISK.","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["This application is a continuation-in-part of and claims priority from U.S. application Ser. No. 10\/248,029, filed Dec. 12, 2002, and also claims priority from Provisional Application Nos. 60\/437,809 and 60\/437,944, both filed on Jan. 2, 2003, all of which are incorporated herein by reference.","NOT APPLICABLE","NOT APPLICABLE","The present invention relates to offloading network communication functions from a host processor.","OSI Layers","The Open Systems Interconnection (OSI) model describes seven layers for a data communications network. This modularization allows the layers to be independently handled. When messages are sent across a network, headers for each layer encapsulate other layers and their headers. In the transmitting direction, each layer may add its own header. In the receiving direction, the appropriate header can be dealt with, then stripped off by one layer, which passes the remaining message to another layer.  illustrate these layers and the protocols and hardware that operate at each layer.","1. Physical Layer. This provides for the transmission of data, and handles the electrical and mechanical properties. A repeater functions at this layer.","2. Data Link layer. This layer controls the transmission of blocks of data between network peers over a physical link. A bridge functions at this later. Ethernet is an example protocol.","3. Network Access layer. This layer routes data from one network node to others, using routing information and performing fragmentation and reassembly as needed. Routers function at this layer. Protocols include IP, X.25 and Frame Relay.","4. Transport layer. This layer provides flow control and error control. TCP and UDP are example protocols.","5. Session layer. This layer provides for applications to synchronize and manage their dialog and data exchange.","6. Presentation layer. This provides services that interpret the meaning of the information exchanged. An example protocol is XDR (eXternal Data Representation).","7. Application layer. This layer directly serves the end user. It includes applications such as file transfer and database access. Example protocols are FTP (File Transfer Protocol), NFS (Network File System), CIFS (Common Internet File System), HTTP (Hyper Text Transfer Protocol), database query, SQL (Standard Query Language), and XML (Extensible Markup Language).","Types of Storage","There are multiple ways that data and files can be accessed over a network.  illustrates some of these.","Direct Attached Storage (DAS). Direct attached storage is the term used to describe a storage device that is directly attached to a host system. The simplest example of DAS is the internal hard drive of a server computer, though storage devices housed in an external box come under this banner as well. Other computers on a network can access the data through communications with the host, which handles the communications in addition to its other processing tasks. For example, a disk drive attached to application server  in  would be DAS.","Network Attached Storage (NAS). Network Attached Storage is a server attached to a network and dedicated to only file sharing. NAS storage can be expanded by adding more servers, each attached to the network with its own IP address. NAS  is shown attached directly to a network through Ethernet switch .","Storage Area Network (SAN). A SAN is a subnetwork of storage devices that are connected to each other and to a server, or cluster of servers, which act as an access point to the SAN for clients on a main network. SAN storage is expanded by adding more disks to the subnetwork behind the same server. Storage switch  is an example of an access point to storage devices  and  on a subnetwork accessed through storage switch . For example, switch  could include a SAN controller, and storage  could be a RAID controller which accesses a group of disk drives.","RAID (Redundant Array of Independent Disks) is a system where a group of disks are used together, with data being written across them redundantly or with error correction, providing fault tolerance that allows data recovery where one of the disks fails.","Storage Access Protocols","SCSI (Small Computer System Interface) is a parallel interface used for storage. It provides faster transmission rates than standard serial or parallel ports, and is used to connect computers to disk drives and printers. Many devices can be attached to a single SCSI port, so it is really an I\/O bus.","There are two main standard protocols for storage access over a network, both of which use SCSI.","Fibre channel (fiber with an \u2018re\u2019) interconnects storage devices allowing them to communicate at very high speeds and allowing devices to be connected over a much greater distance. SCSI commands are still used for the actual communication to the disk drives by the DAS, NAS or SAN server at the end of the fiber.","iSCSI (internet SCSI) encapsulates SCSI commands in an IP packet, allowing data to be transported to and from storage devices over a standard IP network.","Routing and Storage Access Equipment","Routers have been developed to route messages over a network to the appropriate destination. An example of a router is shown in 3COM U.S. Pat. No. 5,991,299.","Specialized network processors have been developed for the specialized flow control and routing of messages. An example of such a network processor is shown in IBM U.S. Pat. No. 6,460,120. Such a processor typically deals with the first three layers of the OSI model. A processor which accesses layers 4 and above for flow control, to make routing decisions based on quality of service, is shown in Top Layer Networks U.S. Pat. No. 6,430,184. This allows distinguishing between priority-based email and bandwidth\u2014guarantee-based multimedia.","At the destination, and at the source, of network communications, the communication is handled by an ordinary computer or server with a general purpose processor. Communication is only one of the functions handled by the processor. With the increasing demands for file access over networks, handing the communication can take an unacceptable amount of the processors time. An example structure at a host connected to a network is shown in .","Network Interface Cards (NICs) handle the layer 1 and layer 2 communication tasks for the end-point processor. NIC  is shown connected to the network for this function.","Recently developed TCP\/IP Offload Engines (TOE) have been developed to handle the layer 3 and layer 4 communications for the processor, in particular handling the TCP\/IP protocol stack. TOE  is shown in  between NIC  and host . An example is the TOE of Alacritech, Inc., such as described in U.S. Pat. No. 6,389,479.","In prior systems, the host processor would run a piece of software commonly referred to as the TCP\/IP stack. TOE systems are able to offload this at an interface which requires minimal communication with the host. The host will configure the stack, by providing information such as the domain name, broadcast address, etc. The TOE will then handle establishment of network connections, data transmission and reception, error handling, and connection tear-down when a transmission is completed. Some TOEs, such as those by Alacritech, require the host to establish the network connection, then take over from there.","As shown in , TOE deals with MAC header  and TCP-IP header , and strips them off from message . The message is then forwarded to host . In the opposite direction, a message from the host would have the TCP-IP and MAC headers added by TOE  for transmission through the network.  illustrates a number of examples of where a TOE could be placed in a network. The TOE processes up through layer 4 of the OSI protocol layers. The higher layers are not dealt with, although the categorization of data in fly-by sequencers, including session level and higher layers, is discussed in US Published Applications 2002\/0091844 and 2001\/0037406.","Protocols for Accessing Files Over a Network","Accessing files over a network is accomplished using one of a number of protocols, such as File Transfer Protocol (FTP), NFS (Network File System), introduced by Sun Microsystems for sharing files between UNIX systems, and CIFS (Common Internet File System) introduced as a PC networking standard by Microsoft. CIFS was originally known as SMB (Server Message Block).","The commands for accessing data come from Remote Procedure Calls (RPC) from a client across the network, or the NetBIOS (Network Basic Input Output System), an application programming interface (API) on the host that augments its BIOS for network operations. The RPC commands let a remote client run a command on a host across the network.","The data is organized using meta data, which is like an index system for the data. Meta data indicates where the data came from, when it was created or modified, keywords describing the data contents, etc. Meta data can be organized in an External Data Representation (XDR), a presentation layer protocol, originally developed by Sun Microsystems, that allows the exchange of information between different systems and programming languages.","One of the data structures that may be found in meta-data is inodes (index nodes), which contain information about files in UNIX systems. Inodes provide information such as user and group ownership, access mode (read, write, execute permissions), type (regular, directory, special, FIFO), table of contents to disk blocks, file size, and pointers to the data blocks.","The present invention is intended to work with any of the above types of storage, and any communication standard, such as iSCSI or Fibre Channel.","The present invention provides a method and apparatus for offloading from a host processor the servicing of incoming application level requests over a network. The offloading apparatus can be configured as either a pre-processor or as a co-processor. An interface is provided for receiving a network message sent to the host. An engine performs selected processing of the network message above OSI level 4.","In one embodiment, the application requests serviced are for data access. These can be accesses of databases, web pages, or file access (FTP, NFS, CIFS). Requests can be inspected, and those which are not for data or file access can simply be passed through to the host.","In one embodiment, in a fast-path, a response to the message is sent back to the network without any involvement by the host, providing a complete offload. For other messages, certain pre-processing can be performed, such as parsing of a header, message authentication, and look-up of meta-data. The results of the look-up are then passed to the host with the processed header, simplifying the tasks the host needs to perform. The messages and data are transferred to the host using control and data buffers.","Unlike a TOE, which doesn't need access to host data, much of application level offloading does. The invention uses a cache with a copy of the meta-data or data available to the host processor for its application level processing. This allows the application level processor to handle application level communications.","In particular, the present invention is directed to file access over a network. The invention handles both the reception and transmission of messages related to file access. The embodiments also deal with the handling of response messages from the host to the network.","In a pre-processor implementation, the pre-processor sits between the host and a TOE. The pre-processor is largely transparent to the TOE, passing its messages through to the host, so that the TOE continues to believe it is speaking directly to the host.","In one embodiment, the pre-processor sits between the host and an external CPU which has an Ethernet interface. The external CPU has the functionality of a TOE.","For further understanding of the nature and advantages of the invention, reference should be made to the following description taken in conjunction with the accompanying drawings.","Offloading from the host processor any more than the protocol processing done by the TOE devices is problematic. Since higher levels involve access to data under host control, it is undesirable to relinquish host control of the organization and handling of that meta-data.","The present invention recognizes the advantages to be gained with a pre-processor or co-processor approach which offloads standard parts of the processing completely from the host processor. In addition, for certain other operations, advanced or speculative execution of some common functions are done and passed on to the host to reduce the host processing time. This is done using a copy of the host meta-data in a cache that is kept coherent with the host cache. This avoids interfering with the host accessing of its own cache.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 5","b":["36","26","28","26","24","36","38","40","36","42"]},"A message  passed to APU  by TOE  is first examined to determine if it is the type of message the APU would handle. For example, the APU may be configured to only handle file access messages, passing other messages on to host . After doing any necessary parsing and authentication of the message header, any required look-up can be done in cache  as illustrated by arrow . After the look-up, there are two options. First, if the look-up completes the commands required by message , the return message is sent back to TOE , as illustrated by arrow . Second, if more processing is required, the looked-up data and parsed or otherwise processed header are forwarded to the host  as illustrated by arrow . For example, the host  may be required to recover data from storage . The returned messages are handled by APU  to forward them from host  back to TOE .","APU  also acts as a semi-transparent interface between TOE  and host . APU  will forward messages sent from host  to TOE  and vice versa during configuration, initializing of a session with TOE , or other needed communications. The APU can perform some processing on outbound response messages from the host where appropriate. For messages from TOE  which are not of the type handled by APU , these are simply forwarded through to host .",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 6","FIG. 6"],"b":["110","112","114","116","118","26","112","114","26","36","116","118","120","122","118"]},"The host then does any data look-up responding to commands in the message, and returns the message with an NAS return header  and response data . APU  modifies the NAS header as needed, and provides a modified NAS header  and a response data  to TOE . TOE then adds a MAC header , a TCP\/IP header  and sends the message along to the network.","In some cases, APU  generates a modified NAS header  and response data  by locally processing incoming NAS header  and associated data , without passing any processed message to the HOST .",{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 7","b":["36","28","50","52","54","36","28","56","58","60","28","54"]},"When the host processes the commands and prepares a response, it similarly places the data in data buffer  and places the response in a response buffer  in control buffer .",{"@attributes":{"id":"p-0066","num":"0065"},"figref":["FIG. 8","FIG. 5","FIG. 7"],"b":["64","26","63","65"]},{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 9","b":["1","10","66","68","70","72","6","7","74"]},"Completely offloaded messages include those where the requester simply wants to know what the meta-data is. Another example is when the data to be read is in the cache memory. Partial offload includes, for example, accessing of data in the actual final storage, whether disk drives or otherwise. In this case, a pointer to the location in storage may be contained in the cache, and this can be looked up by the processor of the present invention and passed along to the host, saving the host the pointer look-up time.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 10","b":["76","78","80","82","84"]},"A non fast-path operation could involve a cache miss, in which case the message is passed, as indicated by arrow , directly to the host for further processing. Also, if actual data in a disk array  or an SAN  is required, from step  a look-up is done to get the pointers to that data, and this is passed along to the host as indicated by arrow . The host, in step , performs any necessary meta-data accessing and processing, and does the data transfer by accessing the data in the disk array and performing the command, with data being sent back to the network as required.","In one embodiment, instead of sending the message to the host, it could be redirected anywhere on a network. Alternately, a message could be both sent to the host and redirected, or a portion could be sent to the host, and a portion redirected. The redirection can be with or without preprocessing. These messages are basically requests for information, and can be sent to more than one device to retrieve different portions of the total desired information.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":"FIG. 11","b":["99","100","101","102","105","111","107"]},"Input buffers  and output buffers  are also provided. A copy\/move unit moves data between the input buffers, FLIC engine and output buffers, and allows the FLIC engine to access memory resources such as lookup cache ","NFS Processing","The APU processor of the present invention supports both NFS V, V and CIFS protocols. NFS requests arrive as RPC messages. A connection may utilize either secure or standard RPC messages. Prior to decoding the field of the RPC, there may also be a need to change the byte ordering of the input message depending upon the byte ordering employed by the host processor. The APU also provides hardware for XDR functions.","Once the byte order for the RPC message is re-arranged so that it is compatible with the order assumed for processing in the APU, the APU determines whether the RPC message is a secured RPC message. In case secure RPC messaging is being utilized, prior to NFS fields extraction, the RPC message authentication is performed. The APU utilizes an external security processor, or the external general purpose processor. The external processor may be connected through a dedicated optional system bus or through a shared system bus. An external security co-processor may be connected through a dedicated co-processor bus, or a PCI-X bus.","After the RPC message has been authenticated, a flexible hardware extraction unit scans the RPC header to determine whether the request is a NFS request. If not, the request is ignored, and no processing is done, and it is passed on to the host. If the request corresponds to an NFS request, a combination of hardware and software (running on the embedded processor) does the mapping of the NFS request to the Virtual File System (VFS) call.","NFS V is stateless. The NFS V processing does not involve examining any data-structures associated with the connection on which the request arrives. Also, for NFS V there is only one NFS request per RPC message.","NFS V has states. Also, one RPC message may carry compound requests. In case of compound requests, the requests are parsed and processed, one at a time.","CIFS Processing","CIFS requests are received as SMB messages. Some of the messages are passed on to the host processor without processing, and others, which involve File System access, are converted to a VFS interface.","HTTP Processing","The APU receives HTTP messages as over TCP. Again, a combination of hardware and software performs the function of mapping a HTTP request to VFS.","In case a secure HTTP request is received, the message is first passed to an external SSL co-processor. The decoded message is then processed by the APU.","Generalized Look-Up","For all file access oriented protocols, the first stage of the APU extracts the parameters of the request, and creates a Virtual File System (VFS) interface request. Several of the FS requests involve accessing a meta-data cache to either determine the pointer to some internal data structure or to have access to the final attributes. The APU provides the hardware implementation of the generalized meta-data cache. Appropriate mechanisms are provided to ensure that the data in the generalized meta-data cache are coherent with respect to the software view of them the File system running on the host processor. The APU performs the meta-data look-up part of the VFS call in advance. This scheme is referred to as the Advance Generalized Look-up scheme. The result of the look-up, and the pointer to a validity flag for the result, is then sent along with the VFS call to the file system running on the host processor. This can be applied to other protocols as well, such as database and XML protocols.","A generalized look-up is also used to provide mapping of file pointers to the block of data in the block-cache.","Note that the generalized look-up structure can also be accessed in a co-processor model as well. In this case access is in a synchronous mode from the host processor.","Selective Early Completion","In certain cases, the file system network request only comprises reading a meta-data pointer or some file attributes. The requests that only require a cache look-up, and are read-only, are completed by the pre-processor without the need to go to the host processor. There are mechanisms in place to ensure consistency\/coherency of the read data with respect to other operations executing on the host processor.","The specialized process of the present invention only needs a subset of the type of commands needed by a general purpose processor. In particular, it needs instructions related to copying and moving data, as well as doing look-ups. It also needs to be able to do ALU and branch operations, as well as locking and unlocking of blocks of data to avoid conflicts with other processors trying to access the same data.","Software Models and Logical Flow",{"@attributes":{"id":"p-0087","num":"0086"},"figref":"FIG. 12","b":["118","110","1","112","2","114","116","3","3","4","120","4","4"]},{"@attributes":{"id":"p-0088","num":"0087"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0089","num":"0088"},"figref":"FIG. 13","b":["122","124","126","1","2","1","128","130","132","124","134","136","138","138","140","126"]},"In one embodiment, path  is used to pass through packets not belonging to NAS protocols. The packet headers are examined, and if they do not belong to an NAS protocol, they are passed through.","Path  is used for NAS request acceleration. At host , file systems  communicate through NAS lite layer  and FAP driver . FAP  similarly uses FAP host driver  and an FAP microengine , which then communicates with PE FAP socket  and TOE\/Ethernet driver .",{"@attributes":{"id":"p-0092","num":"0091"},"figref":["FIG. 14","FIG. 14","FIG. 13"],"b":["1","2","136","124","1","124","144","146","134","136","138"]},"As can be seen from the diagrams of , the socket layer is stretched, or split, into two parts, part on the host and part on the FAP .","PE  receives TCP processed network packets from TOE  at the socket layer, PE  classifies these into\n\n","PE  passes above classified packets to FAP through two different FAP registers HOST_SOCK_DMA_REG and PE_RCV_BUF_REG respectively. Packets sent to FAP take three paths in the FAP\n\n","The next three figures show above scenarios.","Non NAS Packet Receive",{"@attributes":{"id":"p-0097","num":"0101"},"figref":["FIG. 15","FIG. 15"],"b":["136","150","152","1","1","154","156","124","158"]},"An acknowledgement is then generated in steps 3, 4 and 5. The acknowledgement is formed in a register  and then pushed into a DMA acknowledgement register  along with length LEN . Register  is pointed to by a FIFO buffer , while DMA acknowledgement register  is pointed to by a FIFO buffer . A summary of the steps of  is set forth below:\n\n",{"@attributes":{"id":"p-0099","num":"0108"},"figref":"FIG. 16","b":["122","136","2","2","124","166","168","124","170","1","150","136","2","166","1"]},"The acknowledgement is then generated through steps 3, 4 and 5 similarly to as shown in , using FIFO , register , register  and FIFO .","FAP  then allocates a local SRAM transmit buffer , in this example ST. The FAP micro engine , labeled \u201ccontext 1\u201d in , then partially process the NAS packet using microcode and forms a packet to be transmitted to the host which is put in the ST buffer in step 7.","In steps 8 and 9, the partially processed NAS request is DMAed to host  using a host DMA register queue  and a FIFO buffer pointer  to one of NAS receive buffers  in host .","A summary of the steps executed in  is set forth below.\n\n",{"@attributes":{"id":"p-0104","num":"0122"},"figref":["FIG. 17","FIG. 17","FIG. 16","FIG. 17"],"b":["124","180","182","122","184"]},"1. PE passes address, PR, and length, len, of the received NAS packet to FAP through PE_RCV_BUF_REC\n\n",{"@attributes":{"id":"p-0106","num":"0132"},"figref":"FIGS. 18 and 19","b":"124","ul":{"@attributes":{"id":"ul0011","list-style":"none"},"li":{"@attributes":{"id":"ul0011-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0012","list-style":"none"},"li":["1. Non-NAS related packets","2. NAS responses\n\nNon NAS Packet Transmit\n"]}}}},{"@attributes":{"id":"p-0107","num":"0135"},"figref":"FIG. 18","b":["186","124","1","1","1","188","136","190","192","136"]},"In one embodiment, an acknowledgement packet to host  is accomplished using an acknowledge buffer FIFO , a local response buffer , host acknowledge DMA register  and host acknowledge buffer FIFO  to provide an acknowledge back to acknowledge buffer  of host . In another embodiment, the acknowledgement packet may be generated by the PE. A summary of the steps performed in  is set forth below.\n\n","There are two ways in which an NAS response can be formed.\n\n","The first category above is covered above in , NAS Request Early Termination. The second category is covered in .","As shown in , host  generates a command with a NAS response packet and sends it to FAP  using NAS command buffer register . FAP allocates SRAM receive buffer  and receives the command through a DMA, then the command in SRAM receive buffer  is operated on by micro engine . FAP also allocates a local SRAM transmit buffer , which is used by the micro engine to generate the NAS response. FAP provides a DMA write of the NAS response in SRAM transmit buffer  to NAS transmit buffers  of PE  using PE_NAS_DMA register  and FIFO buffer . The receive and transmit SRAM memory are pointed to by receive FIFO buffer  and transmit FIFO buffer . The acknowledge is done in the same manner as described in  above.","Set forth below is a summary of the steps followed.\n\n","Commands flow from:\n\n","The targets of the commands are:\n\n","The host expects a response for each of the commands it issues. The responses could be:\n\n","Many commands don't need explicit responses from the targets. Only the host needs to know that the commands are copied into FAP\/PE memories before it can reclaim the command buffers. The FAP hardware acts like a proxy and forms and sends responses to those commands as soon as the DMA of the command is done.","The host knows when it expects a proxy response and when it needs target responses, which indicate completion of the commands. The host conveys this to the FAP through the Command ID, CID. The command header in the command always contains a valid CID. The host, when passing a command, could write a real CID or a 0 (zero) along with the command address and length into FAP command registers.\n\n","For case 1, refer to , which illustrate two examples in which responses are auto generated by an FAP proxy.","For case 2, scatter gather is a good example.","Scatter\/gather is a technique used to do DMA data transfers of data that is written to non-contiguous areas of memory. A scatter\/gather list can be a list of vectors, each of which gives the location and length of one segment in the overall read or write request.","Scatter Gather Write","A scatter\/gather write operation is illustrated in . The following is a summary of the logic flow of :\n\n",{"@attributes":{"id":"p-0122","num":"0180"},"figref":["FIG. 21","FIG. 21"],"ul":{"@attributes":{"id":"ul0029","list-style":"none"},"li":{"@attributes":{"id":"ul0029-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0030","list-style":"none"},"li":["1. Host forms a command along with a NAS READ response packet containing scatter gather list and sends it to FAP by writing the address, HT, length, len, and 0 as CID, of the packet to a FAP register, HF_NAS_CMD_BUF_REG. (CID \u20180\u2019 is used to indicate the acknowledgement will come from the target, PE)","2. FAP DMAes host command along with the transmit packet from host memory, HT, to a local SRAM receive buffer, SR, obtained from sram_rcv_buf_fifo.","3. FAP allocates a local SRAM transmit buffer, ST, from sram_tr_buf_fifo and injects the NAS packet in SR along with transmit buffer ST into micro engine, Context 1","4. Microcode processes the NAS response packet for XDR and forms a response packet in ST buffer along with scatter gather list","5. Microcode sets up a DMA of the NAS response by pushing the address, ST and length, len, of the packet into PE DMA queue, PE_NAS_DMA_REG","6. FAP gets a PE NAS buffer, PN, from pe_nas_buf_fifo and DMAes the packet from FAP SRAM memory, ST, to PE memory, PN. The PE is interrupted (not shown in the figure)","7. PE passes the list to TOE and TOE uses the scatter gather buffers. PE sends the completion of command, CID and the status of the execution, status to FAP through a register, PE_HF_ACK_REG, write","8. FAP forms an ack to the command in a local ack buffer, LA, obtained from lack_buf_fifo","9. FAP sets up a DMA in HF_ACK_DMA_REG to send the ack in LA to the host","10. FAP obtains a host ack buffer HAS, from hf_ack_buf_fifo and DMAes the response in LA into host memory HAS. Host is interrupted (not shown in the picture)\n\nControl Traffic\n"]}}}},"Control traffic between Host and PE follow a similar path as non-NAS packets take as in , Non NAS Packet Transmit, for Host to PE communication, and , Non NAS related packet receive, for PE to Host communications.","Though the flow path is the same, they go through different registers, buffer pools and fifos, all of which contain higher priority than the non-NAS traffic counter part. For control packet flow from host to PE, the following set is used (refer to  for comparison)\n\n","For control packets flow from PE to host following set is used (refer to  for comparison)\n\n","Some TOES work without scatter gather for data transfers. FAP also handles this scenario in one embodiment. The FAP can support scatter gather even if the TOE does not.","There is no difference in the flow for READ requests. Since WRITE requests may need to buffer large amounts of data to simulate scatter gather, a different mechanism is used.","The write header goes through the same path as before. All the data buffers, even though they belong to NAS, take a path similar to non-NAS packets, but use different registers, buffers pools and fifos. Write data uses the following register (refer to  Non NAS related packet receive for reference)\n\n","The interrupt mechanism on FAP is managed by ISR, IRR and ICR registers. There are two sets of interrupt registers on FAP each one managing follow two categories respectively:\n\n","FAP uses FE_ISR register to keep the status of any interrupts to PE. FAP uses PE_IMR to mask off any interrupts to PE. The PE interrupt line is kept high as long as any bits in PE_ISR are set which are not masked by PE_IMR register. The PE_ICR register is used by the host to clear any interrupts.","FAP maintains a group of FIFOs to handle communications between PE and FAP. PE_ISR bits are set.\n\n","PE_ISR may be cleared whenever above conditions are not present or cleared explicitly by the PE.","FAP and Host Interrupts","FAP uses HF_ISR register to keep the status of any interrupts to host. FAP uses HF_IRR to mask off any interrupts to host. The host interrupt line is kept high as long as any bits in HF_ISR are set which are not masked by HF_TRR register. FAP keeps a shadow copy of HF_ISR on the host. HF_ICR register is used by host to clear any interrupts.","HF_ISR bits are set if any DMA is done to the host or an exceptions condition happened on the FAP like FIFO overflow or underflow.","As will be understood by those with skill in the art, the present invention may be embodied in other specific forms without departing from the essential characteristics thereof. For example, the data control buffers could be in SRAM, DRAM, or even in the on-board cache of the host processor. The specialized processor could be either a pre-processor, or a co-processor. The processor of the invention could be integrated on the same semiconductor chip as the TOE, or as the host. Alternately, the processor could be integrated with a memory controller or any other device. Instead of having a duplicate cache, a dual-ported single cache could be shared by the host and the processor of this invention. Accordingly, the foregoing description is intended to be illustrative, but not limiting, of the scope of the invention which is set forth in the following claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIGS. 1 and 2"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 6","FIG. 5"]},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIGS. 13 and 14"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIGS. 15-21"}]},"DETDESC":[{},{}]}
