---
title: Haptic messaging in handheld communication devices
abstract: providing a control signal associated with the contact to an actuator coupled to the handheld communication device, the control signal being configured to cause the actuator to output a haptic effect associated with the input signal.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08316166&OS=08316166&RS=08316166
owner: Immersion Corporation
number: 08316166
owner_city: San Jose
owner_country: US
publication_date: 20031208
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","FIELD OF THE INVENTION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application claims priority based upon to U.S. Provisional Patent Application Ser. No. 60\/431,662, filed on Dec. 8, 2002, the entire disclosure of which is incorporated herein by reference. This application also claims priority under the Patent Cooperation Treaty based upon co-pending PCT application no. PCT\/US03\/38900 filed Dec. 8, 2003.","This invention relates generally to haptic-feedback systems. More specifically, embodiments of the present invention relate to using customized haptic effects in a variety of applications to convey information to users of handheld communication devices.","As handheld communication devices become part of everyday life, device manufactures and service providers strive to enhance the versatility and performance of such devices.","Handheld communication devices in the art (e.g., mobile phones, pagers, personal digital assistants (PDAs), etc.) typically use auditory and visual cues to alert a user when incoming messages, such as voice calls and emails, are received. Such auditory and visual alerts, however, have the disadvantages of being distracting in some situations (e.g., during driving), or annoying in others (e.g., during a meeting or a concert). Although vibratory alerts are made available in some communication devices such as cellular phones, such vibratory effects cannot be customized or personalized according to applications, thus conveying little information to the user. A need, therefore, exists in the art for a new sensory modality that delivers information to users of handheld communication devices in a personalized fashion.","Embodiments of the invention relate to methods and systems for providing customized \u201chaptic messaging\u201d to users of handheld communication devices in a variety of applications.","In one embodiment, a method of haptic messaging includes: receiving an input signal associated with an actuation of a user-interface member; determining a haptic code associated with the actuation; and including the haptic code in an output signal to be sent to a remote handheld communication device.","In another embodiment, a method of haptic messaging includes: receiving an input signal; outputting a request relating to a contact with a user-interface member coupled to a handheld communication device; and providing a control signal associated with the contact to an actuator coupled to the handheld communication device, the control signal being configured to cause the actuator to output a haptic effect associated with the input signal.","Further details and advantages of embodiments of the invention are set forth below.","Embodiments described in the following description are provided by way of example to illustrate some general principles of the invention, and should not be construed as limiting the scope of the invention in any manner. One skilled in the art would also recognize that various changes and modifications can be made herein, without departing from the principles and scope of the invention.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 1","b":"100"},"Device  includes a device body including a housing  and a user-interface ; a processor ; at least one actuator  in communication with processor ; and a memory  in communication with processor . Device  also includes an antenna  and a transceiver , in communication with processor . Device  additionally includes a display module  and an audio module , in communication with processor . Display module  may include, for example, a liquid crystal device. Audio means  may include, for example, a speaker, a microphone, and the like.","For purpose of illustration in the embodiment of , processor , actuator , and memory  are shown to be enclosed within and coupled to the device body. Such an illustration, however, should not be construed as limiting the scope of the invention in any manner. In alternative embodiments, actuator  may, for example, be coupled to the outside of housing , or embedded in housing  via a suitable mechanism. Further, user-interface  may include one or more user-interface members. As used herein, a user-interface member includes, without limitation, a key pad having one or more keys, one or more buttons, a touch screen or touch pad, a scroll wheel, a direction pad, a trackball, a knob, a miniature joystick, or other user-interface means known in the art.","Device  further includes an API (Application Program Interface) , working in conjunction with an operating system . A device driver (not shown) may optionally provide an interface between operating system  and processor .","Memory  of device  stores a program code that includes instructions to cause processor  to perform various tasks. The following description provides some examples.",{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 2","FIG. 1"],"b":["200","210","220","230"]},"Furthermore at step , a collection of haptic effects is provided, each haptic effect being associated with a control signal. For example, memory  of  can store a program code that includes instructions to generate the control signals (e.g., each characterized by a distinct waveform) for rendering the corresponding haptic effects. Haptic effects (along with associated control signals) may also be downloaded or transmitted from a remote source, such as a service provider, a network resource, a Web server, a remote handheld communication device or computer. Such downloaded or transmitted haptic effects can be further edited or modified. At step , a mapping between an event of interest and one of the stored haptic effects is received. By way of example, memory  of  may also store a program code that enables a user to map an event of interest to one of the haptic effects as provided, e.g., via user-interface  through API , where the event may be identified by its source. At step , the one-to-one mappings made between various events of interest and the corresponding haptic effects are compiled into a haptic lookup table, which can, for example, be stored in memory  of .","In the embodiment of , the term \u201cselecting\u201d includes, without limitation, looking up a predetermined mapping between the event of interest and a corresponding haptic effect based on the source determination, and selecting\/generating a control signal that is configured to render the desired haptic effect associated with the event (e.g., upon being applied to an actuator). Selection can be made based upon the aforementioned haptic lookup table, for example.","In one embodiment, the input signal may include a communication signal associated with a call event, such as a voice call, an e-mail, or a message in text or multimedia form, which may be received via antenna  and transceiver  of , for example. The \u201csource\u201d of a call event may be related to a characteristic that distinctly identifies or characterizes the call event, such as the caller's phone number, the sender's e-mail address, a graphical feature or an icon associated with the incoming message, etc.","In another embodiment, the input signal may be associated with a reminder event, which may be a self-generated message on the handheld communication device serving as a reminder for a pre-scheduled activity (e.g., an appointment or a meeting). The source in this scenario may be associated with the type of a pre-scheduled activity (e.g., a business meeting vs. a restaurant reservation), or the time at which the pre-scheduled activity takes place.","In yet another embodiment, the input signal may include a communication signal associated with a status event, for example, received via antenna  and transceiver  of . Examples of a status event include, but are not limited to: an advertisement (e.g., sale) event, a one-to-one marketing event, a business-transaction event, a stock-trading event, a weather-forecast event, a sports (or game) event, an entertainment event, and an emergency (e.g., 911) event. In this scenario, the source may be associated with a characteristic that distinctly identifies the sender and\/or the nature of a status event, such as the phone number of the handheld user's stock broker, the e-mail address of the user's favorite store, the logo associated with the user's favorite TV or radio station, and so on.","In one embodiment, an event of interest can be accompanied by a distinct haptic effect, or overlapping haptic effects, conveying to the user customized information such as \u201cwho is calling,\u201d \u201cwhat is happening,\u201d and so on. The user can also be allowed to update the haptic lookup table, e.g., to include new events, and\/or to modify the mappings between the existing events of interest and the corresponding haptic effects.","Moreover, a specific haptic effect can be assigned to any incoming signal event whose source is unknown, so as to alert the user that the incoming message is from an un-identifiable or sender.","As used herein, the term \u201chandheld communication device\u201d includes, without limitation, a mobile phone such as a cellular phone or a satellite phone, a personal digital assistant (PDA), a cordless telephone, a pager, a two-way radio, a handheld or portable computer, a game console controller, a personal gaming device, an MP3 player, or other personal electronic devices known in the art that are equipped with communication or networking capabilities.","In one embodiment, the aforementioned haptic effects can be used as haptic ringers (e.g., counterparts to auditory ring tones) that are customized or personalized to convey information to the user about various events of interest. By way of example, a haptic ringer associated with a call from a loved one (e.g., the user's spouse) may comprise low-amplitude and high frequency vibrations that impart gentle sensations to the user. In contrast, a haptic ringer associated with an emergency event (such as a 911-call) may comprise jolt-like pulses that impart pounding sensations to the user.","In contrast with conventional auditory ring tones, the aforementioned haptic effects (e.g., haptic ringers) are more desirable in an environment where extraneous auditory signals are prohibited (e.g., during a meeting or a concert), and\/or where it is difficult to distinguish auditory signals (e.g., in a loud environment such as an airport). The haptic ringers are also more suitable in distracting situations such as driving, so that the user of a handheld communication device can keep eyes on the road without having to look at the device. Moreover, such haptic ringers convey customized information to the user, so that the user is aware of \u201cwho is calling,\u201d \u201cwhat is happening,\u201d and so on, as the following examples further illustrate.","A handheld communication device such as a mobile phone may be configured to allow a user to include haptic information or a haptic code in an outgoing communication signal, e.g., carrying a voice call, an e-mail, or a message. The encoding of a communication signal with haptic information may be based on an established scheme or protocol, and\/or on a per-system basis. The haptic code is configured to cause a haptic effect to be output when the communication signal is delivered to another handheld communication device. In one embodiment, businesses and organizations may each be associated with a distinct haptic logo (e.g., a particular vibration pattern) and include their haptic logos in various messages sent to the handheld communication devices of their customers. Such haptic logos can serve as counterparts to conventional logos known in the art, for example. Various status events mentioned above may also be transmitted in this manner. By way of example, a merchant may include its haptic logo in various advertisement events and business transaction events to be transmitted to the handheld communication devices of its customers. Stock brokers (or brokerage firms), TV or radio stations, and marketing\/advertising agencies may likewise include their haptic logos in various stock-trading events, weather-forecast events, sports events, entertainment events, and one-to-one marketing events to be transmitted to the handheld users.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 3","b":["300","310","320","330","330"]},"In one embodiment, the extracted haptic code may be directly applied to the actuator for rendering the desired haptic effect. In another embodiment, the haptic code may be configured according to a predetermined scheme or protocol that includes, for example, a table of haptic codes (some of which may be associated with one or more haptic logos) versus control signals for rendering the corresponding haptic effects. In this way, a processor in the handheld communication device can look up the corresponding control signal from the table based on the extracted haptic code, and output the selected control signal to the actuator for rendering the desired haptic effect.","In the embodiments of  or , the handheld communication device (or the haptic code) may be programmed such that the haptic effect is output immediately, or at a prescribed time after receiving the input signal, as desired in applications. The haptic effects can also be triggered by, or synchronized with, other occurrences.","A handheld communication device may be further configured such that some of its user-interface members (such as those described above) are each associated with a haptic code, e.g., according to a predetermined scheme or protocol. In one embodiment, some of these haptic codes may be associated with haptic effects that emulate expressions or behaviors, such as \u201claugh,\u201d \u201cgiggle,\u201d \u201chug,\u201d \u201chigh-five,\u201d \u201cheartbeat,\u201d \u201cpet purring,\u201d etc. This allows haptic effects to be transmitted and experienced, e.g., in an interactive conversation or a chat session, by pressing or manipulating such members.","By way of example, suppose that user A (termed \u201cAlice\u201d herein) is engaged in a chat session with user B (termed \u201cBob\u201d herein) via their respective mobile phones. In one embodiment, when Bob tells Alice a joke, Alice can respond by sending a \u201claugh\u201d sensation to Bob, e.g., by pressing a key on her mobile phone that is assigned with a haptic code corresponding to a laugh sensation. This causes a signal to be transmitted from Alice's phone to Bob's phone, and a corresponding haptic effect to be output to Bob's phone (and thereby experienced by Bob). In alternative embodiments, Alice can include a haptic code in an outgoing message (which may also contain a video image such as a picture taken by her mobile phone, and\/or a graphical feature such as an emoticon emulating a smiley face) to be transmitted to Bob, e.g., by pressing the corresponding user-interface member. The haptic code causes a haptic effect to be output when the message is delivered to a remote device such as Bob's mobile phone. In one embodiment, the haptic effect may be correlated or synchronized with the displaying of a video image contained in the message. In another embodiment, the generation of the haptic effect based on the haptic code may be carried out in a manner similar to that described above with respect to the embodiment of .",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 4","b":["400","410","420","430"]},"A handheld communication device may also be configured such that a haptic effect, along with a message, is output upon a contact with a user-interface member being made (e.g., by a user or an input device).  depicts a flowchart  illustrating a method of haptic message that can be associated with this situation, according to an embodiment of the invention. At step  of the flowchart , a handheld communication device receives an input signal. At step , the handheld communication device outputs a request for a contact with a user-interface member coupled to the handheld communication device. At step , the handheld communication device provides a control signal associated with the contact to an actuator coupled to the handheld communication device. The control signal is configured to cause the actuator to output a haptic effect associated with the input signal. Step  may include having a visual effect displayed, an auditory effect played, and\/or a distinctive haptic ringer output, which requests a contact with the user-interface member being made.","In one embodiment, the input signal in  may include a haptic code, along with a message, a video image, and\/or a graphical feature, etc. For example, the haptic code may be configured to cause a \u201chug\u201d sensation to be output when the video image contained in the input signal is displayed. The input signal may also contain a provision or protocol that specifies that the incoming message along with the corresponding haptic effect is output upon a contact with a particular user-interface member (e.g., the #5 key) being made. Alternatively, the handheld communication device may determine the user-interface member to be contacted, before outputting incoming message along with the corresponding haptic effect.","In another embodiment, the input signal of  may be associated with a \u201cvirtual touch,\u201d e.g., to mimic a handshake, a \u201chigh-five,\u201d a pat on the back, a pulse or heartbeat sensation, a pet purring sensation, or other touch sensations associated with human (and\/or human-animal) interactions. In one scenario, the input signal at step  may include a \u201cvirtual touch indicator,\u201d based on which the request for a contact with a particular user-interface member is made. The virtual touch indicator may be in the form of a haptic code, a message, or other informative means. The control signal at step  may be generated, e.g., based on the virtual touch indicator, a haptic code associated with the user-interface member at play, or other predetermined scheme. The input signal at step  may also include a virtual touch indicator along with a virtual touch signal for rendering the desired haptic effect. In this case, the control signal at step  may be based on the virtual touch signal.","Referring back to the chat session between Alice and Bob, by way of example at the end of their chat session, Alice may wish to send Bob a \u201chigh-five.\u201d She sends to Bob's mobile phone a signal including a virtual touch indicator, which in turn prompts a request that Bob be in contact with a user-interface member coupled to his phone, such as a direction pad (e.g., by putting his fingers on the individual keys of the direction pad), a key pad, a touch screen, a trackball, a joystick, or the like. The control signal for rendering a haptic effect that emulates a \u201chigh-five\u201d may be based on the haptic code associated with the user-interface member, transmitted with the input signal from Alice, and\/or other predetermined scheme.","Interactive virtual touch can also be engaged between users of handheld communication devices, where the manipulation of a user-interface member on one handheld communication device is transmitted possibly in substantially real-time to another handheld device and experienced by its user, and vice versa.  depicts a flowchart  illustrating a method of providing interactive virtual touch in one embodiment of the present invention. In the embodiment shown, a handheld communication device first receives an input signal including a virtual touch indicator at step . A distinctive haptic ringer may, for example, accompany the arrival of the virtual touch indicator, identifying the sender and the nature of the input signal. The handheld communication device may then perform any necessary initialization to enable the communication at step , which may also include requesting a contact with a particular user-interface member coupled to the handheld communication device at step . The handheld communication device subsequently receives a virtual touch signal in the communication associated with the desired haptic effect at step . The handheld communication device provides the haptic effect at step , e.g., by applying the virtual touch signal to an actuator coupled to the user-interface member.","In one embodiment, the virtual touch signal may be associated with the manipulation of a user-interface member on a remote handheld device and transmitted in substantially real-time. And the user on the receiving end may respond by acting in a similar fashion, so as to emulate an interactive touch. Any schemes for delivering virtual touch to users of handheld communication devices may be used.","Haptic effects can also be used to enhance and complement the information content communicated between handheld communication devices. In one embodiment, a plurality of handheld communication users may be engaged in a chat session via their handheld communication devices. The users may each have a graphical representation or avatar displayed on other handheld communication devices. Such avatars can also be haptically enabled, for example, whereby their expressions and\/or behaviors are accompanied and enhanced by corresponding haptic effects.  is a flowchart  depicting a method of carrying out a chat session using handheld communication devices, according to an embodiment of the invention. In the embodiment shown, a handheld communication device receives an input signal associated with a chat message at step . The handheld communication device displays an avatar associated with the chat message at step . The avatar may be shown on display  of , in one embodiment. At step , the handheld communication device provides a haptic effect associated with the chat message. Step  may include outputting a control signal to an actuator coupled to the handheld communication device, where the control signal is configured to cause the actuator to output the haptic effect. In one embodiment, the haptic effect may be correlated with an expression or behavior of the avatar, such as a laugh or giggle, a cry, a pet purring, or the like.","Handheld communication devices are increasingly equipped with navigation capability, for example, in communication with the Global Position System (GPS) or other navigation systems. Haptic effects can also be used to convey navigation information, such as positional and\/or directional information, to handheld users. By way of example,  shows a flowchart  depicting a method of haptic navigation, according to an embodiment of the present invention. The flowchart  discloses receiving an input signal associated with a position of a handheld communication device at step ; determining the position of a handheld communication device relative to a predetermined location at step ; and providing a haptic effect associated with the determination at step . Step  may include outputting a control signal associated with the determination to an actuator coupled to the handheld communication device, the control signal being configured to cause the actuator to output the haptic effect. Further, the input signal at step  may be received from GPS, a digital compass, or other navigation systems known in the art.","In one embodiment, the haptic effect may be associated with a distance between the position of the handheld communication device and a predetermined location (termed \u201cdestination\u201d herein). For example, the haptic effect may include a vibration having a magnitude and a frequency, where at least one of the magnitude and the frequency decreases as the distance from the destination diminishes. Additionally, the haptic effect may be configured to convey a quantitative measure of the distance. By way of example, the haptic effect may include one or more pulse or jolt sensations, where the number of pulses is proportional to the number of miles between the position of the handheld device and the destination.","Processors described above (including processor  of ) can include, for example, one or more digital logical processors capable of processing input, execute algorithms, and generate output as necessary to perform various tasks, such as those described above. Such processors\/controllers may include a microprocessor, an Application Specific Integrated Circuit (ASIC), and state machines. Such processors include, or may be in communication with, media (including memory  of ). Such media include, for example, computer readable media, which stores program code that, when executed by a processor, cause the processor to perform the steps described herein. Embodiments of computer-readable media include, but are not limited to, an electronic, optical, magnetic, or other storage or transmission device capable of providing a processor, such as the processor in a web server, with computer-readable instructions. Other examples of suitable media include, but are not limited to, a floppy disk, CD-ROM, magnetic disk, memory chip, ROM, RAM, ASIC, configured processor, all optical media, all magnetic tape or other magnetic media, or any other medium from which a computer processor can read. Also, various other forms of computer-readable media may transmit or carry instructions to a computer, including a router, private or public network, or other transmission device or channel.","Program code and associated application programs related to various applications may also reside on a remote source, such as a network resource, a Web server, a remote handheld communication device or computer, which can be transmitted or downloaded to a handheld communication device on a regular or predetermined basis. Haptic effects (along with associated control signals) can also be downloaded or transmitted from a remote source, as described above.","Actuators described above (including actuator  shown in ) can include, for example, a pager motor, an eccentric rotating motor, a harmonic eccentric rotating motor, a voice coil, a solenoid, a resistive actuator, a piezoelectric actuator, an electro-active polymer actuator, or other types of active\/passive actuators suitable for generating haptic effects. U.S. Pat. Nos. 6,429,846 and 6,424,333 disclose further details relating to some of these actuators, both of which are incorporated in full herein by reference. In some embodiments, one or more actuators may be implemented in a handheld communication device, configured to deliver appropriate haptic effects. It will be appreciated that various control schemes can be devised accordingly, for controlling the actuator(s) in a manner that best achieves the desired haptic effects.","Referring back to . In one embodiment, actuator  may be coupled to housing , thereby imparting haptic effects thus generated to the device body. Haptic ringers (or alerts) described above may be delivered in this manner, for instance. In another embodiment, actuator  may be coupled to user-interface  of the device body. For instance, an active and\/or resistive actuator can be coupled to user-interface  to deliver a virtual touch described above. One or more actuators can also be coupled to user-interface , for example, to convey a virtual touch such to a user. In yet another embodiment, a plurality of actuators can be coupled to housing  as well as user-interface . In addition, one or more actuators may also be coupled to a headset, a wristband, or other accessory means associated with a handheld communication device.","Embodiments of the invention include the following.","In one embodiment, an individual (or \u201cBob\u201d) can have a mobile phone according to the invention. The mobile phone also has an e-mail capability, for example, including both \u201creceive\u201d and \u201csend\u201d). The mobile phone is configured to provide a plurality of haptic effects, e.g., by including appropriate hardware (such as actuators described above) and program code. Bob can program the mobile phone, for example, via user-interface  through API  shown in , by inputting various events of interest and associating each with a distinct haptic effect. Thus, when an event of interest is subsequently received, the mobile phone provides the corresponding haptic effect.","In one embodiment, Bob's phone includes programming that provides a first haptic effect when an input signal is received from the mobile phone of Bob's wife (or \u201cAlice\u201d). Bob's phone also includes programming that provides a second haptic effect that is different and distinct from the first haptic effect, when an input signal is received from the mobile phone of Bob's supervisor at work (termed \u201cCarol\u201d herein). Bob's phone is further be configured to provide a third haptic effect that is different from the two mentioned above, e.g., when an e-mail is received from the e-mail address of Bob's stock broker (where the e-mail contains a \u201csmiley-face\u201d emoticon, for instance). The third haptic effect can be a vibration with high magnitude and short duration, e.g., to emulate a \u201chigh-five.\u201d","In another embodiment, Bob can be watching a movie in a theater with his mobile phone in his pocket. It is set to make no noise, because Bob is in a theater. While Bob is watching the movie, Bob's mobile phone vibrates with the second haptic effect mentioned above. Bob chooses to ignore the call, because he does not wish to speak with his supervisor at a movie theater. Later, Bob's mobile phone vibrates with the first haptic effect. Bob wants to speak with Alice, for example, to make plans to meet later. So Bob answers the phone and quickly exits the theater to talk with Alice.","Bob's mobile phone can also include a personal schedule\/calendar application. After speaking with Alice, Bob can enter an entry in the calendar at the 7:00 PM time mark\u2014\u201cMeet Alice\u201d. Bob can also choose a fourth haptic effect to associate with the calendar entry. The mobile phone can be programmed to output the fourth haptic effect fifteen minutes before the time entry of the calendar (i.e., at 6:45 PM).","Bob's mobile phone can be equipped with GPS capability, along with an associated application program for location determination. Bob can also store addresses of various locations of interest in the application program. In one embodiment, Bob can be on the road. Bob's mobile phone vibrates with a distinct fifth haptic effect. Bob recognizes the fifth haptic effect being associated with the haptic logo of his favorite electronics store. He then checks with the application program, and receives a sixth haptic effect associated with the distance between his current position and the store location. Bob then decides to make a stop at the store.","A haptically-enabled handheld communication device of the invention may be further used as a two-way haptic remote control, for example, for controlling a remote system such as a Television set or a multimedia system. In one embodiment, the events as referred to above may be related to program channels shown on the remote system, each identified by a channel number (which may be used as the \u201csource\u201d), for instance. The corresponding haptic effects may be customized on a per-channel basis. Such haptic effects can serve to inform a user as to which channel is on, as a user is channel-surfing by way of this haptic remote control, so that the user need not to look up the display screen.",{"@attributes":{"id":"p-0064","num":"0063"},"figref":"FIG. 9","b":["910","920","930","940"]},"The first haptic effect can be further customized according to the received feedback signal. In one embodiment, the remote system provides information (e.g., via the feedback signal) to the remote control regarding the state of the display, e.g., based on a predetermined scheme. The remote control may use the information to determine a corresponding haptic effect to provide at step . In alternative embodiments, the remote system may determine the appropriate haptic effect to provide and include a corresponding haptic code in the feedback signal. The remote control provides the haptic effect at step  based on this haptic code.","The foregoing description of the preferred embodiments of the invention has been presented only for the purpose of illustration and description and is not intended to be exhaustive or to limit the invention to the precise forms disclosed. Numerous modifications and adaptations thereof will be apparent to those skilled in the art without departing from the spirit and scope of the present invention."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE FIGURES","p":["These and other features, aspects, and advantages of the present invention are better understood when the following Detailed Description is read with reference to the accompanying drawings, wherein:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9"}]},"DETDESC":[{},{}]}
