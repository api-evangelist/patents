---
title: Interactive task-sensitive assistant
abstract: A system and method in accordance with the present invention include means for providing interactive assistance for the performance of a set of predefined steps, including selecting the set of predefined steps and automatically generating a step-sensitive grammar for each step. Generating the step-sensitive grammar includes generating a set of navigation commands related to each step and generating a set of rules to recognize potential queries related to each step. A recognizer is configured for determining if a received utterance forms one of the navigation commands or one of the potential queries, within a context of the current step. Form this determination, provided are navigation to a different step if the utterance was a navigation command or a response if the utterance was a query.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07890336&OS=07890336&RS=07890336
owner: Northwestern University
number: 07890336
owner_city: Evanston
owner_country: US
publication_date: 20030113
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["STATEMENT OF GOVERNMENT INTEREST","CROSS REFERENCES TO RELATED APPLICATIONS","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["The U.S. Government has no interest in or to the present invention.","There are no prior related patent applications.","1. Field of the Invention","The inventive concepts relate to systems and methods useful for assisting a user in the performance of tasks. More specifically, the inventive concepts relate to systems and methods for providing interactive and task sensitive assistance to the user in performance of such tasks.","2. Background","Like many processes, cooking can be a complicated task involving a myriad of actions and decisions that often need to be performed under strict constraints of time, space, and attention. When someone is learning to cook, he follows the instructions in a cookbook, or a recipe. However, the cookbook takes up valuable countertop space, it can be difficult to turn pages of a cookbook when hands are occupied or dirty, and it is hard to keep track of where you are in the recipe. Then, there is also the problem of running around the kitchen between reading each step of the recipe. All this commotion can be highly stressful and intimidating for the novice cook, or in some cases even for an experienced cook learning a new recipe. Often the only solution is to have someone else present to read the recipe or to just make the best of it.","Individuals performing similar tasks can be faced with the same challenges. For example, vehicle repair, surgery or other medical treatments, mechanical device operation, maintenance activities, installation activities, building or assembly projects, or any number of training or operational activities can all be complicated and highly demanding of the individual or individuals performing the tasks.","Presently, systems are not available to assist an individual or individuals in such a situation. In order to be effective, any system that is designed to help a user under these conditions has to be both sensitive to the constraints of such tasks and actually able to exploit them. This means not only facilitating a hands-free or even visually inattentive interaction, but also attending to the details of the task itself.","A system and method in accordance with the present invention include means for providing interactive assistance for the performance of a set of predefined steps, including selecting the set of predefined steps and automatically generating a step-sensitive grammar for each step in a given set of steps. Generating the \u201cstep-sensitive\u201d grammar includes identifying a set of navigation commands related to each step and generating a set of rules to recognize potential queries related to each step. A recognizer is configured for determining if a received utterance forms one of said set of navigation commands or one of said potential queries, within a context of the current step. With this determination made, provided are navigation to a different step if the utterance was a navigation command or a response if the utterance was a query.","As will be appreciated by those skilled in the art, a system in accordance with the present invention could be implemented in any of a variety of contexts wherein a predefined set of steps must be accomplished and where intelligent interaction would be useful in assisting an individual performing those steps. For instance, a system in accordance with the present invention could be used to guide individuals in cooking using a recipe, car repair, surgery or other medical treatments, mechanical device operation, maintenance activities, installation activities, building or assembly projects, or in any number of training activities.","In accordance with the present invention, the gap between having an on-site instructor or assistant and, for example, watching a TV show or video, or simply using a manual or cookbook, is bridged. Such a system walks a user (or group of users) through a selected set of steps (e.g., a recipe), reading aloud each step, and displaying, and optionally highlighting, relevant instructions and\/or diagrammatic information on a display device. Since the system is voice-controlled, the user's hands are free to perform the specified tasks. Furthermore, the system maintains an awareness of the context associated with all points throughout the process of performing the steps. This context sensitivity increases the accuracy and precision of speech recognition. The result is a system that emulates the behavior of a human instructor or assistant.","The present interactive system can act intelligently, since it knows what the user is doing and why she is doing it, at all possible times. Generally, the more a system understands the context surrounding a situation, the more helpful and knowledgeable it can be. However, it can be very difficult to figure out the context of a particular situation at any given time. The system would have to know an incredible amount of information about the world it lives in. Unlike other systems, in the present invention, the system knows the environment, i.e., the context of the situation is established by the system itself. More specifically, such an interactive system has an easier time tracking a user doing a task because the system is actually guiding the user through the steps. In this circumstance, the system knows when the user is doing something, why the user is doing it, and what s\/he is trying to accomplish. This makes it possible for the system to better provide helpful, insightful, and intelligent information.","For illustrative purposes, the present invention is described with respect to a system for implementing steps in a recipe, but those skilled in the art will appreciated that the present invention could be implemented in systems useful in any of a variety of contexts wherein a predefined set of steps must be accomplished and where intelligent interaction would be useful in assisting an individual (or individuals) performing those steps. Such a system preferably includes a processing device having a graphical user interface capable of presenting text, audio and video content, along with means for voice interaction by a user (or users).","In the preferred form, the system includes a large searchable database of recipes or instructions and\/or may have such available from one or more on-line sources, e.g., via the Internet. The user can specify (e.g., by voice or keyboard input) search terms for the recipe title, the type of food, and\/or the ingredients in order to find a recipe or other instruction sequence. Once the user selects a recipe, the system renders the recipe on a display, such as display  shown in . Other manners of searching for and opening a recipe file may also be provided, such as other known methods used for typically searching and opening files. In the preferred form, display  includes a recipe window  having the numbered steps of the recipe and user selectable ingredients window mechanism , which causes a window to be rendered having a listing of the recipe's ingredients. The recipe title  may also be displayed for some or all of the user's session. In other embodiments, the ingredient and recipe display contents could be merged into a single window, perhaps has different panes, or they could be provided in separate displays.","The system supports interaction with respect to a variety of types of user questions or queries. As examples, if the user has questions regarding the ingredients needed for the step, he may ask the system to tell him how much of an ingredient is needed or to show him the entire list of ingredients again. If a video demonstration is available for elements of the step, the system will notify the user verbally and\/or visually and will play the video upon request. The system could be configured to play the video in the same window or in a new window. Preferably, the system also includes other visual cues to help facilitate the user's interaction with the system. For example, in the preferred form, the current step  is set apart from the other steps, and the techniques with help available are highlighted (e.g., underlined), as is shown in .","The user can speak a variety of commands, such as \u201cI'm ready\u201d or \u201cLet's begin\u201d to start the cooking process. At each step, the user speaks to the system naturally and unaffectedly, as he would to another human being. This way, the user is in control of the speed at which he moves through each step. An example of a transcript for a typical interaction between a user and the system is provided below:\n\n","The system is able to achieve this type of highly natural and responsive interaction with a user because instead of using a large general dictionary for dictation and then analyzing all of the spoken words uttered by the user, the system starts from the other end of the spectrum with the relatively small rule-based grammar set, custom generated for each step in the recipe. This significantly reduces the system's speech recognition processing needs by tailoring these needs to the task at hand.","Generally, in the preferred form, there are two functional modules of the system, a grammar generator (or recipe pre-processor) and a \u201crecognizer\u201d. The grammar generator performs initial analysis of the recipe, including preparing the step-sensitive grammar for use by the recognizer during performance of the steps. Once the user has selected a recipe to prepare, the grammar generator tasks include:\n\n","During cooking, the system follows the process  illustrated in . However, those skilled in the art will appreciate that other functional modules and processes may be defined or used to implement the present invention, and that the present invention is not limited to the modules shown or referred to herein or to the process  of . The recognizer  detects valid queries (or utterances)  from a user  (via microphone ) and translates them to text, which the recognizer  parses. Applying the step-sensitive grammars  prepared by the recipe pre-processor's grammar generator to the parsed text , the recognizer  obtains result tags  expressing the essence of the user's utterance. As an example, if the user asked the question \u201cHow much flour do I need\u201d , application of the step sensitive grammar  produces two result tags : \u201caskQuantity\u201d and \u201cflour\u201d.","In the preferred form, the system is primarily comprised of Java modules, and uses IBM's ViaVoice Millennium Pro with Speech for Java SDK as speech to text application and generates step-sensitive grammar as Java Speech Grammar Format (JSGF) files. However, once again, the present invention need not be implemented in Java, nor with the third party products mentioned herein. Using Java's reflection abilities, the recognizer  is able to dynamically invoke different methods based on that query. In this case, \u201caskQuantity\u201d is the method to be invoked and \u201cflour\u201d is an argument to that method. Recognizer  passes the methods and arguments  to a dynamic result listener , which invokes a response method , which in turn obtains the response  to the user's utterance .","Some processing may occur within the methods in order to determine the correct response. The response is a function of the context provided by the step being processed when the utterance was received by recognizer . Accordingly, response method  searches for responses according to the step-sensitive grammar for the current step. Once response  is determined, a speech synthesizer  generates an audio speech output thereof . Other interactions, such as navigation of the recipe or asking for assistance with a particular technique, are handled in a similar way. In this embodiment, the response is output as the speech phrase \u201cYou need \u00bc pounds of wheat flour.\u201d  (via speakers ).","A software architecture  showing one embodiment of the primary functional modules of a system in accordance with the present invention, for example as is provided in , is shown in . As will be appreciated by those skilled in the art, the present invention may be implemented using other architectures, and in any of a number of combinations of software, hardware and firmware. Architecture  includes a StartApp module  that initializes the system application, including initializing the speech-to-text application and provides general window control, access to system data sources and other system functionality. StartApp module , for example, initiates a SearchRecipes module  to search for recipes from recipe data sources, in response to a user's request.","A CookRecipe module  serves as a central control module for the system. CookRecipe module  includes task follower  that manages the interaction with the user. The task follower , tasks a HTML generator  to provide recipe pages suitable for display, a QTVideo (or Quick Time Video) module  for playing selected videos, and an IngredientsWindow module  for rendering a window having the recipe's ingredients. The task follower , in conjunction with the HTMLGenerator , highlights each step on the screen, causes it to be output as audio (or read aloud), and then awaits (or listens for) the user's next utterance. The user may communicate with the system by speaking to it, using a commercial speaker-independent (i.e., untrained) speech recognition system (currently IBM Via Voice).","In the preferred form, the user's utterances can serve at least three (3) purposes: navigation through the task, questions about the ingredients, or help with a technique or in the use of a utensil or tool. The user may indicate navigation commands both explicitly (e.g., \u201cgo on,\u201d \u201cnext step please,\u201d \u201cgo back a step,\u201d etc.) as well as implicitly (e.g., \u201cOK,\u201d \u201cuh-huh, got it,\u201d etc.). The user can ask for more information about ingredients, in particular asking for quantity information or more general information (e.g., \u201cHow much salt?\u201d or \u201cTell me about the broccoli again,\u201d etc.). The user can also ask for help regarding a particular technique (e.g., \u201cHow do I do that?\u201d or \u201cHow do I saute the onions?\u201d) or in the use of a particular utensil or implement (e.g., \u201cHow do I use a wok?\u201d). The system highlights the names of utensils or techniques for which it has help available, such as in the display  of . When asked for help, the system displays short videos or illustrations with audio presenting the proper technique or use, e.g., using QTVideo module . The presentation system is also voice-controlled and supports general navigation and control commands (e.g., \u201cstop,\u201d \u201ccontinue,\u201d \u201cclose,\u201d etc.). Help information is not hard-wired to particular recipe steps. Rather, help is characterized by key-words when entered, and these key-words are correlated with words in the recipes when they are prepared for use, which can be done either upon request or in a batch prior to use of the system.",{"@attributes":{"id":"p-0032","num":"0067"},"figref":"FIG. 4","b":["400","332","402","410","412","332","410","420","422","360","332","420","430","432","342","332"]},"Grammar generator  is the portion of the system that automatically generates grammars for each step of the recipe. An illustrative process for generating grammars is shown in . Step  includes parsing a selected recipe into a list of ingredients, tools, and preparation steps. As examples, the parser may be provided as part of the Grammar generator , CookRecipe module , or could be a standalone module accessed by either of the foregoing. In step , a determination is made of whether there are any recipe steps left for which a step-sensitive grammar must be generated. If there are, a recipe step is chosen from the list of recipe steps, in step .","In step , a determination is made of whether the recipe step includes a reference to an ingredient. If so, a rule is added to the grammar that \u201clistens\u201d for queries about that ingredient, in step . As an example, such a query could be \u201cHow much X?\u201d where X is the ingredient in question. From either of steps  or , the process continues to step , where a determination is made of whether the recipe step includes a reference to a certain technique (e.g., stir-fry). If so, a rule is added to the grammar that listens for queries about that technique, in step . As an example, such a query could be \u201cHow do I X?\u201d where X is a technique. From either of steps  or , the process continues to step , where a determination is made of whether the recipe step includes a reference to a tool (e.g., wok). If so, a rule is added to the grammar that listens for queries about that tool, in step . As an example, such a query could be \u201cHow do I use the X?\u201d where X is a tool. This process continues for each step in the recipe, until a step-sensitive grammar is formed for each recipe step.","While the foregoing has described what are considered to be the best mode and\/or other preferred embodiments, it is understood that various modifications may be made therein and that the invention or inventions may be implemented in various forms and embodiments, and that they may be applied in numerous applications, only some of which have been described herein. As used herein, the terms \u201cincludes\u201d and \u201cincluding\u201d mean without limitation. It is intended by the following claims to claim any and all modifications and variations that fall within the true scope of the inventive concepts.","For example, the system can be (and has been) generalized to a variety of tasks similar to cooking, such as auto maintenance and gardening, as well as other maintenance and operational tasks generally. The techniques for generating the grammar for each step described above can be generalized by noting that repair and operational tasks typically have analogs to ingredients (e.g., parts, work in progress, etc.), utensils (e.g., tools), and of course have techniques or steps. The grammars could be extended to enable questions about a wider variety of help topics, e.g., \u201cWhat does\/should X look like?\u201d where X is an ingredient, a part, or a work in progress. As a general rule, regardless of the field, one could consider the things operated on elements, the things used to operate on them tools, and the methods used techniques.","As examples, devices which may be useful in implementing the present invention include, but are not limited to, personal computers (including laptop computers), personal digital assistants, interactive television devices, appropriately enabled cellular telephones, or other such devices that may be specifically configured to implement the present invention. Such devices could also be integral with kitchen appliances. Such devices may be network enabled and capable of accessing content (e.g., recipes) and functionality via a network. For example, in some forms, a user could download a recipe to the device from the Web and then execute the system functionality locally on the device for the downloaded recipe. Or, the device could accept or obtain content (e.g., recipes and videos) and execute functionality from transportable media, such as CD ROM or DVD."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The drawing figures depict preferred embodiments by way of example, not by way of limitations. In the figures, like reference numerals refer to the same or similar elements.",{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 5","FIG. 3"]}]},"DETDESC":[{},{}]}
