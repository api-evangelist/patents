---
title: Play back apparatus, playback method and program for playing back 3D video
abstract: The playback apparatus realizes stereoscopic viewing by overlaying planar or stereoscopic graphics over stereoscopic video in a way that reduces eye strain using following method in abstract: A graphics plane holds therein data composed of graphics data. A shift engine shifts, in a case when a composition unit composites the graphics data with a left-view video frame, coordinates of each of the pixels is shifted in a first horizontal direction, and in a case when the composition unit composites the graphics data with a right-view video frame, coordinates of each of the pixels is shifted in a second horizontal direction that is opposite to the first direction.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08306387&OS=08306387&RS=08306387
owner: Panasonic Corporation
number: 08306387
owner_city: Osaka
owner_country: JP
publication_date: 20090723
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","PRIOR ART DOCUMENTS","Patent Documents","Non-Patent Document","SUMMARY OF THE INVENTION","The Problems to be Solved by the Invention","Means to Solve the Problems","Effects of the Invention","DESCRIPTION OF PREFERRED EMBODIMENT","Second Embodiment","INDUSTRIAL APPLICABILITY","DESCRIPTION OF REFERENCE NUMERALS"],"p":["(1) Field of the Invention","The present invention belongs to a technical field of a graphics composition technique.","(2) Description of the Related Art","The graphics composition technique is a technique of compositing graphics such as subtitles or a GUI, to each frame of video which constructs a video stream, then displaying the result. As a technical trend of display device, displays that can display stereoscopic video as well as planar video are becoming popular. Various methods of stereoscopic viewing are adopted in the stereoscopic display devices, however, nearly all of the methods use the basic principle of displaying each of left eye and a right eye a different image to create stereoscopic effect, using binocular disparity.","In order to allow the viewers to view the stereoscopic video at the same frame rate as normal planar video, response performance twice as high as response performance needed for the normal planar video is necessary. This means, for example, that it is necessary to switch-among at least 120 frames per second in order to display video consisting of 60 frames per second.","Accordingly, the video stream to be displayed needs to be encoded at 120 frames per second. A stereoscopic effect may also be obtained without increasing the frame rate, by using a side-by-side method as described in a Non-Patent Document 1 or checker pattern method as described in Patent Document 2.","There is also, a technique known to generate stereoscopic images, that extracts information indicating the number of objects from a 2D video, then creating the number of layers corresponding to the number of objects so stereoscopic images can be generated by changing the depth of each of the layers as disclosed in a Patent Document 3.",{"@attributes":{"id":"p-0009","num":"0000"},"ul":{"@attributes":{"id":"ul0001","list-style":"none"},"li":["[Patent Document 1] International Publication No. 2005\/119675 pamphlet","[Patent Document 2] US Patent Application Publication No. 2008-0036854","[Patent Document 3] US Patent Application Publication No. 2002-0118275"]}},{"@attributes":{"id":"p-0010","num":"0000"},"ul":{"@attributes":{"id":"ul0002","list-style":"none"},"li":"[Non-Patent Document 1] FOUNDATIONS OF THE STEREOSCOPIC CINEMA. A STUDY IN DEPTH (by Lenny LIPTON)"}},"As the situation now stands, application of a method of allowing viewers to enjoy viewing video streams stereoscopically is mainly engaged at theaters and the like. However, it is expected that it will be common for the viewers to enjoy viewing the stereoscopic video streams with use of playback apparatuses for household use in the future.","In package media such as BD-ROMs and DVD-videos, subtitles are not pre-embedded as part of video like the movies. In package media, plurality of subtitle data corresponding to plurality of languages is recorded separately from a video stream. This is because it is necessary to composite appropriate subtitle data with a video in accordance with a language setting in a playback apparatus, and to display data obtained as a result of the composition.","Also, according to graphics for realizing the GUI, a plurality of pieces of graphics data is recorded separately from the video stream. This is also because it is necessary to composite appropriate graphics data with a video in accordance with a language setting in a playback apparatus, and to display data obtained as a result of the composition. In this case, it is desirable that both of data for a left view (left-view data) and data for a right view (right-view data) are prepared for each of graphics showing subtitles, and graphics showing the GUI. However, since BD-ROMs have limited capacity, it may not be possible to prepare both the left-view data and the right-view data for each of the video and the graphics.","In a case where only one of the left-view data or the right-view data can be prepared for the graphics, the graphics will appear to be flat while the video corresponding to the stereoscopic video stream can be viewed stereoscopically. Suppose that the planar graphics is composited with the stereoscopic video stream without the consideration of spacing caused by the stereoscopic effect of displaying separate left-view video and right-view video data. In such case, a flat graphics will appear within a stereoscopic video as a result of composition. As a result, the graphics will appear to be buried into the stereoscopic video, which in turn will cause displeasure to the viewers. This is caused by the eyes not being able to adjust to an unnatural stereoscopic composition not seen in real life, leading to decrease in realistic sensation.","The present invention has an objective to provide a playback apparatus that is capable of executing stereoscopic playback by performing composition of the video and the graphics so as to prevent viewers from feeling uncomfortable despite when only graphics for one eye, either graphics for left view (left-view graphics) or graphics for right view (right-view graphics), is recorded on a recording medium.","In order to solve the above-stated problem, the present invention is a playback apparatus that executes stereoscopic playback, the playback apparatus comprising: a video decoder operable to decode a video stream to obtain video frames; a video plane that holds therein the video frames; a graphics plane that holds therein graphics data, the graphics data having a resolution of a predetermined number of horizontal and vertical pixels; a composition unit operable to composite the graphics data within the graphics plane with one of the video frames; and a shift engine operable to perform plane shifting of the graphics plane, wherein each of the video frames in the video plane is outputted as a right-view video frame or a left-view video frame, and the stated plane shifting of the graphics plane is defined as; prior to outputting the left-view video frame, shifting each of the pixels of the graphics data within the graphics plane in a right or a left direction, and prior to outputting the right-view video frame, shifting each of the pixels of the graphics data within the graphics plane in an opposite direction from left view, and then giving the resulted shifted graphics data within the graphics plane to the composition unit for the composition.","By shifting the coordinates of each of the pixel data pieces held in the graphics plane (hereinafter, referred to as \u201cplane shifting of the graphics plane), it will become possible to adjust the depth position of the graphics to be displayed. The stated depth position meaning how close or far the objects on the plane will appear to the user in accordance to the display depth. Therefore, even in a case where subtitles and GUI appear to be buried in the stereoscopic video because both of the right-view graphics (right-view interactive graphics) and the left-view graphics (left-view interactive graphics) are not provided in a recording medium, a more natural stereoscopic composition (graphics depth position is closer to the viewer than the video depth position) can be achieved. Since the depth position of the subtitles and GUI are changed by such an adjustment, it is not necessary to prepare both the left-view graphics and the right-view graphics and only prepare 2D graphics for displaying the subtitles and the GUI stereoscopically or adding the depths thereto. Therefore, even in a case where a BD-ROM whose capacity is limited is a target for the playback, it is possible to provide the user with preferable stereoscopic view.","Also for authoring purposes, it will become possible to re-use the graphics for 2D playback, thus will be able to skip the conversion process of stereoscopic graphics (create a second view), resulting in a reduction of labor cost for generating stereoscopic contents.","Even when the depths of the graphics showing the subtitles and GUI are not appropriate, it is possible to change the depth of the graphics to an appropriate depth in accordance with the depth of video to be outputted, by performing the above-stated shifting. Therefore, the graphics to which the depth is added appears to be natural, and there will be no difference in how the video and the graphics showing the subtitles and GUI appear stereoscopically. Therefore, stress caused to the naked eyes of the viewers is reduced.","Also, since it is not necessary to load the left-view graphics and the right-view graphics in a memory separately, the memory capacity of the playback apparatus will not be consumed even when an image obtained by compositing the video with the graphics is displayed stereoscopically.","With the above-stated structure, the stereoscopic video playback apparatus pertaining to the present invention can stereoscopically display the subtitles and the GUI on the video even if both of the left-view graphics and right-view graphics are not prepared.","The following describes the embodiments of a recording medium and a playback apparatus  having the above-stated Means to Solve the Problems with reference to the drawings.",{"@attributes":{"id":"p-0066","num":"0067"},"figref":["FIG. 1","FIG. 1"],"b":["200","100","200","300","400","500"]},"The BD-ROM  provides the above-stated home theater system with a movie, for example.","The playback apparatus  is connected to the TV , and plays back the BD-ROM .","The remote control  is a device that receives an operation for the hierarchized GUI from the user. In order to receive such an operation, the remote control  includes: a menu key for calling menus composing the GUI; an arrow key for moving a focus of the GUI parts composing each menu; a decision key for performing determined operation on the GUI parts composing each menu; a return key for returning to higher order hierarchized menus; and a numerical key.","The TV  provides the user with a dialogical operational environment by displaying the playback picture of the movie, a menu and the like.","The liquid crystal shutter glasses  are composed of crystal liquid shutters and a control unit, and realize stereoscopic view with use of binocular disparity of the viewer's eyes. Lenses having a feature that the transmittance of light is changed by changing applied voltage are used for the crystal liquid shutters of the liquid crystal shutter glasses . The control unit of the liquid crystal shutter glasses  receives a SYNC signal for switching between a right-view image and a left-eye image that are transmitted from the playback apparatus , and switches between a first state and a second state in accordance with this SYNC signal.","In the first state, the control unit adjusts the applied voltage such that light does not transmit through a liquid crystal lens corresponding to the right view, and adjust the applied voltage such that light transmits through a liquid crystal lens corresponding to the left view. In such a state, only the left-view image is viewed.","In the second state, the control unit adjusts the applied voltage such that the liquid crystal lens corresponding to the right view transmits light, and adjusts the applied voltage such that the liquid crystal lens corresponding to the left view does not transmit light. In such a state, the crystal liquid shutters provide view of the right-view image.","Generally, the right-view image and left-view image look a little different due to differences between angles. With use of such a difference, the user can recognize an image as a stereoscopic image. Thus, the user confuses a planar display with a stereoscopic display by synchronizing timing of switching between the above-stated first state and second state with timing of switching between the right-view image and the left-view image. Next, a description is given of a time interval in displaying right-view video and left-view video.","Specifically, there is a difference between the right-view image and the left-view image that corresponds to binocular disparity of the user in a planar image. By displaying theses images while switching the images at a short time interval, the images appear as if the images are displayed stereoscopically.","The short time interval may be a time period just enough to confuse the user on planar images with stereoscopic images when the switching and the displaying are performed as stated in the above.","This concludes the description of the home theater system.","The following describes a recording medium to be played back by the playback apparatus . The playback apparatus  plays back the BD-ROM .  shows the internal structure of the BD-ROM .","The BD-ROM is shown in a fourth tier from the top in the present figure, and a track on the BD-ROM is shown in a third tier. Although the track is usually formed in a spiral manner from an inner circumference to an outer circumference, the track is drawn in a laterally-expanded manner in the present figure. This track consists of a read-in area, a volume area and a read-out area. Also, in the read-in area exists a special area called BCA (Burst Cutting Area) that can be read only by a drive. Since this area cannot be read by an application, this area is often used in copyright protection technology.","The volume area in the present figure has a layer model having a physical layer, a file system layer and an application layer. Application data such as image data starting with file system information (volume) is stored in the volume area. The file system is UDF, ISO9660 or the like. In the file system, it is possible to read logic data recorded in the same manner as a normal PC, with use of a directory or a file structure. Also, a file name or a directory name consisting of 255 words can be read. A top tier of  shows an application layer format (application format) of the BD-ROM expressed using a directory structure. As shown in the first tier, in the BD-ROM, a CERTIFICATE directory and a BDMV directory exists below the Root directory.","Below the CERTIFICATE directory, a file of a root certificate (app.discroot.certificate) of a disc exists. This app.discroot.certificate is a digital certificate used in a process that checks whether an application has been tampered, or identifies the application (hereinafter, signature verification) when executing a program of a JAVA\u2122 application that performs dynamic scenario control using a JAVA\u2122 virtual machine.","The BDMV directory is a directory in which data such as AV content and management information used in the BD-ROM are recorded. Six directories called \u201cPLAYLIST directory\u201d, \u201cCLIPINF directory\u201d, \u201cSTREAM directory\u201d, \u201cBDJO directory\u201d, \u201cJAR directory\u201d and \u201cMETA directory\u201d exist below the BDMV directory. Also, two types of files (i.e. INDEX.BDMV and MovieObject.bdmv) are arrayed.","The STREAM directory is a directory storing a file which is a so-called transport stream body. A file (000001.m2ts) to which an extension \u201cm2ts\u201d is given exists in the STREAM directory.","A file (000001.mpls) to which an extension \u201cmpls\u201d is given exists in the PLAYLIST directory.","A file (000001.clpi) to which an extension \u201cclpi\u201d is given exists in the CLIPINF directory.","A file (XXXXX.bdjo) to which an extension \u201cbdjo\u201d is given exists in the BDJO directory.","A file (YYYYY.jar) to which an extension \u201cjar\u201d is given exists in the JAR directory.","An XML file (ZZZZZ.xml) exists in the META directory.","The following describes these files.","Firstly, a description is given of the file to which the extension \u201cm2ts\u201d is given. The file to which the extension \u201cm2ts\u201d is given is a digital AV stream in the MPEG-TS (Transport Stream) method, and is acquired by multiplexing a video stream, one or more audio streams, a graphics stream, a text subtitle stream and the like. The video stream represents moving part of the movie, and the audio stream represents audio part of the movie. In the case of the 3D stream, both of left-eye data and right-eye data may be included in m2ts, or m2ts may be prepared separately for each of the left-eye data and the right-eye data. It is preferable to use a codec (e.g. MPEG-4 AVC MVC) in which a left-view stream and a right-view stream refer to one another in order to save disc capacity used for streams. Video streams compressed and encoded with use of such a codec are called MVC video streams.","There are 2 types of MVC video streams, base view video stream and enhanced view video stream. The base view video stream is a video stream composing either the left view or the right view video that realizes planar view display. Meanwhile, the \u201cenhanced view video stream\u201d is the video stream that is used with the base view to construct stereoscopic video, composing the left or right view video that is not composed in the base view video stream. Picture data pieces composing the enhanced view video stream are compressed and encoded based on frame correlativity with picture data pieces composing the base view stream.","The file to which the extension \u201cmpls\u201d is given is a file storing PlayList (PL) information. The PL information defines a playlist referring to the AVClip.","In the present embodiment, it is possible to determine whether streams to be played back include a 3D video stream, based on a structural format of the PlayList (PL) stored on the BD-ROM.","The PlayList information includes MainPath information, Subpath information and PlayListMark information.","1) The MainPath information defines a logic playback section by defining at least one pair of a time point (In_Time) and a time point (Out_Time) on a playback time axis of the AV stream. The MainPath information has a stream number table (STN_table) that stipulates which elementary streams that have been multiplexed into AV stream are permitted to be played back and are not permitted to be played back.","2) The PlayListMark information shows specification of a time point corresponding to a chapter in a part of the AV stream specified by the pair of the In_Time information and the Out_Time information.","3) The Subpath information is composed of at least one piece of SubPlayItem information. The SubPlayItem information includes information on specification of an elementary stream to be played back in synchronization with the AV stream, and includes a pair of In_Time information and Out_Time information on the playback time axis of the elementary stream. The Java\u2122 application for controlling playback instructs a Java\u2122 virtual machine to generate a JMF (Java Media Frame work) player instance that plays back this PlayList information. This starts the playback of the AV stream. The JMF player instance is actual data generated on a heap memory of the virtual machine based on the JMF player class.","Hereinafter, a stream including only a stream for 2D playback is referred to as a \u201c2D stream\u201d, and a stream including both a 2D and 3D streams is referred to as a \u201c3D stream\u201d.","Furthermore, according to a term definition, a 2D playlist is a playlist including only a stream for the 2D playback while a 3D playlist includes a stream for 3D viewing in addition to the 2D stream.","The file to which the extension \u201cclpi\u201d is given is Clip information which is in one to one correspondence with AVclip information. Since the Clip information is management information, the Clip information has an EP_map showing an encoding format of the stream in the AVClip, a frame rate, a bit rate, information on resolution and the like, and a starting point of GOPs. The Clip information and PL information are classified as \u201cstatic scenario\u201d.","The following describes the file to which the extension \u201cBD-J object\u201d is given. The file to which the extension \u201cBD-J object\u201d is given is a file storing a BD-J object. The BD-J object is information that defines a title by association an AVClip string defined by the PlayList information with an application.","The entity of the Java\u2122 application corresponds to a Java\u2122 archive file (YYYYY.jar) stored in the JAR directory under the BDMV directory in .","The application is a Java\u2122 application, and is composed of one or more xlet programs loaded in the heap area (also called \u201cwork memory\u201d) of the virtual machine. The application is composed of the xlet program loaded in the work memory and data.","In the meta file (ZZZZZ.xml) included in the META directory is stored various information pieces relating to the movie in the disc. Examples of information pieces stored in the meta file are a name of the disc and an image of the disc, information on who has created the disc, and a title name for each title. This concludes the description of the BD-RO . The meta file is not a prerequisite, and some BD-ROMs do not include this meta file. This concludes the description of the BD-ROM.","The following describes the BD-J object.  shows the internal structure of the BD-J object. As shown in , the BD-J object is composed of an \u201capplication management table\u201d, a \u201cGUI management table\u201d and a \u201cplaylist management table\u201d.","The following describes these elements.","The \u201capplication management table\u201d is a table for causing the playback apparatus  to perform application signaling that runs the title as a life cycle. A lead line bj shows the internal structure of the application management table in closeup. As shown in this lead line, the application management table includes an \u201capplication identifier\u201d and a \u201ccontrol code\u201d that specify an application to be operated when a title corresponding to the BD-J object becomes a current title. When the control code is set to AutoRun, the control code shows that this application is automatically started after the application is loaded on the heap memory. When the control code is set to Present, the control code waits for a call from another application, and shows whether the application should be operated after the application is loaded on the heap memory.","The \u201cGUI management table\u201d is a table used for GUI related operations by the application. More specifically, resolution, font data used, masking information when GUI for executing the menu call, or a title call is instructed by the user, is included. A lead line bj shows the internal structure of the GUI management table in closeup. As shown by this lead line bj, the GUI management table may be set to one of HD3D1920\u00d71080, HD3D1280\u00d7720, HD1920\u00d71080, HD1280\u00d7720, QHD960\u00d7540, SD, SD50 HZ720576 and SD60 HZ720480.","A lead line bj shows the internal structure of the playlist management table in closeup. The playlist management table includes information on specification of the playlist to be operated by default when a title corresponding to the BD-J object becomes a current title. A lead line bj shows the internal structure of a auto start playlist in closeup. As shown by the lead line bj, 3D playlist 1920*1080, 3D playlist 1280*720, 2D playlist 1920*1080, 2D playlist 1280*720, 2D playlist 720*576 and 2D playlist 720*480 may be specified as information specifying the auto start playlist.",{"@attributes":{"id":"p-0110","num":"0111"},"figref":["FIG. 4","FIG. 4"],"b":["200","101","102","103","104","105","106","107","200"]},"The front end unit  is a data input source. In a figure described in the following, the front end unit  includes a BD drive  and a local storage , for example.","The system LSI  is composed of logic elements, and is a core part of the playback apparatus . This system LSI includes therein at least a demultiplexer , video decoders and , image decoders and , an audio decoder , a playback state\/setting register (PSR: Player Status\/Setting Register) set , a playback control engine , a composition unit , a plane shift engine  and an offset setting unit .","The memory device  is composed of arrays of memory devices such as an SDRAM.","The back end unit  is a connection interface that connects internal parts of the playback apparatus  with other devices.","The nonvolatile memory  is a readable and writable recording medium, and is a medium that can hold recorded contents without needing power source supply. The nonvolatile memory  is used for backup of information on a display mode stored in a display mode storage unit  (described in the following). A flash memory, an FeRAM or the like may be used as this nonvolatile memory .","The host microcomputer  is a core part of the playback apparatus , and is composed of an MPU, a ROM and a RAM. The host microcomputer  includes a BD-J platform  and a command interpreter  from among the elements specifically described in the following.","The network interface  is for performing communication with an external device outside the playback apparatus , and is capable of accessing a server accessible via the Web, and accessing a server connected by a local network. For example, the network interface  is used for downloading BD-ROM additional contents publicized on the web. The BD-ROM additional content is content that is not stored in an original BD-ROM, examples of which are additional sub audio, subtitles, special features and an application. It is possible to control the network interface  from the BD-J platform, and to download, in the local storage , the additional content publicized on the web.","As stated in the above, the front end unit  includes the BD drive  and the local storage , for example.","The BD drive  includes, for example, a semiconductor laser (not shown), collimator lenses (not shown), a beam splitter (not shown), an objective lens (not shown), a condenser lens (not shown), an optical head (not shown) including a light detector (not shown). Light beam outputted from the semiconductor laser is collected on a information side of the optical disc through the collimator lenses, the beam splitter and the objective lens. The collected light beam is reflected and diffracted on the optical disc, and then collected by the light detector through the objective lenses, the beam splitter and the condenser lenses. The generated signal corresponds to data read from the BD-ROM in accordance with the amount of light collected on the light detector.","The local storage  includes a built-in media and a removable media, and is used for storing the downloaded additional contents and data used by the application. A storage area for the additional contents is provided for each BD-ROM, and an area that can be used for storing data is provided for each application. Also, merge management information, which is a merge rule regarding how the downloaded additional contents are merged with the data on the BD-ROM, is also stored in the built-in media and the removable media.","The built-in media is a writable recording medium such as a hard disk drive and a memory built in the playback apparatus .","The removable medium is a portable recording medium, for example, and is preferably a portable semiconductor memory card such as an SD card.","A description is given taking a case where the removable media is a semiconductor memory card as an example. The playback apparatus  is provided with a slot (not shown) into which the removable media is inserted, and an interface (e.g. memory card I\/F) for reading the removable area inserted into the slot. When the semiconductor memory is inserted into the slot, the removable media and the playback apparatus  are electrically connected to each other, and it is possible to convert data recorded in the semiconductor memory into an electrical signal and read the electrical signal with use of the interface (e.g. memory card I\/F).","The elements in the front end unit , the system LSI, the nonvolatile memory , the memory device , the back end unit and the host microcomputer  are further described.  shows the structure of the front end unit , the system LSI, the nonvolatile memory , the memory device , the back end unit and the host microcomputer  in detail. As shown in , the front end unit , the system LSI, the nonvolatile memory , the memory device , the back end unit and the host microcomputer  include a read buffers  and , a virtual file system , a demultiplexer , the video decoders and , a video plane , image decoders and , image memories and , an image plane , an audio decoder , an interactive graphics plane , a background plane , the playback state\/setting register (PSR) set , a static scenario memory , the playback control engine , the composition unit , an HDMI transmission\/reception unit , a left-right processing storage unit , a display function flag holding unit , a plane shift engine , the offset setting unit , the BD-J platform , a dynamic scenario memory , a mode management module , an HDMV module , a UO detection module , a still image memory , a still image decoder , a display mode setting initial display setting unit  and a display mode storage unit .","The read buffer  temporarily stores source packets composing extents that compose the base view stream read from the BD drive . The read buffer  transfers the source packets to the demultiplexer  after adjusting the transfer speed, and has a size \u201cRB\u201d as stated in the above.","The read buffer  stores source packets composing extents that compose the enhanced view stream read from the BD drive . The read buffer  transfers the source packets to the demultiplexer after adjusting the transfer speed, and has a size \u201cRB\u201d as stated in the above.","The virtual file system  configures a virtual BD-ROM (virtual package) in which the additional contents stored in the local storage are merged with the contents on the loaded BD-ROM based on the merge management information downloaded in the local storage  together with the additional contents.","The virtual package and the original BD-ROM can be referred to from a command interpreter which is a main operational part in the HDMV mode, and the BD-J platform which is a main operational part in the BD-J mode. The playback apparatus  performs the playback control with use of the data on the BD-ROM and the data on the local storage during the playback of the virtual package.","The demultiplexer  is composed of a source packet depacketizer and a PID filter. Receiving an instruction from a packet identifier corresponding to a stream to be played back (the stream is included in the structured virtual package (data on the loaded BD-ROM and the local storage corresponding to the loaded BD-ROM), the demultiplexer  executes packet filtering based on the packet identifier. In executing the packet filtering, the demultiplexer  extracts one of the left-view video stream and the right-view video stream that corresponds to a display method flag based on the flag in the left-right processing storage unit , and the demultiplexer  transfers the video stream to the video decoder or the video decoder ","When a stream separated from the stream to be played back is a subtitle stream, the demultiplexer  writes the separated subtitle stream in to the image memory. When the subtitle streams (a left-view subtitle stream, and a right-view subtitle stream) are included in the stream, the demultiplexer  writes the left-view subtitle stream in the image memory , and writes the right-view subtitle stream in the image memory ","When the 2D subtitle stream (subtitle stream used for the planar display) is included in the stream, the demultiplexer  writes the 2D subtitle stream in the image memory ","The video decoder decodes a TS packet outputted from the demultiplexer , and writes a compressed picture in a left-eye plane  (expressed as a code (L) in the video plane  in ).","The video decoder decodes the enhanced view video stream outputted from the demultiplexer , decodes the TS packet, and writes the uncompressed picture in a right view video plane  (expressed as a code (R) in the video plane  in ).","The right-view video plane  is a plane memory that can store picture data having a resolution such as 1920*2160 (1280*1440). The video plane  has a left-eye plane (expressed as the code (L) in the video plane  in ) having an area capable of storing data with resolution such as 1920*1080 (1280*720), and a right-eye plane (expressed as the code (R) in the video plane  in ) having an area capable of storing data with resolution such as 1920*1080 (1280*720).","When the display mode of the video plane is in 3D display mode, and the stereo mode is ON, the video decoder decodes the left-view video stream, and writes the decoded left-view video stream in the left-eye plane (expressed as the code (L) in the video plane  in ). The video decoder decodes the right-view video stream, and writes the decoded right-view video stream in the right-eye plane (expressed as the code (R) in the video plane  in ).","When the display mode of the video plane is a 3D display mode, and the stereo mode is OFF, the video decoder decodes the left-view video stream, for example, and writes the decoded left-view video stream in the left-eye plane (expressed as the code (L) in the video plane  in ) and in the right-eye plane (expressed as the code (R) in the video plane  in ).","When the display mode of the video plane is a 2D display mode, the demultiplexer  transmits the 2D video stream to the video decoder , and the video decoder writes the decoded 2D video data held in the left-eye plane (expressed as the code (L) in the video plane  in ).","Although an examples are shown for cases where each of the left-eye plane and the right-eye plane included in the video plane  shown in  is a physically separated memory, the structure of the video plane  is not limited to this. Therefore, areas for the left-eye plane and the right-eye plane may be provided together as one memory. In such case, the video data is written in each of the corresponding areas (left and right).","Each of the image decoders and decodes TS packets composing the subtitle stream that is outputted from the demultiplexer  and written in the image memories and , and writes the uncompressed graphics subtitles in the graphics plane . The \u201csubtitle streams\u201d decoded from the image decoders and are data pieces each showing subtitles compressed by a run-length coding, and is defined by pixel codes showing a Y value, a Cr value, a Cb value and an a value and a run lengths of the pixel codes.","The image plane  is a graphics plane capable of storing graphics data (e.g. subtitle data) obtained by for example, decoding the subtitle stream with a resolution of 1920*1080 (1280\u00d7720). The image plane  has a left-eye plane (expressed as a code (L) in the image plane  in ) having an area capable of storing data having a resolution of 1920*1080 (1280*720), for example, and a right-eye plane (expressed as a code (R) in the image plane  in ) having an area capable of storing data having a resolution of 1920*1080 (1280*720), for example.","When the display mode of the plane with subtitle data is in 3D display mode, and the stereo mode is ON, the image decoder decodes the left-view subtitle stream stored in the image memory , and writes the decoded subtitle stream in the left-eye plane (expressed as a code (L) in the image plane  in ). The image decoder decodes the right-view subtitle stream stored in the image memory , and writes the decoded right-view subtitle stream in the right-eye plane (expressed as a code (R) in the image plane  in ).","When the display mode of the plane with subtitle data is a 3D display mode, and the stereo mode is OFF, the image decoder decodes the left-view subtitle stream stored in the image memory , and writes the decoded left-view subtitle stream in the left-eye plane (expressed as a code (L) in the image plane  in ) and in the right-eye plane (expressed as a code (R) in the image plane  in ).","When the display mode of the plane with subtitle data is a 2D display mode, the demultiplexer  stores the 2D subtitle stream in the image memory , and the image decoder decodes the 2D subtitle stream stored in the image memory , and writes the left-eye video plane (expressed as a code (L) in the image plane  in ).","Although an examples are shown for cases where each of the left-eye plane and the right-eye plane included in the image plane  shown in  is a physically separated memory, the structure of the image plane  is not limited to this. Therefore, areas for the left-eye plane and the right-eye plane may be provided together as one memory. In such case, the corresponding graphics data is written in each of the corresponding areas (left and right).","The audio decoder  decodes audio frames outputted from the demultiplexer , and outputs the uncompressed audio data.","The interactive graphics plane  is a graphics plane having a storage area capable of storing graphics data written by the BD-J application using the rendering engine  with resolutions such as 1920*2160 (1280*1440). The interactive graphics plane  has, for an example, a left-eye plane (expressed as a code (L) in the interactive graphics plane  in ) having an area capable of storing data having a resolution of 1920*1080 (1280*720), and a right-eye plane (expressed as a code (R) in the interactive graphics plane  in ) having an area capable of storing data having a resolution of 1920*1080 (1280*720).","When the display mode of the interactive graphics plane is in 3D display mode, and the stereo mode is ON, it is indicated that the BD-J application includes a program that writes an interactive graphics that is viewable by the left eye (left-eye interactive graphics) and an interactive graphics that is viewable by the right eye and is different from the left-eye interactive graphics (right-eye interactive graphics).","The left-eye interactive graphics and the right-eye interactive graphics written by this rendering program can be seen from different angles so as to allow the viewer to see stereoscopic graphics.","When the left-eye interactive graphics and the right-eye interactive graphics are displayed, the BD-J application writes the left-view interactive graphics in the left-eye plane (to which a code (L) is given in the interactive graphics plane  in ) with use of the rendering engine , and writes the right-view interactive graphics in the right-eye plane (to which a code (R) is given in the interactive graphics plane  in ).","When the display mode of the interactive graphics plane is in 3D display mode, and the stereo mode is OFF, the BD-J application writes the left-view interactive graphics in the each of the planes to which the code (L) and the code (R) are respectively given, with use of the rendering engine .","When the display mode of the interactive graphics plane is in 2D display mode, the BD-J application writes the 2D interactive graphics in the interactive graphics plane  (more specifically, the plane to which the code (L) is given in the interactive graphics plane ) with use of the rendering engine .","Although examples are shown for cases where a left-eye area (to which the code (L) is given) and a right-eye area (to which the code (R) is given) of the interactive graphics plane  shown in  are provided in one plane memory, the structure of the interactive graphics plane  plane is not limited to this. Therefore, the left-eye area (to which the code (L) is given) and the right-eye area (to which the code (R) is given) of the interactive graphics plane  may be physically separated from one another.","The \u201cgraphics data\u201d held in the interactive graphics plane  is graphics whose pixels each is defined by an R value, a G value, a B value, and an \u03b1 value. The graphics written in the interactive graphics plane  is an image or a widget mainly used for composing the GUI.","Although the image data and the graphics data are different in terms of structure, they are collectively expressed as graphics data. There are two types of the graphics plane (i.e. the image plane  and interactive graphics plane ). Hereafter, when the term \u201cgraphics plane\u201d is used, it referrers to both or one of the image plane  and the interactive graphics plane .","The still image memory stores still image data that is extracted from the structured virtual package and is to be a background image.","The background plane  is a plane memory capable of storing the still image data to be a background image having a resolution such as 1920*2160 (1280*1440). Specifically, the background plane  has a left-eye plane (expressed as a code (L) in the background plane  in ) having an area capable of storing data having a resolution of 1920*1080 (1280*720), and a right-eye plane (expressed as a code (R) in the background plane  in ) having an area capable of storing data having a resolution of 1920*1080 (1280*720).","When the display mode of the background plane is in 3D display mode, and the stereo mode is ON, the still image decoder decodes left-view still image data and right-view still image data that are stored in the still image memory . Then the image decoder writes the left-view still image data and the right-view still image data held in the left-eye plane (to which a code (L) is given in the background plane  shown in ) and the right-view plane (to which a code (R) is given in the background plane  shown in ), respectively.","When the display mode of the background plane is in 3D display mode, and the stereo mode is OFF, the background plane  decodes the left-view still image data from among the 3D background images stored in the still image memory (the left-view still image data and the right-view still image data), and writes the decoded left-view image data held in the left-eye plane (to which a code (L) is given in the background plane  shown in ) and in the right-eye plane (to which a code (R) is given in the background plane  shown in ).","When the display mode of the background image is a 2D display mode, the still image decoder decodes the 2D still image data stored in the still image decoder , and writes the decoded 2D still image data held in the left-eye plane (to which a code (L) is given in the background plane  shown in ).","Although examples are shown for cases where the left-eye plane (to which the code (L) is given) and a right-eye plane (to which the code (R) is given) of the background plane  shown in  are provided in one plane memory, the structure of the background plane  is not limited to this. Therefore, the left-eye plane (to which the code (L) is given) and the right-eye plane (to which the code (R) is given) of the background plane  may be physically separated from one another.","Note that although it is disclosed that each of the video plane , the image plane , the interactive graphics plane  and the background plane  as shown in  is provided with a storage area for storing the left-eye data and a storage area for storing the right-eye data, the structures of these planes are not limited to this. Therefore, each of the planes may have only one memory area that is alternatively used as a left-eye area and a right-eye area.","The PSR set  is a collection of registers including a playback state register storing therein information on playback states of playlists, a playback setting register storing configuration information showing a configuration in the playback apparatus , and a general register capable of storing arbitrary information used by the contents. Each of the playback states of the playlists shows which of the AV data pieces in each kind of AV data information pieces that are written in the playlist are used, and at which position (time point) of the playlist the playback is performed.","When the state of each of the playlists changes, the playback control engine  stores information on what has been changed in the PSR set . Also, according to an instruction from the application executed by the command interpreter which is a main operational part in the HDMV mode or the main operational part in the BD-J mode, the playback control engine  is capable of storing a value specified by the application, and transferring the stored value to the application.","The static scenario memory  is a memory for storing current PlayList information or a current clip information. The current PlayList information is a current processing target from among a plurality of pieces of PlayList information accessible from the BD-ROM, a built-in media drive or a removable media drive. The current clip information is a current processing target from among a plurality of pieces of clip information accessible from the BD-ROM, a built-in media drive or a removable media drive.","The playback control engine  executes an AV playback function and a playback function of the playlist in response to a function call from the command interpreter which is the main operational part in the HDMV mode and the Java platform which is the main operational part in the BD-J function. The AV playback function is a set of functions used in DVD players and CD players, and includes playback start, playback stop, pause, release of pause, release of freeze frame function, fast forwarding at a playback speed specified by an immediate value, fast rewinding at a playback speed specified by an immediate value, audio conversion, sub image conversion, and angle conversion. The playlist playback function is to perform playback start or playback stop from among the above-stated AV playback functions according to the current PlayList information composing current playlists, and current clip information.","When a disc is inserted into the medium, a playlist and an AV stream that are playback processing targets by the playback control engine  are a auto start playlist (AutoStartPlaylist) and a default start stream respectively that are written in the current scenario on the BD-ROM. The playback of the AV stream starts due to a user operation (e.g. playback button) or automatically done by event triggered by the terminal (i.e. such as resident application).","The composition unit  composites data held in the interactive graphics plane , data held in the image plane , data held in the video plane  and data held in the background plane .","Each of the interactive graphics plane , the image plane , the video plane  and the background plane  has a separate layer structure. Data held in each of the planes is composited (overlaid) in order of the background plane , the video plane , the image plane , then the interactive graphics plane . That is, even in the case where the planar graphics is composited with the stereoscopic video, the composition unit  composites video held in the video plane  with the background image held in the background plane , then composites the subtitles held in the image plane , then at last composites the graphics held in the interactive graphics plane . The composited image is displayed as a result. If done otherwise, graphics part may be hidden by the video, and thus will look unnatural.","The composition unit  also includes a scalar function. When the composition unit  composites shifted data pieces in the planes, the composition unit  is capable of performing scaling to make the image appear to be smaller or larger.","The purpose of performing the scaling is described in the following. In the real world, close objects appear to be larger, and distant objects appear to be smaller. However, just shifting the above-stated image data makes the object appear to be close to or distant from the viewer with its size unchanged. In such case, the viewer possibly may feel uncomfortable. The scaling is performed for the purpose of reducing such a sense of discomfort. One example, would be to in order to display the image closer to the viewer with a large shift amount, the subtitles held in the image plane  and the image held in the interactive graphics plane  can be enlarged at the timing of scaling.","The HDMI transmission\/reception unit  includes an interface that complies with the HDMI standard (HDMI: High Definition Multimedia Interface). The HDMI transmission\/reception unit  performs transmission and reception such that the playback apparatus  and a device (in this example, a TV ) that performs the HDMI connection with the playback apparatus  comply with the HDMI standard. The picture data stored in the video and audio data decoded from the uncompressed audio data by the audio decoder  are transmitted to the TV  via the HDMI transmission\/reception unit . The TV  holds information such as, whether the TV  is capable of displaying data stereoscopically, information regarding-resolutions at which the planar display can be performed, and information regarding resolutions at which the stereoscopic display can be performed. When the playback apparatus  gives a request via the HDMI transmission\/reception unit , the TV  gives the playback apparatus  necessary information (e.g. information regarding whether the TV  is capable of displaying data stereoscopically, information regarding resolutions at which the planar display can be performed, and information regarding resolutions at which the stereoscopic display can be performed) requested by the TV . Thus, the playback apparatus  is capable of obtaining, from the TV , the information regarding whether the TV  is capable of displaying data stereoscopically via the HDMI transmission\/reception unit .","The left-right processing storage unit  stores information showing whether the current output processing is for left-view video or right-view video. A flag in the left-right processing storage unit  shows whether or not data to be outputted to a display device (TV in ) connected to the playback apparatus  shown in  is the left-view video or the right-view video. While the left-view video is outputted, the flag in the left-right processing storage unit  is set as the left-view output. Also, while the right-view video is outputted, the flag in the left-right processing storage unit  is set as the right-view output.","The display function flag holding unit  stores a 3D display function flag showing whether the playback apparatus  is capable of performing the 3D display or not.","The plane shift engine  shifts coordinates of each of pixel data pieces held in the image plane  and\/or coordinates of each of the pixel data pieces in the interactive graphics plane  in a predetermined direction (e.g. in a horizontal direction on a display screen) based on the flag in the left-right processing storage unit  and depth information on the data held in the graphics plane. That is, even if the objects of the graphics such as subtitles and the GUI used for data held in the image plane  and the data held in the interactive graphics plane  are not materials for the stereoscopic viewing, it is possible to obtain an effect that the objects are displayed in a position closer to the viewer than a position of the display screen. When the viewer wants only the graphics to have a stereoscopic effect with video displayed as 2 dimension, the composition unit  uses the left-view video for both the left view and the right view instead of using the set of the left-view video and the right-view video, and then composites the shifted data held in the image plane  and the shifted data held in the interactive graphics plane  with the video.","The shifting targets do not have to be both the data held in the image plane  and the data held in the interactive graphics plane . Shifting target can be done for only one of the planes, either the data held in the interactive graphics plane  or the data held in the image plane .","The plane shift engine  includes a storage area for storing a \u201cplane offset\u201d (offset value) showing a direction in which data is shifted, along with distance by which the data is shifted, for performing the shifting. For example, when the playback apparatus  includes a setup function that can set a plane offset value, the plane shift engine  stores a value set using the setup function. The playback apparatus  may have two offset values, one for the image plane , and the other for the interactive graphics plane , and chooses one of the offset values for use according to a shifting target. When the playback apparatus  does not have the setup function, \u201c0\u201d may be specified as a default (in this case, graphics such as the subtitles and the GUI are displayed in the position of the display screen, and there is no effect that an object pops out from the display screen).","The rendering engine  includes base software (e.g. Java 2D, OPEN-GL), and writes graphics and a character string in the interactive graphics plane  in accordance with the instruction from the BD-J platform  in the BD-J mode. Also, in the HDMV mode, the rendering engine  writes graphics data (e.g. graphics data corresponding to an input button) extracted from the graphics stream other than a stream corresponding to the subtitles (subtitle stream), and writes the extracted graphics data held in the interactive graphics plane .","The BD-J platform  is a Java platform which is a main operational part in the BD-J mode. The BD-J platform  is fully provided with the Java2Micro_Edition (J2ME) Personal Basis Profile (PBP 1.0) and Globally Executable MHP specification (GEM1.0.2) for package media targets. The BD-J platform  reads byte codes from a class file in the JAR archive file, and stores the heap memory to start the BD-J application. Then, the BD-J platform  converts byte codes composing the BD-J application and byte codes composing a system application into native codes, and causes the MPU to execute the native codes.","The dynamic scenario memory  stores current dynamic scenario, and is used for processing by the HDMV module which is the main operational part in the HDMV mode, and the Java platform which is the main operational part in the BD-J mode. The current dynamic scenario is a current execution target which is one of Index.bdmv, the BD-J object and the movie object recorded in the BD-ROM, the built-in media, or the removable media.","The display mode management module  stores Index.bdmv read from the BD-ROM, the built-in media, or the removable media, and performs mode management and branching control. The mode management by the mode management module  is to perform allocation of the dynamic scenario to the module (i.e. to cause one of the BD-J platform  and the HDMV module  to execute the dynamic scenario).","The HDMV module  is a DVD virtual player to be a main operational part in the HDMV mode, and is a main execution part. This module includes a command interpreter, and executes control of the HDMV mode by reading and executing the navigation commands composing the movie object. The navigation commands are written by a syntax similar to a syntax for the DVD-Video. Therefore, the playback control like the DVD-Video can be realized by executing these navigation commands.","The UO detection module  receives the user operation on the GUI. The user operation received by the GUI includes title selection determining which of the titles recorded in the BD-ROM is selected, subtitle selection and audio selection. In particular, one of the user operations unique to the stereoscopic playback is to receive the depth of stereoscopic video. For example, there are three levels of the depth such as distant, usual and close, or levels of the depth may be expressed by the numerical values such as how many centimeter or how many millimeter.","The still image memory stores still image data read from the BD-ROM (or configured virtual package).","The still image decoder decodes still image data read from the read buffer , and writes the uncompressed background image data held in the background plane .","The display mode storage unit  stores information on a display mode and information on a stereo mode. When the 3D display function flag of the playback apparatus  shows that the playback apparatus  is capable of displaying 3D video, the display mode which is a terminal setting stored in the display mode storage unit  may be switched to one of a 2D mode and a 3D mode. Hereinafter, a state of the display mode shown as \u201c3D\u201d is referred to as a \u201c3D display mode\u201d, and a state of the display mode shown as \u201c2D\u201d is referred to as a \u201c2D display mode\u201d.","When the playback apparatus  is in the 3D playback mode, the stereo modes of the planes are either ON or OFF. The difference between ON and OFF of the stereo modes affects compositing methods for the planes.","\u201cStereo mode ON\u201d is a 3D display mode in which composition is performed such that the playback apparatus  displays the left-view and the right-view that look different.","\u201cStereo mode OFF\u201d is a 3D display mode in which composition is performed such that the playback apparatus  displays the left-view and the right-view that look the same. That is, when viewed by both of the eyes, the picture does not look stereoscopic (planar). However, when the data held in the graphics plane  is shifted in the horizontal direction by the plane offset, the plane graphics data (subtitle data) that is held in the graphics plane  is to be displayed can be displayed in a position closer to the viewer than a position of the display screen, or in a position more distant from the viewer than a position of the display screen. The same effect can be obtained when offsets of video data held in the video plane , interactive graphics data held in the interactive graphics plane , and background image data held in the background plane  are adjusted when the \u201cstereo mode is in the OFF state\u201d.","As described in the above, there are two modes, \u201cStereo mode ON\u201d and \u201cStereo mode OFF\u201d in the \u201c3D display mode\u201d. When the playback apparatus  is in the \u201cStereo mode ON\u201d state in the 3D display mode, the left-view data and the right-view data (e.g. an image viewed by the left eye and the image viewed by the right eye can be seen from different angles) are held in the left-eye plane and the right-view plane, respectively, and displayed in accordance with the SYNC signal. This makes it possible to display the stereoscopic image.","Also, when the playback apparatus  is in the \u201cStereo mode OFF\u201d state in the 3D display mode, one of the left-view data and the right-view data (the left-view data held in the present embodiment) is held in each of the left-eye plane and the right-view plane, and the offsets of the stored data pieces are adjusted. This makes it possible to display the planar image in a position closer to or more distant from the viewer than the position of the display screen.","In the present embodiment, the \u201cStereo mode ON\u201d and the \u201cstereo mode OFF\u201d can be set for each plane (i.e. the video plane , the graphics plane , the interactive graphics plane  and the background plane ).","The \u201c2D display mode\u201d is a normal display that displays the image in a position corresponding to the position of the display screen. In such case, a decoder and a plane used in a default setting is predetermined, and the composited image is displayed with use of the decoder and the plane.","For example, when the playback apparatus  is in the \u201c2D display mode\u201d, the composition unit  composites: the 2D video data written by the video decoder in the left-eye video plane (expressed as the code (L) in the video plane  in ); the 2D graphics data (subtitle data) written by the image decoder in the left-eye plane (expressed as the code (L) in the image plane  in ); the 2D interactive graphics written by the BD-J application in the left-eye plane (expressed as the code (L) in the interactive graphics plane  in ) using the rendering engine ; and the still image data written by the still image decoder in the left-eye plane (expressed as the code (L) in the background plane  in ).","At this time, the composition unit  performs the composition in the order of the 2D still image data, the 2D video data, the 2D graphics data (subtitle data) and the 2D interactive graphics data in order from the data from the bottom. The composition may be performed without compositing the 2D still image data when the video data is displayed on the whole screen. The flag in the display mode storage unit  showing whether the playback apparatus  is in the 2D display mode or the 3D display mode may also be stored in the playback state register , or may be stored in both the display mode storage unit  and the playback state register .","The display mode setting initial display setting unit , sets the display mode and the resolutions based on the BD-J object in the current title provided with the BD-J platform unit.","This concludes a description of the internal structure of the playback apparatus . The following describes switching between the 2D display mode and the 3D display mode in the present embodiment in detail.",{"@attributes":{"id":"p-0197","num":"0198"},"figref":["FIG. 6","FIG. 6","FIG. 6","FIG. 6"],"b":["6","8","10","11"]},"Therefore, the same data is used for the left view and the right view in the 2D display mode. As a result, the same data is outputted.","On the right side of , an output model in the 3D display mode is shown. When the playback apparatus  is in the 3D display mode, the video plane , the image plane  (\u201cSubtitle\u201d in ) and the interactive graphics plane  are prepared for each of the left view and the right view. The picture data and the graphics data to be played back are held in each of the video plane , the image plane  (\u201cSubtitle\u201d in ), the interactive graphics plane  and the background plane  for the left eye and the right eye.","Therefore, the left-view output and the right-view output are performed separately in the 3D display mode. A different image can be provided for the left eye and the right eye. As a result, it is possible to obtain a 3D effect that the stereoscopic object in the screen appears to pop out closer to the viewer due to the binocular disparity.","(Specification of the Stereoscopic Effect)",{"@attributes":{"id":"p-0202","num":"0203"},"figref":"FIG. 7"},"Although  shows an example of a case where the stereo modes of the planes are the same, ON\/OFF of the stereo mode may be changed for each of the planes.","On the left side of , the plane structure when the stereo modes of all the planes are ON is shown. On the right side of , the plane structure when the stereo modes of all the planes are ON.","The first row shows the background plane  and the outputted data before the composition.","The second row shows the video stream and the outputted data before the composition.","The third row shows the image plane  and the outputted data before the composition.","The fourth row shows the interactive graphics plane  and the outputted data before the composition.","When the stereo mode is ON, a left-eye background plane which is expressed as an area to which (L) is given is used for writing the left-view background data, and a right-eye background plane which is expressed as an area to which (R) is given is used for writing the right-view background data. Each of the background data pieces is composited with the corresponding left-eye or right-view picture. When the stereo mode of the background plane  is OFF, the left-view background data is written, by the application, in each of the areas to which (L) and (R) are given respectively in the background plane . Therefore, the right-view background data does not affect the display.","When the stereo mode is ON, picture data of the left-eye video in the video stream is held in the left-view video plane. Also, picture data of right-eye video in the video stream is held in the right-view video plane. When the video plane  is in the OFF state of the stereo mode, the picture data of the left-eye video is held in both the left-view video plane and the right-view video plane.","When the stereo mode is ON, in the image plane , left-view image data is written in a left-eye image plane expressed as the area to which (L) is given, and right-view image data is written in a right-eye image plane expressed as the area to which (R) is given. Each of the image data pieces is composited with the corresponding left-eye or right-view picture.","When the image plane  is in the OFF state of the stereo mode, the subtitle graphics corresponding to the right-view image data does not affect the display. Also, when the stereo mode is OFF, the content in the image plane  is a content shifted in the right or left direction (\u201cShifted Left\u201d in ).","When the stereo mode is ON, in the interactive graphics plane , left-view interactive graphics is written in a left-view interactive graphics plane expressed as an area to which (L) is given, and right-view interactive graphics is written in a right-view interactive graphics plane expressed as an area to which (R) is given. Each of the interactive graphics data pieces is composited with the corresponding left-eye or right-view picture.","When the interactive graphics plane  is in the OFF state of the stereo mode, the right-view interactive graphics by the application does not affect the display. Also, when the stereo mode is OFF, the content in the interactive graphics plane  is a content that is shifted in the right or left direction (\u201cShifted Left\u201d in ).",{"@attributes":{"id":"p-0215","num":"0216"},"figref":"FIG. 8","b":["11","6","8","10","4","3","2","8","1","10"]},"Also, it can be seen that right-view background data u, right-view video u read from the video stream, right-view graphics u in the image plane  and right-view graphics u in the interactive graphics plane  are composited as the right view in this order.",{"@attributes":{"id":"p-0217","num":"0218"},"figref":["FIG. 9","FIG. 8","FIG. 9"],"b":["11","6","8","10","4","2","3","8","1","10"]},"Also, it can be seen that right-view background data r, left-view video r read from the video stream, Shifted Left graphics r which is the left-view graphics in the image plane  that has been shifted in a direction opposite to the predetermined direction (the left direction in ) and Shifted Left graphics r that is the left-view graphics in the interactive graphics plane  that has been shifted in a direction opposite to the predetermined direction (the left direction in ) are composited as the right view in this order.","In  to , offsets of the background data and the video were not adjusted (i.e. an offset is 0, more specifically, the image is displayed in the position of the display screen) strictly for the purpose of simplifying the above-stated description. Therefore, the setting of the offsets is not limited to the above-stated descriptions, and the offsets may be adjusted such that the video is positioned in a position more distant from the viewer than a position of the graphics image (subtitles), and the background data is in a position more distant from the viewer than a position of the background data.","The following describes switching between the stereo modes in the present embodiment.",{"@attributes":{"id":"p-0221","num":"0222"},"figref":"FIG. 10"},"Each of L and R are examples of composition results for the video plane . It can be seen from a difference in direction in which a woman faces that images in a left-view stream and images a right-view stream are taken from different angles. Note that a difference in directions in which a man and the woman face and a difference in positions of the man and woman are schematic, and show neither accurate directions in which the man and woman face nor accurate positions of the man and woman for realizing the stereoscopic display.","Subtitles \u201cI love you\u201d in the image plane  is an image obtained by decoding the subtitle data by the image decoder.","A GUI part in a form of the sun in the interactive graphics plane  is written in the interactive graphics plane  by the BD-J application.",{"@attributes":{"id":"p-0225","num":"0226"},"b":["6","6","6","6"]},{"@attributes":{"id":"p-0226","num":"0227"},"figref":"FIG. 11"},"A right-view image and a left-view image are filtered through the shutter glasses , for example, appear differently from each other to corresponding eyes. Observe that the subtitles \u201cI love you\u201d and the GUI part in the form of the sun are different in each of the right an left images in addition to the fact that the images of the video stream are made stereoscopic by compositing the left-eye and the right-eye images. Thus, it can be seen that the depths of the video, the subtitles and the GUI are maintained naturally by turning the stereo mode ON when both the right-eye and left-eye contents are prepared in advance.",{"@attributes":{"id":"p-0228","num":"0229"},"figref":["FIG. 12","FIG. 12"],"b":["500","6","6","8","10","6"]},"(Control for Realizing the Stereoscopic Effect)","The following describes a direction in which the data held in the graphics plane is shifted for realizing the stereoscopic effects.","Directions to which the plane shift engine  shifts the data held in the graphics plane depends on whether the data held in the graphics plane should stereoscopically appear in a position distant from the viewer than a position of the screen or should stereoscopically appear to pop out from the screen. In the present embodiment, it is presumed that the left-view images are shifted in the right direction (i.e. the data stereoscopically appears to pop out from the screen).","A difference between coordinates of each pixel data piece shifted in the right direction and coordinates of each pixel data piece shifted in the left direction is called a \u201cshift amount\u201d. Thus, the shift amount is calculated in a way that the outputted result controls the depth of the image plane  or the data held in the interactive graphics plane . Here, the depth value shows how close to or distant from the viewer data held in each plane is displayed. The shift amount also can be calculated with use of one of parameters that can be adopted as the binocular disparity between both of the eyes at a time of executing the stereoscopic playback.","The parameter for shifting the pixel data pieces in the graphics plane in the right and left directions by the above-stated shift amount is called \u201cplane offset\u201d. While the shift amount is a scalar amount, the plane offset is a vector having a positive or negative value. The plane offset indicates the direction, left direction or right direction, and the amount of shifting to be shifted in pixels from the current position. In the following description, the shifting is executed according to the plane offset. The plane offsets can be represented as the actual shift amount in pixels (with positive and negative value) or it can be represented as a value that can be used to calculate the actual shift amount in pixels.","The following describes the meanings of the positive and negative signs of the plane offset.","The plane offset of the graphics plane shows by how many pixels the coordinates of each of the pixel data pieces held in the right-view graphics plane and the coordinates of each of the pixel data pieces held in the left-view graphics plane are shifted.","When the viewer wants to obtain an effect that the video in the graphics plane pops out from the screen, the plane shift engine  shifts the data held in the left-view graphics plane in the right direction by the shift amount shown by the plane offset before the composition of data pieces in the planes. Then the plane shift engine  shifts the data held in the right-view graphics plane in the left direction by the shift amount shown by the plane offset. In the present embodiment, an effect that the images pops out from the screen can be obtained when the sign of the plane offset is a \u201cpositive sign\u201d.","When the viewer wants to obtain an effect that the images are displayed in a position distant from the viewer than the position of the screen, the plane shift engine  shifts the data held in the left-view graphics plane in the left direction by the shift amount shown by the plane offset before the composition of data pieces in the planes. Then the plane shift engine  shifts the data held in the right-view graphics plane in the right direction by the shift amount shown by the plane offset. In the present embodiment, an effect that the images are displayed in the position distant from the viewer than the position of the screen can be obtained when the sign of the plane offset is a \u201cnegative sign\u201d.","When the plane offset is \u201c0\u201d, the plane shift engine  does not perform the shifting, which means that the plane shift engine  intentionally omits the shifting.",{"@attributes":{"id":"p-0239","num":"0240"},"figref":["FIG. 13A","FIG. 13B"]},"As shown in , as a result of shifting the image plane  to the right direction, a transparent area at the left end exists, and an end portion of the image plane is cropped. Similarly, there is a transparent area at the left end of the interactive graphics plane  that is shifted in the right direction, and an end portion of the interactive graphics plane is cropped.","As shown in , as a result of shifting the image plane  to the left direction, a transparent area at the right end exists, and the left end portion of the image plane is cropped. Similarly, there is a transparent area at the right end portion of the interactive graphics plane  that is shifted in the left direction, and the left end portion of the interactive graphics plane is cropped.","Each of  and  shows the internal structure of the image plane . When the resolution is set to 1920*1080, the image plane  is composed of 8 bit-length memory elements, and has a size of 1920(horizontal)*1080(vertical) as shown in . This means that the image plane  has a resolution of 1920*1080, and has a memory allocation capable of storing an 8-bit pixel code for each pixel. The 8-bit pixel codes stored in the memory elements are converted into Y, CR and Cb values by color conversion using the color look-up table. The correspondence relationship among the pixel codes and the Y, CR and Cb values is defined by a pallet definition segment in the subtitle data.",{"@attributes":{"id":"p-0243","num":"0244"},"figref":["FIG. 14B","FIG. 14B"],"b":["8","8","6","8","6","10","6","15","8","11","6"]},{"@attributes":{"id":"p-0244","num":"0245"},"figref":["FIG. 15A","FIG. 15B","FIG. 15C","FIG. 15A","FIG. 15B","FIG. 15C"]},"This concludes the description of the internal structure of the image plane , and the description of the arrangements of pixel data pieces before and after the plane shift engine  performs the shifting in the image plane . The following describes the internal structure of the interactive graphics plane , and the arrangements of pixel data pieces held in the internal structure of the interactive graphics plane  before and after the shifting.","Each of  and  shows the internal structure of the interactive graphics plane . When the resolution is set to 1920*1080, the interactive graphics plane  is composed of 32 bit-length memory elements, and has a size of 1920*1080 as shown in . This means that the interactive graphics plane  has a resolution of 1920*1080, and has a memory allocation capable of storing a 32-bit R, G, B and \u03b1 values per pixel. The 32-bit R, G, B and a values are composed of an 8-bit R value, an 8-bit G value, an 8-bit B value and an 8-bit transparency \u03b1, respectively.",{"@attributes":{"id":"p-0247","num":"0248"},"figref":["FIG. 16B","FIG. 16B"],"b":["10","10","6","10","6"]},"The graphics data held in the background graphics plane , the video in the video plane  and the graphics data held in the image plane  can be seen through when the foreground plane has a transparent pixel and the composition unit  composites these data pieces in the respective planes. The transparent area contributes to realizing the composition.","This concludes the description of the pixel data pieces composing the foreground area and the pixel data pieces composing the background area after the shifting in the right direction and the shifting in the left direction have been performed.",{"@attributes":{"id":"p-0250","num":"0251"},"figref":["FIG. 17A","FIG. 17B","FIG. 17C","FIG. 17A","FIG. 17B","FIG. 17C"]},{"@attributes":{"id":"p-0251","num":"0252"},"figref":["FIG. 18A","FIG. 18B","FIG. 18C"],"b":"8"},{"@attributes":{"id":"p-0252","num":"0253"},"figref":"FIG. 18A"},{"@attributes":{"id":"p-0253","num":"0254"},"figref":["FIG. 18B","FIG. 18B"],"b":["1","1","1","2","1","3","1","1","19","8","1","2","19","8","1","3","19","8"]},{"@attributes":{"id":"p-0254","num":"0255"},"figref":["FIG. 18C","FIG. 18C"],"b":["2","1","2","2","2","3","2","1","19","8","2","2","19","8","2","3","19","8"]},"Next, meanings of the positive and negative signs of plane offsets are described.","When the playback apparatus  is in the 3D display mode and the stereo mode of the image plane  is OFF, the playback apparatus  perform the composition after performing the following processing in the planes based on the shift amount shown by the plane offsets.","When the positive sign of the plane offset is set, the plane shift engine  shifts coordinates of each of the pixel data in the left-view image plane  in the right direction by the shift amount indicated by the plane offset. Then, the plane shift engine  shifts coordinates of each of the pixel data in the right-view image plane  in the left direction by the shift amount indicated by the plane offset.","When the negative sign of the plane offset is set, the plane shift engine  shifts coordinates of each of the pixel data in the left-view image plane  in the left direction by the shift amount indicated by the plane offset before the composition of the data in the respective planes. Then, the plane shift engine  shifts coordinates of each of the pixel data pieces in the right-view image plane  in the right direction by the shift amount indicated by the plane offset.",{"@attributes":{"id":"p-0259","num":"0260"},"figref":["FIG. 19","FIG. 19B","FIG. 19C"],"b":"10"},{"@attributes":{"id":"p-0260","num":"0261"},"figref":"FIG. 19A"},{"@attributes":{"id":"p-0261","num":"0262"},"figref":["FIG. 19B","FIG. 19B"],"b":["1","1","1","2","1","3","1","1","19","10","1","2","19","10","1","3","19","10"]},{"@attributes":{"id":"p-0262","num":"0263"},"figref":["FIG. 19C","FIG. 19C"],"b":["2","1","2","2","2","3","2","1","19","10"]},"(-) The plane shift engine  shifts the coordinates of each of the pixel data pieces in the interactive graphics plane  horizontally in the left direction by a shift amount indicated by the plane offset. (-) The plane shift engine  adds a transparent area at the left end of the interactive graphics plane .","The following describes the size of the right end area and left end area of the graphics data to be cropped, and the size of the areas to be added at the right end and left end of the graphics data, in the interactive graphics plane , at the time of shifting the coordinates of each of the pixel data pieces in the respective planes. The plane offset used for the above-stated shifting is a value that responds to the binocular disparity between the right eye and the left eye. This means that each of: the number of horizontal pixels composing the right end area to be cropped; the number of horizontal pixels composing the left end area of the graphics data to be cropped in the graphics plane; and the number of horizontal pixels composing the transparent area to be added at each of the right and left ends of the graphics data held in the graphics plane need to be the number of pixels corresponding to the plane offset.","Therefore, the number of horizontal pixels composing the right end area to be cropped and the number of horizontal pixels composing the left end area to be cropped in the graphics plane is the number of pixels corresponding to the shift amount indicated by the plane offset. Also, the number of vertical pixels composing the transparent areas is the number of pixels corresponding to the height of the graphics plane.","Similarly, the number of horizontal pixels composing the transparent areas to be added at each of the right and end ends of the graphics image held in the graphics plane is the number of pixels corresponding to the shift amount indicated by the plane offset. The number of vertical pixels composing the transparent areas is the number of pixels corresponding to the height of the graphics plane.","This concludes the description of the process of shifting the image plane  and the interactive graphics plane . The following describes the meanings of the positive and negative signs of the plane offset.","When the playback apparatus  is in the 3D playback mode, and the stereo mode of the interactive graphics plane  is OFF, the playback apparatus  performs the composition after performing the following process in the planes based on the plane offset.","When the positive sign of the plane offset is set, the plane shift engine  shifts the left-view graphics plane in the right direction by the shift amount shown by the plane offset. And, the plane shift engine  shifts the right-view graphics plane by the shift amount shown by the plane offset.","When the negative sign of the plane offset is set, the plane shift engine  shifts the left-view graphics plane in the left direction by the shift amount shown by the plane offset. And, the plane shift engine  shifts the right-view graphics plane in the right direction by the shift amount shown by the plane offset.",{"@attributes":{"id":"p-0271","num":"0272"},"figref":["FIG. 20A","FIG. 20B"]},"An image depicting the graphics data that is closer to the viewer in each of  and  is a graphics image for the right view (right-view graphics image) after shifting. An image depicting the graphics data that is distant from the viewer in each of  and  is a graphics image for the left view (left-view graphics image) after shifting.",{"@attributes":{"id":"p-0273","num":"0274"},"figref":"FIG. 20A","b":"19"},{"@attributes":{"id":"p-0274","num":"0275"},"figref":"FIG. 20B"},"This concludes the description of the method for displaying the subtitles in a position closer to the viewer than the position of the display screen or in a position more distant from the viewer than the position of the display screen by switching between the positive offset and the negative offset.",{"@attributes":{"id":"p-0276","num":"0277"},"figref":["FIG. 31A","FIG. 31B","FIG. 31C"],"b":"19"},"In each of ,  and , a circle is an image displayed on the display screen.","Firstly, since the image seen by the right eye and the image seen by the left eye are in the same position when there is no offset, the focus position at which both of the eyes see the image is on the display position ().","Meanwhile, when the playback apparatus  is in the 3D display mode, and the stereo mode is OFF, the image seen by the left eye should appear in a position more to the right compared to the case where the offset is \u201c0\u201d. At this time, the right eye should be covered by the crystal liquid shutter glasses so that the right eye cannot see anything. The image seen by the right eye, on the other hand, should be in a position more to the left compared to the case where the offset is \u201c0\u201d. At this time, the left eye should be covered by the crystal liquid shutter glasses so that the left eye cannot see anything ().","We focus on the image with use of both of the eyes to recognize the image in the focus position. Accordingly, when switching between a state in which the left eye sees the image and a state in which the right eye sees the image is performed by the crystal liquid shutter glasses at a short time interval, both of our eyes try to focus on the image in a position closer to us than the position of the display screen. As a result, we have an illusion as if the image is in the focus position closer to us than the position of the display screen ().",{"@attributes":{"id":"p-0281","num":"0282"},"figref":["FIG. 42","FIG. 42B","FIG. 42C"],"b":"19"},"In each of ,  and , a circle is an image displayed on the display screen. Firstly, since the image seen by the right eye and the image seen by the left eye are in the same position when there is no offset, the focus position at which both of the eyes see the image is the position of display screen ().","Meanwhile, when the playback apparatus  is in the 3D display mode, and the stereo mode is OFF, the image seen by the left eye should appear in a position more to the left compared to the case where the offset is \u201c0\u201d. At this time, the right eye should be covered by the crystal liquid shutter glasses so that the right eye cannot see anything. The image seen by the right eye, on the other hand, should be in a position more to the right compared to the case where the offset is \u201c0\u201d. At this time, the left eye should be covered by the crystal liquid shutter glasses so that the left eye cannot see anything ().","When switching between a state in which the left eye sees the image and a state in which the right eye sees the image is performed by the crystal liquid shutter glasses at a short time interval, both of our eyes try to focus on the image in a position more distant from us than the position of the display screen. As a result, we have an illusion as if the image is in the focus position more distant from us than the position of the display screen ().","This concludes the description of the graphics image written in the graphics plane. However, it is needless to say that the same concept of the above-stated offset may be applied to the interactive graphics plane , the video plane  and the background plane .","(Shifting of the Coordinates of the Pixel Data in the Respective Memory Elements in the Graphics Plane)","The following describes how the plane shift engine  shifts coordinates of the pixel data in the memory elements in the graphics plane due to the above-stated shifting. The graphics data is composed of pixel data pieces, and has a resolution 1920*1080 or 1280*720, for example.",{"@attributes":{"id":"p-0288","num":"0289"},"figref":["FIG. 21","FIG. 21"]},"The pixel data in a pair of coordinates (0, 0) is stored in the memory element whose address is 0001. The pixel data whose coordinates are (1, 0) is stored in a memory element whose address is 0002. The pixel data whose coordinates are (1918, 0) is stored in a memory element whose address is 07A7. The pixel data whose coordinates are (0, 1) is stored in a memory element whose address is 07A9. That is, it can be seen that graphics data is stored such that a plurality of lines composing the graphics are composed of memory elements having serially-arranged addresses thus, these pixel data pieces may be read in a burst mode by sequentially performing the DMA transfer on the memory elements to which the serial addresses are given.","Each of  and  shows what is held in the graphics plane after the shifting has been performed.",{"@attributes":{"id":"p-0291","num":"0292"},"figref":"FIG. 22A"},"Also, it can be seen that pixel data whose coordinates are (0, 1) in the graphics plane coordinate system is stored in a memory element whose address is 07AC, pixel data whose coordinates are (1, 1) in the graphics plane coordinate system is stored in a memory element whose address is 07AD, and pixel data whose coordinates are (2, 1) in the graphics plane coordinate system is stored in a memory element whose address is 07AE.",{"@attributes":{"id":"p-0293","num":"0294"},"figref":"FIG. 22B","b":"19"},"Also, it can be seen that pixel data whose coordinates are (3, 1) in the graphics plane coordinate system is stored in a memory element whose address is 07A9, pixel data whose coordinates are (4, 1) in the graphics plane coordinate system is stored in a memory element whose address is 07AA, and pixel data whose coordinates are (5, 1) in the graphics plane coordinate system is stored in a memory element whose address is 07AB.","As described in the above, it can be seen that, in the graphics plane after the shifting has been performed, the coordinates of each of the pixel data in the graphics plane are shifted to the right or left from the original coordinates of each of the pixel data pieces by the number of pixels shown by the plane offset.","In order to realize the shifting in the graphics plane, the plane shift engine  needs to shift the coordinates of each of the pixel data composing the graphics data by an amount indicated in a predetermined address, an address of a memory element on which each of the pixel data pieces composing the graphics data is positioned. It is needless to say that the plane shift engine  can realize the shifting in the graphics plane without changing the address of the memory element on which each of the pixel data pieces is arranged, by performing processing that corresponds to the above-stated processing.","This concludes the description of what is held in the graphics plane after the plane shift engine  has performed the shifting.",{"@attributes":{"id":"p-0298","num":"0299"},"figref":["FIG. 23","FIG. 23"],"b":["31","32","33","34","35"]},"The heap memory  is a stack area on which the byte code of the system application, the byte code of the BD-J application, a system parameter used by the system application and an application parameter used by the BD-J application are arranged.","The byte code interpreter  converts the byte codes composing the BD-J application stored in the heap memory  and byte codes composing the system application into native codes, and causes the MPU to execute the converted codes.","The middleware  is an operating system for the embedded software, and is composed of a kernel and a device driver. The kernel provides the BD-J application with functions specific to the playback apparatus  in accordance with calls of the application programming interface (API) from the BD-J application. Also, the kernel realizes hardware control such as starting an interrupt handler unit by an interrupt signal.","The class loader  is one of the system applications, and loads the BD-J application by reading the byte codes from the class files that exist in the JAR archive file, and storing the byte codes in the heap memory .","The application manager  is one of the system applications, and performs the application signaling of the BD-J application such as starting the BD-J application or ending the BD-J application, based on the application management table in the BD-J object.","This concludes the description of the internal structure of the BD-J platform unit.","In the above-stated layer model, the display mode setting initial display setting unit  is in the lower layer of the platform unit, which sets a display mode and a resolution based on the BD-J object in the current title used by the BD-J platform unit.","(Internal Structure of the Display Mode Storage Unit )","The display mode storage unit  can be referred to from the above-stated layer model. Therefore, the display mode storage unit  can be referred to from the layer model via the API, and includes information showing a setting and a state of each of the background graphics plane , the video plane , the image plane  and the interactive graphics plane . The following describes the structure of the display mode storage unit , referring to .",{"@attributes":{"id":"p-0308","num":"0309"},"figref":"FIG. 24","b":"29"},"In , the display mode storage unit  stores information on the setting of the background plane , information on the setting of the video plane , information on the setting of the image plane , information on the setting of the interactive graphics plane , and information on the state of the display mode showing whether the playback apparatus  is in the 2D mode or the 3D mode. \u201cResolution (:YY\u00d7ZZ in FIG. )\u201d and a stereo mode (:ON or OFF in ) and a setting of THREE_D (:ON or OFF in ) are stored as setting items of each plane. Besides the above-stated setting items, the plane offset may be set in a range of \u201c\u221263\u201d to \u201c+63\u201d in the setting of the image plane  and the setting of the interactive graphics plane .","The following describes the resolution supported by the display mode storage unit .","When the playback apparatus  is in the 2D display mode, the display mode storage unit  supports a resolution of 1920*1080 pixels, a resolution of 1280*720 pixels, a resolution of 720*576 pixels, and a resolution of a 720*480 pixels for the background plane , the video plane , the image plane  and the interactive graphics plane , as the initial display setting. When the playback apparatus  is in the 3D display mode, the display mode storage unit  may support a resolution of 1920*2160 pixels or a resolution of 1280*1440 pixels for each of the background plane , the image plane  and the interactive graphics plane  in addition to the resolution of the 2D display mode. In such case, an aspect ratio of 1920*2160 pixels or an aspect ratio of 1280*1440 pixels will be an aspect ratio of (16\/18), and an upper half of each plane is used as an area for the left eye, and a lower half of each plane is used as an area for the right eye.","This concludes the description of what is stored in the display mode storage unit .","The following describes the case where the THREE_D setting of each plane changes.","Firstly, it is necessary to change a setting of each plane in the display mode storage unit  as condition when the display mode is switched. For example, when the display mode is set to the 2D display mode, the THREE_D setting of each plane needs to be OFF. Also, when the display mode is set to the 3D display mode, the THREE_D setting of each plane needs to be ON.","The following describes a case where a stereo mode and a plane offset are reset.","When the playback apparatus  falls in the 2D display mode as a result of the title selection, the stereo mode of each of the background plane , the video plane , the image plane  and the interactive graphics plane  is switched to OFF, and the shift amount of each of the image plane  and the interactive graphics plane  shown by the offset is set to \u201c0\u201d.","When the display mode cannot be determined before the title selection, the display mode before starting the title is the 2D display mode.","The following describes what causes the switching between the display modes to be performed.","The display mode in the display mode storage unit  is possibly switched in one of two: a case where the playlist is switched, and a case where the BD-J application expressly gives an instruction for the switching by a method call.","The following describes patterns of switching between the display modes caused by playback of the playlist.","The following describes the pattern in which the display mode is changed by the playback of the playlist. When the 2D playlist is played back in the 3D display mode, the playback apparatus  automatically switches the display mode in the display mode storage unit  to the 2D display mode. When the display mode is switched, an event is generated asynchronously to the event listener registered in the BD-J application.","The display mode is not switched even if the playback of the playlist is stopped. That is, the display mode always remains in the current state even after the playback of the playlist is stopped.","The following describes the initial display setting by the display mode setting initial display setting unit .","The initial display setting is a value set \u201cat the time of starting the title\u201d of the display setting such as a resolution stored in the display mode storage unit .","The following describes what affects the initial display setting.","When the 3D display function flag shows that the playback apparatus  is capable of displaying 3D graphics, the initial display setting is not determined based on only the auto start playlist (playlist) of the 2D playback apparatus or the default setting described in the BD-J object. The determination of the initial display setting is also affected by the 3D display mode before the title selection.","The following describes criteria for determining the initial display setting. The initial display setting is determined based on the default start playlist.","When there is a auto start playlist, the playback apparatus  sets a resolution for the 2D graphics corresponding to a resolution of the video of the auto start playlist after automatically switching the display mode to the 2D display mode when the playback apparatus  is in the 3D display mode, and the playlist is a 2D playlist.","When there is the auto start playlist, and the auto start playlist does not affect the display mode, the playback apparatus  selects the initial display setting of a resolution corresponding to a resolution of a video from among resolutions supported by the display mode before the title selection, and sets the resolution.","The following describes a case where the resolution and the plane offset do not change.","When there is the auto start playlist, and the playback apparatus  switches to 3D display mode as a result of the title selection, stereo mode values (described in the following) of the background plane , the video plane , the image plane  and the interactive graphics plane  do not change, and the plane offset for each of these planes does not change, either.","The following describes the criteria for determining the setting when there is no auto start playlist.","When there is no auto start playlist, the initial display setting is always determined based on a value of the default resolution that is written in the BD-J object and corresponds to the selected title. In this case, the determination of the initial display setting is not affected by the display mode before starting the title.","The following describes a case where the stereo mode and the plane offset are reset.","When the title is selected in which the auto start playlist does not exist, the stereo mode of each of the image plane  and the interactive graphics plane  is ON if the display mode is the 3D display mode, and the stereo mode of each of the background plane  and the video plane  is OFF.","Furthermore, when the display mode is switched from the 3D display mode to the 2D display mode, a stereo mode of each plane is set to OFF, and the shift amount shown by the plane offset is set to \u201c0\u201d.","(Switching Between Display Modes when a Title is Changed)","As described in the above, there are information on resolutions and specification of the auto start playlist for each of the BD-J objects corresponding to the titles. Therefore, when a title is changed, the corresponding BD-J object is also changed. Thus, the content of the display mode set in the display mode storage unit  also changes accordingly. The following describes how the display mode changes when the title is changed, with use of .",{"@attributes":{"id":"p-0339","num":"0340"},"figref":["FIG. 25","FIG. 25"]},"The default playlists and the default resolutions are in the exclusive relationship. If the auto start playlist exits in the title (i.e. the title is valid), the display mode responds to the resolution stipulated in the auto start playlist. If the auto start playlist does not exist in the title (i.e. the title is invalid), the display mode responds to the resolution stipulated in the auto start playlist.","The upper part CR of the table shows the display mode setting when the auto start playlist exists in the title (i.e. the title is valid), and the lower part CR of the table shows the display mode setting when the auto start playlist does not exist in the title (i.e. the title is invalid).","According to the contents written in the upper part of the table, when the immediately preceding display mode is a 3D display mode, and the auto start playlist is a 3D playlist, the display mode is set as the 3D output. In other cases, the display mode is set as the 2D output.","According to the contents written in the lower part of the table, when the immediately preceding display mode is a 2D display mode or a 3D display mode, and the default-resolution is HD3D1920*1080, or HD3D1280*720, the display mode is set as the 3D output.","(Change in Display Modes in a Title)","A title is not always composed of one playlist such as auto start playlist. The title is composed of a plurality of playlists in some cases. When the title is composed of a plurality of playlists, the setting of the display mode in the display mode storage unit  is switched when the playback of the playlist is changed. The following describes how the display mode changes when the playlist changes in a title.",{"@attributes":{"id":"p-0346","num":"0347"},"figref":["FIG. 26","FIG. 26"]},"When the current display mode is a 3D display mode, and there is no playlist being played back (e.g. when only the interactive graphics is displayed or the interactive graphics and the background data are composited and displayed), or processing to be performed is playback of the 3D playlist, the display mode is set as the 3D display mode.","When the current display mode is a 3D display mode, and there is no playlist being played back (e.g. when only the interactive graphics is displayed or the interactive graphics and the background data are composited and displayed), or the display mode of the processing to be performed is set as the 3D display mode by the BD-J application, the display mode is set to be the 3D display mode.","When the current display mode is a 2D or 3D display mode, and there is no playlist being played back, or the playlist is a 3D playlist, the display mode is set as the 3D display mode if the display mode by the BD-J application of the processing to be performed is the 3D display mode.","This concludes the description of switching between the display modes when the playlist being played back is changed in the titles.","The following describes the components of the middleware. In , the middleware  includes a plane control module .","If the BD-J application sets the stereo mode of the background plane  in the display mode storage unit  to ON, the composition unit  performs composition such that the data held in the background plane  that is written for the left eye is used for the left view, and the data held in the background plane  that is written for the right eye is used for the right view. When the stereo mode of the background plane  is set to OFF, the data held in the background plane  for the right eye and the left eye should be the same. In case a vertically long area is used as the background plane , the upper half of the area is used for the left view, and the lower half of the area is used for the right view. Note that when the stereo mode of the background plane  is set to OFF in such a case, the writing performed in the lower half of the area by the application does not affect the display.","The method for specifying the stereoscopic effect of the image plane  and the interactive graphics plane  is performed by stereo mode properties in the image plane  setting and the interactive graphics plane  setting. When the stereo mode is set to ON by the stereo mode property, the composition unit  performs the composition such that the data held in the image plane  and the data held in the interactive graphics plane  that have been written for the left eye are used for the left view, and the data held in the image plane  and the data held in the interactive graphics plane  that have been written for the right eye are used for the right view, as with the background plane . When the stereo mode is set to OFF, each of the data held in the image plane  for the left eye and the right eye; and the data held in the interactive graphics plane  for the left eye and the right eye should be the same. In case a vertically long area that combins left-view and right-view is used for the image plane  and\/or the interactive graphics plane , the composition unit  performs the composition such that the upper half of the area is used for the left view, and the lower half of the area is used for the right view. Note that when the stereo mode of the image plane  and the stereo mode of the interactive graphics plane  are set to OFF in such a case, the writing performed in the lower part of the area by the application does not affect the display.","The plane control module  is composed of libraries for the plane control, and realizes the plane control by the API call from the platform unit.","(API Used for the Setting of the Display Mode Storage Unit )","The display mode storage unit  described in the above exists in a position closer to the physical layer in the software layer model of the playback apparatus . Therefore, the contents in the display mode storage unit  can be changed through the application programming interface. The following describes the setting of the display mode storage unit  by instructions from the application, with reference to  and . The following describes the application programming interface provided to the application by the plane control module .",{"@attributes":{"id":"p-0357","num":"0358"},"figref":["FIG. 27A","FIG. 27B"],"b":"29"},{"@attributes":{"id":"p-0358","num":"0359"},"figref":"FIG. 27A"},"The following describes the acquisition of the plane status.","The BD-J application specifies, for example, a plane to acquire as an argument, and call the getConfigTemplate method to acquire a template expressing the status of the plane as the argument.  shows four templates that can be acquired by the method. These four templates show the background plane  setting, the video plane  setting, the image plane  setting, the interactive graphics plane  setting, respectively.","Although the present embodiment shows the structure in which the plane offset cannot be set in the background plane  setting and the video plane  setting, a structure in which the plane offset can be set is possible. In order to simplify the description, the following describes a structure in which the plane offset cannot be set in the background plane  setting and the video plane  setting.","The following describes a THREE_D setting first.","The BD-J application acquires information on a parameter that can be set from the acquired template, specifies, as an argument, a parameter that can be set if necessary, and call the setPreference method to set the parameter that has been set as the argument. For example, when the parameter can be set as THREE_D setting, the BD-J application specifies the parameter as the argument, and calls the setPreference method to set the THREE_D setting to ON or OFF. Also, the result of whether or not the application has succeeded in the setting.","When the BD-J application acquires the current display setting, the gefCurrentConfiguration is used. The getCurrentConfiguration is an API that causes the BD-J application to acquire the display setting of each plane (the background plane , the video plane , the image plane , the interactive graphics plane ) such as display mode and the stereo mode that are currently set in the display mode storage unit .","Also, the getBestConfiguration method gives the BD-J application the best setting information of each plane (the background plane , the video plane , the image plane  and the interactive graphics plane ) in the playback apparatus .","Also, when the setCoherentConfigurations method is called from the BD-J application, individual plane setting can be specified at once (the background plane , the video plane , the image plane  and the interactive graphics plane ).","For example, when THREE_D setting of each plane (the background plane , the video plane , the image plane  and the interactive graphics plane ) is ON, the BD-J application specifies information for setting the THREE_D setting ON as the argument, and calls the setCoherentConfiguration method to set the THREE_D setting of each plane (the background plane , the video plane , the image plane  and the interactive graphics plane ) ON.","Also, when the BD-J application specifies the resolution as the argument, and calls the setCoherentConfiguration method, the resolution of each plane (the background plane , the video plane , the image plane  and the interactive graphics plane ) can be the same.","Although a description is given of a structure in which the BD-J application specifies the THREE_D setting and the resolution as arguments, and calls the setCoherentConfigurations method, the BD-J application may specify a plurality of parameters as arguments at once, and call the setCoherentConfigurations method.","While the setCoherentConfigurations method can set the setting of each plane at once, the setConfiguration method can change the setting of the planes specified as the arguments.","The following describes the configuration setting.","If the BD-J application specifies the configuration as the argument with use of the template changed by the setPreference method, and calls the setConfiguration method, or calls the setCohetentConfigurations method, the configuration is reflected in the display mode storage unit .","The following describes in what case the display mode changes.","When the BD-J application changes the display mode, the setConfiguration method is used. However, as a restriction, the BD-J application is not allowed to switch the display mode during the playback of the 2D playlist.","The following describes in what case switching between the displays modes fail.","The request for switching between the display modes by the BD-J application fails in the following case.","1. In a case where some of the THREE_D settings of each plane set at the time of calling the setCoherentConfiguration method is ON and some are OFF.","2. In a case where the BD-J application attempts to set the display setting of the THREE_D setting to ON during the playback of the 2D playlist.","3. In a case during when the THREE_D setting is OFF the stereo mode gets specified to turn ON.","In the above-stated cases 1 to 3, the getBestConfiguration method fails.","Furthermore, the following structure may be possible. The BD-J application makes a display mode switching request for the 3D display mode, and acquires, from the display device connected to the playback apparatus , information showing whether the display device is capable of display the 3D graphics. When the information indicates that the display device is not capable of displaying the 3D graphics, the display device replies to the BD-J application that it is not possible to responds to the request (i.e. processing for executing the request fails).","This concludes the description of the API used for settings in the display mode storage unit .","(Setting of the Plane Offset)","The shifting amount used when the plane shift engine  performs the shifting, needs to be calculated to pixel value prior to shifting process. It is desirable to adopt a plane offset for the stereoscopic viewing embedded in the MVC (Multi View Codec) video stream as a parameter for calculating the shift amount. However, the parameter for calculating the shift amount is not limited to this, and it may be preferable that the parameter is provided to the plane shift engine  through various information elements that the content provider provides to the playback apparatus  through the BD-ROM, depending on the use case.","The following describes the processing for setting the plane offset with reference to .",{"@attributes":{"id":"p-0386","num":"0387"},"figref":"FIG. 28","b":["20","19","19","20"]},"(AA) The writing control unit can update the plane offset in the plane setting in the display mode storage unit  by the method call of the setOffsetValue by the BD-J application.","The above-stated offset can be obtained by the BD-J application in the getOffsetValue method.","When the BD-J application calls the API; and the plane offset is embedded in the BD-J application, the flexibility is high, but the ability to change offset in real-time according to depth of the video is difficult. When the plane shift engine  refers to the offset specified by the BD-J application, the writing control unit in the offset setting unit  writes the offset value in the display mode storage unit  to the plane offset value in the plane shift engine . The plane shift engine  automatically shifts the plane in the horizontal direction based on the plane offset values at the time of the composition.","The following describes timing of the setting.","At any time after the application has been started, the started application can call the API that changes the depth of data held in each of the image plane  and the interactive graphics plane . This is whether the video is stopped or not. In either case (video is played or not at the time of API call), it is possible to ensure that the shift amount for the right view is in synchronization with the shift amount for the left view, by controlling timing of setting the plane offset value (from the display mode storage unit ) in the plane shift engine .","Specifically, the writing control unit does not update the plane offset value in the plane shift engine  at timing that the BD-J application calls the setOffset( ). It is checked whether or not the writing control unit has updated the plane offset in the display mode storage unit  at a time when one frame worth of the left-view and one frame worth of the right-view data have been outputted. In accordance with the update, the writing control unit updates the offset value of the plane shift engine . Thus, it is possible to ensure that the shift amount for the right-view is in synchronization with the shift amount for the left view. When the shift amount for the right view is not in synchronization with the shift amount for the left view, the display appears in a way that is not intended by the content creator, which results in providing the unpleasant outputted video to the viewer.","(BB) When the BD-ROM is loaded, or when virtual package is constructed, the writing control unit updates the plane offset value in the plane shift engine  read from the meta file (ZZZZZ.xml) stored in the META directory specified by the BD-ROM or the virtual package.","(CC) When reading and decoding of the MVC video stream starts, the writing control unit updates, to the plane offset value in the plane shift engine , the plane offset embedded in a header area of each of the PES packets that compose the MVC video stream. Desirably, when output of one frame worth of the left-view data and one frame worth of the right-view data has completed, the writing control unit updates the offset corresponding to the next frame to be processed to a plane offset value in the plane shift engine .","In case the plane offset is embedded in the MVC video stream, since offset can be set for each video frame, the plane offset can be shifted dynamically but the cost of authoring can become a burden.","(DD) When the reading and decoding of the transport stream starts, the writing control unit updates the plane offset embedded in the header area of the transport stream to the plane offset value in the plane shift engine . Desirably, when output of one frame worth of the left-view data and one frame worth of the right-view data has completed, the writing control unit updates the offset corresponding to the frame being processed as a plane offset value in the plane shift engine .","In a case where the plane offset value is embedded in the stream, the offset value may be shifted dynamically with the video. Therefore, the real time property is high, but the cost of authoring can become a burden.","(EE) When the current playlist is determined, and the playlist information is loaded, the plane offset of the playlist information is set to a plane offset value in the plane shift engine . When the playlist information is used for determining the offset, flexibility is high at the time of authoring. However, compared to the case where the offset is embedded in the stream, it is not possible to shorten the time interval from a time point at which an offset is set to a time point at which the offset is updated. Therefore, the real-time property is a little poor.","(FF) Receiving the user operation that changes the level of the depth of image plane  and the data held in the interactive graphics plane  by the operation of the button attached to a remote control or a device (i.e. the depth is expressed by the three levels such as \u201cdistant\u201d, \u201cnormal\u201d and \u201cclose\u201d, or depth is expressed by the numerical values such as \u201chow many cm\u201d or \u201chow many mm\u201d), the UO detection module  updates the plane offset value in the plane shift engine  with use of the user operation. This update increases or decreases the plane offset depending on the number of times the right-arrow key of the remote control is pressed. Thus, the graphics can be displayed closer to the viewer or distant from the viewer by changing the number of times the right arrow or the left arrow is pressed. This enhances the operational property.","The shift amount by which the image plane  and the interactive graphics plane  are shifted is obtained by performing the calculation based on the plane offset in the plane shift engine  after the above-stated processing is performed. The reason why the calculation processing is necessary is that while the shift amount of the pixel data pieces in each of the image plane  and the interactive graphics plane  is defined by the number of pixels, the plane offset is often defined by units different from units of pixels.","If the plane offset is embedded in the MVC video stream, the plane shift engine  calculates the shift amount by which the coordinates of the pixel data pieces held in the graphics plane based on the shift amount shown by the plane offset that the offset setting unit have stored in the plane shift engine , when output of one frame worth of the left-view data and one frame worth of the right-view data have completed. This is because the plane offset is possibly changed for each frame in some cases when the plane offset is stored in the MVC video stream.","This concludes the description of the various cases where the offset setting unit  sets the plane offset. The following describes a value provided by the user operation or the application.","The value provided from the user operation or the application may not be the actual shift amount in pixels, but is possibly an adjusted value from the value set in the current-state plane shift engine . In such case, the calculation of the plane offset value needs to be executed. For example, when the right-arrow key is pressed three times or a value \u201c3\u201d of a numerical value key is inputted, the plane shift engine  adds this value to the plane offset set in the apparatus, and calculates the plane offset based on the added value. When the value is a \u201c+\u201d value, the shift amount is decreased, and the graphics appears to be more distant from the viewer, for example. When the value is a \u201c\u2212\u201d value, the shift amount is increased, and the graphics appears to be closer to the viewer, for example.","The following describes a change in depth.","As described in the above, when graphics such as subtitles and GUIs are shifted along the horizontal axis, the depth is changed by changing a shift amount for the subtitles, and shift amount for the GUI along the horizontal axis. For example, the closer the left-view subtitles and the right-view subtitles become in a predetermined direction, the closer the graphics are displayed to the screen. The more distant the left-view subtitles and the right-view subtitles become from one another in an opposite direction, the more distant the graphics are displayed from the screen. However, the relationship between the plane offset and the pop-out level is greatly affected by the number of inches of the TV and the characteristic of the liquid crystal of the 3D glasses. By setting stated coefficients in the terminal in advance, a value obtained by multiplying the plane offset by this coefficient can be used for the shifting in order to realize such an optical effect. Multiplying the plane offset by the coefficient in such a manner makes it possible to adjust the pop-out level of the stereoscopic video based on the characteristics of the TV, the playback apparatus  and the liquid crystal of the 3D glasses.","The following describes the various methods for shifting the coordinates of each of the pixel data pieces.","When the coordinates of each of the pixel data pieces is shifted in the left direction in the image plane  and the interactive graphics plane , shifted data obtained as a result of the shifting is held in each of the planes. At the timing when the data for the right view is played back, it is possible to adopt a method of shifting the shifted data held in the graphics plane in a direction opposite from the left direction by a shift amount twice as much the above-stated shift amount. In this case, it is not necessary to perform the image decoding twice.","This concludes the description of the internal structure of the playback apparatus .","(Implementation of the Display Mode Setting Initial Display Setting Unit )","The following describes the implementation of the display mode setting initial display setting unit . During a time period in which one title is selected, and a BD-J object corresponding to the title is valid in the playback apparatus , a new playlist is played back in some cases if the application in operation calls the JMF player instance according to the user operation. When the new playlist is played back, it is necessary to make the setting of the display mode again in the title.","The function of the display mode setting initial display setting unit  is to support: the display mode setting in the title when the title changes; the display mode setting when the playlist changes in the title; and the display mode setting set when the application expressly calls the API. Specifically, the display mode setting initial display setting unit  may be implemented by: creating a program that causes the MPU to execute the processing procedures shown in ; and installing the program in the playback apparatus .",{"@attributes":{"id":"p-0412","num":"0413"},"figref":"FIG. 29","b":["24","25","27","21","22","23","26"]},"Step S is a judgment of whether the auto start playlist exists or not, and Step S is a judgment of whether the immediately preceding display mode is a 3D display mode. Step S is a judgment of whether or not the auto start playlist of the selected title is a 3D playlist with a resolution of 1920*1080 or a 3D playlist with a resolution of 1280*720.","When the auto start playlist does not exist, it is judged whether the default resolution of the BD-J object is HD3D1920\u00d71080, or HD3D1280\u00d7720 in Step S. If the judgment of Step S is Yes, the display mode is set to a 3D display mode, and the resolution is set to 1920\u00d71080 or 1280\u00d7720 in Step S.","If the judgment of Step S is No, the display mode is set to a 2D display mode in Step S, and the resolution is set to a default resolution in the BD-J object.","When the auto start playlist does exists, it is judged whether or not the immediately preceding display mode is the 2D display mode in Step S. If Step S is Yes, it is judged whether or not the playlist is a 3D playlist in Step S and the resolution is 1920*1080 and 1280*720 in Step S. If the judgment of Step S or Step  is No, the display mode is set to the 2D display mode, and a resolution is set to the resolution of the auto start playlist in Step S.","If the judgment of Step S is Yes, and the judgment of Step S is also Yes, the display mode is set to a 3D display mode, and the resolution is set to 1920*1080 and 1280*720 according to the resolution of the auto start playlist in Step S.","This concludes the description of processing procedures for setting the display modes in the title.",{"@attributes":{"id":"p-0419","num":"0420"},"figref":"FIG. 30","b":["31","32","31","34","32","33","34"]},"This concludes the description of the processing procedures for setting the display mode in the title.","(Implementation of the Playback Control Engine )","When a current playlist is selected due to some factor, the playback control engine  plays back the current playlist. Specifically, the playback control engine  needs to realize processing of: reading playlist information corresponding to the current playlist in the static scenario memory ; and playing back a 3D stream and a 2D stream referred to by the playitem information in the playlist information. More specifically, it is necessary to: create a program that executes processing procedures shown in  and ; install the program in the playback apparatus ; and cause the MPU to execute the program.",{"@attributes":{"id":"p-0423","num":"0424"},"figref":"FIG. 32"},"Step S is a judgment of whether the current playlist number is set by setting of the auto start playlist in the BD-J object that relates to the selected title, or generation of the JMF player instance. If the current playlist number is set, a playlist information file indicated by the current playlist number is loaded in the scenario memory in Step S. If a plane offset exists in the playlist information in Step S, the offset setting unit  sets the plane offset as the plane offset value in the plane shift engine . Then, the display mode in the title is set in Step S.","In Step S, the first playitem number in the loaded playlist information is set to the current playitem number. In Step S, the current stream is selected from among PES streams permitted to be played back in the current playlist information.","In Step S, what number of a stream is used is decided based on the playitem information.","In Step S, it is judged whether the display mode determined in the Step S is the 2D display mode or the 3D display mode. If the display mode is the 3D display mode, the playback control engine  executes the playback of the 3D video stream in the 3D display mode in Step S. If the display mode is the 2D display mode, Step S is performed.","Step S is judgments of whether the video stream indicated by the current stream number and whether the subtitles are 2D or 3D. If it is judged that the video stream and the subtitles are 2D in Step S, the playback control engine  executes the playback of a 2D AV stream in the 2D display mode in Step S. If it is judged that the video stream and the subtitles are 3D, the playback control engine  executes the playback of the 3D video stream in the 2D display mode in Step S. Lastly, when the procedure reaches \u201cend\u201d in , the playback of the playlist starts.",{"@attributes":{"id":"p-0429","num":"0430"},"figref":"FIG. 33"},"In Step S, the plane offset embedded in the video stream is set in the plane shift engine . In Step S, a current PlayItem. In_Time and a current PlayItem. Out_Time are converted into a Start_SPN[i] and End_SPN[i] respectively, with use of an entry map corresponding to the a packet ID of the base view stream.","The SubPlatItemIn_Time and SubPlayItemOut_Time specified with use of an entry map [j] corresponding to a packet ID [j] of the enhanced view stream are converted into Start_SPN[j] and End_SPN[j], respectively (Step S).","The playback control engine  specifies an extent that falls in a read range [i] for reading Start_SPN[i] to End_SPN[i] of a TS packet [i] of the packet ID [i] (Step S). The playback control engine  specifies an extent that belongs to a read range for reading Start_SPN[j] to End_SPN[j] of a TS packet [j] of the packet ID [j] (Step S). The playback control engine  instructs the drive to sorts addresses of the extents that belong to the read ranges [i] and [j] in an ascending order in Step S, and to sequentially read these extents that belong to the read ranges [i] and [j] with use of the sorted addresses in Step S.","This concludes the description of the playback control engine .","(Implementation of the Plane Shift Engine )","The plane shift engine  realizes, in each display period for a video frame, the processing of: reading the graphics data from each of the image plane  and the interactive graphics plane ; and compositing the graphics data with picture data (sometimes called a video frame) to be played back in each of the display periods. The plane shift engine  should support: reading processing and composition processing when the graphics data is to be read from the image plane ; and reading processing and composition processing when the graphics data is to be read from the interactive graphics plane . Furthermore, a type of processing is determined depending on whether the stereo mode is ON or OFF. Also, a type of processing for the left view and a type of processing for the right view are different. Therefore, in order to implement the plane shift engine , it is necessary to: create a program that executes the processing procedures shown in  and  according to the display mode setting in the playback apparatus ; install the program in the playback apparatus ; and cause the MPU to execute the program.","(Processing Procedures for the 3D Video Stream at the Time of the 3D Display Mode)","When the current display mode is the 3D display mode, and the playback targets are the 3D playlist and the 3D stream, the processing procedures shown in  and  are executed.","Each of  and  is a flowchart showing 3D stream processing in the 3D display mode.","Each of the flowchart in  and the flowchart in  has a loop configuration that repeats Step S to Step S. Each of the flowchart in  and the flowchart in  ends under a condition that it is judged that a next frame does not exists in Step S. Step S to Step S in  are process taken for the left view, and Step S to Step S in  are process taken for the right view. Firstly, the composition unit  acquires background data written in the left-view background plane for the left view. The left-view background plane stores the background data that has been written through the still image decoder according to the rendering instruction by the BD-J application (Step S).","Next, after the video decoder decodes the left-view video stream, and writes the decoded left-view video stream in the video plane  (to which (L) is given in ), the composition unit  acquires the left-view video data written in the video plane  (Step S).","Then, the composition unit  checks the flag of the stereo mode in the image plane  settings in the display mode storage unit  in Step S. When the stereo mode is OFF, the composition unit  uses the image decoder to decode the left-view image, and writes the decoded left-view image in the image plane  (a code (L)), then plane shift engine  performs the shift processing for the left view (Step S).","When the stereo mode is ON, the composition unit  uses the image decoder to decode the left-view image, and writes the decoded left-view image in the image plane  (to which the code (L) is given). When the stereo mode is ON, the plane shift engine  does not perform the shift processing for the left view on the decoded left-view image in the image plane  (to which the code (L) is given). This is because, when the stereo mode is ON, the composition unit  writes, in the image plane  (to which a (R) is given), the right-view image which is seen from the different angle from the left-view image (Step S).","The image plane  to which the code (L) is given in Step Sor in Step Sholds therein the image data which is stored in the image memory , and is decoded by the graphics decoder .","Next, the composition unit  checks a flag of the stereo mode in the interactive graphics plane  setting in the mode storage unit  in Step S. When the stereo mode is OFF, the BD-J application writes the left-view interactive graphics  in the left-eye plane (to which the code (L) is given in the interactive graphics plane  in ) with use of the rendering engine , and acquires the left-view interactive graphics from the left-eye plane (to which the code (L) is given in the interactive graphics plane  in ). The plane shift engine  performs shift processing for the left-eye on the acquired left-view interactive graphics (Step S).","When the stereo mode is ON, the BD-J application writes the left-view interactive graphics in the left-eye plane (to which the code (L) is given in the interactive graphics plane  in ) with use of the rendering engine . After that, although the BD-J application acquires left-view interactive graphics from the left-eye plane (to which the code (L) is given in the interactive graphics plane  in ) for display, the plane shift engine  does not perform the shift processing for the left eye on the left-view interactive graphics (Step S).","The left-view interactive graphics plane from which the left-view interactive graphics is acquired in Step Sand Step Sstores therein the data that has been written through the rendering engine  according to the rendering instruction by the BD-J application in the BD-J mode.","In case HDMV mode, the left-view interactive graphics plane stores therein the decoding result of the graphics data extracted from a graphics stream instead of graphics data drawn by the BD-J application.","In Step S, the composition unit  composites: the background data written in the background plane  to which the code (L) is given in Step S; video data written in the video plane  to which the code (L) is given in Step S; the subtitle data written in the image plane  to which the code (L) is given in Step S; and the GUI data written in the interactive graphics plane  to which the code (L) is given in Step S in order. Then, the resultant composited data is outputted to the display as left-view data. In this case, if the stereo mode is OFF in Step S and Step S, data obtained as a result of the shift processing performed in the corresponding planes are used for composition. As the final process of Step S, the flag in the left-right processing storage unit is changed when the data is outputted to the display. Note that each process in Step S to  is processed as process for the left eye. Which eye to process is determined by referring to the left-right processing storage unit .","Next, the processing for the right eye is performed after the processing for the left eye in Step S to S is completed.  is a flowchart for describing the processing for the right eye. The composition unit  checks the flag of the stereo mode in the background plane  setting in the display mode storage unit  in Step S. When the stereo mode is OFF, the composition unit  writes the left-view background data held in the background plane  to which the code (R) is given, and acquires the background data from the background plane  to which the code (R) is given (Step S). When the stereo mode is ON, the composition unit writes the right-view background data held in the background plane  to which the code (R) is given, and acquires the right-view background data held in the background plane  to which the code (R) is given (Step S).","Next, the composition unit  checks the flag of the stereo mode in the video plane  setting in the display mode storage unit  in Step S. When the stereo mode is OFF, the composition unit  uses the video decoder to decode the left-view video stream, writes the decoded image in the video plane  (to which the code (R) is given in ), and acquires the left-view video data from the video plane  (to which the code (R) is given in ) (Step S). When the stereo mode is ON, the composition unit  uses the video decoder to decode the right-view video stream, writes the decoded right-view video stream in the video plane  (to which the code (R) is given in ), and acquires the right-view video data from the video plane  the video plane  (to which the code (R) is given in ) (Step S).","Then, the composition unit checks the flag of the stereo mode in the image plane  setting in the display mode storage unit  in Step S. When the stereo mode is OFF, the composition unit  writes the left-view image decoded by the image decoder in the image plane  (to which the code (R) is given). After that, the plane shift engine  performs processing for the right eye on the left-view image written in the image plane  (to which the code (R) is given) (Step S). When the stereo mode is ON, the composition unit  writes, in the image plane  (to which the code (R) is given), the right-view image decoded by the image decoder . However, When the stereo mode is ON, the plane shift engine  does not perform the shift processing (Step S).","The image plane  from which the images are acquired in Step Sand Step Sstores therein the subtitle data that has been stored in the image memory , and decoded by the image decoder  (image decoders or ).","Next, the composition unit  checks the flag of the stereo mode in the interactive graphics plane  setting in the display mode storage unit  in Step S. When the stereo mode is OFF, the right-eye plane (to which the code (R) is given in the interactive graphics plane  in ) contains left-view interactive graphics written by the BD-J application using the rendering engine . Then the plane shift engine  performs the shift processing for the right eye on the left-view interactive graphics written in the right-eye plane (to which the code (R) is given in the interactive graphics plane  in ) (Step S).","When the stereo mode is ON, the BD-J application uses the rendering engine  to write the right-view interactive graphics in the right-eye plane (to which the code (R) is given in the interactive graphics plane  in ). However, the plane shift engine  does not perform the shift processing on the right-view interactive graphics written in the right-eye plane (to which the code (R) is given in the interactive graphics plane  in ) (Step S).","In Step S, the composition unit  composites: the background data written in the background plane  (to which the code (R) is given) in Step S; the video data written in the video plane  (to which the code (R) is given) in Step S; the image data written in the image plane  (to which the code (R) is given) in Step S; and the GUI data written in the interactive graphics plane  in Step S in order. In case the stereo mode is OFF in Step S and Step S, data obtained as a result of the shift processing performed in the corresponding plane are targeted for the composition. The resultant composited data is outputted to the display as the right-view data. When the composited data is outputted to the display, the flag in the left-right processing storage unit  is changed. Note that Step S to Step S is processed for the right eye. Whether or not the current process is for the right eye is judged by referring to the left-right processing storage unit .","As long as frames are continuously inputted, the above-stated processing is repeated (Step S).","Note that when the method for acquiring the offset from the header area of the AV stream is adopted in the terminal, and the update of each frame is implemented, it is necessary to update an offset value in the plane shift engine  to a value corresponding to the next frame by the offset setting unit  during Step S.","This concludes the description of the 3D stream processing in the 3D display mode.","(Processing Procedure in the 2D Display Mode)","When the display mode is the 2D display mode, the AV stream to be played back may be one of the left-view stream and the right-view stream that compose the 3D stream, or may be a 2D stream. A description is given, taking a case where the 2D stream is used as an example.","When the current display mode is the 2D display mode, processing procedures in  and  are executed.",{"@attributes":{"id":"p-0462","num":"0463"},"figref":"FIG. 36A"},"Firstly, in Step S, the composition unit  acquires the background data written in the background plane . Next, the video decoder decodes the 2D video stream, and writes the decoded video data held in the video plane  (to which the code (L) is given), and the composition unit  acquires the video data (Step S).","Then, in Step S, the composition unit  uses the image decoder to decode the 2D subtitle stream, writes the decoded image data held in the image plane  (to which the code (L) is given), and acquires the image data.","Next, in Step S, the BD-J application uses the rendering engine  to write the 2D graphics in the left-eye plane (to which the code. (L) is given in the interactive graphics plane  in ). The composition unit  acquires the interactive graphics data from the interactive graphics plane  (to which the code (L) is given).","In Step S, the composition unit  composites: data held in the background plane  obtained in Step S, data obtained in the video plane  in Step S, data obtained in the image plane  in Step S and data obtained in the interactive graphics plane  in Step S in order, and outputs the resultant composited data to the display. As long as frames are continuously inputted, processing returns to S (Step S).",{"@attributes":{"id":"p-0467","num":"0468"},"figref":"FIG. 36B"},"The flowchart of  is created based on , and the same reference numerals are given to the steps that are same as the steps in the flowchart of . The outline of the processing is almost the same, but is briefly described. Firstly, in Step S, the composition unit  acquires the background data from the background plane  (expressed as a code (L)).","Next, the left-view video data is decoded by the video decoder in the video plane  (to which the code (L) is given), then the composition unit  acquires the left-view video data from the video plane  (to which the code (L) is given) (Step S).","Then, in Step S, the left-view image data is decoded by the image decoder in the image plane  (to which the code (L) is given), then the composition unit  acquires the stated image data from the image plane  (to which the code (L) is given).","Next, in Step S, the composition unit  acquires the left-view interactive graphics data, which is written by BD-J application using the rendering engine , held in the interactive graphics plane  (to which the code (L) is given).","In S, the composition unit  composites: the data held in the background plane  obtained in Step S; the data held in the video plane  obtained in Step S; the data held in the image plane  obtained in Step S; and the data held in the interactive graphics plane  obtained in Step S in order, and outputs the resultant composited data to the display. As long as frames are continuously inputted, processing returns to Step S (Step S).","This concludes the description of the processing procedures in the 2D display mode.","(Processing Procedures for Updating the Offset Updating by the BD-J Application)","The following describes what causes a change in depth by the BD-J application.","The following describes, with reference to , processing in a case where the application started by the BD-J module calls the API that changes the depths of data held in the image plane  and data held in the interactive graphics plane .",{"@attributes":{"id":"p-0477","num":"0478"},"figref":["FIG. 37","FIG. 37","FIG. 34","FIG. 35"],"b":["1001","1002","1003","701","810"]},"Up on receiving the calls from the API for changing the depth of the graphics plane, the BD-J module updates the plane offset of the plane which is a target of the display mode storage unit  based on the plane offset received in Step S.","In this case, if the target plane is the image plane , the BD-J module updates the plane offset in the image plane  setting, and if the target plane is the interactive graphics plane , the BD-J module updates the plane offset in the interactive graphics plane  setting.","Meanwhile, in Step S, the BD-J module checks whether the image plane  setting in the display mode storage unit  or the plane offset in the interactive graphics plane  setting is updated or not. If the plane offset is updated in Step S (Step S: Yes), the BD-J module updates the plane offset in the plane shift engine  (Step S). Note that if the image plane  setting is updated in Step S, the BD-J module updates the plane offset value in the image plane  in the plane shift engine , and if the interactive graphics plane  setting is updated in Step S, the BD-J module updates the plane offset value in the interactive graphics plane  in the plane shift engine . If the plane offset is not updated (Step S: No), Step S is not performed, and Step S starts.","As described in the present embodiment, it is possible to adjust a distance of how close the subtitle graphics are to the viewer, and a distance of how far the subtitle graphics are to the viewer from the display by moving coordinates of each of the pixel data pieces in the graphics plane (e.g. shifting in a direction horizontal to the display screen).","Furthermore, even in a case where both the right-view graphics (right-view interactive graphics) and left-view graphics (left-view interactive graphics) are not recorded on the recording medium (i.e. only the 2D graphics and 2D interactive graphics are provided), and therefore the subtitle graphics will normally would appear to be buried in the stereoscopic video because the subtitle graphics can be displayed only in a position on the display screen, it is possible to display the subtitles and GUI in a position (e.g. a position at which the object appear to be closer to the viewer than a position at which the 3D video is displayed) that does not interfere with the depth position in which the video stereoscopically pops out, by storing the 2D graphics in (2D interactive graphics) in a corresponding plane (to which a code (L) or (R) is provided) and adjusting the offset. Thus, it is possible to composite the subtitles and the GUI, and display the composited data while preventing the unpleasant stereoscopic display of the video as much as possible. Therefore, the appearance of the stereoscopic video can be kept pleasant and will reduce the eye strain. Since the depth of the subtitle graphics can be adjusted by the above-stated adjustment, it is not necessary to prepare the left-view graphics and the right-view graphics for the stereoscopic playback of the video. Therefore, even in a case where a BD-ROM whose capacity is limited, and only graphics data for one eye can be recorded on the media, it is possible to provide the user with preferable stereoscopic view.","For an authoring studio, it is possible to skip the generation process of one of the right-view graphics for the stereoscopic playback, which reduces the man-hours of generating films.","In the first embodiment, the shifting of the data held in each plane is realized by shifting content in each memory element in the plane memory. However, the present embodiment relates to the improvement that realizes the above-stated shifting when the pixel data pieces stored in the plane memory is read by the composition unit  in units of lines. In a pixel data aggregate with a resolution of 1920*1080 or 1280*720, a line (i.e. a group of 1920 horizontal pixels or a group of 1280 horizontal pixels) is referred to as line data. The composition unit  composites line data read from each of the video plane , the background plane , the image plane  and the interactive graphics plane .","Each of ,  and  shows a structure of the composition unit . As shown in ,  and , the composition unit  is composed of line memories  to , an \u03b11 multiplication unit , a (1\u2212\u03b11) multiplication unit , a blend unit , a (1\u2212\u03b12) multiplication unit , a scalar ; a multiplication unit , a blend unit , a scalar , an \u03b13 multiplication unit , a (1\u2212\u03b13) multiplication unit , and a blend unit .","The line memory  stores therein line data read from the interactive graphics plane .","The line memory  stores therein line data read from the image plane .","The line memory  stores therein line data read from the video plane .","The line memory  stores therein line data read from the background plane .","The \u03b11 multiplication unit  multiplies, by a transmittance \u03b1, brightness of the line data composing pictures stored in the line memory .","The (1\u2212\u03b11) multiplication unit  multiplies, by a transmittance (1\u2212\u03b11), brightness of the line data composing the graphics data stored in the line memory .","The blend unit  blends the line data whose pixels each is multiplied by the transmittance \u03b1 by the \u03b11 multiplication unit  with the line data whose pixels each is multiplied by the transmittance (1\u2212\u03b11) by the (1\u2212\u03b11) multiplication unit .","The (1\u2212\u03b12) multiplication unit  multiplies the output from the blend unit  by the transmittance (1\u2212\u03b12).","The scalar  enlarges the line data read from the line memory .","The \u03b12 multiplication unit  multiplies, by the transmittance \u03b1, brightness of the line data composing the picture enlarged by the scalar .","The blend unit  blends the line data multiplied by the transmittance \u03b1 with the line data whose pixels each is multiplied by the transmittance (1\u2212\u03b12) by the (1\u2212\u03b12) multiplication unit .","The scalar  enlarges the line data read from the line memory .","The \u03b13 multiplication unit  multiplies, by the transmittance \u03b1, brightness of the line data that is read by the line memory , and composes the graphics enlarged by the scalar .","The (1\u2212\u03b13) multiplication unit  multiplies, by the transmittance (1\u2212\u03b13), brightness of the line data that is an output result obtained from the blend unit .","The blend unit  blends the line data pieces each multiplied by the transmittance \u03b1 with the line data whose pixels each is multiplied by the transmittance (1\u2212\u03b13) by the (1\u2212\u03b13) multiplication unit .","This concludes the description of the structure of the composition unit .","The plane shift engine  described in the first embodiment realizes the transfer processing of: reading pixel data pieces in units of lines from memory elements in the background graphics plane , the video plane , the image plane  and the interactive graphics plane , and storing the pixel data pieces in the line memories  to . In this transfer processing, it is possible to realize processing that is equivalent to the shifting of coordinates of each of the pixel data pieces in the memory elements as described in the first embodiment by changing the addresses of the line memories  to  to which the pixel data pieces are transferred.",{"@attributes":{"id":"p-0503","num":"0504"},"figref":["FIG. 39A","FIG. 39B","FIG. 39C","FIG. 39A","FIG. 39B","FIG. 39B"],"sup":["th ","th ","th "]},{"@attributes":{"id":"p-0504","num":"0505"},"figref":"FIG. 39C"},{"@attributes":{"id":"p-0505","num":"0506"},"figref":["FIG. 40A","FIG. 40B","FIG. 40C","FIG. 40A","FIG. 40B","FIG. 40B"],"sup":["th ","th ","th "]},{"@attributes":{"id":"p-0506","num":"0507"},"figref":"FIG. 40C"},"This concludes the description of processes for executing the shifting of coordinates of pixel data pieces composing each line data in the plane.","The plane shift engine  that executes the shifting of coordinates of pixel data pieces composing each line data in the plane can be implemented by creating a program that causes the MPU to execute the processing procedures shown in a flowchart of , and installing the program in the playback apparatus . The following describes the implementation of the plane shift engine  by software.",{"@attributes":{"id":"p-0509","num":"0510"},"figref":"FIG. 41"},"Processing from Step S to Step S has a loop configuration that repeats Step S to Step S after a parameter i is set to 0 in Step S. This loop ends under a condition that the parameter i becomes a value (the number of lines\u22121) in Step S. As long as it is judged that the parameter i is not a value (the number of lines\u22121) in Step S., the parameter i is incremented, and Step S to Step S are repeated. In Step S, the plane shift engine  reads pixel data pieces (Xo, Yi) to (Xn\u2212plane offset\u22121, Yi) in the graphics plane, and writes the pixel data pieces in (Xo+plane offset) to (Xn). In Step S, the plane shift engine  writes transparent pixel data pieces in Xo to Xo+offset\u22121 in the line memory.","Processing from Step S to Step S has a loop configuration that repeats Step S to Step S after a parameter i is set to 0 in Step S. This loop ends under a condition that the parameter i becomes a value (the number of lines\u22121) in Step S. As long as it is judged that the parameter i is not a value (the number of lines\u22121) in Step S, the parameter i is incremented, and Step S to Step S are repeated. In Step S, the plane shift engine  reads pixel data pieces (Xn+plane offset, Yi) to (Xn, Yi) in the graphics plane, and writes the pixel data pieces in (Xo) to (Xn\u2212plane offset\u22121). In Step S, the plane shift engine  writes transparent pixel data pieces in (Xo) to (Xo+offset\u22121) in the line memory.","This concludes the description of the processes for executing the shifting of coordinates of pixel data pieces composing each line data in the plane in the left direction.","According to the present embodiment as described in the above, the memory access to the graphics plane can be less frequent since the shifting of coordinates of pixel data held in the right direction and the left direction is realized in each line memory when the plane shift engine  reads the pixel data pieces in the graphics plane for each line data.","(Notes)","This concludes the description of the best modes of carrying out the invention known to the applicant at the time of application. However, further improvements and variations related to the technical topics indicated below can be added. Whether to carry out the invention as indicated in the embodiments or to use these improvements and variations is arbitrary, and is left to the discretion of the one who carries out the invention.","(Implementation as the Recording Medium)","The playback apparatus  includes a local storage including a built-in media library and a removable media. Therefore, since the playback apparatus  is expected to write data in the built-in media drive and the local storage, the playback apparatus  described in the present Description has a function as the recording medium. When the playback apparatus  functions as the recording medium, the playback apparatus  executes the writing of a management object in the following two manners (1) and (2).","(1) When the playback apparatus  has a function of playing back the virtual package, the playback apparatus  write the BD-J object in the following way. That is, when the BD-ROM is loaded, the playback apparatus  acquires additional contents corresponding to the BD-ROM from a WWW server via the network in accordance with a request from an application. The acquired additional contents include the BD-J object in which the GUI management table is written. A control unit, in the playback apparatus , that perform recording control writes the acquire BD-J object in the local storage in accordance with the request from the application. Thus, it is possible to configure the virtual package by compositing the contents in the BD-ROM with the additional contents recorded in the local storage.","In the BD-ROM are recorded an identifier of a disc root certificate, an identifier of an organization that distributes the BD-Rom contents and an identifier of the BD-ROM. An area in which the additional contents are stored are specified by a file path including the identifier of the disc root certificate, the organization identifier and the BD-ROM identifier.","The application performs writing by sending, to the control unit, the file path that specifies the area in which the additional contents are stored.","When the local storage has a file system that limits the names of directories and files to 255 characters or less, the file path used for writing to the local storage includes file names and extensions in a 8.3-format file system in which directory names are 8 characters or less and file names and extension names are three characters or less.","(2) If the playback apparatus  has a function of receiving the BD-J object from an on-demand manufacture service or an electrical sell-through services (MODEST), the playback apparatus  writes the BD-J object as follows.","That is, when the playback apparatus  receives the BD-J object from an on-demand manufacture service or an electrical sell-through services (MODEST), the playback apparatus  creates a default directory and a MODEST directory under the root directory in the removable media, and creates the BDMV directory under the MODEST directory. The MODEST directory is a first MODEST directory. The first MODEST directory is created when the user receives the service for the first time. When the user receives the service for the second time onwards, the control unit in the playback apparatus  creates a MODEST directory corresponding to a service from the second time onwards.","As described in the above, acquiring the BD-J object in which the GUI management table is written, the control unit writes a start-up program in the default directory, and writes the BD-J object in the BDMV directory under the MODEST directory. This start-up program is a program to be executed first when the recording medium is loaded in the playback apparatus . The start-up program causes the playback apparatus : to display a menu from which user operation of selecting the BDMV directory is received, and to execute a root change function. This root change function is a function of causing the MODEST directory to which the BDMV directory belongs to be recognized as the root directory when the user performs the selection operation on the menu. The root change function makes it possible to execute the playback control based on the acquired BD-J object by the same control procedures as the control procedures for playing back the BD-ROM.","(Java\u2122 Application)","The BD-J application may be, for example, an Electronic Commerce (EC) client application, or may be an online game played against opponents on the Internet. Furthermore, by working together with a search engine, various online services can be provided to the user.","(Units for Integrating the GUI Table)","Although in the embodiment, the GUI management object is provided in the BD-J object, the invention may be configured so as to provide the GUI management table to correlate PlayList information and PlayItem information, and so that the timing at which the current PlayList becomes the current PlayItem or when the current PlayItem becomes the specified PlayItem, the plane memory is released, and plane memories for stereoscopic playback and for planar playback may be reserved. This enables the area of the memory device to be managed with more precise time accuracy.","(Video Stream for Stereoscopic View)","Recording left view and right view video streams on a BD-ROM is only one example. Playback may also be provided by recording on the BD-ROM, for each picture, as an EnhancedView video stream, a video stream indicating per pixel depth values.","(Package to be Implemented)","When implementing an playback apparatus, the following BD-J Extensions are preferably implemented in the playback apparatus. The BD-J Extensions include various packages that have been specialized for providing functions exceeding GEM [1.0.2] to a Java\u2122 format. Packages to which BD-J Extensions are provided are as follows.","org.bluray.media","This package provides specialized functions to be added to the Java\u2122 Media FrameWork. Control for angles, audio, and subtitle selection are added to the package.","org.bluray.ti","This package includes a structure for referring to an API for operating by mapping \u201cservices\u201d to \u201ctitles\u201d according to GEM [1.0.2] and referring to title information from a BD-ROM, and a structure for selecting a new title.","org.bluray.application","This package includes an API for managing life cycles of applications. Also, this package includes an API for referring to necessary information for signaling when executing applications.","org.bluray.ui","This package includes a class that defines a constant number for key events specialized in the BD-ROM, and realizes synchronization with the video playback.","org.bluray.vfs","This package provides a binding scheme for binding contents that are recorded on the BD-ROM (on-disk contents) and contents in the Local Storage that are not recorded on the BD-ROM (off-disk contents) and playing back the contents seamlessly, regardless of the location of the contents.","The Binding Scheme correlates contents on the BD-ROM (AV clips, subtitles, BD-J applications) with related contents in the Local Storage. This Binding Scheme realizes seamless playback regardless of the location of the contents.","(Structure of the Graphics Plane)","When the image plane  and the interactive graphics plane  are composed of SDRAM, a unique control for shifting the coordinates of the pixel data pieces stored in the SDRAM is necessary.","The SDRAM includes a ROW address decoder that outputs a ROW address output at time-divided address pins to a memory array, a COLUMN address decoder that outputs a COLUMN address output at time-divided address pins to a memory array, a page data buffer that holds one page length worth of data read from the memory array, and outputs the one page length worth of data at the address pins. Since the SDRAM uses a condenser as a storage element, natural discharge occurs. For this reason, it is necessary in the SDRAM to perform refresh on the storage elements, and additional circuits must be added for performing refresh.","When a picture is stored in the SDRAM, the plane controller forms a command by compositing the states of RAS, CAS, WE, CS, and CKE, and by compositing the command and a composition of the addresses, reading and writing are performed. For example, when using a burst transfer mode, an activated command is issued, and a ROW address is issued at the address pin of the SDRAM. After a delay of a fixed time period, a READ command is issued, and the COLUMN address is issued at the address pin.","(Programming Language Application Range)","It is described in the embodiments that Java\u2122 language is used as the virtual machine programming language. However, the language is not limited to Java\u2122, and other programming languages, such as B-Shell, Perl Script, and ECMA Script, which are used in UNIX\u2122 OS and the like, may also be used.","(Changing to Multidrive)","The above-described embodiments describe a BD-ROM as an example of a recording medium, and a BD-ROM drive as an example of a specific device fulfilling a function of reading data from the BD-ROM. However, a BD-ROM is merely one example, and it is also possible to perform the operations described in the above embodiments when an optical disk medium such as BD-R, BD-RE, DVD, or CD is used as the recording medium, data having the above-described data structure is stored on such recording medium, and there is a drive device capable of reading such recording medium.","The recording media of the embodiments include all types of package media such as optical disks, semi-conductor memory cards, etc. The recording media of the embodiments described, as an example, an optical disk (for example, a preexisting read-only optical disk such as a BD-ROM or a DVD-ROM). However, the present invention is not limited to this. For example, it is possible to implement the present invention by writing 3D contents, including data that is necessary for implementing the present invention and has been broadcast or distributed over a network, with use of a terminal device fulfilling a function of writing 3D contents (for example, the function may be included in the playback apparatus, or may be included in an apparatus other than the playback apparatus), on a writable optical disk (for example, a preexisting writable optical disk such as BD-RE or DVD-RAM).","Also, it is possible to implement the present invention when the recording medium is, besides an optical disk, for example, a removable medium such as an SD memory card (semiconductor memory card).","When a semiconductor memory is used instead of the BD-ROM, data in the read buffer  and the read buffer  is transferred to the heap memory , the dynamic scenario memory  and the static scenario memory  via an interface (memory card I\/F) for reading the data in the semiconductor memory.","More specifically, when the semiconductor memory card is inserted into a slot (not shown) in the playback apparatus , the playback apparatus  and the semiconductor memory card are electrically connected to each other via the memory card I\/F. The data recorded in the semiconductor memory card is transferred to the read buffer , the read buffer , the heap memory , the dynamic scenario memory  and the static scenario memory  via the memory card I\/F.","From a standpoint, for example, of improving the confidentiality of data and copyright protection, there are cases in which portions of the data recorded on the BD-ROM are encoded as necessary.","For example, the encoded data of the data recorded on the BD-ROM may be, for example, data corresponding to a video stream, data corresponding to an audio stream, or data corresponding to a stream that includes both video and audio.","The following describes deciphering of encoded data that is among the data recorded on the BD-ROM.","In the playback apparatus, data corresponding to a key necessary for deciphering encoded data on the BD-ROM (for example, a device key) is recorded in the playback apparatus in advance.","Meanwhile, data corresponding to the key necessary for deciphering encoded data (for example, an MKB (media key block) corresponding to the device key) and data in which the key itself, for deciphering the encoded data, is encoded (for example an encoded title key corresponding to the device key and the MKB), is recorded on the BD-ROM. Here, the device key, the MKB, and the encoded title key correspond to each other, and furthermore correspond to an identifier (for example, a volume ID) written in an area that cannot be normally copied on the BD-ROM (an area called BCA). If this composition is not correct, the code cannot be deciphered. Only if the composition is correct, the key necessary for deciphering the code (for example, a decoded title key obtained by decoding the encoded title key based on the device key, the MKB and volume key, can be elicited, and with use of the key necessary for the encoding, the encoded data can be deciphered.","When the inserted BD-ROM is played back in the playback apparatus, encoded data cannot be played back unless the BD-ROM includes a device key that is paired with a title key or MKB (or corresponds to a title key or MKB). The reason is that the key necessary for deciphering the encoded data (the title key) is itself encoded when recorded on the BD-ROM (as an encoded title key), and if the composition of the MKB and the device key is not correct, the key necessary for deciphering the code cannot be elicited.","On the other hand, the playback apparatus is configured so that, if the composition of the encoded title key, MKB, device key, and volume ID is correct, the video stream is decoded, for example with use of the key necessary for deciphering the code (the decoded title key obtained by decoding the encoded title key based on the device key, the MKB and the volume ID), and the audio stream is decoded by the audio decoder.","Although in the present embodiments, a BD-ROM is described as an example of a recording medium, the recording medium is not limited to being a BD-ROM, and the present invention can be implemented even when using, for example, a readable\/writable semiconductor memory (for example, a semiconductor memory card having a nonvolatile property such as an SD card).","For example, the playback apparatus may be configured to record data corresponding to data recorded on the BD-ROM on a memory card with use of digital distribution, and to play back the data from the semiconductor memory card. When distributing the necessary data with use of digital distribution and recording the distributed data, it is preferable to distribute the data after having performed partial or entire decoding of the distributed data as necessary, and leaving data that is necessary for the semiconductor memory card in an encoded state.","The following describes operation using, for example, digital distribution, for recording data (distributed data) corresponding to the data described in the above embodiments on the semiconductor memory.","The operations described above may be configured to be performed by the playback apparatus described in the embodiments, or by a terminal apparatus dedicated to recording distributed data on a semiconductor memory that is separate from the playback apparatus in the embodiments. Here, an example of the playback apparatus performing the operations is described. Also, an SD card is described as an example of the recording destination.","When recording distributed data to the SD memory card inserted in the slot of the playback apparatus, first, transmission is requested of the distributed data to a distribution server (not illustrated) that accumulates the distributed data. The playback apparatus reads, from the SD memory card, information for uniquely identifying the SD memory card that is inserted at the playback apparatus at this time (for example, a specific identification number assigned individually to the particular SD memory card, more specifically, a serial number of the SD memory card, etc.), and transmits the read identification information to the distribution server along with the distribution request.","This identification information for uniquely identifying the SD memory card corresponds to, for example, the above-described volume ID.","Meanwhile, in the distribution server, decoding is performed so that necessary data among the data that is distributed (video streams, audio streams, etc.) can be deciphered with use of the key that is necessary for deciphering the code (for example, the title key), and the necessary data is stored in the server.","For example, a private key is stored in the distribution server, and the distribution server is configured so that different public keys are dynamically created to correspond respectively to the semiconductor memory card-specific identification numbers.","Also, the distribution server is configured so that encoding is possible towards the key that is necessary for deciphering the encoded data itself (the title key) (in other words, configured so that an encoded title key can be generated).","The generated public key information includes information corresponding to the above-described MKB, volume ID, and encoded title key. If the composition of, for example, the semiconductor memory card-specific identification number, the actual public key included in the public key information described later, and the device key recorded in advance in the recording apparatus, is correct, the key necessary for deciphering the code (for example, the title key obtained by decoding the encoded title key based on, for example, the device key, the MKB, and the semiconductor memory card-specific identification number) is acquired, and with use of this acquired key (title key) necessary for deciphering the code, decoding of the encoded data can be performed.","Next, the playback apparatus records the received public key information and distributed data in the recording area of the semiconductor memory card inserted in the slot.","Next, the following describes an exemplary method for decoding and playing back encoded data, from among the data included in the public key information recorded in the recording area of the semiconductor memory card and the data included in the distribution data.","The received public key information is, for example, recorded on a device list indicating the public key itself (for example, the MKB and the encoded title key), signature information, the semiconductor memory card-specific identification number, and information pertaining to a device to be invalidated.","The signature information includes, for example, hash values of the public key information.","In the device list, information is recorded pertaining to, for example, an apparatus that is possibly performing unauthorized playback. This is for example a device key, an identification number of the playback apparatus, or an identification number of a decoder in the playback apparatus recorded in advance on the playback apparatus, information for uniquely specifying the device, a part included in the apparatus, or a function (program) of the apparatus possibly performing unauthorized playback.","The following description pertains to playback of encoded data from among the distribution data recorded in the recording area of the semiconductor memory card.","First, a check is performed pertaining to whether the encoded key itself may be operated before decoding the encoded data with use of the public key itself.","Specifically, the following checks are performed:","(1) whether there is a match between the semiconductor memory identification information included in the public key information and the specific identification number stored in advance on the semiconductor memory card,","(2) whether there is a match between a hash value of the public key information calculated in the playback apparatus, and a hash value included in the signature information, and","(3) whether, based on information indicated in the device list included in the public key information, the playback apparatus performing playback is possibly performing unauthorized playback (for example, by checking whether the device key included in the device list matches the device key stored in the playback apparatus in advance). These checks may be performed in any order.","Control is performed so that the playback apparatus does not decode the encoded data if any of the following is satisfied, in the above-described checks 1 to 3: i) the semiconductor memory-specific identification information included in the public key information does not match the specific identification number stored in advance on the semiconductor memory card, ii) the hash value of the public key information calculated in the playback apparatus does not match the hash value included in the signature information, or iii) a judgment is made that the playback apparatus performing the playback is possibly performing unauthorized playback.","Also, a judgment is made that the composition of the semiconductor memory-specific identification number, the public key included in the public key information, and the device key recorded in advance in the playback apparatus, is correct if i) the semiconductor memory card-specific identification information included in the public key information matches the specific identification number saved on the semiconductor memory card in advance, (ii), the hash value of the public key information calculated in the playback apparatus matches the hash value included in the signature information, and (iii) a judgment is made that the playback apparatus is not possibly performing unauthorized playback. When the composition is judged to be correct, the encoded data is deciphered with use of the key necessary for deciphering the code (based on a device key, the MKB and the semiconductor memory-specific identification number).","For example, when the encoded data is a video stream and an audio stream, the video decoder decodes (decodes) the video stream with use of the key necessary for deciphering the code (the title key obtained by decoding the encoded title key), and the audio decoder decodes (decodes) the audio stream with use of the key necessary for deciphering the code.","According to this type of structure, for any playback apparatus, parts, function (program), etc. that is possibly performing unauthorized use at the time of electronic distribution, information for the identification of such is provided to the device list, and if distribution is attempted, since playback decoding with use of public key information (the public key) can be suppressed on the playback apparatus side if information is included that is indicated in the device list, even if the composition of the semiconductor memory-specific identification number, the public key included in the public key information, and the device key recorded in the playback apparatus in advance, is correct, since control can be performed so that the deciphering of the encoded data is not performed, use of distributed data on an unauthorized device can be suppressed.","Also, it is preferable to use a structure in which the semiconductor memory card-specific identifier recorded in advance on the semiconductor memory card is stored in a highly confidential recording area. The reason is that when the specific number recorded on the semiconductor memory card (for example, in the example of an SD memory card, the SD memory card serial number, etc.) has been altered, illegal copying is facilitated. The reason is that different specific identification numbers are allocated to different semiconductor memory cards, but if the specific identification numbers are altered to be the same, the judgment in (1) becomes meaningless, and there is a possibility of illegal copying, corresponding to the number that was altered, being performed.","Accordingly, it is preferable for the information that is the semiconductor memory card-specific identification number to be recorded in a high-confidentiality recording area.","To realize this type of structure, for example by providing a recording area (called a second recording area) that is separate from the recording area (called a first recording area) that stores normal data as recording areas for recording high-confidentiality data that is semiconductor memory card-specific identifiers), and providing a control circuit for accessing the recording area, access to the second recording area can be made only via the control circuit.","For example, the data recorded in the second recording area has been encoded and recorded. For example, a circuit for decoding the encoded data is built into the control circuit. When there is access of the data in the second recording area via the control circuit, the structure need merely be such that the code is decoding and the decoded data is returned. Also, if the control circuit stores information of a storage location of data recorded in the second recording area, and there is a request to access the data, the corresponding storage location of the data need merely be specified, and the data read from the specified storage location be returned.","Upon issuing an access request to the data recorded in the second recording area to the control circuit via the memory card I\/F (for example, semiconductor memory-specific identification number), applications that operate in the playback apparatus that request recording to the semiconductor memory card with use of digital distribution, the control circuit that received the request reads the data recorded in the second recording area and returns the data to the application operating in the playback apparatus. Along with the semiconductor memory card-specific identification number, the distribution request for the necessary data need only be requested from the distribution server, and the public key information sent from the distribution server and the corresponding request for distribution of the data, may be recorded to the first recording area.","Also, an application operating in the playback apparatus, that requests recording on the semiconductor memory card with use of digital distribution, before issuing the request to the control circuit via the memory card I\/F to access the data recorded on the second recording area (for example, the semiconductor memory card-specific identification numbers), preferably checks in advance whether the application has been altered. For example, a digital certificate compliant with preexisting X.509 specifications may be used in the check for alteration.","Also, access to the distribution data recorded in the first recording area of the semiconductor memory card need not necessarily be access via a control circuit on the semiconductor memory card.","(Implementation as a Program)","The application program described in the embodiments can be made as described below. First, the software developer, with use of a programming language, writes a source program to realize the content of the flowcharts and the functional structural elements. When writing the source program that embodies the content of the flowcharts and the functional structural elements, the software developer uses the class structures, variables, array variables, and external function calls to write the program in accordance with the syntax of the programming language.","The written source programs are given as files to a compiler. The compiler translates the source programs and creates an object program.","The translation by the compiler is made up of the processes of syntax analysis, optimization, resource allocation, and code generation. Syntax analysis involves performing lexical analysis and semantic analysis of the source programs, and converting the source programs to an intermediary program. Optimization involves performing operations to divide the intermediary program into basic blocks, analyze the control flow of the intermediary program, and analyze the data flow of the intermediary program. In resource allocation, to improve suitability with a command set of a targeted processor, variables in the intermediary program are allocated to a register or a memory in a targeted processor. Code generation is performed by converting the intermediary commands in the intermediary program into program code, and obtaining an object program.","The object program generated here is made up of one or more program codes for executing, on a computer, the steps of the flowcharts and the various processes carried out by the functional structural elements in the embodiments. Here, program code may be any of various types such as native code of a processor or JAVA byte code. There are various formats for realization of the steps by the program code. If it is possible to use external functions to realize the steps, call texts that call such functions become program code. Also, there are cases in which a program code for realizing one step is attributed to separate object programs. In a RISC processor in which command types are limited, the steps of the flowcharts may be realized by compositing calculation operation commands, logical calculation commands, branch instruction commands, etc.","When the object programs have been created, the programmer starts up a linker. The linker allocates the object programs and library programs to memory spaces, composites the object programs and library programs into one, and generates a load module. The load module generated thus is anticipated to be read by a computer, and causes the computer to execute the processing procedures and functional structural components shown in the flowcharts. The programs may be provided to users by being recorded on a recording medium that is readable by a computer.","(Singular Implementation of the LSI)","The system LSI is obtained by implementing a bare chip on a high-density substrate and packaging them. The system LSI is also obtained by implementing a plurality of bare chips on a high-density substrate and packaging them, so that the plurality of bare chips have an outer appearance of one LSI (such a system LSI is called a multi-chip module).","The system LSI has a QFP (Quad Planar view Package) type and a PGA (Pin Grid Array) type. In the QFP-type system LSI, pins are attached to the four sides of the package. In the PGA-type system LSI, a lot of pins are attached to the entire bottom.","These pins function as an interface with other circuits. The system LSI, which is connected with other circuits through such pins as an interface, plays a role as the core of the playback apparatus .","Such a system LSI can be embedded into various types of devices that can play back images, such as a television, game machine, personal computer, one segment mobile phone, as well as into the playback apparatus . The system LSI thus greatly broadens the use of the present invention.","When an elementary buffer, video decoder, audio decoder, and graphics decoder are integrated into a system LSI, it is desirable that the system LSI conforms to the Uniphier architecture.","A system LSI conforming to the Uniphier architecture includes the following circuit blocks.","Data Parallel Processor (DPP)","The DPP is an SIMD-type processor where a plurality of elemental processors perform a same operation. The DPP achieves a parallel decoding of a plurality of pixels constituting a picture by causing operating units, respectively embedded in the elemental processors, to operate simultaneously by one instruction.","Instruction Parallel Processor (IPP)","The IPP includes: a local memory controller that is composed of instruction RAM, instruction cache, data RAM, and data cache; processing unit that is composed of instruction fetch unit, decoder, execution unit, and register file; and virtual multi processing unit that causes the processing unit to execute a parallel execution of a plurality of applications.","MPU Block","The MPU block is composed of: peripheral circuits such as ARM core, external bus interface (Bus Control Unit: BCU), DMA controller, timer, vector interrupt controller; and peripheral interfaces such as UART, GPIO (General Purpose Input Output), and sync serial interface.","Stream I\/O Block","The stream I\/O block performs data input\/output with the drive device, hard disk drive device, and SD memory card drive device which are connected onto the external busses via the USB interface and the ATA packet interface.","AV I\/O Block","The AV I\/O block, which is composed of audio input\/output, video input\/output, and OSD controller, performs data input\/output with the television and the AV amplifier.","Memory Control Block","The memory control block performs reading and writing from\/to the SD-RAM connected therewith via the external buses. The memory control block is composed of internal bus connection unit for controlling internal connection between blocks, access control unit for transferring data with the SD-RAM connected to outside of the system LSI, and access schedule unit for adjusting requests from the blocks to access the SD-RAM.","The following describes a detailed production procedure. First, a circuit diagram of a part to be the system LSI is drawn, based on the drawings that show structures of the embodiments. And then the constituent elements of the target structure are realized using circuit elements, ICs, or LSIs.","As the constituent elements are realized, buses connecting between the circuit elements, ICs, or LSIs, peripheral circuits, interfaces with external entities and the like are defined. Further, the connection lines, power lines, ground lines, clock signals and the like are defined. For these definitions, the operation timings of the constituent elements are adjusted by taking into consideration the LSI specifications, and bandwidths necessary for the constituent elements are reserved. With other necessary adjustments, the circuit diagram is completed.","After the circuit diagram is completed, the implementation design is performed. The implementation design is a work for creating a board layout by determining how to arrange the parts (circuit elements, ICs, LSIs) of the circuit and the connection lines onto the board.","After the implementation design is performed and the board layout is created, the results of the implementation design are converted into CAM data, and the CAM data is output to equipment such as an NC (Numerical Control) machine tool. The NC machine tool performs the SoC implementation or the SiP implementation. The SoC (System on Chip) implementation is a technology for printing a plurality of circuits onto a chip. The SiP (System in Package) implementation is a technology for packaging a plurality of circuits by resin or the like. Through these processes, a system LSI of the present invention can be produced based on the internal structure of the playback apparatus  described in each embodiment above.","It should be noted here that the integrated circuit generated as described above may be called IC, LSI, ultra LSI, super LSI or the like, depending on the level of the integration.","It is also possible to achieve the system LSI by using the FPGA (Field Programmable Gate Array). In this case, a lot of logic elements are to be arranged lattice-like, and vertical and horizontal wires are connected based on the input\/output compositions described in LUT (Look-Up Table), so that the hardware structure described in each embodiment can be realized. The LUT is stored in the SRAM. Since the contents of the SRAM are erased when the power is off, when the FPGA is used, it is necessary to define the Config information so as to write, onto the SRAM, the LUT for realizing the hardware structure described in each embodiment.","In the embodiment, the invention is realized by middleware and hardware corresponding to the system LSI, hardware other than the system LSI, an interface portion corresponding to the middleware, an interface portion to intermediate between the middleware and the system LSI, an interface portion to intermediate between the middleware and the necessary hardware other than the system LSI, and a user interface portion, and when integrating these elements to form the playback apparatus, particular functions are provided by operating the respective elements in tandem.","Appropriately defining the interface corresponding to the middleware and the interface for the middleware and the system LSI enables parallel, independent development of the user interface portion, the middleware portion, and the system LSI portion of the playback apparatus respectively, and enables more efficient development. Note that there are various ways of dividing up the respective interface portions. For example, when the described video recorder , video recorder , audio decoder , and composite unit  are included on a chip in the system LSI , development of an interface portion between the middleware to control these units and the middleware corresponding to these units is performed when developing the chip. After completion, including the developed middleware and interface portion in a storage unit such as a memory of the playback apparatus, along with integrating the chip into the playback apparatus, enables performing development of the playback apparatus and the chip in parallel, thereby improving development efficiency.","Versatility is improved when the same interface portion is used regardless of the type of developed chip and the middleware pertaining to the developed chip.","Needless to say, the portion structured as a system LSI in the above description is not limited to being structured as an LSI, and may instead be configured with use of a signal processing circuit that includes corresponding functions to those to be included in the system LSI.","The present application relates to a technique of compositing subtitles and graphics with a stereoscopic video stream, and displaying the resultant data in the playback apparatus that plays back the stereoscopic video stream, and is particularly applicable in a stereoscopic video playback apparatus that composites the subtitles and the graphics as well as the stereoscopic video stream, and outputs the resultant data stereoscopically.",{"@attributes":{"id":"p-0631","num":"0000"},"ul":{"@attributes":{"id":"ul0003","list-style":"none"},"li":[{"@attributes":{"id":"ul0003-0001","num":"0632"},"b":"100"},{"@attributes":{"id":"ul0003-0002","num":"0633"},"b":"200"},{"@attributes":{"id":"ul0003-0003","num":"0634"},"b":"300"},{"@attributes":{"id":"ul0003-0004","num":"0635"},"b":"400"},{"@attributes":{"id":"ul0003-0005","num":"0636"},"b":"500"},{"@attributes":{"id":"ul0003-0006","num":"0637"},"b":"101"},{"@attributes":{"id":"ul0003-0007","num":"0638"},"b":"102"},{"@attributes":{"id":"ul0003-0008","num":"0639"},"b":"103"},{"@attributes":{"id":"ul0003-0009","num":"0640"},"b":"104"},{"@attributes":{"id":"ul0003-0010","num":"0641"},"b":"105"},{"@attributes":{"id":"ul0003-0011","num":"0642"},"b":"106"},{"@attributes":{"id":"ul0003-0012","num":"0643"},"b":"107"},{"@attributes":{"id":"ul0003-0013","num":"0644"},"b":"110"},{"@attributes":{"id":"ul0003-0014","num":"0645"},"b":"111"},{"@attributes":{"id":"ul0003-0015","num":"0646"},"b":["1","2"]},{"@attributes":{"id":"ul0003-0016","num":"0647"},"b":"3"},{"@attributes":{"id":"ul0003-0017","num":"0648"},"b":"4"},{"@attributes":{"id":"ul0003-0018","num":"0649"},"b":["5","5"],"i":["a","b "]},{"@attributes":{"id":"ul0003-0019","num":"0650"},"b":"6"},{"@attributes":{"id":"ul0003-0020","num":"0651"},"b":["7","7"],"i":["a","b "]},{"@attributes":{"id":"ul0003-0021","num":"0652"},"b":["7","7"],"i":["c","d "]},{"@attributes":{"id":"ul0003-0022","num":"0653"},"b":"8"},{"@attributes":{"id":"ul0003-0023","num":"0654"},"b":"9"},{"@attributes":{"id":"ul0003-0024","num":"0655"},"b":"10"},{"@attributes":{"id":"ul0003-0025","num":"0656"},"b":"11"},{"@attributes":{"id":"ul0003-0026","num":"0657"},"b":"12"},{"@attributes":{"id":"ul0003-0027","num":"0658"},"b":"13"},{"@attributes":{"id":"ul0003-0028","num":"0659"},"b":"14"},{"@attributes":{"id":"ul0003-0029","num":"0660"},"b":"15"},{"@attributes":{"id":"ul0003-0030","num":"0661"},"b":"16"},{"@attributes":{"id":"ul0003-0031","num":"0662"},"b":"17"},{"@attributes":{"id":"ul0003-0032","num":"0663"},"b":"18"},{"@attributes":{"id":"ul0003-0033","num":"0664"},"b":"19"},{"@attributes":{"id":"ul0003-0034","num":"0665"},"b":"20"},{"@attributes":{"id":"ul0003-0035","num":"0666"},"b":"22"},{"@attributes":{"id":"ul0003-0036","num":"0667"},"b":"23"},{"@attributes":{"id":"ul0003-0037","num":"0668"},"b":"24"},{"@attributes":{"id":"ul0003-0038","num":"0669"},"b":"25"},{"@attributes":{"id":"ul0003-0039","num":"0670"},"b":"26"},{"@attributes":{"id":"ul0003-0040","num":"0671"},"b":"27","i":"a "},{"@attributes":{"id":"ul0003-0041","num":"0672"},"b":"27","i":"b "},{"@attributes":{"id":"ul0003-0042","num":"0673"},"b":"28"},{"@attributes":{"id":"ul0003-0043","num":"0674"},"b":"29"}]}}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["These and the other objects, advantages and features of the invention will become apparent from the following description thereof taken in conjunction with the accompanying drawings which illustrate a specific embodiment of the invention. In the drawings:",{"@attributes":{"id":"p-0023","num":"0024"},"figref":"FIG. 1","b":"200"},{"@attributes":{"id":"p-0024","num":"0025"},"figref":"FIG. 2","b":"100"},{"@attributes":{"id":"p-0025","num":"0026"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0026","num":"0027"},"figref":"FIG. 4","b":"200"},{"@attributes":{"id":"p-0027","num":"0028"},"figref":"FIG. 5","b":["101","105","13","106"]},{"@attributes":{"id":"p-0028","num":"0029"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0029","num":"0030"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0030","num":"0031"},"figref":"FIG. 8","b":["6","8","10"]},{"@attributes":{"id":"p-0031","num":"0032"},"figref":"FIG. 9","b":["6","10"]},{"@attributes":{"id":"p-0032","num":"0033"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0033","num":"0034"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0034","num":"0035"},"figref":"FIG. 12","b":["500","6"]},{"@attributes":{"id":"p-0035","num":"0036"},"figref":["FIG. 13A","FIG. 13B"]},{"@attributes":{"id":"p-0036","num":"0037"},"figref":["FIG. 14A","FIG. 14B"],"b":"8"},{"@attributes":{"id":"p-0037","num":"0038"},"figref":["FIG. 15A","FIG. 15B","FIG. 15C"],"b":"19"},"Each of  and  shows an internal structure of the interactive graphics plane ;",{"@attributes":{"id":"p-0039","num":"0040"},"figref":["FIG. 17A","FIG. 17B","FIG. 17C"],"b":"19"},{"@attributes":{"id":"p-0040","num":"0041"},"figref":["FIG. 18A","FIG. 18B","FIG. 18C"],"b":"8"},{"@attributes":{"id":"p-0041","num":"0042"},"figref":["FIG. 19A","FIG. 19B","FIG. 19C"],"b":"10"},{"@attributes":{"id":"p-0042","num":"0043"},"figref":["FIG. 20A","FIG. 20B"]},{"@attributes":{"id":"p-0043","num":"0044"},"figref":"FIG. 21"},"Each of  and  shows what is held in the graphics plane after the plane shift engine  shifts the coordinates of each of the pixel data pieces;",{"@attributes":{"id":"p-0045","num":"0046"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0046","num":"0047"},"figref":"FIG. 24","b":"29"},{"@attributes":{"id":"p-0047","num":"0048"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0048","num":"0049"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0049","num":"0050"},"figref":["FIG. 27A","FIG. 27B"],"b":"29"},{"@attributes":{"id":"p-0050","num":"0051"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0051","num":"0052"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0052","num":"0053"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0053","num":"0054"},"figref":["FIG. 31A","FIG. 31B","FIG. 31C"]},{"@attributes":{"id":"p-0054","num":"0055"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0055","num":"0056"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0056","num":"0057"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0057","num":"0058"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0058","num":"0059"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0059","num":"0060"},"figref":"FIG. 37"},{"@attributes":{"id":"p-0060","num":"0061"},"figref":"FIG. 38","b":"15"},{"@attributes":{"id":"p-0061","num":"0062"},"figref":["FIG. 39A","FIG. 38B","FIG. 38C"]},{"@attributes":{"id":"p-0062","num":"0063"},"figref":["FIG. 40A","FIG. 40B","FIG. 40C"]},{"@attributes":{"id":"p-0063","num":"0064"},"figref":"FIG. 41"},{"@attributes":{"id":"p-0064","num":"0065"},"figref":["FIG. 42A","FIG. 42B","FIG. 42C"]}]},"DETDESC":[{},{}]}
