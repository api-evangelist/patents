---
title: Systems, methods, and apparatus for indicating processor hierarchical topology
abstract: The present invention utilizes a topology application programming interface (API) to provide relation information describing processor and platform topology to an executable program via a standardized interface. By providing topology information, the topology API allows the program to optimize its performance based upon the information without having to be explicitly aware of the actual platform architecture. The present invention also provides an expandable topology API that allows for future expansion of information type, without altering the standardized interface. In another instance of the present invention, the topology API collects, processes, and provides topology information about an underlying hardware architecture.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07451459&OS=07451459&RS=07451459
owner: Microsoft Corporation
number: 07451459
owner_city: Redmond
owner_country: US
publication_date: 20030505
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["The present invention relates generally to processor and platform topology, and more particularly to apparatus, systems and methods for indicating processor and platform topology to software program applications in a computing environment.","Computers have become an essential part of our everyday lives. They have the capability to process information quickly and accurately. Because of this, society has embraced utilizing computers for critical needs such as banking, space flight, medical, and air traffic control and the like. Thus, a computer's speed and accuracy are paramount in these types of critical transactions. These characteristics have also been embraced, however, by people expecting the same great performance from computers in non-critical applications such as for large information storage and retrieval systems. Thus, programs, such as database programs and the like, that execute high numbers of transactions per second also require high performance computing systems. These extreme demands on computing systems have driven great gains in the area of computing performance.","A computing system is generally composed of hardware and software components that interact with each other. The hardware components can be described generally as those parts of the computing system that a person can physically touch. These include processors, memory chips, hard drives, connecting wires and traces, and other supporting hardware devices. Typically, the processing hardware components are constructed so that they can recognize two logical states, namely a \u201c0\u201d state (or low electrical state) and a \u201c1\u201d state (or high electrical state). Employing a number of these states together in a sequence allows data to be stored and processed by the hardware. The software components contain instruction sets that utilize the hardware to accomplish a particular task. They are typically written in \u201ccode\u201d that is a high level software language for representing the desired zeroes and ones (or \u201clow\u201d and \u201chigh\u201d states). In this manner, software can be written to accurately control the hardware components to return a desired effect.","As can be expected as technology progresses, the lines between what is hardware and what is software tends to blur a little. Thus, the concept of \u201cfirmware\u201d arises where the name indicates that it is not quite hardware but also not quite software. Generally speaking, firmware is ones and zeroes that reside in somewhat of a permanent state on a hardware component to allow control of the hardware at a low level or \u201croot\u201d level. It is considered \u201cfirm\u201d because it does not change often and is utilized for a particular type of hardware component or platform. Firmware typically handles hardware specific interfaces and the startup sequences of the hardware components.","When computing systems were first developed, it was desirable to have some common software that could handle reading and writing to hard drives and some basic repetitive tasks necessary to operate the computing system. These included diagnostics, data file structures, and human-machine interfaces. A disk operating system was developed initially to handle file structures and basic interfaces. This progressed into what is known today as an \u201coperating system.\u201d Gone are text based user-interfaces and now graphical user interfaces (\u201cGUI\u201d) are considered the norm. Thus, the disk operating system has developed into a full blown, user-oriented operating system that provides a greater amount of flexibility, ease of use, and control over a computing system than was previously achievable.","With fast hardware and an easy to use operating system, all that is needed is a way to get the computing system to behave in a way that gives a desired result. This could be achieved by continuously altering an operating system. However, people typically have different tasks that they want a computing system to perform. So, the operating system remains \u201ccommon\u201d software and additional task specific software is written to perform those specific tasks, called \u201capplication\u201d software (or executable software). For example, if a user wants to balance their checkbook, they can install financial application software on their computing system and perform that task. Thus, having application software allows the computing system to expand its tasking capabilities without changing its hardware components and\/or operating system. Utilizing this type of hardware and software architectural structure allows almost infinite task capability for a given computing system.","The typical limitations on a computing systems task capability can be generally characterized by its speed. How much and how fast a computing system can handle information usually indicates the limits of what the system is capable of achieving. Therefore, increasing the performance of a computing system allows it to be more flexible and to do more work. This can be accomplished in any one of the architectural levels of a computing system. Thus, strides have been made in optimizing hardware components and also software components for speed. As competing hardware manufacturers have introduced new and different hardware architectures for increased performance, often times operating systems and even applications must change also to utilize those changes before performance gains can be realized.","One of the first areas of hardware performance gains was in introducing a data \u201ccache\u201d. This allowed frequently used data to be available quickly to hardware processing components, increasing their speed. Eventually, multi-leveled caches were developed and some even placed on a semiconductor die (\u201conboard\u201d cache) along with the processor to achieve even faster response times. Along with optimizing frequently used data retrieval, manufacturers also worked on increasing the processing speed itself. Processor semiconductor chips were shrunk dramatically in size and new materials were used to get even smaller sized chips. This allowed extremely fast state (zeroes and ones) changes within the processors. Today, processor speeds have reached beyond 3 gigahertz levels with front side bus speeds well over 500 megahertz. Increasing the bus (or \u201cconnection\u201d) speed allows the processors to access \u201coffboard\u201d cache faster, facilitating the processor speed.","Typically, increasing a processor's speed may not require extensive changes to an operating system nor to applications that run on a computing system. These types of changes are generally \u201coverall\u201d performance increases that mean faster processing even with unchanged software. Unfortunately, there are physical limitations to this type of performance increase. Semiconductor sizes are nearing atomic levels where eventually it will not be possible to go any smaller. This has created a push in architectural optimization to increase processing in a computing system. Hardware manufacturers have begun to develop computing platforms (systems) with multiple processors instead of just a single processor. They have also introduced single physical packages that contain multiple processing cores in what used to be only a single processor core. Additionally, recent trends have produced processors with multiple \u201clogical\u201d processors that are utilized, for example, in simultaneous multi-threading. These logical processors are not physical processors, but appear as such from a user's perspective. They typically share functional resources such as adders and memory and the like. Caches have begun to be shared between both physical and logical processors. Buses have also been utilized as shared resources for performance gains. Thus, the hardware components in a computing system have grown quite complex in their architecture and can vary greatly with each computing platform.","This newer breed of enhanced platform optimization requires changes in software to fully realize the platform's potential. The reason for this is the introduction of multiple processing entities, whether they are physical and\/or logical entities. A software application can often increase its performance by utilizing more than one processing entity. This is not always the case because it requires that an application have internal processes that do not require a serial process (i.e., one action must always precede another action in sequence) in order to allow multiple processes to execute at the same time. An application must also be aware that it has access to a platform with multiple processing entities. It must also have its code written so that it can optimize itself based upon a particular processing architecture. Obviously, this requires changes to the software application before a user will obtain increased performance.","Independent software vendors (ISVs) who write applications typically license their applications. Many determine whether a license is being \u201cused\u201d based on how many processors it executes on. With the introduction of multiple processors, multiple cores, and multiple logical processors, this task becomes quite complex. Each computing platform could conceivably have a different architecture. So, regardless of whether for licensing and\/or for performance gains, an ISV must orientate their software application for all possible combinations of architectures found on platforms that they hope their software will operate on. In addition, they must research the architecture, test and execute their code on all of those platforms, sometimes a very daunting task.","Because of the constant need to increase computing system speeds, it is very likely that performance strides will continue to be made. Therefore, it is unlikely that only existing hardware architectures utilized today will be the only ones used in the future. Thus, it is more likely that even higher complexity architectures will be developed with even more varying combinations. This will also drive to increase the complexity of the software applications in order for them to adequately exploit the hardware architecture to fully optimize their application's performance. However, to remain competitive, ISVs must keep pace with the hardware architecture changes to optimize their application's performance or risk losing market share for their products.","The following presents a simplified summary of the invention in order to provide a basic understanding of some aspects of the invention. This summary is not an extensive overview of the invention. It is not intended to identify key\/critical elements of the invention or to delineate the scope of the invention. Its sole purpose is to present some concepts of the invention in a simplified form as a prelude to the more detailed description that is presented later.","The present invention relates generally to processor and platform topology, and more particularly to apparatus, systems and methods for indicating processor and platform topology to software program applications in a computing environment. A topology application programming interface (API) is leveraged to provide relation information describing processor and platform topology to an executable program. By providing topology information, the topology API allows the program to optimize its performance based upon the information without having to be explicitly aware of the actual platform architecture, easily enhancing application performance for a multitude of hardware architectures. The present invention also allows for executable programs to receive the information via a standardized interface that remains common regardless of the type of hardware platform architecture, permitting ISVs to concentrate on development of their task at hand rather than spending time learning new platform architectures, saving time and money.","The present invention also facilitates platform and processor usage by allowing complex architectures to be easily assimilated by executable programs. This permits more advanced architectures to be developed without being concerned that ISVs will not be able to fully optimize the architecture due to its complexity. The topology API provides topology information required to optimize the executable program without an ISV having to learn a new specific architecture. This reduces costs and time associated with development of an executable program, both in reducing its interface complexity and also in reducing the types of experts required for its code development. The present invention also provides an expandable topology API that allows for future expansion of information type, without altering the standardized interface. In this fashion, the present invention can expand its flexibility and does not require an ISV to relearn a new interface. This flexibility drastically decreases the development time of an executable program and, at the same time, enables interactivity with any hardware platform, allowing an ISV to quickly code an executable program and optimize its performance as necessary, maximizing its speed and providing a reliable, highly stable executable program.","To the accomplishment of the foregoing and related ends, certain illustrative aspects of the invention are described herein in connection with the following description and the annexed drawings. These aspects are indicative, however, of but a few of the various ways in which the principles of the invention may be employed and the present invention is intended to include all such aspects and their equivalents. Other advantages and novel features of the invention may become apparent from the following detailed description of the invention when considered in conjunction with the drawings.","The present invention is now described with reference to the drawings, wherein like reference numerals are used to refer to like elements throughout. In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the present invention. It may be evident, however, that the present invention may be practiced without these specific details. In other instances, well-known structures and devices are shown in block diagram form in order to facilitate describing the present invention.","As used in this application, the term \u201ccomponent\u201d is intended to refer to a computer-related entity, either hardware, a combination of hardware and software, software, or software in execution. For example, a component may be, but is not limited to being, a process running on a processor, a processor, an object, an executable, a thread of execution, a program, and\/or a computer. By way of illustration, both an application running on a server and the server can be a computer component. One or more components may reside within a process and\/or thread of execution and a component may be localized on one computer and\/or distributed between two or more computers. A \u201cthread\u201d is the entity within a process that the operating system kernel schedules for execution. As is well known in the art, each thread has an associated \u201ccontext\u201d which is the volatile data associated with the execution of the thread. A thread's context includes the contents of system registers and the virtual address belonging to the thread's process. Thus, the actual data comprising a thread's context varies as it executes.","The present invention provides a simple mechanism to describe a variety of logical processor properties and relationships between logical processors. A logical processor is generally defined as a software code-executing entity with its own unique state (e.g., own registers). Traditional information mechanisms require separate API specification and documentation to relate various logical processor properties and relationships. The present invention provides a common, expandable API for providing a variety of logical processor information. This mechanism can be used, for example, to describe per logical processor cache information, symmetric multi-threading (SMT) relations, multi-core processors, shared package caches, non-uniform memory access (NUMA) node membership, platform caches, and processor bus information and the like utilizing a single interface. The present invention communicates a variety of information about logical processors and various relationships between logical processors via a descriptive but expandable means.","In one aspect of the present invention, this means is accomplished by employing a single API that returns a series of records. The records are organized with three components including a logical affinity mask for representing each logical processor, a relation value indicating the type of property and its relationship described in the record and meta data specific to the property and relationship. Each logical processor in a computing system is represented in the affinity mask by a single bit. Thus, the mask can make the record refer to one or more logical processors within the computing system. The relation value indicates a type of relationship between logical processors specified in the affinity mask. The relation values and meta data may be expanded without modification to the API. This allows for describing various processor properties and relations in a concise manner without mandating the specification, development, and documentation of a new API for each additional bit of functionality. The information provided by the API allows applications easy access to processor and platform information that they can utilize to optimize their applications and\/or implement licensing policy. In another instance of the present invention, an operating system kernel creates and returns these records upon request by an application. In still other instances of the present invention, the API can provide a description of per logical processor caches, multi-core processor relationships, multi-core shared processor caches, and\/or platform caches and the like.","Referring to , a block diagram of a hardware topology system  in accordance with an aspect of the present invention is shown. A topology API  operates within an operating system  on a computing system. The topology API  interfaces with executable software . In this instance of the present invention, the executable software  is comprised of application \u201c1\u201d , application \u201c2\u201d , and application \u201cM\u201d  which represents a series of applications from 1 to \u201cM\u201d, where M is any integer from one to infinity. Thus, the topology API  can be invoked by any number of executable programs or applications. In this particular instance of the present invention, the operating system  interfaces with hardware components  of the computing system. In other instances of the present invention, the topology API  can interface directly with the hardware components . The hardware components include such components as a platform, cache, processors, and buses and the like of a computing system.  only illustrates a series of processors, but the present invention is not limited to only interfacing with processors. The hardware components  in this example are comprised of processor \u201c1\u201d , processor \u201c2\u201d , and processor \u201cN\u201d  which represents a series of processors from 1 to \u201cN\u201d, where N is any integer from one to infinity. In general, however, a typical operating system has a bounded processor handling capability that would limit the total number of processors. In still other instances of the present invention, the processor range is zero to infinity, allowing for circumstances where no processors are available for use by an application.","Thus, the operating system  and\/or the topology API  can interface with any number of hardware components. In this instance of the present invention, the operating system  collects topology data from the hardware components  and generates topology information about the topology data. Data about data is generally referred to as meta data and, thus, the topology information is meta data generated from the topology data. When the topology API  is invoked by a component of the executable software , it provides the topology information to an application (executable software program) via a standardized interface. This allows applications to be \u201chardware topology aware\u201d and to optimize their execution based on the topology of the underlying hardware. And the topology API  allows developers to spend more time developing their task code than researching how to extract topology data from a multitude of hardware component combinations.","Turning to , a block diagram of a hardware topology system environment  in accordance with an aspect of the present invention is illustrated. The environment  is comprised of a hardware component , a firmware component , and a software component . The software component  is comprised of an operating system  and executable programs . A topology API  operates within the operating system . The executable programs, in this instance, are comprised of an application . The topology API  interfaces with the application . In this manner, the application  can invoke the topology API  in order to retrieve topology information via a \u201ccall\u201d or code line invoking the topology API . The hardware component  is comprised of a processor . Typically, the processor  will also have processor cache and a system bus associated with it (not illustrated). The firmware  is comprised of low level platform software and is often represented by \u201cBIOS\u201d  or basic input\/output software. This low level code typically starts the processors and handles any hardware specifics to a particular platform. That is, a typical BIOS is platform specific and facilitates in allowing a more common hardware interface to higher level code such as an operating system. Once the processor  is up and running, the operating system  can then utilize the processor . There are still some types of information that the BIOS  can provide and, therefore, the operating system  typically continues to interface with the BIOS when that information is required.","In this instance of the present invention, the topology API  is invoked by the application  via a standardized interface. The topology API  obtains topology information from the operating system  and provides it to the application  in a format easily discerned by the application . Although, in this instance of the present invention, the operating system  interrogates the hardware component  and the firmware component  and generates topology information, in other instances of the present invention, the topology API  handles some or all of this functionality as well (see infra). In still other instances of the present invention, the topology information can be obtained prior to the topology API  being invoked. For example, the information can be gathered at system startup and the like.","The present invention has a capability to provide topology information about various types of hardware configurations and platforms. Turning to , a block diagram of a hardware topology system processor interface  in accordance with an aspect of the present invention is depicted. In this example, the interface  is comprised of a topology API  linked directly or indirectly to a processor . The processor  is a single core processor comprised of an architectural state , a processor execution engine , and onboard cache . The processor  is also connected to a bus  and can additionally be connected to offboard cache (not shown).  depicts a typical processor in that it has only one architectural state , one execution engine  and one onboard cache . In this instance of the present invention, the topology API  receives information that the processor  is a single core processor with a single architectural state  with no shared resources. This type of hardware configuration has been the standard for computing systems for many years. However, the architectural structures of hardware components and platforms have increased in complexity as illustrated infra. In this particular example, the topology API  provides the topology information to an application when the topology API  is invoked. Under these circumstances, the application will most likely execute in a default or standard mode. This is due to the fact that the application is running on a single core processor, and the application's performance is mainly garnered by the single thread processing speed of the processor .","Hence, it is possible to provide hardware components and platforms that can enable an application to achieve much higher performance than that achieved by utilizing single core processors. Referring to , a block diagram of a hardware topology system multi-core processor interface  in accordance with an aspect of the present invention is shown. The interface  is comprised of a topology API  linked directly or indirectly to a multi-core processor . The processor  is comprised of multiple architectural states , , , multiple processor execution engines , , , and multiple onboard caches , , . The processor  is also connected to a bus  and can additionally be connected to offboard caches (not shown). The processor  can also be connected to multiple buses. In this instance of the present invention, each \u201ccore\u201d of the processor  is comprised of an architectural state, a processor execution engine, and an onboard cache. It can be appreciated that each core can be comprised of more or less components than those illustrated in , such as no onboard cache, shared caches, or multiple caches and the like. In this example, components of a single core of the processor  are represented by the like numbering such as architectural state \u201c1\u201d , processor execution engine \u201c1\u201d , and onboard cache \u201c1\u201d . Grouped together, these elements comprise a first core. Likewise, architectural state \u201c2\u201d , processor execution engine \u201c2\u201d , and onboard cache \u201c2\u201d  represent a second core. And, architectural state \u201cN\u201d , processor execution engine \u201cN\u201d , and onboard cache \u201cN\u201d  represent an Nth core, where N represents the total number of cores and can be any integer from one to infinity. Thus, theoretically, there can be any number of cores within a processor. However, practically speaking, the number of cores is limited by the technology available to manufacture such miniature devices.","The processor  is actually \u201cN\u201d processors that have been manufactured on a single die. Therefore, although the processor  may look like a single processor in a physical sense, it is actually \u201cN\u201d complete and separate processors. When the topology API  is invoked by an application in this instance of the present invention, the topology API  provides the application with topology information indicating that the processor  is a multi-core processor. This allows the application to adjust accordingly to optimize its required processing. Since the processor  contains multiple complete processors, the application can run simultaneous threads to substantially increase its performance. This is due to the fact that each core has a separate execution engine. The only shared resource in this example may be the power supplied to the single physical hardware package. It is also conceivable that the cores can be comprised of separate architectural states and execution engines, but share a single onboard cache. Alternatively, the cores can have no onboard cache.","Multi-core processors can be very expensive to manufacture due to the miniscule scale of the manufacturing technology required to produce complete cores on a single die. As an alternative, other \u201chybrid\u201d or \u201cpartial\u201d core devices have been developed. In , a block diagram of a hardware topology system multi-logic processor interface  in accordance with an aspect of the present invention is depicted. The interface  is comprised of a topology API  linked directly or indirectly to a multi-logic processor . The processor  is comprised of multiple architectural states -, a single processor execution engine , and a single onboard cache . The processor  is also connected to a bus  and can additionally be connected to offboard caches (not shown). The processor  can also be connected to multiple buses. In this instance of the present invention, each \u201clogical processor\u201d of the processor  is comprised of an architectural state, a shared processor execution engine, and a shared onboard cache. It can be appreciated that each logical processor can be comprised of more or less components than those illustrated in , such as no onboard cache or multiple caches and the like. In this illustration example, each logical processor shares the same prosecution engine  and the same cache . The number of logical processors in  can be represented by architecture state \u201c1\u201d , architecture state \u201c2\u201d , architecture state \u201c3\u201d , and architecture state \u201cN\u201d , where N represents the total number of architectural states and can be any integer from one to infinity. Thus, theoretically speaking, there can be any number of logical processors within a physical processor component.","From an application's standpoint, this type of processor appears as multiple separate processors. However, it should be noted that each logical processor must share resources utilized by every other logical processor. Therefore, this type of hybrid processor generally does not produce as high a performance gain as a multi-core processor. When the topology API  is invoked by an application in this instance of the present invention, the topology API  provides the application with topology information indicating that the processor  is a multi-logic processor. This allows the application to adjust accordingly to optimize its required processing. Since the processor  contains multiple logical processors, the application can run simultaneous threads to substantially increase its performance. However, unlike with a multi-core processor, performance is not optimized if the threads require the same shared resources at the same time. Care must be taken to optimize the threads such that they run at times when the other threads are not utilizing the same shared resources. In this manner, application performance can be enhanced. This is due to the fact that each logical processor shares a single execution engine and typically a single cache. It is also conceivable that the processor may have no onboard cache and, thus, the logical processors share an outboard cache along with a shared bus. Thus, the topology information gained from the present invention is vital in optimizing the application.","Obviously, it would be beneficial performance wise to utilize more than one of any type of processor in a computing system platform. Thus, a hardware topology can quickly become even more complex. Turning to , another block diagram of a hardware topology system multi-logic processor interface  in accordance with an aspect of the present invention is illustrated. The interface  is comprised of a topology API , a first multi-logic physical processor , a second multi-logic physical processor , and an \u201cNth\u201d multi-logic physical processor , where N represents the total number of physical processors and can be any integer from one to infinity. Thus, theoretically any number of physically distinct processors can be represented by the interface .","The first multi-logic physical processor  is comprised of logical processor \u201c1\u201d  and logical processor \u201c2\u201d . The second multi-logic physical processor  is comprised of logical processor \u201c3\u201d  and logical processor \u201c4\u201d . The Nth multi-logic physical processor  is comprised of logical processor \u201cX-1\u201d  and logical processor \u201cX\u201d , where X represents the total number of logical processors and can be any integer from one to infinity.  illustrates an example where the topology API  interfaces directly or indirectly with multiple physical processors, each having multiple logical processors. Although for this example each physical processor is shown with only two logical processors, it can be appreciated that each physical processor could have, theoretically, unlimited logical processors. In this instance of the present invention, the logical processors are ordered starting with the logical processors ,  on the first multi-logic physical processor . This numbering then continues in order with the logical processors ,  on the second multi-logic physical processor . The numbering continues in this fashion until the logical processors ,  of the Nth multi-logic physical processor are ordered. Thus, the logical processors are numbered, essentially, in sequence beginning with the first multi-logic physical processor to the last multi-logic physical processor.","This type of ordering system may seem perfectly logical at first glance, but it is generally not considered to be the most efficient use of processing resources. This is due to the way applications typically attempt to utilize processors. For example, an application can send a processing thread # to logical processor \u201c1\u201d  and a thread # to logical processor \u201c2\u201d . This means that the first multi-logic physical processor  is processing both threads at the same time and utilizing the same resources. In this scenario, greater performance gains would be realized if the application sent thread # to logical processor \u201c1\u201d  and thread # to logical processor \u201c3\u201d . This allows the threads to be processed by separate physical processors and no resources are shared between the threads. Thus, it is important to applications to not only know how many logical processors are available, but also how they relate to the physical processors and shared resources. Therefore, when the topology API  is invoked by an application, topology information is provided to the application, so the application can adjust its processing needs accordingly to optimize performance.","Until higher complexity architectures become standard for computing systems, alternative approaches to configuring logical processors generally facilitate better performance without relaying the complexity of the underlying hardware architecture to the applications. In , yet another block diagram of a hardware topology system multi-logic processor interface  in accordance with an aspect of the present invention is shown. The interface  is comprised of a topology API , a first multi-logic physical processor , a second multi-logic physical processor , and an \u201cNth\u201d multi-logic physical processor , where N represents the total number of physical processors and can be any integer from one to infinity. Thus, theoretically any number of physically distinct processors can be represented by the interface .","The first multi-logic physical processor  is comprised of logical processor \u201c1\u201d  and logical processor \u201cX\/2+1\u201d , where X represents the total number of logical processors and can be any integer from one to infinity. Therefore, \u201cX\/2\u201d represents the total number of logical processors divided by two. The significance of the divisor is strictly related to this example which utilizes two logical processors per physical processor. The second multi-logic physical processor  is comprised of logical processor \u201c2\u201d  and logical processor \u201cX\/2+2\u201d . The Nth multi-logic physical processor  is comprised of logical processor \u201cX\/2\u201d  and logical processor \u201cX\u201d .  illustrates another example, similar to , where the topology API  interfaces directly or indirectly with multiple physical processors, each having multiple logical processors. Even though for this example each physical processor is shown with only two logical processors, it can be appreciated that each physical processor could have, theoretically, unlimited processors.","In this instance of the present invention, the logical processors are ordered starting with the logical processor \u201c1\u201d  on the first multi-logic physical processor  and then moving to logical processor \u201c2\u201d  on the second multi-logic physical processor . This numbering then continues in order until the first processor of each multi-logic physical processor has been numbered. In this example, the Nth multi-logic physical processor  has its first logical processor numbered as logical processor \u201cX\/2\u201d. At this point, the numbering goes back to the first multi-logic physical processor  and continues with the second logical processor, logical processor \u201cX\/2+1\u201d  and so on. The numbering ends, in this example, with the second logical processor, logical processor \u201cX\u201d , on the Nth multi-logic physical processor . Thus, all first logical processors are numbered first, followed by all second logical processors and so forth until all logical processors are accounted for on all the multi-logic physical processors. One skilled in the art can also appreciate that if a platform has a mixture of multi-logic, multi-core, and single core processors a similar scheme could be utilized to account for all types of processors.","This type of ordering system allows for the most efficient use of processing resources. This is because applications can assign threads to processors in order without having to know intimate details of processor numbering. This allows each processing thread to be easily sent to a logical processor on a separate physical processor to allow for processing with unshared resources, up to a point. In this example, the point is reached, when the number of threads equals approximately half (utilizing two logical processors per physical processor) the number of available logical processors. At this juncture, the processing threads might have to be sent to a logical processor residing on a physical processor that already has another logical processor processing another thread, possibly slowing its execution due to shared resources.","For example, an application can send a processing thread # to logical processor \u201c1\u201d  and a thread # to logical processor \u201cX\/2+1\u201d . This means that the first multi-logic physical processor  is processing both threads at the same time and utilizing the same resources. In this scenario, greater performance gains would be realized if the application sent thread # to logical processor \u201c1\u201d  and thread # to logical processor \u201c2\u201d . This allows the threads to be processed by separate physical processors and no resources are shared between the threads. Thus, although it is important to applications know how many logical processors are available and their relations, logical processors can be ordered to shelter some of the hardware complexities from the applications. Therefore, when the topology API  is invoked by an application, relevant topology information is provided to the application, so the application can adjust its processing needs accordingly to optimize performance.","In other instances of the present invention, the topology API contains a processing optimization component (not illustrated) that ensures that processors are ordered to obtain an optimal configuration. This component would interact with hardware components directly or indirectly to assign hardware component usage order to allow for optimum hardware component usage. The optimization component, in other instances, can provide performance enhancing means such as better utilization of multiple mixed types of processors within a platform.","As discussed supra, topology information about a computing platform and its processors is critical to the performance of applications. And, due to all of the complexities of underlying hardware, an efficient and standardized means of providing this information is needed. Turning to , another block diagram of a hardware topology system environment  in accordance with an aspect of the present invention is illustrated. This environment  is comprised of an operating system , a set of executable software programs (applications) , and a set of hardware components (platform and processors) . The operating system  interfaces interactively with the executable software programs  and\/or the hardware components . In this instance of the present invention, the operating system  hosts subcomponents comprised of a kernel startup component , a description mechanism component , and a topology API component . In other instances of the present invention, functionality of the kernel startup component  and\/or the description mechanism component  are part of the topology API component . Such an instance of the present invention is denoted by a dashed box in  as an optional topology API . The topology API  interfaces with the set of executable software programs  and utilizes a standardized interface to provide topology information, upon request, to applications within the set of executable programs  relating to the set of hardware components . The kernel startup component  collects topology data from the set of hardware components  and provides it to the description mechanism component . The description mechanism component then generates topology information from the topology data and provides it to the topology API component .","Another example of the interrelationships and functionality of the aforementioned components is illustrated in  which is a process diagram of a hardware topology system  in accordance with an aspect of the present invention. The system  is comprised of a kernel startup component , a description mechanism component , and a topology API component . In this instance of the present invention, functionality of the kernel startup component  is comprised of initializing the kernel , collecting NUMA information from a platform , collecting information about processors and\/or their relationships , and constructing data structures describing the relations . Functionality of the description mechanism component  is comprised of interrogating the data structures built by the kernel startup component , generating affinity mask information, relation value information, and meta data relation information tuples based on the data structures , and creating a data structure describing the relations between processors . Functionality of the topology API component  is comprised of interfacing with applications and allowing the topology API component  to be invoked  and providing relation information describing processor and platform topology to applications via a standardized interface . In other instances of the present invention, a topology API has some or all of the functionality - of the kernel startup component , the description mechanism  and the topology APT component . In yet other instances of the present invention a topology API can accept input from applications and utilize this input to alter topology information provided to the applications.","A typical example of types of topology information is illustrated in . A block diagram of a hardware topology component  in accordance with an aspect of the present invention is shown. The hardware topology component  is comprised of a topology API  containing a logical affinity mask record , a relation value record , and a relation type meta data record . In one instance of the present invention, the logical affinity mask record  utilizes a single bit in the mask to represent each logical processor in a computing system. Thus, the mask record  can be employed to refer to one or more logical processors within the system. The relation value record  indicates a relation type of relationship between the logical processors specified in the affinity mask record . An example of this is symmetric multithreading where logical processors share functional units. The meta data record  includes information specific to the relation type from the relation value record . In this manner, the present invention communicates a variety of information about logical processors and various relationships between logical processors via a descriptive, but expandable means.","The types of topology API information include, but are not limited to, per logical processor cache information, symmetric multithreading relations, multi-core information, shared package cache information, NUMA node membership, platform cache information, and processor bus information. The topology API  allows an operating system to describe various properties and relations in a concise manner without mandating the specification, development, and documentation of a new API for each additional bit of functionality. Additionally, information is provided that allows applications easy access to processor and platform information that the applications can utilize to optimize themselves and\/or utilize to implement licensing policies.","An example of a data structure of records provided by a topology API to an application in one instance of the present invention is illustrated in . A table of a hardware topology component data structure  in accordance with an aspect of the present invention is shown. The data structure  is comprised of a logical affinity mask record column , a relation value record column , and a relation type meta data record column . Each bit of an eight bit set (in this instance only) of digits in the logical affinity mask record column  represents a logical processor in a computing system. The relation value record column  is comprised of a cache type , a processor core type , a NUMA type  and a future relation type . The relation type meta data record column  provides meta information about the types of the relation value record column . The future relation type  illustrates how, in one instance of the present invention, a future relation can be incorporated, such as when the number of digits is expanded from eight to nine digits in the logical affinity mask record column .","Turning to , a diagram of a hardware hierarchical structure  of a computing system in accordance with an aspect of the present invention is illustrated. The example structure  is comprised of a processor group  (also denoted by \u201cA\u201d), a symmetric multithreading group  (also denoted by \u201cB\u201d), a cache group  (also denoted by \u201cC\u201d) and a NUMA node group  (also denoted by \u201cD\u201d). In this particular instance of the present invention, the processor group  is comprised of  processors (P-P). The structure  indicates that at least two processors are grouped to a single SMT within the symmetric multithreading group . Thus, eight SMTs handle the  processors. The structure  also shows that a single cache in the cache group  is shared by at least two SMTs. Thus, the structure  illustrates four caches within the cache group . Each NUMA node of the NUMA node group  handles at least two of the caches from the cache group . The two NUMA nodes   have been designated NUMA \u201c0\u201d  and NUMA \u201c1\u201d . The letter designations within the dotted lines are provided to make easier references between  and  for the various groups.","In , another table of a hardware topology component data structure  in accordance with an aspect of the present invention is depicted. The data structure  is comprised of a processor affinity representation  (also denoted by \u201cA\u201d), an SMT affinity representation  (also denoted by \u201cB\u201d), a cache affinity representation  (also denoted by \u201cC\u201d), and a NUMA node affinity representation  (also denoted by \u201cD\u201d). In this instance of the present invention, the affinity representations - utilize a 16 bit data structure. However, one skilled in the art can appreciate that any size data structure can be utilized by the present invention. The affinity representations in  relate to the hardware hierarchical structure  of . The letter references allow for easy correlation between the figures.","The processor affinity representation  of all \u201cones\u201d indicates that 16 processors are available, where each \u201cone\u201d represents a single processor as shown in FIG. 's processor group . The SMT affinity representation  utilizes the 16 bit data structure to indicate which processors of the processor group  are associated with that particular SMT. As shown in FIG. 's SMT affinity representation , two bits of the 16 bit data structure represent two processors and are located in a specific spot within the 16 bit data structure to indicate which processors are associated with that particular SMT. The cache affinity representation  utilizes a similar structure method to indicate which of the processors of FIG. 's processor group  are associated with the caches in FIG. 's cache group . In this example, four bits of the 16 bit structure shown in  are employed to indicate this relationship. The NUMA node affinity representation  utilizes the 16 bit data structure to indicate which processors of the processor group  are associated with a particular NUMA node. In this example, NUMA node \u201c0\u201d  is related to the first eight processors (P-P in ) and NUMA node \u201c1\u201d  is related to the last eight processors (P-P in ). In this manner, the data structure  allows a topology API to provide information about a computing system's processor and platform topology via a standardized format. The topology API is easily expandable by utilizing the same affinity representation, in this example a 16 bit data structure, and simply adding another relation value type and additional meta data information about that relation value type. Thus, a topology API interface can remain standardized and, at the same time, expandable. This allows applications to easily structure an interface and adapt to any new information without changing the interface.","It should be noted that one skilled in the art can appreciate that a specific bit count for an interface data structure is not required for practicing the present invention. 8-bit, 16-bit, 32-bit, 64-bit, and\/or 128-bit data structures and the like are within the scope of the present invention. Additionally, the present invention can be accomplished utilizing a list as well (e.g., a data structure conveying similar information).","In view of the exemplary systems shown and described above, methodologies that may be implemented in accordance with the present invention will be better appreciated with reference to the flow charts of . While, for purposes of simplicity of explanation, the methodologies are shown and described as a series of blocks, it is to be understood and appreciated that the present invention is not limited by the order of the blocks, as some blocks may, in accordance with the present invention, occur in different orders and\/or concurrently with other blocks from that shown and described herein. Moreover, not all illustrated blocks may be required to implement the methodologies in accordance with the present invention.","The invention may be described in the general context of computer-executable instructions, such as program modules, executed by one or more components. Generally, program modules include routines, programs, objects, data structures, etc. that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments.","In , a flow diagram of a method  of providing hardware topology information in accordance with an aspect of the present invention is depicted. The method  starts  with making a determination as to whether a topology API is being invoked by an application . If it is not, the determination is repeated until the topology API is invoked. However, if the topology API is invoked, the topology API returns relational information describing processor and platform topology to the application that invoked the topology API , ending the flow . This information includes, but is not limited to, an affinity mask information tuple, a relation value information tuple, and a meta data relation information tuple. The information is provided via a standardized interface to facilitate application optimization and licensing related to hardware platform architecture.","Referring to , another flow diagram of a method  of providing hardware topology information in accordance with an aspect of the present invention is illustrated. The method  starts  with making a determination as to whether a topology API is being invoked by an application . If it is not, the determination is repeated until the topology API is invoked. However, if the topology API is invoked, the topology API makes a determination if the application has provided a topology API input . If no input is given, the topology API returns relational information describing processor and platform topology to the application that invoked the topology API , ending the flow . However, if a topology API input is provided by the application, the topology API alters relation information according to the topology API input . This generally is a means to limit the returned information, but the input could also be utilized to increase the information provided by the topology API. In that instance, the information is not constrained, but \u201cenhanced.\u201d and\/or added to. Once the input has been accounted for, the topology API returns the altered relational information describing processor and platform topology to the application that invoked the topology API , ending the flow . This information includes, but is not limited to, an affinity mask tuple, a relation value tuple, and a meta data relation tuple. The information is provided via a standardized interface to facilitate application optimization and licensing related to hardware platform architecture.","Turning to , yet another flow diagram of a method  of providing hardware topology information in accordance with an aspect of the present invention is depicted. The method  starts  with making a determination as to whether a topology API is being invoked by an application . If it is not, the determination is repeated until the topology API is invoked. However, if the topology API is invoked, the topology API then interrogates a hardware platform to collect topology data . The topology API then processes the collected topology data and generates information relating to the topology data such as affinity, relation, and meta data about the relations and the like . Once the information has been generated, the topology API returns the relational information describing processor and platform topology to the application that invoked the topology API , ending the flow . Typically a topology API operates within an operating system and provides an interface between the operating system and an application. In this example illustrated in , the topology API does not rely on the operating system to interrogate, collect and generate information desired by an application. Instead, the topology API itself interrogates, collects, generates and also provides the information requested by the application. Thus, the functionality of a topology API can be increased while the interface to the application remains unaltered.","It should also be noted that in other instances of the present invention (not illustrated), topology API functions include generation and reporting of topology information while an operating system provides the interrogation and collection of relevant data functionalities for a hardware platform.","In order to provide additional context for implementing various aspects of the present invention,  and the following discussion is intended to provide a brief, general description of a suitable computing environment  in which the various aspects of the present invention may be implemented. While the invention has been described above in the general context of computer-executable instructions of a computer program that runs on a local computer and\/or remote computer, those skilled in the art will recognize that the invention also may be implemented in combination with other program modules. Generally, program modules include routines, programs, components, data structures, etc. that perform particular tasks and\/or implement particular abstract data types. Moreover, those skilled in the art will appreciate that the inventive methods may be practiced with other computer system configurations, including single-processor or multi-processor computer systems, minicomputers, mainframe computers, as well as personal computers, hand-held computing devices, microprocessor-based and\/or programmable consumer electronics, and the like, each of which may operatively communicate with one or more associated devices. The illustrated aspects of the invention may also be practiced in distributed computing environments where certain tasks are performed by remote processing devices that are linked through a communications network. However, some, if not all, aspects of the invention may be practiced on stand-alone computers. In a distributed computing environment, program modules may be located in local and\/or remote memory storage devices.","As used in this application, the term \u201ccomponent\u201d is intended to refer to a computer-related entity, either hardware, a combination of hardware and software, software, or software in execution. For example, a component may be, but is not limited to, a process running on a processor, a processor, an object, an executable, a thread of execution, a program, and a computer. By way of illustration, an application running on a server and\/or the server can be a component. In addition, a component may include one or more subcomponents.","With reference to , an exemplary system environment  for implementing the various aspects of the invention includes a conventional computer , including a processing unit , a system memory , and a system bus  that couples various system components, including the system memory, to the processing unit . The processing unit  may be any commercially available or proprietary processor. In addition, the processing unit may be implemented as multi-processor formed of more than one processor, such as may be connected in parallel.","The system bus  may be any of several types of bus structure including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of conventional bus architectures such as PCI, VESA, Microchannel, ISA, and EISA, to name a few. The system memory  includes read only memory (ROM)  and random access memory (RAM) . A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between elements within the computer , such as during start-up, is stored in ROM .","The computer  also may include, for example, a hard disk drive , a magnetic disk drive , e.g., to read from or write to a removable disk , and an optical disk drive , eg., for reading from or writing to a CD-ROM disk  or other optical media. The hard disk drive , magnetic disk drive , and optical disk drive  are connected to the system bus  by a hard disk drive interface , a magnetic disk drive interface , and an optical drive interlace , respectively. The drives - and their associated computer-readable media provide nonvolatile storage of data, data structures, computer-executable instructions, etc. for the computer . Although the description of computer-readable media above refers to a hard disk, a removable magnetic disk and a CD, it should be appreciated by those skilled in the art that other types of media which are readable by a computer, such as magnetic cassettes, flash memory cards, digital video disks, Bernoulli cartridges, and the like, can also be used in the exemplary operating environment , and further that any such media may contain computer-executable instructions for performing the methods of the present invention.","A number of program modules may be stored in the drives - and RAM , including an operating system , one or more application programs , other program modules , and program data . The operating system  may be any suitable operating system or combination of operating systems. By way of example, the operating system  can include a topology API component that utilizes data in accordance with an aspect of the present invention. Additionally, the operating system  can include input data from hardware for interfacing with the topology API in accordance with an aspect of the present invention.","A user can enter commands and information into the computer  through one or more user input devices, such as a keyboard  and a pointing device (e.g., a mouse ). Other input devices (not shown) may include a microphone, a joystick, a game pad, a satellite dish, wireless remote, a scanner, or the like. These and other input devices are often connected to the processing unit  through a serial port interface  that is coupled to the system bus , but may be connected by other interfaces, such as a parallel port, a game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video adapter . In addition to the monitor , the computer  may include other peripheral output devices (not shown), such as speakers, printers, etc.","It is to be appreciated that the computer  can operate in a networked environment using logical connections to one or more remote computers . The remote computer  may be a workstation, a server computer, a router, a peer device or other common network node, and typically includes many or all of the elements described relative to the computer , although, for purposes of brevity, only a memory storage device  is illustrated in . The logical connections depicted in  can include a local area network (LAN)  and a wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, for example, the computer  is connected to the local network  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem (e.g., telephone, DSL, cable, etc.) , or is connected to a communications server on the LAN, or has other means for establishing communications over the WAN , such as the Internet. The modem , which can be internal or external relative to the computer , is connected to the system bus  via the serial port interface . In a networked environment, program modules (including application programs ) and\/or program data  can be stored in the remote memory storage device . It will be appreciated that the network connections shown are exemplary and other means (e.g., wired or wireless) of establishing a communications link between the computers  and  can be used when carrying out an aspect of the present invention.","In accordance with the practices of persons skilled in the art of computer programming, the present invention has been described with reference to acts and symbolic representations of operations that are performed by a computer, such as the computer  or remote computer , unless otherwise indicated. Such acts and operations are sometimes referred to as being computer-executed. It will be appreciated that the acts and symbolically represented operations include the manipulation by the processing unit  of electrical signals representing data bits which causes a resulting transformation or reduction of the electrical signal representation, and the maintenance of data bits at memory locations in the memory system (including the system memory , hard drive , floppy disks , CD-ROM , and remote memory ) to thereby reconfigure or otherwise alter the computer system's operation, as well as other processing of signals. The memory locations where such data bits are maintained are physical locations that have particular electrical, magnetic, or optical properties corresponding to the data bits.",{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 18","b":["1800","1800","1802","1802","1800","1804","1804","1804","1802","1804","1800","1808","1802","1804","1802","1810","1802","1804","1806","1804"]},"In one instance of the present invention, a data packet is transmitted between two or more computer components that facilitates describing processor and platform properties and relations thereof with the data packet comprised, at least in part, of hardware topology information, based, in part, on data from a topology API.","In another instance of the present invention, a computer readable medium storing computer executable components of a system for facilitating describing processor and platform properties and relations thereof that is comprised of a topology API that provides a standardized interface for executable programs and provides information about topology data relating to at least one hierarchical structure of hardware associated with a computing system via the standardized interface.","In yet another instance of the present invention, a computer-readable medium having stored thereon a data structure comprised of a first data field containing at least one affinity mask record relating to data about a hardware topology, a second data field containing at least one relation value record derived from relations of the hardware topology, and a third data field containing at least one meta data record about the relation value record of the hardware topology.","It is to be appreciated that the apparatus, systems and\/or methods of the present invention can be utilized in a hardware hierarchical structure analysis scheme for facilitating computer components and non-computer related components alike. Further, those skilled in the art will recognize that the apparatus, systems and\/or methods of the present invention can be employed in a vast array of electronic related technologies, including, but not limited to, computers, servers and\/or handheld electronic devices and the like.","What has been described above includes examples of the present invention. It is, of course, not possible to describe every conceivable combination of components or methodologies for purposes of describing the present invention, but one of ordinary skill in the art may recognize that many further combinations and permutations of the present invention are possible. Accordingly, the present invention is intended to embrace all such alterations, modifications and variations that fall within the spirit and scope of the appended claims. Furthermore, to the extent that the term \u201cincludes\u201d is used in either the detailed description or the claims, such term is intended to be inclusive in a manner similar to the term \u201ccomprising\u201d as \u201ccomprising\u201d is interpreted when employed as a transitional word in a claim."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 18"}]},"DETDESC":[{},{}]}
