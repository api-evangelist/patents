---
title: Method and system to reduce thrashing in a multi-threaded programming environment
abstract: A method and system to reduce thrashing in a multi-threaded programming environment is disclosed. A method in accordance with one embodiment of the present invention includes intercepting an operating system thread creation request for a function, creating a thread including a stack in response to intercepting the operating system thread creation request, modifying an initial stack pointer of the stack, and executing the function utilizing the thread in response to modifying the initial stack pointer.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06978466&OS=06978466&RS=06978466
owner: Intel Corporation
number: 06978466
owner_city: Santa Clara
owner_country: US
publication_date: 20020102
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","DETAILED DESCRIPTION"],"p":["1. Field of the Invention","The present invention relates generally to an improved method and system for data processing. More particularly, the present invention relates to a method and system to reduce thrashing in a multi-threaded programming environment.","2. Description of the Related Art","Many conventional data processing systems include operating systems which provide a multithreaded programming environment. Multithreading is the ability of an operating system to manage the use of a process by more than one entity (e.g. a user or another process) at a time or multiple requests for use by a single entity using a single copy of the process in memory. Each process managed by the operating system defines a virtual address space including code, data, and one or more threads associated with the process. Each thread within a process in turn defines a path of execution through the process and may include data processing system state (e.g. processor state) and a stack beginning at an aligned virtual address boundary. For example, under the Windows\u2122 operating system available from Microsoft\u2122 Corporation of Redmond, Wash., each thread's stack is created on a 1 MB (megabyte) boundary.","As a thread is executed on a processor, it accesses data at a location within its stack using the location's corresponding virtual addresses. In many modem data processing systems, the data may be stored in an entry within a virtually-addressable cache memory associated with the thread's processor which is indexed or \u201ctagged\u201d using the least significant bit(s) (e.g. the least significant 16 bits) of the data location's virtual address. In a data processing system having such a virtually-addressable cache memory shared among multiple physical or virtual processors, several threads may be created for a given process and the virtual addresses of corresponding locations within each thread's stack may be distinguishable only by the most significant bit(s) of the virtual address which designate the stack's starting boundary and initial stack pointer. As a result, thread execution and stack access within such multiprocessor data processing systems may cause shared, virtually-addressable caches to thrash.","A method and system to reduce thrashing in a multi-threaded programming environment are described herein. In the following detailed description, numerous specific details such as specific data processing system, processor, and process address space elements, structures, architectures, and configurations are set forth in order to provide a more thorough understanding of the present invention. It should be evident however, that these and other specific details described need not be utilized to practice the present invention. In other circumstances, well-known structures, elements, operations, or connections have been omitted, or have not been described in particular detail in order to avoid unnecessarily obscuring the present invention.",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 1","b":["100","102","104","106","102","104","108","110","108","110","104"]},"MCH  may comprise a suitable interface controller to provide for any suitable communication link to processor system bus  and\/or to any suitable device or component in communication with MCH . MCH  in one embodiment provides suitable arbitration, buffering, and coherency management for each interface.","MCH  is coupled to processor system bus  and provides an interface to processor(s)  over the processor system bus . Processor(s)  may, in alternative embodiments of the present invention be combined with MCH  or chipset  to form a single chip. MCH  in one embodiment also provides an interface to a memory  and a graphics controller , each of which may be coupled to MCH  as illustrated. Memory  is capable of storing data and\/or instructions executable on a processor such as one of the processor(s)  of data processing system  and may comprise any suitable memory such as, for example, dynamic random access memory (DRAM). Graphics controller  controls the display of information on a suitable display , such as a cathode ray tube (CRT) or liquid crystal display (LCD) for example, coupled to graphics controller . In the illustrated embodiment, MCH  interfaces with graphics controller  through an accelerated graphics port. It should be appreciated however that the present invention may be practiced using any suitable graphics bus or port standard. In one embodiment graphics controller  may alternatively be combined with MCH  to form a single chip.","MCH  is also coupled to ICH  to provide access to ICH  through a hub interface. ICH  provides an interface to I\/O devices or peripheral components for data processing system . ICH  may comprise any suitable interface controller to provide for any suitable communication link to MCH  and\/or to any suitable device or component in communication with ICH . ICH  in one embodiment provides suitable buffering and arbitration for each interface.","In the illustrated embodiment, ICH  further provides an interface to a network interface controller , a mass storage device , and to a keyboard , a mouse , a floppy disk drive , as well as additional devices via one or more standard parallel  or serial  ports through a super I\/O controller . Network interface controller  or alternatively a modem codec (not illustrated) may be utilized to couple data processing system  to a suitable communications network via various well-known methods. Mass storage device  may comprise any suitable device or component to store data and\/or instructions such as a tape or fixed disk magnetic storage device, or an optical storage device such as a compact disk (CD) or digital versatile disk (DVD) read only memory (ROM) device. In one embodiment of the present invention, mass storage device  comprises one or more hard disk drives (HDD). In the illustrated embodiment, ICH  also provides an interface to an expansion bus bridge  to facilitate the attachment of additional I\/O devices or peripheral components via an expansion bus such as a Peripheral Component Interconnect (PCI), Industry Standard Architecture (ISA), or Universal Serial (USB) bus (not illustrated).","Embodiments of the present invention may include software, data processing hardware, and various processing methods and operations, further described herein. The features, methods, and process operations of the present invention may be embodied in executable instructions embodied within a machine-accessible medium such as memory , mass storage device , removable disk media coupled with floppy disk drive , a communications network available via network interface controller , or the like.","A machine-accessible medium may include any mechanism that provides (i.e., stores and\/or transmits) information in a form accessible by a machine (e.g., data processing system ). For example, a machine-accessible medium includes but is not limited to: read only memory (ROM); random access memory (RAM); magnetic disk storage media; optical storage media; flash memory devices; electrical, optical, acoustical or other form of propagated signals (e.g., carrier waves, infrared signals, digital signals, etc.); or the like. The instructions can be used to cause a general or special purpose processor such as one or more of processor(s) , programmed with the instructions, to perform methods or processes of the present invention. Alternatively, the features, methods, and operations of the present invention may be performed by specific hardware components that contain hard-wired logic, or by any combination of programmed data processing components and custom hardware components.","It should also be appreciated that the present invention may be practiced utilizing a data processing system  having a greater or lesser number of components as the illustrated exemplary system. For example, data processing system  may comprise, in alternative embodiments of the present invention, one of a wide variety of server or client computer systems or devices such as a workstation, personal computer, \u201cthin client\u201d (i.e. network computer or NetPC), Internet appliance, terminal, palmtop computing device, robust cellular or Personal Communications Services (PCS) telephone, \u201cthin server\u201d (sometimes called an appliance server, application server, or specialty server), or the like.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 2","FIG. 1"],"b":["102","102","202","204","206","208","210","202","206"]},"Processor core  may comprise any number of functional units (not illustrated) such as instruction fetch units, instruction decode units, instruction dispatch units, integer or floating point execution units, reorder buffers, instruction retirement units, or the like to execute instructions and process data. In one embodiment, processor  provides support for at least two virtual processors sharing processor core  and L1 cache  by maintaining a separate set or copy of architectural registers  corresponding to each virtual processor. Architectural registers  define the architectural state of the processor  and may include basic program execution registers such as an instruction pointer or program counter, various execution flags, and general purpose registers to store data and instructions to be processed, executed, or otherwise manipulated by processor core , as well as various other registers utilized in the operation of processor . In one embodiment, a thread may include data processing system state in the form of the values of one or more of architectural registers .","BIU  may be utilized to couple processor  to data processing system  via a processor system bus , allowing processor  to load and to store data and instructions to and from memory . Data and instructions retrieved from memory  via BIU  or produced by processor core  may be stored within one or more of L1 cache  and L2 cache . In one embodiment, L1 cache  and L2 cache  function hierarchically to provide data and instructions to processor core . In one embodiment, L2 cache  stores a subset of the data and\/or instructions found within memory  indexed utilizing a physical address generated by an address translation functional unit (not illustrated) within processor . In another embodiment, L1 cache  in turn stores a subset of the data and\/or instructions found within the L2 cache  indexed utilizing a virtual address generated by the processor core .","L1 cache  is checked first on a memory access to determine whether a desired block or memory location is (a cache hit) or is not (a cache miss) present utilizing a virtual address generated by processor core . In one embodiment, only the least significant bit(s) (e.g. the least significant 16 bits) are utilized for the described L1 cache  hit\/miss resolution. On a cache miss, L2 cache  is checked to determine whether the desired block or memory location is present using a physical address generated by an address translation unit (not illustrated). If the desired block or memory location is not present within the L1 cache  or L2 cache , it may be retrieved from memory  via the processor system bus  and BIU  and stored within the L1  and\/or L2  cache for future access.","It should be appreciated that in alternative embodiments of the present invention L1 cache  and\/or L2 cache  may be located outside and separate from processor  and may be unified (i.e. containing instructions and data) or split. Similarly, in other embodiments, L1 cache  and L2 cache  may be arranged differently within processor . For example, L1 cache may be coupled directly to BIU  rather than or in addition to being coupled to BIU  via L2 cache . In still other embodiments, L2 cache  may be indexed via a virtual address rather than a physical address or eliminated altogether.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 3","b":["302","304","306","308"]},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 4","b":["400","402","404","406","402","404","406","400"]},"Operating system private region  and shared region  together may include operating system code, memory-mapped files, dynamic-link libraries (DLLs), and applications or other components or resources utilized by an operating system or shared among the data processing system's other processes. In one embodiment, shared region  includes a kernel dynamic-link library (DLL)  such as the Kernel32 DLL of the Win32\u2122 application programming interface (API). Kernel DLL  may in turn include an operating system thread creation function  such as the CreateThread function provided by the Win32\u2122 API. In alternative embodiments, operating system thread creation function  may comprise an alternate Win32\u2122 or Microsoft\u2122 Foundation Class (MFC) thread creation function (e.g., beginthread, beginthreadex, cwinthread, afxbeginthread) or any one of a number of non-Win32\u2122-based (e.g. Unix\/Posix) thread creation functions.","In one embodiment, process private region  comprises a stack area , an application , and a thread creation dynamic-link library  according to the present invention. In an alternative embodiment, process private region  may additionally comprise one or more conventional dynamic-link libraries . Thread creation dynamic-link library  may include an initialization function , a substitute thread creation function , a thread stack modification function , and a reference table . In the illustrated embodiment, thread creation DLL , application , and conventional dynamic-link library  may each contain a reference table (e.g. a Windows\u2122 \u201cthunk\u201d table) to dynamically resolve or bind addresses or other references to various functions within address space  at run time. For example, reference table  may include a reference  to operating system thread creation function  within kernel DLL  which is utilized whenever a call to operating system thread creation function  is made within thread creation dynamic-link library .","Once thread creation DLL  is loaded within address space , initialization function  is called or invoked to initialize the thread creation DLL . In one embodiment, initialization function first detects the processor type to determine if the method and system of the present invention may be or should be implemented. Referring now to , a logic flow diagram of the initialization function  of  according to an embodiment of the method of the present invention is illustrated. The illustrated function process begins and thereafter the thread creation DLL  is linked with application  (block ) and then initialized (block ).","In one embodiment, initialization of the thread creation DLL  comprises identifying each program module loaded within address space  which is linked or otherwise associated with application , saving an original reference table reference for at least one of a plurality of functions including the following Win32\u2122 API functions: CreateThread, ExitProcess, GetProcAddress, LoadLibraryA, LoadLibraryExA, LoadLibraryExW, and LoadLibraryW for each identified program module as well as application , and then replacing each of the original reference table references with a reference to a corresponding substitute function within the thread creation DLL . A program module may comprise hardware, firmware, or software such as a dynamic-link library, an application, or any subroutine or sub-function thereof.","Thereafter, initialization function  determines when any function is called or invoked by application  (block ). When a function is called, it is then determined whether the function call was for an ExitProcess function (block ) or at least one of a plurality of functions including the following Win32\u2122 API functions: GetProcAddress, LoadLibraryA, LoadLibraryExA, LoadLibraryExW, and LoadLibraryW (block ). If the application function call was for at least one of the GetProcAddress, LoadLibraryA, LoadLibraryExA, LoadLibraryExW, and LoadLibraryW functions it is then determined whether or not the reference tables for all program modules linked or otherwise associated with application  have been modified (block ) during the original initialization of the thread creation DLL .","If it is determined that all program modules linked or otherwise associated with application  have been modified, initialization function  waits for an application function call (block ), otherwise, initialization function  saves an original reference table reference for at least one of the GetProcAddress, LoadLibraryA, LoadLibraryExA, LoadLibraryExW, and LoadLibraryW functions (block ) and then replaces each of the original reference table references with a reference to a corresponding substitute function within the thread creation DLL  (block ) and then waits until an application function call is received (block ).","If it is determined that a received application function call was for an ExitProcess function, it is then determined whether or not the reference tables for any program modules linked or otherwise associated with application  have been modified (block ). If no such program modules have been modified, the illustrated process terminates immediately. Otherwise, the initialization function replaces each reference table reference to a substitute function within thread creation DLL  with a corresponding saved original reference table reference (block ) and then terminates. If it is determined (blocks  and ) that the received application function call was not for any of the described functions, the initialization function  then waits until an application function call is received (block ).","Referring again to the embodiment illustrated in , the execution of initialization function  causes references  to operating system thread creation function  within reference tables  and  of application  and conventional DLL , respectively to be replaced with references  to substitute thread creation function . Accordingly, whenever a call to operating system thread creation function  is made for a function within application  or conventional DLL , the substitute thread creation function  of the present invention is executed. Referring now to , a logic flow diagram of a substitute thread creation function  of  according to an embodiment of the method of the present invention is illustrated. The illustrated function process begins when a call to operating system thread creation function  is made for a first function within application  or conventional DLL . A reference to the first function and a function parameter are passed as arguments by a caller and received by the substitute thread creation function  (block ). Thereafter, a stack pointer offset is determined (block ).","The value of the stack pointer offset may be determined using a variety of techniques. In one embodiment, a round-robin technique is utilized in which the stack pointer offset value is determined based on the number of threads executing within the address space  of the process. For example, the first thread to be created may have no stack pointer offset with the stack pointer of all subsequently created threads being increased by a fixed amount (e.g. 1 KB) which may be selected or calculated based on the total number of threads in the system. In an alternative embodiment, a random stack pointer offset may be selected. In yet other embodiments, the stack pointer offset value may be determined based on the function for which a thread is to be created, the function stack frame size, and\/or the level of thrashing present or the cache line size in an associated cache.","Once the stack pointer offset has been determined, a data structure is created including the reference to the first function, the function parameter, and the stack pointer offset (block ). A call is then generated to operating system thread creation function  including a reference to thread stack modification function  and a reference to the created data structure (block ). Thereafter, the illustrated process terminates. Referring briefly to , each time a call is generated to operating system thread creation function  as described, a new thread is created for thread stack modification function . For each new thread, a new stack is created within stack area  having a starting boundary and initial stack pointer on an aligned virtual address boundary (e.g., on a 64 KB or 1 MB virtual address boundary).","Referring now to , a logic flow diagram of a thread stack modification function  of  according to an embodiment of the method of the present invention is illustrated. The illustrated function process begins when a thread created for thread stack modification function  executes and the thread stack modification function  then receives the created data structure including the reference to the first function, the function parameter, and the stack pointer offset (block ). In one embodiment, thread stack modification function  then copies the reference to the first function, the function parameter, and the stack pointer offset into local variables and frees or deallocates the data structure's associated memory. Next, the initial stack pointer of the created thread's stack is modified utilizing the stack pointer offset (block ).","The initial stack pointer of the created thread's stack may also be modified utilizing a variety of techniques. In one embodiment, the initial stack pointer is modified by dynamically allocating a stack-pointer-offset-sized amount of memory on the stack using an \u201calloca\u201d function call. In an alternative embodiment, the initial stack pointer may be modified or incremented using assembly code (e.g., an \u201cadd\u201d or \u201cshift\u201d assembly instruction) directly. Once the initial stack pointer of the created thread's stack has been modified, thread stack modification function  executes the first function utilizing the reference to the first function and the function parameter (block ) and the illustrated process terminates.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 8","FIG. 4"],"b":["412","412","802","804","806","802"],"i":["a\u2013e ","a\u2013e ","a\u2013e ","a\u2013e, "]},"In the foregoing description, the present invention has been described with reference to specific exemplary embodiments thereof. It will be apparent however, that variations or modifications of the exemplary embodiments described as well as alternative embodiments of the present invention may be implemented without departing from the broader spirit or scope of the present invention as defined in the appended claims. The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings in which similar references are utilized to indicate similar elements and in which:",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":["FIG. 2","FIG. 1"],"b":"102"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":["FIG. 5","FIG. 4"],"b":"426"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 6","FIG. 4"],"b":"428"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 7","FIG. 4"],"b":"430"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIG. 8","FIG. 4"],"b":"412"}]},"DETDESC":[{},{}]}
