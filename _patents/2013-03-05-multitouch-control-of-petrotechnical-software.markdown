---
title: Multitouch control of petrotechnical software
abstract: A method can include commencing a petrotechnical analysis workflow that includes a plurality of tasks; initializing one or more touch modules associated with the workflow; accessing data associated with the workflow; rendering one or more visualizations of the data to a touchscreen; and sensing multiple touches via the touchscreen for controlling one or more actions associated with the workflow according to the one or more touch modules. Various other apparatuses, systems, methods, etc., are also disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09329690&OS=09329690&RS=09329690
owner: SCHLUMBERGER TECHNOLOGY CORPORATION
number: 09329690
owner_city: Sugar Land
owner_country: US
publication_date: 20130305
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This application claims priority to and the benefit of U.S. Provisional Patent Application Ser. No. 61\/609,034, entitled \u201cMultitouch Control of Petrotechnical Software\u201d, filed 9 Mar. 2012, which is incorporated by reference herein in its entirety.","Various devices include technologies for multitouch input, gesture input, etc. As an example, consider a tablet device that includes a touchscreen that may support touch-based gestures for viewing photos where a pinch gesture may resize a photo and a swipe gesture may cause another photo to be presented. In such an example, the gestures allow a user to control two basic functions associated with a particular task, i.e., viewing photos. Various technologies, techniques, etc., described herein pertain to controlling functions associated with parallel tasks, serial tasks, multi-user tasks, etc., for example, which may be part of a workflow or workflows.","A method can include commencing a petrotechnical analysis workflow that includes a plurality of tasks; initializing one or more touch modules associated with the workflow; accessing data associated with the workflow; rendering one or more visualizations of the data to a touchscreen; and sensing multiple touches via the touchscreen for controlling one or more actions associated with the workflow according to the one or more touch modules. A system can include a processor; memory operatively coupled to the processor; and one or more modules stored in the memory that include instructions executable by the processor to instruct the system to commence a petrotechnical analysis workflow that includes a plurality of tasks; initialize one or more touch modules associated with the workflow; access data associated with the workflow; render one or more visualizations of the data to a touchscreen; and sense multiple touches via the touchscreen for controlling one or more actions associated with the workflow according to the one or more touch modules. One or more computer-readable storage media can include computer-executable instructions to instruct a computing device to: commence a petrotechnical analysis workflow that includes a plurality of tasks; initialize one or more touch modules associated with the workflow; access data associated with the workflow; render one or more visualizations of the data to a touchscreen; and sense multiple touches via the touchscreen for controlling one or more actions associated with the workflow according to the one or more touch modules. Various other apparatuses, systems, methods, etc., are also disclosed.","This summary is provided to introduce a selection of concepts that are further described below in the detailed description. This summary is not intended to identify key or essential features of the claimed subject matter, nor is it intended to be used as an aid in limiting the scope of the claimed subject matter.","The following description includes the best mode presently contemplated for practicing the described implementations. This description is not to be taken in a limiting sense, but rather is made merely for the purpose of describing the general principles of the implementations. The scope of the described implementations should be ascertained with reference to the issued claims.","In geophysics, a process that may be referred to interpretation can include analyzing data, for example, to generate reasonable models and predictions about the properties and structures of a geologic environment (e.g., subsurface properties and structures). As an example, one type of data to be interpreted may be seismic data. For example, a three-dimensional volume of seismic data may be organized by numerous closely-spaced seismic lines (e.g., inlines and crosslines) where spacing aims to provide a high spatially sampled measure of subsurface reflectivity. Such a data volume may be \u201ccut\u201d, transformed, processed, etc. Interpretation of a seismic volume may include cutting, transforming, processing, etc., as part of an effort to identify geological events, geobodies, etc. and to locate such features in their proper vertical and horizontal positions. As an example, a user may cut a seismic volume to present a two-dimensional surface and then identify a feature on that two-dimensional surface and then re-cut the seismic volume in an effort to identify the same feature in another plane (e.g., on another two-dimensional surface), etc.","As an example, interpretation of seismic data may be provided as part of a petrotechnical service, for example, that may use petrotechnical software to access data, analyze data, etc. Petrotechnical services may be provided using a team approach, for example, where various tasks are divided amongst members of the team. In such an example, an overall workflow may exist, which may change depending on individual tasks performed by team members. Thus, collaboration may benefit team members, for example, to help ensure that appropriate adaptations may take place to the workflow in response to results stemming from the performance of one or more tasks.","As an example, consider dividing a seismic volume into eight sectors distributed to eight individuals for interpretation. In such an example, a feature may emerge from one sector and continue to another sector. With collaboration, an individual may temporarily grab the other sector (e.g., a visual representation of seismic data for the other sector) and mark it to expedite interpretation of that other sector by another individual. More specifically, a touchscreen may provide for rendering multiple views of multiple sectors, for example, where an individual may perform tasks on one sector while viewing tasks being performed on one or more neighboring sectors. Where multitouch commands are available, an individual may, for example, grab a neighboring sector to assist another individual and, in turn, expedite the overall workflow.","While the foregoing example mentions individuals performing tasks that may have commonalities, petrotechnical services may employ individuals across a broad range of disciplines, for example, for purposes of reservoir characterization, interpretation, reservoir and production solutions, geomechanics studies, rapid evaluations, field-development planning, etc.","As an example, petrotechnical services may include geomechanics petrotechnical services (e.g., predicting drilling risks, maximizing recovery from mature assets, etc.), unconventional resources petrotechnical services (e.g., improving recovery of unconventional resources, providing solutions across a project life cycle, etc.), shale oil petrotechnical services, accelerated unconventional play assessment petrotechnical services, petrophysics interpretation services (e.g., processing, interpretation, integration of E&P data, etc.), geology interpretation services (e.g., borehole imaging services for microresistivity formation images, etc.), geophysics interpretation services (e.g., integrating seismic attribute interpretation and analysis with the results of stratigraphic, structural, and geochemical analysis to identify prospects, etc.), etc.",{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 1","b":["100","110","150","110","150","150","160","110"]},"In the example of , the management components  include a seismic data component , an additional information component  (e.g., well\/logging data), a processing component , a simulation component , an attribute component , an analysis\/visualization component  and a workflow component . In operation, seismic data and other information provided per the components  and  may be input to the simulation component .","In an example embodiment, the simulation component  may rely on entities . Entities  may include earth entities or geological objects such as wells, surfaces, reservoirs, etc. In the system , the entities  can include virtual representations of actual physical entities that are reconstructed for purposes of simulation. The entities  may include entities based on data acquired via sensing, observation, etc. (e.g., the seismic data  and other information ).","In an example embodiment, the simulation component  may rely on a software framework such as an object-based framework. In such a framework, entities may include entities based on pre-defined classes to facilitate modeling and simulation. A commercially available example of an object-based framework is the MICROSOFT\u00ae .NET\u2122 framework (Redmond, Wash.), which provides a set of extensible object classes. In the .NET\u2122 framework, an object class encapsulates a module of reusable code and associated data structures. Object classes can be used to instantiate object instances for use in by a program, script, etc. For example, borehole classes may define objects for representing boreholes based on well data.","In the example of , the simulation component  may process information to conform to one or more attributes specified by the attribute component , which may include a library of attributes. Such processing may occur prior to input to the simulation component . Alternatively, or in addition, the simulation component  may perform operations on input information based on one or more attributes specified by the attribute component . In an example embodiment, the simulation component  may construct one or more models of the geologic environment , which may be relied on to simulate behavior of the geologic environment  (e.g., responsive to one or more acts, whether natural or artificial). In the example of , the analysis\/visualization component  may allow for interaction with a model or model-based results. Additionally, or alternatively, output from the simulation component  may be input to one or more other workflows, as indicated by a workflow component .","In an example embodiment, the management components  may include features of a commercially available simulation framework such as the PETREL\u00ae seismic to simulation software framework (Schlumberger Limited, Houston, Tex.). The PETREL\u00ae framework provides components that allow for optimization of exploration and development operations. The PETREL\u00ae framework includes seismic to simulation software components that can output information for use in increasing reservoir performance, for example, by improving asset team productivity. Through use of such a framework, various professionals (e.g., geophysicists, geologists, and reservoir engineers) can develop collaborative workflows and integrate operations to streamline processes. Such a framework may be considered an application and may be considered a data-driven application (e.g., where data is input for purposes of simulating a geologic environment).","As an example, the simulation component  may include one or more features of a simulator such as the ECLIPSE\u2122 reservoir simulator (Schlumberger Limited, Houston Tex.), the INTERSECT\u2122 reservoir simulator (Schlumberger Limited, Houston Tex.), etc. As an example, a reservoir or reservoirs may be simulated with respect to one or more enhanced recovery techniques (e.g., consider a thermal process such as SAGD, etc.). As an example, a simulator may accept as input a grid such as, for example, a structured grid for purposes of simulating one or more physical phenomena. As an example, such a structured grid may be generated by transforming a grid in a computational space to a grid in a real space, for example, where one or more faults have been introduced into the grid in the computational space such that the one or more faults exist in the structured grid in the real space (e.g., structured according to an indexing system).","In an example embodiment, various aspects of the management components  may include add-ons or plug-ins that operate according to specifications of a framework environment. For example, a commercially available framework environment marketed as the OCEAN\u00ae framework environment (Schlumberger Limited, Houston, Tex.) allows for seamless integration of add-ons (or plug-ins) into a PETREL\u00ae framework workflow. The OCEAN\u00ae framework environment leverages .NET\u00ae tools (Microsoft Corporation, Redmond, Wash.) and offers stable, user-friendly interfaces for efficient development. In an example embodiment, various components may be implemented as add-ons (or plug-ins) that conform to and operate according to specifications of a framework environment (e.g., according to application programming interface (API) specifications, etc.).",{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 1","b":["170","180","190","195","175","170","180"]},"The model simulation layer  may provide domain objects , act as a data source , provide for rendering  and provide for various user interfaces . Rendering  may provide a graphical environment in which applications can display their data while the user interfaces  may provide a common look and feel for application user interface components.","In the example of , the domain objects  can include entity objects, property objects and optionally other objects. Entity objects may be used to geometrically represent wells, surfaces, reservoirs, etc., while property objects may be used to provide property values as well as data versions and display parameters. For example, an entity object may represent a well where a property object provides log information as well as version information and display information (e.g., to display the well as part of a model).","In the example of , data may be stored in one or more data sources (or data stores, generally physical data storage devices), which may be at the same or different physical sites and accessible via one or more networks. The model simulation layer  may be configured to model projects. As such, a particular project may be stored where stored project information may include inputs, models, results and cases. Thus, upon completion of a workflow task (e.g., a workstep), a modeling session, etc., a user may store a project. At a later time, the project can be accessed and restored using the model simulation layer , which can recreate instances of the relevant domain objects.","In the example of , the geologic environment  may be outfitted with any of a variety of sensors, detectors, actuators, etc. For example, equipment  may include communication circuitry to receive and to transmit information with respect to one or more networks . Such information may include information associated with downhole equipment , which may be equipment to acquire information, to assist with resource recovery, etc. Other equipment  may be located remote from a well site and include sensing, detecting, emitting or other circuitry. Such equipment may include storage and communication circuitry to store and to communicate data, instructions, etc.","As mentioned the system  of  may be used to perform one or more tasks, workflows, etc. For example, the system  may include a workflow editor module to create, edit, etc. one or more workflows. As an example, the system  may include a task (e.g., or workstep) creator that can create, edit, etc. one or more tasks (e.g., or worksteps). As an example, the system  may include options to associate a task with one or more multitouch commands, which may include gesture commands. For example, where a user implements an interpretation tool (e.g., as part of a framework) to perform a task using a touchscreen, the one or more multitouch commands may become available; whereas, if the user is not using a touchscreen, the commands may be available via other means such as a keyboard, a mouse, a trackball, etc. As an example, a workflow may be created that provides multitouch command options that can be implemented for use on appropriate multitouch hardware. Such a workflow may be created for performance by an individual or a team, for example, with appropriate provisions to optionally allow for mixed hardware types (e.g., one individual with a touchscreen and another individual with a trackball).","As to types of hardware that may be considered suitable for multitouch input, for example, consider capacitive, resistive, acoustic, optical, embedded and other technologies. As an example, a capacitive multitouch device may include circuitry for projected capacitance, surface capacitance, etc. Touch technology may include circuitry for sensing voltage, current, ultrasonic waves, capacitance change, light, images, force, etc. Multitouch may be defined, for example, as an ability to recognize two or more simultaneous touch points. As described herein, multitouch may include time dependent touch or touches, which may optionally be performed using a single digit (e.g., index finger tapping, etc.).",{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 2","b":["201","210","230","234","201","202","205","206","207","202","203","204","205","202","206","207","204","203"]},"As to the method , it includes a touchscreen sensor block , that provides information to a controller\/driver block  that can instruct an operating system block  to interact with an application block  (e.g., which may be implemented using software, a framework, a plug-in, an API, etc.). As an example, the touchscreen sensor block  may be configured to sense multiple simultaneous points (e.g., touches), the controller\/driver block  may be configured to deliver sets of simultaneous points to the operation system block  to allow the operating system block  to forward multiple streams of moving points (e.g., and optionally acting on a defined subset thereof) to the application block , which may be configured to decode the multiple streams of moving points and taking one or more actions in response.","As an example, an interface device (e.g., for sensing touch) may implement one or more operating systems. As an example, consider the family of iOS\u00ae operating systems (marketed by Apple Inc., Cupertino, Calif. under license of a trademark of Cisco Systems, Inc., San Jose, Calif.). As to some other examples, one or more of the following operating systems may be implemented WINDOWS\u00ae OS family (Microsoft Corp., Redmond, Wash.), ANDROID\u2122 OS family (a trademark of Google Inc., Mountain View, Calif.), the PALM\u00ae (or Garnet) OS family (Hewlett-Packard Co., Palo Alto, Calif.), etc.","Software operating on a computing device may include a seismic-to-simulation software suite, such as the PETREL\u00ae software (which may be referred to herein as a framework); noting that the PETREL\u00ae framework is an example as other petrotechnical softwares may include code, plug-ins, APIs, etc. for one or more techniques, technologies, etc. described herein (e.g., consider the ECLIPSE\u00ae, the GEOFRAME\u00ae, the INTERSECT\u00ae, the PIPESIM\u00ae, the TECHLOG\u00ae and the MALCOM\u00ae families of technologies).","In the example of , the screen  includes peripheral features that may be referred to as \u201cchrome\u201d (e.g., file menu and top tool bars , bottom tool bars , and right tool bars ) and more central features (e.g., panes  and windows  and ). As an example, a system may act to stream content being rendered to the screen  to the screen . As an example, such an approach may enhance collaboration where the screen  is being used at one location and the screen  is being used at another location. As an example, a user at the screen  may initiate streaming to one or more other screens such as the screen  or a user at the screen  may initiate streaming from the screen , or optionally vice versa. As to streaming techniques, a technique may be hardware dependent, bandwidth dependent, etc. For example, where the screen  is a screen of a smart phone, a data compression technique may compress data prior to transmitting the data via a cellular phone network to the smart phone. As an example, image data may be streamed rather than underlying data. As an example, where a screen renders vector processed data, streaming may stream the data and vector instructions for remote processing or optionally, for example, stream an image of rendered vector processed data (e.g., consider a print screen command that captures a screen image that may then be communicated for rendering at another device). As an example, streaming may include pixel or voxel streaming.","As an example, streaming may include streaming content without chrome. For example, content of the window  of the screen  may be streamed to the screen  without the one or more pieces of chrome (see, e.g., items ,  and ). As an example, streaming may include streaming a portion of a screen. For example, either of the window  or the window  may be streamed and rendered on the screen .","As an example, a system may include a remote device (e.g., a tablet device) with a touchscreen for input of touches that are streamed to controllers on another device (e.g., a desktop computer) for manipulating views, taking actions, etc., which, in turn, after performed may cause one or more visualizations stemming from the input to be replicated on the remote device (e.g., consider camera manipulation touches being input on a remote device where graphics computing is performed on another device and a final result streamed to the remote device).",{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 3","b":["320","330","350","320","330"]},"As an example, a view may include one or more camera, for example, to provide for different perspectives. As an example, a touch may be input to control position and focal distance of a camera. As an example, a seek gesture (e.g., a double tap) may changes two degrees of freedom, a pan in the view plane, etc. As an example, where an object may be positioned off-center in a screen, a seek gesture may cause the object to be rendered to center, optionally with zoom (e.g., at pre-defined length).","As to the method , it includes an initiation block , a command block  and a next block . In the example of , the command block  provides a command responsive to a two finger drag for panning a 3D camera. As an example, the method  may be initiated via the initiation block  and a two finger drag sensed inside a 3D window to result in a command per the command block  that causes panning of a 3D camera. In such an example, A(x,y) and B(x,y) may represent contact points for each of the two fingers and C(x,y) may be the bisector of the vector AB. In such an example, C(x,y) and C(x,y) represent where the initial contact was made and broken respectively, with \u0394Cx and \u0394Cy being the scalar distances in screen space of the gesture. In such an example, the delta values may be normalized to window dimensions in screen space and multiplied by a configurable constant D that determines the sensitivity of the gesture. The X and Y values may then be used to generate a transition matrix, which may then be multiplied by an existing camera matrix to update the view.","The method  is shown in  in association with various computer-readable media (CRM) blocks , , and . Such blocks generally include instructions suitable for execution by one or more processors (or cores) to instruct a computing device or system to perform one or more actions. While various blocks are shown, a single medium may be configured with instructions to allow for, at least in part, performance of various actions of the method . As an example, a computer-readable medium (CRM) may be a computer-readable storage medium. As an example, a CRM block may be a module, for example, such as a module as in the one or more modules  of the system . In such an example, the system  may be implemented to perform, at least in part, the method  of .",{"@attributes":{"id":"p-0055","num":"0054"},"figref":["FIG. 4","FIG. 4"],"b":["430","431","442","444","431","431","442","444"]},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 4","b":["480","1","1","1","480","1","2","480","1","2"],"sub":["A","B","C","D","M ","C "]},"As an example a workflow component may include associated sets of parameters that may optionally be selected, for example, using a workflow editor, a workstep creator (e.g., task creator), etc. As an example, such a workflow component may include discovery code to discovery a type of hardware, for example, to determine whether a touchscreen is available for use in performing the workflow and optionally the types of touches, gestures, etc. that may be input using that touchscreen (see, e.g., the blocks  and  of the method  of ).","Referring again to the system  of , as mentioned the framework  may include the domain objects , which may include can include entity objects, property objects and optionally other objects where entity objects may be used to geometrically represent wells, surfaces, reservoirs, etc., while property objects may be used to provide property values as well as data versions and display parameters. As an example, a property object may include one or more parameters associated with a touchscreen setting (e.g., touchscreen touch capabilities, etc.). As an example, a touch module may be configured as a plug-in, for example, that can plug into a framework (e.g., consider the aforementioned OCEAN\u00ae framework).","As an example, a system may provide for multitouch gestures to control cameras in a 2D or a 3D window, slide in touch-friendly menus, touch (e.g., or active stylus) to perform domain specific workflow interpretation, multitouch gestures to directly manipulate domain objects, multitouch gestures to trigger one or more tasks (e.g., optionally global tasks). As an example, where a screen displays multiple panels, touches such as a three finger downward swipe may cause the panels to tile vertically while a three finger upward swipe may cause the panels to tile horizontally. In such an example, a three finger tap may cause the panels to be displayed (e.g., \u201cview all\u201d).",{"@attributes":{"id":"p-0060","num":"0059"},"figref":["FIG. 5","FIG. 5"],"b":["530","532","534","536","542","544","546","552","532","554","536","556","532","534","536","532","534","536","544","556","556","556","556","552","554","552","554"]},"As shown in the example of , the tools menu  and the help menu  may be organized as tiles, which may optionally be user selectable as to their positions. As an example, where a task or tasks are to be performed and where touch hardware is available, the tools menu  and\/or the help menu  may be pre-arranged for that task or those tasks. As an example, where a workflow is a collaborative workflow, the tools menu  and\/or the help menu  may be pre-arranged to enhance collaboration. For example, a tool listed in the tools menu  may provide for rendering of a current workflow tree that indicates what tasks have been performed, what tasks are being performed, who is performing tasks, etc. As an example, a tool listed in the tools menu  may provide for rendering one or more views being rendered on another screen (e.g., a remote screen). As an example, a tool listed in the tools menu  may provide for sharing one or more views being rendered on the screen  (e.g., for input of remote touches). As an example, a workflow editor module executable on a system such as the system  may provide for selecting, arranging, etc. one or more tools of a tools menu, one or more help items for a help menu, one or more keyboard options (e.g., language, symbols, specialized keys, etc.), etc.","As an example, a displayed keyboard may flick up from bottom edge of screen, left- or right-hand friendly, be displayed in a common location, and be displayed in a size and orientation optimal for a screen. As an example, character-based keys, such as \u2018a\u2019 or \u20187\u2019, may function when pressed to a send key command that is transmitted to a last triggered software. As an example, a keyboard may enable light use touch-based text input machine. As an example, a keyboard may allow a user to free workspace by stowing of physical keyboard, for example, to improve desktop workspace ergonomics, to simplify a collaborative environment, etc.","As an example, a flick is a multiple touch, for example, where multiple touches are sensed over a portion of a touchscreen with respect to a period of time (e.g., a time window). In such an example, a flick may include a direction, which may be approximated as being linear. As an example, a flick may include a velocity, an acceleration, etc. While a flick is mentioned as being a multiple touch, other types of touches or gestures may likewise be considered multiple touches (e.g., a single finger clockwise or counter-clockwise gesture, etc.).","As an example, when implemented in a workflow, a slide in keyboard may provide for writing one or more annotations, messaging, labeling a data object, entering numeric and\/or character variables.",{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 6","b":["600","610","620","630","640","650","650","620"]},"The method  is shown in  in association with various computer-readable media (CRM) blocks , , ,  and . Such blocks generally include instructions suitable for execution by one or more processors (or cores) to instruct a computing device or system to perform one or more actions. While various blocks are shown, a single medium may be configured with instructions to allow for, at least in part, performance of various actions of the method . As an example, a computer-readable medium (CRM) may be a computer-readable storage medium. As an example, a CRM block may be a module, for example, such as a module as in the one or more modules  of the system . In such an example, the system  may be implemented to perform, at least in part, the method  of .",{"@attributes":{"id":"p-0067","num":"0066"},"figref":["FIG. 6","FIG. 6","FIG. 4","FIG. 2"],"b":["680","690","680","681","682","683","685","686","687","688","683","682","681","681","688","681","685","686","687","690","688","620","600","480","680","201","207","680"]},"As an example, a method for a workflow may include selecting a workstep class, defining input and output arguments, linking the workstep class and the arguments (e.g., for creating an instance of the workstep class with such arguments), and adding the workstep to the workflow. In such an example, a touch module may include one or more touch classes, which may also be linked such that the added workstep includes touch functionality (e.g., for interacting with that workstep upon its instantiation and use). As an example, where a workstep class is predefined as to its input, output, etc., one or more touch modules may be linked to provide touch functionality for a workstep associated with the workstep class. As an example, one or more touch modules may be linked to a task (e.g., workstep), for example, via a user interface (UI) argument. For example, a UI argument value may act to direct executable code to one or more touch modules, tables, etc. such that touch functionality becomes available during execution of that code. As an example, a touch module may include information to provide a UI (or UIs) with one or more menus, a keyboard, touch functionality, collaboration features, etc.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":"FIG. 7","b":["710","720","710","711","712","714","716","711"]},"As an example, a simulation may be performed using a simulator (see, e.g., various components of the system  of ) that simulates condensate with respect to time and space (e.g., using a 4D simulation model). As to the task , it includes rendering a visualization of the portion of the well bore  along with simulation results  that indicate condensate concentration, for example, about the horizontal segment  of the wellbore. In such an example, the simulation model may be a grid-based model that includes volumetric grid elements where each element may be assigned a value based on the simulation results. Rendering of such elements may yield a blocky opaque view such as the view associated with the task .",{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 8","FIG. 7","FIG. 8"],"b":["730","740","720","718","730","801","830","712","711","714","711","716","718","830","870","718","718","870","871","872","718","830"]},"As to the task , the hand  is shown as interacting with the panel  of the screen  to adjust one or more parameters that control how the simulation results  are rendered to the screen . In the example of , the user touches a point in the panel  above a portion of the color scale  to adjust the opacity value or values  for that portion of the color scale . The user may touch as many portions of the panel  as desired to achieve a rendering of the simulation results , for example, to facilitate interpretation of the simulation results . In such an example, a user may readily touch and view, touch and view, etc. to gain a better understanding of the simulation results . Such touches may be to the panel, to the visualization of the simulation results , etc. For example, a user may rotate the portion of the wellbore  and adjust one or more opacity levels for one or more portions of the color scale. As an example, a user may use two hands, for example, a left hand for touching the panel  to control how simulation results  are rendered and a right hand for touching the visualization of the simulation results  to orient them (e.g., via a camera, a zoom-in, a zoom-out, a pan, etc.).",{"@attributes":{"id":"p-0073","num":"0072"},"figref":["FIG. 9","FIG. 9","FIG. 7","FIG. 9"],"b":["750","710","720","730","740","830","718","711","870","870","870","871","873","875","872","874","876","718","714","711","870","720","750","870"]},{"@attributes":{"id":"p-0074","num":"0073"},"figref":["FIG. 10","FIG. 3","FIG. 10"],"b":["1010","1020","1030","1010","1013","330","1010","5","6","7"]},"As to the task , well logs associated with the wells ,  and  are rendered to provide a visualization of well logs  where each well log is displayed with respect to depth on a vertical axis and a measured value on a horizontal axis. The task  can include implementing a well log camera that is configured for control via touches such as multiple touches (e.g., multitouches), for example, to control rendering of one or more well logs. As an example, touches for a well log camera may include two finger drag to pan (e.g., horizontal and vertical), two finger pinch with vertical tendency in a log track to adjust a vertical scale, two finger pinch with horizontal tendency in a log track to adjust a horizontal scale, a single finger drag in a log track to pan the log up and down, etc. In the example of , the task  includes an outwardly directed spanning of two fingers to enlarge the well logs for wells ,  and  to generate a visualization of the well logs , for example, to perform the task .","As to the task , touches may be made to a touchscreen at a particular point on each of the well logs for the wells ,  and , for example, where the touches correspond to a feature in each of the well logs that may be associated with a geological layer (e.g., a layer of sediment, etc.). As shown in the visualization , the features are at different depths in each of the well logs, for example, because a geological layer that gives rise to the feature may be sloping within a geologic environment. Upon entry of touches to identify a suspected common feature, a well log analysis module may connect the features via a line  and, for example, define a plane based on the three depth locations.","As an example, one or more users may touch one or more touchscreens such that touch circuitry of the one or more touchscreens performs touch sensing and translates sensed touch to issue one or more commands to control petrotechnical software (e.g., a petrotechnical framework, etc.). As an example, given a touchscreen and rendering of well logs on the touchscreen, one or more users may touch individual well logs (e.g., log tracks) to adjust a depth, a depth range, etc. As an example, one or more of the users may perform a pinch gesture that can be sensed by touch circuitry of the touchscreen to adjust a depth, a depth range, etc. of a well log or well logs. In such a manner, a user may scroll to a depth for a well log (e.g., a beginning depth, an end depth, etc. of a well log) and then enlarge a portion of that well log, for example, to assess a feature (e.g., a change in amplitude, etc. in well log data).",{"@attributes":{"id":"p-0078","num":"0077"},"figref":["FIG. 11","FIG. 10","FIG. 11"],"b":["1040","1010","1020","1030","1040","1130","1150","5","6","7","1101","1130","1150","1150","1150","1150"]},{"@attributes":{"id":"p-0079","num":"0078"},"figref":["FIG. 12","FIG. 2","FIG. 12"],"b":["1201","1203","1210","1220","1234","1236","1203","234","236","230","1201","1210","1220","1234","1211","1212","1213"]},"As to the task , a two finger swipe may advance data in a data set such as a seismic volume. For example, where a seismic volume is organized by seismic lines (e.g., inlines and crosslines), a swipe may advance along one of those lines by issuing a command to access the appropriate data and to render a visualization of that data to the right region . As an example, a swipe from right to left may increment to a higher number line while a swipe from left to right may decrement to a lower number line. As an example, where a volume of data is sliced at an angle that is not aligned with an axis defining the data (e.g., an inline or a crossline or a depth or time), an algorithm may access appropriate data to present another slice that is parallel to a rendered slice. For example, such an algorithm may be defined with respect to an inward or outward normal to the slice where incrementing or decrementing occurs for a particular distance along the inward or outward normal.","As to the task , a user may use her hand  to touch the rendered view of the seismic slice  in the right region  such that sensing of the touch by touch circuitry of the touchscreen  causes rendering of one or more seismic slices  and  in the left region . As an example, touches in the seismic slice in the right region  may issue commands for rendering one or more orthogonal slices in the left region . For example, the touchscreen  may sense a series of vertical touches, issue a command to access data for a seismic slice along a seismic line (e.g., an inline or a crossline) and then render a visualization of the data in the left region . As an example, the slice  rendered in the left view  may correspond to the slice  in the right view .",{"@attributes":{"id":"p-0082","num":"0081"},"figref":["FIG. 13","FIG. 2","FIG. 13"],"b":["1301","1303","1310","1320","1334","1336","1203","234","236","230","1301","1310","1320","1334","1311","1312","1314","1314","1336","1312","1334"]},"As to the task , a finger swipe may cause a tool menu  to be rendered in the left region  and a finger tap may cause activation of a tool listed in the tool menu . As mentioned, where a seismic volume is organized by seismic lines (e.g., inlines and crosslines), a swipe may advance along one of those lines by issuing a command to access the appropriate data and to render a visualization of that data to the right region . As an example, an upward swipe may increment to a higher number line while a downward swipe may decrement to a lower number line.","As to the task , a user may use his hand  to touch one of the slices  and  in the left region  such that sensing of the touch by touch circuitry of the touchscreen  increments to a higher number line and renders a slice for that higher number line (e.g., while maintaining the other slice in a stationary position). As an example, a user may rotate the slices  and  in the left region  (e.g., about their intersection) and then touch one of the slices  and  such that sensing of the touch by touch circuitry of the touchscreen  decrements to a lower number line and renders a slice for that lower number line (e.g., while maintaining the other slice in a stationary position). As an example, the left and right regions  and  may be linked such that a change to a slice in one region is carried over to the other region. For example, if a user increments a slice number in the left region , the corresponding slice may be rendered in the right region  (e.g., and vice-versa).","As an example, a feature in a data set may be represented by a domain object. In such an example, the task  may include manipulating one or more domain objects (e.g., within a framework).",{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 14","b":["1452","1454","1452","1432","1454","1436","1460","1470","1452"]},"As an example, upon selection of the tool tile , information may be rendered as indicated by a panel  that may include content, one or more settings, etc. (e.g., consider the panel  of ). As an example, upon selection of the menu tile , information may be rendered as indicated by a panel  that may include content (e.g., text, image, video, etc.), one or more settings, one or more hyperlinks, etc.","As an example, a graphic control (e.g., a tile, button, etc.) on a menu may be linked to a macro function. For example, a tile named \u201cNew Fault Interpretation\u201d may create an interpretation window, load a default seismic plane, commence a seismic interpretation process, create a new interpretation folder, add a new fault to that folder and enter a \u201cFault Interpretation\u201d mode.","As an example, a help menu can include tiles (e.g., buttons) that have an illustration and a label. For example, where the illustration and the label describe a help subject (e.g., tile panels vertically, etc.). As an example, a gesture such as a three finger flick may cause a help menu to slide in to view.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":["FIG. 15","FIG. 15","FIG. 15"],"b":["1500","1500","1510","1520","1530","1540","1510","1520"]},"The method  is shown in  in association with various computer-readable media (CRM) blocks , ,  and . Such blocks generally include instructions suitable for execution by one or more processors (or cores) to instruct a computing device or system to perform one or more actions. While various blocks are shown, a single medium may be configured with instructions to allow for, at least in part, performance of various actions of the method . As an example, a computer-readable medium (CRM) may be a computer-readable storage medium. As an example, a CRM block may be a module, for example, such as a module as in the one or more modules  of the system . In such an example, the system  may be implemented to perform, at least in part, the method  of .","As an example, various types of touches may be associated with actions (e.g., commands, etc.). As an example, one or more tables may be provided that associate touches with various types of actions (e.g., commands, etc.). As an example, a touch module (see, e.g., the one or more modules  of the system  of ) may include a set or sets of associations (e.g., between touches and actions). As an example, a touch module may include a set or sets of associations organized as or organizable in a table format. As an example, a touch module may be implemented as a layer in a hierarchy such as a hierarchy for the method  of . In such an example, as a task changes in a workflow, a touch module may change within the hierarchy where that touch module may be specific to that task. As an example, where a touchscreen renders information to different regions of a touchscreen, each of the regions may be controlled via different touch modules (e.g., a touch module for a planar view region and a touch module for a perspective view region).","Some examples of tables appear below for tap gestures, hold gestures, swipe gestures, flick gestures, rotate gestures, scale gestures, scroll gestures, anchor gestures, and 3D gestures.",{"@attributes":{"id":"p-0094","num":"0093"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Example Tap Gestures:"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["one finger tap to n-finger tap","Single finger select, Two finger menu"]},{"entry":["one finger to n-finger double tap","Single finger double tap seek to zoom."]},{"entry":"one finger triple"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0095","num":"0094"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"thead":{"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]},{"entry":[{},"Example Hold Gestures:"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"119pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"one finger to n-finger hold","Menu"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}}]}}},{"@attributes":{"id":"p-0096","num":"0095"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Example Swipe Gestures:"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["one finger to n-finger swipe","3 finger up\/down tile horizontal\/vertical,"]},{"entry":[{},"4 finger down close windows\/panels"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0097","num":"0096"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Example Flick Gestures:"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["one finger to five finger flick","2 finger left\/right flick next seismic plane,"]},{"entry":[{},"3 finger left right next\/previous fault"]},{"entry":[{},"line\/horizon"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0098","num":"0097"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Example Rotate Gestures:"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"98pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"119pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["two finger rotate two hands","Orbit about x and y axis simultaneously"]},{"entry":["two to n-finger rotate one hand","Orbit about z-axis (fixed)"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0099","num":"0098"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Example Scale Gestures:"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["two finger vertical scale,","Increase log scale (e.g., one or more),"]},{"entry":[{},"increase log scale (track) when on log."]},{"entry":[{},"Increase z scale (3d) increase y scale"]},{"entry":["two finger horizontal scale","Increase x scale"]},{"entry":["two to n-finger scale","Zoom in x and y evenly"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0100","num":"0099"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Example Scroll Gestures:"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["one to n-finger scroll","Move log track up down, move multiple log"]},{"entry":[{},"tracks up down"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0101","num":"0100"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Example Anchor Gestures:"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"133pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["anchor tap (three finger left,","Select mode (pick an object, e.g., regardless"]},{"entry":["one finger right)","of current mode)"]},{"entry":"anchor double tap"},{"entry":"anchor flick"},{"entry":"anchor scale"},{"entry":"anchor rotate"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},{"@attributes":{"id":"p-0102","num":"0101"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Example 3D Gestures:"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"126pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["lock two + 1 finger tilt","2 fingers one hand plus one finger second"]},{"entry":["(precise tilt vertical)","hand tilt about x axis"]},{"entry":["lock two + 1 finger tilt","2 fingers one hand plus one finger second"]},{"entry":["(precise tilt horizontal)","hand tilt about y axis"]},{"entry":"three finger pan (aggressive)"},{"entry":"three finger tilt (aggressive)"},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"As an example, a method may include an editor for associating one or more touch modules with a task. For example, an editor may include a menu for one or more of the aforementioned gestures. As an example, predefined actions may be provided (e.g., as suggested actions, default actions, etc.), which may be editable, for example, to customize one or more gestures and actions for a task or tasks. For example, entries in the right columns of the foregoing tables may be editable to select other actions, make other associations, etc. (e.g., noting that the same may be available for entries in the left columns).","As an example, an editor to edit touch and action associations may be a plug-in or included as part of a workflow editor, for example, which may be configured to define, select, edit, etc. one or more tasks (e.g., worksteps) that form a workflow (see, e.g., the workflow  of ). As an example, consider a workstep that takes input and creates a result via an algorithm, for example, where one or more of the input, the algorithm, the result, etc. may be subject to one or more touches (e.g., via a touchscreen or touchscreens) with one or more associated actions. In such an example, the one or more touches and one or more associated actions may optionally be configured using the workflow editor.","As an example, a method can include commencing a petrotechnical analysis workflow (e.g., that includes a plurality of tasks); initializing one or more touch modules associated with the workflow; accessing data associated with the workflow; rendering one or more visualizations of the data to a touchscreen; and sensing multiple touches via the touchscreen for controlling one or more actions associated with the workflow according to the one or more touch modules. In such an example, the one or more touch modules may associate touches and actions for each of the plurality of tasks.","As an example, a method can include, responsive to sensing multiple touches, rendering a menu of items to a region of the touchscreen. For example, a method may include rendering a menu selected from one of a plurality of different menus associated with a workflow. As an example, the menu may be associated with one of a plurality of tasks of the workflow and include items (e.g., tool items, help items, etc.) for performing that task.","As an example, a method can include, responsive to sensing multiple touches, rendering a panel to a region of a touchscreen where the panel includes one or more visualization controls (e.g., rendering controls such as opacity controls, etc.). In such an example, the rendered panel can include a touchable region for adjusting one or more opacity values for rendering of data values. As an example, for simulation results, sensing of touches to the panel may alter a visualization of the simulation results (e.g., in real-time or near real-time).","As an example, a method can include providing (e.g., or accessing) volume data for a reservoir organized with respect to three axes, rendering a visualization of a portion of the volume data and sensing multiple touches (e.g., a swipe) that controls traversing at least one of the three axes of the volume data to render another visualization of at least another portion of the volume data.","As an example, a method can include rendering a first visualization to a first region of a touchscreen and rendering a second visualization to a second region of the touchscreen. In such an example, one or more touch modules can include a first set of touch associations for the first visualization and a second set of touch associations for the second visualization (e.g., where the first set differs from the second set). As an example, one set may be for a planar visualization and another set may be for a perspective visualization.","As an example, a method can include rendering well logs to a touchscreen. In such an example, the method may include sensing multiple touches via the touchscreen to sense multiple touches for controlling one or more actions associated with the well logs (e.g., according to a touch module being a well logs module that associates multiple touches with one or more actions for analyzing well logs). As an example, such a method may include initializing the touch module as part of a well logs analysis task of a workflow.","As an example, a method can include rendering a visualization of a seismic slice of a seismic data volume and sensing multiple touches via a touchscreen for controlling selection of the seismic slice.","As an example, a system can include a processor; memory operatively coupled to the processor; and one or more modules stored in the memory that include instructions executable by the processor to instruct the system to commence a petrotechnical analysis workflow that includes a plurality of tasks; initialize one or more touch modules associated with the workflow; access data associated with the workflow; render one or more visualizations of the data to a touchscreen; and sense multiple touches via the touchscreen for controlling one or more actions associated with the workflow according to the one or more touch modules. Such a system may include touch modules for sets of associations between multiple touches and actions.","As an example, one or more computer-readable storage media can include computer-executable instructions to instruct a computing device to: commence a petrotechnical analysis workflow that includes a plurality of tasks; initialize one or more touch modules associated with the workflow; access data associated with the workflow; render one or more visualizations of the data to a touchscreen; and sense multiple touches via the touchscreen for controlling one or more actions associated with the workflow according to the one or more touch modules",{"@attributes":{"id":"p-0114","num":"0113"},"figref":"FIG. 16","b":["1600","1610","1600","1602","1604","1606","1608","1604","1602","1608","1606"]},"In an example embodiment, components may be distributed, such as in the network system . The network system  includes components -, -, -, . . . -N. For example, the components - may include the processor(s)  while the component(s) - may include memory accessible by the processor(s) . Further, the component(s) - may include an I\/O device for display and optionally interaction with a method. The network may be or include the Internet, an intranet, a cellular network, a satellite network, etc.","As an example, a device may be a mobile device that includes one or more network interfaces for communication of information. For example, a mobile device may include a wireless network interface (e.g., operable via IEEE 802.11, ETSI GSM, BLUETOOTH\u00ae, satellite, etc.). As an example, a mobile device may include components such as a main processor, memory, a display, display graphics circuitry (e.g., optionally including touch and gesture circuitry), a SIM slot, audio\/video circuitry, motion processing circuitry (e.g., accelerometer, gyroscope), wireless LAN circuitry, smart card circuitry, transmitter circuitry, GPS circuitry, and a battery. As an example, a mobile device may be configured as a cell phone, a tablet, etc. As an example, a method may be implemented (e.g., wholly or in part) using a mobile device. As an example, a system may include one or more mobile devices.","As an example, a system may be a distributed environment, for example, a so-called \u201ccloud\u201d environment where various devices, components, etc. interact for purposes of data storage, communications, computing, etc. As an example, a device or a system may include one or more components for communication of information via one or more of the Internet (e.g., where communication occurs via one or more Internet protocols), a cellular network, a satellite network, etc. As an example, a method may be implemented in a distributed environment (e.g., wholly or in part as a cloud-based service).","As an example, information may be input from a display (e.g., consider a touchscreen), output to a display or both. As an example, information may be output to a projector, a laser device, a printer, etc. such that the information may be viewed. As an example, information may be output stereographically or holographically. As to a printer, consider a 2D or a 3D printer. As an example, a 3D printer may include one or more substances that can be output to construct a 3D object. For example, data may be provided to a 3D printer to construct a 3D representation of a subterranean formation. As an example, layers may be constructed in 3D (e.g., horizons, etc.), geobodies constructed in 3D, etc. As an example, holes, fractures, etc., may be constructed in 3D (e.g., as positive structures, as negative structures, etc.).","Although only a few example embodiments have been described in detail above, those skilled in the art will readily appreciate that many modifications are possible in the example embodiments without materially departing from a radial bearing assembly (or assemblies) for a centrifugal pump. Accordingly, all such modifications are intended to be included within the scope of this disclosure as defined in the following claims. In the claims, means-plus-function clauses are intended to cover the structures described herein as performing the recited function and not only structural equivalents, but also equivalent structures. Thus, although a nail and a screw may not be structural equivalents in that a nail employs a cylindrical surface to secure wooden parts together, whereas a screw employs a helical surface, in the environment of fastening wooden parts, a nail and a screw may be equivalent structures. It is the express intention of the applicant not to invoke 35 U.S.C. \u00a7112, paragraph 6 for any limitations of any of the claims herein, except for those in which the claim expressly uses the words \u201cmeans for\u201d together with an associated function.","The following document is incorporated by reference herein: US Patent Application Publication No. 2012\/0144306 A1, entitled \u201cMethod and system for interacting or collaborating with exploration\u201d, published 7 Jun. 2012, to Moody et al."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Features and advantages of the described implementations can be more readily understood by reference to the following description taken in conjunction with the accompanying drawings.",{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 16"}]},"DETDESC":[{},{}]}
