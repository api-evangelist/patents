---
title: Customizing virtual assets
abstract: Customizing virtual assets is disclosed, including: transforming each of a plurality of initially identical copies of a virtual asset or a portion thereof to isolate a feature of the virtual asset or portion thereof; and enabling the isolated feature to be changed by a user in at least one of the transformed copies. In some embodiments, customizing virtual assets includes: receiving a three-dimensional model associated with the virtual asset; receiving an indication to save a two-dimensional virtual asset based on the 3D model with a 2D image wrapped on it; and using the 3D model with the 2D image wrapped on it to generate the 2D virtual asset.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09472161&OS=09472161&RS=09472161
owner: CIE Games LLC
number: 09472161
owner_city: San Francisco
owner_country: US
publication_date: 20111130
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO OTHER APPLICATIONS","BACKGROUND OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This application claims priority to U.S. Provisional Patent Application No. 61\/458,844 entitled COLORIZING VIRTUAL GOODS IN FLASH CLIENT filed Dec. 1, 2010 which is incorporated herein by reference for all purposes.","Interactive computer gaming is an expanding industry. With the increasing prevalence of networked devices and social media, online interactive gaming has also become convenient and popular. In the realm of online gaming, users can interact with one another via virtual identities and also virtual assets. As users spend more time engaging with virtual assets, it would be desirable to allow users to customize virtual assets to suit their interests and aesthetic tastes, for example.","The invention can be implemented in numerous ways, including as a process; an apparatus; a system; a composition of matter; a computer program product embodied on a computer readable storage medium; and\/or a processor, such as a processor configured to execute instructions stored on and\/or provided by a memory coupled to the processor. In this specification, these implementations, or any other form that the invention may take, may be referred to as techniques. In general, the order of the steps of disclosed processes may be altered within the scope of the invention. Unless stated otherwise, a component such as a processor or a memory described as being configured to perform a task may be implemented as a general component that is temporarily configured to perform the task at a given time or a specific component that is manufactured to perform the task. As used herein, the term \u2018processor\u2019 refers to one or more devices, circuits, and\/or processing cores configured to process data, such as computer program instructions.","A detailed description of one or more embodiments of the invention is provided below along with accompanying figures that illustrate the principles of the invention. The invention is described in connection with such embodiments, but the invention is not limited to any embodiment. The scope of the invention is limited only by the claims and the invention encompasses numerous alternatives, modifications and equivalents. Numerous specific details are set forth in the following description in order to provide a thorough understanding of the invention. These details are provided for the purpose of example and the invention may be practiced according to the claims without some or all of these specific details. For the purpose of clarity, technical material that is known in the technical fields related to the invention has not been described in detail so that the invention is not unnecessarily obscured.","Customizing a virtual asset is disclosed. In some embodiments, the color associated with a virtual asset can be customized by allowing a user to select a base color associated with the asset. In some embodiments, a graphic design can be applied to an asset by first wrapping a two-dimensional, user-chosen image over a three-dimensional model of the asset. In some embodiments, one or more two-dimensional images associated with the asset are then generated from the model wrapped with the user-chosen image.",{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 1","b":["100","102","104","106","104"]},"Device  is configured to access asset customization server  via network . For example, device  can be a laptop computer, a desktop computer, a tablet device, a smart phone, a mobile device, or any other computing device. In various embodiments, a web browser and\/or software application and\/or environment is installed at device  to enable device  to engage in an interactive online game hosted by asset customization server . For example, a Flash Client can be installed at device . For example, a user can use device  to access the game via a web browser by accessing the appropriate uniform resource locator (URL) and\/or performing authentication (e.g., associated with an account that the user has with the game). In some embodiments, a user who wishes to access the game needs to first access a third-party application\/website (e.g., Facebook\u00ae) prior to logging into the game. In some embodiments, device  includes an application and\/or logic to communicate with asset customization server  to send and\/or receive data files associated with the game hosted by asset customization server . In some embodiments, data files related to the game hosted by asset customization server  can be stored on one or both of device  or asset customization server .","In some embodiments, asset customization server  is configured to host a game over network  and also to communicate with device . Asset customization server  sends data and\/or logic to device  to enable a user at device  to customize a color associated with an asset. Asset customization server  sends data associated with an asset to device . Device  transforms the asset into multiple copies and processes each copy independently to isolate a particular feature associated with the original asset in an image layer. In some embodiments, at least one of the copies is processed to include a solid color, which can be changed to any one color that is available. Then, the layers are combined to form an asset with, for example, a base color different than the color of the original asset.","In some embodiments, asset customization server  is configured to send data and\/or logic to device  to enable a user at device  to customize an asset by applying a 2D graphic design to it. The asset is represented in game play by one or more 2D images (as such, herein, the asset is sometimes referred to as a 2D asset), where each 2D image of the asset shows a different angle\/perspective of the 3D asset. However, each 2D image of the asset is rendered to give a 3D-like appearance (e.g., the image includes the appearance of highlights and shadows that show depth and dimension) of the asset at that particular angle\/perspective. To generate a 3D-appearing 2D image of the asset with the desired graphic design applied to it, in some embodiments, a 3D model of the asset is used to model the 3D appearance of the asset with the desired graphic design wrapped around it.","Colorizing Virtual Assets",{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 2","b":["200","100","200","102","100"]},"At , an asset is duplicated into a plurality of copies. For example, an asset can be an Adobe Flash SWF file that comprises one or more layers of bitmap data. In some embodiments, the virtual asset is used, played with, or otherwise animated in a virtual gaming environment. The asset may be created based on an original artwork created by a digital artist using authoring software or some other tool. At least one of the layers of bitmap data is marked for coloring (the colorable layer). For example, in the SWF file of the asset, the colorable layer includes shading, highlight, and base color information. In some embodiments, the layer that is marked for coloring is initially colored a neutral red color. The asset is sent from a server, such as asset customization server , to the client (e.g., device ) and if appropriate, the asset is loaded in an associated environment. For example, the server can send an asset that is an SWF file to the client device and then the SWF file can be loaded into a Flash Client installed at the client device. The asset (or the colorable layer thereof) is duplicated (e.g., using the Flash API) to generate multiple layers that are initially identical to one another.","At , each of at least one of the plurality of copies is transformed into a layer that isolates one or more different features of the asset. For example, a virtual car may be duplicated to generate three copies; the first copy can be associated with a base color of the car, the second copy can be associated with shading of the car, and the third copy can be associated with highlights of the car. For example, each copy can be processed differently from the other copies using a known image processing technique. For example, each duplicate of the colorable layer of the SWF file of the asset can be processed to isolate one of the shading, highlight, and base color features of the asset. In some embodiments, the color associated with the base color layer can be changed, as discussed further below.",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 3","b":["300","300","106","102","300","300"]},"In some embodiments, virtual car asset  is a 2D virtual good asset that is rendered to appear 3D. In some embodiments, the 2D image shown in  is one of many possible angles\/perspectives of the virtual car asset  and each angle\/perspective can be represented by a different 2D image. Although, for illustrative purposes, only the angle\/perspective of virtual good asset  as seen in  is used in subsequent examples.",{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 4","b":["300","300","402","404","406","300","402","404","406","300","300","300","300","300"]},{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 5","FIG. 4","FIG. 5"],"b":["300","300","402","404","406","300","300","502","504","506"]},"In some embodiments, base color layer  is filled in solid with a desired color. Alternatively, the same result can be achieved by first creating a bitmap completely filled with the desired color (i.e., a solid rectangle), then duplicating the alpha channel from the source bitmap. In various embodiments, the desired color used to fill base color layer  is selected by a user. In some embodiments, shading layer  is processed into a multiply layer consisting of only the dark portions of the original asset. This is done in some embodiments by adjusting the hue of the red component to maximum lightness (e.g., via Flash's ColorMatrixFilter), then changing the layer mode to \u201cmultiply.\u201d In some embodiments, highlight layer  is processed into a screen layer consisting of only the light portions of the original asset. This is done in some embodiments by adjusting the hue of the red component to minimum lightness (e.g., via Flash's ColorMatrixFilter), then changing the layer mode to \u201cscreen.\u201d",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 6","b":["600","100"]},"At , a selection associated with a color is received. In some embodiments, the color of the base color layer such as base color layer  of an asset can be selected to be one that is desired by a user. In some embodiments, the desired color can be selected by a user at a user interface. For example, the user interface can be associated with an interactive (e.g., online) game hosted by a server such as asset customization server . Also, for example, the user interface can be available at a particular URL over a web browser. The user interface can, for example, be a color palette and\/or lightness to darkness scale.","At , the selected color is applied to a base color layer of an asset. In some embodiments, the base color layer is filled in solid with the color selected at .","At , the base color layer after application of the selected color is combined with one or more other layers associated with the asset. In some embodiments, the base color layer now filled with the selected color is combined with other layers associated with the asset. In some embodiments, the base color layer is combined with other layers in a stack of layers. For example, returning to the example of , once base color layer  is filled with the selected color, it is stacked with shading layer  and highlight layer . For example, the layers can be stacked from bottom up in the following order: base color layer, shading layer, and highlight layer. In another example, the layers can be stacked from bottom up in the following order: base color layer, highlight layer, and shading layer. The combined effect is intended to recreate the original asset, but with the flexibility of setting the base color as any color desired by a user. For example, the processed and combined layers of virtual car asset  can resemble original virtual car asset  again, only with the base color changed to the color selected by a user.",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 7","FIG. 7"],"b":["502","702","704","706"]},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 8","b":"802"},"Customizing a Graphic Design for an Asset Using a 3D Model","Returning to , in some embodiments, asset customization server  sends data associated with a three-dimensional (3D) model (modeled after an asset created, for example, using a 3D authoring tool) to be run at device , associated code, and\/or logic for interaction with a third party (e.g., 3D engine service). Then at device , a user can choose and\/or generate a two-dimensional (2D) image to be wrapped on the 3D model. For example, the image can be chosen from a provided selection, or from the user's personal collection of images, which for example can be selected from the user's image or photo library and uploaded or emailed to asset customization server . In some embodiments, a user interface is provided to enable the user to change the placement of the selected 2D image as wrapped over the 3D model. For example, a 2D template associated with the 3D model, such as a 2D projection of elements comprising the 3D model, is displayed in some embodiments, and the user interface enables the user to position the 2D image as desired over the template, resulting in the 2D image being wrapped on the 3D model based on the user's placement of the image relative to the template. A third-party 3D engine is used in some embodiments to dynamically render a wrap of the chosen 2D image around the appropriate surfaces of the 3D model. The dynamically rendered wrapping over the 3D model can be displayed. In response to a certain condition being met (e.g., the performance of a specific user selection with respect to the user interface), the placement of the selected 2D image over the 3D model is frozen and one or more 2D images (e.g., each associated with a different angle of the 3D model) of the chosen image wrapped over the 3D model are generated. The generated 2D images are stored (e.g., at either or both of device  and asset customization server ) and an appropriate generated 2D image associated with a particular angle\/perspective of the asset can be displayed for the 2D asset at instances of the game play that are associated with that particular angle\/perspective. In some embodiments, generating and storing the 2D assets enables the game to be played with the visual sense of a 3D asset being used in the game environment without requiring that the 3D model be retained on the user device and\/or run during game play time. In some alternative embodiments, the 3D model with the user-chosen image wrapped over it is rendered and stored as a 3D model that incorporates the image as mapped to appropriate locations of its surface, and this generated 3D model is used in game play.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 9","b":["900","100"]},"At , a 3D model associated with an asset is received. In some embodiments, the 3D model is associated with the body of a virtual car asset such as virtual car asset  of . In some embodiments, the virtual car asset associated with the 3D model is first created using a 3D digital content creation tool. Then, the content creation tool or another tool is used to generate the 3D model based on the original 3D digital artwork.","In some embodiments, the 3D model is sent from a server such as asset customization server  to a client device such as device . In some embodiments, the 3D model is a lightweight model with a relatively low polygon count, which can enable faster processing at the client device (as opposed to a model with a higher polygon count). For example, a 3D model (e.g., in Collada format) associated with the asset is received at the client device and imported into the Flash Client. In some embodiments, subsequent to receiving the 3D model, the 3D model is actively run by a third-party 3D engine (e.g., Away3D) at the client.","In some embodiments, an online interactive game hosted by the server is currently being accessed at the client device (e.g., via web browser) and the 3D model is sent to the client in association with the game. For example, the 3D model can be sent from the server to the client subsequent to a user-based selection to create a texture map for a virtual car asset in the game. Applications and\/or programming code associated with the game can enable the 3D model to be loaded into the appropriate environment (e.g., Flash Client) and\/or be supported by the appropriate rendering engine (e.g., Away3D), such that the user at the client does not need to download any additional software to run the 3D model.","At , a 2D image is received. In various embodiments, the 2D image is the basis for the graphic design a user desires to apply to the asset. The 2D image may be generated, uploaded, and\/or selected by the user and\/or generated using a drawing tool. For example, the drawing tool can be built into a user interface associated with the game. In various embodiments, the 2D image may be uploaded (e.g., from Clip Art or from a local or remote drive), selected from among one or more available images (e.g., the images can be available at the user interface associated with the game), and\/or further edited (e.g., enlarged, cropped, shrunk). The 2D image that is selected\/generated\/uploaded by the user is sometimes referred to herein as a \u201cuser-chosen 2D image.\u201d","At , the 3D model with the 2D image wrapped on it is rendered dynamically. In some embodiments, the 2D image can be treated as a UV texture map and wrapped to the 3D model. The \u201cU\u201d and \u201cV\u201d of a UV texture map describe the two dimensions of the 2D image (because \u201cX,\u201d \u201cY,\u201d and \u201cZ\u201d are already used to describe the 3D model in space). A UV texture map allows polygons of a 3D model to be painted with patterns\/colors from a 2D image. UV mapping includes mapping portions of the 2D image to the appropriate areas on the surface of the 3D model.","In some embodiments, the 2D image is positioned over various surface areas of the 3D model and the appearance of the 3D model wrapped with the 2D image is dynamically rendered and displayed for each placement of the 2D image. In some embodiments, the 2D image is positioned over a template associated with the surface area of the 3D model and a user can move the placement of the 2D image over the template (e.g., via a user interface) to customize a desired overlay\/design\/wrapping of the 2D image over the 3D model. For example, using a 3D engine and\/or tool, the Flash Client renders the invisible 3D model with the texture wrapped to the model so that only the texture and\/or other visual data (e.g., layers such as the base color, shading, and highlight) associated with the appropriate angle\/perspective of the 3D model is displayed at the client device. In some embodiments, one or more 2D images can be generated based on various angles\/perspectives of the 3D model with texture wrapped around them. As discussed further below, each of these generated 2D images (sometimes referred to as 2D graphic design images) can be used as a graphic design layer to be stacked with one or more of the base color, shading, and highlight layers to show an asset with the customized graphic design applied to it.",{"@attributes":{"id":"p-0055","num":"0054"},"figref":["FIG. 10","FIG. 3"],"b":["300","1000"]},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 11","b":["1100","1100","1000","1102","1100","1100","1000","1100","1100","1100"]},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 12","b":["1200","100","1200","906","900"]},"At , it is determined whether the wrapping of the 2D image over the 3D model has changed. In some embodiments, when the 2D image changes in shape, size, orientation, and\/or position of placement over a template (if a template such as template  is used) from a previous position, then a change in the wrapping of the 2D image over the 3D model is detected. If such a change is detected, control then passes to . Otherwise, control passes to .","At , the rendering of the 3D model with the 2D image wrapped around it is dynamically updated based at least in part on the detected change. In some embodiments, each change detected at  entails remapping\/rewrapping the 2D image (that is laid over the template) to the surface of the 3D model, based on, for example, the new shape, size, and\/or position over the template of the 2D image. In some embodiments, subsequent to updating the rendering of the 3D model, the updated 3D model is displayed at the user interface with the changed 2D image wrapped around it.","At , it is determined whether the 3D model is to be stopped. In some embodiments, process  is repeated continuously from 1202 until a condition is met, in which the 3D model is prevented from running at the client device. For example, the condition can be that the system is shut down or that a particular user selection that is designated to stop the 3D model from running (e.g., the user selection can be associated with saving the customized asset) has been performed.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 13","FIG. 13","FIG. 13"],"b":["300","1300","1100","1302","1300","1100","1302","300","1302","1300","300","1100","300","1300","300","1302","1300","1100","1300","1100","1300","1300","1100"]},{"@attributes":{"id":"p-0062","num":"0061"},"figref":["FIG. 14","FIG. 14","FIG. 13","FIG. 14","FIG. 14","FIG. 14"],"b":["1300","1100","1300","1100","1200","1300","1302","1302","1300","1100"]},{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 15","b":["1500","100"]},"At , an indication to generate one or more 2D graphic design images based at least in part on a wrapping of the 2D image over the 3D is received. In some embodiments, such an indication is associated with a performance of a specially-designated user selection at the user interface. For example, the user selection can be a user clicking \u201cBuy\u201d with respect to the customized wrapping of the user-chosen 2D image over the virtual car asset (which also indicates the completion of the customization process). In some embodiments, this same designated user selection is also used to cue stopping the 3D model at the client device of  of process .","At , one or more 2D graphic design images based at least in part on the wrapping of the 2D image over the 3D model is generated, each 2D graphic design image being associated with a different perspective of the 3D model. For example, once the indication is received, the wrapping of the user-chosen 2D image over the invisible 3D model can no longer be further updated and the most recently updated wrapping of the user-chosen 2D image over the 3D model is used to generate the one or more 2D graphic design images. In some embodiments, the 3D model with the final wrapping of the user-chosen 2D image is rotated and oriented to match one or more predetermined angles\/perspectives of the 2D asset and a 2D graphic design image is generated for each angle\/perspective of the 2D asset. For example, the Flash Client can iterate through all predetermined angles\/perspectives associated with the asset (e.g., used in the game in which the asset is to be used), and generate a 2D bitmap for each of those angles\/perspectives and save them (e.g., to the clients and\/or server). In some embodiments, six angles\/perspectives are used and so six 2D graphic design images are generated. In some embodiments, each generated 2D graphic design image is used as a graphic design layer that can be inserted over the base color layer and under the shading and highlight layers to create the appearance that the customized graphic design is applied to the asset (all other layers used in the combination are associated with the same angle\/perspective as the graphic design layer). In some embodiments, once the one or more 2D graphic design images are generated, the 3D model is prevented from running at the client device.","In various embodiments, once 2D graphic design images are generated and stored, each time a user views that customized virtual asset (e.g., associated with playing the interactive game), the saved graphic design associated with the appropriate angle\/perspective is loaded in and used (e.g., rather than loading in the 3D model and re-wrapping the user-chosen 2D image to it). In various embodiments, 2D graphic design images are stored and used locally, in addition to and\/or instead of saving them to a server. During game play (or other interaction, in the case of virtual environments other than games), an appropriate one of the previously generated 2D graphic design images is used to display the asset in the context of the virtual game environment. For example, in some embodiments, game application code includes code and\/or values used during game play to select one of the available views of the asset to be displayed based on such factors as the state of game play, a location of the asset within the game or other virtual environment, a direction or other input received from the user, the location and attributes of adjacent virtual assets and\/or elements of the virtual environment, etc. In this way, the appearance and sense of using a 3D asset to interact with a 3D virtual environment is provided to the user using computationally and bandwidth efficient 2D images each showing the asset as viewed from an associated angle\/perspective.",{"@attributes":{"id":"p-0067","num":"0066"},"figref":["FIG. 16A","FIG. 16A"],"b":["1100","1206","1200"]},{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 16B"},{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIG. 17","FIG. 16B"],"b":"300"},"Although the foregoing embodiments have been described in some detail for purposes of clarity of understanding, the invention is not limited to the details provided. There are many alternative ways of implementing the invention. The disclosed embodiments are illustrative and not restrictive."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The patent or application file contains at least one drawing executed in color. Copies of this patent or patent application publication with color drawing(s) will be provided by the Office upon request and payment of the necessary fee.","Various embodiments of the invention are disclosed in the following detailed description and the accompanying drawings.",{"@attributes":{"id":"p-0006","num":"0005"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0007","num":"0006"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 4","b":"300"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 5","b":"300"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 16A"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 16B"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 17"}]},"DETDESC":[{},{}]}
