---
title: Managing dynamic device color profiles
abstract: Device information is extracted from a graphical object's data file to dynamically generate a profile suitable for processing by a color management system. In one embodiment, the graphical object is an image and the graphical object's data file is generated by a digital camera.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07080058&OS=07080058&RS=07080058
owner: Intel Corporation
number: 07080058
owner_city: Santa Clara
owner_country: US
publication_date: 19980626
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The invention relates generally to the use of device color profiles used by image color management systems.","One goal of image color management technology is to ensure that a color image, graphic, or text object (hereinafter collectively referred to as graphical objects) is rendered as close as possible to its original intent on any device, despite differences in imaging technologies and color capabilities between devices. To achieve this goal, color characteristics of devices such as scanners, printers, and display monitors may be determined a priori and encapsulated in a device profile.","A device profile is a file that contains information about how to convert colors in the color space of a specific input device (e.g., a scanner) into a device-independent color space, or from a device independent color space into an output device's color space. Typical input and output device color spaces include the red-green-blue (RGB) and cyan-magenta-yellow-black (CMYK) color spaces. One illustrative device-independent or profile color space (PCS) is the Commission Internationale de l\u00c9clairage (CIE) XYZ color space. (See Commission Internationale de l\u00c9clairage Publication 15.2-1986, \u201cColorimetry, Second Edition.\u201d)","Referring to , computer system  may include one or more graphical applications  that can be used to view and\/or modify graphical objects generated by a device such as a digital scanner. Applications  may communicate with color management module (CMM) , through application programming interface (API)  and graphics  and imaging  libraries. Profiles  may provide CMM  with information about how to convert colors into and out of device color spaces. For example, if the input device is a color scanner, a first profile may provide CMM  with information needed to convert the scanner's input color space (e.g., the red-green-blue, RGB) into the PCS. A second profile may provide the necessary information for CMM  to convert the PCS into a suitable output color space such as for viewing on a display monitor. One example output color space is the sRGB color space as described in version 1.10 of the document entitled \u201cA Standard Default Color Space for the Internet\u2014sRGB,\u201d published by members of Hewlett-Packard Company and Microsoft Incorporated in 1996.","Input and output device profiles  are typically created by device manufacturers or third party vendors and may comprise one, or a few different profiles\u2014where each profile may accommodate different input and output color spaces. In an environment in which one, or at most a few, profiles for each device can be determined a priori, the above described color management scheme may work reasonably well. In an environment in which graphical objects may be subject to a variety of different capture environments (such as images generated by a digital camera), however, a single a priori device profile cannot provide good color reproduction for the different capture environments. Thus, it would be beneficial to provide a technique (apparatus and method) to generate color profiles for graphical objects in a dynamic or automatic fashion.","In one embodiment the invention provides a method and apparatus to dynamically generate device profiles. These embodiments may include receiving a graphical object having associated profile information, generating a profile based on the associated profile information, and identifying the profile to a color management system. The method may include generating a new graphical object, from the received graphical object, that has had its profile information removed. The act of identifying the profile may include associating a filename with the profile and communicating the filename to the color management system, perhaps via an application programming interface function call. The method may further include communicating the graphical object to the color management system.","In another embodiment, a method and apparatus to distinguish between a newly received graphical object's profile information and prior received profile information is provided. In these embodiments, if the newly received graphical object's associated profile information is not equivalent to prior received profile information, a new profile is created and identified to the color management system. Equivalence may be determined by comparing profile attribute values such as measurement tag values, and\/or illuminant tag values, and\/or rendering intents values.","Methods in accordance with the invention may be stored in any media that is readable and executable by a computer system. Illustrative media include: semiconductor memory devices such as EPROM, EEPROM, and flash devices; magnetic disks (fixed, floppy, and removable); other magnetic media such as tape; and optical media such as CD-ROM disks. Further, methods in accordance with the invention may be embodied in a hardware device such as a printed circuit board comprising discrete logic, integrated circuits, or specially designed application specific integrated circuits (ASIC).","Techniques (including methods and devices) to dynamically generate device profiles are described. The following embodiments of this inventive concept are illustrative only and are not to be considered limiting in any respect.","Referring to , a representative computer system  for use with digital camera  is shown. Computer system  includes processor  coupled to system bus  through bridge circuit . Illustrative host processors  include the PENTIUM\u00ae family of processors and the 80X86 families of processors from Intel Corporation. One illustrative bridge circuit  is the 82443LX PCI-to-AGP controller manufactured by Intel Corporation.","Bridge circuit  provides an interface for system random access memory (RAM) , accelerated graphics port (AGP)  devices such as display unit , and one or more expansion slots . Expansion slots  may be personal computer memory card international association (PCMCIA) slots.","Bridge circuit  may also couple system bus  to secondary bus , while also providing universal serial bus (USB)  and integrated device electronics (IDE)  interfaces. Common IDE devices include magnetic and optical storage units . Also coupled to secondary bus  may be system read only memory (ROM) , keyboard controller (KYBD) , audio device , and input-output (I\/O) circuit . One illustrative bridge circuit  is the 82371AB PCI-to-ISA\/IDE controller manufactured by Intel Corporation. Input-output circuit  may provide an interface for parallel  and serial  ports, floppy disk drives , and infrared ports .","Camera  may associate (e.g., store) profile information with each image at the time the image is captured. The associated profile information may include profile information in accordance with the International Color Consortium's (ICC's) profile format specification, version 3.4, August 1997. Thus, an image file generated by camera  may have the structure shown in : a first portion comprising profile information  and a second portion comprising image data . Profile information , in turn, may comprise profile header information , tag information table of contents , and tag table data  in accordance with the aforementioned ICC profile format specification. In an embodiment where camera  is an RGB device and the profile color space (PCS) is the CIE XYZ color space, the ICC profile format specification stipulates that tag table  comprise some of the tags enumerated in Table 1. While other device and profile color spaces may be used, for brevity, only RGB and XYZ color spaces will be discussed herein.",{"@attributes":{"id":"p-0021","num":"0020"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 1"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Illustrative Profile Tag Table Entries"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Tag Name","Description"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}},{"entry":["redColorantTag","Red colorant XYZ relative tristimulus value."]},{"entry":["greenColorantTag","Green colorant XYZ relative tristimulus value."]},{"entry":["blueColorantTag","Blue colorant XYZ relative tristimulus value."]},{"entry":["redTRCTag","Red channel tone reproduction curve."]},{"entry":["greenTRCTag","Green channel tone reproduction curve."]},{"entry":["blueTRCTag","Blue channel tone reproduction curve."]},{"entry":["mediaWhitePointTag","Media XYZ white point."]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"Measurement tags redColorantTag, greenColorantTag, and blueColorantTag represent the relative XYZ values of the input device's (e.g., camera ) red, green, and blue colorants. Rendering intent information such as red, green, and blue tone reproduction curve (TRC) tags or attributes may be used by a color management module (CMM) to linearize RGB input and may be ignored if the input data is already linear. Illuminant tag information such as the mediaWhitePointTag may be used to record the XYZ (e.g., the PCS color space) values of the capture media's (e.g., digital \u201cfilm\u201d) white point. Another illuminant tag that may be recorded by camera  and included in an image's profile information  is the viewingConditionsType and associated tag value. The viewingConditionsType attribute may record the illuminant condition under which an image is captured such as whether it was taken under daylight, tungsten, or fluorescent lighting conditions. (In one embodiment of the ICC profile format, the mediaWhitePointTag value is used for generating absolute colorimetry and is referenced to the PCS so that the media white point as represented in the PCS is equivalent to this tag value.) Because each image captured by camera  may be subject to a different illumination condition it is, in general, not possible to generate a color profile a priori that provides good color reproduction of the captured image. This is one distinguishing feature between a digital camera and other image capture devices such as digital scanners which have a substantially constant capture environment. The lack of certainty in describing an image's illuminant condition means that, without a means of generating a device profile based on the image itself, the ability of a color management system to render the image as close as possible to its original intent on any device, despite differences in imaging technologies and color capabilities between devices, is substantially limited.","One method to dynamically generate a device profile is illustrated in . First, camera  captures an image in a file, including therein profile data in accordance with  and Table 1 (step ). At some later time, the image file may be transferred to computer system  (step ). Computer system  may then use the image file's profile information  portion to generate a profile file in accordance with the ICC profile specification (step ). The dynamically generated profile is assigned a unique filename, and this filename is passed to the CMM (step ). Notification, or identification of the dynamically generated profile's filename to the CMM may be accomplished in a number of ways such as through application programming interface (API) calls. Having a profile that accurately reflects the image's taking\/capture conditions, the CMM can faithfully process the image in accordance with user instructions and the generated device profile (step ).","In another embodiment, referred to herein as the \u201clive\u201d mode of operation, camera  is coupled to computer system  during image capture, periodically transferring captured images in an automated manner. By way of example, camera  may be coupled to computer system  via electrical cable, radio frequency or infrared transmission channels, and may transfer images to computer system  at a rate of up to approximately 30 images per second. The transfer may be initiated by computer system  or by camera . When camera  is coupled to computer system , the probability of successive images having different taking conditions is relatively small. Thus, when operating in the live mode, it may not be necessary to create a new profile for every image that is transferred from camera  to computer system .","Referring to , computer system  receives an image file and designates it as the \u201ccurrent\u201d image (step ). Next, the current image's profile data  (see ) is compared to that associated with previously transferred profile image data (step ). In particular, those values associated with profile tags that are subject to change based on changes in capture environment (e.g., redColorantTag, greenColorantTag, blueColorantTag, mediaWhitePointTag, and viewingConditionsTag data values) may be compared to previously transferred tag table data that has been used to create prior profiles (see discussion below and Table 1). These prior profiles may have been created in accordance with . For example, if no prior profiles exist, step  may perform no operation and the \u2018no\u2019 prong of step  is traversed.","If there is no match (the \u2018no\u2019 prong of step ), a new profile is generated as described above and assigned a unique filename (step ). The newly created profile may be indexed in a manner that allows its use with another image (step ), and the CMM is notified of the new profile's filename via an appropriate applications programming interface (API) call (step ). In one embodiment, a profile is generated for each unique set of tag table data, and a list\/table of the filenames and associated profile information is kept available so that each incoming (i.e., current) image's profile data may be compared to prior unique profile data. In another embodiment, a new profile is generated (step ) only when the current image's profile information differs from previous profile data by a specified amount. For example, a new profile may be created when the current image's mediaWhitePointTag value differs from a previous profile's mediaWhitePointTag value by a first specified percentage, or when the viewingConditionsTag value differs from a second specified percentage.","If there is a match between the current image's profile data and profile data associated with a previous image (the \u2018yes\u2019 prong of step ), the filename associated with the matching profile's data is determined (step ) and provided to the CMM through an appropriate API call (step ). If the live mode session is complete (the \u2018yes\u2019 prong of step ), processing is terminated (step ). If the live mode session is not complete (the \u2018no\u2019 prong of step ), processing continues at step .","In another embodiment, the ability to distinguish between live mode and non-live mode operations may be provided in a single application (comprising one or more computer programs) as shown in . First, an image may be generated by a digital camera or other suitable device (step ) and transferred to, and received by, an application program executing on a computer system (step ). If the imaging device coupled to the computer system is not operating in the live mode (the \u2018no\u2019 prong of step ), a new profile may be generated (step , see also  and associated description). The CMM may then be notified of the image's profile (step ) which is then processed (step ). When not operating in the live mode (the \u2018no\u2019 prong of step ), the just created profile is deleted (step ) and processing terminates (step ).","If the imaging device is operating in the live mode (the \u2018yes\u2019 prong of step ), the received image's profile information is compared with existing (i.e., previously generated and stored) profile data that is subject to change based on the image's capture environment such as changes in illuminant tag values such as mediaWhitePointTag and viewingConditionsTag values, or measurement tag values such as redColorantTag, greenColorantTag, and blueColorantTag values (step ). If there is no match (the \u2018no\u2019 prong of step ), a new profile is generated, assigned a unique filename, and indexed as described above and shown in  (steps  and ). After the CMM is notified of the image through appropriate API calls (step ), it processes the image (step ). A check may then be made to determine if the live mode session is complete (via the \u2018yes\u2019 prong of step ). If the live mode is complete (the \u2018yes\u2019 prong of step ), previously created profiles are deleted (step ) and processing terminates (step ). If the live mode is not complete (the \u2018no\u2019 prong of step ), processing continues at step .","If there is a match between the current image's profile information and previous profile data (the \u2018yes\u2019 prong of step ), that profile associated with the matching profile data is determined (step ) and processing continues at step .","One advantage of dynamically generating device profiles is that each graphical object (e.g., an image) may be rendered as close as possible to its original intent on any device, despite differences in the imaging technologies and color capabilities between the device that captured the graphical object and the device displaying the graphical object. Another advantage of dynamically generated device profiles in accordance with one embodiment of the invention is that existing color management application programs are not required to be modified\u2014they may interact with dynamically generated device profiles via a standard application programming interface. Yet another advantage of dynamically generated profiles is that in live mode the number of profiles needed to accurately process a large number of images may be small. (This is because a camera's capture environment is not likely to change frequently when coupled to a computer system.) In these cases, only a few unique profiles are created (see ) and so operational memory requirements (e.g., to store the dynamically generated profiles) and speed (e.g., the time to compare those tag values subject to change) may be small.","Various changes in the materials, components, circuit elements, as well as in the details of the illustrated operational methods are possible without departing from the scope of the claims. For example, an image capture device may be a digital camera or any other device capable of providing an image containing device profile information. Thus, previously captured image files may be provided from computer storage such as magnetic and optical disks, magnetic tape, and flash memory devices. In one embodiment, an image capture device may be coupled to computer system  through expansion slots  or through I\/O circuit .","Method steps of , , and A and B may be performed by a computer processor (e.g., processor ) executing instructions organized into a program module or a custom designed state machine. Storage devices suitable for tangibly embodying computer program instructions include all forms of non-volatile memory including, but not limited to: semiconductor memory devices such as EPROM, EEPROM, and flash devices; magnetic disks (fixed, floppy, and removable); other magnetic media such as tape; and optical media such as CD-ROM disks. Further, the methods described herein may be embodied in a hardware device such as a printed circuit board comprising discrete logic, integrated circuits, or specially designed application specific integrated circuits (ASIC)."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":["FIGS. 6A and 6B","FIGS. 4 and 5"]}]},"DETDESC":[{},{}]}
