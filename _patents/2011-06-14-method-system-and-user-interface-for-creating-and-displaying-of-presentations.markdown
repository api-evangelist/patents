---
title: Method, system and user interface for creating and displaying of presentations
abstract: A method and system for creating at least one presentation, comprising: at least one computer; at least one application operable on the at least one computer, the at least one application configured for: receiving a plurality of assets; and allowing at least one user to define the at least one presentation over the time that the at least one presentation is to be displayed, using at least two assets to be simultaneously presented for at least one selected point in time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08850320&OS=08850320&RS=08850320
owner: 
number: 08850320
owner_city: 
owner_country: 
publication_date: 20110614
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BRIEF DESCRIPTION OF THE FIGURES","DESCRIPTION OF SEVERAL EMBODIMENTS","Example Embodiments"],"p":["This application claims the benefit of U.S. Provisional Application No. 61\/354,984, filed Jun. 15, 2010, which is incorporated by reference in its entirety.",{"@attributes":{"id":"p-0003","num":"0002"},"figref":"FIGS. 1-5","b":["15","16"]},{"@attributes":{"id":"p-0004","num":"0003"},"figref":"FIGS. 6-14","b":["17","77"]},{"@attributes":{"id":"p-0005","num":"0004"},"figref":["FIG. 1","FIG. 3"],"b":["100","100","100","305","100","315","320","315","320","310","100"]},"The widgets can comprise at least one text chat widget, at least one audio\/video chat widget, at least one asset browser widget, at least one discussion widget, at least one audio recording\/playback widget, at least one video recording\/playback widget, at least one stream recording\/playback widget, at least one audio\/video editing widget, at least one document viewing widget, at least one document editing widget, at least one linking widget, at least one activity widget, at least one slide show editing\/viewing widget, at least one diagram editing\/viewing widget, at least one drawing suite widget, at least one whiteboard widget, at least one polling widget, at least one survey widget, at least one assessment widget, at least one spreadsheet widget, at least one user list widget, at least one source code viewing and editing widget, at least one tracking widget, at least one glossary widget, at least one screen sharing and\/or screen recording widget, at least one wiki widget, at least one bookmark widget, at least one calculator widget, at least one presentation index widget, at least one layers widget, at least one integrations widget, or at least one third party platform interactive widget, or any combination thereof. It should be noted that any widget can be provided using third-party software. In addition, those of ordinary skill will see that any widget function(s) can be combined with any other widget function(s) to form other widgets.","Referring to , in one embodiment, server (e.g., host) computer  can communicate over a network  (e.g., Intranet, Internet) with client computer . A creation\/playback application  can be accessed by a user utilizing the client computer  and\/or the server computer . The creation\/playback application  can support a number of modes which include, but are not limited to: editor mode, run-time\/playback mode, record mode, or collaborate mode, or any combination thereof. Those of ordinary skill in the art will see that many other modes can be created and implemented by the system  in the creation\/playback application . The system  can be set to be run in multiple modes simultaneously and\/or use capabilities of the multiple modes simultaneously. The creation\/playback application  can also: use editor mode and editor mode capabilities to create and\/or edit an information presentation; use runtime mode (e.g., playback mode) and run-time mode capabilities to playback an information presentation; use collaborate mode and collaborate mode capabilities to support collaboration within the application and system (above and beyond the inherent real-time capability of any individual asset or widget, such as chat or video chat); or use record mode to record any and all state changes to an information presentation wherein such state changes may be played back or further edited; or any combination thereof. The capabilities of the modes are further described below, as well as illustrated together with the embodiments of the creation\/playback application  executing some of the capabilities of the system .","In one embodiment, the creation\/playback application , can run on the server computer  (as shown in ). In alternate embodiments, the creation\/playback application  can run on the client computer  or a combination of the server computer  and client computer . Thus, any of the modules in the creation\/playback application  can reside on the server computer  or the client computer . For example, in one embodiment, some of the modules could reside on the server computer  and some on the client computer . In other embodiments, all of the modules could reside on the server computer  or the client computer .","Creation\/Playback Application",{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIGS. 2A and 2B","b":["120","120"]},"At this point, it should be noted that state change\/time definition data can describe and\/or define a change to the state of the information presentation (including describing changes in state for the creation playback application itself and describing changes to other state change\/time definition objects\/data) for a given point in time. The state change\/time definition data can specify a state change to be: immediately executed, executed at some point in the future, or executed at some point in the past; or any combination thereof. In this way, state change\/time definition data can collectively and together define an information presentation and an information presentation over time, and together with the creation\/playback application , flexibly accommodate a number of capabilities of the system .","In one example of capabilities, a collection of state change\/time definition data for various points in the past and future can represent an information presentation over time and can be received by the creation\/playback application. As previously mentioned, state change\/time definition objects, in addition to defining state changes to both the application and to other state change\/time definition objects, can define state changes to the information presentation, and specifically, state changes as they pertain to the use or state of assets, wherein assets, as well as assets meta-data is also received\/to be received by the state-time application. Using such information presentation data as described, the creation\/playback application  can: render the information presentation over time, visually on a timeline area and\/or playback the information presentation by executing the state change\/time definition data at the appropriate times, thereby \u201cplaying back\u201d the information presentation (e.g., by actuating, activating, and displaying the assets).","As previously detailed, state change\/time definition data can be of an immediate run nature; i.e., defined to be executed immediately. In the previous example, one use of immediate run state change\/time definition data could be for initializing the application and information presentation. The capability of implementing immediate run state change\/time definition data can support a number of other capabilities of the system. For example, immediate run state changes can be used to initialize the application and the information presentation into a known state, and can allow for a user, at any point in time, including at the application's initialization, to access the information presentation at any point of the information presentation's potential duration, as well as to sync the state of the application that may be defined for that point in time. Another example using this capability could be where a second user can enter into the application and immediately be synced to the state of the application and information presentation of a first user, thereby immediately replicating exactly what the first user sees at that point in time.","The creation\/playback application  can continually listen for, receive, process, store and execute all information presentation data, including immediate-run state change\/time definition data. In this way, the state of the creation\/playback application  and the information presentation (and all of both of their constituent parts) can be continually updated and modified in real-time. By providing for essentially any real time change and any real time update, any real-time capability can be achieved, including that of various real-time collaborative capabilities, including, but not limited to: real-time capabilities within widgets (for instance real-time updates to the text chat widget), real-time viewing of information presentations, real-time viewing of many user's devices' cursor pointers and locations, and collaborative editing of information presentations.","Additional details related to the state change\/time definition data is further described below with respect to .","Referring back to , the creation\/playback application  can comprise: an application load manager module , an editor mode module , a run-time (e.g., playback) mode module , a collaboration mode module , a bus\/network communications I\/O manager module , a data loader\/initial application updater module , a central application reference and application programming interface (API) (hereinafter referred to as CARA) , a user input analyzer and router module , a local asset database module , a local state change and timing database , a time controller and manager module , state change proxy module , multicast data broadcaster module , asset load manager , or user interface module ; or any combination thereof. Examples of capabilities of the system provided for by the creation\/playback application  are further documented in a number of usage scenarios presented throughout this document.","It should be noted that the various components of  can together enable the various modes of the creation\/playback application , wherein the modes of the application together with the assets can enable the capabilities of the system . Those of ordinary skill in the art will see that any of the modules\/databases discussed in this application can be combined with any other modules\/databases. In addition, those of ordinary skill in the art will see that certain functions can be separated from the modules and incorporated into other existing modules or new modules. Furthermore, any of the modules can be configured to be run on a variety of devices and\/or in a variety of different modes.","The application load manager module  can be an initialization module containing all the logic for instantiating and integrating all other modules within the creation\/playback application . The application load manager module  can also be responsible for helping to coordinate the creation\/playback application's simultaneous capabilities using the various modes (e.g., editor mode, run-time mode, collaboration mode, etc.). In this way, the application load manager module  can execute multiple algorithms for such multi-mode capability when needed.","The editor mode module , run-time mode module , and collaboration mode module  can be three or more independent modules (herein referred to collectively as per-mode modules) that can enable the creation\/playback application instances to encapsulate, expose and\/or contain per-mode focused initialization algorithms and per-mode focused execution algorithms. Each per mode module can enable the creation\/playback application  to be run in its respective mode. In some embodiments, a per-mode module can be run separately and independently of any dependency on other per-mode modules, while other modules (such as the application load manager module ) can also use various combinations of the per mode modules to combine the per-mode capabilities together within the application and by users of the application.","The per-mode modules can receive the CARA  and the full creation\/playback application context, and can populate and\/or inject custom per-mode instructions\/functionality and capability into any and all dependent module instances in the application. For example, custom handling capability and routines can be provided and\/or injected into: the timeline area renderer module  to support timeline area rendering capability; or the user input analyzer and router module  to support per mode user input handling functionality; or any combination thereof.","The bus\/network communications I\/O manager  can be responsible for all communications between the creation\/playback application  and: external support components; external data stores; other remote applications (e.g., other creation\/playback applications instances in use by other users); any other network connected resource, or other remote systems; or any combination thereof. For example, some creation\/playback application instances can be dependent on receiving live data from other creation\/playback application instances or from the system . In addition, the bus\/network communications I\/O manager  can be responsible for communications between the creation\/playback application  and: external application support systems ; external database(s) ; or other remote systems ; or any combination thereof. In some embodiments, the bus\/network communications I\/O manager  can communicate using numerous protocols (e.g., TCP\/IP, IP protocols).","The data loader\/initial application updater module  can be responsible for receiving information presentation data from the bus\/network communications I\/O manager module . The data loader\/initial application updater module  can then add the received data or references to the data to various data store modules within the creation\/playback application . The data loader\/initial application updater module  can also identify any state change objects that need to be executed and pass the state change objects off for execution. The data loader\/initial application updater module  can also: add assets and assets meta data to the local asset database ; add non-immediate (future or past state change data) to the local state change and timing database ; identify state change objects which should be immediately executed upon receipt and pass these state change objects to the state change proxy module  for immediate execution.","The CARA (Central Application Reference and API)  can provide and\/or implement structured APIs and make the creation\/playback application  addressable from any other module or component within the creation\/playback application . In some embodiments, any module and any state change can be invoked through access via CARA . In some embodiments, CARA  can: provide access to all application state data; organize access to some or all other modules\/data\/objects\/instructions within the creation\/playback application ; or expose\/implement encapsulated state change routines; or any combination thereof.","The user input analyzer and router module  can handle user input for all of the user interface module's submodules. The user input analyzer and router module  can also, independently, or in conjunction with injected dependencies (see description of per-mode modules , , ), analyze: the state of the information presentation and the information presentation state or data for any given point in time, the state of the creation\/playback application ; or the source graphical user interface (GUI) of the input: or any combination thereof. In addition, the user input analyzer and router module  can respond or perform actions based on such analysis. The actions it can take can include: updating\/adding\/deleting state changes and\/or state change\/time definition data and\/or state change\/time definition objects; prompting for additional user input: identifying updated\/added\/deleted state changes and\/or state change objects which necessitate notification of the update\/add\/change to other components of the creation\/playback application ; or notifying and providing dependent modules with changes to state changes and\/or state change objects (note that dependent modules can include state change proxy module , local state change and timing database , multi data broadcaster module ); or any combination thereof. The user input analyzer and router module  can be responsible for implementing the contextual and predictive user interface capabilities further described with respect to .","The local asset database  can store assets and\/or asset instances along with metadata. The local state change and timing database  can store local data for any state change objects.","The time controller and manager module  can be responsible for implementing\/executing all time related aspects of the creation\/playback application  within information presentations. A time controller (e.g., contained within the time controller and manager module ) can be invoked on an as-needed basis by state change commands\/objects through the state change proxy module , such as to initialize, start or stop the time controller and\/or the playback of the information presentation. In addition, in some embodiments the user can start or stop or activate or inactivate the time controller, and\/or the playback of the information presentation, or the time controller can be started automatically by the creation\/playback application . The time controller can implement an internal clock management functionality based on the system 's hardware or software clock capabilities and data received from subsequent state change invocations. For example, suppose an information presentation starts with a set of predefined state change\/time changes, contained and included in the initialization payload processed after the application initializes. The predefined state change\/time data can include immediate run state changes (e.g. intended to initialize the information presentation and\/or initialize or configure the creation\/playback application ). These immediate run state changes can invoke the time controller with relevant data describing the structure of the information presentation, whereby the information presentation is a time oriented presentation by virtue of the data provided. Using this data, the time oriented information presentation can then be implemented and managed over time, wherein the time controller executes the relevant state changes described in the state change\/time definition data and state change\/time data objects by invoking a state change proxy module (and passing the state change\/time data\/objects) when the appropriate time in the duration of information presentation is reached. The time controller and manager module  can be started as a routine on CARA  and\/or invoked through and immediate state change command\/object, or started by the user or automatically by the creation\/playback application as previously described.","The state change proxy module  can execute all state changes contained\/described in the collection of 1\u2212n state change\/time data\/objects it is invoked with. Additionally, the state change proxy module  can interact\/query on an as-needed basis with the dependent state change module . The state change proxy module  can also be used to implement the automatic\/manual mode configurations of the system . For example, the state change proxy module  can monitor values on CARA , and if it is determined that the user has entered manual mode, can prevent certain classes of state changes from being invoked\/executed (e.g., layout change state changes).","The dependent state change module  can analyze a collection\/list of state changes to be executed, and can augment the collection\/list with additional implied or dependent, state change directives, if needed.","The multicast data broadcaster module  can be responsible for: generating messages and\/or state change\/time definition data\/objects for all dependent creation\/playback application instances and then passing messages\/objects to the bus\/network communications I\/O manager module  to be sent outside the creation\/playback application , for example, such as for sending real time updates to other user's creation\/playback application instances, either directly to such instances, or to instances external application support systems  for the recipient system to determine all dependent creation\/playback application instances and send to all dependent instances; or any combination thereof.","The asset load manager  can be responsible for all asset loading needs in the creation\/playback application . As such, the asset load manager can monitor or listen to the local state change and timing database  for updated\/added\/removed state change\/time objects. Upon notification and receipt of the updated\/added\/removed object, the object can be analyzed for references to any dependent assets referenced by the state change object. In addition, the asset load manager  can provide for speed and efficiency within the system  and across any computer networks used, as the asset load manager  can contain logic to load assets or portions of assets for the information presentation as the assets are needed.","The user interface module  can comprise modules that enable an editor and\/or a user to define and\/or control a presentation by allowing the editor and\/or user to enter commands or provide user input through a user interface, as well as to visually represent the state of the system and the information presentation. The user interface module  can accommodate multiple approaches for defining, playing back and interacting with an information presentation. The user interface module  can be comprised of a stage module , a timeline display area module , a GUI controls module , a layout manager module  and a timeline area renderer module .","The stage module  can be the graphical area in which all elements of the creation\/playback application  and information presentation are visually displayed. The elements that can be visually displayed can include, but are not limited to, all graphical user interface controls for the creation\/playback application  and all assets.","The timeline display area module  can be the graphical area in which all elements relating to the information presentation's and creation\/playback application's state over time can be visually displayed, including a timeline(s) and tracks as described below. In addition, the timeline display area can visually display other elements of the creation\/playback application  and information presentation.","The GUI controls module  can encapsulate and\/or provide any and all necessary graphical user interface elements and components used anywhere in the user interface by other user interface modules. Part of the GUI controls module  can be provided\/fulfilled by the native support of the system  on which the creation\/playback application  is running.","The layout manager module  can comprise many components\/instruction sets for providing various layouts for the assets within the creation\/playback application  or on the information presentation screen(s). The layout manager module  can provide flexible, input driven algorithms for laying out 1\u2212n assets in various positions. It can also encapsulate and provide for automatic or convenience layout capabilities with additional encapsulated algorithms with predefined default values or which can evaluate the context of the assets which it is laying out and automatically determine the best layout. With respect to evaluation of context and subsequent automatic layout, the layout manager module  can analyze various aspects of the system , including, but not limited to: number of assets to be laid out, type of assets, dimensions and\/or aspect ratio of assets to be laid out (e.g., 8.5 inch by 11 inch document, 800 pixel by 600 pixel presentation document, 4:3 video document, 16:9 video document, etc), font size(s) of text within the assets, or available space on the user interface within creation\/playback application  or information presentation on the particular device that is being used for display; or any combination thereof. For example, depending on the configuration of the application, the layout manager module  can determine that two assets are to be displayed (e.g., a 4:3 video, and an 800 by 600 presentation), and then determine that there is enough available space to layout the assets side by side on the screen. Likewise, the layout manager module  could determine that there is not enough space to optimally display both assets, and provide a side by side layout which only can show one asset at a time but can allow the user to \u201cslide\u201d back and forth between the two assets. In this scenario, it could also determine to show the two assets as one on top of the other.","The timeline area renderer module  can be responsible for rendering relevant state change and time definition data visually in the timeline area(s) and attaching GUI behavior\/interaction handling code\/instructions to the timeline area(s). The timeline area renderer module  can: contain core and generic subroutines used in various modes as well as routines intended for a per mode basis and\/or be injected with additional per-mode subroutine codes in order to render the timeline area.","Various Modes",{"@attributes":{"id":"p-0036","num":"0035"},"figref":["FIGS. 15-16","FIG. 15"],"b":["120","205","120","120"]},"In one embodiment, the user can interact with the at least one timeline, the timeline being rendered visually by the user interface module(s), to define the information presentation, wherein the creation\/playback application can create state change\/time definition data for the defined state changes that comprise the defined information presentation. An additional editor mode capability can include the ability for the creation\/playback application  to enter a record mode. While the record mode is activated, a user can make state changes to an information presentation and assets in real-time and the creation\/playback application  can monitor and record all input made by the user as it relates to state changes of the information presentation, assets, creation\/playback application , etc. Some specific examples of recordable state changes include, but are not limited to: actuating, activating, moving, showing, hiding assets; using the whiteboard widget; editing a document using the document editing widget; editing a spreadsheet using the spreadsheet editing widget; drawing using the drawing suite widget; gesturing with a device's cursor pointer; or manipulating or interacting with any assets or widgets; or any combination thereof. After a record mode session is ended, the recorded state changes can be rendered in the timeline area. The user can repeatedly engage the record mode to either overwrite recorded state change\/time definition data or to supplement it with additional recorded state change\/time definition data. Recorded state change\/time definition data can be immediately edited using the other editor mode capabilities, such as interacting with the timeline area. Additionally, the creation\/playback application  can persist the information presentation data and it's constituent parts (i.e., to an external database , a remote system , an external application support system or sub system ), and recall them again for editing as well as playback at any time. It should be noted that an editor user can include any person or computer capability that uses any device for defining the information. It should be noted that the record mode capability of the system is recording actual changes to the underlying data and state of the creation playback application and the information presentation such that that information presentation and full sequence of events may be \u201cplayed back\u201d at a later, rather than recording the screen or a video.","As indicated in , the runtime\/playback mode capabilities, enabled in one embodiment by the runtime\/playback mode module , can enable a user to: access and view information presentations and assets; interact directly and indirectly with the information presentation and assets; customize and edit the information presentation and the assets and the way they are presented; interact with other users of the system; or collaborate with other users of the system together with the information presentation or the assets; or any combination thereof. This capability will be referred to hereinafter as \u201cthe user viewing and interacting with the information presentation\u201d.","The collaboration mode capabilities, enabled in one embodiment of a collaboration mode module , can enable users to collaborate in real-time and non real-time in ways that may not be directly supported through any disclosed assets. For example, users of the system could use a collaboration mode capability whereby all users are able to view any other user's interactions or user invoked changes to the state of the information presentation, assets or application. Another example could be where each user can view the cursor indicator or mouse pointer of all other users viewing an information presentation collaboratively (hereinafter called a multi-cursor view). In this example, a multi-cursor view is not necessarily provided for by any other module, and thusly could be provided for by the collaboration mode module . When the multi-cursor view is activated, the collaboration mode module  can send state change\/time definition data through the multicast data broadcaster module  to notify the other users' applications to also activate this feature immediately. After all users' applications have the feature activated, each of the respective collaboration mode modules  can then be responsible for (e.g., while the feature is activated) engaging the multicast data broadcaster module  to send the coordinate details of the respective users' cursors as state change\/time definition data.","Those of ordinary skill in the art will see that any of the capabilities\/functions of any of the modes can be combined with the capabilities of other modes.",{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIGS. 40A and 40B","b":"100"},"By manipulating the information presentation during playback, such as selecting\/configuring\/changing the layout or adding\/removing assets from the screen, or inviting other users to collaborate, the creation\/playback application  can change from playing the information presentation in its predefined format (automatic play mode) into manual play mode, wherein the creation\/playback application  can no longer implement some or all of the predefined information presentation's state changes, such as the display\/activation of assets and layout changes. The user\/editor can immediately switch back to automatic mode with a single user gesture, such as clicking on a button. This capability is also detailed in FIGS.  and -, and their accompanying descriptions below.","Tracks","The user interface module , together with other modules, can accommodate multiple approaches for defining, playing back, visualizing and interacting with an information presentation. In one embodiment, one of the multiple approaches that can be implemented using the user interface module  can be the implementation by the creation\/playback application  of a visual timeline with zero or more tracks within a timeline display area, wherein the visual timeline and tracks are a specific graphical user interface that can be used interactively by the user with the system to: a) define states of the information presentation, states of the assets, and states of the creation\/playback application  and\/or the changes of the state of the information presentation, the state of the assets, and the state of the creation\/playback application over time; b) interact with the information presentation, the assets, and the creation\/playback application's states and state changes over time; or c) generally interact with the information presentation, the assets, and the creation\/playback application; or any combination thereof). The graphical user interface can also be used to visually represent for the user the information presentation, the assets and the creation playback application (e.g., changes of the state over time).","Tracks can flexibly accommodate the user in various capacities in visualizing, interacting with and configuring\/defining an information presentation, its assets and the creation\/playback application's state over time. The timeline area can have multiple tracks with certain tracks devoted to visualizing or configuring certain aspects of the state over time. For example, a multi-track embodiment in any mode may contain a track for each of the 1\u2212n assets to be displayed or activated\/actuated and certain aspects of state related to that specific type of asset. Tracks of this nature can be referred to as asset tracks. In addition there can be tracks that can be specifically implemented for defining and controlling other aspects of the information presentation over time, such as the layout of the information presentation, the abilities or constraints of the user to modify the layout of the information presentation, the functional capabilities of the assets and the information presentation, or the logic and rules regarding if real-time interactive widgets should be displayed and provided; or any combination thereof. Tracks of this nature can be referred to as control tracks. Examples of control tracks include: asset layout control tracks purposed around controlling\/defining the layout of the assets; application layout control tracks purposed around controlling\/defining the layout of the creation\/playback application; user constraint tracks purposed around defining certain actions that can or cannot be taken by the user; or any combination thereof. Additional detailed information with regards to tracks can be found in  and its accompanying description.","Assets and Structure",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 3","b":["305","310","305","100","315","320","315","320","310","100","100","100"]},"The widgets can comprise at least one text chat widget, at least one audio\/video chat widget, at least one asset browser widget, at least one discussion widget, at least one audio recording\/playback widget, at least one video recording\/playback widget, at least one stream playback widget, at least one audio\/video editing widget, at least one document viewing widget, at least one document editing widget, at least one linking widget, at least one activity widget, at least one slide show editing\/viewing widget, at least one diagram editing\/viewing widget, at least one drawing suite widget, at least one whiteboard widget, at least one polling widget, at least one survey widget, at least one assessment widget, at least one spreadsheet widget, at least one user list widget, at least one source code viewing and editing widget, at least one tracking widget, at least one glossary widget, at least one screen sharing and\/or screen recording widget, at least one wiki widget, at least one bookmark widget, at least one calculator widget, at least one presentation index widget, at least one layers widget, at least one integrations widget, or at least one third party platform interactive widget; or any combination thereof. It should be noted that any widget can be provided using third-party software. In addition, those of ordinary skill will see that any widget function(s) can be combined with any other widget function(s) to form other widgets.","The text chat widget can enable real-time text-based interactive discussion between multiple users of the system or the information presentation.","The audio\/video chat widget can enable real-time audio and video chat between users of the system through their respective devices, whereby each user can simultaneously view real-time video and audio feeds\/streams being broadcast from many users of the system. In some embodiments, it may use the stream playback widget. Various video camera and audio input sources can be supported through standard technologies and interfaces on various devices. Examples include web cam technology built into many notebook computers and video camera support built into mobile devices. In addition, the audio\/video chat widget can support a record mode and can be used to record a user's audio and\/or video input for use in a variety of ways in non real-time scenarios. For example, the audio and\/or video recorded could be used as an asset within an information presentation or within any other widget, such as being used in an audio and\/or video mode embodiment of the discussion widget.","The document editing widget can enable a user to create, edit, save and\/or recall and view documents and\/or can provide rich text editing similar to a document editor (e.g., Microsoft Word, etc.).","The slide show editing\/viewing widget can enable a user to design, create, edit, save, recall or view (or any combination thereof) slide oriented documents (e.g., slide show presentations) and slide shows similar to other slide show presentation creation tools (e.g., Microsoft PowerPoint, Apple Keynote, etc).","The linking widget can be used independently and standalone or in conjunction or as part of any other asset or widget. The linking widget allows any other assets or object within an asset or widget, or within rich text element (e.g., image, video, drawing\/diagrams element such as a shape, highlight, bitmapped image, etc; discussions within the discussion widget) or any text within any asset to be linked to or contain links including, but not limited to: 1) one or more points in time in the information presentation; 2) other assets; 3) other states of other assets; 4) other layers in the layers widget; 5) other information presentations; or 6) any other URI or URL; or any combination thereof, any of which can be displayed within the linked from\/original information presentation or outside of the information presentation.","The activity widget can be used in conjunction with other widgets in order to assemble or connect a sequence of other widgets or a sequence of layers or screens containing widgets together into a multistep interactive user activity, wherein such activity can be added to and become a part of an information presentation. Further, the activities can be timed or time limited and can be required or not required to be completed by the user.","The diagram editing\/viewing widget can enable a user to design, create, edit, save and\/or recall and view various types of diagram oriented documents similar to other diagram creation and viewing tools (e.g., Microsoft Visio, etc).","The drawing suite widget can enable a user to design, create, edit, save, recall, insert or view (or any combination thereof) various types of image files and assets of various types including raster\/bitmap formats (e.g., GIF, PNG, JPEG) vector file formats (e.g., SVG, EPS, Adobe Illustrator), various image or vector objects or drawing shapes (i.e., circles, squares, highlights, text). The drawing suite widget can support both vector drawing and image manipulation capabilities and raster\/bitmap image manipulation and capabilities, and can combine capabilities of various other standard drawing and image manipulation tools (e.g. Adobe Illustrator, Adobe Photoshop, Adobe Fireworks). As may be the case with any widget, the drawing widget may be placed\/moved\/positioned over top of any other asset or over all assets displayed within the creation\/playback application. It is important to note that any widget can be placed on top of any other widget within the user interface and stage of the creation\/playback application or within a layer (i.e., within the layer widget) or any combination thereof.","The asset browser widget can enable a user to browse, preview, view, or interact with (or any combination thereof) any asset that may or may not be related to a given information presentation. The asset browser widget may use other widgets if necessary in order to provide its capabilities related to browsing the assets. In addition, the asset browser widget can be one way in which a user may select and add assets to an information presentation or to the stage.","The discussion widget can provide various ways for a user to engage in discussions with other users of the system, according to several embodiments. The discussion widget can be used for various functions for message oriented communication, such as posting, replying, viewing, or archiving messages (or any combination thereof). The discussion widget can be configured to support discussions in several ways, including: ongoing and\/or thread oriented discussions similar in structure to other widely used online discussion\/message boards (also known as forums); ongoing lists of comments similar in structure to other widely used comment systems; or in other ways (including question and answer, etc.). The discussions and posts\/messages can be text or rich text based (i.e., text with various font sizes, colors, embedded drawings, embedded video and\/or multimedia, embedded images, etc. examples of which could be Microsoft Word documents or HTML documents), as well as audio and\/or video based. For example, discussions, messages, discussion posts and comments can be posted by users in an audio and\/or video format, or audio and\/or video in rich text format, wherein such audio and\/or video may have been recorded using the audio\/video chat widget's record mode capability Discussions and messages can be associated with a given point or several points in time within an information presentation, and as such, can be rendered visually on the timeline in various ways. The discussion widget can be configured to notify a number of devices when an interaction with the discussion widget has happened (e.g., notifications to mobile phones, SMS messages, email, notification popups in the creation playback application, when messages are posted or replied to). In addition, the discussion widget and its constituent posts\/messages and the posts\/messages content can provide for access (such as through links, etc.) directly into the information presentation, at the exact point in time for which the discussion or posts\/messages can be associated or other points in time in the information presentation. In addition, the discussion widget and its constituent posts\/messages can both be linked as well as contain links in any way provided for by the linking widget, and both can also easily reference and be linked to other discussions and posts\/messages.",{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIGS. 48A and 48B","b":["1","2","3","4","5","6","7","8"]},"The audio recording\/playback widget can allow for recording of at least one audio document and\/or the selection of at least one audio document, or controlling, viewing or hearing the playback of the audio document, or any combination thereof. The video recording\/playback widget can allow for recording of at least one video document and\/or enable a user to select at least one video document, or control, view or hear the playback of the video document, or any combination thereof.","The stream playback widget can allow a user to select and\/or to connect to at least one real-time (e.g., live) audio, real-time video, or real-time data stream, or to view and\/or hear the streams, or any combination thereof.","The audio\/video editing widget can enable a user to flexibly edit audio or video documents and assets or any combination thereof in a non-linear fashion similar to other non-linear editing systems. Similar to other non-linear editing systems, a user can create, define and output\/save video and audio files and\/or assets that are composited or mixed from multiple video and audio files\/assets in a non-destructive manner (e.g., without destructing, degrading or modifying the original video and audio assets). The user can use many standard user interface elements and approaches similar to the user interface of other non-linear video and editing systems, such as layers, visual in\/out points, etc.","The document viewing widget can enable a user to load and view text based documents in various formats (e.g., Microsoft Office, PDF).","The whiteboard widget can enable a user to draw and diagram independently, above, and\/or in conjunction with (e.g., on) any other asset, individually (e.g., visible to only one user) or collaboratively (e.g., with other users in real-time (e.g., live) and non real-time (e.g., non-live)). In addition to its own native drawing capabilities, the whiteboard widget can make use of other widgets, such as, but not limited to, the drawing widget and diagram editing and viewing widget.","The polling widget can enable a user to define and\/or participate in question based polls, both in real-time and non-real time. The survey widget can enable a user to define and participate in surveys, both in real-time and non-real time.","The assessment widget can allow users to define or view\/access\/participate in assessments (such as quizzes and exams) using numerous question types (e.g., multiple choice, true\/false, branching, matching, drag and drop, short answer, essay, etc.) and at least one question. The assessment widget can be configured to present to the user one or more questions or assessment activities at any point during an information presentation. The assessment widget can be configured in various ways including presenting any or all questions\/assessment activities modally (e.g., where the user must provide an answer or a correct answer before proceeding within the information presentation). The assessment widget can also allow determining, storing and\/or displaying scores, both within an information presentation and across multiple information presentations. Assessments created\/defined using the widget can be timed or time limited and individual questions in the assessment can be timed or time limited. The assessment widget can also be configured in various ways to ensure to ensure security of the assessment data, authenticity of the user and the integrity of the assessment. For example the assessment widget can secure a users device such that only the creation playback application (and no other applications or limited access to other applications) can be used during an assessment or track usage of any other applications on the device (e.g., both capabilities can be used to prevent cheating, etc.). Additionally, the assessment widget can use or be used in combination with various real-time assets and widgets to ensure integrity or the assessment and authenticity of the user and to prevent cheating. For example, the audio\/video chat widget can be used to verify the authenticity of the user and to proctor and\/or monitor users as they use the application and participate in an assessment.","The spreadsheet widget can create\/define\/edit and\/or allow viewing of spreadsheets (e.g., Excel) and\/or spreadsheet oriented activities similar to other spreadsheet applications (e.g., Microsoft Excel, etc.).","The user list widget can allow for users of the system or information presentation to see information about other users of the system or information presentation, and\/or interact with other users or solicit interactions with other users of the system or of the information presentation. For example, a user could activate the user list widget and sec a list of all users (e.g., editors, viewers, contributors) of an information presentation as well as additional information, such as their name, online status (or last time online), availability. A user could also interact with other users, such as \u201cknocking\u201d on their door or requesting various forms of collaboration, such as chat, collaboration mode, shared white board, etc.","The source code viewing and editing widget can enable a user with software development tool capabilities, ranging from enabling a user to view formatted and color coded computer programming source code (e.g., source code formatting) to enabling a user to participate in a fully integrated development environment. In the integrated development environment embodiment, the source code viewing and editing widget can provide for capabilities such as, but not limited to: source formatting, code highlighting, editing of source code, code completion and hinting, step oriented debugging capabilities, linking to object code, or compiling and execution of code, or any combination thereof. In addition, the source code viewing and editing widget can be one way of implementing and providing for programming to CARA . This ability to program against and for CARA  could be used to define an information presentation and the state of the information presentation and assets over time programmatically. For example, a user could choose to write code for or \u201cscript\u201d to define an information presentation and the state of an information presentation over time or a portion of an information presentation or any asset at any point in time in an information presentation, as an alternative to or in conjunction with using the applications various other capabilities (e.g., user interface) available for defining an information presentation.","The tracking widget can enable a user to track and\/or view his progress within an information presentation and across information presentations. Further, it can track and log every single action or interaction a user takes and the time at which it happened, providing for an analysis and reporting data set. The glossary widget can enable a user to view and\/or access a glossary for a specific information presentation, or across information presentations. The screen sharing and screen recording widget can enable a user to replicate and\/or broadcast in real-time and\/or record or playback (e.g., in real-time or non-real time) at least one portion of a user's device's screen, and\/or to view another user's recording and\/or broadcast on other user's screen. The screen sharing and screen recording widget also allows users of the system to take control of other user's systems (i.e., operating systems) such that a user or multiple users can control another user's computer. In addition, the recorded video of the screen capture can be used as an asset in an information presentation or within other assets.","The layers widget can provide a user and\/or editor with the ability to create and edit multiple layers upon the stage within the creation\/playback application. Each layer operates similarly to the stage and can be used to display one or more assets. From the user interface of the creation\/playback application  users can choose to view the one or more layers containing the assets together or separately, depending on their capabilities, as allowed\/disallowed by an editor. (Details regarding constraint controls discussed later in this disclosure).","The wiki widget can provide a user with wiki oriented collaborative knowledge building functions similar to other wikis using rich text, such as Wikipedia. The bookmark widget can enable a user to bookmark and\/or recall any point in time in an information presentation or an asset at any point in time, and\/or to share and or send these bookmarks with\/to other users and other systems. The calculator widget can enable a user to display a graphical calculator (including various types of calculators, such as standard, accounting, scientific, binary, graphing, etc.) and\/or to define calculator-based exercises or activities to be used in an information presentation. Those of ordinary skill in the art will see that various calculators (e.g., scientific calculator, accounting calculator, etc.) can be used. The presentation index widget can enable a user to define and\/or access an index of various points in time in an information presentation.","The third party platform widget can enable a user to integrate\/use widgets built or compiled for\/from a variety of platforms. The third party platform widget can include, but is not limited to, a widget built for the Adobe Flash platform ((SWF files etc), Microsoft SilverLight, or other technologies or web technologies (e.g., HTML, JavaScript, CSS, etc.), used separately or in combination.",{"@attributes":{"id":"p-0072","num":"0071"},"figref":["FIG. 37","FIG. 37"],"b":"120"},"Each state change\/time definition object can generally contain a time value, which can be the time in milliseconds for the state change to be executed. The time can be either absolute time or time relative to another time or relative to the start time of the presentation. In addition, the state change\/time definition object can comprise an indicator set to a value indicating a state change is to be executed immediately upon receipt. Furthermore, the state change\/time definition object can comprise a relative-to indicator, which can indicate what the time value is relative to.","The state change data within each state change\/time definition object can define an actual change in state to the information presentation, a change in state to the creation playback application , or a change in state to other state change\/time definition objects. In one embodiment, each state change\/time definition data can be: a discrete unit with a named reference or memory address based reference to a data values in memory within the application context and a new value to change to; a discrete unit with a named or memory address based reference to executable instructions along with input values for the executable instructions; or a discrete unit with executable instructions along with input values for the executable instructions; or any combination thereof.","Methods of Using the Creation\/Playback Application",{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIGS. 38A and 38B","b":["3805","3810","110","120","3811","3812","3811","110","3812","110","120","3815","115","3820","3821","3822","3823","3821","3822","3823","120"]},"In , the creation\/playback application  can open a network communication connection to the server computer  using a bus\/network communications I\/O manager . Remote server access can be connected via any IP\/Socket Protocol. In , the creation\/playback application instance can notify the server computer  that the initialization is complete. In , the creation\/playback application instance can process incoming data related to the initially received information presentation data. This can be done by invoking the data loader\/initial application updater module  with the initialization payload data, as set forth in -.","In , the information presentation data can be received. In , the assets and assets metadata can be added\/updated to the local assets database . In , the real-time or other state change\/time definition objects that require immediate processing and execution can be separated and identified. In , these real-time or other state change\/time definition objects that require immediate processing and execution can be handed to the state change proxy module  to be immediately executed. In , the state change\/time definition objects can be added and\/or updated in the local state change and timing database  with other state-change\/time definition objects which will potentially need to be executed later.","In , the creation\/playback application instance can begin the process of continually listening for incoming information presentation data, as set forth in -. In , the creation\/playback application  listens for newly received data. In , it is determined whether new data is received. If yes, new data is received, in , the data is sent to be processed (as described and illustrated in ). If no, new data is not received, in , the process returns to , where the creation\/playback application  continually listens for new incoming data.",{"@attributes":{"id":"p-0079","num":"0078"},"figref":"FIG. 4","b":["400","405","410","415","420","405","410"]},{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 5","b":["500","505","510","515","505","520","515","505"]},"Non-Track and Single Track Embodiments",{"@attributes":{"id":"p-0081","num":"0080"},"figref":["FIGS. 6-14","FIG. 17"],"b":["17","18","1705","1710","1715","1720","1725","1","2","3","4","5","6"]},{"@attributes":{"id":"p-0082","num":"0081"},"figref":"FIG. 18","b":["1805","1810","1815"]},{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIGS. 6-8","b":"120"},{"@attributes":{"id":"p-0084","num":"0083"},"figref":"FIG. 6","b":["605","610","615","625","620","630","625"]},{"@attributes":{"id":"p-0085","num":"0084"},"figref":"FIG. 7","b":["730","710","715","720","735","735","740","725"]},{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 8","b":"810"},{"@attributes":{"id":"p-0087","num":"0086"},"figref":"FIG. 9","b":["905","910","910"]},{"@attributes":{"id":"p-0088","num":"0087"},"figref":["FIGS. 10-12","FIG. 9","FIGS. 10-12"],"b":"910"},{"@attributes":{"id":"p-0089","num":"0088"},"figref":"FIG. 13","b":["1305","1315","1310","1320","1325","1330","1335"]},{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 14"},"Multi-Track Embodiment",{"@attributes":{"id":"p-0091","num":"0090"},"figref":["FIGS. 19-34","FIG. 19","FIG. 20"],"b":["100","100","100"]},{"@attributes":{"id":"p-0092","num":"0091"},"figref":["FIG. 21","FIG. 21","FIG. 19","FIG. 21"],"b":["2105","2110","2115","2120","2120","2125","2130","2135","2140","2145","2150","2155","2160"]},{"@attributes":{"id":"p-0093","num":"0092"},"figref":["FIG. 22","FIG. 22","FIG. 33"],"b":["100","240"]},{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 33","FIG. 33","FIG. 22"],"b":["240","3305","3310","240","240","3315","3320"]},{"@attributes":{"id":"p-0095","num":"0094"},"figref":"FIG. 34","b":["1","4"]},{"@attributes":{"id":"p-0096","num":"0095"},"figref":["FIGS. 23-32","FIGS. 23-26","FIG. 23","FIGS. 23","FIGS. 24-27"],"b":["100","1","2","1","3","3","4"]},"In , in , the timeline area and\/or track display a number \u201c2\u201d signifying the displayed slide show asset slide from the slide show asset being changed to slide number . (Note that since there is no state change indicted on the timeline, no layout state change occurs at this point in time.) In , the asterisk on the timeline can indicate the activation and display of an external resource widget (e.g., external web page, external web page link) where additional information may be found.","In , a timeline indicating a part of an information presentation is indicated. In , a player can reach the time in an information presentation whereby a state change(s) is to occur, wherein the state change(s) to occur is for the assessment widget to be activated. Once the player (i.e., creation\/playback application) reaches the applicable point in time, the video asset can be paused, and the assessment can be activated for the user to complete. This assessment can be timed, as represented by the clock icon. In , once the assessment is finished, the information presentation can continue. In , the player and information presentation reaches another set of state changes within the information presentation: a calculator widget is added to the stage, the stage switches from a two asset layout to a three asset layout, and, as signified by the unlock icon in the user layout constraint control track, the state of the information presentation and application is now such that a user can change the layout of the assets without constraint.","In  a timeline indicating another part of an information presentation is indicated. In , an audio asset can be triggered to play (and in this example to replace the video that was previously playing). Because the audio asset does not require a visual, the information presentation can switch from a three asset layout to a two asset layout, as indicated on the asset layout control track. In , another state change indicator can indicate another change in the information presentation. In this example, the player approaches another state change (visually represented by a pin), and the slide show can switch to a document. The layout can remain a two asset layout. The number \u201c22\u201d can indicate that page 22 should be the part of the document presented.","In , a timeline indicating another part of an information presentation is indicated. In , a player can reach a set of state changes that represent a non-timed interactive exercise (indicated by the infinity sign on the timeline) that uses a spreadsheet widget and a calculator widget. As defined by the editor user, the information presentation changes state to display a spreadsheet widget and a calculator widget on the screen and in a two asset layout. In , once the user is finished with the activity and prompts to continue, the information presentation continues, with the creation\/playback application  immediately executing a set of state changes. In this instance, the state changes are such that the spreadsheet widget is removed from the stage and a four asset layout is applied, containing the calculator widget, a video asset, a document viewer widget, and a chat widget.",{"@attributes":{"id":"p-0101","num":"0100"},"figref":["FIGS. 27-28","FIG. 27"],"b":["2705","2710","2715"]},{"@attributes":{"id":"p-0102","num":"0101"},"figref":"FIG. 28","b":["2805","120","2810","2815"]},"The user can also select whatever layout the user prefers using a variety of means. By means of a user modifying the information presentation during playback, such as selecting\/configuring\/changing the layout or adding\/removing assets from the screen, or inviting other users to collaborate in collaborate mode, the creation\/playback application  can change from playing the information presentation in its predefined format (e.g., automatic play mode) into manual play mode, wherein the creation\/playback application in manual play mode can no longer implement some or all the predefined information presentation's state changes, such as the display\/activation of assets and layout changes. The user can immediately switch back to automatic mode with a single user gesture, such as clicking on a button. In the example, after the user removes the calculator widget, the creation\/playback application  is now in manual mode. As the system in run-time mode continues to play the information presentation, and the time and time line of the information presentation reaches the respective point in time, the state of the information presentation as per defined by the editor user during the use of the system in editor mode is such that the information presentation uses a three asset layout, displaying the video widget, the slide show editing\/viewing widget with loaded slide presentation on slide number , and the calculator widget. However, some or all of these state changes, may not be executed, as a result of the various constraints that may have been implemented as part of the information presentation, and because the creation\/playback application  is in manual mode. The state change where an audio asset is played is executed, while the video asset (which video has ended) remains on the screen in the layout defined by the user. In addition, the user can continue to modify the information presentation as described above. For example, an asset can be added by having the user click on an icon representing the asset browser, and then drag and drop different assets to a certain pant of the screen. Those of ordinary skill in the art will see that other methods are also possible for adding an asset.",{"@attributes":{"id":"p-0104","num":"0103"},"figref":["FIGS. 29A-31","FIGS. 29A and 29B"],"b":["240","235","1","2","2","3","4","5","6"]},"In a manner similar to ,  illustrate a slide number click in a multi-track embodiment. In , an editor can click on an existing slide number. In , the editor's slide selection can be displayed, along with summary information, a list of possible actions, etc. In this example, a new slide is being inserted. In , a list of available slides can be displayed. Optionally, the editor may load slides from a new file. In , the editor can drop a new slide onto the timeline, represented by a pin with a slide number in it. In , the new stage layout can be shown. (Note that in this example there was no stage change as the new slide was inserted on an existing slide track.)","In a manner similar to ,  illustrate a defined time asset click in a multi-track embodiment. In , a two asset layout is displayed. An editor can click on the track\/video asset at time 12:22. In , a context aware pop-up menu can be displayed with a list of options. In , based on the user's previous selection, a popup presenting the user a list of types of time control\/defined time assets can be presented. In , based on what type of asset a user selects to add, various files can be shown for selecting or uploading. In this example, an \u2018Audio Asset\u2019 has been selected. In , an audio recording\/playback widget can be loaded into another subsequent popup menu, allowing the editor to preview the audio file\/asset. In , the editor can be notified that there will be a change in the layout because the audio file has nothing to display. In , the user has completed the addition of the asset (i.e., audio file) and the change in layout is shown within the application and system.",{"@attributes":{"id":"p-0107","num":"0106"},"figref":["FIG. 32","FIG. 32"]},{"@attributes":{"id":"p-0108","num":"0107"},"figref":"FIGS. 35-36","b":["39","41","47","100"]},{"@attributes":{"id":"p-0109","num":"0108"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0110","num":"0109"},"figref":["FIG. 36","FIG. 36"],"b":["100","120","120","120","120","120"]},{"@attributes":{"id":"p-0111","num":"0110"},"figref":"FIGS. 41A and 41B","b":"120"},"For example, in Scenario 1, a user Hiroko can view Professor X's predefined information presentation of a slide show in . In , Hiroko can view Professor X's predefined information presentation of a slide show and video. In , although Professor X is not online, Hiroko can activate the chat widget and video-chat widget and collaborate and interact with other available friends and information presentation viewers in real-time. When Hiroko modifies\/edits the run-time information presentation and adds the chat widget, the information presentation mode can change to manual mode.","In Scenario 2 of , in , John, like Hiroko, can view Professor X's predefined presentation of a slide show. In (), Professor X can come online. This can cause the predefined layout to be interrupted to expose the chat widget. In  and , even though the chat widget is appearing, because it was pre-configured to be able to appear, the information presentation is still in automatic play mode.","In Scenario 3 of , in , Julie, like Hiroko and John, is a user viewing Professor X's predefined presentation. In (), during Julie's viewing session, Professor X's office hours occur. This can interrupt the predefined layout to expose the chat widget. In  and , a slide show and video appear along with the chat widget. Because the chat widget was pre-configured to be able to appear, the information presentation is still in automatic mode.",{"@attributes":{"id":"p-0115","num":"0114"},"figref":"FIG. 42A-42C","b":["120","1","2","3","4","5","6","7","100","8","9","10"]},{"@attributes":{"id":"p-0116","num":"0115"},"figref":["FIGS. 43A and 43B","FIGS. 43A and 43B"],"b":"120"},{"@attributes":{"id":"p-0117","num":"0116"},"figref":"FIG. 44","b":"120"},"Scenes 2 and 3 take place in London where it is 5:00 PM. Using the creation\/playback application  in run-time mode, users are able to witness and interact with the information presentation and with other available users, including the editor user, in real-time, using such capabilities as the chat widget, video chat, etc. In Scene 2, the user is viewing the information presentation in automatic mode. In Scene 2, the presenter has specified a 3 asset layout that includes a live video feed, a slide show presentation, and a calculator widget. In Scene 3, however, the user has opted to run the live information presentation in manual mode, configuring his workspace (as allowed by the editor user) to his liking. The user in Scene 3 has opted to listen to the audio stream of the live information presentation, while viewing the slides, and activating the chat widget to converse with other users.","Scenes 4 and 5 take place in Tokyo, Japan. Since it is 1:00 AM in Japan at the time of the live information presentation, users will opt not to not see the information presentation until they wake up the next morning. In Scene 4, a user is viewing a published on-demand version of the information presentation at a later point in time (non-real time). The user can view it in automatic mode, seeing the information presentation exactly as the instructor intended\/defined\/recorded, or the user may (where permitted by the editor) modify the layout of the information presentation and view it in manual mode. In Scene 5, a user is viewing a non-real time version of the information presentation, but is chatting with the professor who delivered the presentation at a time in which both parties happen to be online.",{"@attributes":{"id":"p-0120","num":"0119"},"figref":"FIGS. 45A and 45B","b":["120","1","100","120","2","3","120","100","120"]},"In Scenario 2, the editor user loads, then uses the predefined information presentation within the creation\/playback application  in editor mode, in front of a live audience setting during a presentation. In addition, he can have set the creation playback application  into record submode. In , Professor X interrupts his information presentation using the creation playback application  and the predefined information presentation to show the audience how to calculate something. In . Professor X activates the calculator widget and begins showing the audience how to calculate the answer to a problem. He asks the audience to try to calculate it themselves and discuss their results. In , once complete, Professor X decides to take questions from students and other users of the system  viewing the information presentation and activates the chat widget that is available and running in the background to be displayed for both live audience members and all other users of the system  viewing the information presentation.","In Scenario 3, a user accesses the system and the information presentation from a remote location, in real-time as it is being defined and delivered by the editor user. This user uses the system in automatic mode, such that the information presentation is played back exactly as it is being defined by the editor user. Thus, in , John is in London and watches Professor X's information presentation live in real time. He sees a video of Professor X on the right and the slides on the left. In , since John is viewing the information presentation in automatic mode, when Professor X activates the calculator widget, John's screen automatically reorients itself to display the calculator widget. In , once Professor X activates the chat widget, John's screen reorients itself to display the chat widget so that he can have discussions with users.","In Scenario 4, another user also accesses the system and the information presentation from a remote location, in real-time as it is being define and delivered by the editor user. However, this user opts to inactivate and hide some of the widgets that the presenter\/editor user is displaying, thereby putting the application into manual mode. If a state change was to be activated but cannot due to the inactivation of some of the widgets, the user is notified of the specific state change that was to be implemented, but was not implemented due to being in manual mode, through a notification indicator popping up on the screen. In this scenario, the editor user added a calculator widget to display within the information presentation, and the user was notified of this state change via a pop-up window. Thus, in , Julie, like John views the information presentation from a remote location in real time. She finds the video footage too distracting and so opts to only see the slides by closing the video widget. In , because Julie is not in manual mode, when Professor X adds a calculator to the screen, she only receives a popup notification indicating that a state change has occurred. If she desires, she can click on the pop-up to see the predefined stage as it appears in automatic mode. In , when Professor X activates the chat widget, Julie remembers a question. She clicks to activate the chat widget and joins the discussion Professor X has started.","In Scenario 5, the user watches the information presentation, initially in automatic mode, as it was recorded\/defined by the editor user hours earlier. The user then changes and customizes the layout, thereby changing to manual mode, and then uses the real time interactive text chat widget. Thus, in , Hiroko is in Tokyo during the class, so she views the information presentation in non-real-time the next day. In , the screen can be configured to Hiroko's liking. For example, when Professor X activated the calculator widget, Hiroko can choose to close the video widget. In , because Professor X activated the chat widget and enabled it to run continuously, Hiroko can chat with other present viewers of the information presentation or other users of the system. Moreover, because Professor X decided to make himself \u201cknown\u201d when he logs on, Hiroko can ask him questions in real-time.",{"@attributes":{"id":"p-0125","num":"0124"},"figref":"FIGS. 39A and 39B","b":["120","1","1","1","2","3","4","5","6","7","8","9"],"i":["a","b"]},{"@attributes":{"id":"p-0126","num":"0125"},"figref":"FIGS. 46A-47","b":["120","1","2","3","4","5","6","7","8"]},"Continuing on in , in , after John is finished syncing Hiroko's slides to Julie's presentation, they collaboratively review the presentation and decide what additional tools, like the calculator widget, to add to the information presentation. In , as Hiroko and John are doing this, Julie feels that it might be a good idea to start taking notes on potential questions they might want to ask viewers through the presentation. She activates her note pad (not her workspace like she did previously) in private mode so as not to disturb John's and Hiroko's work, and begins taking notes. In , once John, Hiroko, and Julie have finished configuring the widgets on the stage, Julie shares her note pad with the team, showing them all the questions she has jotted down. They collaboratively edit the questions on Julie's note pad. Once finished, Julie emails a copy to everyone, so they have their own copy of the content. In , once they have finished building the information presentation, they preview the information presentation in its entirety in automatic mode. In , now that they have reviewed the information presentation and are satisfied with it, John configures the settings for the information presentation before publishing it to the web. In , the information presentation settings are shown.","FIGS.  and - are screen shots illustrating various single track and multi-track embodiments of the creation\/playback application , and various information presentations and assets. With respect to these figures, and other examples screens illustrated throughout this disclosure, those of ordinary skill in the art will understand that all of these examples screens can be sequenced together in different ways to create and playback many different types of activities using the activities widget.",{"@attributes":{"id":"p-0129","num":"0128"},"figref":"FIG. 49"},{"@attributes":{"id":"p-0130","num":"0129"},"figref":"FIG. 50"},{"@attributes":{"id":"p-0131","num":"0130"},"figref":"FIG. 51"},{"@attributes":{"id":"p-0132","num":"0131"},"figref":"FIG. 52"},{"@attributes":{"id":"p-0133","num":"0132"},"figref":"FIG. 53"},{"@attributes":{"id":"p-0134","num":"0133"},"figref":"FIG. 54"},{"@attributes":{"id":"p-0135","num":"0134"},"figref":"FIG. 55"},{"@attributes":{"id":"p-0136","num":"0135"},"figref":"FIG. 56"},{"@attributes":{"id":"p-0137","num":"0136"},"figref":"FIG. 57"},{"@attributes":{"id":"p-0138","num":"0137"},"figref":"FIG. 58"},{"@attributes":{"id":"p-0139","num":"0138"},"figref":"FIG. 59"},{"@attributes":{"id":"p-0140","num":"0139"},"figref":"FIG. 60"},{"@attributes":{"id":"p-0141","num":"0140"},"figref":"FIG. 61"},{"@attributes":{"id":"p-0142","num":"0141"},"figref":"FIG. 62"},{"@attributes":{"id":"p-0143","num":"0142"},"figref":"FIG. 63"},{"@attributes":{"id":"p-0144","num":"0143"},"figref":"FIG. 64"},{"@attributes":{"id":"p-0145","num":"0144"},"figref":"FIG. 65"},{"@attributes":{"id":"p-0146","num":"0145"},"figref":"FIG. 66"},{"@attributes":{"id":"p-0147","num":"0146"},"figref":"FIG. 67"},{"@attributes":{"id":"p-0148","num":"0147"},"figref":["FIGS. 68-74","FIGS. 68-74"],"b":"120"},{"@attributes":{"id":"p-0149","num":"0148"},"figref":"FIG. 68"},{"@attributes":{"id":"p-0150","num":"0149"},"figref":"FIG. 69"},{"@attributes":{"id":"p-0151","num":"0150"},"figref":["FIG. 70","FIG. 70","FIG. 71","FIG. 71"]},{"@attributes":{"id":"p-0152","num":"0151"},"figref":["FIG. 71","FIG. 71","FIG. 72"]},"The discussion board widget depicted in  shows many different discussions, each of which may be submissions from users using the rich text entry method described and depicted in .",{"@attributes":{"id":"p-0154","num":"0153"},"figref":["FIG. 73","FIG. 72"]},{"@attributes":{"id":"p-0155","num":"0154"},"figref":"FIG. 73"},{"@attributes":{"id":"p-0156","num":"0155"},"figref":"FIG. 74"},{"@attributes":{"id":"p-0157","num":"0156"},"figref":["FIGS. 75A-75E","FIGS. 75A and 75B"],"b":["100","120"]},"For example, referring to , in . Professor X may be creating a predefined information presentation using an editor mode embodiment using his desktop computer, tablet PC, mobile\/smart phone, or other computing\/controller device, or any combination thereof. In , the creation playback application opens in editor mode with the multi-track timeline visible. Professor X sets the initial state of the presentation to use a video recording\/playback widget and a document viewing\/editing widget. In , Professor X activates record mode. The user interface presents various options based on the context of the user interaction and configuration of the information presentation at the given point in time. In . Professor X clicks \u201cStart Recording\u201d and proceeds to record himself giving a presentation. At this point, Professor X is recording himself on video and audio and proceeds through the first few pages of the document. In , a short way into his presentation, Professor X decides he'd like to better explain a concept and will engage a few other assets and widgets to do so. First, using the asset browser widget, Professor X locates a relevant diagram. It is important to note that Professor X could have also chosen to create and display a new diagram. Referring to , in , a detailed view of the multi-track timeline, demonstrating how during the recording of an information presentation, all changes of state of any sort to the assets, widgets or information presentation may be recorded, as well as displayed visually on the multi track timeline.","In , the user interface presents Professor X with various options for adding the diagram to the stage and information presentation using a diagram viewing editing\/widget, including automatic layout options where the application automatically detects the best layout option. The application can also automatically add the diagram asset or widget to the stage without prompting the user, Professor X. In , Professor X activates the drawing widget. In , using various keyboard shortcuts, and\/or on screen prompts, etc., Professor X is able draw on\/within and\/or interact with both individual widgets or assets, as well as the stage as a whole. For example. Professor X makes some modifications to the diagram in real time, the state changes for which are being recorded. Likewise, Professor X can draw shapes overlaying and overlapping the various assets on the stage. It should be noted that  is only one example of the combining of widget capabilities together with other widgets, in this case the drawing suite widget being used and combined with the diagram viewing\/editing widget, as well as the document editing widget. In addition,  is also one example of the ability to put assets on top of other assets, in this case, the drawing suite widget being used to draw over top of the entire stage within the creation\/playback application .","Referring to , in , Professor X decides he'd like to have some supplementary information in the presentation, but leave the existing widgets and layout intact. To do this, Professor X can use the layers widget, to create a new layer on the stage.","In A, after creating the new layer, Professor X adds a new slide show editing\/viewing widget to the layer on the stage. Professor X edits the slide show, adding some text in bullet point form, then adds a calculator to the screen and performs an example calculation, all of which may still be recorded.","In B. Professor X then changes back to the first layer to continue with the main portion of the presentation.","Referring to , in , Professor X is done presenting the materials and stops the recording process (e.g., by clicking a stop button). All of the changes of state of the information presentation have been recorded and persisted by the system and creation playback application.","In , all of the changes of state of the information presentation that have been recorded are rendered and represented visually on the multi-track timeline. Professor X would now like to make some additions and changes to the information presentation. Specifically, Professor X would like to make some areas of the diagram he used into links to: 1) one or more points in time in the information presentation; 2) other assets\/widgets; 3) other states of other assets\/widgets; 4) other layers in the layers widget; 5) other information presentations; or 6) any other URI or URL; or any combination thereof. Any of these options can be displayed within the linked from\/original information presentation or outside of the information presentation. Those of ordinary skill in the art will see that there are other link types that may be created and applied to objects in the system.","Referring back to  on . Professor X may drag the timeline indicator\/playhead across the timeline in order to quickly find the point in the presentation","In , after locating the point in the information presentation where the diagram was added, Professor X now begins interacting with the diagram viewing\/editing widget and the application in order to create the links he would like.","In , it is demonstrated how, in this embodiment, by selecting and right clicking on an object (e.g., shape, image, text, etc.), Professor X can access the linking widget. In this example, Professor X is making the large blue arrow in the diagram link to another point in the information presentation, such that when a user clicks the arrow, the playhead will jump to another point in time in the presentation and the presentation will play from that point in time. The user interface in this embodiment allows a user to enter a time in hours, minutes, and seconds format, or to use the timeline and playhead to select the point in time (i.e., by clicking and dragging the playhead to the desired location\/time in the information presentation to link to).","Referring to , in . Professor X continues to link several other objects within the diagram, using all of the different linking types. The creation of each link type works similarly to that described in , wherein after right-clicking, then selecting a link type, the user\/editor (i.e., Professor X) is presented with special dialog boxes for creating that link type. In the example in , Professor X is linking an object to another asset or widget. The menu presented allows him to select an asset as well as some options for how the asset is displayed (e.g., add asset to stage, display asset modally). Those of ordinary skill in the art will see that there are many other configuration options available for all of the link types.","In , Professor X finishes creating the presentation and uses the save capability of the system  and creation\/playback application to save the presentation.",{"@attributes":{"id":"p-0170","num":"0169"},"figref":["FIGS. 76A-76D","FIG. 76A"],"b":["100","120","1","100","120","100","120"]},"In , Presenter X is preparing to give a live presentation to both a live and remote audience. He will also be recording the presentation for later editing or playback. Before or during the presentation, Presenter X can configure the application in many ways. Examples of such ways include, but are not limited to: what he will see while presenting, what his main control device will be, what other users will see, how other presenters may interact by default, what the constraints are on a user's ability to change the stage and activate other widgets and assets, and what other connected devices and systems to integrate with.","Referring to , in , Professor X begins his presentation using video and a document loaded into a document viewing\/editing widget. Presenter X's Tablet PC controller screen running an editor mode embodiment is depicted showing a full set of controls  available for controlling\/editing the information presentations display and changes of state. Other users' device's screens are depicted running either editor mode or runtime mode embodiments, and will show a limited set of controls  for controlling\/editing the information presentation, based on the constraints being set and managed by Presenter X and\/or other presenters, using various embodiments of the system and application.","In , Professor X next chooses to display one or more poll questions to the users and audience, using the polling widget. In this embodiment he is able to select a poll\/survey question from a bank of existing questions or he can create a new question. Additionally, a depiction of what a user my see on their embodiment is included, wherein such user's embodiment is displaying a poll response window (part of the polling widget). As with all embodiments, users can be either in the live audience or the remote audience, and can be using a desktop PC, a mobile\/smartphone, a tablet PC, a television, or any other computing or audio\/visual device.","Referring to , in , Professor X monitors the poll's results. When he is satisfied that all or enough users have submitted their responses, he can close the poll and choose whether or not to display the results to the users.","In , Presenter X decides to do a hands-on demonstration for the users using the document camera. Presenter X uses the integrations widget to switch the video feed to the connected document camera. Presenter X clicks\/selects the tools icon to access the integrations widget and is presented with a menu of relevant options based on the state of the information presentation and other context. Presenter X is able to select various routing options for this document camera video, including adding a new video to the stage. In this scenario he chooses to route the document camera to the screen in place of the current video on the stage.","Referring to , in , an example is depicted of what may be displayed in a user's embodiment after Presenter X activates the document camera as described above. What is shown is the video on the stage of Presenter X doing a pen and paper based activity. It is important to note that any type of camera or specialized camera (e.g., surgical camera, etc) may be used.","In , after Presenter X completes the hands on demonstrations using the document camera, he decides he will do a demonstration using screen sharing, such that he may display his computer\/tablet\/device desktop and its running applications. Using his chosen device, Presenter X selects to activate the screen sharing widget, and opts to use full screen sharing over the whole stage, rather than replacing a particular widget that may be currently visible to the users on the stage of the creation\/playback application .","In , an example is depicted of what users, as well as Presenter X, may see while Presenter X is using the screen sharing widget. Presenter X sees a full set of controls  over his desktop (which he can also hide). Users will see limited set of controls based on constraints, and are able to see Presenter X's desktop.",{"@attributes":{"id":"p-0179","num":"0178"},"figref":"FIG. 77","b":["120","1","2","3","3","4","5"]},"It is important to note that the sequences of screenshots illustrated in this disclosure can represent: 1) an information presentation being delivered and controlled live and in real-time by an editor user and viewed live by one or more users; or 2) an information presentation which was predefined and is being played back by users at a later time; or 3) any combination thereof.","While various embodiments of the present invention have been described above, it should be understood that they have been presented by way of example, and not limitation. It will be apparent to persons skilled in the relevant art(s) that various changes in form and detail can be made therein without departing from the spirit and scope of the present invention. Thus, the present invention should not be limited by any of the above-described exemplary embodiments.","In addition, it should be understood that the figures described above, which highlight the functionality and advantages of the present invention, are presented for example purposes only. The architecture of the present invention is sufficiently flexible and configurable, such that it may be utilized in ways other than that shown in the figures.","In addition, it should be noted that the terms \u201ca\u201d, \u201can\u201d, \u201cthe\u201d, \u201csaid\u201d, etc. in the specification, figures and claims signify \u201cat least one\u201d, \u201cthe at least one\u201d, \u201csaid at least one\u201d, etc.","Further, the purpose of the Abstract of the Disclosure is to enable the U.S. Patent and Trademark Office and the public generally, and especially the scientists, engineers and practitioners in the art who are not familiar with patent or legal terms or phraseology, to determine quickly from a cursory inspection the nature and essence of the technical disclosure of the application. The Abstract of the Disclosure is not intended to be limiting as to the scope of the present invention in any way.","Finally, it is the applicant's intent that only claims that include the express language \u201cmeans for\u201d or \u201cstep for\u201d be interpreted under 35 U.S.C. 112, paragraph 6. Claims that do not expressly include the phrase \u201cmeans for\u201d or \u201cstep for\u201d are not to be interpreted less than 35 U.S.C. 112, paragraph 6."],"BRFSUM":[{},{}],"DETDESC":[{},{}]}
