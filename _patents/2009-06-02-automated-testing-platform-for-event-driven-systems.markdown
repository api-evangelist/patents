---
title: Automated testing platform for event driven systems
abstract: A platform for the automated testing of event driven software applications is provided. A source environment is replicated to a target environment. The target environment includes a target system. A test case is defined with a target system, specific attributes and verification information. The attributes of the test case include the target system. The test case is fired. An event is simulated for the test case based on the target system and the specific attributes. The simulated event is transmitted to the target environment. The results of the test case being fired are determined based on verification information. The results are recorded to a data store.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08150674&OS=08150674&RS=08150674
owner: AT&T Intellectual Property I, LP
number: 08150674
owner_city: Atlanta
owner_country: US
publication_date: 20090602
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Embodiments relate to the automated testing of event driven systems. More particularly, embodiments relate to the running of test cases for event driven systems in an automated fashion.","Conventional software testing tools provide for automating the testing of a software application or system by simulating input into a graphical user interface (GUI) of the software application. The simulated input is received by the software application being tested and the testing tool captures the response of the software application by information returned to the GUI. The GUI for a software application is commonly considered the front end of the system. Such tools that provide front end testing of software applications typically do not address testing of the transactions taking place in the backend of the system. The backend of a software application can be considered the elements of the system that are not presented to a user of the system. For software applications that are primarily driven by events, front end testing tools provide limited use in evaluating the proper functioning of the software application. An event, in relation to this application, is a transaction related to a software system other than receiving input from a user or the transmission of user output.","Typically, testing the backend functionality of a system involves multiple steps. A non-exclusive list of steps typically performed for backend testing includes: setting up the testing environment, deploying the software, creating test cases, the execution of test cases, regression\/stress testing and evaluating the results of the test cases and the regression\/stress testing. Typically, the evaluation of the results is performed by testers manually searching the software application logs for the results. All of these steps are typically performed manually or with the use of custom written scripts. The manual operation of these steps and their ad hoc nature requires organizations that test software applications to spend considerable time and effort performing the manual steps and writing scripts each time it is necessary to test a software application.","Embodiments address issues such as these and others by providing for the automation of the backend testing of software applications. Various embodiments provide for the creation of test cases in a standardized GUI and the saving of the created test cases in a data store. Embodiments further provide for specifying of conditional statements and criterion for the evaluation and verification of test cases. Embodiments also further provide for the simulation of events in response to the firing of test cases and the transmission of the events to a target environment. Additionally, embodiments provide for the verification of the results based on the specified conditional statements and criterion. Embodiments further provide for the logging of the results to a data store and for regression and stress testing of event driven systems.","Embodiments include a method for the automated testing of an event driven software application. The method involves retrieving an event structure and default attributes for one or more systems from configuration files of each of the one or more systems. The method further involves creating one or more adaptors for each of the one or more systems from the event structure and the default event attributes of each of the one or more systems, each adaptor defined for a particular system. The method additionally involves receiving information that specifies a target system, non-default event attributes, and verification information to create a test case. When a request to fire the test case is received, the method further involves an adaptor for the target system being executed where the adaptor provides the event structure and default event attributes for events of the target system. The method additionally involves a simulated event being generated upon receiving the request to fire the test case. The simulated event is generated based on the event structure, default event attributes and non-default attributes. The method also involves the simulated event being transmitted to the target system and the results being determined by examining a response of the target system to the simulated event and comparing the response to the verification of the test case when a request to fire the test case is received.","Embodiments provide a computer readable medium containing instructions that when executed by a processor result in acts that include receiving a request to fire a test case, wherein the test case specifies a target system, non-default event attributes, and verification information. The acts further involve in response to the request to the fire the test case, a processor executing an adaptor, wherein an adaptor is defined for a plurality of target systems, each adaptor specifying an event structure and default event attributes based on information contained in configuration files of each target system. The acts additionally involve receiving from the executed adaptor the event structure and default attributes of the target system and generating a simulated event based on the event structure, the default event attributes and the non-default event attributes. The acts also involve transmitting the simulated event to the target system and determining the results of the test case by examining a response of the target system to the simulated event and comparing the response to the verification information of the test case.","Embodiments include a method for the automated testing of an event driven software application. The method involves receiving a request to fire a test case, wherein the test case specifies a target system, non-default event attributes, and verification information. The method further involves in response to the request to the fire the test case, a processor executing an adaptor, wherein an adaptor is defined for a plurality of target systems, each adaptor specifying an event structure and default event attributes based on information contained in configuration files of each target system. The method additionally involves receiving from the executed adaptor the event structure and default attributes of the target system and generating a simulated event based on the event structure, the default event attributes and the non-default event attributes. The method also involves transmitting the simulated event to the target system and determining the results of the test case by examining a response of the target system to the simulated event and comparing the response to the verification information of the test case.","Other systems, methods, and\/or computer program products according to embodiments will be or become apparent to one with skill in the art upon review of the following drawings and detailed description. It is intended that all such additional systems, methods, and\/or computer program products be included within this description, be within the scope of the present invention, and be protected by the accompanying claims.","Embodiments provide for the creation of test cases in a standardized GUI and the saving of the created test cases in a data store. Embodiments further provide for the verification of test cases by simulating events and transmitting the events to a target environment. Embodiments additionally provide for the replicating of a source environment and the configuration of a target environment. In an exemplary embodiment, the automated testing platform can be designed to provide testing services for software applications that support web services and can be optimized for systems utilizing a Service Oriented Architecture (SOA).","The automated testing platform (ATP) described throughout this application is referred to as the platform. In an embodiment, the platform can be used to take a snapshot of the environment of an event driven software application that requires testing to be performed. The snapshot can be stored within the platform. An event driven software application or application server is also referred to generally as a system. A snapshot refers to a copy of the set of files and directories on the source environment that are related to a system. An environment encompasses the system as well as the related structure and objects on a machine necessary for a system to function properly. The environment of the software application that a snapshot is taken of can be referred to as the source environment.","A machine, as referred to in this disclosure, is a computer capable of executing software. The computer can include a processor and computer readable media. Computer readable media can include magnetic and optical storage devices. The platform itself can be resident on one or more computers.","A target environment can be created for performing testing. The source environment can be replicated to a target machine with the use of the snapshot stored within the platform to create a target environment. With the creation of a target environment, a target system is created capable of processing events. A target environment separate from the source environment allows testing to take place without any negative effects on the source environment. Separate source and target environments are not a requirement for testing to be performed. The source environment may be used also as the target environment for the transmission and processing of events.","A test case can be created for testing a software application. A test case can include all attributes and parameters necessary for firing the test case, creating a simulated event, and verifying the results of the simulated event being executed by the target system. Conditional statements along with criterion for the results of the conditional statements to be compared to can be defined for a test case. The combination of conditional statements and criterion for a test case can be referred to as verification information. The event for a test case can be simulated with the aid of an Adaptor. The Adaptor can provide default attributes for the simulated event. The simulated event can be transmitted to a target environment where the event is received and processed by the target system. The results of the test case can be verified by interrogating or querying the structured storage of the target environment, applying the conditional statements to the log files and determining whether the results of the conditional statements correspond to the specified criterion. The structured storage may comprise a database, a structured log file or any structured data store. The results of the test case can be logged and reported to a user.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 1"},"As shown in , a Test Case Creator  can be provided for defining and controlling the firing of test cases. A Load & Soak Browser  can be provided for controlling the running of multiple test cases and configuring multiple test cases to be fired at the same time in a repetitive fashion. An Introspection & Schema Inspector  can be provided for creating verification information for test cases by identifying the data structure of a target environment. A Criteria Engine  can be provided for defining criterion for verifying the results of test cases. Events can be simulated for the running of test cases. A Simulator Engine  can be provided for simulating events based upon input received from test cases. Adaptors  can be provided for the Simulator Engine  to access, the Adaptors  providing additional input to the Simulator Engine  for the creation of simulated events.","As shown in , a target environment  can be provided for receiving simulated events and responding to the received simulated events. A Result Verifier  can be provided for verifying the results of a test case based on the response of the target environment  to simulated events that correspond to fired test cases. A Result Logger  can be provided for logging the results verified by the Result Verifier . Configuration Files  can be provided for maintaining the configuration of systems defined for testing by the platform. A Configuration Engine  can be provided for interacting with the Configuration Files  and for the platform accessing and reading the Configuration Files . A Data Store  can be provided for storing information pertaining to the platform. A Data Bus  can be provided so that each one of the modules may communicate with the Data Store  and each other. The Core Application Programming Interface (API) Layer  can be provided to provide the programming structure for each one of the modules.","As shown in , a Source Environment  can be accessed by the platform. The Source Environment  is any environment that requires the replication of its environment so test cases may be ran for testing a software application installed in the source environment. The Source Environment  can also be any environment that a user wishes to replicate from one location to another. An Environment Replicator  can be provided as part of the platform. The Environment Replicator  can provide for the replicating of the source environment  to the target environment . A Reporting Engine  can be provided for reporting the results of test case. An ATP Generic Browser  can also be provided such that a user can access the platform.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 2","b":["202","114","114","130","130","114","114","130","114","114","114"]},"In step  shown in , a test case can be created. A test case can be created by specifying the system that the test case is to be created for. The particular attributes for the test case can also be specified. Once the test case has been created the test case can be fired. When the test case is fired, in step , the platform can dispatch the test case to the Simulator Engine . When the Simulator Engine  receives the test case, in step  the Simulator Engine  can simulate an event. The event can be simulated based upon the attributes of the test case. Once the event is simulated the event can be transmitted to the target environment . The target environment  can be specified as an attribute of the test case.","In step  shown in , once the simulated event is transmitted by the Simulator Engine  and received by the target environment , the target system can process the simulated event. The target system can process the simulated event as an event that would be expected for the target system in the regular course of the execution of the software application. Once the simulated event is processed by the target system, in step , the platform can interrogate data of the target system pertaining to received events to discover the results of the target system processing the simulated event. Once the results of the target system processing the simulated event are identified by the platform, in step  the platform can record the results of the simulated event\/test case.",{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 3","b":["302","114","114","130","304","130","114","306","114","130","114","308"]},"In step , as shown in , whether an Adaptor is required for the test system can be determined. When no Adaptor is available an Adaptor can be created based on the configuration files of the source environment  that correspond to the test case in step . An Adaptor may be created dynamically from configuration files of the source environment  defined on the platform. When an Adaptor has been defined for the source environment , flow can proceed to step . In step , whether a desired test case has been defined can be determined. When a desired test case is available, flow can proceed to step . When no desired test cases have been defined, flow can proceed to step . In step , the basic properties of a new test case can be defined. Once the basic properties of a test case have been defined, flow can proceed to step .","In step , as shown in , whether verification information is to be defined for the test case can be determined. When verification information is not to be defined for the test case, flow can proceed to step . When verification information is to be defined for the test case, flow can proceed to step . In step , conditional statements can be defined for the test case. In step , criterion for results of the conditional statements to be compared to can be defined.","In step  shown in , the test case can be fired. Once the test case is fired, the firing of the test case can prompt the simulation of an event based on the attributes of the test case and the response of an Adaptor as shown in step . In step , the simulated event can be transmitted to the target environment . Once the target environment  processes the simulated event, the platform can receive a response from the target environment  that the event has been simulated in step .","Once a response has been received indicating the event has been simulated, whether verification information has been defined for the test case can be determined in step  of . When verification information has been defined for the test case, flow can proceed to step . When no verification information has been defined for the test case, flow can proceed to step . In step , the event data of the target environment  can be accessed. The data in the structured storage of the target system can be queried with the conditional statements defined for the test case in step . The response of the target environment  to the conditional statements can be compared to criterion defined for the test case in step . The results of the comparison can be recorded in step . When no verification information has been defined for the test case, the results of the test case being processed by the target environment  can be recorded in step . Once the results of the test case have been recorded, the results can be reported in step .","As mentioned above, the functions of the platform can be organized into modules. One module of the platform can be the Test Case Creator . The Test Case Creator  as shown in  can provide for defining and configuring test cases. When a test case is defined it can be saved in the data store. A new test case can be created by entering the name of the test case, the event type that the test case is to simulate, specifying the source system that the test case is simulating, and whether the test case is active or not. In an exemplary embodiment, the test case is defined by a plurality of XML statements. The test case can also be defined by other means such as another open language other than XML or by the use of various proprietary statements. Once the definition of the test case is complete the test case can be saved in the Data Store .","A user interface screen can be provided for defining new test cases. The screen for adding new test cases can comprise two tabs. One of the tabs can be for providing the basic properties of a test case. In an exemplary embodiment, the basic properties of a test case can include: a test case name, a source system name that the test case is simulating events for, a simulator interface (i.e. Adaptor), a template location to bootstrap the simulated events attribute values, an event type, and whether the test case is active. The event types available for a test case will depend upon the source system that is selected for a test case. Particular examples of event types can include: change created, approver group added, send email, and send email with attachment. When a test case is inactive the test case is disabled from being fired. shows one example of the initial tab of a new test case screen.","Another tab for a new test case screen can be the attributes tab. shows one example of the attributes tab of the new test case screen. The attribute tab can comprise a plurality of fields with drop down boxes to select an attribute name to specify for the event to be simulated by the test case. The attribute name field can have a corresponding value field to specify a value for the attribute. The field for the value can accept free-form text or can query a structured storage to list available values. For test cases that have been defined and saved to the data store, the screens shown in and can be used to modify the properties and attributes of existing test cases.","After a test case is created, it can be selected for execution. The executing of a test case can also be referred to as \u201cfiring\u201d of the test case. In an exemplary embodiment, the platform provides for selecting multiple test cases at once for firing. The platform can also provide the ability to select multiple test cases and perform other actions at once to each selected test case. Other actions that can be performed on a plurality of test cases include: deleting, modifying and copying.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 5","FIG. 5"],"i":["a ","a"]},"Additionally, the user screen of can provide shortcuts for each test case. Each shortcut performs an indicated function for the particular test case that the shortcut is associated to. The association for a shortcut to a particular test case is shown by the shortcut and test case being located in the same row of the user screen. Certain examples of shortcut buttons that can be provided include: a fire shortcut, a modify shortcut, and a remove shortcut. Navigational shortcuts can be provided on the interface for the user to navigate to additional screens.","Additional properties and attributes can be specified for a test case. These properties and attributes can include current properties, default properties and attributes. The current properties can include: Server Uniform Resource Locator (URL), URL Suffix, and Event Template. The default properties can include: Server URL, URL Suffix, Event Template, Class Name, Test Case Name, Simulator Interface, Event Type and Template Location.","There can be two levels of properties: Global properties and local properties. The Global properties apply to all users. A particular user can change these settings by editing local properties of the user and saving the local properties of the user. The local properties override the global properties for test cases defined by the user. Additionally, a user can temporarily override and point all test cases to a particular URL. Pointing all test cases to a particular URL is transient and does not persist from a first user session to a second user session.","An additional window provided by the screen can also display additional properties and attributes of a test case. This additional window can be activated by hovering the pointer over the particular test case. shows one example of a screen window detailing the additional properties and attributes of a test case.","Test case sets can also be defined for the logical grouping of test cases. A test case set selection screen can also be provided for defining, selecting, and modifying test case sets.  shows one example of test case selection screen. The screen can provide the option to select one of a plurality of test case sets. Once a test case set is selected, a user can specify to load, delete, or rename the test case set. The user can specify any one of these functions by buttons provided on the screen. The user can also create a new test case set by selecting a create button provided on the screen.",{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 7","b":["702","704","706","708"]},"In step , shown in , a determination can be made as to whether there is additional verification information to be defined for the test case. When there is additional verification information to define, the flow can proceed back to step . When there is no additional verification information to define, the flow can proceed to step . In step , a determination can be made as to whether there are additional test cases to be added. When there are additional test cases to be added, the flow can proceed back to step . When there are no additional test cases to be added, the adding of test cases is complete.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 8","FIG. 5"],"i":"a","b":["802","804","806","808","804","810","810"]},"An Additional module of the platform can be the Environment Replicator . The Environment Replicator  can be provided to allow the replication of the source environment  and the saving of the source environment  on the platform. The source environment  may also be replicated to a target environment  by the Environment Replicator . The Environment Replicator  enables the moving of the environment of a software application without having to replicate an entire computing system that the software application is running on. The Environment Replicator  can accomplish this by copying only the files required by the software application and by performing parameterization of configuration files pertaining to the source environment . The parameterization of the configuration files allows a user to move the software application and avoid the risk associated with the manual editing of the configuration files. Copying the necessary information from the source environment  for replication can be referred to as taking a snapshot.","The replication of an environment by the Environment Replicator  can involve multiple steps. First, the Environment Replicator  can request from a user a location of an environment that includes a system (software application) that a user wishes to test or just wishes to move from one computer system to another. The Environment Replicator  allows a user to take a snapshot of a computing environment by copying the necessary files and directory structure of the environment. The Environment Replicator  may request a user to input where particular files are stored on the source machine related to the source environment . A user may need to specify the URL, Internet Protocol (IP) address and paths of where objects related to the source environment  are located.","The Environment Replicator  also identifies the necessary configuration files required for replicating the source environment . The location of the configuration files for the source environment  can be identified based on a root location of where software of the source environment  is installed that has been specified by a user. The location and names of the configuration files can then be determined based on the root location if the configuration files follow a particular convention for the naming and locations of the files. Once the configuration files are identified these files are also copied from the source environment .","Once the configuration files are copied, the Environment Replicator  can parameterize the configuration files. Parameterization involves the Environment Replicator  identifying key attributes contained within the configuration files that may require new values based on moving the software application from a first location (i.e. source environment ) to a second location (the platform or target environment ). Once these key attributes are identified the Environment Replicator  can prompt a user for appropriate values corresponding to the replicated location of the software application. The Environment Replicator  can prompt a user through a GUI for the necessary changes to the parameterized fields of the configuration files and thus can prevent a user from having to directly edit the configuration files. The configuration files can contain name\/value matched pairs for each attribute where the name of an attribute is followed by the configured value for the attribute.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 9","b":["130","114","902","130","130","904","130","132","114","906","908","132","114","910"]},"In an exemplary embodiment, the configuration files are in an XML format. The identification of key attributes is performed by matching predetermined XML tags that are known to correspond to particular attributes that require updating when an environment is replicated. In another exemplary embodiment, the configuration files are in a standardized form and the Environment Replicator  identifies the key attributes according to the standardized form of the configuration files.","Templates can also be provided to aid in the parameterization of configuration files. A template can specify the name of key attributes and the format\/structure of the key attributes. The template can also contain information pertaining to the overall structure of the configuration files, the naming conventions of the configuration files, and the appropriate locations of the configuration files relative to a root directory. The template can apply to a class of source environments or a grouping of source environments.","A template may not specify all of the key attributes for a configuration file for a particular source environment. When the template fails to identify all of the key attributes, the platform can receive from a user information to identify additional key attributes that may require parameterization. A template might also not have knowledge of every configuration file for a particular source environment. In that case, the user can also specify the additional configuration files. Once the additional key attributes and\/or configuration files are supplied, this additional information can be combined with an existing template to define a new template that can apply to another grouping of source environments.","A template may include suggested values for a user to update key attributes with or the template may specify to the Environment Replicator  to automatically insert new values for certain key attributes. One particular example can be where there are numerous key attributes that contain the same value, such as the new address of the replicated source environment  (i.e. the target environment ). This new address can be inserted into the appropriate value fields as required.","Particular examples of key attributes can include: network addresses of the destination system, system names, socket addresses that the software application may use for communication, the maximum number of sockets to be used by the application, the number of file descriptors available and file system paths. Once the new values of the attributes are provided, the Environment Replicator  can update the replicated configuration files accordingly.","In a particular embodiment, a screen can be provided by the Environment Replicator  for specifying the details to create a snapshot of a database. As one particular example, the screen can be adapted for taking a snapshot of an Oracle database. The screen can also be adapted for taking a snapshot of other database products or can be adapted for taking a snapshot of various types of databases. shows an example of a screen for taking the snapshot. The screen can have a plurality of labels as shown in the figure for specifying various attributes pertaining to taking the snapshot. These labels can have corresponding fields for specifying values for the various attributes. Depending upon the particular attribute, these fields can accept free-form text or can provide a drop down box for selecting various predetermined values from the drop down box. A button can also be provided for executing\/running the snapshot.","An additional screen can be provided for specifying the source environment  and the target environment  in replicating an environment by the Environment Replicator . shows an example of a screen for replicating an environment. In an exemplary embodiment, the screen can provide fields for specifying addresses pertaining to both the source environment  and the target environment  including the Machine IP, port and the machine location for each environment. A button can also be provided for the running of the replication.","An additional module can be included with the platform. The Load and Soak Browser , as shown in , can be provided to allow the testing of a plurality of test cases along with the repetitive testing of a plurality of test cases. Test cases can be fired in Bulk Load or Maintained Load mode for the automating of stress testing and regression testing.","The Bulk Load mode can comprise loading the target environment  with the normal activity of a typical system and increasing the frequency of simulated events to identify the \u201cbreaking point\u201d\u2014the performance limitation of the software application running on the target environment . For example, a user can specify that all test cases for a particular system be ran at periodic intervals at a certain frequency that approximates the expected use of the application by the user community. The frequency of the test cases can be increased until the target environment  being tested responds at an unacceptable level. An unacceptable level can be defined as when a certain level of errors are recorded in the event related data of the target environment . For example, a user can specify that all test cases of a set  of test cases and a set  of test cases for a particular system be executed within a particular period of time. The time period between firing of test cases can then be incrementally changed to shorter periods until performance of the system degrades to an unacceptable level.","The Maintained Load option can allow a source system to be tested for a prolonged period of time according to the expected regular productive use of the source system. An extended duration can be specified to running a pattern of selected events. The pattern of events can be selected to approximate the expected use that the system would receive. The events can then be ran in this pattern repetitively for the specified extended duration.","Another additional module of the platform can be the Configuration Engine . The Configuration Engine  can allow a user to specify a new system for testing or edit the configuration of a previously defined system. The Configuration Engine  reads the configuration files previously stored with the platform to initialize the platform upon start up. For each system defined within the platform, there can be a set of configuration files. The configuration settings for a system defined on the platform include means for specifying the target environment where simulated events are to be transmitted to for testing. For each system defined on the platform, the platform can include the machine address of the target environment for running simulated events configured for a particular target system. The address of a target environment can be provided as an IP address. In an embodiment adapted for web services, the configuration settings can include the URL for the target environment where simulated events are to be transmitted for testing for a particular system.","In an embodiment, a configuration file can have three levels: global, local, and temporary. The global level contains configurations shared by all users of the platform. The local level contains configurations for only the current user. The temporary level contains configurations for the current session of the user. The local configuration settings can override the global configuration settings. The temporary configuration settings can override both the global and local configuration settings.","When defining a new system within the platform, the user can select whether the change to the configuration is to affect the global, local, or temporary configuration. After specifying which configuration the new system is to be applied to, the new system can be defined.","In , an initial screen is shown for an exemplary embodiment of the platform for configuring the global configuration. In the screen, a drop down box can be provided for selecting the global system properties or global system details for editing or viewing. A button can also be provided for selecting the selected file for viewing or editing. A field can also be provided for specifying a new system to be added to the platform. A button can also be provided for adding a new system once the field is populated with a name for the system.",{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 11","i":"b "},"For local configuration settings, an additional screen can be provided, as shown in . In an exemplary embodiment where the platform is adapted for providing testing for software applications that support web services, the screen can provide a field for specifying a single URL for pointing test cases towards. This URL will direct the platform to deliver all simulated events from test cases to the specified location (i.e. designate a particular target system for all events to be transmitted to). From this screen, a drop down box can also be provided to allow a user to select local system properties or local system details to be viewed or edited.","Another module of the platform can be the Introspection and Schema Inspector  as shown in . The module may also be referred to as the Inspector . The Inspector  is capable of inspecting the data structure of the target environment  that contains historical data regarding the response of the target system to received events. Once the data structure is discovered the Inspector  can determine the structure required for conditional statements to verify simulated events once they have been received by the target environment . This structure can then enable the creation of the conditional statements for verifying the results of the simulated events received by the target environment . Rather than inspecting the data structure of the target environment , the Inspector  may also be configured to inspect the data structure of the source environment  that corresponds to the system to be tested. The source environment  may be accessed remotely at the source machine or accessed via the snapshot of the source environment  stored on the platform within the Data Store .","As a simplified example of the functionality of the Inspector , a test case may be written to test an email system, the test case defined to simulate an e-mail being delivered to the target environment . A user may desire that verification information be defined for the test case that verifies that the email was received properly by the target environment . However, the user may not know how the receipt of an e-mail is recorded or logged by the target environment . The Inspector  can expose the data structure of the target environment  that records or logs the receipt of emails. Once the data structure of the target environment  is exposed, conditional statements for querying the receipt of an email can be determined based on the data structure of the target environment .","The Inspector  can provide to a user suggested conditional statements for a user to select for verifying the results of a test case. Depending upon the data structure of the target environment , the Inspector  can provide complete conditional statements for the user to select or may provide to the user partial conditional statements to the user where the user may need to complete the conditional statements. The selection by the Inspector  of suggested conditional statements may be at least partially based on attributes specified for the particular test case.","In an exemplary embodiment, the platform and target environment  can support Java Database Connectivity (JDBC) for the exchange of data. The platform can also support Open Database Connectivity (ODBC). The data structure of the target environment  can comprise a relational database. The target environment  can be a replicated environment stored on the automated testing platform, or a production environment at a remote location that is accessible to the platform. The target environment  can also be a dedicated testing environment.","A further module of the platform can be the Criteria Engine . The Criteria Engine  is capable of retrieving historical event related data of the target environment . By retrieving historical event-related data, the Criteria Engine  can define criterion for a test case. The conditional statements defined using the Inspector  combined with the criterion defined with the Criteria Engine  can be combined as verification information for a test case. The event related data can include values stored in log files or a data store of the target environment  related to the processing of received events. Along with the event related data, the Criteria Engine  can retrieve the attributes for the events that correspond to the values related to those particular events. From these values, corresponding event attributes and related conditional statements, the Criteria Engine  can provide to a user expected values that should result from test cases that specify related attributes when the test cases are fired against the target environment .",{"@attributes":{"id":"p-0085","num":"0084"},"figref":"FIG. 12","b":["106","108","1202","130","1204","1206","130","1208","1210"]},"As a simplified example of the functionality of the Criteria Engine, a test case may be written to test an email system, as in the example given above in regards to the Inspector , with a test case defined for simulating an event being delivered to a target environment . Conditional statements may be defined for verifying the receipt of the email but the expected results of applying the conditional statements to the target environment may not be know by the user of the platform. The Criteria Engine can be used to retrieve values from previous events, such as values saved in a log file or a data store, due to a previously received e-mail or a previously ran test case that prompted the simulation of an e-mail being sent, and provide these values to the user to allow the user to specify or select the expected results of the conditional statements. These expected results can be saved as the criterion for the test case.","Rather than inspecting the event related data of the target environment , the Inspector  may also be configured to inspect the event related data of the source environment  that corresponds to the system to be tested. The source environment  may be accessed remotely at the source machine or accessed via the snapshot of the source environment  stored on the platform.","The expected results of a test case discovered by the Criteria Engine  can be used to specify criteria for the test case. The criteria for a test case are associated with related conditional statements for the test case. When the conditional statements are ran on the target environment , the expected results are specified by the selected criterion. The conditional statements and the combined matching criterion can be referred to as verification information. The verification information can include rules for when the results for a test case are to be considered as \u201cpassed\u201d or \u201cfailed.\u201d The verification information can be saved as part of the properties of a test case. The rules can define that certain responses should be within a specified range of the expected results (criteria) or that a specified amount of expected results must be met for a test case to be marked as passed.","Another module of the platform can be the Simulator Engine . The Simulator Engine  can simulate events based upon received test cases. The simulator engine operates by the use of Adaptors . An Adaptor specifies the structure required for the event based upon the structure of the source environment . The Adaptor also provides all necessary default attributes for a simulated event. In a particular embodiment, an event can have 200 or more attributes. The attributes defined by the test case replace or overwrite the attributes defined within the Adaptor. For attributes not specified by the test case, the default values provided by Adaptors  are used in creating the simulated event. In a preferred embodiment, each Adaptor is a compiled executable. In an alternative embodiment, each Adaptor may be a flat file with the attributes and structure of events for the system specified in plain text.","For the source system, an Adaptor can be defined on the platform prior to the running of a test case for the source system. If an Adaptor is not defined on the platform when a test case is ran, an Adaptor can be created dynamically by examining the configuration files for the source environment . The configuration files of the source environment  can be accessed from a copy of the configuration files saved on the platform where the copy was created by the platform previously taking a snapshot of the source environment . The configuration files of the source environment  may also be accessed by the platform receiving an address of the source environment  and the platform remotely accessing the source environment  located on a source machine. The address of the source environment  may be specified in a particular embodiment by a user entering one or more URLs that specify the location(s) of the source environment  configuration files.","The configuration files of the source environment  are examined to identify the structure and attributes for building an Adaptor for the source system. For the platform to dynamically build the Adaptor the configuration files must be understood by the platform and contain all necessary information for building the Adaptor. The dynamic building of an Adaptor can occur automatically with no input from a user. When the source system is not defined on the platform, not accessible to the platform, or when the configuration files of the source environment  are not understood by the platform, an Adaptor may be built by receiving input from a user. The platform may also be able to partially build an Adaptor automatically by examining the source environment  configuration files and then complete the building of the Adaptor by receiving input from a user. Once an Adaptor is built for a source system the Adaptor is saved in the Data Store  of the platform. The platform can also be adapted to recognize the structure of additional source environment  configuration files by modifying or adding to the open API of the platform.","For the Simulator Engine  to simulate an event, the Simulator Engine  parses a test case to identify which source system the case is written for. Based on the identification of the source system for the test case, the Simulator Engine  determines which Adaptor to use for simulating an event for the test case. The Simulator Engine  executes the particular Adaptor and creates the simulated event based on the output of the Adaptor and attributes specified for the test case. The Simulator Engine  then transmits the simulated event to the target environment . In a typical embodiment, the platform determines the address of the target environment  based on the system specified for the event. The address of the target environment  for the system can be retrieved from the configuration files for the system stored on the platform in the Data Store .","Prior to the Simulator Engine  transmitting an event to the target environment , the target environment  may be configured for the processing of events received from the Simulator Engine .  shows one example of a set of steps that may be performed for creating the target environment . In step  an environment configuration screen can be accessed. In step , whether a snapshot for creating the target environment  is to be used from the data store or a new snapshot is to be used can be determined. When a new snapshot is to be used, in step  the snapshot from the source environment  can be created and stored in the Data Store . Once the new snapshot is created, flow can proceed to step  and the snapshot can be selected from the Data Store . In step , the machine for the target environment  can be selected. In step , the selected snapshot can be replicated to the selected target machine.","An additional module of the platform can be the Result Verifier . The Result Verifier  determines the results of test cases. The Result Verifier  determines results of the test case by interrogating the event logs or event data of the target environment . The interrogation can be performed in an exemplary embodiment by querying the target environment . The target environment  can be queried via JDBC or ODBC calls to the target environment . The Result Verifier  determines the results by the verification information provided for a test case.","The Result Verifier  can query the target environment  with the conditional statements associated with a test case. The response of the target environment  can be compared to the criterion specified for the test case. If the response matches the specified criterion then the test case can be marked as a success. Rules may also specify that a relationship between the response to the conditional statements and the criterion for a test case to be marked as \u201cpassed\u201d or \u201cfailed.\u201d When rules are specified for the test case, the determination can further involve the Result Verifier  verifying whether the test case \u201cpassed\u201d or failed.\u201d Test cases do not need to specify criterion to be ran or fired successfully. Test cases can be ran and the response of the target environment  can be recorded when no verification information is specified.",{"@attributes":{"id":"p-0096","num":"0095"},"figref":"FIG. 14","b":["1402","1404","1406","1408","1410","1412","114","1414","114"]},"In step  shown in , a determination is made as to whether verification information has been supplied for the test case. When verification information is provided, flow can proceed to step . When no verification information is provided for the test case, flow can proceed to step . In step , the target environment  can be queried with the conditional statements. In step , the response of the target environment  to the conditional statements can be compared to criterion defined for the test case. In step , the results of the test case can be recorded to the Data Store . In step , a determination can be made as to whether there is additional verification information to be checked for the test case. When there is additional verification information for the test case, flow can proceed back to step . When there is no additional checking to be performed, flow can proceed to step . In step , the results of the test case can be displayed via a report.","Another additional module of the platform can be the Result Logger . The Result Logger  can receive the results from the Result Verifier and log them to the Data Store  via the Data Bus .","A further module of the platform can be the Reporting Engine . The Reporting Engine  can retrieve the results from the Data Store  and present the results through various graphical means for a user to view or print. In an exemplary embodiment, the Reporting Engine  interfaces with a third party reporting tool to present reports to users.","While embodiments have been particularly shown and described, it will be understood by those skilled in the art that various other changes in the form and details may be made therein without departing from the spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4","i":"a "},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4","i":"b "},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5","i":"a "},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5","i":"b "},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 10","i":"a "},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 10","i":"b "},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 11","i":"a "},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 11","i":"b "},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 11","i":"c "},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 14"}]},"DETDESC":[{},{}]}
