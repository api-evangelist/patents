---
title: Tracking noise via dynamic systems with a continuum of states
abstract: A system and method reduces noise in a time series signal. A primary signal including stationary and non-stationary noise is modeled by a dynamic system having a continuum of states. A secondary signal including time series data is added to the primary signal to form a combined signal. The generic noise in the combined signal is estimated from samples of the combined signal using the dynamic system modeling the generic noise. Then, the estimated generic noise is removed from the combined signal to recover time series data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07050954&OS=07050954&RS=07050954
owner: Mitsubishi Electric Research Laboratories, Inc.
number: 07050954
owner_city: Cambridge
owner_country: US
publication_date: 20021113
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["STATEMENT OF GOVERNMENT INTEREST","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT","Generic Noise Dynamic System","Noise Estimation","Sampling the Predicted State Density","Compensating for Noise","EFFECT OF THE INVENTION"],"p":["The invention described herein may be manufactured and used by or for the Government of the United States of America for governmental purposes without the payment of any royalties thereon or therefor.","This invention relates generally to signal processing, and more particularly, methods and systems for reducing noise in time series signals.","In the prior art as shown in , a signal processing system  is generally modeled as follows. A dynamic system  generates a primary signal . The primary signal  as used herein is a dynamic time series, e.g. human speech.","The primary signal  is subject  to a corrupting and additive secondary signal , e.g., stationary random, white or Gaussian noise, to produce a combined signal . Because the noise \u201clooks\u201d the same at any instant in time, it can be considered \u201cstationary.\u201d The problem is to substantially recover the primary  signal from the combined signal .","Therefore, in the prior art, the combined signal  is measured to obtain samples . An estimate  of the stationary noise is determined  based on an understanding or model of the dynamic system  that generated the primary signal , i.e., the speech signal. The estimated noise  is then removed  from the samples  to recover the primary signal  having a reduced level of noise.","The prior art model  assumes that the noise in the combined time series data  is the output of some underlying process. The nature or the parameters of that process may not be fully known, therefore, it is generally modeled as a random process.","Additional formulations represent what is known about the underlying primary signal. The dynamic systems  represent a convenient tool for such representations of the primary signal because dynamic systems can accommodate arbitrarily complex processes, diverse sources of information, and are amenable to standard analytical tools when simplified to suitable forms.","A conventional approach to estimating  the noise  affecting the combined signal  is to model the speech signal as an output  of the dynamic system , such as a hidden Markov model (HMM), and to estimate  the noise  based on variations of the measured signal  from typical output of the known underlying system .","Tracking dynamic systems with a continuum of states in an analytical manner becomes difficult when conditional densities of the combined signal  are mixtures of many component densities. Unfortunately, this is the case in most real-world systems where speech is subject to both stationary noise, and dynamic or non-stationary noise, e.g., background conversation, music, environmental acoustics, traffic, etc. This analytical intractability is primarily due to two conditions.","First, the complexity of the estimated distribution for the state of the system, as measured by the number of parameters in the system, increases exponentially over time. In addition, when the relationship between the measured output and the true output of the system is non-linear, the estimated state distributions may not have a closed form. Both of these problems are encountered in continuous-state dynamic systems used to estimate time series data.","The present invention tracks noise in an acoustic signal as a sequence of states of a dynamic system with a continuum of states. The dynamic system according to the invention is represented in a closed form. Acoustic samples generated by the system are assumed to be related to the states by a functional relation. The relationship models speech as a corrupting influence on noise. This is in contrast with the prior art, where the noise is always considered as a corruption of the underlying speech signal.","The complexity of the estimated distribution of the state of the system is reduced by sampling the predicted distribution of the state at time steps, locally discretizing the samples in a dynamic manner and propagating the thus simplified distributions in time. The non-linearity of the relation between the true and measured outputs of the system is tackled by locally linearizing the relationship around each sample of the states.","Thus, by sampling the system iteratively, an estimate of the noise can be obtained, and the noise can then be removed from the signal to provide results that improve upon prior art stationary noise models.","In stark contrast with prior art vector Taylor system (VTS) approaches, the invention assumes that it is the speech signal that corrupts the noise. The measurements of the speech-corrupted noise are non-linearly related to both the hypothetical measurements of the noise that would have been made, had there been no corrupting speech, and the corresponding measurements of the corrupting speech in the absence of noise. Note that this is totally different from the statement that the noise and the corrupting speech are non-linearly combined.","Based on this model, the invention estimates the noise from its \u201cspeech-corrupted\u201d measurements. After the noise has been estimated, it can be removed from the input signal, using known methods, to recover the speech signal.","In one embodiment of the invention, the dynamic system is a continuous-state dynamic system, which uses linear Markovian dynamics. These represent a first order fit to any underlying dynamic system, however complex, and capture most of the salient features of the underlying system. Also, first-order parameters are fewer and can be learned robustly from a small amount of training data. In another embodiment, the system can use non-linear dynamics.","This is of immense practical value in most situations encountered in speech recognition, wherein the system must compensate for noise.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 2","b":["200","200","210","211","211"]},"The primary signal  is subject  to a corrupting and additive secondary signal , specifically, a dynamic signal, such as human speech, to produce a combined signal . The problem is to recover the secondary signal  from the combined signal .","Therefore, according to the invention, the combined signal  is measured to obtain samples . An estimate  of the generic noise  is determined  based on a understanding or model of the dynamic system  that generated the primary signal . The estimated noise  is then removed from the samples , using known methods, to recover the secondary signal .","Our invention describes the dynamic system  by two equations. A state equation specifies state dynamics  of the system, and an observation equation relates an underlying state of the system to the measurements, i.e., samples  of the combined signal . When the state dynamics of the system are assumed to be Markovian, the state equation can be represented as\n\n=\u0192(, \u03b5) \u2003\u2003(1)\n","where the state sat time t is a function of the state at time t\u22121, and a driving term \u03b5, e.g., a Gaussian excitation process. The output of the system at any time is usually assumed to be dependent only on the state of the system at that time.","The observation equation can be represented as\n\n(, \u03b3) \u2003\u2003(2)\n","where ois the observation at time t and \u03b3represents the noise affecting the system at time t.","In many cases, the best set of state and observation equations required to model the system  accurately can be quite complex, making the estimation of the state from the observations  intractable. In addition, the estimation of the parameters of the system can be very difficult from a finite amount of data. For these reasons, it is often advantageous to approximate the dynamics with a simple first-order system.","In keeping with this argument, we model the dynamics of the system  whose states are log-spectral vectors of noise expressed as\n\n+\u03b5\u2003\u2003(3)\n","where nrepresents the noise log-spectral vector at time t, A represents a parameter of an auto-regressive model (AR), and \u03b5represents the Gaussian excitation process. The AR model is of order one and assumes that the sequence of noise log-spectral vectors can be modeled as the output of a first-order AR system excited by a zero mean Gaussian process. The AR parameter A and the variance \u03c6 of \u03b5can all be learned from a small number of representative noise samples. The mean of \u03b5is assumed to be zero.","The log-spectral vectors of noisy samples y are related to the state of the dynamic system by n and the log-spectra of the corrupting speech  by\n\n=\u0192()=+log(1+exp ())=()\u2003\u2003(4)\n","Equations (3) and (4) represent the state and observation equations of the system  respectively.","Having thus represented the dynamic system , we next need to determine the state of the dynamic system, namely the noise , given only the sequence of samples , the parameters of the state equation A and \u03c6hd \u03b5, and the distribution of x.","We model the distribution of xby a mixture Gaussian density of the form",{"@attributes":{"id":"p-0039","num":"0038"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["x","t"]}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","mrow":{"msub":{"mi":["c","k"]},"mo":"\u2062","mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":[{"mi":["x","t"]},{"mi":["\u03bc","k"]}],"mo":";"},"mo":",","msub":{"mi":["\u03c3","k"]}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"5"}}]}}}}},"where c, \u03bcand \u03c3represent the mixture weight, mean and variance respectively of the Gaussian mixture, and the function N( ) represents the Gaussian.","The sequence of observations, e.g. the samples  y, . . . , yas y. The a posteriori probability distribution of the state of the system at time t, given the sequence of observations y is obtained through the following recursion:",{"@attributes":{"id":"p-0042","num":"0041"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":["(",")"],"mrow":{"msub":[{"mi":["n","t"]},{"mi":"y","mrow":{"mn":"0","mo":",","mrow":{"mi":"t","mo":"-","mn":"1"}}}],"mo":"\u2758"}},{"msubsup":{"mo":"\u222b","mrow":{"mo":"-","mi":"\u221e"},"mi":"\u221e"},"mo":"\u2062","mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["n","t"]},{"mi":"n","mrow":{"mi":"t","mo":"-","mn":"1"}}],"mo":"\u2758"}}},{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":"n","mrow":{"mi":"t","mo":"-","mn":"1"}},{"mi":"y","mrow":{"mn":"0","mo":",","mrow":{"mi":"t","mo":"-","mn":"1"}}}],"mo":"\u2758"}}},{"mo":"\u2146","msub":{"mi":"n","mrow":{"mi":"t","mo":"-","mn":"1"}}}],"mo":["\u2062","\u2062"]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}},"br":{},"in-line-formulae":[{},{}],"i":["P","n","|y","CP","n","|y","P","y","|n"],"sub":["t","0,t","t","0,t\u22121","t","t"]},"where C is a normalizing constant.","Equation 6 is referred to as a prediction equation and equation 7 as an update equation. P(n|y)) is the predicted distribution for nand P(n|y) is the updated distribution for n. When the dynamic system is linear, equation 6 is readily solvable. When the dynamic system is non-linear, equation 6 can be solved by first linearizing the first term (P(n|n)) of the integral in equation 6.","The problem is to estimate the updated distribution. We refer to recursions of Equation 6 and Equation 7 as the Kalman recursion.","From Equation 3, because \u03b5has a Gaussian distribution, the conditional density of ngiven nis\n\n()=(, \u03c6)\u2003\u2003(8)\n","The speech vector at any time t may have been generated by any of the K Gaussians in the Gaussian mixture distribution in Equation 5, with a probability c, and therefore",{"@attributes":{"id":"p-0048","num":"0047"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":["(",")"],"mrow":{"msub":[{"mi":["y","t"]},{"mi":["n","t"]}],"mo":"\u2758"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","mrow":{"msub":{"mi":["c","k"]},"mo":"\u2062","mrow":{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["y","t"]},"mo":"\u2758","mrow":{"msub":{"mi":"n","msup":{"mi":"t","mo":"*"}},"mo":"\u2062","mi":"k"}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}}}}},"where P(y,|n,k) is the probability of y, conditioned on n, and given that the speech vector was generated by the kGaussian in the mixture.","It can be shown that",{"@attributes":{"id":"p-0051","num":"0050"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"P","mo":["(",")"],"mrow":{"mrow":{"msub":[{"mi":["y","t"]},{"mi":["n","t"]}],"mo":"\u2758"},"mo":",","mi":"k"}},"mo":"=","mfrac":{"mrow":[{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mrow":{"msup":{"mi":"f","mrow":{"mo":"-","mn":"1"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["y","t"]},{"mi":["n","t"]}],"mo":","}}},"mo":";","msub":{"mi":["\u03bc","k"]}},"mo":",","msub":{"mi":["\u03c3","k"]}}}},{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"mo":"\u2146","msub":{"mi":["y","t"]}},{"mo":"\u2146","msub":{"mi":["x","t"]}}]}}]}}},{"mrow":{"mo":["(",")"],"mn":"10"}}]}}}}},"where \u0192is the inverse function that derives yas a function of x, and n, and the Jacobian determinant of yin the denominator is the determinant of the derivative of ywith respect to x.","Both \u0192and the Jacobian are highly non-linear functions, as a result of which P(y,|n,k) has a form that leads to complicated solutions. In order to avoid this complication, we approximate Equation 4 by a truncated Taylor series, expanded around the mean of the kGaussian:\n\n()=(\u03bc)+\u2032(\u03bc)(\u2212\u03bc)+\u2003\u2003(11)\n","Higher order terms are not shown in the Equation 11. We truncate","this series after the first term, to obtain\n\n()\u2248(\u03bc)\u2003\u2003(12)\n","which can be used to derive P(y,|n,k) as\n\n()=(;\u03bc(\u03bc), \u03c3)=(;\u0192(\u03bc), \u03c3)\u2003\u2003(13)\n","We could truncate the series expansion in Equation 11 after the first order term, and P(y,|n,k) would still be Gaussian. However, inclusion of higher order terms in the approximation will result in more complicated distributions for P(y,|n,k).","It is important to note that the approximation in Equation 12 is specific to the kGaussian. Combining Equation 13 with Equation 9, we get the approximation of P(y,|n,)",{"@attributes":{"id":"p-0059","num":"0058"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":["(",")"],"mrow":{"msub":[{"mi":["y","t"]},{"mi":["n","t"]}],"mo":"\u2758"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"k","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","mrow":{"msub":{"mi":["c","k"]},"mo":"\u2062","mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":{"mi":["y","t"]},"mo":";","mrow":{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["\u03bc","k"]},{"mi":["n","t"]}],"mo":","}}}},"mo":",","msub":{"mi":["\u03c3","k"]}}}}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"14"}}]}}}}},"The Kalman recursion mentioned above is initialized using the a priori distribution of the noise\n\n()=()\u2003\u2003(15)\n","While it is now possible to now run the Kalman recursion by direct computations of Equations 6 and 7, this results in an exponential increase in the complexity of the updated distribution for the vectors nwith increasing time t, as shown in . In general, the estimated distribution of the vectors nare a mixture of KGaussians with continuous densities as shown in .","The problem could be simplified by collapsing the Gaussian mixture distribution for P(y,|y) into a single Gaussian at every step. However this leads to unsatisfactory solutions and poor tracking of the noise.","Instead, as shown in , we use sampling methods to reduce the problem. The complexity of the a posteriori noise distribution is reduced by discretizing the predicted noise density at each time step. The predicted noise density is sampled to generate a number of noise samples. The continuous density is then represented by a uniform discrete distribution over these generated samples",{"@attributes":{"id":"p-0064","num":"0063"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":["(",")"],"mrow":{"msub":[{"mi":["n","t"]},{"mi":"y","mrow":{"mn":"0","mo":",","mrow":{"mi":"t","mo":"-","mn":"1"}}}],"mo":"\u2758"}},{"mfrac":{"mn":"1","mi":"N"},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mi":"\u03b4","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["n","t"]},"mo":"-","msup":{"mi":["n","k"]}}}}}}],"mo":"\u2248"}},{"mrow":{"mo":["(",")"],"mn":"16"}}]}}}}},"where nis the knoise sample generated from the continuous density, and N is the total number of samples generated from it. Thereafter, the update equation simply becomes",{"@attributes":{"id":"p-0066","num":"0065"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":["(",")"],"mrow":{"msub":[{"mi":["n","t"]},{"mi":"y","mrow":{"mn":"0","mo":",","mi":"t"}}],"mo":"\u2758"}},{"mi":"C","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"P","mo":["(",")"],"mrow":{"msub":{"mi":["y","t"]},"mo":"\u2758","msup":{"mi":["n","k"]}}},{"mi":"\u03b4","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["n","t"]},"mo":"-","msup":{"mi":["n","k"]}}}}],"mo":"\u2062"}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"17"}}]}}}}},"where C is a normalizing constant that ensures that the total probability sums to 1.0. P(y,|n) is computed using Equation 14. The prediction equation for time t+1 becomes:",{"@attributes":{"id":"p-0068","num":"0067"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":["(",")"],"mrow":{"msub":[{"mi":"n","mrow":{"mi":"t","mo":"+","mn":"1"}},{"mi":"y","mrow":{"mn":"0","mo":",","mi":"t"}}],"mo":"\u2758"}},{"mi":"C","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"P","mo":["(",")"],"mrow":{"msub":{"mi":["y","t"]},"mo":"\u2758","msup":{"mi":["n","k"]}}},{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":"n","mrow":{"mi":"t","mo":"+","mn":"1"}},"mo":"\u2758","msup":{"mi":["n","k"]}}}}],"mo":"\u2062"}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"18"}}]}}}}},"This is a mixture N of distributions of the form P(n|n). This is once again sampled to approximate it as in Equation 16. The overall process is summarized in the five steps shown in .","The noise estimation  process described above estimates, for each frame of incoming combined signal , a discrete a posteriori distribution of the form",{"@attributes":{"id":"p-0071","num":"0070"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"P","mo":["(",")"],"mrow":{"msub":[{"mi":["n","t"]},{"mi":"y","mrow":{"mn":"0","mo":",","mi":"t"}}],"mo":"\u2758"}},{"mi":"C","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"P","mo":["(",")"],"mrow":{"msub":{"mi":["y","t"]},"mo":"\u2758","msup":{"mi":["n","k"]}}},{"mi":"\u03b4","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["n","t"]},"mo":"-","msup":{"mi":["n","k"]}}}}],"mo":"\u2062"}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"19"}}]}}}}},"For any estimate of the noise, n, we estimate x, which is the log spectrum of the speech signal , from the log spectrum of the observed noisy speech signal , using an approximated minimum mean squared estimation (MMSE) procedures:",{"@attributes":{"id":"p-0073","num":"0072"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msubsup":{"mover":{"mi":"x","mo":"^"},"mi":["t","k"]},"mo":"=","mrow":{"msub":{"mi":["y","t"]},"mo":"-","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","mrow":{"mrow":[{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"j","mo":"\u2758","msub":{"mi":["y","t"]}},"mo":",","msup":{"mi":["n","k"]}}}},{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03bc","j"]},"mo":",","msup":{"mi":["n","k"]}}}}],"mo":"\u2062"}}}}},{"mrow":{"mo":["(",")"],"mn":"20"}}]}}}}},"where p(j|y, n) is given by",{"@attributes":{"id":"p-0075","num":"0074"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"j","mo":"\u2758","msub":{"mi":["y","t"]}},"mo":",","msup":{"mi":["n","k"]}}}},"mo":"=","mfrac":{"mrow":[{"msub":{"mi":["c","j"]},"mo":"\u2062","mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":{"mi":["y","t"]},"mo":";","mrow":{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03bc","j"]},"mo":",","msup":{"mi":["n","k"]}}}}},"mo":",","msub":{"mi":["\u03c3","j"]}}}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","mrow":{"msub":{"mi":["c","i"]},"mo":"\u2062","mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"msub":{"mi":["y","t"]},"mo":";","mrow":{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03bc","i"]},"mo":",","msup":{"mi":["n","k"]}}}}},"mo":",","msub":{"mi":["\u03c3","i"]}}}}}}]}}},{"mrow":{"mo":["(",")"],"mn":"21"}}]}}}}},"Combining Equations (19) and (20), we get the overall estimate for xas",{"@attributes":{"id":"p-0077","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mover":{"mi":"x","mo":"^"},"mi":"t"},"mo":"=","mrow":{"msub":{"mi":["y","t"]},"mo":"-","mrow":{"mi":"C","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":"k","mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}]},"mo":"\u2062","mrow":{"mrow":[{"mi":"P","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["y","t"]},"mo":"\u2758","msup":{"mi":["n","k"]}}}},{"munderover":{"mo":"\u2211","mrow":{"mi":"j","mo":"=","mn":"1"},"mi":"K"},"mo":"\u2062","mrow":{"mrow":[{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":"j","mo":"\u2758","msub":{"mi":["y","t"]}},"mo":",","msup":{"mi":["n","k"]}}}},{"mi":"f","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03bc","j"]},"mo":",","msup":{"mi":["n","k"]}}}}],"mo":"\u2062"}}],"mo":"\u2062"}}}}}},{"mrow":{"mo":["(",")"],"mn":"22"}}]}}}}},{"@attributes":{"id":"p-0078","num":"0077"},"figref":"FIG. 6","b":["601","602","603","604","611","612","613"]},"It can be seen that all methods are effective at improving recognition performance at low SNRs. At low SNRs, it is advantageous to eliminate even an average (stationary) characteristic of the noise, regardless of the non-stationary nature of the noise.","However, at higher SNRs, the prior art VTS method begins to falter, because the noises are non-stationary. At these SNRs, recognition performance with VTS-compensated speech is actually poorer than that obtained with the base line uncompensated noisy speech.","In contrast the method according to the invention is able to cope with the non-stationarity of the noise at all SNRs, and performs consistently better than the prior art VTS method. Even at SNRs higher than 20 dB, where the speech is essentially \u201cclean,\u201d the invented method does not degrade performance to a perceptible degree.","The invention results in more reduction in the level of the noise in the final estimate of the speech signal as compared to the prior-art VTS method. The invention improves the noise level effectively by a factor of between 2 and 3, i.e., up to 5 dB, as compared with the prior art VTS method.","The method and system according to the invention uses more information about the noise signal than prior art models. Those generally assume that the noise is stationary. However, the amount of explicit information required about the noise is small, due to the simple first order model assumed for the dynamics.","Even this small amount of information enables the invention to track the noise well. In the examples used to described the invention, the type of noise corrupting the speech signal was assumed to be known. However, in a more generic case, this may not be known. In such applications, one solution has several different dynamic systems trained on a variety of noise types.","The most appropriate model for the noise type affecting the signal can then be identified using system or model identification methods where the speech log-spectra are modeled as the output of an IID process. They can also be modeled by an HMM, without any significant modification of the process. As an extension to the invention, we can treat the systems generating the speech and the noise as coupled dynamic systems, and the entire process can be appropriately modified to simultaneously track both speech and noise.","The dynamic system modeling the noise can itself also be extended. For example, above, the AR order for the dynamic system is assumed to be one. This can easily be extended to higher orders. Additionally, the dynamic system can be made non-linear without major modifications to invention.","It should also be noted that the invention can operate as a single pass on-line process, as opposed to the prior art off-line processes, such as VTS, that require multiple passes over the noisy data. Furthermore, being on-line, the method can be performed in real-time.","The invention estimates the noise at each instant of time without reference to future data enabling for the compensation of data as they are encountered. Furthermore, it should be understand that the invention can be used for any time series signal subject to noise.","Although the invention has been described by way of examples of preferred embodiments, it is to be understood that various other adaptations and modifications may be made within the spirit and scope of the invention. Therefore, it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
