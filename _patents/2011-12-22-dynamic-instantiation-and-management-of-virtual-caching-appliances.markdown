---
title: Dynamic instantiation and management of virtual caching appliances
abstract: It is detected that a metric associated with a first workload has breached a first threshold. It is determined that the first workload and a second workload access the same storage resources, wherein the storage resources are associated with a storage server. It is determined that the metric is impacted by the first workload and the second workload accessing the same storage resources. In response to a determination that the metric is impacted by the first workload and the second workload accessing the same storage resources, a first virtual cache appliance is instantiated and one of the first workload or the second workload is routed through the virtual cache appliance. Routing one of the first workload or the second workload through the first virtual cache appliance causes the first virtual cache appliance to cache data associated with the storage resources.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09274838&OS=09274838&RS=09274838
owner: NetApp, Inc.
number: 09274838
owner_city: Sunnyvale
owner_country: US
publication_date: 20111222
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD","COPYRIGHT NOTICE\/PERMISSION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["Embodiments described are related generally to management of networked storage, and embodiments described are more particularly related to managing a multi-tiered caching system in a virtualized environment.","Portions of the disclosure of this patent document can contain material that is subject to copyright protection. The copyright owner has no objection to the reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records, but otherwise reserves all copyright rights whatsoever. The copyright notice applies to all data as described below, and in the accompanying drawings hereto, as well as to any software described below: Copyright\u00a9 2011, NetApp, Inc., All Rights Reserved.","Data for companies or other organizations is commonly stored in networked storage. The networked storage and its associated compute resources can be referred as a data center. The resources of a data center such as storage and access bandwidth are limited. Thus, a common goal for a data center is to improve utilization of the resources of the networked storage, to improve storage utilization and access throughput. Data access to storage is typically slow relative to computer processing speeds. There may be applications within the company or organization that generate large workloads, making many access requests to the data center. Additionally, the number of workloads and the number of requests for each workload can vary significantly over time. Frequently there are levels of services that are either guaranteed or at least expected for workloads accessing the networked storage.","Workloads accessing data from networked storage often have performance requirements for such access; commonly referred to as service level objectives (SLOs). There is an apparent conflict in a system that has dynamic behavior between providing high resource utilization and meeting service level requirements. If an administrator allocates enough resources to guarantee the needs of service level requirements, the allocation of resources generally results in low resource utilization when workload requests are low. If an administrator allocates fewer resources to try to achieve higher resource utilization, the system may frequently violate service level objectives for the workloads. Furthermore, configuring resource allocation to be dynamic based on historical resource utilization only allows dynamism for general trends of work, and does not address specific workload requests. Such a dynamic system would still be unable to respond to dynamic shifts in workloads, especially if those shifts are outside expected historical trends.","A service level objective (SLO) violation is detected for a workload of a networked storage system, based on a performance metric not being satisfied for the workload. In response to detecting the SLO violation, a controller determines that changing a level of caching at a node of the networked storage system will improve the performance metric for the workload. The controller implements the change by adjusting an operation of a virtual cache appliance (VCA) of the networked storage system. The adjusting can be instantiating a new VCA, or adjusting the level of caching at an existing VCA. The adjusting can be for caching related to the workload itself, or it can be caching for an interfering workload.","Descriptions of certain details and embodiments follow, including a description of the figures, which can depict some or all of the embodiments described below, as well as discussing other potential embodiments or implementations of the inventive concepts presented herein.","As described herein, a networked storage system includes a storage server and at least one compute server. At least one compute server supports a dynamically resizable virtual cache appliance (VCA). The storage system includes VCA management components (collectively, a VCA controller) that monitor, analyze, and execute VCA adjustments to dynamically respond to service level objective (SLO) requirements of the storage system. In one embodiment, the VCA management components can be implemented on a single hardware and\/or virtual device of the storage system. In another embodiment, the VCA management components are distributed in the storage system over multiple hardware devices and\/or virtual devices of the storage system.","The VCA management monitors performance with respect to workloads in the storage system by monitoring one or more performance metrics for each workload. If a performance metric is not being satisfied for a workload, the VCA management determines an SLO violation has occurred. In response to the detected SLO violation, the VCA management performs computations related to determining if caching changes will improve the performance metric, and thus improve or cure the SLO violation. When the VCA management determines that changing caching in the storage system will improve the performance metric, the VCA management adjusts an operation of VCA. The adjusting can be instantiating a new VCA, or adjusting the level of caching at an existing VCA. The adjusting can be for caching related to the workload itself, or it can be caching for an interfering workload. Additionally, when monitoring mechanisms detect that a VCA is no longer needed, adjusting an operation of a VCA can include removing the VGA, or adjusting the level of caching at the VCA. The storage system thus monitors workload performance and resource utilization, and dynamically adjusts operation based on the monitoring; thus, the storage system dynamically responds to changes in workload.",{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 1","b":["100","110","140","110"]},"System  illustrates a storage system with dynamically adjustable caching. In one embodiment, system  is a multi-tiered cache system, with a hierarchy of cache levels or cache tiers that can communicate with each other. Cache  is a lowest tier or tiers of cache in the cache hierarchy. As used herein, \u201ctier\u201d refers to the separation of the control logic within the multi-tiered cache system. Each tier includes a caching device, which includes storage or memory and a feedback\/sizing controller or logic  to determine how caching is to be performed at the specific tier. It will be understood that alternative terms such as \u201clevel\u201d or \u201clayer\u201d could also be used to refer to the separate tiers.","White different levels of caching are possible, examples of cache tiers include cache  of storage server , and VCA  of compute server . In one embodiment, cache  can be implemented as a storage server SSD (solid state drive) cache tier, referring to an SSD or flash device on storage server , and a storage server buffer cache tier. VCA  could also be separated into multiple tiers. The different cache tiers can be shared across clients and workloads, or dedicated to a specific client or workload.","The storage server connects to VCA  via network . Network  can be any type or combination of local area networks or wide area networks. VCA  is instantiated on hypervisor  that is on compute server . Alternatively, VCA  can be instantiated on another hypervisor (not shown), which is on a compute server that is physically close to compute server . In one embodiment, compute server  hosts hypervisor . A compute server can be physical server with a hypervisor, or a server instance of networked hardware. Physically close refers generally to the idea that a local area network or a local connection is used to connect the devices, rather than connecting over a wide area network. As used herein, instantiation refers to creating an instance or a copy of a source object or source code. The source code can be a class, model, or template, and the instance is a copy that includes at least some overlap of a set of attributes, which can have different configuration or settings than the source. Additionally, modification of an instance can occur independent of modification of the source.","VCA  is typically populated as compute server  reads data from the source storage server . On the first read of any data, the cache fetches data from storage server , stores it in VCA  and forwards it to client . As the reads pass through VCA , the cache fills up. Any subsequent access of the data that is stored in VCA  can be immediately served from the dynamic cache, which reduces the roundtrip time or the latency. In one embodiment, VCA  acts like a write-through cache, where all writes from compute server  are passed directly to storage server . Only when storage server  responds to a write request, VCA  acknowledges the result to compute server  or other cache tiers\u2014e.g., RAM (buffer cache) and SSD or flash. Similarly to VCA , cache device  within storage server  caches data to serve to VCA , avoiding access to storage resources for data that is cached within storage server .","Storage server  further includes cache sizing controller , which represents the control logic of storage server  related to determining when a workload characteristic change occurs, or when the working set size has changed, whether there is overlap or interference between working sets of two workloads, and when to propagate these changes to cache sizing controller  of VCA . Working set refers to a set of data being cached due to an application accessing the data. Working set size is the amount of unique data (e.g., unique block addresses) accessed by a client (pr upstream caching tier) in a defined period of time. The time is measured either as wall clock time (e.g., a number of seconds or minutes), or as an amount of total (unique and repeat) data access. Controllers  and  can determine how to adjust cache size based on indications from the other controller. Controller  can be implemented as part of other control logic of the storage server, or it can be implemented as separate control logic (whether virtually (e.g., code), or physically (e.g., hardware) separate).","In one embodiment, controller  is implemented outside the virtual machine (VM) that contains VCA . For example, controller  could be a separate virtual entity of hypervisor . It will be understood that a virtual machine refers to a software environment instance (or virtual environment) that executes on hardware resources shared with other virtual environments. The allocation of hardware resources to virtual environments is typically performed by a virtual machine manager or hypervisor, which maps resource requests from the virtual environments to physical hardware resources.","As illustrated, in one embodiment, storage server  includes VCA controller , compute server  includes VCA controller , and compute server  includes VCA controller . The various controllers , , and  can all be different controllers, or simply different components of the same controller. Typically, system  will only have a single controller, whether implemented at a single location of system , or whether distributed. Similarly to controllers  and , controllers , , and  can each be implemented as part of another controller, or as separate components. They can also be implemented within a VM that interfaces to a client, or outside any VM that receives client requests. In one embodiment, the cache sizing controller and the VCA controller of a particular compute server are part of a single controller. For example, cache sizing controller  can be part of VCA controller . In one embodiment, the VCA controller is a virtual machine executing on a hypervisor. Thus, for example, VCA controller  can be part of hypervisor  or reside on hypervisor .","System  includes at least one monitoring component or monitoring infrastructure that collects statistics related to SLO performance. There can be a single monitor component to collect statistics for all workloads in system . In one embodiment, each compute server of system  collects statistics for its workloads. In one embodiment, system  includes multiple monitoring components, which monitor multiple workloads, but not necessarily those of a particular compute server. The monitoring infrastructure can be implemented, for example, as a monitor daemon that collects statistics related to workload characteristics (e.g., read-write ratio, random-sequential ratio, I\/O size, working set size, heavily accessed block ranges), resource utilization within the storage server and the VCA (e.g., CPU usage, disk or SSD traffic, cache hit rate, number of cache pages touched, or other utilization indicators), or other performance or SLO statistics (e.g., latency, throughput). Monitoring needs visibility into I\/Os in system ; thus, there can be an advantage to placing monitoring functions on storage server , which has access to I\/O from all clients. Alternatively, monitoring activity can be distributed to compute servers that have visibility into I\/O generated by clients located on them. As another alternative, I\/O information can be sent to a compute server or virtual machine that is set up to perform monitoring.","System  includes at least one analysis component that determines what actions to take if an SLO violation is detected. In one embodiment, there is one analysis component located on storage server . In one embodiment, there is one analysis component located on one of the compute servers. In one embodiment, there are multiple analysis components distributed throughout system . In one embodiment, compute server  represents a compute server that is dedicated only to monitoring or analysis or both (a \u201cstorage management server\u201d).","Thus, as illustrated, VGA controller can refer to any or all of the monitoring and\/or analysis functions (the control functions) described above. Any server in system  can include some portion of the VCA control functions. One or more of the servers can be implemented without any portion of the VCA control functions. In one embodiment, monitoring is performed at storage server , while analysis is performed at one or more of compute servers  or .","System  also illustrates different ways that storage server  can experience multiple workloads. Workload  and workload  come to storage server  through a channel other than VCA . More particularly, clients  and  access storage server  over a different network path or via a different host than compute server . Clients  and  can be considered to access storage server  directly and not via a VCA, whereas the access of client  is through VCA . Workload  comes to storage server  via VCA , from client .","The workloads are separate or distinct from each other because the have different sources, or they originate from different applications or different clients. Thus, each set of requests from a different application can be referred to as a distinct workload. The different workloads , , and  could access either the same or different storage object such as a volume on the storage server. Depending on whether the different workloads are accessing the same or different volumes, the storage server experiences a certain resultant workload characteristic at its end.","There are many different possible protocols that could be used by the devices of system  to communicate. In one embodiment, the client can issue packets including file-based access protocols, such as the Common Internet File System (CIFS) protocol or Network File System (NFS) protocol, over the Transmission Control Protocol\/Internet Protocol (TCP\/IP) when accessing information in the form of files and directories. Alternatively, the client can issue packets including block-based access protocols, such as the Small Computer Systems Interface (SCSI) protocol encapsulated over TCP (iSCSI) and SCSI encapsulated over Fibre Channel (FCP), when accessing information in the form of blocks.","VCA controllers , , and  implemented in accordance with any of the single-device or distributed models described above (collectively, the VCA controller of system ), make a determination of whether changing a caching level at a compute server in system  will improve a performance metric associated with a workload's SLO. For example, assume the VCA controller of system  determines that the access latency for reads associated with workload  are below a value indicated in an SLO predefined for workload . In response to such a determination, the VCA controller of system  can determine whether adjusting a caching level within system  will improve the access latency for workload .","It will be understood that a caching adjustment can directly or indirectly affect the SLO performance of a workload. For example, in one embodiment, the VCA controller of system  determines that adjusting caching in compute server  (through which workload  passes) will improve the access latency of workload . Alternatively, in one embodiment, the VCA controller of system  determines that adjusting caching in compute server , such as instantiating a VCA to buffer workload , will improve the access latency of workload . there may be reasons, for example, to instantiate a new VCA in compute server  (for example, if workload  is also close to the maximum or minimum of an SLO performance metric), rather than increasing a caching capacity at compute server . Alternatively, compute server  may not have additional resources to allocate to increase caching in VCA , and thus, adjusting caching at a different compute server would be the only way to potentially improve the access performance for workload .",{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIG. 2","FIG. 1"],"b":["200","200","100","200","210","220","230","220","222","230","232","234","200","240","220","230","200","260","210","240"]},"VM  and VM  share disks , while VM  accesses a different set of disks . Thus, workload  and workload  access overlapping storage space, while workload  does not. It will be understood that an SLO can be associated with a specific workload, and\/or can be associated with a VM. For purposes of system , assume each VM , , and  have an associated SLO for their respective workloads , , and . Assume that due to a change in workload , system  is not meeting the SLO for VM . System  performs an analysis (e.g., via a VCA controller ) to determine what can be done about the detected SLO violation for VM .","In system , VM , VM , and VM  could all interfere with each other. For example, all of the VMs could interfere if there is a memory bottleneck on storage server ; while VM  and VM  could interfere due to a disk bottleneck, given that they share the same underlying disks. In one embodiment, VCA controller  determines co-location by using a set of experimental performance samples and applying a statistical approach to determine the correlation between the metrics of different workloads. Assume for the example here that VCA controller  identifies VM  and VM  as interfering workloads. In one embodiment, VCA controller  then identifies the subset of cacheable workloads, which are workloads that can be offloaded using a cache. For example, VCA controller  can be programmed with a set of rules to filter workloads based on best-practices (e.g., for a write-through cache, workloads with a high fraction (>20%) of write I\/Os will not benefit from caching).","Assume that VCA controller  determines workload  is cacheable, but workload  is an uncacheable workload. Thus, VCA controller  identifies workload  as a candidate for caching, but removes workload  from consideration for a caching adjustment. After filtering for cacheable workloads, VCA controller determines an appropriate size for a VCA to offload a sufficient amount of I\/Os to correct the SLO violation. In one embodiment, VCA controller  uses a cache sizing tool that uses historical working set size estimates gathered by storage system  to build a cache miss-ratio curve. The miss-ratio curve indicates the fraction of I\/Os sent to underlying storage system , i.e., cache misses, for various cache sizes. Using the miss-ratio curve, VCA controller  can estimate the performance impact on the SLOs of each workload of system . More particularly, VCA controller  can utilize an SLO impact analyzer to determine the impact of the residual workload, or the workload after instantiation of VCA for the primary workload () as well as the co-located workloads in the underlying storage system. VCA controller  can also estimate the performance expected to be provided by the VCA.","In one embodiment, based on criteria described above, or through other calculations, VCA controller  generates a list of potential caching solutions. In one embodiment, VCA controller  includes a policy or rules related to use of resources, cost constraints, and\/or other criteria, to rank potential caching solutions. VCA controller  can select a highest-ranked potential solution as the solution to execute to cure the SLO violation.","Assume, for example, that VCA controller  determines that VM  obtains a miss-ratio of 50% for a 4 GB cache, 25% for an 8 GB cache, and 20% for a 16 GB cache. If however, VCA controller  determines that sending 50% of traffic from VM  to storage server  will not solve the SLO violation, VCA controller  may discard an option of creating a 4 GB cache. Similarly, if an administrative policy of VCA controller  indicates a preference to reduce resource cost, an option to create an 8 GB cache would be ranked higher than an option to create a 16 GB cache. Thus, in accordance with these examples, VCA controller  determines to create an 8 GB cache, and determines that it should be instantiated on the same compute server as VM  (compute server ).","Thus, VCA controller  can dynamically create VCA  on compute server , such as with the memory on the compute server and\/or with SSD . VCA  is an 8 GB cache to reduce the load on storage server  in accordance with the example. Workload  is re-routed through VCA . Workload  is removed, and workload  represents workload  as routed through VCA , and will be of a reduced load on storage server  as compared to workload . Reducing the load on storage server  enables system  to meet the SLO requirements for .","The scenario described above could illustrate a reactive caching adjustment. In one embodiment, detecting an SLO violation refers to proactively determining that based on historical performance, an SLO violation is imminent. For example, historical data may indicate that a particular workload changes dramatically due to a change to known peak hours. Thus, as described herein, caching adjustment can be performed reactively to actual detected violations, as well as proactively to expected violations.",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 3","FIGS. 1 and 2"],"b":["300","310","320","330","310","320","330","300","300","300"]},"In one embodiment, SLO monitor  includes service levels . Service levels  indicate levels predetermined for a workload, client, or VM associated with a workload. Service levels  are typically represented as values that represent a minimum, maximum, average, or other statistical metric for a particular characteristic of performance for the workload such as latency of data access or throughput for accesses. Statistics  represent runtime monitoring of the characteristics of performance, additional workload characteristics related to performance, and resource utilization statistics, Statistics are generated or gathered by SLO monitor  as a workload generates I\/O. Workload characteristics that can be the subject of an SLO and tracked can include read-write ratio, random-sequential ratio, I\/O size, IOPS (I\/O per second), working set size, heavily accessed block ranges, latency, throughput, or other characteristics related to data access. Resource utilization statistics can include metrics such as CPU utilization, disk or SDD traffic and utilization, cache hit rate, number of unique cache pages accessed, or other utilization statistics related to identifying how useful the current allocation of resources is. SLO monitor  can directly monitor the I\/O of individual workloads, or receive the runtime statistics as monitored by another monitoring service.","In one embodiment, analyzer  includes violation detection , solution creation , and solution selection . Violation detection  enables analyzer  to compare service levels  with statistics  to determine whether an SLO violation occurs. Violation detection  can be a simple detection, comparing a predetermined value to a monitored value, with a violation detected if the monitored value is outside a range of the predetermined value. In one embodiment, violation detection  further includes historical data and timing detection. With historical data and timing detection, violation detection  can preemptively determine that a violation will occur, rather than just reactively detecting a violation. Preemptive determination works better with accurate trend data indicating specific patterns of workload changes.","Solution creation  enables analyzer  to generate multiple potential solution scenarios, similar to what is set forth above in the description of . Namely, analyzer  can first determine all possible choices of action within the storage system, and then filter down to a \u201cbest\u201d choice based on policies and rules predefined by an administrator. Analyzer  generates a list or set of all possible choices based on system capabilities, such as available resources and allowable operations. Analyzer  filters the list down based on rules or policy indicating utility of a solution (e.g., whether or not the solution will have an effect, or enough of an effect) or preference of a solution (e.g., based on cost, resource utilization, or other administrative factors). Analyzer ranks the possible choices against each other to determine what action to take in response to the SLO violation detection.","Solution selection  enables analyzer  to make calculations or computations related to comparing the possible solutions and filtering them. In one embodiment, the filtering process can be considered the selection process. The solution decided upon by solution selection  can be different for different systems, even if the service levels and monitored performance statistics were exactly the same. The selection of a solution is thus controllable by the rules and preferences that can be edited or otherwise programmed into VCA controller  for a system implementation.","Solution execution  enables VCA controller  to implement a solution selected by analyzer . Solution execution  includes caching change , which represents all features and functions associated with instantiating a VCA or changing a level of caching at a VCA. In one embodiment, changing a level of caching can be performed by instantiating a cache of a different size than one currently available, rerouting all workload traffic through the new cache, and closing the original cache. Caching change  includes accessing a hypervisor that hosts a VM in which the VCA is or will be implemented.","Application rerouting  enables solution execution  to redirect traffic for a particular workload through the VCA as an access channel. Cache warm-up  enables solution execution  to load \u201chot\u201d blocks into a newly-created VCA to reduce the time for rerouting. For example, assuming that a VCA is created to reduce an SLO violation related to access latency, it does not make much sense to reroute traffic through a cache that will then cause further access latency by a series of cache misses to load the requested blocks into the cache. Instead, the VCA can be warmed up by monitoring what blocks are frequently used by the workload, and then preemptively loading those into the cache as soon as it is instantiated. Then many of the initial access requests will be cache hits rather than cache misses.","VCA controller  is implemented on hardware resources of one or more of the servers in the networked storage system. Those hardware resources include at least processing components or processing resources and memory or storage resources. Additionally, VCA controller  can utilize network hardware resources to communicate with a compute server in which a VCA be created or changed.",{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 4","b":["402","404","406","402","300","406","406"]},"Monitoring  can include mechanisms for monitoring either SLO violation, or underutilization of allocated caching resources, or both. The performance monitor is to detect utilization of memory resources outside of a target utilization. For an SLO violation, the target utilization is that the SLO be satisfied. For underutilization, the target utilization is that system resource utilization not fall below a threshold. Thus, in one embodiment, monitoring  includes a performance monitor that is an SLO monitor to detect SLO violations. In one embodiment, monitoring  includes a performance monitor to detect underutilization memory resources in the storage system.","In either case, the performance monitor can monitor one or more performance metrics to determine whether utilization is within the target. For underutilization, performance metrics can be monitored for an entire VCA instance, or for multiple instances, and thus across multiple workloads. For SLO violations, the performance metrics are monitored specifically with respect to a particular workload.","Similarly to monitoring , analysis and planning  can include mechanisms for modifying a level of caching to dynamically adjust resource allocation to either cure an SLO violation, or cure underutilization, or both. For SLO violations, the modification is targeted to adjusting performance with respect to a specific workload. For underutilization, the modification is targeted to adjust performance across one or more caching devices (VCAs).","In monitoring , the VCA controller compares performance  against SLOs  for each monitored workload. SLO violation detection  is illustrated as being within monitoring , but could also be placed in analysis and planning . For example, consider the alternative example of  where violation detection  is within analyzer . The VCA controller can utilize both performance metrics and traffic metrics of each workload running on the storage system. In one embodiment, the VCA controller tracks performance numbers such as IOPS, average latency, and I\/O request sizes. In one embodiment, the VCA controller can track additional workload characteristics  such as the read\/write count  (the I\/O request mix), working set size (WSS)  over different periods of time, and frequently accessed blocks .","In one embodiment, the VCA controller can track resource utilization , which includes characteristics relevant to performance. Such characteristics can include CPU utilization, disk or SSD traffic, cache hit rate, and the number of cache or memory pages touched (accessed). Tracking of resource utilization  enables the VCA controller to selectively remove VCAs from the system when resource utilization can be improved by eliminating them.","Whether SLO violation detection  is considered to be part of monitoring  or analysis and planning , detection of a violation triggers the VCA controller to perform an analysis. In one embodiment, the specifically affected workload  for which the VCA controller detected a violation is used to determine what interfering workloads exist in the storage system. Workload interference detection  enables the VCA controller to identify workloads that compete for the same resources on the underlying storage system as affected workload .","The VCA controller identifies candidate workloads  from interference detection . The candidate workloads are workloads that might be offloaded to affect the detected SLO violation. The VCA controller will attempt to offload either affected workload  or a co-located or interfering workload to free up resource utilization in the storage system and correct the SLO violation. In one embodiment, the VCA controller performs a cacheability check to determine if any of the candidate workloads are not good candidates for cache offloading. The VCA controller can use read\/write count  to determine if a ratio of writes is too high for caching to be effective.","The VCA controller ends up with cacheable candidate workloads , which can then be further analyzed to generate possible solutions. In one embodiment, the VCA controller determines what size of cache would be needed with cache sizing . The cache sizing is directly influenced by the working set size, seeing that the cache size should typically be a predefined ratio of the overall working set size to be effective. In one embodiment, impact analyzer  determines from system configuration  (configuration of the storage server) what is the expected effect of different cache size changes.","The potential cache sizes  represent the possible solutions generated by the VCA controller. The VCA controller performs solution selection  to determine what cache size at what compute server will have the desired performance effect. In one embodiment, after determination, the VCA controller selects a workload and cache size  for cache offload. Host selection  represents the VCA controller identifying the host information of the selected workload to offload. In one embodiment, the VCA controller then implements cache instantiation  for the workload and host information identified . Alternatively, the VCA controller can resize a VCA.","In one embodiment, the VCA controller instantiates a cache  by obtaining a virtual machine image, configuring the memory and network settings, applying the appropriate licenses, and issuing a command to the hypervisor of the selected host to start the VCA. In one embodiment, once the VCA has started, the VCA controller reroutes (application rerouting ) the network connections between the workload and the underlying storage system through the VCA. In one embodiment, in parallel to cache instantiation  and application rerouting , the VCA controller executes cache warm-up procedure  to fetch the most-frequently-used data into the cache from frequently accessed blocks .","The VCA controller can repeat the monitoring, analysis and planning, and execution for the same workload, and\/or for other workloads as often as it detects SLO violations. Thus, the monitoring process continues for all workloads. If the cache usage behavior changes for a workload so that hit rates or other performance metrics are not met, the VCA controller can repeat the entire process for the current workload to either expand the memory used by the existing VCA or create anew VCA and reroute the application to use the new VCA.","In one embodiment, the VCA controller can remove a VCA, as mentioned above. In response to determining that resource utilization is tower than a predetermined threshold, the VCA controller can trigger underutilization detection . The predetermined threshold can be a percentage of resource utilization per time period, either on average or based on peaks, or could be a predefined number of cache accesses. The VCA controller can determine the number of cache accesses either on a cache-by-cache basis, or for a group of caches.","The VCA controller identifies a group of candidate caches  that may be underutilized, or that can be closed in response to detecting underutilization (if the controller determines underutilization by a mechanism that is not directly associated with a specific cache). In one embodiment, impact analyzer  determines from system configuration  (configuration of the storage server) what is the expected effect of removing different caches from the system.","The VCA controller performs cache selection  to determine what cache (VCA) removal at what compute server will have the desired performance effect. It will be understood that reference to removing a cache is specific to de-allocating a VCA. In one embodiment, the VCA controller removes a cache  by obtaining a virtual machine image, configuring the memory and network settings, applying the appropriate licenses, and issuing a command to the hypervisor of the selected host to terminate the VCA. In one embodiment, termination of the VCA may cause the VCA controller to need to reroute workloads, similar to what is described above for cache instantiation.",{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 5","b":["500","100","502","300","504","506"]},"The VCA controller determines if an SLO violation occurs, process block , by comparing the expectations of the predefined SLO with the monitored performance. If there is no SLO violation, process block , the VCA controller continues monitoring at process block . If the VCA controller detects an SLO violation, process block , in one embodiment the VCA controller determines if workload interference exists that could affect workload performance, process block .","If there is no workload interference, process block , the VCA controller can determine an SLO violation solution, process block . Such a solution would involve either a caching change for the specific workload, or a change or solution that is outside the scope of what is discussed herein. If the VCA controller detects interfering workloads, process block , in one embodiment the VCA controller identifies cacheable workloads, process block . Cacheable workloads are workloads for which data access performance is expected to increase in response to caching some or part of the workload data.","In one embodiment, the VCA controller calculates an expected effect of a cache size change, process block . If cacheability is first checked, the VCA controller can calculate for the workloads determined to be cacheable. The VCA controller determines an SLO violation solution based on the calculated expected effects and\/or other factors, process block . In one embodiment, the VCA controller checks all determined solutions for viability, process block . For example, a solution may not be viable if it requires resources that are not available in the system.","If the VCA controller does not find a viable solution, process block , the VCA controller can determine an SLO violation solution that does not include changing caching, process block . For a viable solution, process block , the VCA controller identifies a specific caching change, including a host on which the caching change wilt be implemented. The VCA controller implements the selected caching change, process block .",{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 6","b":["100","602","300","604","606"]},"The VCA controller determines if allocated resources are underutilized, process block , by comparing the expectations of the predefined resource allocations with monitored performance. If there is no underutilization, meaning the allocation of resources is proper, process block , the VCA controller continues monitoring at process block . If the VCA controller detects underutilization, process block , in one embodiment the VCA controller identifies candidate VCAs for reduction or removal, process block . In one embodiment, any VCA in the system can be a candidate for removal. In one embodiment, the VCA controller determines underutilization with respect to a specific VCA, or group of VCAs, which would then be the candidates. In one embodiment, only VCAs below a percentage of utilization are candidates.","If there is not at least one candidate, process block , the VCA controller continues to monitor performance metrics, process block . If there is at least one candidate VCA for reduction or removal, process block , the VCA controller calculates an expected effect of the reduction or removal of a cache, process block . The VCA controller determines a solution based on the calculated expected effects, process block . A solution includes specifically identifying a VCA to remove. Alternatively a solution includes specifically identifying a VCA to reduce, and an amount by which to reduce it. The VCA controller implements a change by removing a VCA calculated to be removable from the system, or reducing an amount of caching resources allocated to a VCA, process block . In one embodiment, when the VCA controller removes a VCA from the system, it also redirects one or more workflows from the VCA to be removed to another VCA or other caching mechanism.","In general, SLO-based VCA management as described herein provides a tow-latency, high-impact mechanism to dynamic changes in a system. Data access in a data center is often highly dynamic. As described above, a storage system with a VCA controller that monitors SLO performance can respond quickly to changes in a highly dynamic environment by changing behavior of the caching. Thus, better resource utilization is accomplished. VCAs can be dynamically instantiated, modified, and de-allocated by the VCA controller, which makes better use of hardware resources than having a dedicated hardware resource to perform the caching.","Dynamism in a data center can be the result of either or both of changes in workload needs over time, or changes in number of workloads over time. Changes in workload needs over time can manifest as peak requirements that are significantly different than normal or baseline or average requirements. It is not uncommon for peak requirements to be at least 10 times the normal requirements. Frequently the peaks in requirements occur in a periodic manner. Additionally, individual workloads can be created and removed over time, which is very common in cloud service environments where many virtual machines are created and\/or destroyed every hour.","While it may be possible for smaller network environments to be monitored by human intervention to adjust for SLO violations, as network sizes scale upward, managing workloads via human intervention to handle every SLO violation or resource crunch is prohibitively expensive if not impossible. As alternatives, traditional management approaches typically include low-latency, low-impact techniques such as throttling, or high-latency, high-impact techniques such as data migration. As described herein, management by the VCA controller provides a low-latency, high-impact technique to handle changes in workload requirements, even in large network environments.","Thus, the monitoring and analysis architecture provided by the VCA controller provides a mechanism for meeting service-level objectives of workloads (or their associated applications) while utilizing only the resources needed. The improved resource utilization towers hardware, power, and management costs for customers.","The VCA controller leverages the availability of virtualized, elastic compute resources that can be allocated or discarded based on demand. The instantiation of virtual compute resources on demand shifts the resource requirements from storage server devices to compute nodes coupled to the storage server. Resources on compute servers are typically cheaper than those on storage servers. Further, resources on compute servers can be used more flexibly. For example, DRAM (dynamic random access memory) on compute servers can be used for the compute needs of applications as well as for the caching needs of a storage stack to create a VCA for a workload of an application.","In one embodiment, the VCA uses both memory and disk (or SSDs) to perform caching. In one embodiment, the data in volatile memory is a subset of the data on disk. In one embodiment, the VCA contemplated herein forwards writes to the storage server and locally invalidates the data blocks that are written to. In one embodiment, the VCA supports a read command that causes no data transfer to the client, but causes the data to be read internally. Such a command can be used by the VCA controller to warm up a newly instantiated VCA.",{"@attributes":{"id":"p-0084","num":"0083"},"figref":"FIG. 7","b":["700","710"]},"Origin  includes storage hardware, including storage volume , which can be one or more logical grouping of data storage resources. In one embodiment, origin  is a blade enclosure with storage resources as well as storage server (controller) resources. Storage server  manages the storage resources of origin . Requests related to data stored at origin  are processed through storage server .","Switch  represents one or more network resources to allow remote access to storage server . As illustrated, switch  connects to virtual environments , , and , which are virtualized environments executing on hardware . Hardware  can represent a single instance of hardware resources on which the virtual environments execute, or there could be separate hardware systems for each virtual environment.","Virtual environment  includes VCA  executing on hypervisor , which acts as a cache tier for storage server . Hypervisor , as well as hypervisors  and  of virtual environments  and , respectively, includes a virtual switch (Vswitch) and a virtual environment filesystem (VFS). Other virtual and\/or real environments could also be executed on hardware . The virtual switches provide access via the hypervisor to hardware switching resources used to connect to the physical resources of origin , and the other virtual environments connected to VCA . In one embodiment, hypervisor , , and  are all the same hypervisor, with VCA  and virtual environments  and  being different VMs executing on it. Each OS and App combination shown can be considered a separate VM; these VMs can also be executed on the same hypervisor in an embodiment where hypervisors , , and  are all the same hypervisor. As is understood by those skilled in the art, the applications and operating systems of each virtual environment access the virtual switch of the respective virtual environment as though the switch were actual hardware. The virtualization controller (hypervisor) manages the mapping of virtual resources to hardware resources, for the virtual switches as well as other virtualized physical resources.","In one embodiment, virtual environment  hosts VCA , and virtual environments  and  host access to clients. As illustrated, environments  and  are configured identically, with multiple operating system (OS) instances and application instances connecting to the corresponding hypervisor ( and ). The configurations do not necessarily have to be identical. In one embodiment, each operating system of virtual environments  and  represents a separate virtual machine (VM), and there can be one or more applications executing on each operating system. The applications could each represent one or more clients. The virtual switch of each virtual environment  and  presents an instance representation ( and , respectively) of storage volumes  of origin .","In one embodiment, the applications are multiple individual threads. In one embodiment, each thread is considered a workload, or one thread is considered an application. The applications are dynamic, and can be opened and closed dynamically, as well as dynamically changing what data and how much data they access.","In one embodiment, VCA  is implemented as an instance of an operating system the same or similar to the one executed on storage server . Thus, storage server  executes a storage server OS natively, while the storage server OS executes virtually on hypervisor , hosted remotely from origin . Storage server  is local to storage volumes , while VCA accesses storage volumes  remotely via switch . Storage resources  represent the physical storage resources for virtual environments , , and . In one embodiment, storage resources  could be considered part of hardware .","VCA  includes protocols and associated drivers and network stacks to communicate over the virtual switch of hypervisor . In one embodiment, VCA  includes at least NRV and NFS as supported protocols. In one embodiment, origin  can be a Fabric Attached Storage (FAS), and export storage volumes to VCA  over the NRV protocol. VCA  can then serve the cached volumes to clients of virtual environments  and  over the NFS protocol.","VCA  also includes a filesystem as well as drivers and management resources for storage . A combination of storage  and RAM  of the hypervisor\/host (part of hardware ) act as the caching device for VCA . Because the VCA cache tier is dynamic, space from both DAS  and RAM  of the hypervisor can be carved out to implement the VCA tier as a dynamic resource. In one embodiment, VCA  controls all storage access for all VMs of virtual environments  and . Data accessed from storage volumes  is cached in storage resources , and presented as instances  and  to virtual environments  and , respectively, by the virtual switches of the respective environments. Each VM can store local data in addition to the data of storage volumes .","As mentioned above, VCA  can respond to dynamic behavior of different workloads, which are represented either directly or indirectly by the applications of the VMs of virtual environments  and . The dynamic behavior of the VCA is controlled in one embodiment by a VCA controller (e.g., , , , ). The various elements labeled VCA controller could be portions of a single distributed VCA controller, or VCA controller could be implemented at any one of the locations illustrated. As discussed above, VCA controller monitors workload performance in system , and makes determinations about dynamically changing caching within system . VCA  or another VCA could be instantiated or changed in size. In response to a reduction in workload requirements, a VCA could also be resized smaller or entirely de-allocated.",{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 8","FIG. 7"],"b":["800","730","750","760","850","810","840","840","842","844","842","830","850","850","850"]},"Physical layer  is depicted with various components that can be present in whole or in part, and additional components or subcomponents can also be present. Physical layer  includes one or more processors or processing resources , which execute instructions and can perform various operations as described herein. Processor  can include any type of microprocessor, central processing unit (CPU), processing core (including multi-core devices), or other processing devices.","Memory  represents the main memory for system , and provides temporary storage for code (e.g., software routines or series of instructions, commands, operations, programs, data) to be executed by processor . Memory  can include read-only memory (ROM), flash memory, one or more varieties of random access memory (RAM), or the like, or a combination of such devices.","The various components of physical layer  can be coupled by one or more buses . Bus  is an abstraction that represents any one or more separate physical buses, communication lines, and\/or point-to-point connections, connected by appropriate bridges, adapters, and\/or controllers. Therefore, bus  can include, for example, one or more of a system bus, a Peripheral Component Interconnect (PCI) bus, a HyperTransport or industry standard architecture (ISA) bus, a small computer system interface (SCSI) bus, a universal serial bus (USB), or an Institute of Electrical and Electronics Engineers (IEEE) standard 1394 bus (commonly referred to as \u201cFirewire\u201d).","Physical layer  includes one or more network interfaces (NIC) , which represent hardware and software (e.g., drivers) that enable physical layer  to connect and communicate with remote devices over one or more networks. In one embodiment, physical layer  includes storage resources separated as local to a particular virtual environment, and other shared data (e.g., shared or cached data for a VCA). For example, storage resources  represent the cached data shared among multiple virtual environments, while storage  represents local storage.","Storage  includes resources for implementing a write cache , which is mapped by virtual filesystem  to virtual machine  to store the data written for various clients. Storage  can be separated into multiple virtual disks (VD) - through -M. The virtualization of disks is merely for purposes of storage management and organization, and can be performed in any way known in the art.","Storage  includes storage resources for implementing a virtual cache layer, with resources separated as virtual disks - through -N. Typically N will be an integer much larger than M. Controller  provides physical-tier management of the storage. The options for control or management of storage  vary widely, depending on the desired implementation. For example, controller  can be implemented as a JBOD (Just a Bunch Of Disks controller, a RAID (Redundant Array of Independent\/Inexpensive Disks\/Drives controller, or other controller.","Thus, it will be understood that storage , in addition to being a virtual resource, can be managed with abstraction layers to allow a logical disk organization. In one embodiment, the abstraction convention implemented in system  is the same as the abstraction used by a backend storage server at the data origin (e.g., storage server  of origin  in ), However, the abstraction convention at system  could be different from a backend storage server that is the source of the cached data.","Virtual device layer  represents the virtual device as mapped by hypervisor . In one embodiment, virtual device  includes network interface , CPU , RAM , BIOS (Basic Input\/Output System) , UART (Universal Asynchronous Receiver-Transmitter) , network storage , and local storage . Network interface  enables virtual device  to access other devices across networks via network interface(s) . CPU  represents the processing resources available to virtual machine , which consists of dedicated and\/or shared processing resources .","RAM  represents memory resources allocated to virtual machine , and includes shared and\/or dedicated resources of memory . BIOS  provides resources to initialize the software and virtual systems on the allocated hardware resources. UART  represents direct-connection resources, rather than point-to-point or network connection resources. Network storage  enables virtual machine  to access storage  via virtual filesystem  and controller . Local storage  can provide, for example, persistent write cache  for storing data at system .","Each of the components described at virtual device layer  has a physical complement at physical hardware layer . Hypervisor  maps the resources of virtual device layer  to its complement in physical hardware layer . Virtual device layer  is illustrated as included in virtual machine , but it will be understood that the resources are included virtually. Virtual machine  includes virtual caching appliance (VCA)  (which could also be referred to as a virtual storage adapter), which has access to the resources of virtual device layer  as the available computing resources.","VCA  includes software and drivers that manage and control the virtual resources. VCA  presents the virtual resources to the applications or workloads that execute on virtual machine . In one embodiment, VCA  includes driver , network stack , protocol(s) , OS , RAID , storage controller , network storage driver , and virtual nonvolatile RAM (V-NVRAM) .","Driver  provides driver resources to drive communication via the network interfaces. Network stack  implements one or more communication stacks for protocol(s) . Protocol(s)  include the one or more protocols used by virtual machine  to communicate with networked devices. Operating system  controls the flow of operation virtual machine . RAID  represents any type of storage abstraction used for managing storage, with one of the various versions of RAID being common types. Many abstraction types are possible. Storage controller  can include, for example, a storage stack and storage drivers used to access storage resources. Network storage driver  provides one type of driver for access to storage area networks (SANs), network area storage (NAS), or other networked storage. Virtual nonvolatile RAM  represents drivers for local storage of virtual machine .",{"@attributes":{"id":"p-0107","num":"0106"},"figref":"FIG. 9A","b":["910","910","910","950","950","950","902","930","930","902"]},"Storage of data in storage units  is managed by storage servers  which receive and respond to various read and write requests from clients , directed to data stored in or to be stored in storage units . Storage units  constitute mass storage devices which can include, for example, flash memory, magnetic or optical disks, or tape drives, illustrated as disks  (A, B). Storage devices  can further be organized into arrays (not illustrated) implementing a Redundant Array of Inexpensive Disks\/Devices (RAID) scheme, whereby storage servers  access storage units  using one or more RAID protocols known in the art.","Storage servers  can provide file-level service such as used in a network-attached storage (NAS) environment, block-level service such as used in a storage area network (SAN) environment, a service which is capable of providing both file-level and block-level service, or any other service capable of providing other data access services. Although storage servers  are each illustrated as single units in , a storage server can, in other embodiments, constitute a separate network element or module (an \u201cN-module\u201d) and disk element or module (a \u201cD-module\u201d). In one embodiment, the D-module includes storage access components for servicing client requests. In contrast, the N-module includes functionality that enables client access to storage access components (e.g., the D-module), and the N-module can include protocol components, such as Common Internet File System (CIFS), Network File System (NFS), or an Internet Protocol (IP) module, for facilitating such connectivity. Details of a distributed architecture environment involving D-modules and N-modules are described further below with respect to  and embodiments of a D-module and an N-module are described further below with respect to .","In one embodiment, storage servers  are referred to as network storage subsystems. A network storage subsystem provides networked storage services for a specific application or purpose, and can be implemented with a collection of networked resources provided across multiple storage servers and\/or storage units.","In the embodiment of , one of the storage servers (e.g., storage server A) functions as a primary provider of data storage services to client . Data storage requests from client  are serviced using disks A organized as one or more storage objects. A secondary storage server (e.g., storage server B) takes a standby role in a mirror relationship with the primary storage server, replicating storage objects from the primary storage server to storage Objects organized on disks of the secondary storage server (e.g., disks B). In operation, the secondary storage server does not service requests from client  until data in the primary storage object becomes inaccessible such as in a disaster with the primary storage server, such event considered a failure at the primary storage server. Upon a failure at the primary storage server, requests from client  intended for the primary storage object are serviced using replicated data (i.e. the secondary storage object) at the secondary storage server.","It will be appreciated that in other embodiments, network storage system  can include more than two storage servers. In these cases, protection relationships can be operative between various storage servers in system  such that one or more primary storage objects from storage server A can be replicated to a storage server other than storage server B (not shown in this figure). Secondary storage objects can further implement protection relationships with other storage objects such that the secondary storage objects are replicated, e.g., to tertiary storage objects, to protect against failures with secondary storage objects. Accordingly, the description of a single-tier protection relationship between primary and secondary storage objects of storage servers  should be taken as illustrative only.","In one embodiment, storage servers  include VCA controller components  (A, B). VCA controller components  enable storage servers  to dynamically adjust caching in system  in response to workload changes. In one embodiment, VCA controller components  monitor workload performance for SLO violation and\/or analyze system data to select a solution to correct the SLO violation.",{"@attributes":{"id":"p-0114","num":"0113"},"figref":["FIG. 9B","FIG. 9B"],"b":["920","910","910","910","952","910","940"]},"Nodes  can be operative as multiple functional components that cooperate to provide a distributed architecture of system . To that end, each node  can be organized as a network element or module (N-module A, B), a disk element or module (D-module A, B), and a management element or module (M-host A, B). In one embodiment, each module includes a processor and memory for carrying out respective module operations. For example, N-module  can include functionality that enables node  to connect to client  via network  and can include protocol components such as a media access layer, Internet Protocol (IP) layer, Transport Control Protocol (TCP) layer, User Datagram Protocol (UDP) layer, and other protocols known in the art.","In contrast, D-module  can connect to one or more storage devices  via cluster switching fabric  and can be operative to service access requests on devices . In one embodiment, the D-module  includes storage access components such as a storage abstraction layer supporting multi-protocol data access (e.g., Common Internet File System protocol, the Network File System protocol, and the Hypertext Transfer Protocol), a storage layer implementing storage protocols (e.g., RAID protocol), and a driver layer implementing storage device protocols (e.g., Small Computer Systems Interface protocol) for carrying out operations in support of storage access operations. In the embodiment shown in , a storage abstraction layer (e.g., file system) of the D-module divides the physical storage of devices  into storage objects. Requests received by node  (e.g. via N-module ) can thus include storage object identifiers to indicate a storage object on which to carry out the request.","Also operative in node  is M-host  which provides cluster services for node  by performing operations in support of a distributed storage system image, for instance, across system . M-host  provides cluster services by managing a data structure such as a RDB  (RDB A, RDB B) which contains information used by N-module  to determine which D-module  \u201cowns\u201d (services) each storage object. The various instances of RDB  across respective nodes  can be updated regularly by M-host  using conventional protocols operative between each of the M-hosts (e.g., across network ) to bring them into synchronization with each other. A client request received by N-module  can then be routed to the appropriate D-module  for servicing to provide a distributed storage system image.","In one embodiment, node A includes VCA controller A and node B includes VCA controller B. VCA controllers, as described above, can include monitoring components, analysis components, or both to dynamically adjust caching responsive to detected actual or anticipated SLO violations. In an alternate embodiment, VCA controller A or parts of it can also be implemented within M-host A, N-Module A, or D-Module A. Similarly, VCA controller B or components of it can be implemented within M-host B, N-Module B, or D-Module B.","It will be noted that while  shows an equal number of N- and D-modules constituting a node in the illustrative system, there can be different number of N- and D-modules constituting a node in accordance with various embodiments. For example, there can be a number of N-modules and D-modules of node A that does not reflect a one-to-one correspondence between the N- and D-modules of node B. As such, the description of a node comprising one N-module and one D-module for each node should be taken as illustrative only.",{"@attributes":{"id":"p-0120","num":"0119"},"figref":["FIG. 10","FIG. 9A"],"b":["910","910","1000","1002","1010","1020","1012","1040","1050"]},"Memory  includes storage locations addressable by processor , network adapter  and storage adapter  for storing processor-executable instructions and data structures associated with a multi-tiered cache with a virtual storage appliance. A storage operating system , portions of which are typically resident in memory  and executed by processor , functionally organizes the storage server by invoking operations in support of the storage services provided by the storage server. It will be apparent to those skilled in the art that other processing means can be used for executing instructions and other memory means, including various computer readable media, can be used for storing program instructions pertaining to the inventive techniques described herein. It will also be apparent that some or all of the functionality of the processor  and executable software can be implemented by hardware, such as integrated currents configured as programmable logic arrays, ASICs, and the like.","Network adapter  comprises one or more ports to couple the storage server to one or more clients over point-to-point links or a network. Thus, network adapter  includes the mechanical, electrical and signaling circuitry needed to couple the storage server to one or more client over a network. Each client can communicate with the storage server over the network by exchanging discrete frames or packets of data according to pre-defined protocols, such as TCP\/IP.","Storage adapter  includes a plurality of ports having input\/output (I\/O) interface circuitry to couple the storage devices (e.g., disks) to bus  over an I\/O interconnect arrangement, such as a conventional high-performance, FC or SAS link topology. Storage adapter  typically includes a device controller (not illustrated) comprising a processor and a memory for controlling the overall operation of the storage units in accordance with read and write commands received from storage operating system . As used herein, data written by a device controller in response to a write command is referred to as \u201cwrite data,\u201d whereas data read by device controller responsive to a read command is referred to as \u201cread data.\u201d","User console  enables an administrator to interface with the storage server to invoke operations and provide inputs to the storage server using a command line interface (CLI) or a graphical user interface (GUI). In one embodiment, user console  is implemented using a monitor and keyboard.","In one embodiment, computing device  includes VCA controller . While shown as a separate component, in one embodiment, VCA controller  is part of OS . VCA controller enables computer  to generate runtime performance data related to workloads, and\/or use such runtime data to determine how to adjust dynamically adjustable caching appliances in a storage system. In one embodiment, VCA controller  compares runtime data to predefined service level objectives to determine if sufficient resources are being allocated to a workload. If the resource allocation is improper as indicated by a violation of the SLO, VCA controller  can implement a caching change through a VCA to correct the violation.","When implemented as anode of a cluster, such as cluster  of , the storage server further includes a cluster access adapter  (shown in phantom) having one or more ports to couple the node to other nodes in a cluster. In one embodiment, Ethernet is used as the clustering protocol and interconnect media, although it will apparent to one of skill in the art that other types of protocols and interconnects can by utilized within the cluster architecture.",{"@attributes":{"id":"p-0127","num":"0126"},"figref":["FIG. 11","FIG. 10","FIG. 10"],"b":["1100","1014","1002","1125"]},"Multi-protocol engine  includes a media access layer  of network drivers (e.g., gigabit Ethernet drivers) that interface with network protocol layers, such as the IP layer  and its supporting transport mechanisms, the TCP layer  and the User Datagram Protocol (UDP) layer , A file system protocol layer provides multi-protocol file access and, to that end, includes support for the Direct Access File System (DAFS) protocol , the NFS protocol , the CIFS protocol  and the Hypertext Transfer Protocol (HTTP) protocol . A VI layer  implements the VI architecture to provide direct access transport (DAT) capabilities, such as RDMA, as required by the DAFS protocol . An iSCSI driver layer  provides block protocol access over the TCP\/IP network protocol layers, while a FC driver layer  receives and transmits block access requests and responses to and from the storage server. In certain cases, a Fibre Channel over Ethernet (FCoE) layer (not shown can also be operative in multi-protocol engine  to receive and transmit requests and responses to and from the storage server. The FC and iSCSI drivers provide respective FC- and iSCSI-specific access control to the blocks and, thus, manage exports of luns to either iSCSI or FCP or, alternatively, to both iSCSI and FCP when accessing blocks on the storage server.","The storage operating system also includes a series of software layers organized to form a storage server  that provides data paths for accessing information stored on storage devices. Information can include data received from a client, in addition to data accessed by the storage operating system in support of storage server operations such as program application data or other system data. Preferably, client data can be organized as one or more logical storage objects (e.g., volumes) that comprise a collection of storage devices cooperating to define an overall logical arrangement. In one embodiment, the logical arrangement can involve logical volume block number (vbn) spaces, wherein each volume is associated with a unique vbn.","File system  implements a virtualization system of the storage operating system through the interaction with one or more virtualization modules (illustrated as a SCSI target module ). SCSI target module  is generally disposed between drivers ,  and file system  to provide a translation layer between the block (lun) space and the file system space, where luns are represented as blocks. In one embodiment, file system  implements a WAFL (write anywhere file layout) file system having an on-disk format representation that is block-based using, e.g., 4 kilobyte (KB) blocks and using a data structure such as index nodes (\u201cinodes\u201d) to identify files and file attributes (such as creation time, access permissions, size and block location). File system  uses files to store metadata describing the layout of its file system, including an inode file, which directly or indirectly references (points to) the underlying data blocks of a file.","Operationally, a request from a client is forwarded as a packet over the network and onto the storage server where it is received at a network adapter. A network driver such as layer  or layer  processes the packet and, if appropriate, passes it on to a network protocol and file access layer for additional processing prior to forwarding to file system . There, file system  generates operations to load (retrieve) the requested data from the disks if it is not resident \u201cin core\u201d, i.e., in memory . If the information is not in memory, file system  accesses the mode file to retrieve a logical vbn and passes a message structure including the vbn to the RAID system . There, the logical vbn is mapped to a disk identifier and device block number (disk, dbn) and sent to an appropriate driver of disk driver system . The disk driver accesses the dbn from die specified disk and loads the requested data block(s) in memory for processing by the storage server. Upon completion of the request, the node (and operating system ) returns a reply to the client over the network.","It should be noted that the software \u201cpath\u201d through the storage operating system layers described above needed to perform data storage access for the client request received at the storage server adaptable to the teachings of the invention can alternatively be implemented in hardware. That is, in an alternate embodiment of the invention, a storage access request data path can be implemented as logic circuitry embodied within a field programmable gate array (FPGA) or an application specific integrated circuit (ASIC). This type of hardware embodiment increases the performance of the storage service provided by the storage server in response to a request issued by a client. Moreover, in another alternate embodiment of the invention, the processing elements of adapters ,  can be configured to offload some or all of the packet processing and storage access operations, respectively, from processor , to thereby increase the performance of the storage service provided by the storage server. It is expressly contemplated that the various processes, architectures and procedures described herein can be implemented in hardware, firmware or software.","When implemented in a cluster, data access components of the storage operating system can be embodied as D-module  for accessing data stored on disk. In contrast, multi-protocol engine  can be embodied as N-module  to perform protocol termination with respect to a client issuing incoming access over the network, as well as to redirect the access requests to any other N-module in the cluster. A cluster services system  can further implement an M-host (e.g., NI-host ) to provide cluster services for generating information sharing operations to present a distributed file system image for the cluster. For instance, media access layer  can send and receive information packets between the various cluster services systems of the nodes to synchronize the replicated databases in each of the nodes.","In addition, a cluster fabric (CF) interface module  (CF interface modules A, B) can facilitate intra-cluster communication between N-module  and D-module  using a CF protocol . For instance, D-module  can expose a CF application programming interface (API) to which N-module  (or another D-module not shown) issues calls. To that end, CF interface module  can be organized as a CF encoder\/decoder using local procedure calls (LPCs) and remote procedure calls (RPCs) to communicate a file system command to between D-modules residing on the same node and remote nodes, respectively.","In one embodiment, storage operating system  includes a performance monitor layer , which enables the storage operating system to provide services related to monitoring performance of workloads with respect to their SLOs. Performance monitor layer  can be implemented as an interrupt-driven routine that operates at periodic intervals to perform monitoring operations. In one embodiment, storage operating system  includes VCA solution system , which enables the storage operating system to provide services related to determining how to cure a detected SLO violation. The services include one or more algorithms executed to determine what possible solutions may exist, and select one of the possible solutions for implementation. Additionally, VCA solution system  can include routines to issue commands related to instantiating and resizing VCAs. In an alternate embodiment, components  and , or parts of them, can be implemented as part of N-Module , D-Module , or M-Host .","As used herein, the term \u201cstorage operating system\u201d generally refers to the computer-executable code operable on a computer to perform a storage function that manages data access and can implement data access semantics of a general purpose operating system. The storage operating system can also be implemented as a microkernel, an application program operating over a general-purpose operating system, ovum a general-purpose operating system with configurable functionality, which is configured for storage applications as described herein.","Flow diagrams as illustrated herein provide examples of sequences of various process actions. Although shown in a particular sequence or order, unless otherwise specified, the order of the actions can be modified. Thus, the illustrated embodiments should be understood only as an example, and the process can be performed in a different order, and some actions can be performed in parallel. Additionally, one or more actions can be omitted in various embodiments; thus, not all actions are required in every embodiment. Other process flows are possible.","Various operations or functions are described herein, which can be described or defined as software code, instructions, configuration, and\/or data. The content can be directly executable (\u201cobject\u201d or \u201cexecutable\u201d form), source code, or difference code (\u201cdelta\u201d or \u201cpatch\u201d code). The software content of the embodiments described herein can be provided via an article of manufacture with the content stored thereon, or via a method of operating a communications interface to send data via the communications interface. A machine readable medium or computer readable medium can cause a machine to perform the functions or operations described, and includes any mechanism that provides (i.e., stores and\/or transmits) information in a form accessible by a machine (e.g., computing device, electronic system, or other device), such as via recordable\/non-recordable storage media (e.g., read only memory (ROM), random access memory (RAM), magnetic disk storage media, optical storage media, flash memory devices, or other storage media) or via transmission media (e.g., optical, digital, electrical, acoustic signals or other propagated signal). A communication interface includes any mechanism that interfaces to any of a hardwired, wireless, optical, or other medium to communicate to another device, such as a memory bus interface, a processor bus interface, an Internet connection, a disk controller. The communication interface can be configured by providing configuration parameters and\/or sending signals to prepare the communication interface to provide a data signal describing the software content.","Various components described herein can be a means for performing the operations or functions described. Each component described herein includes software, hardware, or a combination of these. The components can be implemented as software modules, hardware modules, special-purpose hardware (e.g., application specific hardware, application specific integrated circuits (ASICs), digital signal processors (DSPs), etc.), embedded controllers, hardwired circuitry, etc.","Besides what is described herein, various modifications can be made to the disclosed embodiments and implementations without departing from their scope. Therefore, the illustrations and examples herein should be construed in an illustrative, and not a restrictive sense."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The following description includes discussion of figures having illustrations given by way of example of implementations of embodiments described. The drawings should be understood by way of example, and not by way of limitation. As used herein, references to one or more \u201cembodiments\u201d are to be understood as describing a particular feature, structure, or characteristic included in at least one implementation. Thus, phrases such as \u201cin one embodiment\u201d or \u201cin an alternate embodiment\u201d appearing herein describe various embodiments and implementations, and do not necessarily all refer to the same embodiment. However, they are also not necessarily mutually exclusive.",{"@attributes":{"id":"p-0008","num":"0007"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0009","num":"0008"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 9A"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 9B"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 10","FIGS. 9A and 9B"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 11","FIG. 10"]}]},"DETDESC":[{},{}]}
