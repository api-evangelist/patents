---
title: Integration of three dimensional scene hierarchy into two dimensional compositing system
abstract: A hierarchy of 2D visual objects and 3D scene objects are integrated for seamless processing to render 2D images including a 2D view of a 3D scene on a 2D computer display. The processing of the 3D model objects and 2D visual objects in the visual hierarchy is integrated so that the processing is readily handed off between 3D and 2D operations. Further the number of transitions between processing visual 2D objects and 3D model objects when creating a display image has no architectural limit. A data structure integrates computer program objects for creating 3D images and 2D images in a visual tree object hierarchy having visual 2D objects or 3D scene objects pointing to 3D model objects. The data structure comprises an object tree hierarchy, one or more visual 2D objects, and one or more 3D reference or scene objects pointing to 3D model objects. The visual 2D objects define operations drawing a 2D image. The 3D reference or scene objects define references pointing to objects with operations that together draw a two-dimensional view of a three-dimensional scene made up of one or more 3D models. The 3D reference or scene objects point to 3D model objects and a camera object. The camera object defines a two-dimensional view of the 3D scene. The 3D model objects draw the 3D models and define mesh information used in drawing contours of a model and material information used in drawing surface texture of a model. The material information for the surface texture of a model may be defined by a visual 2D object, a 3D reference or scene object or a tree hierarchy of visual 2D objects and/or 3D reference scene objects.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07145562&OS=07145562&RS=07145562
owner: Microsoft Corporation
number: 07145562
owner_city: Redmond
owner_country: US
publication_date: 20040503
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATION","TECHNICAL FIELD","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE INVENTION"],"p":["The present application is related to U.S. patent application Ser. No. 10\/838,931, entitled TRANSLATING USER INPUT THROUGH TWO-DIMENSIONAL IMAGES INTO THREE-DIMENSIONAL SCENE, filed May 3, 2004 and U.S. patent application Ser. No. 10\/838,936 entitled MODEL 3CONSTRUCTION APPLICATION PROGRAM INTERFACE, filed May 3, 2004, both applications assigned to the Assignee of the present invention and hereby incorporated by reference in their entirety.","The invention relates generally to the field of computer graphics. More particularly, the invention relates to integrating three-dimensional graphics in a two dimensional compositing system.","The limits of the traditional model of accessing graphics on computer systems are being reached, in part because memory and bus speeds have not kept up with the advancements in main processors and\/or graphics processors. In general, the current model for preparing a frame using bitmaps requires too much data processing to keep up with the hardware refresh rate when complex graphics effects are desired. As a result, when complex graphics effects are attempted with conventional graphics models, instead of completing the changes that result in the perceived visual effects in time for the next frame, the changes may be added over different frames, causing results that are visually undesirable.","Further, this problem is aggravated by the introduction of three dimensional (3D) graphics and special effects such as animation of the 3D images being displayed. What is needed is a graphics generation and compositing system that can render 3D images in real time, creating the images as the images are called up by the computer program. Further, the creation of 3D images should be integrated into two-dimensional (2D) graphics display as needed to provide a mix of 3D and 2D images on the display. It is with respect to these considerations and others that the present invention has been made.","The above and other problems are solved by integrating 3D model objects into a hierarchy of 2D visual objects and seamlessly processing 3D images and 2D images for rendering on a 2D display. The processing of the 3D model objects and 2D visual objects in the visual hierarchy is integrated so that the processing is readily handed off between 3D and 2D operations. Further the number of transitions between processing visual 2D objects and 3D model objects when creating a display image has no architectural limit. Thus, the user is free to create graphics embedding 3D images in 2D images and 2D images in 3D images ad infinitum. For example, a user interface dialog box could be textured onto a sphere which is displayed as part of another dialog box which in turn is textured onto a cone.","In accordance with another aspect, the present invention relates to a data structure for integrating computer program objects for creating 3D images and 2D images in a visual tree object hierarchy having visual 2D objects or 3D scene objects pointing to 3D model objects. The data structure comprises an object tree hierarchy, one or more visual 2D objects, and one or more 3D reference or scene objects pointing to 3D model objects. The visual 2D objects define operations drawing a 2D image. The 3D reference or scene objects define references pointing to objects with operations that together draw a two-dimensional view of a three-dimensional scene made up of one or more 3D models. The 3D reference or scene objects point to 3D model objects and a camera object. The camera object defines a two-dimensional view of the 3D scene. The 3D model objects draw the 3D models and define mesh information used in drawing contours of a model and material information used in drawing surface texture of a model. The material information for the surface texture of a model may be defined by a visual 2D object, a 3D reference or scene object or a tree hierarchy of visual 2D objects and\/or 3D reference scene objects.","In accordance with a further aspect, the present invention relates to a method for processing a hierarchy of computer program visual objects for creating a mix of two-dimensional (2D) and three-dimensional (3D) images as output from a computer. The method comprises traversing branches of a first tree hierarchy of visual objects to process leaf objects and branch objects and detecting whether the next unprocessed visual object is a visual 2D object or a visual 3D object. If a visual 2D object is detected, a 2D process is called to process the visual object. If a visual 3D object is detected, a 3D process is called to process the visual object. The 3D process sets a camera view and draws images of one or more 3D models defined by the visual 3D object. The images are drawn based on the camera view of the one or more 3D models.","The invention may be implemented as a computer process, a computing system or as an article of manufacture such as a computer program product or computer readable media. The computer readable media may be a computer storage media readable by a computer system and encoding a computer program of instructions for executing a computer process. The computer readable media may also be a propagated signal on a carrier readable by a computing system and encoding a computer program of instructions for executing a computer process.","In accordance with one embodiment of the invention,  illustrates 3D reference or scene objects integrated into a visual objects tree hierarchy so that the tree has both visual 2D objects and 3D reference or scene visual objects. \u201cVisual\u201d, when associated herein with objects, represents a drawing rendered on a computer display screen by the object. In this exemplary illustration of a visual tree, a root visual object  has four children with alternate embodiments for one child that is a 3D scene child. The visual 2D children are objects , , and , and one of the 3D scene objects  and  in the alternative is the fourth child of the root visual object .","The 3D scene object  is a visual 3D object  and contains a reference or pointer  to model 3D object(s)  and a reference or pointer  to a camera object  for viewing a 3D models as a 2D image. Visual 3D objects are described in more detail in the cross-referenced patent application entitled MODEL 3D CONSTRUCTION APPLICATION PROGRAM INTERFACE and cited above. The camera  views the 3D model(s) drawn by object(s)  as a 3D scene. The model 3D object(s)  and camera object  together produce a 2D image of the 3D scene on a computer display screen. The 3D scene object  is a visual 2D object with drawing context. In this embodiment of the invention, the drawing context of the visual 2D object contains the reference or pointer  to the model 3D object(s)  and the reference or pointer  to the camera object .","To create an image and render a display the branches of the visual tree are traversed and processed from left to right; thus the render sequence in  is shown from left to right.","The visual 2D object with drawing context and the processing of the visual tree is described in the commonly-assigned application entitled TRANSLATING USER INPUT THROUGH TWO-DIMENSIONAL IMAGES INTO THREE-DIMENSIONAL SCENE cited above in the cross-reference to related applications. above in the cross-reference to related applications. A brief review of that processing will be included herein in the description of .","To illustrate how an image display is produced in this render sequence we will assume that the visual 2D object  creates a triangle, the visual 2D object  produces a circle, and the visual 2D object  produces a square. The 3D scene visual 3D object  or 3D scene visual 2D object  produces a 3D scene as viewed from a camera. Since the render sequence is from left to right and later rendered objects overlay earlier rendered objects, the visual tree  will produce the display image  in . In other words, the triangle, produced from visual , and the circle, produced from visual , are overlapped by the square provided by visual  because visual  is processed after visual  and . Likewise, the 2D view of the 3D scene created by 3D scene object  or  is produced after the circle and overlays the circle. By providing a 3D scene objects containing a 3D scene and a virtual camera to view that scene, the 3D scene is converted to a 2D image which can be rendered as another 2D image from the visual tree. Further, since the images are drawn rather than being bitmap images, the display can be rendered in real time on a computer display screen or as other computer video output.","In another significant feature of the invention, the 3D model object(s)  have material or texture information . The material information  can point to another visual tree represented by visual object . This visual object  may have visual 2D objects and 3D scene objects just as visual tree root object . Thus, the visual tree hierarchy can embed 3D scene objects in a visual tree with 2D objects and, further, a second visual tree with 2D objects and 3D scene objects can in turn be embedded in the 3D models of the 3D scene objects in the first visual tree. This sequential alternate embedding of 3D and 2D objects in the tree hierarchy can proceed as many times as desired by the graphics program creator to create the desired display of mixed 2D and 3D images.","A more detailed illustration of the integration of 3D objects with 2D objects in a visual tree hierarchy is shown in . However,  are now described to provide an exemplary operating environment and a software environment for processing the integrated visual tree hierarchy.","Exemplary Operating Environment",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 2","b":["100","100","100","100"]},"The invention is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, tablet devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like.","The invention may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, and so forth, which perform particular tasks or implement particular abstract data types. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices.","With reference to , an exemplary system for implementing the invention includes a general purpose computing device in the form of a computer . Components of the computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, Accelerated Graphics Port (AGP) bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","The computer  typically includes a variety of computer-readable media. Computer-readable media can be any available media that can be accessed by the computer  and includes both volatile and nonvolatile media, and removable and non-removable media. By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can accessed by the computer . Communication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer-readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , other program modules  and program data .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media, discussed above and illustrated in , provide storage of computer-readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules  and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers herein to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer  through input devices such as a tablet (electronic digitizer) , a microphone , a keyboard  and pointing device , commonly referred to as mouse, trackball or touch pad. Other input devices (not shown) may include a joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . The monitor  may also be integrated with a touch-screen panel  or the like that can input digitized input such as handwriting into the computer system  via an interface, such as a touch-screen interface . Note that the monitor and\/or touch screen panel can be physically coupled to a housing in which the computing device  is incorporated, such as in a tablet-type personal computer, wherein the touch screen panel  essentially serves as the tablet . In addition, computers such as the computing device  may also include other peripheral output devices such as speakers  and printer , which may be connected through an output peripheral interface  or the like.","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet. When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface  or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation,  illustrates remote application programs  as residing on memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Software Environment for Processing the Visual Tree Hierarchy",{"@attributes":{"id":"p-0037","num":"0036"},"figref":["FIG. 3","FIG. 3"],"b":["200","202","204","206","212","204","202","206","206","208","210","212"]},"The graphics layer architecture  includes a high-level composition and animation engine , which includes or is otherwise associated with a caching data structure . The caching data structure  contains a scene graph comprising hierarchically-arranged objects that are managed according to a defined object model, as described below. In general, the visual API layer  provides the program code  (and the presenter system ) with an interface to the caching data structure , including the ability to create objects, open and close objects to provide data to them, and so forth. In other words, the high-level composition and animation engine  exposes a unified media API layer  by which developers may express intentions about graphics and media to display graphics information, and provide an underlying platform with enough information such that the platform can optimize the use of the hardware for the program code. For example, the underlying platform will be responsible for caching, resource negotiation and media integration.","The high-level composition and animation engine  passes an instruction stream and possibly other data (e.g., pointers to bitmaps) to a fast, low-level compositing and animation engine . As used herein, the terms \u201chigh-level\u201d and \u201clow-level\u201d are similar to those used in other computing scenarios, wherein in general, the lower a software component is relative to higher components, the closer that component is to the hardware. Thus, for example, graphics information sent from the high-level composition and animation engine  may be received at the low-level compositing and animation engine , where the information is used to send graphics data to the graphics subsystem including the hardware .","The high-level composition and animation engine  in conjunction with the program code  builds a scene graph to represent a graphics scene provided by the program code . For example, each item to be drawn may be loaded with drawing instructions, which the system can cache in the scene graph data structure . As will be described below, there are a number of various ways to specify this data structure , and what is drawn. Further, the high-level composition and animation engine  integrates with timing and animation systems  to provide declarative (or other) animation control (e.g., animation intervals) and timing control. Note that the animation system allows animate values to be passed essentially anywhere in the system, including, for example, at the element property level , inside of the visual API layer , and in any of the other resources. The timing system is exposed at the element and visual levels.","The low-level compositing and animation engine  manages the composing, animating and rendering of the scene, which is then provided to the graphics subsystem . The low-level engine  composes the renderings for the scenes of multiple applications, and with rendering components, implements the actual rendering of graphics to the screen. Note, however, that at times it may be necessary and\/or advantageous for some of the rendering to happen at higher levels. For example, while the lower layers service requests from multiple applications, the higher layers are instantiated on a per-application basis, whereby is possible via the imaging mechanisms  to perform time-consuming or application-specific rendering at higher levels, and pass references to a bitmap to the lower layers.",{"@attributes":{"id":"p-0042","num":"0041"},"figref":["FIGS. 4 and 5","FIG. 4","FIG. 3","FIG. 4"],"b":["300","400","302","304","306","304","306","304","308","218","306","308","218","222","310","315","302","316","317","318","319"]},{"@attributes":{"id":"p-0043","num":"0042"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public abstract class Visual : VisualComponent"]},{"entry":[{},"{"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public Transform Transform { get; set; }"]},{"entry":[{},"public float Opacity { get; set; }"]},{"entry":[{},"public BlendMode BlendMode { get; set; }"]},{"entry":[{},"public Geometry Clip { get; set; }"]},{"entry":[{},"public bool Show { get; set; }"]},{"entry":[{},"public HitTestResult HitTest (Point point);"]},{"entry":[{},"public bool IsDescendant (Visual visual);"]},{"entry":[{},"public static Point TransformToDescendant ("]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Visual reference,"]},{"entry":[{},"Visual descendant,"]},{"entry":[{},"Point point);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"public static Point TransformFromDescendant ("]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"Visual reference,"]},{"entry":[{},"Visual descendant,"]},{"entry":[{},"Point point);"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"public Rect CalculateBounds( ); \/\/ Loose bounds"]},{"entry":[{},"public Rect CalculateTightBounds( ); \/\/"]},{"entry":[{},"public bool HitTestable { get; set; }"]},{"entry":[{},"public bool HitTestIgnoreChildren { get; set; }"]},{"entry":[{},"public bool HitTestFinal { get; set; }"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"}"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"A transformation, set by the transform property, defines the coordinate system for the sub-graph of a visual. The coordinate system before the transformation is called pre-transform coordinate system, the one after the transform is called post-transform coordinate system, that is, a visual with a transformation is equivalent to a visual with a transformation node as a parent.","A more complete description of the visual tree and the compositing system is included in the related patent application entitled TRANSLATING USER INPUT THROUGH TWO-DIMENSIONAL IMAGES INTO THREE-DIMENSIONAL SCENE cross-referenced above.","Integration of Visual 3D into Visual Tree Hierarchy","With the above hardware and software environment in mind,  illustrates the integration of 3D scene objects into a visual tree hierarchy also having visual 2D objects. As previously described with reference to , the visual 3D scene object creates a 2D image\u2014camera view of a 3D scene. As described above for  the 3D scene object is implemented as a visual 3D object with a pointer to 3D model(s) or a visual 2D object having drawing context with a pointer to 3D model(s). Also as described for , there would be a second pointer shown in  to a camera object. In the example of  the pointer from 3D scene object to 3D model(s) is represented by pointer . This pointer  points to a 3D model primitive  which will draw a 3D object and make use of mesh information  and material information  in drawing the 3D object.","Mesh information  refers to a mesh of 2D shapes that may be used to approximate the 3D contours of the 3D model. For example, if one pictures pressing a cloth mesh net over a 3D model such as a chair; the net assumes the contours of the chair. Typically the mesh is made up of planar triangular shapes. The triangles are usually quite small and as such form a fine mesh that may be used to follow 3D contours. In addition to triangles other 2D shapes with more than three sides or even continuous sides may be used to form the mesh, but triangles are preferred because the three points of a triangle define a plane and this simplifies the computation of the mesh.","Material information , which is also information associated for 3D model object , refers to texture used to fill-in a surface on the image of the 3D model. Texture might be shading, color, or additional visual images. In  the additional visual image for the material is a 3D scene object .","The 3D scene object  may be either a visual 3D object or a visual 2D object as described in . In either event it will have a pointer to the 3D models and a pointer to the camera object. Pointer  points to the camera object to define the camera parameters to render the 2D view of the 3D scene. The pointer  to the 3D objects in  is a part of the 3D content . Pointer  is points to the root object  of the model 3D objects making up a 3D visual tree. The root object is 3D model group object . A 3D model group object serves as either as root node or collection node in a 3D visual tree containing one or more model 3D primitive objects. The primitive objects will be at the leaf of a branch in the visual 3D tree and contain the drawing information for creating a 3D model. In , there are two model 3D primitive objects\u2014primitive  and primitive \u2014and a model 3D light object . The light information content of light object  defines the light illuminating the 3D scene made up of the 3D models and the direction of the light rays if applicable. The draw information content of each of the 3D model primitives includes mesh information and material information. This content is only shown for primitive  as mesh information  and material information . The material information  may simply have drawing content information or it may have a visual 2D object or a 3D scene object or both. In the example in  the material information  has a visual 2D object .","To review the integration that is illustrated by ,  starts with a pointer from a 3D scene object, such as object  or object  in , to a model 3D object . The model 3D object  has material information  that has a further 3D scene object  pointing to a model 3D group object  and a camera object . In the 3D scene defined by 3D group  with its children, the 3D primitive object  has material information pointing to a visual 2D object . In this way a visual tree hierarchy with 2D visual objects may have integrated into it a 3D scene created by a 3D scene object. In turn model 3D object in the 3D scene tree may have information pointing to a second visual tree that has integrated into it a further visual 2D object, a 3D scene object or both types of objects. This integration of 3D scene objects and visual 2D objects can proceed ad infinitum.","One of the salient features of the invention is the fact that the visual objects and model 3D objects do not store bitmaps of the images to be produced, but instead provide instructions for drawing the images when the visual tree is processed. Described immediately above was the processing for such a visual tree. The processing of a 3D scene visual tree is similar but adds a few operations to create the 2D view of a 3D scene defined by the model 3D objects.","A 3D scene object creates a camera view, i.e. a 2D view, of the 3D scene. The camera view is specified by parameters that identify the virtual camera \u201cposition,\u201d the \u201clook at\u201d or aim direction for the camera and the \u201cfield\u201d of view of the camera. A example of camera parameters is illustrated in  where the camera position or viewpoint is located at X, Y, Z coordinates , , . The look-at or aim direction of the camera is specified by the look-at location XYZ is , , . The field of view of the camera is indicated as 30 degrees. These camera parameters are used to set the camera or 2D view when drawing the 3D models created by the 3D primitives.","These camera parameters reflect a perspective view camera. Other cameras might be used such as those described in the commonly assigned patent application entitled MODEL 3D CONSTRUCTION APPLICATION PROGRAM INTERFACE cited above in the cross-reference to related applications. For example an orthogonal camera would provide an orthogonal view where all light rays are parallel and the primary camera parameters are aim, or look-at, direction and field of view.",{"@attributes":{"id":"p-0054","num":"0053"},"figref":["FIGS. 8 and 9","FIG. 10","FIGS. 8 and 9","FIGS. 8 and 9","FIGS. 8 and 9"]},"In the example of  the visual tree represents a window on a computer display screen. The visual 2D root object  for the window has three children, panel visual object , checkbox visual object , and visual 3D object . The panel visual object  is a container visual object and has two children, a button visual object  and a scrollbar visual object . Thus the programmer is creating a window with a button, a scroll bar and checkbox along with a 3D scene object to provide 3D scene viewed as a 2D image.","The 3D scene object  points to camera parameters  with pointer  and points to the 3D scene  with pointer . The 3D scene is made up of two model 3D group objects  and , two model 3D primitive objects  and , and a model 3D light object . Each of the 3D primitives contains drawing context and in each case they illustrate a different drawing context possibility. The light object  specifies the illumination of the models drawn by primitive object  as the light object  and primitive object  are children of group object . Primitive object  contains mesh information  and material information . Primitive  contains mesh information  and material information . The material information  points to a further visual tree that has visual tree root , and both a visual 2D object  and a 3D scene object .","The operational flow for processing the visual tree in  begins in , which shows visual 2D object processing with a bridge to 3D scene object processing. As will become apparent in the description of this operation flow, the flow in  is a recursive flow. The operation flow processes a branch of the tree down to the leaves and then processes other branches down to the leaves. As described in  the tree traversal and image rendering sequence is from left to right; however, it could be organized any number of ways as, for example, from right to left through the tree, or by length of branches or by any other priority for traversing the tree the programmer might wish to implement.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":["FIG. 8","FIG. 10","FIG. 8"],"b":["1002","800","801","1002","802","803","704","802"]},"Call operation  calls 2D process entry point . At entry point  the operation flow passes to 3D scene test operation . Test operation  detects whether the object is a 3D scene object or a visual 2D object. If it is a visual 2D object, as in this case for window object  in , the operation flow branches \u201cNO\u201d to process visual operation . Process operation  executes the window object  to draw a window image. The operation  is described in related patent application cross referenced above and entitled Visual And Scene Graph Interfaces. After the process visual operation  is completed, the return operation  returns the operational flow to call operation .","At call operation  the flow is directed to more objects test operation . More objects test operation  detects whether there are more objects to be processed in the visual tree. If there are, the operation flow branches YES to move operation . Move operation  moves down the left most branch of the tree to panel object  in  which is the next unprocessed object. The branches of the tree will be processed from left to right.","Panel object  is another visual 2D object and is processed in the same manner as just discussed for window object . Return operation again returns the flow to call operation  and the flow passes to move operation . Processing now moves to the first child of panel object  which is button visual 2D object . Button object is processed for as described above for object  and the flow returns to call operation  and hence to move operation . The next unprocessed object in the same branch is the scroll bar visual object . This is a visual 2D object, and the operation flow will again pass to process visual 2D operation  through 3D scene test operaion . Process visual 2D operation  will process the scroll bar visual object  in the same manner as described above for the processing of the window object . The operation flow again returns to the call operation , and move operation  walks the visual tree in  to the first object in the next branch, i.e. check box object .","After the checkbox visual 2D object  is processed, move operation  walks the tree to 3D scene object . The 3D scene object  will be detected by test operation , and the operation flow will branch \u201cYES\u201d to call 3D scene process at call operation . The 3D scene process operational flow is illustrated in , and call operation  passes the operation flow to 3D scene entry point  in .","In , move operation  moves the processing to the next object in the 3D scene tree which has not been processed. The first such object is 3D group object  which is also the root node of the 3D scene tree. The operation flow enters loop  which contains call operation  and more objects test operation . As model 3D objects in the 3D scene tree  are processed, the operation flow around the loop  walks the process through the branches of the 3D scene tree from left to right.","Call operation  calls 3D process module entry point . At entry point  the operation flow passes to group object test operation . The first object is 3D group object . The group test operation  will detect the group object and branch the operation flow to the process 3D group operation . A group operation might be a transform operation or other operations such as setting a model clip operation, a shading operation, a wire frame operation, etc. After process group operation , the return to caller operation  again returns the flow to call operation .","A return to call operation  causes the flow to pass around loop  to more objects test operation . More objects test operation  detects whether there are more objects to be processed in the 3D scene tree. If there are, the operation flow branches YES to move operation . Move operation  moves down the left most branch of the 3D scene tree to 3D group object  in  which is the next unprocessed object. The branches of the tree will be processed from left to right.","Model 3D object  is another group object and group test operation  will branch the flow YES to process group operation  to process group object . Return operation  again returns the flow to call operation , and the flow passes to move operation . Processing now moves to the model 3D light object  which is the next unprocessed object in the same branch of the 3D scene tree . Group object test operation passes the flow to light object test operation . Light object  is detected and passed to process light object operation . Process light operation sets the light for the 3D scene collected by 3D group object , and the flow then passes to return-to-caller operation .","The flow returns to call operation  and hence to move operation . The next unprocessed object in the same branch is the 3D primitive object . Primitive objects draw the 3D models. Group object test  and light object test  respond with negative results when detecting primitive object . Accordingly, the operation flow branches \u201cNO\u201d from light object test  to retrieve camera operation  which retrieves the camera parameters. Set view operation  then sets the camera or 2D view, and the operation flow passes to 2D content test operation . Since the primitive object  in  has no visual objects and thus no 2D content attached, the operation flow would branch \u201cNO\u201d to draw primitive operation . Draw primitive operation  draws a 3D model based on mesh information  and material information  contained in the model 3D primitive object . The model is drawn from the perspective of the camera view based on the camera parameters. The result is a 2D image of a 3D model as illuminated according to light object . At return-to-caller operation , the operation flow returns to the call operation  again. More objects test operation  detects that there are more objects in the 3D scene tree to be processed. Move operation  walks the 3D scene tree to the next branch and to 3D primitive object , the next unprocessed object.","The 3D primitive object  does have material information  that includes both visual 2D and 3D scene objects in the material information. Accordingly, the operation flow branches YES from 2D content test operation  to call visual tree process operation . Call visual tree process calls the visual tree entry point  in , and move operation  moves program control to process visual 2D object . Call operation  calls the 2D process, and visual 2D object  is processed by process visual operation . The operation flow passes to return-to-caller operation  and returns to call operation . Move operation  then walks the 2D content tree to visual 2D object . The 2D process is called again to process visual 2D object . Object  is processed by process visual operation and the operation flow returns to loop . Now the move operation  moves control to 3D scene object .","Call operation  calls the 2D process, and the 3D scene object  will be detected by 3D scene test operation . As a result call operation  calls the 3D scene process in  to process model 3D objects (not shown) of a 3D scene. The processing would be the same as that discussed above in the example of 3D scene . The 3D scene object  in  is called to process the 3D scene models represented by visual 3D object , and when the last model for the 3D scene object  is drawn, the operation flow passes to return-to-caller operation  in . The caller in this situation is call operation .","Call operation  passes the flow to more objects test  detects that there are no more objects associated with the 3D scene object . The operation flow branches NO to return to caller operation  which passes the flow back to call operation . Call operation passes the flow to call operation . More objects test operation  detects there are no more objects to be processed for the 2D content tree composed of objects ,  and . Accordingly the flow branches NO to return to caller operation . In this case the return is to call operation  that called the visual tree process to handle the 2D content tree. Draw 3D primitive operation  now draws the 3D model for primitive object  using the material information represented by 2D content tree objects ,  and . Return to caller operation  then returns the flow to call operation .","More objects test operation  then detects no more objects in the 3D scene tree  and passes the flow to return to caller operation . Return operation  now returns the flow to call 3D scene operation  in . The flow then is passed back to call operation  by return operation . More objects test operation  detects that the visual tree of  has been completely processed and therefore passes the operation flow to return-to-caller operation . The return-to-caller operation passes the program control back to caller . Call operation  calls the 2D process in  which now processes visual 2D object . Visual 2D object  is the root object for the material information . Process visual operation  processes root object , and return-to-caller operation  passes program control back to primary caller (not shown) that called to process the visual tree of . This completes the processing of the example visual tree in  with its integrated 3D scene objects and visual 2D objects.","Although the invention has been described in language specific to computer structural features, methodological acts and by computer readable media, it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific structures, acts or media described. Therefore, the specific structural features, acts and mediums are disclosed as exemplary embodiments implementing the claimed invention.","The various embodiments described above are provided by way of illustration only and should not be construed to limit the invention. Those skilled in the art will readily recognize various modifications and changes that may be made to the present invention without following the example embodiments and applications illustrated and described herein, and without departing from the true spirit and scope of the present invention, which is set forth in the following claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"p":["These and various other features as well as advantages, which characterize the present invention, will be apparent from a reading of the following detailed description and a review of the associated drawings.",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":["FIG. 10","FIGS. 8 and 9"]}],"heading":"BRIEF DESCRIPTION OF THE DRAWINGS"},"DETDESC":[{},{}]}
