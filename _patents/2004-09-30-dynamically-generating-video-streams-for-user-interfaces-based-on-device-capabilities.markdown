---
title: Dynamically generating video streams for user interfaces based on device capabilities
abstract: The present invention provides for transferring user interface information from a host computing device to an electronic device that typically has limited resources. A request to display a user interface on an electronic device is received. Further, information about the electronic device is received for determining the capabilities of the electronic device. Based on the determination, a video codec is utilized for dynamically generating a video data stream that includes user interface information corresponding to at least a portion of the user interface. The video data stream is then transmitted to the electronic device for rendering the user interface on a display of the electronic device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08166507&OS=08166507&RS=08166507
owner: Microsoft Corporation
number: 08166507
owner_city: Redmond
owner_country: US
publication_date: 20040930
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","BRIEF SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["This is a continuation of U.S. patent application Ser. No. 10\/917,645, filed on Aug. 13, 2004.","1. The Field of the Invention","The present invention generally relates to displaying graphical and image data on electronic devices in an entertainment network, e.g., a home entertainment network. More particularly, the present invention provides for dynamically generating video data streams for transferring graphical\/image data from a host computing device to an electronic device\u2014that typically has limited resources\u2014for rendering the data.","2. Background and Related Art","Computerized systems provide many advantages towards people's ability to perform tasks. To enable these advantages, computer systems often come equipped with (or are expandable to include) multiple hardware devices that can store or read data or enable a software program to perform a specific action on data. Such devices can include, e.g., a hard drive, a Compact Disk (i.e., CDROM, CDRW, etc.), a Universal Serial Bus (USB) device (e.g., a printer, a scanner, etc.), and so on. Present computer systems also commonly have installed there on multiple software (or \u201capplications\u201d) programs such as a word processing program, a spread sheet program, an imaging program, and an electronic mail program, which instruct the devices to perform specific actions on the data.","Indeed, the computer system's ability to process information has transformed the way we live and work. Computing systems now take a wide variety of forms including desktop computers, laptop computers, tablet PCs, Personal Digital Assistants (PDAs), and the like. Even household devices (such as refrigerators, ovens, sewing machines, security systems, and the like) have varying levels of processing capability and thus may be considered computing systems. Processing capabilities continue to be incorporated into devices that traditionally did not have such processing power. Accordingly, the diversity trend of computing systems will likely increase.","This increase in computing resources has partially driven the need for coupling computer systems to one another to form both wired and wireless computer networks over which the computer systems can communicate electronically to share data. As a result, many tasks performed at a computer system (e.g., voice communication, accessing electronic mail, electronic conferencing, web browsing) include electronic communication with one or more other computer systems via wired and\/or wireless computer networks.","More recently, various operating systems and frameworks have allowed single applications to be run simultaneously by multiple users at different computing systems. This \u201csession-oriented\u201d extension turns an ordinary computer into a centralized, timeshared server similar to mainframes and dumb terminals. The difference is that these extensions provide a graphical interface, whereas mainframes provide only character-based interfaces. All the data processing is performed in the server\/host computer, and the client displays only the user interface and screen changes. Such centralized processing power, as well as the advancement in consumer electronic devices, has been the catalyst for the movement of the digital-home network.","As the advent of the digital-home network evolves consumers are discovering the benefits of connecting their personal computers to other consumer electronic devices. For example, by storing music, digital photos, movies, and other content on their personal computers and interfacing the host computer with various consumer electronic devices (e.g., network televisions, wireless monitors, DVDs, set-top box (STB), or other digital media), consumers can turn their home network into a complete home entertainment system. Such centralized storage and connectivity allows users to easily search, sort, and reproduce content, at a number of different electronic devices. In addition, by utilizing the advancement of session-oriented processing capabilities of a host computer, users can have a rich user experience of various applications at each consumer electronic device, without having to be physically at the host computer.","Usually, the central or host computer of a home network is more powerful than the consumer electronic devices. Creating a home network in this fashion\u2014i.e., using less powerful electronic devices, for example\u2014alleviates the issues of cost and distribution of computing load. The cost of a home network to a consumer is reduced because the electronic devices typically have limited processing resources and other capabilities, thus they are not as expensive as more intelligent platforms.","Although the reduction in cost is a great benefit, other difficulties arise. For example, in order for an electronic device to render and interact with the user interface (UI) of a session for an application running on the host computer, the consumer electronic device will typically use a UI protocol such as Remote Desktop Protocol (RDP)\/Independent Computer Architecture (ICA) or a common language such as HyperText Markup Language (HTML). Such protocols and languages, however, put an extra burden on the electronic device in the form of complexity, hardware capabilities, etc.","Another problem using consumer electronic devices with limited resources in a home network is that a simple processing session for a host computer can appear heavy and burdensome for a consumer electronic device. For example, a slideshow (i.e., the ability to show photos or image data consecutively and in full screens) is typically a very simple process on a host computer. Nevertheless, each image in a slideshow can be several megapixels is size. Accordingly, transferring the data to an electronic device means large bursts across the network\u2014especially wireless networks\u2014and lots of data to be decompressed during playback by the electronic device's central processor unit (CPU). The result is a slideshow that lacks a high level of visual refinement, such as visible painting on the screen, which feels sluggish and cheap to a consumer. This problem is even further elevated by any transitional information associated with the slideshow, such as panning, zooming, etc.","One approach to alleviate the above-identified problem for rendering slideshow presentations on consumer electronic devices is to compile the photos into a video file, which can be transferred to the device. Since the video file must be pre-compiled, however, this approach does not allow for user interactivity for manipulating the slides, which is often desirable. Accordingly there exits a need for being able to more effectively transmit and render graphical\/image data at consumer electronic devices with limited resources for enhancing the user experience.","The above-identified deficiencies and draw backs of current home entertainment networks are over come by the present invention. For example, in an entertainment network environment comprising a host computing device and at least one electronic device that typically has limited resources, the present invention provides for transferring user interface information from the host computing device to the electronic device using dynamically generated video data streams.","Example embodiments provide for receiving a request to open a session of an application for displaying corresponding user interface at an electronic device within an entertainment network. In response to the request, a session on a host computer is opened for generating user interface information for the electronic device. Utilizing a video codec at lease a portion of the user interface information is dynamically converted into a video data stream, which is capable of being processed at the electronic device by a video processor. The video data stream is then transmitted to the electronic device for displaying the user interface.","Other example embodiments provide for dynamically generating a video data stream based on the capabilities of an electronic device. A request to display a user interface on an electronic device is received. Further, information about the electronic device is received for determining the capabilities of the electronic device. Base on the determination, a video data stream is dynamically generated utilizing a video codec, wherein the video data stream includes user interface information corresponding to at least a portion of the user interface. The video data stream is then transmitted to the electronic device for rendering the user interface on a display of the electronic device.","Still other example embodiments provide for an electronic device that can receive a video data stream that contains user interface information and render the user interface on a display. A video data stream is received at an electronic device, which includes user interface information coded in a video codec formant. A video processor is used for decoding at least a portion of the video data stream into video frame data. At least a portion of the user interface is displayed as video frame data on a display of the electronic device.","In still yet other example embodiments, the present invention provides for rendering slideshow presentation information on the display of an electronic device that typically has limited resources. An electronic device may receive a video data stream, which includes slideshow presentation data coded in a video codec format. The slideshow presentation data including image data accessible by host computer. A video processor of the electronic device is used for decoding at least a portion of the video data stream into video frame data. At least a portion of the slideshow presentation data is then displayed as video frame data on a display of the electronic device.","Other example embodiments provided for transferring slideshow presentation information from a host computing device to an electronic device that typically has limited resources for rendering bitmap images. A request to display a slideshow presentation at an electronic device is received. The slideshow presentation configured to include slideshow presentation data corresponding to image data representing one or more bitmaps. In response to the request, a session of an application is opened on a host computer that produces the slideshow presentation data. A video codec is then utilized for dynamically converting the slideshow presentation data into a video data stream that represents the slideshow presentation. The video data stream is then transmitted to the electronic device for rendering the slideshow presentation.","In yet another example embodiment, an entertainment network is provided for rendering bitmap images with transitional information on an electronic device that typically has limited resources. A request to display a slideshow presentation at an electronic device is received. The slideshow presentation is configured to include slideshow presentation data corresponding to image data representing one or more bitmaps. Further, the slideshow presentation is configured to include transitional information that indicates how the image data is to visual represented at one or more moments in time within the slideshow presentation. In response to the request, a session of an application is opened on a host computer that produces the slideshow presentation data. A video codec is utilized for dynamically converting the slideshow presentation data into a video data stream that represents the slideshow presentation. The video data stream is then transmitted to the electronic device for rendering the slideshow presentation.","Additional features and advantages of the invention will be set forth in the description which follows, and in part will be obvious from the description, or may be learned by the practice of the invention. The features and advantages of the invention may be realized and obtained by means of the instruments and combinations particularly pointed out in the appended claims. These and other features of the present invention will become more fully apparent from the following description and appended claims, or may be learned by the practice of the invention as set forth hereinafter.","The present invention extends to methods, systems and computer program products for dynamically generating and rendering graphical\/image data on a consumer electronic device that typically has limited resources. The embodiments of the present invention may comprise a special purpose or general-purpose computer including various computer hardware, as discussed in greater detail below.","Generally the present invention provides for the ability to display graphical and\/or image data on an electronic device that typically has limited processing resources. More particularly, the present invention allows for user interface (UI) information and slideshow presentation data to be transmitted to and rendered at an electronic in an entertainment network, i.e., a home network. A video codec (Coder\/Decoder) on the host computer enables dynamic generation of streamed video representing UI and slideshow presentation generation and transmitting the video data stream to the electronic device. The device is then able to render the UI and slideshow presentation stream using a video processor similar to typical hardware used for rendering video.","This has the benefit of offering an updating UI and slideshow presentation information in a flexible platform without putting an extra burden on the electronic device in the form of complexity, hardware, capabilities, etc. Visual fidelity is limited only by the power of the host computer and the complexity of the video codec. Although the present invention provides compatibility with application and components that use existing Remote Desktop Protocol (RDP), example embodiments also provide for replacing traditional RDP with a local procedure call version.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 1","b":["100","105","130","130","130","105","115","110","105","110","194","190","115"]},"Rather than rendering the UI to a window, the UI information (or at least a portion thereof, as described below in greater detail below) is processed and passed to video codec  for dynamically generating video data stream . The processing may be one of re-sampling\/resizing the image to the appropriate target resolution, i.e., the resolution supported by the. electronic device. Further, example implementations details provide that a presentation service protocol, e.g., RDP, connection is made between the session  and an executable process (not shown) running on the host computer . Because the video data stream  is fed from the executable process, all application programming interfaces (APIs), e.g., graphics device interface (GDI), accessible UI is captured and encoded, without modification to the application . This results in full compatibility with all media extensibility apps  and shell components that already work over such standard protocols, e.g., RDP.","Regardless of the presentation protocol and process used to abstract the UI from the session  and the video codec , the video codec  dynamically converts the UI information into any well know format used to transport video and audio data, e.g., MPEG, MPEG 2, DMV, WMV, etc. The user interface associated with a session  may then be transmitted via any well known wire or wireless transports to the electronic device via a video data stream , which is capable of being processed by a video processor  on the electronic device . The electronic device  receives the video data stream  and uses its video processor  to decode the video data stream  into frame data, which is then rendered on display . The electronic device may be anyone of a set top box, DVD, network television set, digital media adapter, etc.","Example embodiments further provide for dynamically generating a video data stream  based on a determination of the capabilities of the electronic device. For example, using UPnP AV (Universal Pug-n-Play Audio Video), or any other manual or automatic way to determine and detect the presence of an electronic devise  or host computer , the capabilities of the electronic device  may be assessed by the host computer  in determining what portion of the video data stream  can support control information, e.g., command data. The capabilities determined may be any one of a central processing unit  speed, available bandwidth, sustain bandwidth, resolution of a display , color depth of the display amount of memory available, memory access speed, graphically capabilities, etc. It should further be noted that the capabilities themselves may be furthered defined to establish whether or not the control data can be sustained by the electronic device . For example, the graphical capabilities may be further assessed to determine whether the electronic device  supports alpha blending, 3D image rendering, etc.","After determining the capabilities of the electronic device , portions of the video data stream  may be processed to include control information. For example, objects associated with the user interface for session  may be sent as control information to the electronic device . The control information may be passed to the CPU , which stores the object information  in store  for future reference. Subsequently, command data can be sent in to the electronic device  for indicating how an instant of the object information  is to be manipulated on the electronic device . That is, the control information may include command data within the data stream  that includes information about sizing, a location, graphical appearance, the behavior, etc., of an instance of the object information . The CPU  on electronic device  may interpret this command data and render the object on display  as appropriate. Other UI, e.g., background and other images will still be received via the dynamically generated video data stream  in a video codec format and rendered via the video processor .","Other example embodiments provide that the dynamic conversion of at least a portion of the UI into the video data stream  is formatted by a re-sampling a resizing based on the display capabilities of the electronic device. Further, as previously mentioned, video data stream  may include an audio data stream portion.","Yet other example embodiments provide that user input may be received by the host computer  that indicates a change in one or more of the portions of the user interface. For example, a remote device  may be used to interact with the user interface shown in display  of the electronic device . When user input is received, the video data stream  may be altered in accordance with the desired user input. This user input may be received initially from the electronic device  and passed through a back channel  to the host computer . Alternative embodiments provide that the received signal for the user input may be received directly at the host computer by one or more of an inferred light, microwave, or radio waves, or any other well know means of transferring user input.","Still other example embodiments provide for the ability to render slideshow presentations on the electronic device . The present invention improves the visual quality of the slideshow displays on electronic devices, while decreasing the burden on the electronic device's 's CPU . This differs from traditional approaches in that the host computer  is generating the slideshow for the electronic device .",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 1","b":["175","190","170","105","110","194","190","115","175","130","180","120","130","140"]},"The processing may be one of taking a first image and re-sampling\/resizing the image to the appropriate target resolution, i.e., the resolution supported by the electronic device , and fed into the codec . A second image is also resampled\/resized to the target resolution and fed into the codec . Further, any transitional information, e.g., pan, zoom, fade, etc., is also fed into codec . Once the appropriate information is received, video codec  dynamically generates a video data stream , which can be sent to the electronic device  for processing similar to that described above with regards to the UI. This process is repeated throughout the slide show, or until user input is received.","Other example embodiments provide for receiving transitional information that indicates how the image data is to be visually represented at one or moments in time within the slideshow presentation. For example, remote device  may send signals to electronic device  or directly to the host computer . In the case were the signal from the remote device  is received at the host computer, command data may be sent in the video data stream  formatted as transitional information as one or more of an animate, pan, zoom, cross-fade, a playing of music, etc. Alternatively, if the command data is received from remote  at the electronic device , either the CPU  can interrupt the command data if capable, otherwise the command data may be sent through the back channel  and appropriately processed by host computer .","Other example embodiments provide that when the image data  represents a series of bitmaps, user input may be received to change the ordering or the display of the series. For example as the slideshow presentation is being displayed on display , remote device  may receive some user input indicating a change of one or more of a pause, skip stop, fast forward, reverse, etc. In such case, the video data stream  will be altered in accordance with the user input received, via the back channel , the CPU , or directly at host computer , as previously described. As with the user interface, the video data stream  for the slideshow presentation may be formatted in any standard video\/audio format, e.g., MPEG, MPEG 2, DMV, WMV, etc. Of course, other formats for generating video codec are available. Accordingly, the above examples, of video\/audio format are used for illustrative purposes only and are not meant to limit or otherwise narrow the scope of the present invention unless otherwise explicitly claimed.","In both the user interface and slideshow presentation examples described above, other exemplary embodiments provide that the control information (e.g., command data) can supersede the user interface or image data. For example, if user control information within the video data stream  is received after a portion user interface or image data is received, but before the video frame data is fully processed, the control data can be processed before the full processing of the video frame data. In other words, the present invention allows for the expedition of user input, transitional information, object rendering, etc., for enhancing the user experience.","The present invention may also be described in terms of methods comprising functional steps and\/or non-functional acts. The following is a description of steps and acts that may be preformed in practicing the present invention. Usually, functional steps describe the invention in terms of results that are accomplished where as non-functional acts describe more specific actions for achieving a particular result. Although the function steps and the non-functional acts may be described or claimed in any particular order, the present invention is not necessarily limited to any particular order or combination of acts and\/or steps. Further, the use acts and\/or steps in the recitation of the claim and in the following description of the flow charts for  are used to indicate the desired specific use of such terms.",{"@attributes":{"id":"p-0048","num":"0047"},"figref":["FIGS. 2-6","FIGS. 2-6","FIG. 1","FIG. 1"]},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 2","b":["200","200","205","105","130","130"]},"Method  also includes a functional result-oriented step for determining  the capabilities of an electronic device. Step  includes an act of receiving  information about the electronic device. For example, host computer  may receive information about the capabilities of an electronic device . The capabilities may be manually input into host computer , or automatically determined upon detection of the electronic device  by UPnP AV process. The capabilities determined may be one or more of a central processing  speed, available bandwidth, sustained bandwidth, resolution of a display , a color depth, a map of memory available, memory access speed, graphic capabilities, etc. Further, the graphic capabilities may be one or more of an alpha-blend and support for 3D image rendering.","Method  further includes a functional result-oriented step for dynamically generating  a video data stream. Step  includes an act of utilizing  a video codec. For example, host computer  may utilize video codec  for a dynamically generating video data stream  that includes image data corresponding to at least a portion of graphics for the user interface. The video data stream  may be formatted as one or an MPEG, MPEG 2, DMV, WMV, etc. format.","The video data stream  may also include control information configured to be processed by a central processing unit  in the electronic device . The control information may include object info  associated with a portion of the user interface configured to be stored  by the electronic device  for future reference. For instance, the object info  may be configured to be used in rendering portions of other UI on the electronic device . Further, the control information may include command data, which indicates how an instance of the object info  is to be manipulated on the electronic device . For example, the command data may include one or more of a sizing, location, the graphical appearance, the behavior, etc., of an instance for the object. Other embodiments provide that the object information may be configured to be used in rendering portions of other user interfaces on the electronic device .","Prior to dynamically generating the video stream, example embodiments provide that the user interface information may be formatted by one or more of a re-sampling or resizing based on the display capabilities of the electronic device. Further, the video data stream  can include audio data stream portion.","Method  also includes and act of transmitting  video data stream to the electronic device. For example, host computer  may transmit the video data stream  to the electronic device  for render the user interface, or at least a portion thereof, on a display  of the electronic devise .",{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 3","b":["300","300","320","320","305","105","130","110","130","100","320","310","105","115","110","130","320","315","105","180","120","120","130","145"]},"Method  also includes an act of transmitting  video data stream to the electronic device. For example, host computer  may transmit video data stream  to the electronic device  for appropriate processing.","Other similar capabilities as described above with regards to Method  are also available in Method . For example, the video data stream  may be formatted as one of MPEG, MPEG 2, DMV, WMV, etc. formats. Further, the electronic device  may be one or a set top box, DVD player, network television set, digital media player, etc. Moreover, UPNP AV may be used to detect the presence of the host computer , the electronic device , or both. Prior to dynamically generating the video stream, example embodiments provide that the user interface information may be formatted by one or more of a re-sampling or resizing based on the display capabilities of the electronic device. Further, the video data stream  can include audio data stream portion.","The video data stream  may also include control information configured to be processed by a central processing unit  in the electronic device . The control information may include object info  associated with a portion of the user interface configured to be stored  by the electronic device  for future reference. For instance, the object info  may be configured to be used in rendering portions of other UI on the electronic device . Further, the control information may include command data, which indicates how an instance of the object info  is to be manipulated on the electronic device . For example, the command data may include one or more of a sizing, location, the graphical appearance, the behavior, etc., of an instance for the object. Other embodiments provide that the object information may be configured to be used in rendering portions of other user interfaces on the electronic device .","In addition both Method  and  also include example embodiments for receiving user input that indicates a change in one or more portions of the user interface. In such embodiments, the video data stream  may be altered in accordance with the user input received. The user input may be received through a back channel  associated with a video stream channel used to transmit the video data stream . Alternatively, the user input may be received directly from a remote device  by conventional means such as inferred light, microwaves, radio waves, etc.",{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 4","b":["400","400","405","130","120","105","120","120","130","105","130"]},"Method  also includes an act of using  a video processor for decoding the video data screen. For example, video processor  and electronic device  may be utilized for decoding at least a portion of the video data stream  into video frame date.","Method  further includes an act of displaying  user interface as video frame data. For example, electronic device  may render on display  a portion of the user interface as video frame data.","Method  also includes an act of transmitting user input that indicates a change in one or more portions of the user interface. In such instance, an altered video data stream  may be received in accordance with the user input. The user input may be transmitted through a back channel associated with a video channel used to transmit the video data stream . The user input may be received at the electronic device  from a remote device  by one or more of inferred light waves, micro waves, radio waves, etc.","Similar to Method  and , the video data stream  in Method  may also include control information configured to be processed by a central processing unit  in the electronic device . The control information may include object info  associated with a portion of the user interface configured to be stored  by the electronic device  for future reference. For instance, the object info  may be configured to be used in rendering portions of other UI on the electronic device . Further, the control information may include command data, which indicates how an instance of the object info  is to be manipulated on the electronic device . For example, the command data may include one or more of a sizing, location, the graphical appearance, the behavior, etc., of an instance for the object. Other embodiments provide that the object information may be configured to be used in rendering portions of other user interfaces on the electronic device .",{"@attributes":{"id":"p-0065","num":"0064"},"figref":"FIG. 5","b":["500","500","520","520","505","105","130","175"]},"Step  also includes an act of opening  a session of an application. For instance, host computer  in response to the request to display a slideshow presentation at electronic device  may open a session  of application  for producing the presentation data. Further, step  further includes an act of utilizing a video codec. For example, host computer  can use video codec  for dynamically converting the slideshow presentation data, e.g., image data , transitional information, etc, into a video data stream  that represents the slideshow presentation. The video data stream  may be formatted as one of MPEG, MPEG 2, DMV, WMV, etc. formats.","Method  then includes and act of transmitting  video data stream to an electronic device. For example, host computer  after dynamically generating the slideshow presentation data into a video data stream, can transmit the video data stream to the electronic device  for rendering the slideshow presentation. The electronic device  may be one or a set top box, DVD player, network television set, digital media player, etc. Moreover, UPnP AV may be used to detect the presence of the host computer , the electronic device , or both.","Method  may also include an act of receiving command data that indicates how the image data is to be visually represented at one or more moments in time during the slideshow presentation. The command data may be received by a remote device . The command data may be one or more of an animate, pan, zoom, cross-fade, playing music, etc. In such instance, control information is generated with transitional information and included as part of the video data stream  and sent to the electronic device . The control information to be processed by the central processing unit  of the electronic device. Other embodiments provide that the translational information is part of the slideshow presentation generated by the application , and that the video data stream  includes the transitional information within the control information.","Other embodiments provide that the image data  represents a series of bitmaps, and that the Method  further includes an act of receiving user input that indicates a change in the ordering or display of the series of bitmaps. The change being one or a pause, skip, stop, fast forward, reverse, etc. In such instance, the video data stream  is altered in accordance with the user input received. The user input may be received through a back channel associated with a video stream channel used to transmit the video data stream . Alternatively, the user input may be received at the host computer  from a remote device  by one or more of inferred light waves, micro waves, radio waves, etc.",{"@attributes":{"id":"p-0070","num":"0069"},"figref":"FIG. 6","b":["600","600","605","130","120","175","105","120","130","105","130"]},"Method  may also include an act of using  a video processor for decoding video data stream. For example, electronic device  may utilize video processor  for decoding video data stream  or at least a portion thereof, into video frame data.","Method  may also include and act of displaying  slideshow presentation data. For example, electronic device  after receiving video data stream  may end decoding it, may display at least a portion of the slideshow presentation data as video frame data on display  of the electronic device. The slideshow presentation data may further include transitional information that indicates how the image data is to be visually represented at one or more moments in time during the slideshow presentation. The transitional information within the video data stream  being processed by a central processing unit  of the electronic device . The transitional information may be one or more of an animate, pan, zoom, cross-fade, playing music, etc.","Method  may also include an act of receiving command data that indicates how the image data is to be visually represented at one or more moments in time during the slideshow presentation. The command data may be received by a remote device  and processed by central processing unit  of the electronic device . The command data may be one or more of an animate, pan, zoom, cross-fade, playing music, etc.","Other embodiments provide that the image data  represents a series of bitmaps, and that the Method  further includes an act of transmitting to the host computer  the user input that indicates a change in the ordering or display of the series of bitmaps. The change being one or a pause, skip, stop, fast forward, reverse, etc. In such instance, an altered video data stream  is received in accordance with the user input received. The user input may be transmitted through a back channel associated with a video stream channel used to transmit the video data stream . Further, the user may be received at electronic device  from a remote device  by one or more of inferred light waves, micro waves, radio waves, etc.","Embodiments within the scope of the present invention also include computer-readable media for carrying or having computer-executable instructions or data structures stored thereon. Such computer-readable media can be divided into two separate categories: computer storage media and communication media. Computer storage media comprises RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage or other magnetic storage devices. Computer storage media, however, does not include signals. Communication media, on the other hand, comprises signals and the media used to transmit signals. For example, when information is transferred or provided over a network or another communications connection (either hardwired, wireless, or a combination of hardwired or wireless) to a computer, the computer properly views the connection as a communication medium. Combinations of the above should also be included within the scope of computer-readable media. Computer-executable instructions comprise, for example, instructions and data which cause a general purpose computer, special purpose computer, or special purpose processing device to perform a certain function or group of functions.",{"@attributes":{"id":"p-0076","num":"0075"},"figref":"FIG. 7"},"Those skilled in the art will appreciate that the invention may be practiced in network computing environments with many types of computer system configurations, including personal computers, hand-held devices, multi-processor systems, microprocessor-based or programmable consumer electronics, network PCs, minicomputers, mainframe computers, and the like. The invention may also be practiced in distributed computing environments where tasks are performed by local and remote processing devices that are linked (either by hardwired links, wireless links, or by a combination of hardwired or wireless links) through a communications network. In a distributed computing environment, program modules may be located in both local and remote memory storage devices.","With reference to , an exemplary system for implementing the invention includes a general purpose computing device in the form of a conventional computer , including a processing unit , a system memory , and a system bus  that couples various system components including the system memory  to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. The system memory includes read only memory (ROM)  and random access memory (RAM) . A basic input\/output system (BIOS) , containing the basic routines that help transfer information between elements within the computer , such as during start-up, may be stored in ROM .","The computer  may also include a magnetic hard disk drive  for reading from and writing to a magnetic hard disk , a magnetic disk drive  for reading from or writing to a removable magnetic disk , and an optical disk drive  for reading from or writing to removable optical disk  such as a CD-ROM or other optical media. The magnetic hard disk drive , magnetic disk drive , and optical disk drive  are connected to the system bus  by a hard disk drive interface , a magnetic disk drive-interface , and an optical drive interface , respectively. The drives and their associated computer-readable media provide nonvolatile storage of computer-executable instructions, data structures, program modules and other data for the computer . Although the exemplary environment described herein employs a magnetic hard disk , a removable magnetic disk  and a removable optical disk , other types of computer readable media for storing data can be used, including magnetic cassettes, flash memory cards, digital versatile disks, Bernoulli cartridges, RAMs, ROMs, and the like.","Program code means comprising one or more program modules may be stored on the hard disk , magnetic disk , optical disk , ROM , or RAM , including an operating system , one or more application programs , other program modules, and program data . A user may enter commands and information into the computer  through keyboard , pointing device , or other input devices (not shown), such as a microphone, joy stick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a serial port interface  coupled to the system bus . Alternatively, the input devices may be connected by other interfaces, such as a parallel port, a game port or a universal serial bus (USB). A monitor  or another display device is also connected to system bus  via an interface, such as video adapter . In addition to the monitor, personal computers typically include other peripheral output devices (not shown), such as speakers and printers.","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as remote computers and . Remote computers and may each be another personal computer, a server, a router, a network PC, a peer device or other common network node, and typically include many or all of the elements described above relative to the computer , although only memory storage devices and and their associated application programs and have been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN)  that are presented here by way of example and not limitation. Such networking environments are commonplace in office-wide or enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the local network  through a network interface or adapter . When used in a WAN networking environment, the computer  may include a modem , a wireless link, or other means for establishing communications over the wide area network , such as the Internet. The modem , which may be internal or external, is connected to the system bus  via the serial port interface . In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing communications over wide area network  may be used.","The present invention may be embodied in other specific forms without departing from its spirit or essential characteristics. The described embodiments are to be considered in all respects only as illustrative and not restrictive. The scope of the invention is, therefore, indicated by the appended claims rather than by the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["In order to describe the manner in which the above-recited and other advantages and features of the invention can be obtained, a more particular description of the invention briefly described above will be rendered by reference to specific embodiments thereof which are illustrated in the appended drawings. Understanding that these drawings depict only typical embodiments of the invention and are not therefore to be considered to be limiting of its scope, the invention will be described and explained with additional specificity and detail through the use of the accompanying drawings in which:",{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 7"}]},"DETDESC":[{},{}]}
