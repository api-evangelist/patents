---
title: Managing timeline modification and synchronization of multiple media streams in networked client/server systems
abstract: In a client/server network system, multimedia content is streamed from one or more servers to the client. The multimedia content includes multiple media streams that can be streamed to the client from the same server or from different servers. The user is able to modify the playback speed of the multimedia content, allowing the playback to be either speeded up or slowed down.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07096271&OS=07096271&RS=07096271
owner: Microsoft Corporation
number: 07096271
owner_city: Redmond
owner_country: US
publication_date: 20000329
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This is a continuation-in-part of U.S. patent application Ser. No. 09\/153,664, filed on Sep. 15, 1998, entitled \u201cMultimedia Timeline Modification in Networked Client\/Server Systems\u201d, published as U.S. Patent Application No. 20020038374 A1 on Mar. 28, 2002, now U.S. Pat. No. 6,622,171.","This invention relates to networked client\/server systems and to managing the streaming and rendering of multimedia content in such systems.","Multimedia streaming\u2014the continuous delivery of synchronized media data like video, audio, text, and animation\u2014is a critical link in the digital multimedia revolution. Today, streaming media is primarily about video and audio, but a richer, broader digital media era is emerging with a profound and growing impact on the Internet and digital broadcasting.","Synchronized media means multiple media objects that share a common timeline. Video and audio are examples of synchronized media\u2014each is a separate data stream with its own data structure, but the two data streams are played back in synchronization with each other. Virtually any media type can have a timeline. For example, an image object can change like an animated .gif file, text can change and move, and animation and digital effects happen over time. This concept of synchronizing multiple media types is gaining greater meaning and currency with the emergence of more sophisticated media composition frameworks implied by MPEG-4, Dynamic HTML, and other media playback environments.","The term \u201cstreaming\u201d is used to indicate that the data representing the various media types is provided over a network to a client computer on a real-time, as-needed basis, rather than being pre-delivered in its entirety before playback. Thus, the client computer renders streaming data as it is received from a network server, rather than waiting for an entire \u201cfile\u201d to be delivered.","The widespread availability of streaming multimedia enables a variety of informational content that was not previously available over the Internet or other computer networks. Live content is one significant example of such content. Using streaming multimedia, audio, video, or audio\/visual coverage of noteworthy events can be broadcast over the Internet as the events unfold. Similarly, television and radio stations can transmit their live content over the Internet.","Although streaming multimedia content compares favorably with more traditional paper-based content in most regards, one disadvantage is that it requires significant time for viewing. It cannot be \u201cskimmed\u201d like paper-based content. Thus, information consumers are forced to choose between the efficiency of the written word and the richness of the multimedia experience.","The invention described below addresses this disadvantage of prior art streaming multimedia content, allowing more efficient multimedia perusal of streaming multimedia presentations than has previously been possible.","In a client\/server network system, multimedia content is streamed from one or more servers to the client. The multimedia content includes multiple media streams that can be streamed to the client from the same server or from different servers. The user is able to modify the playback speed of the multimedia content, allowing the playback to be either speeded up or slowed down. According to one aspect of the invention, the multimedia content includes text streams, image, and\/or animation streams.","According to one aspect of the invention, a separate control component is included in the client and\/or the server for each individual media stream that manages the presentation of that particular media stream. An additional master control component manages the overall timeline modification for all of the streams in the multimedia content. When a user requests a new playback speed the timeline of the master control component is changed (either speeded up or slowed down) in accordance with the user's request. Each of the separate control components is made aware of this change in the master control timeline, either by the master control sending messages to the separate controls indicating the change, or by the separate controls monitoring the master control timeline. Once aware of the change in the master control timeline, each of the separate control components can adjust their timelines accordingly.","According to another aspect of the invention, the master control detects when the client\/server system will potentially be overloaded (e.g., due to a user request for a change in playback speed). This overloading can be due to requiring too much computational power on the part of the client, or on requiring too much bandwidth between the server and the client. If such an overloading condition exists, the master control takes appropriate action to avoid the overloading. Such actions include, for example, changing timescale modification for selected streams from being performed at the client to being performed at the server, reducing the quality of selected streams, pausing selected streams, etc.","General Network Structure",{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 1","FIG. 1"],"b":["102","104","106","102","104"]},"Multimedia servers  have access to streaming media content in the form of different media streams. These media streams can be individual media streams (e.g., audio, video, graphical, etc.), or alternatively composite media streams including multiple such individual streams. Some media streams might be stored as files  in a database or other file storage system, while other media streams  might be supplied to the server on a \u201clive\u201d basis from other data source components through dedicated communications channels or through the Internet itself.","The media streams received from servers  are rendered at the client computers  as a multimedia presentation, which can include media streams from one or more of the servers . These different media streams can include one or more of the same or different types of media streams. For example, a multimedia presentation may include two video streams, one audio stream, and one stream of graphical images. A user interface (UI) at the client computer  allows users to either increase or decrease the speed at which the multimedia presentation is rendered.","Streaming Media","In this discussion, streaming media refers to one or more individual media streams being transferred over a network to a client computer on an as-needed basis rather than being pre-delivered in their entirety before playback. Each of the individual media streams corresponds to and represents a different media type and each of the media streams can be rendered by a network client to produce a user-perceivable presentation using a particular presentation medium. The individual media streams can be rendered to produce a plurality of different types of user-perceivable media, including synchronized audio or sound, video graphics or motion pictures, animation, textual content, command script sequences, or other media types that convey time-varying information or content in a way that can be sensed and perceived by a human. The individual media streams have their own timelines, which are synchronized with each other so that the media streams can be rendered simultaneously for a coordinated multimedia presentation. These individual media streams can be delivered to the client computer as individual streams from one or more servers, as a composite media stream(s) from one or more servers, or a combination thereof.","In this discussion, the term \u201ccomposite media stream\u201d describes synchronized streaming data that represents a segment of multimedia content. The composite media stream has a timeline that establishes the speed at which the content is rendered. The composite media stream can be rendered to produce a plurality of different types of user-perceivable media, such as synchronized audio or sound, video graphics or motion pictures, animation, textual content, command script sequences, etc. A composite media stream includes a plurality of individual media streams representing the multimedia content.","There are various standards for streaming media content and composite media streams. The \u201cAdvanced Streaming Format\u201d (ASF) is an example of such a standard, including both accepted versions of the standard and proposed standards for future adoption. ASF specifies the way in which multimedia content is stored, streamed, and presented by the tools, servers, and clients of various multimedia vendors. ASF provides benefits such as local and network playback, extensible media types, component download, scalable media types, prioritization of streams, multiple language support, environment independence, rich inter-stream relationships, and expandability. Further details about ASF are available from Microsoft Corporation of Redmond, Wash.","Regardless of the streaming format used, an individual data stream contains a sequence of digital data units that are rendered individually, in sequence, to produce an image, sound, or some other stimuli that is perceived by a human to be continuously varying. For example, an audio data stream comprises a sequence of sample values that are converted to a pitch and volume to produce continuously varying sound. A video data stream comprises a sequence of digitally-specified graphics frames that are rendered in sequence to produce a moving picture.","For a composite media stream, the individual data streams are typically interleaved in a single sequence of data packets. Various types of data compression might be used within a particular data format to reduce communications bandwidth requirements.","The sequential data units (such as audio sample values or video frames) of the individual streams are associated with both delivery times and presentation times, relative to an arbitrary start time. The delivery time of a data unit indicates when the data unit should be delivered to a rendering client. The presentation time indicates when the value should be actually rendered. Normally, the delivery time of a data unit precedes the presentation time.","The presentation times determine the actual speed of playback. For data streams representing actual events or performances, the presentation times correspond to the relative times at which the data samples were actually recorded. The presentation times of the various different individual data streams are consistent with each other so that the streams remain coordinated and synchronized during playback.","Exemplary Computer Environment","In the discussion below, the invention will be described in the general context of computer-executable instructions, such as program modules, being executed by one or more conventional personal computers. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Moreover, those skilled in the art will appreciate that the invention may be practiced with other computer system configurations, including hand-held devices, multiprocessor systems, microprocessor-based or programmable consumer electronics, network PCs, minicomputers, mainframe computers, and the like. In a distributed computer environment, program modules may be located in both local and remote memory storage devices.","Alternatively, the invention could be implemented in hardware or a combination of hardware, software, and\/or firmware. For example, one or more application specific integrated circuits (ASICs) could be programmed to carry out the invention.",{"@attributes":{"id":"p-0039","num":"0038"},"figref":["FIG. 2","FIG. 1"],"b":["142","142","102","104"]},"Computer  includes one or more processors or processing units , a system memory , and a system bus  that couples various system components including the system memory  to processors .","The bus  represents one or more of any of several types of bus structures, including a memory bus or memory controller, a peripheral bus, an accelerated graphics port, and a processor or local bus using any of a variety of bus architectures. The system memory includes read only memory (ROM)  and random access memory (RAM) . A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between elements within computer , such as during start-up, is stored in ROM . Computer  further includes a hard disk drive  for reading from and writing to a hard disk, not shown, a magnetic disk drive  for reading from and writing to a removable magnetic disk , and an optical disk drive  for reading from or writing to a removable optical disk  such as a CD ROM or other optical media. The hard disk drive , magnetic disk drive , and optical disk drive  are connected to the system bus  by an SCSI interface  or some other appropriate interface. The drives and their associated computer-readable media provide nonvolatile storage of computer readable instructions, data structures, program modules and other data for computer . Although the exemplary environment described herein employs a hard disk, a removable magnetic disk  and a removable optical disk , it should be appreciated by those skilled in the art that other types of computer readable media which can store data that is accessible by a computer, such as magnetic cassettes, flash memory cards, digital video disks, random access memories (RAMs) read only memories (ROM), and the like, may also be used in the exemplary operating environment.","A number of program modules may be stored on the hard disk, magnetic disk , optical disk , ROM , or RAM , including an operating system , one or more application programs , other program modules , and program data . A user may enter commands and information into computer  through input devices such as keyboard  and pointing device . Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are connected to the processing unit  through an interface  that is coupled to the system bus. A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video adapter . In addition to the monitor, personal computers typically include other peripheral output devices (not shown) such as speakers and printers.","Computer  operates in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be another personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet. In the described embodiment of the invention, remote computer  executes an Internet Web browser program such as the \u201cInternet Explorer\u201d Web browser manufactured and distributed by Microsoft Corporation of Redmond, Wash.","When used in a LAN networking environment, computer  is connected to the local network  through a network interface or adapter . When used in a WAN networking environment, computer  typically includes a modem  or other means for establishing communications over the wide area network , such as the Internet. The modem , which may be internal or external, is connected to the system bus  via a serial port interface . In a networked environment, program modules depicted relative to the personal computer , or portions thereof, may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Generally, the data processors of computer  are programmed by means of instructions stored at different times in the various computer-readable storage media of the computer. Programs and operating systems are typically distributed, for example, on floppy disks or CD-ROMs. From there, they are installed or loaded into the secondary memory of a computer. At execution, they are loaded at least partially into the computer's primary electronic memory. The invention described herein includes these and other various types of computer-readable storage media when such media contain instructions or programs for implementing the steps described below in conjunction with a microprocessor or other data processor. The invention also includes the computer itself when programmed according to the methods and techniques described below. Furthermore, certain sub-components of the computer may be programmed to perform the functions and steps described below. The invention includes such sub-components when they are programmed as described. In addition, the invention described herein includes data structures, described below, as embodied on various types of memory media.","For purposes of illustration, programs and other executable program components such as the operating system are illustrated herein as discrete blocks, although it is recognized that such programs and components reside at various times in different storage components of the computer, and are executed by the data processor(s) of the computer.","Client-Based Multimedia Time-Scale Modification","As shown in , a network system in accordance with the invention includes a network server(s)  from which a plurality of media streams are available. In some cases, the media streams are actually stored by server(s) . In other cases, server(s)  obtain the media streams from other network sources or devices.","The system also includes network clients . Generally, the network clients  are responsive to user input to request media streams corresponding to selected multimedia content. In response to a request for a media stream corresponding to multimedia content, server(s)  streams the requested media streams to the network client  in accordance with some known format such as ASF. The client renders the data streams to produce the multimedia content.","A network client  also accepts a speed designation from a human user. The speed designation is a speed factor relative to the original or default playback speed of the selected multimedia content. For example, a speed factor of 1.2 indicates that the multimedia content is to be rendered at 1.2 times its original or default speed, thereby achieving time compression. A speed factor of 0.8 indicates that the multimedia content is to be rendered at 0.8 times its original or default speed, thereby achieving time expansion.","In response to the speed designation from the user, the system modifies the timelines of the individual media streams of the multimedia content, while keeping the timelines synchronized with each other and while maintaining the original pitch of any audio produced from audio streams. In one embodiment of the invention, such timeline modification is performed by the network client. In other embodiments of the invention, the timeline modification can be performed at the network server before the media streams are streamed to the network client.","Timeline modification changes the timeline of the received data streams in accordance with the user speed designation to achieve either time compression or time expansion (also referred to as \u201ctime-scale modification\u201d). With some types of media, such as video, text, and image streams, this involves omitting selected frames or modifying the presentation times of the individual data units or video frames. In other cases, such as with audio streams, the time-modification is more difficult\u2014simply changing the presentation times would alter the pitch of the original audio and make it unintelligible. Accordingly, some type of audio processing technique is used to time-compress or time-expand audio streams, while maintaining the original pitch of the audio\u2014thereby maintaining the intelligibility of the audio.","There are various known methods of audio time modification, commonly referred to as \u201ctime-scale-modification,\u201d most of which concentrate on removing redundant information from the speech signal. In a method referred to as sampling, short segments are dropped from the speech signal at regular intervals. Cross fading or smoothing between adjacent segments improves the resulting sound quality.","Another method, referred to as synchronized overlap add method (SOLA or OLA), consists of shifting the beginning of a new speech segment over the end of the preceding segment to find the point of highest cross-correlation (i.e., maximum similarity). The overlapping frames are averaged, or smoothed together, as in the sampling method.","Sampling with dichotic presentation is a variant of the sampling method that takes advantage of the auditory system's ability to integrate information from both ears. In improves on the sampling method by playing the standard sampled signal to one ear and the \u201cdiscarded\u201d material to the other ear. Intelligibility and compression increase under this dichotic presentation condition when compared with standard presentation techniques.","The methods mentioned above are considered \u201clinear\u201d because all portions of the speech signal are compressed or expanded uniformly. Other methods are considered non-linear because they non-uniformly remove portions of the time signal. One example of a non-linear time-compression method is referred to as pause removal. When using this method, a speed processing algorithm attempts to identify and remove any pauses in a recording. Either linear or non-linear time-scale modification can be used with the invention.","More information regarding audio time modification is given in an article that appeared in the March, 1997, issue of \u201cACM Transactions on Computer-Human Interaction\u201d (Volume 4, Number 1, pages 3\u201338) (1997). For purposes of this disclosure, it can be assumed that audio time modification involves some combination of changing individual data stream samples, dropping certain samples, and adjusting presentation times of any samples that are actually rendered.","Similarly, text streams can also be time-scale modified either linearly or non-linearly. Linear time-scale modification can be accomplished by speeding up or slowing down the rate at which the text data is streamed to the client and\/or rendered by the client. Non-linear time-scale modification can be accomplished by using an algorithm to summarize the text data by selecting key words, phrases, sentences or paragraphs. There are various known methods for selecting such words or portions of textual content, such as the term frequency\/inverse document frequency technique.","Time-scale modification of image streams can also be performed linearly or non-linearly. Linear time-scale modification can be accomplished by speeding up or slowing down the rate at which the image data is streamed to the client and\/or rendered by the client. Non-linear time-scale modification can be accomplished by using an algorithm to analyze the images and rank their importance relative to one another. Less important images can then be removed to time-compress the image stream. There are various known methods of determining the importance of images, such as the compressed domain shot boundary detection, pixel-based shot boundary detection, histogram-based shot boundary detection, and feature-based shot boundary detection algorithms.","Non-linear time-scale modification of image streams can also be accomplished by using progressive rendering. In progressive rendering, each image is made up of multiple layers that are streamed to the client. These layers are rendered at the client with subsequent layers being overlaid on top of previous layers, each subsequent layer providing further detail to the previous layers. The image stream can thus be time modified by removing (or adding) layers to the images.","Animation streams are similar to image streams, except that the images of an animation stream are tied to a timeline. Animation streams can be linearly or non-linearly time-scale modified. Linear time-scale modification can be accomplished by speeding up or slowing down the timeline the images in the animation stream are tied to, thereby reducing or increasing the duration that each image in the animation stream is rendered. Non-linear time-scale modification can also be accomplished using any of the techniques discussed above with reference to image streams.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":["FIG. 3","FIG. 3"],"b":["104","102","202","104","102","104","202"]},"Each media stream has a timeline, and the timelines of the individual streams are synchronized with each other so that the streams can be rendered in combination to produce coordinated multimedia content at the network client . The original timelines correspond to the original recording or rendition of the multimedia material, so that rendering the streams according to their timelines results in presentation speeds that closely match the speed of the original event or performance. In the case of audio streams, the timelines preserve the original speed and pitch of the original audio content.","The client computer has a demultiplexer component  that receives the composite media stream and that separates out the individual media streams from the composite format in which the data is streamed (such as ASF). This results in video streams  and , an audio stream , a text stream , an image stream , and an animation stream . Client  includes a different \u201ccontrol\u201d , , , , , and  for each of the media streams , , , , , and , respectively. Each of these controls is a set of instructions, executed by a processor of client , that manages the presentation of its corresponding media stream. Client  also includes a master control  that coordinates the overall presentation of the media content, as discussed in more detail below.","The individual media streams are sent to and received by respective decoders , , , , , and  that perform in accordance with the particular data format being employed. For example, the decoders might perform data decompression.","The decoded data streams are then sent to and received by respective time modification components: video timeline modification components  and , an audio timeline modification component , a text timeline modification component , an image timeline modification component , and an animation timeline modification component . These components receive input from a human operator in the form of a speed designation as described above. The timeline modification components change the timelines of the received media streams in accordance with the user speed designation to achieve either linear time compression or linear time expansion. With some types of media (e.g., with video streams, text streams, image streams, or animation streams) this involves either omitting selected portions of the streams or modifying the presentation times of the individual data units or frames of the stream. In other cases (e.g., with audio streams), some type of audio processing technique as the SOLA technique described above is used to time-compress or time-expand audio streams, while maintaining the original pitch of the audio and to also retain the intelligibility of the audio.","The timeline modification components \u2013 produce individual media streams that are provided to and received by respective renderers , , , , , and . The rendering components \u2013 render the streams in accordance with their modified timelines, as the streams continue to be streamed from the network server. In alternative embodiments of the invention, timeline modification components \u2013 might be eliminated and their functions performed by decoders \u2013.","Note that the speed designation, provided by the user, dictates the rate at which the network client consumes the composite data stream. Because of this, the client communicates the speed designation to the network server when requesting a particular media stream. The server responds by streaming the media stream at a rate that depends on or is proportional to the speed designation provided by the user. For example, for a speed factor of 2.0, the client consumes data at twice the normal rate. Accordingly, the server streams the media stream at twice its normal rate to meet the demands of the client.","In the described embodiment, the user is allowed to change the speed designation during rendering of the multimedia content. In some cases, however, it may not be possible to change the playback speed without interrupting the playback momentarily. If this is the case, playback resumes as soon as possible, beginning at a point that shortly precedes the point at which playback was discontinued. Thus, there is some overlap in the presentation\u2014when the presentation resumes, the overlap provides context for the new content that follows.",{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIG. 4","FIG. 4","FIG. 3"],"b":["104","102"]},"Multimedia content from network server  is selected for rendering at network client  (step ). In most cases, a user performs this selection from a menu of available content or via an URL (uniform resource locator) selection. In some cases, different media streams might be available for a particular content segment, varying perhaps in quality and in required bandwidth. Preferably, however, the user is unaware of anything except the simple act of selecting a single topic or composite stream.","A speed designation for the multimedia content is accepted from a human user (step ). This step is independent of the previous step of selecting the content itself. Furthermore, the user can vary the speed designation at any time during presentation of the selected content, without having to re-select the content.","The selected content is requested from the server at a speed that will satisfy the requirements of the user's speed designation (step ). Based on this request, the server identifies the particular composite media stream corresponding to the selected content (step ). The server streams this composite media stream to the client (step ). In this embodiment, the composite media stream has its original timeline, which does not necessarily result in the speed that the user has designated for playback.","The client receives the streaming content (step ) and modifies the timeline of the media stream(s) in accordance with the speed designation provided by the user (step ). As described above, this involves modifying the timelines of the individual media streams while maintaining their synchronization and intelligibility. The composite media stream is then rendered in accordance with its modified timeline (step ).","Server-Based Multimedia Time-Scale Modification","In various embodiments of the invention, modifying the timeline of the requested multimedia content can be performed dynamically (or \u201con the fly\u201d) in the client as described above, in the server, or in both the client and server. In embodiments where the timeline modification for a stream is carried out at the server the time modification component \u2013 of  for that stream need not be included in client . Rather, components \u2013 would be included in the corresponding server that is providing the stream. Additionally, modifying the timeline of different streams for requested multimedia content can be performed in different locations for different streams. For example, audio and video timeline modification may be performed at the server, while image, animation, and text timeline modification may be performed at the client. However, in the network environment, it is often desirable to avoid performing any significant timeline modification in the server. Otherwise, the server could quickly become overloaded with requests from multiple clients.","Alternatively, in some cases it may be desirable to store multiple versions of media streams at a server and to select particular versions of the media streams depending on the timeline requirements of the client, as designated by the user. One advantage of this method is that it can require comparatively less communications bandwidth between the server and client.","As a general example, a server might store a plurality of media streams having timelines modified by different factors. When a client requests a composite media stream, the server selects the version of the media stream whose timeline most closely accords with the speed designation set by the user. If the timeline does not exactly match the speed designation, the client can perform further timeline modification.",{"@attributes":{"id":"p-0077","num":"0076"},"figref":["FIG. 5","FIG. 5"],"b":["302","304","306"]},"The various individual data streams have timelines that are modified by different degrees. The speed factors are indicated in . In this embodiment, the audio, video, text, and image streams are organized as sets, each set forming a composite media stream having a timeline that has been modified by a factor of 0.5, 1.0, or 1.5.","When a client  requests multimedia content from server , the client  identifies both the content and the speed factor. In response, the server selects the audio, video, image, and text streams that have timelines most closely approximating the identified speed factor, and combines those individual media streams to form the composite media stream. The resulting composite media stream is then sent to the client. When the timeline is accelerated, this saves bandwidth in comparison to sending an unaltered composite media stream having a higher streaming rate to meet the accelerated consumption demands of the client.","As a further optimization, the server can store composite media streams having different degrees of timeline modification and different degrees of quality. Generally, a media stream of a lower quality will consume less communications bandwidth than a media stream of a higher quality. Before selecting an appropriate media stream, the server determines the available bandwidth between the server and the client. It then selects a combination of individual media streams that provides the best quality while requiring no more than the available bandwidth.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 6","b":["310","312","314","316","318","320"]},"When a client  requests the multimedia content from server , the server determines or notes both the speed factor designated by the user and the available bandwidth. It then selects the video stream that has best available quality while also requiring no more bandwidth (at the requested speed factor) than the difference between the available bandwidth and the bandwidth consumed by the selected audio stream. Again, this allows the system to compensate for various available bandwidths.",{"@attributes":{"id":"p-0083","num":"0082"},"figref":"FIG. 7","b":["328","330","332","334"]},"When a client  requests the multimedia content from server , the server determines or notes both the speed factor designated by the user and the available bandwidth. It then selects a text stream that most closely accords with the specified speed factor. It then selects the image stream that has best available quality while also requiring no more bandwidth than the difference between the available bandwidth and the bandwidth consumed by the selected text stream. Again, this allows the system to compensate for various available bandwidths.",{"@attributes":{"id":"p-0085","num":"0084"},"figref":"FIG. 8","b":["340","342","344","346"]},"At a normal, unaltered playback rate, assume the text stream utilizes a bandwidth of 16 Kbps (kilobits per second), the low bandwidth image streams require a bandwidth of 20 Kbps, and while the high bandwidth image streams require a bandwidth of 40 Kbps. Now, suppose that a client requests the multimedia content over a communications channel having a bandwidth of 56 Kbps, at a speed factor of 2.0. At this speed factor, the client consumes text data at twice the normal rate, which in this case is 32 Kbps. That leaves 24 Kbps of available bandwidth. Accordingly, the server selects the low bandwidth image stream with the timeline modified by a factor of 2.0, and combines it with the text stream to form a composite media stream for streaming to the client. The total required communications bandwidth is 52 Kbps, which is within the limits of the available bandwidth.","Although the example given with reference to  is relatively specific, this method of bandwidth utilization can be generalized to include other types of media streams with each stream being assigned a priority.","Furthermore, a stream can sometimes be timeline-modified dynamically at the server without incurring significant overhead. Accordingly, the server can adjust the timeline and quality of the stream dynamically to match the available bandwidth, eliminating the need to store multiple streams of the same content at the server. As an example of a situation where this might be easily accomplished, an MPEG (Motion Picture Expert Group) video stream contains independent frames and several levels of dependent frames. One easy way to reduce bandwidth is to simply drop lower-level dependent frames from the video stream.","Additionally, although  illustrate the streaming of all media streams for particular multimedia content from a single server, the streams can alternatively be streamed from multiple servers. Thus, rather than streaming a composite stream from a single server that includes all the data streams for a particular multimedia presentation, the individual streams can be received from different servers. Additionally, multiple composite streams can be received from different servers, such as a composite stream from one server including image and text data streams, and another composite stream from another server including audio and video data streams. Additional communication between servers or between the client and servers may be required when multiple servers are streaming the data for particular multimedia content. For example, the text stream and corresponding required bandwidth selected by one server (or the client) can be communicated to the other server(s) to allow the other server(s) to determine the amount of available bandwidth.","Stream Synchronization","Media content can be provided to the client  of  from one or more servers  as discussed above. Different time-scale modification techniques can be used for each of the different streams. For example, video() time modification component  of  may use a non-linear compression algorithm, while video() time modification component  may use a linear compression algorithm. Additionally, time-scale modification for some streams may be carried out at client  and time-scale modification for other streams may be carried out at the server.","Master control  of  coordinates the time-scale modification of all the streams in the multimedia content. Master control  receives user requests for changes in the playback speed of the multimedia content. Such changes are communicated to the individual stream controls \u2013 or to the server(s) that are providing the time-scale modification (whether it be dynamically modified or pre-stored streams) for the individual stream(s). Alternatively, the coordination provided by master control  can be distributed partly or wholly throughout controls \u2013, thereby embedding the coordination of presenting a stream wholly or partly in the control of that stream.","When master control  receives a user request for a new playback speed for the multimedia content, master control  sends a message to each of the individual stream controls \u2013 of the new playback speed. This message is used by the corresponding time modification components \u2013 (whether they be located in the client  or server ) to change the time-scale modification being performed to the new playback speed.","In an alternate embodiment, master control  does not send such messages to the individual stream controls \u2013. Rather, master control  maintains a presentation clock referred to as the \u201cmaster clock\u201d. Each of the individual stream controls \u2013 maintains its own clock, referred to as a \u201cslave clock\u201d, that the respective controls \u2013 synchronize with the master clock. The controls \u2013 monitor the master clock and keep their slave clocks in pace with the master clock, speeding up or slowing down their respective slave clocks as the master clock speeds up or slows down.","By maintaining a master clock and slave clock relationship, each of the controls \u2013 is alleviated of the burden of providing \u201celegant\u201d time-scale modification. That is, some of the controls \u2013 may not have the ability to speed up or slow down the rate at which the media stream is rendered, remove less important portions of the media stream, etc. Rather, these controls may merely be able to detect when they are out of synchronization with the master clock and either jump ahead in their rendering or temporarily pause their rendering until they are re-synchronized.","Master control  may also perform additional monitoring of the multimedia content and alter the time-scale modification being performed based on available bandwidth between the server and client and\/or based on the processing capabilities of the client.",{"@attributes":{"id":"p-0096","num":"0095"},"figref":["FIG. 9","FIG. 9","FIG. 9","FIG. 3"],"b":"230"},"Master control  monitors the usage of both the bandwidth between server  and client  and the processing capabilities of client  (step ). Master control  can be either pre-programmed or dynamically programmed with the server to client bandwidth devoted to streaming the multimedia content and the processing capabilities of client  devoted to playing back the multimedia content. Master control  compares these programmed values to the current bandwidth and processing usage to determine whether to make an alteration in a stream(s). The monitoring of step  can be performed continually, or alternatively in response to certain events (such as a new playback speed being requested by the user).","The monitored and programmed values are used to determine whether the bandwidth allotted to streaming the data or the processing capacity has been exceeded (step ). Such changes can result, for example, due to a user request for a faster playback speed, or a reduction in the amount of bandwidth or processing capacity that can be devoted to streaming or playing back of the multimedia content.","If the allotted bandwidth or processing capacity has been exceeded, then master control  selects a stream(s) to be altered (step ). The selection of stream(s) can be accomplished in a variety of manners. An ordered list can be provided to the master control (e.g., generated by the author of master control , by the author of the multimedia content or the user of client ) that identifies the order in which streams are to be selected. Alternatively, each stream may be given a priority ranking and this priority ranking used by master control  to determine which stream to select for alteration (e.g., the lowest priority stream).","Master control also alters the selected stream(s) to conform to the current bandwidth and processing capacity requirements (step ). In the illustrated example this alteration includes one or more of transferring time-scale modification for a selected stream(s) from client  to server , reducing the quality of the selected stream(s), or pausing a selected stream(s). Which of these actions is to be performed by master control can be determined by a set of rules programmed into master control . These rules can be generated by, for example, the author of master control , the author of the multimedia content, or the user of client . For example, the rules may indicate that all streams should continue to be played back regardless of the quality reduction of the selected streams, the rules may indicate that time-modification of only certain streams can be transferred to the client, the rules may indicate that audio or text streams should be paused rather than reducing the quality of any of the other streams, etc. Master control  sends messages to the appropriate individual stream controls as well as the appropriate servers to change the quality of a stream, pause a stream, or transfer time-scale modification processing from the local stream control to the server.","Returning to step , master control  also checks whether there is excess bandwidth or processing capacity that it can use (step ). Such excess bandwidth or processing capacity can arise, for example, due to a reduction in the playback speed of the multimedia content or extra capacity or bandwidth being devoted to streaming or playback of the multimedia content. If such excess bandwidth or processing capacity is detected, master control  selects a stream(s) to alter (step ). This selection process is analogous to that of step , except that the ordering of streams may be \u201creversed\u201d. For example, higher priority streams may be selected for improved quality due to the excess bandwidth or processing capacity. Alternatively, master control  may select the same streams that were previously selected for alteration in step .","Master control  also alters the selected stream(s) to take advantage of the excess bandwidth or processing capacity. This alteration is analogous to that of step , or alternatively may be to \u201cundo\u201d whatever alteration was previously performed for the stream in step . In making the selection and alteration in steps  and , master control  compares the bandwidth and processing capacities of the proposed alteration to the excess bandwidth or processing capacity to verify that neither the bandwidth nor the processing capacity devoted to the multimedia content is exceeded. For example, excess processing capacity at client  may be available, but the first alteration that master control  would want to make may exceed the bandwidth constraints and therefore cannot be carried out. Thus, master control  tests another alteration. If no alteration can be made that violates neither the bandwidth nor the processing capacities, then no alteration is made.","The operation of master control  in altering the streaming and the time-scale modification of the multimedia content is further illustrated in the following example. Assume that the bandwidth devoted to multimedia content is 150 Kbps and that the multimedia content includes two video streams, an image stream, an audio stream, and a text stream. Further assume that the time-scale modification of each of the video streams is performed at the client, that the time-scale modification of the image, audio, and text streams is performed at the server, and that at a speedup factor of 1.0, the video streams each require 30 Kbps, the image and audio streams each require 20 Kbps, and the text stream requires 10 Kbps. At the speedup factor of 1.0, the streams require only 110 Kbps of the available 150 Kbps of bandwidth. If the playback speed is increased to a speedup factor of 1.5, the video streams would require 45 Kbps of bandwidth to be time-compressed at the client, while the image and audio streams would still require 20 Kbps and the text stream 10 Kbps as these streams are being time-compressed at the server. At the speedup factor of 1.5, the streams require only 140 Kbps of the available 150 Kbps of bandwidth. However, if the speedup factor were to be increased to 2.0, then the video streams would require 60 Kbps while the image, audio, and text streams would require 20 Kbps, 20 Kbps, and 10 Kbps, respectively. The streams would require a total of 170 Kbps, which is not available. Thus, the master control would select and alter at least one of the streams, such as selecting one of the video streams for time-scale modification at the server (which would reduce the bandwidth requirements to 140 Kbps), or pause the text stream so it is no longer being streamed (which would reduce the bandwidth requirements to 150 Kbps).","Timeline Correlation","When the playback speed of the multimedia content is altered by the user, the playback of the multimedia content should continue in a relatively uninterrupted manner, albeit at the new playback speed. For example, suppose a user changes the playback speed from a speedup factor of 1.0 to a speedup factor of 1.5. The playback of the multimedia content should continue at approximately the location where the playback speed change was requested by the user rather than beginning playback at the beginning of the multimedia content at the new playback speed.","If timeline modification is performed at the client or is performed dynamically at the server, then the client or server can begin timeline modification when the user request is received. As the timeline modification is being performed \u201con the fly\u201d on the same underlying data stream, difficulties in maintaining timeline correlation typically do not arise.","However, in situations where multiple versions of a media stream are stored at a server (e.g., as discussed above with reference to ), timeline correlation problems can arise. In order for the server to switch from one data stream to another (corresponding to the new playback speed), the correct location in the new stream to begin streaming needs to be determined.","In order to make such determinations, one of the versions of a particular data stream (e.g., one of the video streams  of ) is referred to as a primary or reference version of the media stream. A primary media stream normally has a timeline that has not been altered. The remaining versions of the data stream stored by the server are media streams having timelines that have been altered in accordance with linear and\/or non-linear techniques.","There is a known timeline correlation between the data units of the various media streams. The term \u201ctimeline correlation\u201d as used herein refers to a correlation in content between two streams that differ in the degree and\/or manner in which their timelines have been modified. Thus, a playback point one minute into an unaltered timeline correlates to a point thirty seconds into a timeline that has been linearly altered by a factor of 2.0 (accelerated to twice the speed of the original). More generally, the point in the new timeline equals oldtime(oldfactor\/newfactor), where oldtime is the presentation time in the first media stream at which the speed change is to occur, oldfactor is the playback speed or factor of the old media stream, and newfactor is the playback speed or factor of the new media stream.","When non-linear timeline alteration is involved, the correlation between streams cannot be calculated in this manner. In the illustrated example, the timeline correlations are compiled and stored as the non-linear compression is performed (step ). The stored data is then referenced by the system when it becomes necessary to find content in one stream corresponding to the same content in another stream.","Specifically, the server stores one or more sets of timeline correlations between the timelines of the primary and timeline-altered media streams. These sets of correlations are arranged to allow each cross-referencing between the various streams. For example, one set of correlations contains mappings from presentation times of the primary media stream to timeline-correlated presentation times of the timeline-altered media streams. Other sets of correlations correspond to individual ones of the time-altered media streams. Each of these sets contains mappings from presentation times of the corresponding timeline-altered media stream to correlated presentation times of the primary media stream.",{"@attributes":{"id":"p-0111","num":"0110"},"figref":["FIG. 10","FIG. 10"],"b":["370","372","374"]},"Also shown in  are reference tables or data objects corresponding to the media streams. Table , associated with primary media stream , is a cross-reference containing mappings from presentation times of the primary media stream to timeline-correlated presentation times of the first and second media streams. Table  is indexed by presentation times of the primary media stream. Thus, for any given presentation time of the primary media stream, it is possible to quickly find a corresponding or timeline-correlated presentation time in either of the two timeline-altered media streams.","By itself, table  is useful when switching from primary media stream  to one of the timeline-altered media streams  and . To transition, for instance, from the primary media stream to the first timeline-altered media stream, the current presentation time of the primary media stream is noted. This presentation time is used as an index into table  to find the correlated presentation time in the first media stream. The first media stream is then initiated at the correlated time as found in the table.","Further tables or data objects  and  are associated respectively with first and second timeline-altered media streams  and , and are used as back-references to the primary media stream. Each of these tables is indexed by the presentation times of its associated media stream, to find timeline-correlated presentation times in the primary media stream.","The tables or data objects can be stored and referenced by server . Alternatively, they can be stored by server  and downloaded to client  as needed. As a further alternative, the data objects with the timeline-altered media streams can be provided with individual data units of the timeline-altered media streams. In accordance with this further alternative, each data unit is accompanied by a presentation time at which the data unit is to be rendered, and also by a reference presentation time, where the reference presentation time indicates a presentation time in the primary reference stream that corresponds to the presentation time of the data unit in the timeline-altered media stream. This reference presentation time is then used to index table  associated with primary stream .",{"@attributes":{"id":"p-0116","num":"0115"},"figref":["FIG. 11","FIG. 11","FIG. 11","FIG. 10"]},"Playback of the first media stream is initially stopped at a particular presentation time of the first media stream (step ). A stored table or cross-reference  is referenced to determine a presentation time of the primary media stream that has a timeline correlation with the particular presentation time at which playback of the first media stream was stopped (step ). A table  of primary media stream  is then referred to in order to determine a presentation time of the second media stream that has a timeline correlation with the determined presentation time of the primary media stream (step ). Playback of the second media stream is then initiated at a point in the second media stream having a presentation time that is no greater than the determined presentation time (step ). In the described embodiment of the invention, playback is initiated somewhat prior to the determined presentation time, thus providing a short overlap in the rendered content to provide context when initiating the second timeline-altered media stream in midstream.","The referencing steps are illustrated in . An arrow from the reference table  of first media stream  indicates that the table  is used to find a time-correlated presentation time in the primary media stream. This value is used to index table  of primary stream  to find a timeline-correlated presentation time in second media stream .","User Experience","The functionality described above is exposed through an application program executed at network client , referred to herein as a streaming multimedia player. The streaming multimedia player may be incorporated into the operating system or run as a separate, self-contained application. In either case, the streaming multimedia player operates in a graphical user interface windowing environment such as provided by the \u201cWindows\u201d brand of operating systems, available from Microsoft Corporation of Redmond, Wash.",{"@attributes":{"id":"p-0120","num":"0119"},"figref":"FIG. 12","b":["400","400","402","404","406","408","410","402"]},"Media screen  is the region of the UI within which the visual media stream(s) is rendered. For video, image, animation, and text streams, the underlying video, images, animations, and text are displayed on screen . Each of these streams can be displayed in a different portion of the screen  (alternatively, one or more of the portions may be overlapped by another portion).","Shuttle controls  enable the user to control play of the multimedia content. Shuttle controls  include multiple play buttons (), (), and (), a stop button , a pause button , rewind buttons  and , and fast forward buttons  and .","Play buttons ()\u2013() are associated with different playback speeds of the multimedia content. In this illustration, play button () corresponds to a normal playback speed (i.e., \u201c\u00d71.0\u201d), play button () corresponds to a faster playback speed with a speed up factor of 25% (i.e., \u201c\u00d71.25\u201d), and play button () corresponds to an even faster playback speed with a speed up factor of 50% (i.e., \u201c\u00d71.50\u201d). It is noted, however, that more or less than three buttons may be used (e.g., two, four, five, etc.) and may correspond to speeds both above and below the normalized speed of \u201c\u00d71.0\u201d.","The user can actuate one of the play buttons via a UI actuation mechanism, such as a pointer  or by tabbing to the desired play button and hitting the \u201center\u201d key. Upon selection of a play button, the multimedia player plays the multimedia content at the playback speed associated with the selected play button. For instance, if the user selects play button () with a 25% speedup factor, the multimedia player plays the content at a playback speed of 1.25 times the original or default playback speed.","Once the multimedia content is playing at one speed, the user is free to select a new speed by actuating another of the play buttons ()\u2013(). Suppose the user decides to slow the content back to normal speed. The user can actuate the \u201c\u00d71.0\u201d play button () to return the media content to the normal speed. In response to speed changes, the multimedia player is configured to repeat a portion of the multimedia content at the new speed.","Content information space  lists information pertaining to the multimedia content being rendered on the media screen . The content information space includes the show name, author and copyright information, and tracking\/timing data.",{"@attributes":{"id":"p-0127","num":"0126"},"figref":["FIG. 13","FIG. 11"],"b":["440","400","440","402","404","406","408","410","442","442"]},"UI  has a scale mechanism  to vary the speed of the content during rendering. The scale mechanism has a range of playback speeds , which in this example range from 0.5\u00d7 to 2.5\u00d7 the normal speed. Scale mechanism  also has a movable slider  that is movable over the range . The user can position the slider  at the desired speed at which the multimedia player is to play the multimedia content.","In the  illustration, range  is a continuous range from a high playback speed (i.e., 2.5\u00d7) to a low playback speed (i.e., 0.5\u00d7). Slider  moves continuously over the range. In other implementations, range  is a discrete range of discrete playback speeds (e.g., 0.5\u00d7, 1.0\u00d7, 1.5\u00d7, 2.0\u00d7, and 2.5\u00d7) and the slider is movable among the discrete playback speeds.","Once the multimedia content is playing at one speed, the user is free to select a new speed by moving the slider  to a new speed. In response to use manipulation of the scale mechanism, the multimedia player repeats a portion of the multimedia content and begins playing at the new speed.",{"@attributes":{"id":"p-0131","num":"0130"},"figref":"FIG. 14","b":["460","460","462","460","464","464","466","464","426","462"]},"Menu  lists multiple playback speeds from which a user can select. In the illustrated example, five playback speeds are listed: \u00d70.5, \u00d70.75, \u00d71.0, \u00d71.25, and \u00d71.5. The user can select one of the listed speeds to instruct the multimedia player to play the multimedia content at a desired speed. As noted above, the user can select a new speed after the content has begun playing by invoking the menu and selecting the new speed. In response, the multimedia player repeats a portion of the multimedia content and begins playing at the new speed.","Although the invention has been described in language specific to structural features and\/or methodological steps, it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or steps described. Rather, the specific features and steps are disclosed as preferred forms of implementing the claimed invention."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 14"}]},"DETDESC":[{},{}]}
