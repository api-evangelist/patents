---
title: Synthesizer multi-bus component
abstract: An audio generation system produces streams of audio wave data and routes the audio wave data to audio buffers via logic buses that correspond respectively to the audio buffers. A logic bus, or buses, are assigned to an audio wave data source. Additionally, a logic bus corresponds to an audio buffer. Thus, any streams of audio wave data generated by the audio wave data source are routed to the audio buffer corresponding to the logic bus. A logic bus can receive streams of audio wave data from multiple sources, and route the multiple audio wave data streams to an audio buffer. Additionally, an audio buffer can receive streams of audio wave data from multiple logic buses.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07089068&OS=07089068&RS=07089068
owner: Microsoft Corporation
number: 07089068
owner_city: Redmond
owner_country: US
publication_date: 20010307
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["RELATED APPLICATIONS","TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","CONCLUSION"],"p":["This application is related to a concurrently-filed U.S. Patent Application entitled \u201cAudio Generation System Manager\u201d, to Todor Fay and Brian Schmidt, which is identified as Ser. No. 09\/801,922, the disclosure of which is incorporated by reference herein.","This application is also related to a concurrently-filed U.S. Patent Application entitled \u201cAccessing Audio Processing Components in an Audio Generation System\u201d, to Todor Fay and Brian Schmidt, which is identified as Ser. No. 09\/801,938, the disclosure of which is incorporated by reference herein.","This application is also related to a concurrently-filed U.S. Patent Application entitled \u201cDynamic Channel Allocation in a Synthesizer Component\u201d, to Todor Fay, which is identified as Ser. No. 09\/802,323, the disclosure of which is incorporated by reference herein.","This invention relates to audio processing and, in particular, to interfacing a synthesizer component with audio buffer components.","Multimedia programs present data to a user through both audio and video events while a user interacts with a program via a keyboard, joystick, or other interactive input device. A user associates elements and occurrences of a video presentation with the associated audio representation. A common implementation is to associate audio with movement of characters or objects in a video game. When a new character or object appears, the audio associated with that entity is incorporated into the overall presentation for a more dynamic representation of the video presentation.","Audio representation is an essential component of electronic and multimedia products such as computer based and stand-alone video games, computer-based slide show presentations, computer animation, and other similar products and applications. As a result, audio generating devices and components are integrated with electronic and multimedia products for composing and providing graphically associated audio representations. These audio representations can be dynamically generated and varied in response to various input parameters, real-time events, and conditions. Thus, a user can experience the sensation of live audio or musical accompaniment with a multimedia experience.","Conventionally, computer audio is produced in one of two fundamentally different ways. One way is to reproduce an audio waveform from a digital sample of an audio source which is typically stored in a wave file (i.e., a .wav file). A digital sample can reproduce any sound, and the output is very similar on all sound cards, or similar computer audio rendering devices. However, a file of digital samples consumes a substantial amount of memory and resources for streaming the audio content. As a result, the variety of audio samples that can be provided using this approach is limited. Another disadvantage of this approach is that the stored digital samples cannot be easily varied.","Another way to produce computer audio is to synthesize musical instrument sounds, typically in response to instructions in a Musical Instrument Digital Interface (MIDI) file. MIDI is a protocol for recording and playing back music and audio on digital synthesizers incorporated with computer sound cards. Rather than representing musical sound directly, MIDI transmits information and instructions about how music is produced. The MIDI command set includes note-on, note-off, key velocity, pitch bend, and other methods of controlling a synthesizer.","The audio sound waves produced with a synthesizer are those already stored in a wavetable in the receiving instrument or sound card. A wavetable is a table of stored sound waves that are digitized samples of actual recorded sound. A wavetable can be stored in read-only memory (ROM) on a sound card chip, or provided with software. Prestoring sound waveforms in a lookup table improves rendered audio quality and throughput. An advantage of MIDI files is that they are compact and require few audio streaming resources, but the output is limited to the number of instruments available in the designated General MIDI set and in the synthesizer, and may sound very different on different computer systems.","MIDI instructions sent from one device to another indicate actions to be taken by the controlled device, such as identifying a musical instrument (e.g., piano, flute, drums, etc.) for music generation, turning on a note, and\/or altering a parameter in order to generate or control a sound. In this way, MIDI instructions control the generation of sound by remote instruments without the MIDI control instructions carrying sound or digitized information. A MIDI sequencer stores, edits, and coordinates the MIDI information and instructions. A synthesizer connected to a sequencer generates audio based on the MIDI information and instructions received from the sequencer. Many sounds and sound effects are a combination of multiple simple sounds generated in response to the MIDI instructions.","A MIDI system allows audio and music to be represented with only a few digital samples rather than converting an analog signal to many digital samples. The MIDI standard supports different channels that can each simultaneously provide an output of audio sound wave data. There are sixteen defined MIDI channels, meaning that no more than sixteen instruments can be playing at one time. Typically, the command input for each channel represents the notes corresponding to an instrument. However, MIDI instructions can program a channel to be a particular instrument. Once programmed, the note instructions for a channel will be played or recorded as the instrument for which the channel has been programmed. During a particular piece of music, a channel can be dynamically reprogrammed to be a different instrument.","A Downloadable Sounds (DLS) standard published by the MIDI Manufacturers Association allows wavetable synthesis to be based on digital samples of audio content provided at run time rather than stored in memory. The data describing an instrument can be downloaded to a synthesizer and then played like any other MIDI instrument. Because DLS data can be distributed as part of an application, developers can be sure that the audio content will be delivered uniformly on all computer systems. Moreover, developers are not limited in their choice of instruments.","A DLS instrument is created from one or more digital samples, typically representing single pitches, which are then modified by a synthesizer to create other pitches. Multiple samples are used to make an instrument sound realistic over a wide range of pitches. DLS instruments respond to MIDI instructions and commands just like other MIDI instruments. However, a DLS instrument does not have to belong to the General MIDI set or represent a musical instrument at all. Any sound, such as a fragment of speech or a fully composed measure of music, can be associated with a DLS instrument.","Conventional Audio and Music System",{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 1","b":["100","100","102","104"]},"The audio system  includes a synthesizer  having a synthesizer channel . Typically, a synthesizer is implemented in computer software, in hardware as part of a computer's internal sound card, or as an external device such as a MIDI keyboard or module. The synthesizer channel  is an audio data or communications path that represents a destination for a MIDI instruction. The channel  has a left and right audio data output, and a reverb audio data output. The reverb output is input to a reverb component , and the left and right audio data outputs are input to a left or right input component  and , respectively. The output of the reverb  is a stereo pair that is also input to the left or right input component  and , respectively. The synthesizer output  is a stereo pair that is input to a mixing component .","A MIDI instruction, such as a \u201cnote-on\u201d, directs a synthesizer  to play a particular note, or notes, on a synthesizer channel  having a designated instrument. The General MIDI standard defines standard sounds that can be combined and mapped into the sixteen separate instrument and sound channels. A MIDI event on a synthesizer channel corresponds to a particular sound and can represent a keyboard key stroke, for example. The \u201cnote-on\u201d MIDI instruction can be generated with a keyboard when a key is pressed and the \u201cnote-on\u201d instruction is sent to synthesizer . When the key on the keyboard is released, a corresponding \u201cnote-off\u201d instruction is sent to stop the generation of the sound corresponding to the keyboard key.","The audio system  includes a buffer component  that has multiple buffers ( . . . n). The output of the mixing component  associated with synthesizer channels  is input to one buffer () in the buffer component . A buffer in this instance is typically an allocated area of memory that temporarily holds sequential samples of audio data that will be subsequently delivered to an audio rendering device such as a speaker.","An application program typically communicates with synthesizer  via some type of dedicated communication interface, commonly referred to as an API. In the audio system , an application program delivers audio content or other music events to the synthesizer . The audio content and music events are represented as data structures containing information about the audio content and music events such as pitch, relative volume, duration, and the like. Audio events are message-based data, such as MIDI files or musical segments, authored with an external device.","Sound effects can be implemented with a synthesizer, but the output is constrained to the stereo pair . For music generation, only having the ability to process audio in a synthesizer can be sufficient. In an audio system that supports both music and sound effects, however, a single output pair input to one buffer is a limitation to creating and enhancing the sound effects.","An audio generation system produces streams of audio wave data and routes the audio wave data to audio buffers. The audio wave data is routed to the audio buffers via logic buses that correspond respectively to the audio buffers. A synthesizer, multiple synthesizers, and\/or other streaming audio data sources produce the streams of audio wave data.","An audio buffer has one or more corresponding logic buses that route the audio wave data to the buffer. Each logic bus is assigned, or designated, to receive audio wave data from a source. When the source produces streams of audio wave data, the data is input to the assigned or designated logic buses.","A logic bus receives the audio wave data and routes it to the audio buffer corresponding to the logic bus. A logic bus can receive streams of audio wave data from multiple sources, and route the multiple audio wave data streams to an audio buffer. Additionally, an audio buffer can receive streams of audio wave data from multiple logic buses.","The following description describes systems and methods to manage and route streams of audio wave data in an audio processing system. Audio wave data can be stored as a resource or generated by a synthesizer. Buffers receive and store the streams of audio wave data until it is recalled and processed or delivered to an audio rendering device such as a speaker. A multi-bus component is instantiated to route the streams of audio wave data generated by a synthesizer, or synthesizers, to the buffers. The configuration of the multi-bus component allows a stream of audio data output from a synthesizer to be routed to any number of buffers.","Exemplary Audio Generation System",{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 2","b":"200"},"Audio generation system  includes an application program , audio sources , and an audio processing system . Application program  is one of a variety of different types of applications, such as a video game program, some other type of entertainment program, or an application that incorporates an audio representation with a video presentation.","Audio sources  supply digital samples of audio data such as from a wave file (i.e., a .wav file), message-based data such as from a MIDI file or a preauthored segment file, or an audio sample such as a Downloadable Sound (DLS). Although not shown, the audio sources  can be stored in the application program  as a resource rather than in a separate file.","Application program  initiates that an audio source  be loaded and processed by the audio processing system . The application program  interfaces with the other components of the audio generation system  via application programming interfaces (APIs). The various components described herein are implemented using standard programming techniques, including the use of OLE (object linking and embedding) and COM (component object model) interfaces. COM objects are implemented in a system memory of a computing device, each object having one or more interfaces, and each interface having one or more methods. The interfaces and interface methods can be called by application programs and by other objects. The interface methods of the objects are executed by a processing unit of the computing device. Familiarity with object-based programming, and with COM objects in particular, is assumed throughout this disclosure. However, those skilled in the art will recognize that the audio generation systems and the various components described herein are not limited to a COM and\/or OLE implementation, or to any other specific programming technique.","The audio processing system  converts an audio source  to a MIDI message format. Additional information regarding the audio data processing components described herein can be found in the concurrently-filed U.S. Patent Application entitled \u201cAudio Generation System Manager\u201d, which is incorporated by reference above. However, any audio processing system can be used to produce audio instructions for input to the audio generation system components.","The audio generation system  includes a synthesizer component , a multi-bus component , and audio buffers . Synthesizer component  receives formatted MIDI messages from the audio processing system  and generates sound waveforms that can be played by a sound card, for example. The audio buffers  receive the audio wave data (i.e., sound waveforms) generated by the synthesizer  and streams the audio wave data in real-time to an audio rendering device. An audio buffer  can be designated in hardware or in software.","The multi-bus component  routes the audio wave data from the synthesizer component  to the audio buffers . The multi-bus component  is implemented to represent actual studio audio mixing. In a studio, various audio sources such as instruments, vocals, and the like (which can also be outputs of a synthesizer) are input to a multi-channel mixing board that then routes the audio through various effects (e.g., audio processors), and then mixes the audio into the two channels that are a stereo signal. Additional information regarding the audio data processing components described herein can be found in the concurrently-filed U.S. Patent Application entitled \u201cDynamic Channel Allocation in a Synthesizer Component\u201d, which is incorporated by reference above.","Exemplary Synthesizer Multi-Bus Component",{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 3","b":["200","208","300","1","12","300","208"]},"The synthesizer channels  are grouped into channel sets (-) according to the destination of the audio wave data that is output from each channel . Each channel set  has a channel designator  to identify the channels  corresponding to a particular channel set  within the synthesizer . Channel set () includes synthesizer channels (-), channel set () includes synthesizer channels (-), and channel set () includes synthesizer channels (-).","Multi-bus component  has multiple logical buses (-). A logical bus  is a logic connection or data communication path for audio wave data. Each logical bus  has a corresponding bus identifier (busID)  that uniquely identifies a particular logical bus. The logical buses  are configured to receive audio wave data from the synthesizer channels  and route the audio wave data to audio buffers component .","The audio buffers component  includes three buffers (-) that are consumers of the audio wave data. The audio buffers  receive audio wave data output from the logical buses  in the multi-bus component . An audio buffer  receives an input of audio wave data from one or more logical buses , and streams the audio wave data in real-time to a sound card or similar audio rendering device. Alternatively, an audio buffer  can process the audio wave data input with various effects-processing components (i.e., audio processing components) that corresponds to a designated function of a particular audio buffer  before sending the audio data to be further processed and\/or output as audible sound.","The audio buffers component  includes a two channel stereo buffer () that receives audio wave data input from logic buses () and (), a single channel mono buffer () that receives audio wave data input from logic bus (), and a single channel reverb stereo buffer () that receives audio wave data input from logic bus ().","Each logical bus  has a corresponding bus function identifier (funcID)  that indicates the designated effects-processing function of the particular buffer  that receives the audio wave data output from the logical bus. For example, a bus funcID can indicate that the audio wave data output of a corresponding logical bus will be to a buffer  that functions as a left audio channel such as bus (), a right audio channel such as bus (), a mono channel such as bus (), or a reverb channel such as bus (). Additionally, a logical bus can output audio wave data to a buffer  that functions as a three-dimensional (3-D) audio channel, or output audio wave data to other types of effects-processing buffers.","Each channel set  in synthesizer  has a bus designator  to identify the logical buses  corresponding to a particular channel set . For example, synthesizer channels (-) of channel set () output audio wave data that is designated as input for audio buffer (). Audio buffer () is a two channel stereo buffer, thus having two associated buses () and () that input audio wave data to the buffer. The channel set () bus designator  designates buses  and  as the destination for audio wave data output from channels (-) in the channel set.","Channel set () includes synthesizer channels (-) that output audio wave data designated as input for audio buffer (). Audio buffer () is a single channel mono buffer and has one associated bus () that inputs audio wave data to the buffer. The channel set () bus designator  designates bus  as the destination for audio wave data output from synthesizer channels (-). Channel set () includes synthesizer channels (-) that output audio wave data designated as input for audio buffers () and (). The channel set () bus designator  designates buses , , and  as the destination for audio wave data output from synthesizer channels (-).","A logical bus  can have more than one input, from more than one synthesizer, synthesizer channel, and\/or audio source. A synthesizer  can mix audio wave data by routing one output from a synthesizer channel  to any number of logical buses  in the multi-bus component . For example, logical bus () has multiple inputs from synthesizer channels (-) and (-). Each logical bus  outputs audio wave data to one associated buffer , but a particular buffer  can have more than one input from different logical buses. For example, logical buses () and () output audio wave data to one designated buffer. The designated audio buffer (), however, receives the audio wave data output from both buses.","Although the multi-bus component  is shown having only four logical buses (-), it is to be appreciated that the logical buses are dynamically created as needed, and released when no longer needed. Thus, the multi-bus component  can support any number of logical buses at any one time as needed to route audio wave data from the synthesizer  to the audio buffers . Similarly, it is to be appreciated that there can be any number of audio buffers  available to receive audio wave data at any one time. Furthermore, although the multi-bus component  is shown as an independent component, it can be integrated with the synthesizer component , or the audio buffers component .",{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 4","b":["400","210","400","402","404","406","400","406","310","402","400"]},"Audio wave data is routed from the synthesizer channels  to the audio buffers  based on a \u201cpull model\u201d. That is, when an audio buffer  is available to receive audio wave data, the buffer requests output from the synthesizer . The synthesizer  receives the request for audio wave data from an audio buffer  along with a busID for the bus, or busIDs for the buses, that correspond to the buffer. The active list  is passed to the synthesizer  when a buffer  requests the audio wave data. The synthesizer  determines the associated funcID  of each logical bus corresponding to the available buffer and then designates which synthesizer channels  will output the audio wave data to the corresponding bus, or buses.","File Format and Component Instantiation","Configuration information for the synthesizer component , the multi-bus component , and the audio buffers component  is stored in a well-known format such as the Resource Interchange File Format (RIFF). A RIFF file includes a file header followed by what are known as \u201cchunks.\u201d The file header contains data describing an audio buffer object, for example, such as a buffer identifier, descriptor, the buffer function and associated effects (i.e., audio processors), and corresponding busIDs.","Each of the chunks following a file header corresponds to a data item that describes the object, such as an audio buffer object effect. Each chunk consists of a chunk header followed by actual chunk data. A chunk header specifies an object class identifier (CLSID) that can be used for creating an instance of the object. Chunk data consists of the audio buffer effect data to define the audio buffer configuration.","Audio buffers are created in accordance with configurations defined by RIFF files. A RIFF file for a buffer configuration includes a buffer global unique identifier (buffer GUID), a buffer descriptor, and bus identifier (busID) data. The buffer GUID uniquely identifies each buffer. A buffer GUID can be used to determine which synthesizer channels connect to which buffers. By using a unique buffer GUID for each buffer, different synthesizer channels, and channels from different synthesizers, can connect to the same buffer or uniquely different ones, whichever is preferred.","The buffer descriptor defines how many audio channels a buffer will have as well as initial settings for volume, and the like. The busID data designates a logic bus, or buses, that connect to a particular buffer. There can be any number of logic buses connected to a particular buffer to input audio wave data. For example, stereo buffer () () is a two channel stereo buffer and has two busIDs: a busID_LEFT corresponding to logic bus () and a busID_RIGHT corresponding to logic bus ().","A RIFF file for a synthesizer configuration defines the synthesizer channels and includes both a synthesizer channel-to-buffer assignment list and a buffer configuration list stored in the synthesizer configuration data. The synthesizer channel-to-buffer assignment list defines the synthesizer channel sets and the buffers that are designated as the destination for audio wave data output from the synthesizer channels in the channel set. The assignment list associates buffers according to buffer GUIDs which are defined in the buffer configuration list.","Defining the buffers by buffer GUIDs facilitates the synthesizer channel-to-buffer assignments to identify which buffer will receive audio wave data from a synthesizer channel. Defining buffers by buffer GUIDs also facilitates sharing resources. More than one synthesizer can output audio wave data to the same audio buffer. When an audio buffer is instantiated, or provided, for use by a first synthesizer, a second synthesizer can output audio wave data to the buffer if it is available to receive data input. The buffer configuration list also maintains flag indicators that indicate whether a particular buffer can be a shared resource or not.","The buffer and synthesizer configurations support COM interfaces for reading and loading the data from a file. To instantiate, or provide, a synthesizer component  and\/or an audio buffer , an application program  first instantiates a component using a COM function. The application program then calls a load method for a synthesizer object or a buffer object, and specifies a RIFF file stream. The object parses the RIFF file stream and extracts header information. When it reads individual chunks, it creates corresponding synthesizer channel objects or a buffer object based on the chunk header information. However, those skilled in the art will recognize that the audio generation systems and the various components described herein are not limited to a COM implementation, or to any other specific programming technique.","Method for an Exemplary Audio Generation System",{"@attributes":{"id":"p-0063","num":"0062"},"figref":["FIG. 5","FIGS. 2\u20134"]},"At block , a synthesizer component is provided. For example, the synthesizer component can be instantiated from a synthesizer configuration file format (e.g., a RIFF file as described above). A synthesizer component can also be created from a file representation that is loaded and stored in a synthesizer configuration object that maintains all of the information defined in the synthesizer configuration file format. Alternatively, a synthesizer component can be created directly by an audio rendition manager.","At block , audio buffers are provided. For example, the audio buffers can be instantiated from a buffer configuration file format (e.g., a RIFF file). Alternatively, an audio buffer component can be created from a file representation that is loaded and stored in a buffer configuration object that maintains all of the information defined in the buffer configuration file format. The information includes the number of buffer channels, a buffer GUID, and the busID data that indicates the funcID of each logical bus that connects to the audio buffer.","At block , a multi-bus component is provided having logical buses corresponding to the audio buffers created at block . For example, stereo buffer () is created and logical buses () and () corresponding to stereo buffer () are instantiated. At block , a bus-to-buffer mapping list, such as bus active list  for example, is created to reflect which logical buses correspond to an audio buffer.","At block , synthesizer channels are allocated in the synthesizer. The synthesizer channels can be allocated according to a synthesizer channel-to-buffer assignment list stored in the synthesizer configuration data. At block , the synthesizer (instantiated at block ) receives a request from an audio buffer for audio wave data to process. The request for audio wave data includes the bus-to-buffer mapping list (created at block ). At block , the synthesizer determines the function of the requesting audio buffer from the associated funcIDs for each corresponding logic bus listed in the bus-to-buffer mapping list.","At block , the synthesizer channels are assigned to buffers according to corresponding buffer GUIDs maintained in a buffer configuration list which is stored with the synthesizer configuration file data. At block , the synthesizer determines which logic buses correspond to each buffer that has been assigned to a synthesizer channel (at block ). At block , the synthesizer associates a bus designator for each synthesizer channel to indicate which bus or buses correspond to a particular synthesizer channel audio wave data output. For example, bus designator  indicates that synthesizer channels (-) of channel set () are associated with logical buses  and .","At block , the synthesizer determines which synthesizer channels can output audio wave data to the audio buffer that has a function type defined by the funcID corresponding to the associated logical bus or buses. At block , audio data is routed from the synthesizer , through logical buses  in the multi-bus component , and to audio buffers  in the audio buffers component .","Exemplary Computing System and Environment",{"@attributes":{"id":"p-0071","num":"0070"},"figref":"FIG. 6","b":["600","600","600","600"]},"The computer and network architectures can be implemented with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use include, but are not limited to, personal computers, server computers, thin clients, thick clients, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, gaming consoles, distributed computing environments that include any of the above systems or devices, and the like.","Implementing a multi-bus component may be described in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Implementing a multi-bus component may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices.","The computing environment  includes a general-purpose computing system in the form of a computer . The components of computer  can include, by are not limited to, one or more processors or processing units , a system memory , and a system bus  that couples various system components including the processor  to the system memory .","The system bus  represents one or more of any of several types of bus structures, including a memory bus or memory controller, a peripheral bus, an accelerated graphics port, and a processor or local bus using any of a variety of bus architectures. By way of example, such architectures can include an Industry Standard Architecture (ISA) bus, a Micro Channel Architecture (MCA) bus, an Enhanced ISA (EISA) bus, a Video Electronics Standards Association (VESA) local bus, and a Peripheral Component Interconnects (PCI) bus also known as a Mezzanine bus.","Computer system  typically includes a variety of computer readable media. Such media can be any available media that is accessible by computer  and includes both volatile and non-volatile media, removable and non-removable media. The system memory  includes computer readable media in the form of volatile memory, such as random access memory (RAM) , and\/or non-volatile memory, such as read only memory (ROM) . A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between elements within computer , such as during start-up, is stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently operated on by the processing unit .","Computer  can also include other removable\/non-removable, volatile\/non-volatile computer storage media. By way of example,  illustrates a hard disk drive  for reading from and writing to a non-removable, non-volatile magnetic media (not shown), a magnetic disk drive  for reading from and writing to a removable, non-volatile magnetic disk  (e.g., a \u201cfloppy disk\u201d), and an optical disk drive  for reading from and\/or writing to a removable, non-volatile optical disk  such as a CD-ROM, DVD-ROM, or other optical media. The hard disk drive , magnetic disk drive , and optical disk drive  are each connected to the system bus  by one or more data media interfaces . Alternatively, the hard disk drive , magnetic disk drive , and optical disk drive  can be connected to the system bus  by a SCSI interface (not shown).","The disk drives and their associated computer-readable media provide nonvolatile storage of computer readable instructions, data structures, program modules, and other data for computer . Although the example illustrates a hard disk , a removable magnetic disk , and a removable optical disk , it is to be appreciated that other types of computer readable media which can store data that is accessible by a computer, such as magnetic cassettes or other magnetic storage devices, flash memory cards, CD-ROM, digital versatile disks (DVD) or other optical storage, random access memories (RAM), read only memories (ROM), electrically erasable programmable read-only memory (EEPROM), and the like, can also be utilized to implement the exemplary computing system and environment.","Any number of program modules can be stored on the hard disk , magnetic disk , optical disk , ROM , and\/or RAM , including by way of example, an operating system , one or more application programs , other program modules , and program data . Each of such operating system , one or more application programs , other program modules , and program data  (or some combination thereof) may include an embodiment of a implementing a multi-bus component.","Computer system  can include a variety of computer readable media identified as communication media. Communication media typically embodies computer readable instructions, data structures, program modules, or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared, and other wireless media. Combinations of any of the above are also included within the scope of computer readable media.","A user can enter commands and information into computer system  via input devices such as a keyboard  and a pointing device  (e.g., a \u201cmouse\u201d). Other input devices  (not shown specifically) may include a microphone, joystick, game pad, satellite dish, serial port, scanner, and\/or the like. These and other input devices are connected to the processing unit  via input\/output interfaces  that are coupled to the system bus , but may be connected by other interface and bus structures, such as a parallel port, game port, or a universal serial bus (USB).","A monitor  or other type of display device can also be connected to the system bus  via an interface, such as a video adapter . In addition to the monitor , other output peripheral devices can include components such as speakers (not shown) and a printer  which can be connected to computer  via the input\/output interfaces .","Computer  can operate in a networked environment using logical connections to one or more remote computers, such as a remote computing device . By way of example, the remote computing device  can be a personal computer, portable computer, a server, a router, a network computer, a peer device or other common network node, and the like. The remote computing device  is illustrated as a portable computer that can include many or all of the elements and features described herein relative to computer system .","Logical connections between computer  and the remote computer  are depicted as a local area network (LAN)  and a general wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet. When implemented in a LAN networking environment, the computer  is connected to a local network  via a network interface or adapter . When implemented in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the wide network . The modem , which can be internal or external to computer , can be connected to the system bus  via the input\/output interfaces  or other appropriate mechanisms. It is to be appreciated that the illustrated network connections are exemplary and that other means of establishing communication link(s) between the computers  and  can be employed.","In a networked environment, such as that illustrated with computing environment , program modules depicted relative to the computer , or portions thereof, may be stored in a remote memory storage device. By way of example, remote application programs  reside on a memory device of remote computer . For purposes of illustration, application programs and other executable program components, such as the operating system, are illustrated herein as discrete blocks, although it is recognized that such programs and components reside at various times in different storage components of the computer system , and are executed by the data processor(s) of the computer.","A synthesizer and multi-bus component allows an application program to specify, for example, unique 3-D positions for as many video entities as the application requires for audio representation corresponding to a video presentation. Specifically, this is accomplished by routing audio wave data from a synthesizer channel to multiple buffers via logic buses that connect to the multiple buffers having mixing and\/or 3-D effects-processing.","Interfacing the synthesizer and the audio buffers with the logic buses of the multi-bus component allows for greater flexibility in routing the audio wave data generated by the synthesizer. The flexibility in routing also means that groups of instruments can be routed through different buffers with different effects-processing, or sound effects can be sub-mixed and routed to unique 3-D positions.","Although the systems and methods have been described in language specific to structural features and\/or methodological steps, it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or steps described. Rather, the specific features and steps are disclosed as preferred forms of implementing the claimed invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The same numbers are used throughout the drawings to reference like features and components.",{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 3","FIG. 2"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
