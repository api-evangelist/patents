---
title: Processing data feeds
abstract: Exemplary embodiments allow performance of stream computations on real-time data streams using one or more map operations and/or one or more update operations. A map operation is a stream computation in which stream events in one or more real-time data streams are processed in a real-time manner to generate zero, one or more new stream events. An update operation is a stream computation in which stream events in one or more real-time data streams are processed in a real-time manner to create or update one or more static “slate” data structures that are stored in a durable manner.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08595234&OS=08595234&RS=08595234
owner: Wal-Mart Stores, Inc.
number: 08595234
owner_city: Bentonville
owner_country: US
publication_date: 20111118
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","I. Definitions of Certain Relevant Terms","II. Exemplary Data Types","III. Exemplary Map Operations","IV. Exemplary Update Operations","V. Exemplary Stream Processing Systems and Methods","VI. Exemplary Task Scheduling Mechanisms","VII. Exemplary Failure Handling Mechanisms","VIII. Exemplary Stream Event Ordering Mechanisms","IX. Storage and Replay of Application-State Snapshots","X. Exemplary Implementation for Archival of the Last Stream Event in a Data Stream","XI. Exemplary Implementation of the Last Publication Time in a Real-Time Data Stream","XII. Exemplary Implementation of Real-Time Detection of Popular Topics","XIII. Exemplary Implementation of Real-Time K-Rank Computation","XIV. Exemplary Implementation of Stream Clustering","XV. Exemplary Computing Devices","XVI. Exemplary Network Environments","XVII. Equivalents"],"p":["This application is a continuation-in-part of and claims priority to U.S. patent application Ser. No. 13\/106,706 entitled \u201cProcessing Data Feeds,\u201d filed May 12, 2011. U.S. patent application Ser. No. 13\/106,706, filed May 12, 2011, in turn, claims priority to U.S. Provisional Patent Application No. 61\/345,252 entitled \u201cContent Feed,\u201d filed May 17, 2010, and to U.S. Provisional Patent Application No. 61\/415,282 entitled \u201cManaging Real-Time Data Streams,\u201d filed Nov. 18, 2010. The instant application also claims priority to U.S. Provisional Patent Application No. 61\/415,279 entitled \u201cSocial Genome,\u201d filed Nov. 18, 2010. The instant application is also related to a U.S. non-provisional patent application Ser. No. 13\/300,519 entitled \u201cSocial Genome,\u201d filed Nov. 18, 2011, a U.S. non-provisional patent application Ser. No. 13\/300,523 entitled \u201cReal-time Analytics of Streaming Data,\u201d filed Nov. 18, 2011, and a U.S. non-provisional patent application Ser. No. 13\/300,473 entitled \u201cMethods, Systems and Devices for Recommending Products and Services,\u201d filed Nov. 18, 2011. The entire contents of each of the above-referenced applications are incorporated herein in their entirety by reference.","Individuals are increasingly consuming content from social networking services and other information sources that update very frequently. Unfortunately, it can be difficult to locate content of interest in those sources, due to reasons such as the sheer volume of content available and the speed with which new content is made available.","Exemplary embodiments provide devices, systems and methods for performing large-scale long-running stream computations on real-time data streams using one or more map operation and\/or one or more update operations. A map operation is a stream computation in which stream events in one or more real-time data streams are processed in a real-time manner to generate zero, one or more new stream events. An update operation is a stream computation in which stream events in one or more real-time data streams are processed in a real-time manner to create or update one or more static \u201cslate\u201d data structures that are stored in a durable disk storage in a persistent manner.","In accordance with another exemplary embodiment, a computer-implemented method is provided for processing of real-time data streams. The method includes receiving in a real-time manner, at a first worker process running on a first computational device, a first stream event in a first real-time data stream. The method includes processing in a real-time manner, at the first worker process at the first computational device, the first stream event in a first map operation to generate first output data. The method includes transforming the first output data, at the first worker process at the first computational device, to generate a second stream event corresponding to the first stream event and comprising the first output data. The method includes transmitting the second stream event in a real-time manner using the first worker process at the first computational device.","In accordance with another exemplary embodiment, a computer-implemented method is provided for processing of real-time data streams. The method includes receiving in a real-time manner, at a first worker process running on a first computational device, a first stream event in a first real-time data stream, the first stream event comprising first input data. The method includes processing in a real-time manner, at the first worker process at the first computational device, the first input data contained in the first stream event in a first update operation to generate first output data. The method includes transforming the first output data, at the first worker process at the first computational device, to generate or update a first data structure associated with the first input data. The method includes storing the first data structure on a durable storage device.","In accordance with another exemplary embodiment, a computer-implemented method is provided for processing of real-time data streams. The method includes receiving in a real-time manner, at a first worker process, a first input stream event in a first real-time input data stream comprising a plurality of stream events; processing in a real-time manner, at the first worker process, the first input stream event in a first map operation to generate first intermediate output data; generating, at the first worker process, a first intermediate stream event corresponding to the first input stream event and comprising the first intermediate output data; and transmitting, using the first worker process, the first intermediate stream event in a first real-time intermediate data stream in a real-time manner. The method also includes receiving in a real-time manner, at a second worker process, the first intermediate stream event in the first real-time intermediate data stream; processing in a real-time manner, at the second worker process, the first intermediate output data in the first intermediate stream event in a first update operation to generate first final output data; and storing the first final output data in a first data structure associated with the first intermediate output data on a storage device.","In accordance with another exemplary embodiment, a distributed computational system is provided. The system includes a computer-readable storage device for storing computer-executable code associated with a first map operation and a first update operation, and for storing static data output by the first update operation. The system includes a scheduling module for scheduling the first map operation to run on a first worker node and the first update operation to run on a second worker node. The system also includes the first and second worker nodes. The first worker node is programmed to receive in a real-time manner a first input stream event in a first real-time input data stream comprising a plurality of stream events, run the first map operation to process in a real-time manner the first input stream event to generate first intermediate output data, generate a first intermediate stream event corresponding to the first input stream event and comprising the first intermediate output data, and transmit the first intermediate stream event in a first real-time intermediate data stream in a real-time manner. The second worker node is programmed to receive in a real-time manner the first intermediate stream event in the first real-time intermediate data stream, run the first update operation to process in a real-time manner the first intermediate output data in the first intermediate stream event to generate first final output data, and store the first final output data in a first data structure associated with the first intermediate output data on the storage device.","In accordance with another exemplary embodiment, one or more non-transitory computer-readable media having encoded thereon computer-executable instructions for performing a method for processing real-time data streams. The method includes receiving in a real-time manner, at a first worker process, a first input stream event in a first real-time input data stream comprising a plurality of stream events; processing in a real-time manner, at the first worker process, the first input stream event in a first map operation to generate first intermediate output data; generating, at the first worker process, a first intermediate stream event corresponding to the first input stream event and comprising the first intermediate output data; and transmitting, using the first worker process, the first intermediate stream event in a first real-time intermediate data stream in a real-time manner. The method also includes receiving in a real-time manner, at a second worker process, the first intermediate stream event in the first real-time intermediate data stream; processing in a real-time manner, at the second worker process, the first intermediate output data in the first intermediate stream event in a first update operation to generate first final output data; and storing the first final output data in a first data structure associated with the first intermediate output data on a storage device.","The invention can be implemented in numerous ways, including as a process; an apparatus; a system; a composition of matter; a computer program product embodied on a computer readable storage medium; and\/or a processor, such as a processor configured to execute instructions stored on and\/or provided by a memory coupled to the processor. In this specification, these implementations, or any other form that the invention may take, may be referred to as techniques. In general, the order of the steps of disclosed processes may be altered within the scope of the invention. Unless stated otherwise, a component such as a processor or a memory described as being configured to perform a task may be implemented as a general component that is temporarily configured to perform the task at a given time or a specific component that is manufactured to perform the task. As used herein, the term \u2018processor\u2019 refers to one or more devices, circuits, and\/or processing cores configured to process data, such as computer program instructions.","A detailed description of one or more embodiments of the invention is provided below along with accompanying figures that illustrate the principles of the invention. The invention is described in connection with such embodiments, but the invention is not limited to any embodiment. The scope of the invention is limited only by the claims and the invention encompasses numerous alternatives, modifications and equivalents. Numerous specific details are set forth in the following description in order to provide a thorough understanding of the invention. These details are provided for the purpose of example and the invention may be practiced according to the claims without some or all of these specific details. For the purpose of clarity, technical material that is known in the technical fields related to the invention has not been described in detail so that the invention is not unnecessarily obscured.",{"@attributes":{"id":"p-0060","num":"0059"},"figref":"FIG. 1","b":["102","102","102"]},"In some embodiments, system  is a commodity personal computer or other consumer electronic device. In that scenario, the output of system  is made available to a user of the device, such as through an incorporated display, or is provided to a display of a second device in communication with system . In other embodiments, system  is a single server or one of a small number of servers acting in cooperation. For example, publishing entities such as newspapers, and other organizations may each operate a system  for the benefit of employees, subscribers, or other customers. In yet other embodiments, system  comprises a distributed, elastic architecture, an example of which is described in more detail below, such as in the section titled MANAGING REAL-TIME DATA STREAMS.","Whenever system  is described as performing a task, either a single component or a subset of components or all components of system  may cooperate to perform the task. Similarly, whenever a component of system  is described as performing a task, a subcomponent may perform the task and\/or the component may perform the task in conjunction with other components. In various embodiments, portions of system  are provided by one or more third parties. Depending on factors such as the amount of computing resources available to system , various logical components and\/or features of system  may be omitted and the techniques described herein adapted accordingly. Similarly, additional logical components\/features can be added to system  as applicable, such as ones providing additional or alternate ways of processing incoming data and ones making available different types of output. Additional detail on elements depicted in  will now be provided, including examples of how such elements would process tweet data. System  can process a variety of data and is not limited to the examples provided.","Preprocessing Engine","Input from various sources - is ingested by system . Example sources include Twitter (twitter.com), Facebook (facebook.com), foursquare (foursquare.com), and other social networking sites; Flickr (flickr.com) and other media hosting services; Digg (digg.com) and other social news websites; traditional news websites; RSS Feeds; and financial transaction information. System  is configured to access data from the various sources using appropriate techniques, including through application programming interfaces (APIs), crawling, performing standing searches, and the pushing\/pulling of new items, such as via RSS.","Items of data are provided by sources - to system  in a variety of different formats, such as in XML, JSON, and HTML. Examples of items include tweets, updates, articles, RSS feed entries, news articles, reviews, deals, and financial transactions. Preprocessor  is configured to standardize each item of incoming data into a JSON object and to augment the contents of the JSON object with more key-value pairs by performing additional processing through the use of one or more modules -.",{"@attributes":{"id":"p-0066","num":"0065"},"figref":"FIG. 2A","b":"200"},{"@attributes":{"id":"p-0067","num":"0066"},"figref":"FIG. 2B","b":["200","104","112","202","204","206","208","210","212","214"]},"In various embodiments, in addition to standardizing information received from a source such as source , preprocessor  is configured to augment the JSON object contents by performing additional processing. In some embodiments, the additional processing is performed by modules, such as modules -.","Language Module","Language module  is configured to determine the language (e.g., English or Japanese) of an item or content associated with an item. In the example shown in , a language associated with a profile of the author of tweet  is provided by source  (at ). In such a scenario, the processing of language module  can be omitted, or can be used to confirm that a particular tweet is indeed in the expected language. For other sources, such as RSS feeds, an associated language may not be provided by the source and language module  is configured to determine the language of the item and include the determined language in the JSON object of the item. Language module  can also be used to determine the language of information crawled by crawler , as applicable.","Sentiment Analysis Module","Sentiment analysis module  is configured to determine a sentiment (e.g., positive or negative) associated with the item, if applicable, and store the sentiment in the JSON object.","User Importance Score Module","User importance score module  is configured to determine an importance score for the author of the item (or, e.g., in the case of a financial transaction, a party to the transaction) and to include that score in the JSON object. A variety of factors can be used to compute a user importance score. And, over time, a user's importance score can change. The following are examples of factors which can be used in computing an importance score of a given Twitter user:","(1) The number of other users that follow the user. The more followers, the higher the score.","(2) When that user generates content, such as by writing a tweet or posting an update, how much additional traffic is generated (e.g., how many retweets and\/or replies occur).","(3) Is the user a publisher-only account (e.g., belonging to ACME News). Such accounts can be identified (among other ways) based on factors, such as that they rarely, if ever, retweet; they rarely, if ever, respond to other users; and that they have many followers but follow very few, if any, other users.","(4) The frequency with which the user tweets an item that is ultimately associated with an event that is determined to be a top event.","(5) The frequency with which the user is the first to tweet an article.","(6) The importance scores of the users who are following this user.","(7) The importance scores of the users this user is following.","(8) The importance scores of the users who retweet tweets by this user.","(9) The importance scores of the users whose tweets this user retweets.","In some embodiments, factors such as those listed above are used to determine the relative importance of any two users. The comparisons can be used to construct a hierarchy of user importances, once an equilibrium is reached. As one example, suppose all users are assigned a seed rank of 1000. Each time a user retweets an item, the rank of the original tweeter is increased by epsilon and the rank of the retweeting user is decremented by epsilon. Other signals can be used in a similar way. For example, when one user follows another, then the person who is followed could be awarded a higher score based on the score of the person who is following. Additional techniques for computing a user importance score are provided below, such as in the section titled MANAGING REAL-TIME DATA STREAMS.","Crawler Module","Whenever preprocessor  detects the presence of a URL in an item, such as is present in tweet , it instructs crawler module  to crawl that URL and to provide back information such as the title of the crawled page, the full text of the crawled page, and a list of images on the crawled page. Other metadata, such as the list of keywords or tags associated with a blog post are also collected by crawler . Each of the pieces of information obtained by crawler  is included in the JSON object as a name-value pair.","Categorizer Module","Categorizer  is configured to categorize the tweet, and also to categorize content obtained by crawler . Categorization techniques are described in more detail below, such as in the section titled TAGGING A DOCUMENT. The categorization information is included in the JSON object as a series of tags (e.g., \u201cSports\u201d), scores (e.g., \u201cVolleyball=0.999\u201d), or a combination thereof.","Disambiguator Module","In some cases, the meaning of a tweet may be ambiguous. For example, a tweet that says, \u201cI want to buy an apple,\u201d could mean that the author is hungry and wishes to purchase a piece of fruit. The tweet could also indicate that the author desires to purchase a computer or consumer electronic device. As another example, a tweet of \u201cEarthquakes!\u201d could refer to the author experiencing an earthquake or could refer, for example, to the author's support of the San Jose soccer team. Techniques for resolving ambiguities are described below in the section titled TAGGING A DOCUMENT, and are performed in some embodiments by categorizer module , by disambiguator , or both modules.","In some embodiments, if categorizer  is unable to resolve ambiguities (such as the meaning of \u201capple\u201d in the example given above), categorizer  includes tags for all possible meanings in the JSON object. For example, categorizer  might generate tags of \u201cApple (Fruit),\u201d \u201cAPPLE (Satellite),\u201d \u201cApple Mac (Computer),\u201d and \u201cApple Inc.\u201d for the tweet text \u201cI want to buy an apple.\u201d Categorizer  might similarly generate tags of \u201cJapan Earthquake,\u201d \u201cHaiti Earthquake,\u201d \u201cEarthquakes,\u201d \u201cSan Jose Earthquakes (Soccer Team),\u201d and \u201cEarth Quake (Musical Group)\u201d for the tweet text \u201cEarthquake!\u201d Disambiguator module  can be used to resolve such ambiguous meanings through additional context, such as user profile information, historical information, and location information.","System  maintains two dictionaries for each of the following: every Twitter user; every hashtag (e.g., # dogs); every domain (e.g., example.com); every concept; and every word. The first dictionary for each is a list of words used by that user (or words that co-occur with the hashtag, words that co-occur with the domain, words that co-occur in a tweet that has been assigned a given concept, and words that co-occur within tweets). The second dictionary is a list of concepts that the user's tweets are tagged with (or concepts assigned to tweets that include a given hashtag, concepts assigned to tweets that include a given domain, concepts that co-occur, and concepts that are assigned to a tweet that includes a given word). In some embodiments, both types of dictionaries maintain only the top n words (or concepts), instead of an exhaustive list of all words (or concepts). One approach to storing the dictionaries is to store each dictionary as a slate, described in more detail below in the section titled MANAGING REAL-TIME DATA STREAMS.","One way to resolve the ambiguous meaning of \u201capple\u201d in the example tweet provided above, is to analyze the appropriate dictionaries (e.g., for the user posting the tweet). If other tweets made by the user frequently are tagged with food-related concepts, an assumption can be made that \u201cI want to buy an apple\u201d pertains to the purchase of fruit. As another example, if a previous tweet by the user includes the domain apple.com, an assumption can be made that \u201cI want to buy an apple\u201d pertains to the purchase of a computer or other device. In the case of the \u201cEarthquake!\u201d tweet, if the author is located in San Jose or if a soccer game featuring the San Jose Earthquakes is taking place, an assumption can be made that the tweet pertains to the soccer team, while if the author is located in Japan, works for the Red Cross, or sometimes tweets in Japanese, an assumption can be made that the tweet pertains to the March 2011 earthquake.","If disambiguator  is able to resolve an ambiguity, it updates the tags included in the JSON object. For example, if it is determined that a tweet is about the purchase of fruit, disambiguator  would remove the tag \u201cApple Inc.\u201d from the JSON object. Disambiguator  can also add additional tags to the JSON object as applicable.",{"@attributes":{"id":"p-0095","num":"0094"},"figref":["FIG. 3","FIG. 2B"],"b":["112","302","116","118","304","306","308","114","310","312","314","316","318","320","316","322","308"]},"Event Creator","Event creator  is configured to provide to event classifier  a set of event definitions. The event definitions can be created by a human through an interface, can be automatically created, and can be created by a combination of the two. The event definitions can also be updated over time.","One example of an event is a news event, such as an earthquake occurring. A human administrator, aware that the earthquake has occurred, can use a provided interface to create a definition for the event. Specifically, the administrator would indicate a title for the event (e.g., \u201cEarthquake in Japan\u201d) and include other information that defines the event, such as any of the following:","(1) a set of positive concepts\/tags (e.g., \u201cEarthquake\u201d and \u201cJapan\u201d)","(2) a set of positive words (e.g., \u201cOshika Peninsula\u201d and \u201c9.0\u201d)","(3) a set of negative concepts and\/or words which, if present in an item, indicate that it does not pertain to the event","(3) particular users (e.g., the Twitter account of a particular Japanese newspaper or the account of a particular reporter or celebrity involved in an event)","(4) particular hashtags (e.g., #Jishin)","(5) location information (e.g., GPS coordinates or place names)","(6) a text description of the event","(7) pictures and\/or videos that pertain to the event","Other information, such as a start and end time of the event can also be specified. Some events, such as sporting events, may have predefined start and end times. Other events may have a defined start time, and then have an end time automatically generated as interest in the event wanes. Some events (e.g., pertaining to the President of the United States or popular celebrities) may not have clear start or end times but are instead \u201cevergreen.\u201d In some embodiments, when the end time for an event has passed, items will no longer be able to be classified by event classifier  as pertaining to that event.","In some embodiments, at least some of the above information is automatically collected by system  and presented to an administrator as a proposed\/potential event. For example, system  can be configured to detect when groups of words or other things (such as hashtags) co-occur with a frequency that is higher than usual. An increased co-occurrence (e.g., of the terms \u201cJapan\u201d and \u201cearthquake\u201d) can indicate that a newsworthy event is occurring and that information can be surfaced to an administrator for review. Co-occurring contexts are also indicators. For example, if several people in the same approximate location at the same approximate time tweet \u201cfire\u201d or \u201ccrash,\u201d it is likely that an event is occurring at that location\/time. The administrator can approve or disapprove the proposed event, and can make changes, such as by providing a title and refining the event definition.","Hierarchical Events","In some embodiments, events are organized into a hierarchy. Using the Mar. 11, 2011 earthquake in Japan as an example, the earthquake itself would be at the top of the hierarchy. Other events, such as the resulting tsunami, destruction at the Fukushima Nuclear Power Plant, and press conferences by the Prime Minister are examples of sub-events that would be organized into the hierarchy. Periodically, operations to merge events (because they are connected) or split events occur. For example, in the case of the earthquake, events such as the tsunami might originally be part of the main event, but subsequently be split out into events of their own.","Event Classification","Event classifier  is configured to determine whether a given item corresponds to one of the events for which it has received a definition from event creator . In some embodiments, classification is performed as follows.","The event classifier maintains a vector of currently \u201clive\u201d events\u2014those events for which an end time has not passed. Event classifier  receives processed items (e.g., JSON objects) from preprocessor . The classifier computes a similarity metric between the processed item and each of the definitions of the live stories to determine a probability of match. If the probability exceeds a threshold, the item is tagged with the event (e.g., a unique identifier of the event), as yet another name-value pair. If the item matches with multiple events, the item is tagged with each of those events. If the item does not match any events, no additional tags are added by classifier , or a tag of \u201cno event matches\u201d or other appropriate tag(s) are added.","Cluster Server","Cluster server  is configured (1) to cluster multiple processed items together into a cluster definition and (2) to evaluate (and re-evaluate) the cluster, such as by assigning one or more scores to the cluster. For a given item, many hundreds of other items (or more) may be received by system  that are identical or substantially the same. As one example, tweet  may be retweeted by thousands of other users (each of which would be ingested by system  as a separate item). Cluster server  is configured to group the original tweet and all of the retweets together into a single new JSON object that represents the cluster (also referred to as the \u201ccluster object\u201d) and provide the cluster as output, such as to output engine . As another example, many users may tweet identical messages (\u201cSmith scored a goal!\u201d) or substantially similar messages (e.g., all of which include the same URL, or which match within a tolerance). Yet another example is a set of tweets in response to one another\u2014forming a conversation. Cluster server  can similarly be configured to cluster those respective items. For a given event (e.g., as determined by event creator ), multiple clusters can exist.","When cluster server  receives an object from event classifier , it determines whether the object should be included in an existing cluster (because it is identical to or substantially similar to a previously received object). If the object does not match with an existing cluster, a new cluster is created, with the received object serving as the first item included in the cluster. The other information included in the item's JSON object, such as the information illustrated in , is included in the newly created cluster object. If the received item does match an existing cluster, the cluster is updated to include an identifier of the item and other information, such as the cluster's score and representative information is re-evaluated as described in more detail below. Either the newly created cluster object, or the updated cluster object, as applicable, is provided as output to output engine .","Cluster Score","System  maintains, for each cluster, a variety of statistics, including how many items have been included in the cluster, representative information for the cluster, and one or more quality measures for the cluster. Examples of representative information include the first item to be included in the cluster (i.e., tweet ), the most recently received item (i.e., the most recently received retweet of tweet ), the tweet whose author has the highest user importance score, and one or more photographs, videos, or other media representative of the cluster. In the case of a cluster formed around tweet , a representative image might be selected from the information obtained by crawler  (e.g., a photograph appearing in the linked-to article). The representative information of a cluster is re-evaluated each time a new item is included in the cluster. Thus, if a retweet of tweet  is received from a user who has a higher user importance score than any of the user importance scores of the already-included items, the newly received tweet will be designated as a representative tweet for the cluster, replacing the item with the previously highest associated user importance score. In various embodiments, administrators or other individuals are able to manually supplement or override the representative information of a cluster, such as through an interface provided by system .","Examples of quality measures of a cluster include:","(1) the user importance score of the first item in the cluster","(2) the sum of the user importance scores of the authors of each of the items included in the cluster","(3) the highest user importance score of the authors of the items included in the cluster","(4) how many items are included in the cluster","(5) does the cluster include images, videos, or other media","(6) do the clustered items include a URL, and if so, what is the importance of the URL's domain (e.g., with URLs to national newspapers having higher scores than personal blogs)","(7) how quickly are new items being received by system  that are included in the cluster, and is that rate increasing or decreasing","(8) user feedback","The various signals listed above can be combined into one or more cluster scores that indicate the importance of a given cluster. In some embodiments, the cluster score is included in the cluster object as a name-value pair, prior to transmission to output engine .","Output Engine","Output engine  maintains, for every event created by event creator , various top n lists, such as the most popular links associated with the event (), the most popular clusters associated with the event (), the most popular hashtags associated with the event (), the most popular videos associated with the event (), and the most popular images associated with the event (). Output engine  also maintains various global lists, such as the most popular events (). In some embodiments, the lists are maintained as slates and are updated in real-time by workers, described in more detail below. Whenever output engine  receives a cluster from cluster server , the respective workers determine whether any of the lists need to be updated. Historical information about each of the lists is also preserved, allowing for the given top n of an event to be determined for a particular time slice.","Lists - are just some of the examples of data that can be maintained by output engine . Output engine  can also maintain top n lists for other data as well. For example, output engine  can maintain, for a given Twitter user, the most popular items; for a given location, the most popular items; for a given concept the most popular videos or other media; and for a given domain, the Twitter users that most frequently mention the domain. Output engine  may also make use of intermediate slates\/workers.","The information managed by output engine  can be exposed in a variety of ways, such as through an interface provided by device . Various examples of such interfaces are provided in more detail below. In the example shown, device  is a personal computer. Other devices can also be used in conjunction with the techniques described herein, such as cellular phones\/personal digital assistants, tablet computers, game consoles, Internet-connected appliances such as picture frames and refrigerators, and set-top boxes.",{"@attributes":{"id":"p-0133","num":"0132"},"figref":["FIG. 4","FIG. 4"],"b":["102","402","200","402","112","404","404","114","124","406","406","128","408","408","130","410","410"]},"Example User Interfaces",{"@attributes":{"id":"p-0135","num":"0134"},"figref":["FIGS. 5-7","FIGS. 5-7","FIG. 5"],"b":["132","150","502","504","506","508"]},"Element  of the interface shown in  is a representation of a cluster. Included in the representation is the total number of items in the cluster () (e.g., the number of items received by system  and clustered together by cluster server ). Also included in element  is a copy of the representative item of the cluster (tweet ), a representative image (), and other information obtained from crawler  or specified by an administrator, such as description () and title (). Which tweet is shown in representation  is selectable, such as by system , by device , or by another appropriate selector. For example, instead of showing the tweet from the user with the highest user importance score, the first tweet or most recent retweet could be shown instead.","The interface shown is an example of a slideshow view, selectable by a user by clicking on button . Other clusters, such as cluster , will scroll by (resizing as applicable) at the speed selected by the user.",{"@attributes":{"id":"p-0138","num":"0137"},"figref":["FIG. 6","FIG. 5","FIG. 6"]},"In , a viewer of the interface shown in  has clicked on button  and been presented with a list view of clusters. Specifically, cluster  is shown in a more condensed form (), with description  and representative image  omitted. Also included in the interface shown in  is a list () of the top stories of the day.","Additional details on various aspects of interfaces which can be used in conjunction with the techniques described herein will now be provided.","Channels","In the example interfaces shown in , users are able to view clusters across all categories and can also narrow the clusters they are presented with to pre-selected high level categories, such as Sports and Politics. In various embodiments, users are able to specify finer grained topic preferences (e.g., California Politics) and can also create arbitrary channels that precisely define the requirements for clusters to be included for display. For example, a user can specify a channel in which clusters must be tagged with either Sports or Business and can also specify a channel in which clusters must be tagged with both Finance and Semiconductors.","Clusters need not be built based on topics (or combinations of topics) but can instead be based on any of the data stored in item objects, cluster objects, or otherwise tracked by system , such as by output engine . For example, a user can subscribe to a channel of popular links (irrespective of category), a channel of popular business videos, a channel that includes any stories about earthquakes that are written in Japanese or Spanish, and a channel for a specific story (e.g., relating to the Prime Minister of Japan's speech). Another example of a channel is a custom \u201cdeal\u201d channel. Suppose a user is in the market for a television. Using the techniques described herein, the user can subscribe to a \u201c40 inch plasma tv sale\u201d channel.","In some embodiments, channels are defined at least in part on the capabilities of the display device, and can be specified without the need for configuration by an end user of the device. As one example, an Internet connected picture frame can be configured to display a channel constructed from all clusters that include images of a minimum (or maximum) size and\/or resolution.","Yet another example of a channel is a location-based one. Suppose a user is riding on a commuter train. The user's phone can report the user's location to system  which in turn recognizes that the user is on the commuter train. If any items pertaining to the train are received by system , they can be provided to the user. A user in a car can similarly receive traffic updates, accident reports, traffic photos, accident photos, etc. as a channel. As yet another example, if a specific user's location is known (e.g., the user is on a train), a channel of \u201cwhat other people on the same train are reading\u201d can be made available to the user.","One or more channels can also be created automatically for a given user based on interests obtained by system  from a social networking site or other profiles of the user. The user's Twitter stream, blog posts, and other content can be examined by system  for hashtags and the content categorization techniques described herein can be applied to the content to discern topics of interest to the user.","Speed Control","If a user is viewing a channel that is sufficiently narrow in scope, such as one in which clusters are required to pertain to Astronomy-related events, the user will likely be able to read (or otherwise absorb) every cluster provided as output by output engine  at its natural speed. However, even with the clustering techniques described herein employed, for certain channels, such as the \u201cAll Categories\u201d channel , the real time output of output engine  will likely include far more information than can be absorbed by an individual viewing that output in an interface. By manipulating control , the user is able to control how quickly new pieces of information are presented in an interface, such as interface . In some embodiments, the \u201cslower\u201d the control is set, the higher a given cluster's cluster score must be to be shown; the \u201cfaster\u201d the control is set, the lower that a given cluster's cluster score must be to be shown. Thus, irrespective of what speed is selected by the user, the most important information will be shown. In other embodiments, other factors can also be used to adjust what information is presented in interface . For example, in some embodiments, the processing performed by cluster server  is performed simultaneously with the processing performed by output engine and\/or is performed by device . The tolerances for what it means for two items to be \u201csubstantially similar\u201d can be adjusted to be either more inclusive or less inclusive, thus resulting in either fewer, or more clusters to be displayed, respectively.","In some embodiments, stories are clustered using techniques similar to those described for the clustering of items. When viewing a channel such as the \u201cAll Categories\u201d channel , at a slow speed, story clustering can be used to prevent several clusters associated with the same story to be presented in rapid succession. Story scores can also be used in a manner similar to the use of cluster scores described above.","Playback Controls","In the example interfaces shown in , a pause button  is shown. In various embodiments, some or all of the following controls are made available in an interface.","PLAY: This is the default mode when the user views the interface. A stream of clusters for a channel selected by the user is displayed. In the absence of personalization, the global channel stream is provided.","PAUSE: When the pause button is selected, the channel's display is paused and a time marker is set. Clusters continue to be sent to the user's device until a buffer of the device is full. When the PLAY button is selected, the buffered clusters are shown to the user. Depending on speed settings, the user may see highlights for the lost period or the entire stream of clusters. If a particular event (or cluster) has changed while the user interface is paused (e.g., because the event grows in size or decays or splits\/combines, or because the description or other representative information for the cluster has changes), in some embodiments, once the channel is unpaused, the current version of the event (or cluster) is displayed in place of the event (or cluster) as it stood when the stream was paused.","STOP: Stop receiving clusters.","REWIND: System  is configured to permanently store cluster and event information, as well as global information, thus allowing users to request the replay of various channels as they would have appeared at an arbitrary date and time. The user can specify an arbitrary speed with which the channel should be replayed, which can be different from a speed with which the user may have originally viewed the channel (if at all).","RECORD: A user can choose to record the channel stream on a device such as device . The user can also ask for the channel be recorded for a given time interval. In some embodiments, all the clusters in the stream will be recorded, thus giving the user an option to view the stream in varying levels of detail\/speed during playback. In other cases (e.g., a device with constrained resources), only the specified level of detail is recorded. One example use of the record function is for a mobile device user to record one or more channels prior to boarding a flight. During the flight, the user can then play back the stored channel stream. The play back speed could be slow (i.e., to provide entertainment during the flight) or fast (i.e., to allow the user to be \u201ccaught up\u201d with current events quickly). People interested in seeing how events unfold can also use record to review information, such as which news sites reported information first and how the information propagated to other sites.","FAST-FORWARD: While replaying a recording, the techniques described herein can be used to minimize the loss of information when the stream is replayed at a faster-than real time speed. Clicking on FAST-FORWARD will allow the user to view only the most-important clusters in the recording. Different speeds are supported (e.g., slow motion, 2\u00d7, \u00d7, etc.). If the stream is slowed down, fewer clusters will be displayed, but those clusters that are displayed will be more important than those that are not displayed.","Additional Uses of Location Information","An interface can be provided in which users indicate their location on a map and then are shown stories that are occurring nearby. As one example, in the event of a plane crash or a natural disaster, many nearby individuals may be tweeting about the event prior to national news sources. Further, the pictures that are received (e.g., of a volcano erupting or a rocket launch) can be aggregated into a \u201cstory in pictures\u201d as it unfolds. A user nearby the incident may be interested in knowing about the story as soon as possible, while other users (e.g., across the country) may only be interested if\/when the story is picked up nationally.","As another example, during the period of time that a trade show is occurring in Texas (i.e., during a designated start and end of the event as defined in event creator ), a graphical user interface can depict where people are located when they tweet about the trade show (e.g., based on hashtags and other categorization information). For example, early in the evening, the individuals are at the tradeshow. Then they move to a particular vendor's party, as a large group. The individuals then break off into various smaller parties.","Additional Information on Cluster (and\/or Event) Scoring","As explained above, a variety of signals can be used to determine a score indicative of the quality of a cluster (or story). In the case of the importance of domain, a single value can be used, such as a page rank or other score provided by a third party. Other features can also be used, such as how large the domain is, how often the domain breaks news, and how much traffic the domain receives. Another signal is the number of items in a cluster that came from reputable sources. Another signal is the composition of the cluster\u2014how many items are tweets vs blog posts.","Importance can change over time. As a cluster grows, its importance grows. In some embodiments, a decay factor is applied. If nothing has changed for a given period of time, the contribution of dynamics to the cluster starts to decay. A history of the various importance scores of a cluster is recorded. Clusters may also \u201cpick up steam\u201d again after decaying. Since the trend data is known, and the causes are known (e.g., that in the last 10 minutes, 100 people tweeted something that was previously on the decline), the cluster may be shown again.","User feedback can also be employed. There are two kinds of user feedback\u2014general feedback such as how often users collectively click on URLs\u2014and personalized feedback (relating to how likely it is that a story will be of interest to a specific user, e.g., how often they click on entertainment stories). Collaborative filters can also be used to measure how often a group of users that are like an individual user click on a URL. Additional data sources, such as the user's profiles\/history on various social networking sites and browser history, can be used in conjunction with user feedback signals. As one example, say a particular user's friend tweeted about an article. The cluster may be given a higher weight than it might otherwise receive due to the friend having taken that action.","Yet another type of signal relates to a predictive model. Given a particular entertainment story, and historical knowledge of how entertainment stories behave, a prediction can be made about a cluster associated with the story (e.g., how many tweets it is expected to have after 24 hours have elapsed). For example, history stories (i.e., about historical figures and places) tend to move slower than entertainment stories. If a history story is growing quickly, that information can be used as a factor in its importance. Stories that have higher predictive signals may be shown to users more quickly than those that do not. In one example embodiment, users are presented with \u201ctomorrow's news today\u201d user interface based on the signal. The interface can include a histogram of when various news sources are anticipated to pick up the story. As another example, suppose a very important person (e.g., a president) tweets infrequently. If that person tweets on a Monday evening, the predictive model anticipates that the tweet will be a popular news item within 8 hours. Instead of waiting for other sources to pick up the tweet, the story may be presented to users immediately.","The following is an example of a computation of a score calculation. In this example, signals include:","1. User signals: ranks of the users whose items are included in the cluster","2. Site signals: ranks of the domains of the URLs mentioned in the cluster","3. Dynamics signals: How many items are in the cluster and how fast did they arrive","4. Diversity signals: What ratio of the items are tweets, updates, blog posts, etc.","Example score formula: UserSignal*userSignalWeight+SiteSignal*siteSignalWeight+DynamicsSignal*dynamicSignalWeight+DiversitySignal*diversitySignalWeight","In various embodiments, the calculation is weighted based on the channel\u2014scores change based on a channel and an interest.","Managing Real-Time Data Streams",{"@attributes":{"id":"p-0174","num":"0173"},"figref":"FIG. 8","b":"136"},"In some embodiments, system  includes a distributed computation system, such as the one shown in . The system illustrated in  is implemented using commodity nodes interconnected using Gigabit Ethernet.","Data Model","Elements in a data stream are modeled as Events. For example, each tweet is an Event, as is each Facebook status update. Formally, an Event is a record with a variable number of attribute-value pairs. Values can either be atomic or collection types, such as sets and lists. Certain fields are present in every Event: a streamid (which stream does this Event belong to), a timestamp, and a key. The key attribute always has an atomic value. Keys are used to group related Events, and there is no requirement that the key be unique across Events. For example, the key for a tweet can be the Twitter username (e.g., to group tweets by user) or, the key can be a set of categories (e.g., to group tweets by category). The other attributes will depend on the kind of Event. For example, a tweet will contain Twitter-specific fields.","A Stream is a collection of Events with the same streamid attribute. An assumption is made that timestamps are monotonically increasing with time, but not necessarily dense. At any point in time, there are usually several Streams: some of them external (e.g., Twitter, Facebook) and others that are generated as intermediate values and outputs by the application.","A Slate is a persistent attribute-value collection (i.e., a collection of key-value pairs) usually related to a group of Events: for example, all the tweets that mention a particular link, or all the tweets related to a given news story. The attributes are application dependent, except for one required attribute: the slatekey. The value of this attribute is a primary key for the Slate: the system shown in  guarantees that there is exactly one Slate with a given slatekey. The system shown in  persists Slates and makes it very efficient to access them by slatekey; in practice, the most active Slates are stored in memory and only old, inactive Slates may need to be fetched from disk.","The system shown in  provides primitives that construct new Events and Slates, as well as examine, add or modify attributes of existing Slates given their slatekey. Events are assumed to be immutable. If in the process of a computation, it becomes necessary to add an attribute to an Event, the idiom is to create a new event that copies the current Event, add the additional attribute, and emit the new Event, usually on a different Stream.","Computation Model","Computation in a streaming model is Event-driven: things happen in reaction to new Events. One way to organize computation in a streaming model is publish-subscribe. Computational units subscribe to Events and publish Events. All Events from all Streams are placed on the same \u201cStream Bus,\u201d and the system (in particular, the Bus Conductor) takes care of routing Events as appropriate. There are two kinds of computational units: Map and Update.","Map is a stateless computation. A Mapper (the unit that performs a Map) is invoked with an Event. It publishes zero or more new Events on to the bus, possibly to different Streams. Mappers subscribe to one or more Streams, and get invoked for every Event on each of those Streams.","Update is a stateful computation. An Updater is invoked with an Event and a Slate; in particular, the Slate whose slatekey matches the key of the Event. If no such Slate exists, the system creates a blank Slate (with only the slatekey attribute filled in). The Updater can examine the Slate and also add, remove, or modify the Slate in any way (except changing the slatekey). An Updater publishes zero or more Events, possibly to different Streams. An Updater, like a Mapper, subscribes to zero or more Streams, and gets invoked for every Event on each of those Streams. To summarize:","map(Event)\u21924 (Event)*","update(Event, Slate)\u2192(Event)*","If more than one computational unit is subscribed to a Stream, they will each get every Event on the Stream. However, the order in which they get invoked is nondeterministic; it is possible they get invoked concurrently, possibly on different nodes.","In some embodiments, the system shown in  makes the following guarantees related to scheduling and concurrency:\n\n","An Application is a collection of Streams, Mappers, Updaters, and subscriptions.","Map and Update: Additional Details","A Mapper is obtained by subclassing a system-defined Mapper class. The programmer defines a single method with the following signature:","map(Event event)\/* process an Event *\/The programmer uses the system-provided publish(event,streamid) method to publish Events to Streams. An Updater subclasses a system-defined Updater class and provides three methods:","init(Slate slate)\/* initialize the state of a Slate ahead of any Events *\/update(Event","event, Slate slate)\/* process an Event and possibly update the Slate *\/","finalize(Slate slate)\/* called before the Slate is destroyed *\/","The update( ) method: When an Updater is subscribed to a Stream, and an Event arrives with a never-before-seen key, the system creates a new Slate with that slatekey and then calls the init( ) method of the updater. The system guarantees that update( ) will only be called on an initialized Slate.","The init( ) method can be used to initialize application-specific data structures on the Slate. In addition, it can also specify a time-to-live (TTL) for the Slate, using the system-provided set_ttl( ) method. This parameter is interpreted as follows. If the Slate is not accessed (read or written) for a period that equals the TTL, the system calls the finalize( ) method for that Slate and then destroys it. This feature of the model allows the system shown in  to \u201cforget\u201d very old data (e.g., old clusters). The default TTL is infinity; that is, the Slate persists forever.","Once the application has defined its Mappers and Updaters, it calls a system-provided subscribe( ) method on them (this method is provided by the system-defined Mapper and Updater classes that every Mapper or Updater subclasses).","Mapper.subscribe(streamid)","Updater.subscribe(streamid)","Included in the system shown in  is a highly scalable, available, and fault-tolerant persistent key-value store . The key-value store is used to store system metadata as well as persistent storage for Slates. One example of such a key-value store is Cassandra. The key-value store forms the storage layer of the Map-Update system.","Also included in system  are a Stream Bus , a Conductor , and Workers . The Stream Bus receives every Stream Event and buffers it for the Conductor. If the Conductor falls behind or fails over, the Stream Bus buffers the Stream so that Events are not lost. Each Worker node has a pool of Worker processes. Each process has all the code for every Mapper and Updater in the system, and can run any Map or Update. In some embodiments, modules such as modules - are implemented as Workers.","The Conductor is the master that manages subscriptions and routes Events to computational units. It maintains metadata about the available Workers and Subscriptions. When it receives an Event, it finds Mappers and Updaters subscribed to the Stream. It determines which Worker node to use for each Mapper and Updater, and invokes them appropriately.","Slates are stored in the key-value store, indexed by slatekey. The Slate is serialized to become the value in the key-value store and de-serialized when it is read back. It is assumed that the key-value store is distributed and runs on a separate set of nodes from the Map-Update system.","Task Scheduling: One Example Implementation","When an Event arrives, the Conductor has to decide which Worker node(s) run the Mapper(s) and Updater(s) subscribed to the Stream. One implementation is to allocate tasks round-robin among the Workers, hoping that the result will be that every Worker node gets a roughly equal computational load at every point in time. A slightly better scheme is for the Conductor to poll the Workers periodically and collect load data, and schedule tasks on the most-lightly-loaded node.","To ensure atomicity in this model, every time an Updater is scheduled, it needs to read its Slate from the key-value store when it starts, and write back the updated Slate (if it made updates) to the key-value store. Suppose the system processes n events\/second, and each Event accesses k Slates. Also suppose each Slate is s bytes in size. A total of nk key-value store operations\/second, transferring nks bytes\/second of data between the key-value store and Worker nodes is required.","Task Scheduling: Alternate Implementation","Computation blocks are moved close to the data it accesses. At any point, a single Worker node can be made the Primary for a given slatekey. When an Event arrives, the Conductor examines its key, and schedules Updaters for it on the primary node for that key. Mappers are still scheduled as in the prevoius implementation.","Each Worker node maintains an in-memory (or in-SSD) cache of Slates. These are Slates for which this Worker node is the Primary. By default, the cache is write-through; writes are written back immediately to the key-value store. When an Updater is scheduled on a Slate, it is very likely that its most recent value is in the cache, not requiring a read from the key-value store. The application can control the write-through behavior with a write-delay parameter. This parameter relaxes the immediate write-through and allows the cached Slate to be written back, say, every few seconds.","Streams can be subject to spiky behavior, with bursts of activity for the same key. The Primary node approach, together with the write-delay parameter, allows this feature to be harnessed. The Slate for such a \u201chot\u201d key will remain in the Primary's cache, and will be read and written several times in-cache for every access to the key-value store. The write-delay allows the application to trade-off between scalability and absolute correctness. If a Worker node fails, the updates in its cache that have not yet been written through to the key-value store are lost.","The Conductor periodically polls Workers and gathers load data. If the Primary node for an event's key has a load less than a specified threshold (e.g., 80% utilization), schedule the Updater on the Primary. If not, the Conductor picks the most lightly-loaded Worker as the new Primary for this key. It will have to wait for a time period slightly longer than the write-delay before scheduling Updaters for this key on the new primary. That will ensure that any updates from the old Primary have been written through to the key-value store. The new Primary then gets the most recent value of the Slate from the key-value store.","Application Slates and Keyspaces","In some embodiments, the application is given access to the key-value store. Application Slates are used to facilitate application access to the key-value store. Isolation between system-Slates and application-Slates is ensured by using separate keyspaces. A keyspace is specified by a prefix in front of the key, with a colon separating the keyspace name and the key. For example, \u201cfoo:bar\u201d is key \u201cbar\u201d in keyspace \u201cfoo.\u201d Only system  can create Slates in the \u201csystem:\u201d namespace. Applications can create in any other namespace. Updaters can create, access, and modify application Slates by key.","Exemplary embodiments providing methods, systems and devices for processing and managing real-time data streams are described further in the Section entitled \u201cProcessing of Real-Time Data Streams\u201d.","Tagging a Document",{"@attributes":{"id":"p-0216","num":"0218"},"figref":"FIG. 9","b":["916","918","924","918","920","922","922","924","924"]},"In the example shown, documents, such as document , are provided to document processing system  for processing. Examples of documents include blog posts made on site , forum messages exchanged on site , news articles made available through site , the various types of documents served by site , and any other text (in formats such as HTML, TXT, PDF, etc.), as applicable.","In various embodiments, for a given document , document processing engine  produces two types of output\u2014a list of entities  and a document vector . As used herein, an entity is a pair of items\u2014a textual representation (i.e., a string of text appearing in the document) and a concept associated with the textual representation. Unlike the textual representation (which is literally present in the document), the associated concept need not be literally present in the document. Instead, the concept is present in a taxonomy, such as is stored in database .","As one example, suppose a news article describes the saving of a baby from a fire by a dog. An excerpt from the article reads \u201cThe small, heroic sheltie saved baby Fred on Tuesday.\u201d When the article is provided to system , one example of an entity  that is generated is (\u201csheltie\u201d,\u201cShetland Sheepdog\u201d). The first portion of the pair (the textual representation) is the fourth word of the excerpt. The second portion of the pair is the associated concept that is included in a taxonomy of concepts\u2014the canonical name of the breed of dog also known as a \u201csheltie.\u201d Document vector  is a ranked list of concepts associated with the document. An example of a document vector  for the dog article is: (pets:10, dogs:6, Shetland Sheepdog:4, arson:2) with each concept having an associated score. In various embodiments, the associated scores are normalized between 0 and 1.","In the example shown in , system  comprises standard commercially available server hardware (e.g., having a multi-core processor, 4G+ of RAM, and Gigabit network interfact adaptors) running a typical server-class operating system (e.g., Linux). In various embodiments, system  is implemented across a scalable infrastructure comprising multiple such servers, solid state drives, and other applicable high-performance hardware. In the environment shown, Acme Corporation owns a document processing system  that provides functionality similar to that of system . System  is configured to receive as input various internal documents and to categorize and summarize those documents in accordance with the techniques described herein.","Whenever system  is described as performing a task (such as communicating with a client or accessing information in a database), either a single component or a subset of components or all components of system  may cooperate to perform the task. Similarly, whenever a component of system  is described as performing a task, a subcomponent may perform the task and\/or the component may perform the task in conjunction with other components. In various embodiments, portions of system  are provided by one or more third parties. As one example, database  stores a taxonomy comprising millions of concepts. The taxonomy can be created by system  (using techniques described in more detail below) and can also be supplied to system  by a separate component, or by a third party. As another example, database  also includes various statistical information, such as inverse document frequency information, that can be periodically computed by system , supplied by a separate component, or provided by a third party.",{"@attributes":{"id":"p-0222","num":"0224"},"figref":"FIG. 10","b":["906","1010","1014","906","906","1018","906"]},"Conversion\/Preprocessing","When a document, such as document , is received, if applicable, preprocessor  converts the document (e.g., from a DOC or PDF file) or otherwise extracts (e.g., from HTML or XML) a plaintext representation of the content of the document. Preprocessor  is also configured to handle special characters, such as by converting occurrences of the \u201c&\u201d sign into whitespace or into the word \u201cand.\u201d","Boundary Processing\/Position Information","Boundary processor  is configured to recognize certain types of boundaries within a document based on the format of the document (e.g., <head>, <body>, <h1>, and <p>HTML tags) and can also parse configuration information supplied by publishers regarding the formatting of documents on their sites. The document shown in  includes two sections\u2014a title section and a body section. In some embodiments, document boundaries are ignored and the processing of boundary processor  is omitted. In various embodiments, boundary processor  is also configured to store, for each term in the document, the position of the term. As one example, the first word in the document would have a position 0, the second word in the document would have a position 1, and so on. As will be described in more detail below, terms that appear in one section of a document (such as a title) may be scored or otherwise treated differently than terms that appear in another section (such as in the comments). In addition, publishers can use sections to enforce preferences, such as that all terms appearing in a document be used to categorize the document, but that only terms appearing in the main body (and not the title or comments sections) be able to be associated with hyperlinks. Such preferences can be provided by the publisher via configuration .","Natural Language Processing","Natural language processor  is configured to determine part-of-speech information for each term in the document. In various embodiments, natural language processor  uses part-of-speech tags, such as are provided by the Brown corpus, to tag each term in the document. Using the article shown in  as an example, \u201cNASA's\u201d would be tagged \u201cNP$,\u201d meaning that it is a possessive proper noun. As will be described in more detail below, in various embodiments, different parts of speech are assigned different scores and those scores can be used in evaluating textual representations.","Textual Representation Detection","Whitelist , extracted from the taxonomy stored in database , is a list of all of the concepts that are included in the taxonomy. Textual representation detector  is configured to perform a greedy match against the document using whitelist . Each match is included in a list of candidate textual representations . Using the first line of the article shown in  as an example \u201cNASA,\u201d \u201cmission,\u201d \u201corbit,\u201d and \u201cmoon,\u201d would each be included in the list of candidate textual representations\u2014. Suppose \u201cLunar\u201d and \u201cLunar Reconnaissance Orbiter\u201d are both phrases that are included in whitelist  but \u201cLunar Reconnaissance\u201d is not. Because detector  is configured to perform a greedy match, \u201cLunar Reconnaissance Orbiter\u201d will be added to the list of candidate textual representations  while the other two terms will not. In various embodiments, detector  is configured to perform other types of matches, instead of or in addition to greedy matches. In some embodiments, all matches (e.g., both \u201cLunar\u201d and \u201cLunar Reconnaissance Orbiter\u201d) are added to list .","Leading Prepositions","Suppose \u201cThe American\u201d and \u201cAmerican Pie\u201d are both concepts included in whitelist , but that \u201cThe American Pie\u201d is not. Also suppose that document  includes the string \u201cThe American Pie movie is showing at the Downtown Theatre tomorrow.\u201d When performing its greedy match, detector  might add to list  two entries, \u201cThe American\u201d and \u201cPie,\u201d erroneously omitting \u201cAmerican Pie.\u201d To address this problem, in some embodiments, detector  employs a prepositional rule in which, when a match that includes at its start a preposition is detected, the preposition is temporarily ignored and the greedy match continues using the next word in the document. If a match is found, the preposition is discarded and the phrase that does not include it is used. In this example, because \u201cThe American\u201d includes a leading preposition, \u201cThe\u201d would be temporarily ignored, and a match of \u201cAmerican Pie\u201d would be detected. From the three words, \u201cThe American Pie,\u201d only one entry would be added to list \u2014\u201cAmerican Pie.\u201d","Without further refinement, the list of candidate textual representations  might include virtually every word in document . Accordingly, in various embodiments, textual representation detector  employs additional logic to refine the list of candidate textual representations. As will be described in more detail below, the candidate list can be refined\/pruned both before and after feature vectors for items on the candidate list are populated.","Static and Runtime Blacklists","In various embodiments, textual representation detector  is configured to exclude from inclusion in list  those textual representations that match a blacklist . Stop words (such as \u201ca,\u201d \u201cabout,\u201d \u201cagain,\u201d and \u201cwould\u201d) are one example of terms that can be included in a static blacklist. A publisher can also provide custom blacklists (referred to herein as \u201cruntime\u201d blacklists) that should be considered by engine  when processing that particular publisher's documents. As one example, a publisher may blacklist the names of competitors. As another example, the publisher may have an agreement with a third-party advertising company that certain words be directed to that advertising company. By employing a blacklist, the publisher can prevent the already-contracted-for words from being considered by engine . Publishers can also specify constraints such as requiring that all textual representations belong to one or more verticals (also referred to herein as \u201ctop level categories\u201d) specified by the publisher, which will be described in more detail below.","Concept-Based Blacklists","Concepts included in a taxonomy can be used to bias\/prune candidate textual representations, as will be described in more detail below. As with the examples described in the previous section, concept-based blacklists can be static (e.g., applied to all documents) or runtime (e.g., used according to a configuration supplied by a publisher or other runtime clue). For example, an administrator of engine  can configure as blacklisted concepts \u201cchronology\u201d and \u201cdays of the week.\u201d Child topics such as \u201cMonday\u201d and \u201c1997\u201d would be blacklisted as a result. As another example, a preference can be indicated for health-themed textual representations by specifying the vertical, \u201cHealth,\u201d as a whitelisted concept in configuration . A preference against adult-themed textual representations can be implemented by specifying the vertical \u201cAdult Entertainment\u201d as a blacklisted concept. Instead of supplying whitelists\/blacklists, in some embodiments weights are assigned to various categories, so that higher weighted categories are given preference over lower weighted categories by engine . As one example, the following weights could be provided: \u201cHealth(1); Sports(0.5)\u201d indicating a preference for health-related concepts but also indicating that sports concepts should be considered.","In various embodiments, concept whitelist\/blacklist information is passed in at runtime via the provider of document  instead of or in addition to being supplied via configuration . Whitelist information can also be collected on behalf of a publisher, without requiring the publisher to manually specify category preferences. One way of accomplishing this is as follows. When a publisher initially decides to use the services provided by system , system  performs the document categorization techniques described herein across the corpus of documents included in the publisher's site and collects together the dominant concepts into a concept whitelist.","Regular Expression Patterns","In various embodiments, textual representation detector  is configured to exclude from inclusion in list  those textual representations that match a regular expression. As one example, as a result of converter\/preprocessor  manipulating document , a term such as \u201cAT&T GSM\u201d may be converted to \u201cAT T GSM.\u201d Suppose \u201cTGSM\u201d is a concept included in whitelist . During the greedy match portion, \u201cTGSM\u201d may be erroneously added to candidate list . A regular expression pattern that discards matches that begin with a lone \u201cT\u201d or a lone \u201cS\u201d can be used to prevent the erroneous match from being included.","Proper Noun Sequences","In various embodiments, textual representation detector  is configured to evaluate proper nouns included in list  and remove from the list those proper nouns that have an adjacent proper noun that was not selected. One purpose of this rule is to prevent one person that has a famous last name (but is not that famous person) from being erroneously recognized as the famous person. Suppose an article discusses a chemist named John Mozart and that \u201cMozart\u201d is added to list  as a result of the greedy match. Since \u201cJohn Mozart\u201d is not included in whitelist , it is not included in list . Detector  is configured to recognize that Mozart was added, has an adjacent proper noun (\u201cJohn\u201d) and to remove \u201cMozart\u201d from list .","Initial Feature Vector Population","Vector populator  is configured to populate a feature vector  for each candidate textual representation included in list . A feature vector comprises a set of various signals associated with the textual representation. The signals can be used in various ways, as will be described in more detail below. Some of the signal information is obtained from analyzing document  and other information is obtained from data included in database .","One signal, denoted herein as \u201cTitleTF,\u201d indicates the number of times that the term appears in the title section of the document. Using the textual representation, \u201cLunar Reconnaissance Orbiter,\u201d as shown at  in  as an example, that term is not present in the title section of the document and thus has a TitleTF=0. \u201cBodyTF\u201d is a signal that indicates the number of times that the term appears in the body section of the document. The term, \u201cLunar Reconnaissance Orbiter\u201d has a BodyTF=1 because it is present once in the body section of the document. Another textual representation, \u201cLRO,\u201d also has a TitleTF=0, but has a BodyTF=3. Other term frequency counts can also be used instead of or in addition to TitleTF and BodyTF, as applicable. For example, the term's frequencies with respect to meta tags, bold\/strong tags, H3-H6 tags, H1-H2 tags, and anchor classes can all be included in its feature vector. As another example, a CommentTF signal can be used to indicate the number of times a term appears in the comment section of a blog. Arbitrary section frequency counts can also be used, such as Section0TF, Section1TF, Section2TF, etc., indicating the number of times the term appears, respectively, in the 0, 1, and 2sections of the document. One way that section frequency signal information can be used is to allow words occurring in the comments to be considered when categorizing a document, but also to prevent those words from being selected for automated hyperlinking.","As mentioned above, a score (the \u201cNLP score\u201d) can be assigned to a textual representation based on its part of speech. As one example, proper nouns are assigned a score of \u201c1,\u201d common nouns are assigned a score of \u201c0.75,\u201d and verbs are assigned a score of \u201c0.\u201d For multi-word textual representations, the NLP score can be computed as the average of each constituent word's score, the sum of each constituent word's score, or in accordance with any other appropriate calculation. The \u201cCase\u201d signal scores the number of capitalized words in the textual representation. In the example of \u201cLunar Reconnaissance Orbiter,\u201d the Case score is 3 because each component of the term is capitalized. In the example of \u201cApollo landing sites,\u201d as shown in , the Case score is 1.","Both the NLP score and the Case score can be used to resolve whether particular textual representations included in the document are proper nouns or common nouns and also to resolve ambiguities, as described in more detail below. As one example, the occurrence of the words \u201cSimply hired\u201d in a document could refer to the author's explanation of how easy it was to be hired at a job and could also refer to the jobs website, www.simplyhired.com. The Case score of \u201cSimply hired\u201d is 1. The Case score of the canonical name of the jobs website, Simply Hired, is 2. As another example, \u201cit's it\u201d in a document could refer to something the author thinks is \u201cit,\u201d but could also refer to It's-It brand ice cream sandwiches. The Case score of \u201cit's it\u201d as written is 0. The Case score of the canonical form of the ice cream sandwich product is 2.","The Position signal indicates the relative location of the textual representation in the document. \u201cLunar Reconnaissance Orbiter\u201d occurs once in document , at position . In various embodiments, if the textual representation occurs multiple times, the position of each occurrence is included in a list (e.g., Position=100,202,554). In various embodiments, the position of the term can be used to bias various processing. For example, links to terms occurring earlier in the document can be preferred over ones occurring later.","The NumWords signal indicates the number of words included in the textual representation. \u201cLunar Reconnaissance Orbiter\u201d includes three words, and thus has NumWords=3.","The signals described herein are examples of signals and particular signals can be omitted and\/or accompanied by additional signals based on factors such as availability of data\/information, preferences, and other implementation choices.","Transforming Candidate Textual Representations into the Taxonomy Space","Mapper  is configured to map candidate textual representations to nodes in the taxonomy stored in database . As explained above, the whitelist  used to identify textual representations is extracted from a taxonomy stored in database . Each node in the taxonomy has an associated ID. As one example, the concept \u201cLunar Reconnaissance Orbiter\u201d has a ConceptID of 2381014. The concept \u201cacademic conference\u201d has a ConceptID of 118760. In some cases (such as with \u201cLunar Reconnaissance Orbiter\u201d), the textual representation unambiguously corresponds to a single node in the taxonomy (i.e., node ). In other cases, the textual representation's meaning may be ambiguous. For example, a textual representation of \u201cjaguar\u201d occurring in a document could correspond to the concept \u201cJaguar Cars Ltd.,\u201d to the concept \u201cPanthera onca,\u201d to the concept \u201cMac OS X v10.2,\u201d or one of several other concepts. A textual representation of \u201capple\u201d occurring in a document could correspond to the concept \u201cMalus domestica,\u201d to the concept \u201cApple Inc.,\u201d or one of several other concepts.","In various'embodiments, mapper  determines the set of all concepts to which a particular textual representation maps. Each mapping is associated with a mapping vector. Mapping vectors () are either of type \u201cunambiguous\u201d or type \u201cambiguous.\u201d A mapping vector is of type \u201cunambiguous\u201d only if a given textual representation maps to a single concept. Otherwise, it is of type ambiguous. A mapping vector also stores additional information, such as a pointer to the textual representation in the document, the conceptID of the mapped concept, the feature vector of the textual representation, and a strength value that indicates a confidence in the mapping. As will be described in more detail below, in some embodiments the mappings  initially created by mapper  are pruned through a series of refining actions.",{"@attributes":{"id":"p-0254","num":"0256"},"figref":["FIG. 12","FIG. 12"],"b":["1202","1204","1206","1208","1210"],"sub":["1","1","1 ","1 ","2 ","3","2 ","1 ","3"]},"Mapper  sorts a document's textual representations into a set of unambiguous textual representations (e.g., tr) and a set of ambiguous textual representations (e.g., tr, tr, and tr). For each ambiguous textual representation, the mapper determines whether a concept to which it is mapped is also a concept to which a textual representation that is unambiguous is mapped. If so, the ambiguous textual representation is reclassified as an unambiguous textual representation and is mapped solely to the concept to which the unambiguous concept is mapped.",{"@attributes":{"id":"p-0256","num":"0258"},"figref":["FIG. 13","FIG. 13"],"b":["1028","1302","1304","1306"]},{"@attributes":{"id":"p-0257","num":"0259"},"figref":["FIG. 14","FIG. 12","FIG. 13","FIG. 14","FIG. 14"],"sub":["2 ","1 ","3","1 ","1","1 ","2 ","4","1","1","2"],"b":["1028","1210","1208"]},"The process of  can also be used to resolve ambiguities for textual representations which are not synonyms of one another but share related concepts. As one example, suppose \u201cSteve Jobs\u201d is a textual representation included in a document and unambiguously resolves to the concept of businessman, Steven Paul Jobs. The textual representation \u201capple\u201d is also present in the document, in the sentence, \u201cI would like to buy an apple.\u201d The term, \u201capple\u201d is not synonymous with \u201cSteve Jobs,\u201d however, its potential meaning as a fruit can be disambiguated by the presence of Steve Jobs in the document. One approach for accomplishing this is for mapper , when performing portion  of the process shown in , to examine the nearest neighbors of concepts in the taxonomy. Another approach is to use the concept blacklist\/whitelist signals described in more detail below. Yet another approach is to use a document similarity score described in more detail below.","In some embodiments, for any remaining textual representations in the ambiguous textual representation set (e.g., four meanings of \u201cjaguar\u201d), a mapping between the textual representation and the concept corresponding to each possible meaning is added to the unambiguous set (e.g., four different unambiguous mappings), and the textual representation (\u201cjaguar\u201d) is removed from the ambiguous set. Engine  is configured to remember that the meaning of the textual representation was not resolved (i.e., that jaguar could mean one of four things). As will be described in more detail below, pruning of three of the four different unambiguous mapping vectors is performed after a document vector is computed and a document similarity score generated.","Creating a Concept Feature Vector","In addition to the processing described above, vector populator  is also configured to populate a set of concept feature vectors . One way of accomplishing this is as follows. For each concept remaining after the processing of , vector populator  merges the feature vector scores of any textual representations mapped to respective concept (e.g., by adding the values together) and includes additional information (described in more detail below).","Using the example of the representations \u201cLunar Reconnaissance Orbiter\u201d and \u201cLRO,\u201d a concept feature vector for \u201cLunar Reconnaissance Orbiter\u201d is formed by summing the respective feature vectors of the two textual representations and adding additional information. The concept \u201cLunar Reconnaissance Orbiter\u201d would accordingly have a TitleTF=0+0=0, a BodyTF=1+3=4, and so on.","Inverse Document Frequency Signal","One additional piece of information that is included in the concept feature vector is the inverse document frequency (\u201cIDF\u201d) of a canonical textual representation associated with the concept. As one example, \u201cJFK,\u201d \u201cJohn F. Kennedy,\u201d and \u201cJack Kennedy\u201d all refer to the 35president of the United States. The canonical textual representation is \u201cJohn F. Kennedy\u201d and the IDF included in a concept feature vector for the president would be determined using \u201cJohn F. Kennedy.\u201d The canonical textual representation is stored in the taxonomy in database  and is in some embodiments the title of the concept as it appears in a third party corpus such as Wikipedia. In some embodiments, the IDF is computed for all textual representations occurring in the document instead of or in addition to the canonical textual representation.","The IDF is a statistical measure that can be used to evaluate how important a word is to a particular document included in a corpus of documents (e.g., the world wide web, documents on an enterprise server, etc.). For a given term \u201ci,\u201d one way to compute the IDF of i is as follows:",{"@attributes":{"id":"p-0266","num":"0268"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["IDF","i"]},"mo":"=","mrow":{"mi":"log","mo":"\u2062","mfrac":{"mrow":[{"mo":["\uf603","\uf604"],"mi":"D"},{"mo":["\uf603","\uf604"],"mrow":{"mo":["{","}"],"mrow":{"mi":"d","mo":":","mrow":{"msub":{"mi":["t","i"]},"mo":"\u2208","mi":"d"}}}}]}}}}},"br":{},"sub":["i","i "]},"Number of Homonyms Signal","Another piece of information that can be included in the concept feature vector is the Homonyms signal. This signal indicates the number of homonyms for the concept and can be used to weight against (or toward) the selection of concepts that can easily be confused with other concepts. The number of homonyms associated with a concept is, in some embodiments, included in the taxonomy stored in database .","Concept Whitelist\/Blacklist Signals","Yet another piece of information that can be included in the concept feature vector is whether or not the concept is present in a concept whitelist (or concept blacklist, as applicable). For example, in configuration , publishers can specify concept whitelists (concepts they prefer to bias toward) and concept blacklists (concepts they have a bias against). If the concept is present in the concept whitelist, in some embodiments a Whitelist=1 signal is included in the concept feature vector (and has a \u201c0\u201d value otherwise). If the concept is present in the concept blacklist, in some embodiments a Blacklist=1 signal is included in the concept feature vector (and has a \u201c0\u201d value otherwise). The whitelist\/blacklist signals can be used as weights and can also be used to prune concepts.","Linkworthiness, Popularity, and Freshness Signals","\u201cLinkworthiness\u201d is another signal that can be precomputed for a concept in the taxonomy and included in a concept feature vector. One example of a linkworthiness signal is a measure of how frequently the concept is included in a hyperlink in a corpus. As one example, suppose \u201cbottled water\u201d occurs 4,543 times within the corpus of documents that comprise the Wikipedia site. However, the term is linked a single time. Bottled water would accordingly have a linkworthiness score of 1\/4,543=0.00022. As another example, suppose \u201ccarpe diem\u201d occurs 200 times and is linked to 88 times. Carpe diem would accordingly have a linkworthiness score of 88\/200=0.44. A corpus including multiple sites and\/or the entire World Wide Web can also be parsed in determining linkworthiness instead of or in addition to Wikipedia. In some embodiments, the documents used to perform the linkworthiness determination are selected based on a pagerank or other measure of their quality. For example, links included in highly rated newspaper sites might be parsed, while links included in domain parked sites would not. The measure of quality can also be factored into the linkworthiness score itself.","For ambiguous concepts, such as \u201cjaguar,\u201d in addition to determining the number of times a concept is linked, the meaning to which it is linked is also examined. For example, suppose that within Wikipedia, \u201cjaguar\u201d appears 500 times. Of those 500 instances, 300 have associated hyperlinks. Of the 300 hyperlinks, 60% direct the viewer to a page about Panthera onca, 30% direct the viewer to a page about the car company, and the remaining 10% of links direct viewers to other (even less common) meanings of the word. In this example, a popularity score can be associated with each of the meanings and used as a signal (described in more detail below), such as the cat meaning having a popularity score of 0.6, the car meaning having a popularity score of 0.3, and so on. In the case where the Wikipedia corpus is used, whether or not a particular ambiguous concept is designated as the default can also be used as a measure of popularity.","The \u201cfreshness\u201d of a topic can also be used as a signal. Such information can be gleaned by scraping Twitter feeds, news aggregation sites, and other indicators of current topics, stored in the taxonomy and included by vector populator  in the concept feature vector. One example of a change in a concept's freshness is the concept \u201ccupola.\u201d Prior to the STS-130 shuttle mission, the term rarely appeared in news articles and Twitter messages. The inclusion in the payload of a cupola for the International Space Station, however, resulted in considerably more use of the term and thus its freshness score rose.","In various embodiments, the linkworthiness, popularity, and freshness signals are combined together into a single signal. The values may be binary (e.g., fresh=0 or fresh=1) or any other appropriate value, typically normalized between 0 and 1.","Additional Signals","A capitalization signal can be used to indicate how often a concept is capitalized in documents appearing in a corpus such as the World Wide Web. As one example, the n-gram data made available by Google can be used to estimate the percentage of times a concept is capitalized.","In some embodiments, rules are used to weight various signals on a category basis. For example, if a topic such as \u201cHired\u201d belongs to the category \u201cFilm,\u201d a category-based rule can be used to give higher weight to the Case signal accordingly.","Pruning Concepts","In various embodiments, once vector populator  has completed populating concept feature vectors , some of the concepts are pruned. For example, concepts having a non-zero TitleTF score and a BodyTF=0, having NLP scores of 0, or having very low EDF scores (e.g., a term such as \u201cshopping\u201d) are dropped. As another example, concepts that are orphans (e.g., nodes in the taxonomy without at least one parent or child) are also dropped.","As explained above, the \u201cCase\u201d score of a textual representation can be used when determining whether the textual representation maps to a particular concept. Suppose \u201cHas Been\u201d is the name of a musical album (a concept) and \u201chas been\u201d appears in a document . The Case score of the concept is 2, because the musical album's title is capitalized. The Case score of the textual representation is 0. In some embodiments, the musical album is pruned due to the mismatch in Case scores.","As another example, if concept whitelist\/blacklist information has been provided to engine , the information can be used to resolve ambiguous meanings. For example, suppose medically themed site  has specified either the vertical \u201cHealth\u201d or a series of lower level concepts such as \u201cnutrition\u201d and \u201corganic foods\u201d in whitelist . Also suppose that document  includes an ambiguous occurrence of the textual representation \u201capple\u201d which is mapped by mapper  in accordance with the techniques described above to two concepts\u2014a fruit and a computer company. The ambiguity can be resolved (and one of the two concepts pruned) by detecting that the Whitelist signal for the fruit concept has a value of 1 and the Whitelist signal for the computer concept has a value of 0.","In some embodiments, filtering is performed by various components of the document processing engine at various stages of processing. For example, in some embodiments, orphan concepts are omitted from whitelist . As another example, in some embodiments, filtering based on scores such as NLP scores and IDF scores occurs prior to the processing described in conjunction with portion  of the process shown in .","Category Vectors","Each concept \u201cc\u201d in the taxonomy stored in database  has an associated category vector . In various embodiments, the category vector is precomputed (i.e., prior to the processing of document ) and is also stored in database . For a particular concept c in the taxonomy, the category vector is a set of categories\/concepts that are related to that concept c, along with a weight for each of the included categories\/concepts. A variety of techniques can be used to compute the category vector.","One way to populate the category vector is to use the up-lineage of the concept (e.g., parents, grandparents, etc.), and assign a decreasing score based on distance (e.g., parents have a score of 0.9, grandparents have a score of 0.8, etc.). A second way to populate the category vector is to use the down-lineage of the concept (e.g., children). A third way to populate the category vector is to use a predetermined list of concepts designated as being \u201crelated\u201d to the concept (e.g., including siblings), or to use the concept lighting techniques described in more detail below.","A fourth way to populate the category vector is to use membership in a subset \u201cK\u201d of a taxonomy \u201cT,\u201d where |K|<<|C|. For example, K can include only verticals and entity classes. Further, elements within K should not have parent-child relationship, meaning that all members of a given k in K should not automatically be members of another k.","Document Vector","Vector populator  is configured to populate a document vector  for each document . In some embodiments, this is accomplished by computing the average of all category vectors implicated by the concepts associated with document  remaining after the pruning described above. Document vector  can thus be denoted as follows:",{"@attributes":{"id":"p-0290","num":"0292"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"dv","mo":"=","mrow":{"mfrac":{"mrow":{"munder":{"mo":"\u2211","mi":"n"},"mo":"\u2062","msub":{"mi":["cv","i"]}},"mi":"n"},"mo":"."}}}}},"In some embodiments, the document vector is normalized so that the sum of the components of cvis 1. Other techniques can also be used to compute a document vector, as applicable. For example, a weight value on an exponent can be included in the computation such that top level concepts (like \u201chealth\u201d and \u201csports\u201d) are favored or disfavored, as indicated by a publisher, over bottom level concepts (like \u201cSungold Tomato\u201d). As another example, the computation of the document vector can take into account rules such as that concepts that have ambiguous parents be excluded from the document vector, that concepts associated with terms appearing in the title be weighted significantly more than other concepts, etc. Document vector  is one example of output that can be provided by engine  to various applications described in more detail below.","Document Similarity and Further Disambiguation","In some embodiments, vector populator  is configured to use document vector  to compute a set of document similarity scores. For a given concept, the document similarity score is computed as: ds= \u2218 . It provides an indication of how similar the concept vector is to the document vector. Once computed, the document similarity score is included in the concept's feature vector . In various embodiments, other similarity scores, such as a site similarity score, can also be computed (e.g., by computing the similarity of a concept over all the documents from a given site) and included in feature vector .","The document similarity score can be used to resolve remaining ambiguities. For example, suppose document  includes the statement, \u201cJaguar prices are climbing.\u201d Absent additional information, the textual representation \u201cJaguar\u201d could plausibly refer to either an animal or an automobile. By examining the document similarity scores of both the Panthera onca and the Jaguar Cars Ltd. concepts, disambiguation can be performed. For example, if the document is an article about the cost of zoo exhibits; concepts such as \u201czoo\u201d and \u201cwildlife\u201d and \u201cpark\u201d will likely be included in the document vector, while concepts such as \u201cluxury cars\u201d and \u201chigh performance engine\u201d will likely not (or will have considerably lower scores). Accordingly, the document similarity score of \u201cPanthera onca\u201d will be considerably higher than the score for \u201cJaguar Cars Ltd.\u201d and the ambiguity can be finally resolved by pruning the second concept.","In some embodiments, additional information is employed to resolve remaining ambiguities. For example, the textual representation, \u201cMichael Jackson\u201d most frequently refers to the American musician. However, the taxonomy also includes other individuals of note that are also named \u201cMichael Jackson\u201d (e.g., a civil war soldier, a British television executive, etc.). It is possible that a document could be referring to a Michael Jackson that is not the musician. In various embodiments, the popularity of a particular concept is used as one consideration (e.g., with the musician meaning being more popular than the civil war solider) and concept's document similarity score is used as another. Based on customizable weights, engine  can be configured to disambiguate concepts such as \u201cMichael Jackson\u201d by preferring the popular meaning (and pruning the others), except when the document similarity score overwhelmingly indicates (e.g., having a document similarity score exceeding 0.7) that an alternate meaning should be selected. As another example, the freshness of a topic can be considered.","Ranking Results","Even after the scoring and pruning actions described above have been performed, for a given document , it is possible that hundreds (or more) of textual representations and associated concepts remain as candidates. Typically, only a handful of the top textual representations and\/or concepts are needed.","Ranker  is configured to rank the concepts remaining in consideration after the above processing\/pruning has been performed. One approach is to use a scoring function s that computes a score given a concept feature vector. In various embodiments, what weights to apply to the various signals included in the concept feature vector are empirically determined and then tunes using linear regression. In various embodiments, only a subset of the signals is used (e.g., a combination of the document similarity score and linkworthiness\/popularity\/freshness signals). For a given document , a threshold\/cutoff is applied to limit the final list of concepts to an appropriately manageable size for consumption by an application. Concepts having a score above the threshold (and their corresponding textual representations) are provided as output (i.e., \u201centities\u201d).","Publishers can, through configuration , specify customized rules for the combination function used to calculate final concept scores. For example, publisher  can specify as a rule that while all medical concepts should be considered by engine  when generating the document vector , disease symptoms should not be output as entities. As another example, publisher  might choose to weight the values of the Whitelist\/Blacklist signals more heavily than publisher , who might in turn prefer another signal, such as by preferring concepts with the higher freshness scores, or a monetization signal that measures how well a given concept monetizes. One benefit of using category-based monetization is that an extrapolation can be made as to the monetization of a very specific textual representation based on the concept (or higher level category\/vertical) with which it is associated. It may be the case that pharmaceuticals monetize well but names of diseases do not. When a new pharmaceutical is introduced to market, the publisher need not take any action to indicate a preference toward textual representations of the new pharmaceutical as a candidate term. As another example, if specific words are empirically determined to monetize well on a given publisher's website (e.g., \u201cgolden retriever\u201d or \u201ccollie\u201d), the categorization of those words (e.g., \u201cbreeds of dog\u201d) within the taxonomy can be used by engine  to bias the selection of other words belonging the category (e.g., \u201cbeagle\u201d) even absent historic data for those other words.","In some embodiments, the threshold\/cutoff is manually selected, such as by a publisher specifying in configuration  that a maximum number of 10 entities be returned. In other embodiments, engine  applies a dynamically generated threshold based on factors such as the document length. For example, the publisher can specify a link density, such as that up to 5% of the number of words in a document be included in entities. In some embodiments, the number of textual representations remaining in candidate list  is used as a proxy for the document length. Other information, such as click-through rate data, can also be used to determine the cutoff number of entities and also as an additional, site-specific signal that can be stored (e.g., in database ) and used while processing other documents (e.g., as an additional concept feature vector signal).",{"@attributes":{"id":"p-0301","num":"0303"},"figref":["FIG. 15","FIG. 11"],"b":["1502","1504"]},"Example Process for Detecting an Entity",{"@attributes":{"id":"p-0303","num":"0305"},"figref":["FIG. 16","FIG. 16"],"b":["906","1602","1602","118","118","906","1604","1008","1606","1028","1608"]},{"@attributes":{"id":"p-0304","num":"0306"},"figref":["FIG. 17","FIG. 17","FIG. 16"],"b":["906","1702","1702","118","118","906","1704","1604","1608","1706","1014","1706"]},"Creating a Hierarchy of Concepts from a Corpus of Documents",{"@attributes":{"id":"p-0306","num":"0308"},"figref":"FIG. 18","b":["1802","1808","1804","1806"]},"As described in more detail below, crawler  performs tasks such as tagging the documents stored in index  with subject type concepts and with information type concepts (also referred to herein as \u201cinfotypes\u201d). Crawler  also performs and stores the results of frequency and cooccurrence counts. Crawler  may be a single device, or its functionality may be provided by multiple devices. For example, elements typically used in conjunction with a crawler to create an index, such as an indexer, are described herein as being provided by crawler , but may also be performed by separate devices or components and the techniques described herein adapted accordingly. For example, in some embodiments, cooccurrence counts are performed by concept lighting engine .","Documents in collection  can include, but are not limited to text files, multimedia files, and other content. In some embodiments, collection  includes documents found on an intranet. Also included in collection  are a variety of concept data sources -. In the example shown, source  is the set of web pages known collectively as Wikipedia (and available, e.g., at http:\/\/en.wikipedia.org). Source  is a directory of automobile makes and models, and source  is a taxonomy of pharmaceuticals. In some cases, such as with Wikipedia, the pages are used both as concept data sources, and are also included in group  and are crawled accordingly. In other cases, such as with the directory of automobile makes and models, the information may be restricted or otherwise not available to crawler , and the concept data source will serve only as a concept data source and not be included in group .","Concept data sources - each provide information that conveys some kind of relation between concepts and can be used as a source of concepts and also as a source of hierarchical relations between at least some of those concepts. For example, suppose a sample entry in automobile directory  is: \u201c2008 Honda Civic Sedan XL.\u201d Using the techniques described herein, it is possible to extract hierarchical information from the entry, for example, that the \u201c2008 Sedan XL\u201d is a type of \u201cHonda Civic,\u201d and that a \u201cHonda Civic\u201d is manufactured by \u201cHonda.\u201d Pages within Wikipedia typically refer to their conceptual parents by link. For example, the Wikipedia page on the topic of \u201cAstronomy\u201d has a link to its parent (typically by labeling the parent as its \u201ccategory\u201d), the more general subject of \u201cScience.\u201d The Wikipedia page on the topic of \u201cIndia\u201d includes a link to \u201cSouth Asian Countries,\u201d which includes a link to \u201cAsian Countries\u201d which includes a link to \u201cCountries by Continent.\u201d The entries in the pharmaceutical taxonomy are likewise related to one another in a manner that can be harvested using the techniques described herein.","For each of the concept data sources -, one or more arc generators  are used to parse the respective concept data source, extract concepts and relations between concepts, and store the information in a common format () that can be consumed by aggregator . For example, a Wikipedia arc generator is configured to obtain and parse Wikipedia data made available as a single XML file. From the XML file, pairs of concepts\u2014an article and a category to which it belongs\u2014are extracted. Another arc generator is configured to parse the automobile directory (e.g., provided as a spreadsheet) and generate arcs accordingly, such as by knowing that for each line of the spreadsheet, the first column (year) should be combined with the last column to form \u201c2008 Sedan XL,\u201d which has as its parent the second and third column (\u201cHonda Civic\u201d), which has as its parent just the second column (\u201cHonda\u201d). As used herein, an arc is a directional edge between two concepts. A concept is a word n-gram with meaning. One relation between concepts as used herein is an \u201cis a\u201d (\u201ccontaining\u201d) relation. For example, \u201cPhysics:Science\u201d is an arc that means \u201cphysics is a science\u201d (\u201cscience contains physics\u201d). As described in more detail below, additional relations may also be employed, such as by homonym and synonym arcs. Other directed relations between arcs that convey meaning may also be employed, and the techniques described herein adapted as applicable. For example, case variants and tokenization can be handled through the use of flags.","The respective content of concept data sources - may change at various times, and arc generators  are configured to obtain and process fresh versions of data from their corresponding concept data sources as applicable so that files  reflect the most currently known concepts and relations from those sources. For example, Wikipedia () changes frequently, while the content of the pharmaceutical taxonomy  may change very infrequently. As such, in various embodiments, arc generators  periodically process their respective sources according to a schedule appropriate to the source (e.g., with the Wikipedia arc generator running weekly, and the pharmaceutical arc generator running monthly). Editorial list  is a manually maintained list of arcs and relations used, for example, to designate a fixed set of top level concepts (also referred to herein as \u201cverticals\u201d) and to ensure that those top level concepts are not moved underneath one another or omitted.","Aggregator  aggregates the source-specific arc files  extracted by their respective arc generators  and the editorial list of arcs  and creates as output arc list  and vertex list . As described in more detail below, arc list  is a list of edges and properties that will be used to construct a concept hierarchy . Each time aggregator  runs, the newly constructed arc list  replaces any previously constructed arc list. Vertex list  is a persistent list of globally unique concepts that monotonically increases\u2014maintaining a set of stable concept identifiers over the iterations of aggregator 's processing, and growing only when a concept not previously seen is encountered by aggregator , which is then appended to the list.","As described in more detail below, hierarchy builder  constructs hierarchy  using arc list  and additional information such as a list of subtree preferences  and information obtained from index . The subtree preferences list  includes rules to be considered by hierarchy builder  when evaluating arc list . In various embodiments, hierarchy  is stored as a list of pairs of concepts, a weight, and optionally other arc attributes such as homonym and synonym indicators. The weight is a rank indicating whether the arc is the primary arc between a concept and a parent (\u201c1\u201d) or whether the arc is an additional arc (e.g., \u201c2\u201d or \u201c3\u201d) that was inserted into the hierarchy after the primary arc was selected.","In some embodiments, hierarchy builder  constructs hierarchy  by building a directed graph based on the information it receives, and then extracting a directed minimum spanning tree (\u201cDMST\u201d) from that graph (in which every concept (also referred to herein as a \u201cnode\u201d) present in the tree except the root has exactly one parent, and no cycles or orphans are present). A variety of techniques for finding a minimum spanning tree have been developed. One example is the Chu\/Liu-Edmonds algorithm.","Hierarchy builder  optionally employs a DAG builder , which inserts additional nodes into the DMST to form a directed acyclic graph (\u201cDAG\u201d) of concepts. An optional interface allows an administrator to view why nodes are placed in the hierarchy where they are and to audit the effects of making changes to the rules used in constructing the hierarchy. For example, if certain nodes are not consistently being placed under appropriate parents, an administrator can make additions to the subtree preferences list  or add entries to editorial arc list  as applicable. For example, an administrator may use the interface to specify that when B has C as a parent and A has a choice of parent B or C, A should select B as its parent so that a deeper hierarchy is created. This property of A, B, and C is sometimes referred to as transitive reduction.",{"@attributes":{"id":"p-0316","num":"0318"},"figref":"FIG. 19A","b":["1824","1902","1904","1818","1906","1910","1818","1912","1820","1830","1902","1912"]},"One factor that can be considered in the determination of which candidate parent is the best, is what score is assigned (e.g., by an administrator) to each of the candidate parents' concept source (referred to herein as an \u201carc rank\u201d score). Typically, the arcs provided by specialized concept sources (such as the automobile directory) are preferred over more general concept sources (such as Wikipedia). In the example shown in , a lower arc rank score indicates a better (preferred) source. In some embodiments, arc rank generators  are configured with what arc rank score should be assigned their respective arcs, and those scores are included in the source specific arc rank files . In other embodiments, aggregator  is configured by an administrator with a list of sources and their respective scores.","Wikipedia as a source has a score of 20, as indicated in region . The automobile directory is considered a \u201cbetter\u201d source of information than Wikipedia for its specialized information on automobiles, and therefore, each of the arcs that are contributed to arc list  by its arc list  receive a score of 10, as indicated in region . The editorial arc list is intended to override entries in arc list  provided by source specific arc lists  and has an even better (lower preference order) score as indicated in region . As described in more detail below, a graph constructed from the data shown in  would include a leaf \u201cHonda Civic RX\u201d which is a \u201cHonda Civic\u201d which is made by \u201cHonda\u201d which is a \u201cCar Manufacturer(s)\u201d which is contained by \u201cKosmix Autos.\u201d",{"@attributes":{"id":"p-0319","num":"0321"},"figref":"FIG. 19B","b":["1826","1804","1","2","1830"]},{"@attributes":{"id":"p-0320","num":"0322"},"figref":"FIG. 19C","i":"Felidae Puma P. concolor","b":"1828"},"In the example shown in FIG. C\u2014a portion of aggregated arc list \u2014each of the lines was provided by the Wikipedia arc list . The Wikipedia arc generator  is configured to recognize disambiguation pages when parsing the Wikipedia source XML file and record as arcs the ambiguous term and each of the disambiguated options in the arc list  as a pair, along with a \u201chorn\u201d (for homonym) flag. Each disambiguated word is given a separate entry in the vertex file, such as the \u201cJaguar_animal\u201d line shown in . The Wikipedia arc generator  is also configured to recognize redirection pages when parsing the Wikipedia source XML file and records as arcs each of the synonyms and the main entry (\u201ccougar\u201d) in the arc list  as a pair, along with a \u201csyn\u201d (for synonym) flag. In some embodiments, different weights are given to homonyms and\/or synonyms over normal arcs instead of or in addition to the use of flags.","In some embodiments aggregator  is configured to remove homonym arcs in which the ambiguous term and the disambiguated term do not begin with the same word, so that the over generation of homonym arcs is reduced. For example, since \u201cMac OS Jaguar\u201d does not begin with \u201cJaguar,\u201d it is removed (or omitted, as applicable) from arc list . As another example, Wikipedia offers \u201cFiona Apple\u201d as a disambiguation of \u201cApple.\u201d Such an arc would likewise be deleted or omitted from arc list .",{"@attributes":{"id":"p-0323","num":"0325"},"figref":"FIG. 19D","b":["1830","1900","1828"]},"In contrast, entry  states that any chain of arcs (with up to 3 levels distance) that includes a parent of \u201ccountries by continent\u201d is to be preferred. In some embodiments, entries in the subtree preferences list are applicable at all depths and the depth column is omitted. What entries should be included in the subtree preferences list (and what scores\/depths should be assigned) is generally subjective, and can be refined over time, such as by evaluating logs. The subtree preferences provide a mechanism for an administrator to remove or favor a potentially large number of arcs without having to manually enter rules for each arc. For example, by preferring \u201ccountries by continent,\u201d all countries listed in Wikipedia will tend to be grouped under countries by continent (possibly at varying depth levels), and an administrator need not specify a rule for each country.",{"@attributes":{"id":"p-0325","num":"0327"},"figref":["FIG. 20","FIG. 18"],"b":"1830"},"The process begins at  when a graph of arcs of concepts is received. In some embodiments, the graph includes the XML representation of Wikipedia. In some embodiments, the graph comprises an arc list such as arc list . Other sources of arcs of concepts, at least some of which can be connected to form a graph (irrespective of whether that graph contains some orphans or cycles) may also be used, as applicable. For example, in some embodiments a graph or portions thereof is received from a third party at .","At , weights associated with the arcs in the graph are generated. As described in more detail below, a variety of techniques can be used, individually and in combination, to generate weights at . For example, arc rank scores, Boolean values, cooccurrence scores, mutual information, etc., can be used to form a single weight or a vector of weights at .","At , a directed minimum spanning tree is extracted from the graph received at . In some embodiments, preprocessing is performed, such as to remove orphan nodes which cannot be reached from the root, and the directed minimum spanning tree is extracted from the preprocessed graph rather than the graph as received at . One way of constructing a DMST is as follows. For each node in the graph, a single parent is selected, such as by using the vector of weights generated at  to evaluate candidate parents. By biasing the selection of parents toward the best parent (e.g., the one with the lowest source score), an attempt is made to preserve the consistency of the \u201cis a\u201d\/containing relationship up the DMST, such as that calculus is a form of mathematics. Next, any cycles in the graph are detected by hierarchy builder . An example of a cycle is an arc from \u201cships\u201d to \u201cboats\u201d and another from \u201cboats\u201d to \u201cships\u201d both being present in the graph. Sometimes cycles are created in Wikipedia data because two nodes are imputed to have a hierarchical relationship when they are in fact peers. For example, a node \u201cBert\u201d may have as a parent \u201cErnie\u201d and vice versa. Hierarchy builder  runs a process to reduce the number of cycles. The selection of a best parent, the detection of cycles, and the reduction of cycles continues iteratively until an acyclic tree is formed. As described in more detail below, optional post processing can be performed on the acyclic tree.",{"@attributes":{"id":"p-0329","num":"0331"},"figref":["FIG. 21","FIG. 21"],"b":["2102","1824","2104","2102","2104"]},"In various embodiments, some values included in the vector of weights are read in from files, and others are provided by additional processes (e.g., plugins) which calculate and provide scores. The first portion of the vector of weights to compare between the two candidates is the \u201cvariance\u201d score, indicated in column . The variance score indicates the number of internal links which point to the candidate parent. Both candidate parents have a score of three, meaning that the vectors are tied, so the next portion of the vector is evaluated.","The next portion of the vector of weights to compare between the two candidates is the \u201cvertical correction\u201d score, indicated in column . In some embodiments the construction of a DMST is performed twice. The first time it is run, the vertical correction score is zero. The second time it is run, a vertical correction score is determined by a process that attempts to keep nodes that are peers grouped together under the same parent. For example, suppose that 95% of house plants are placed under \u201cbotany,\u201d but 5% select as best parents \u201chealth\u201d on the first run. The vertical correction process is configured to detect the discrepancy and will indicate that a \u201cbotany\u201d parent should be selected by returning a nonzero score in column  (such as a Boolean value) during the second run. In various embodiments, normalization and\/or a threshold is applied so that in cases such as a 60\/40 split, the vertical correction process does not attempt to group peers under the same parent. In the example shown, both candidates have a score of zero. The vectors are tied, so the next portion of the vector is evaluated.","The next portion of the vector of weights to compare between the two candidates is the \u201ctemplates\u201d score, indicated in column . The value for the templates score is provided by a process that evaluates nodes against groups or lists of concepts and attempts to keep those groups together. If concepts are present in multiple groups, the process attempts to keep the most number of groups; or the most important groups together, etc., as applicable. The lists\/groups may be provided by a third party and\/or configured by an administrator or otherwise obtained. For example, Wikipedia provides set information for certain entries which can be scraped by crawler . Examples of groups include a list of the planets in the solar system, a list of human diseases, a list of the seven dwarves, British Commonwealth countries, etc. In the example shown, Ronald Reagan appears in a list of United States presidents. As such, a score of one is present in column  for \u201cU.S. President\u201d but not for \u201cActor.\u201d Since there is no longer a tie between the two vectors, \u201cU.S. President\u201d would be selected as the best parent for the concept \u201cRonald Reagan.\u201d If both values in column  were equal, however, the next portion of the vector would be evaluated, and so on, until the tie was broken. In the example shown, the remaining columns are as follows. Column  reports whether a process evaluating the loaded subtree preferences list  has determined that a positive or negative preference exists for the arc. If no such preference is found, column  reports a zero. If a preference is found, it is indicated in some embodiments as a positive or negative value. Column  is the arc rank score described previously.","Columns , , and  report various statistics about the presence of the concept and its candidate parent within the documents stored in index .","The \u201cocc\u201d column () includes a score that represents a frequency count for the concept. A frequency count indicates the frequency of the occurrence of the concept within the pages in index . The frequency count is determined in some embodiments by crawler  using vertex list  to scan through each of the documents in index  and increment the \u201cocc\u201d for the concept for each page in the index that includes at least one occurrence of the concept. The \u201cpocc\u201d column similarly represents a frequency count for the candidate parent.","The \u201ccooc\u201d column includes a score that represents the cooccurrence of the concept and candidate parent in the pages in index . Cooccurrence scores are determined in some embodiments by crawler  evaluating the cooccurrence of concepts which are connected by an arc (e.g., are present in arc list ). Techniques such as using a running window of words can also be employed to avoid quadratic blowup.",{"@attributes":{"id":"p-0336","num":"0338"},"figref":["FIG. 22","FIG. 22"],"b":"1830"},"The process begins at  when vertex list  is loaded, allowing hierarchy builder  to map concept names (e.g., human readable concept names) to concept IDs. At , a graph is built using arc list \u2014for example by connecting pairs of concepts together and storing any associated properties. If duplicate arcs are encountered, the properties of the duplicate arcs are merged. For example, if one line in arc list  reads Physics:Science:20 and another line in arc list  reads Physics:Science:10, the arcs are \u201cmerged\u201d with the best weight being preserved (e.g., Physics:Science:10). If one source indicates that an arc is a homonym arc, and another source indicates that the arc is a synonym arc, the arcs are merged and both flags are set for the merged arc. At , subtree preferences list  is loaded, as are any applicable case variance or tokenization variance information.","At , a DMST is constructed. First, a best parent is selected for each node by performing a local decision comparing vectors of weights. Next, cycles are detected. One way of detecting cycles is to traverse the graph, marking each node as \u201cseen\u201d as it is visited. If a node is reached again during the traversal, a cycle has been located. For each cycle, an evaluation is made between the cost of removing an arc and the cost of adding an incident arc, and selecting the appropriate arcs whose addition\/removal have the lowest associated cost. In some embodiments, the comparison is a difference of vectors, and is computed by replacing the values in the vectors with minwise elements. As stated previously, the selection of a single parent, the detection of cycles, and the reduction of cycles continues until each node (except the root) has exactly one parent. In some embodiments, post processing is performed, such as vertical correction.","At , the DMST is extended to a DAG using additional arcs. For example, at , synonym arcs are inserted into the DMST, as are homonym arcs, so long as acyclicity is preserved. In some cases, additional concept arcs are included in the DAG where doing so would not result in the formation of a cycle. For example, including \u201cActor\u201d as a second parent of \u201cRonald Reagan\u201d will not result in a cycle and will preserve the \u201cis a\u201d relationship up the hierarchy. However, the insertion of other arcs (not previously shown), such as between \u201cRonald Reagan\u201d and \u201cHollywood Walk of Frame,\u201d might be inappropriate, e.g., because the \u201cis a\u201d\/containing relation would be skewed away (e.g., if the parent of \u201cHollywood Walk of Frame\u201d is \u201cLandmarks\u201d\u2014Ronald Reagan is not a Landmark). One way of inserting additional arcs into the DMST is to first globally rank the omitted arcs. Rules can be used, such as that additional arcs will be inserted into the DAG, in the globally ranked order, so long as the arc to be inserted is of a smaller depth than the existing single parent for the node, or that arcs can be inserted within the same vertical but only one additional arc may be added into a different vertical from the existing single parent, or that additional arcs must have a threshold cooccurrence score before they are placed into the DAG.","In some embodiments at least some orphan nodes are placed back into the DMST at . One way of placing orphans is to perform a search using the orphan as an input to the query categorization techniques described in more detail below. If the results are sufficiently dense, the orphan can be placed in the appropriate place in the DAG. Similarly, the hierarchy of concepts can be expanded by crawling the documents  for word n-grams and also attempting to place them into the DAG by using the word n-grams as an input to the query categorization techniques described in more detail below.",{"@attributes":{"id":"p-0341","num":"0343"},"figref":["FIG. 23","FIG. 22"],"b":["2302","2304","2308","2310","2312","2314","2318"]},"Tagging Documents with Concepts",{"@attributes":{"id":"p-0343","num":"0345"},"figref":["FIG. 24","FIG. 24"],"b":["1828","1830","1806"]},"One way of tagging a document in index  with subject type concepts is as follows. For each concept in vertex list , use the concept as a search query against the documents in index . Evaluate the results using standard text match and link scoring techniques (e.g., by examining the number of occurrences of the query on the page, the page title, the link text, metadata, whether the concept appears in bold, etc). Such techniques, which measure how well the text of a query matches a document are collectively referred to herein as \u201ctext match scoring\u201d techniques producing \u201ctext match scores,\u201d although more than just the text of the document may be evaluated by such techniques.","For any particular page, the concept (query) which results in the highest text match score for the page is that page's top concept. The concept which results in the second highest text match score for the page is that page's second concept, etc. Any given document may include thousands of concepts from vertex list . Thus, in some embodiments, a threshold is applied and the document is tagged with its resulting top n concepts, such as the top 30 concepts.","Websites typically have common elements across the various pages that are included in that site. For example, a news website may include a left or right navigational section that includes the terms, \u201cHealth,\u201d \u201cFinance,\u201d \u201cWorld News,\u201d etc. The site may also include a prominent logo on every page. In some embodiments such common elements are identified and ignored or stripped during indexing so that text match scores are not skewed by the prolific presence of those common elements. Identifying and ignoring or stripping common elements allows text match scores and infotype rules to be applied specifically to the distinct content of each document.","One way of tagging a document in index  with an infotype is to determine whether any rules associated with those infotypes is satisfied by the document. For example, documents hosted by a known image hosting service (e.g., stock-photo library), or having an image with a certain minimum pixel size may be indicative of an image type document (e.g., a document having one or more informative images), and be tagged as having an infotype \u201cimages.\u201d Conversely, documents with discouraging ALT text (e.g., \u201cadvertisement\u201d), a standard advertisement size or location, and generic filenames suggestive of being merely decorative or formatting elements (e.g., \u201cpixel.gif\u201d, \u201cfooter.jpg\u201d) indicate that while including an image, the document is unlikely to be of interest to a user seeking images and are not tagged with the \u201cimages\u201d infotype.","Documents hosted by a known news site (e.g., www.wsj.com), having a title indicative of a news source (e.g., \u201cBreaking News\u201d), or including a copyright notice from a known news agency\/newswire (e.g., \u201cAssociated Press\u201d) are tagged as being of infotype news. Documents with a title that includes words such as \u201cevent,\u201d \u201ccalendar,\u201d \u201cupcoming,\u201d etc., are tagged with the \u201cevents\u201d infotype. Documents that include terms specific to categories of local venues (e.g., amusement parks, toy stores, police stations, That restaurants, dentists) or including links to map services are tagged with the \u201clocal\u201d infotype. Documents that include terms (e.g., appearing on a wordlist) such as \u201cadd to cart,\u201d \u201ccoupon,\u201d and \u201ccheckout\u201d are tagged with a \u201cshopping\u201d infotype, etc.","If multiple rules for different infotypes are satisfied by a document, the document is tagged with multiple infotypes as applicable. For example, a photojournalist's blog about current events might be tagged with both the \u201cimages\u201d and the \u201cnews\u201d infotypes.","Although the foregoing embodiments have been described in some detail for purposes of clarity of understanding, the invention is not limited to the details provided. There are many alternative ways of implementing the invention. The disclosed embodiments are illustrative and not restrictive.","Processing Of Real-Time Data Streams","Many computational methods depend on processing large volumes of real-time data in a distributed manner using a large number of computers. Recent years have seen an explosive growth in the volume of real-time data that may be used by computational methods in many domains. Real-time data is increasingly being made available and being used by a large number of people, for example, through popular social networking services, such as the Twitter\u2122 and Facebook\u2122 social networking websites. The increasing availability, use and growth of real-time data raise real-time data overload issues and the need for sophisticated computational methods that are able to process and track desired information in the real-time data in a rapid, distributed and fault-tolerant manner.","Exemplary embodiments provide devices, systems and methods for performing large-scale long-running stream computations on real-time data streams in which input data in the data streams is selectively read and output data is written to durable storage. Exemplary embodiments allow computations to be performed on input data streams that are dynamic and evolving in real-time as the computations are being performed. That is, exemplary embodiments are not restricted to performing computations on static snapshots of data streams or static data sets. Nonetheless, one of ordinary skill in the art will recognize that exemplary embodiments may also be used to perform stream computations on non real-time data streams and on computations on non-stream data, e.g., static data or static snapshots of data streams.","Exemplary embodiments may allow one or more applications to perform real-time stream computations using one or more map operations and\/or one or more update operations. A map operation is a stream computation in which stream events in one or more real-time data streams are processed in a real-time manner to generate zero, one or more new stream events. The map operation may publish the generated stream events to one or more real-time data streams in a real-time manner. In an exemplary embodiment, a map operation may publish stream events to a data stream from which it receives stream events as input. An update operation is a stream computation in which stream events in one or more real-time data streams are processed in a real-time manner to create or update one or more static \u201cslate\u201d data structures for persistent storage in durable disk storage. In some exemplary embodiments, an update operation may generate zero, one or more new stream events. The update operation may publish the generated stream events to one or more real-time data streams in a real-time manner. In an exemplary embodiment, an update operation may publish stream events to a data stream from which it accepts stream events as input.","Conventional mechanisms of performing computations on large volumes of data include search engines that provide a gateway to the World Wide Web. An exemplary conventional search mechanism offered is by Google Inc. which includes hardware components including clusters of commodity nodes connected through commodity networking means, and software components including the Google File System and the MapReduce software framework. The MapReduce software framework supports distributed computing on large data sets on clusters of computers. MapReduce employs, inter alia, map operators that partition input data and distribute them to worker nodes, worker nodes that processes the data partitions to generate answers, and reduce operators that collect the answers and combine them to form the output.","However, conventional mechanisms like MapReduce are not suitable for use in processing or performing computations on data streams because data streams possess certain fundamentally different properties from the types of non-stream data sets that may be processed by MapReduce. MapReduce is only capable of being run on a static snapshot of a data set in which the input data set does not and cannot change between the start of the MapReduce computation and the end of the computation. For example, in MapReduce, no reduce operator can be run until all of the map operators have completed processing data. In contrast, exemplary embodiments allow stream computations to be performed on data streams that are changing and evolving in real-time as the computations are being performed. That is, exemplary embodiments are not restricted to performing computations on static snapshots of data streams or static data sets.","Every MapReduce computation has a definite \u201cstart\u201d point and a definite \u201cfinish\u201d point, i.e., the computation does not continue forever or for an indeterminate period of time. In MapReduce, for every key that the reduce operators view, the operators need to view all of the values associated with the key, which is not possible to view in a streaming model. In contrast, exemplary embodiments allow stream computations to be performed on data streams that may continue forever or for an indeterminate period of time. Since exemplary stream computations may proceed for an indeterminate period of time, a large amount of state may begin to accumulate in the system. Exemplary embodiments provide mechanisms for storing state so that the state is efficiently accessed and updated in stream computations, e.g., update operations. In addition, in order to avoid an explosive and continual growth in the state saved in the system, exemplary embodiments provide mechanisms to \u201cforget\u201d or delete desired portions of the state.","Conventional computational mechanisms are not susceptible to spikiness in the input data because, since these mechanisms operate on static snapshots of the data over time, spikes in the input data are smoothed away. As a result, conventional mechanisms are able to achieve natural load balancing by partitioning the input data in any suitable manner. In contrast, stream computations performed in exemplary embodiments are susceptible to spikiness in the flow of stream events in the input data streams. For example, a particular topic or link may suddenly become \u201chot\u201d or popular in an input data stream, resulting in a sudden surge and a subsequent sudden subsidence in the number of stream events in the input data streams that are related to that topic or link. In a distributed computing model, spikiness in input data streams can result in \u201chot spots\u201d in the data structures and nodes used to perform computations relating to a popular topic or link. In order to maintain computational efficiency in the face of this issue, exemplary embodiments are able to react in a fast and efficient manner to surges in input data streams, and to balance computational loads relating to the \u201chot spots\u201d so that that the data structures and nodes are still able to operate efficiently and generate output in short response times.","In conventional computational mechanisms like MapReduce, it is possible to re-start a computation in case of a software error or hardware failure. However, it may not be possible to re-start stream computations performed on real-time data streams as the data streams may continue to flow at their own rate oblivious to computational or processing issues. Exemplary embodiments allow computational processes to recover from software errors and hardware failures in a fast and efficient manner to avoid lagging behind input data streams.","Conventional mechanisms like the MapReduce software framework typically read and produce large files that are stored in disk storage that may be represented as a distributed storage layer, like the Google File System and the Hadoop\u2122 Distributed File System (HDFS). In contrast, there is a reduced need for a large disk storage or a large distributed storage layer in exemplary embodiments. Exemplary stream computations may be less disk-heavy and more memory-heavy than conventional mechanisms like the MapReduce software framework. This is because exemplary data stream computations may read a stream as it flows by, maintain in disk storage data structures pertaining to the stream, and maintain in memory one or more active or recently accessed data structures to facilitate fast and efficient access of the in-memory data structures.","Certain terms are defined below to facilitate understanding of exemplary embodiments.","As used herein, the terms \u201cdata stream,\u201d \u201cevent stream\u201d and \u201cstream\u201d refer to a sequence of one or more units of data that are published or transmitted in a real-time manner.","As used herein, the terms \u201cstream event\u201d and \u201cevent\u201d refer to a unit of data published or transmitted in a data stream in a real-time manner. A stream event may have any suitable data structure or format. In an exemplary format, a stream event may include a collection of one or more attribute-value pairs.","As used herein, the term \u201cslate\u201d refers to a static data structure that may be used to record data about a set of one or more related stream events. A slate may have any suitable data structure or format. In an exemplary format, a slate may include a collection of one or more attribute-value pairs. A slate may be stored corresponding to its unique slatekey attribute value and corresponding to an update operation that updates the slate.","As used herein, the terms \u201coperator\u201d and \u201coperation\u201d refer to a set of one or more computations performed at least partially on one or more stream events in a data stream.","As used herein, the terms \u201cmap operation,\u201d \u201cmap operator\u201d and \u201cmapper\u201d refer to a stream operation performed in exemplary embodiments in which stream events in one or more real-time data streams are processed in a real-time manner to generate zero, one or more new stream events. The generated stream events may be published to one or more real-time data streams. In an exemplary embodiment, a map operation may publish stream events to a data stream from which it accepts stream events as input.","As used herein, the terms \u201cupdate operation,\u201d \u201cupdate operator\u201d and \u201cupdater\u201d refer to a stream operation performed in exemplary embodiments in which stream events in one or more real-time data streams are processed in a real-time manner to create or update one or more persistent static \u201cslate\u201d data structures that are stored in a persistent manner in a durable disk storage. In some exemplary embodiments, an update operation may generate zero, one or more new stream events. The generated stream events may be published to one or more real-time data streams. In an exemplary embodiment, an update operation may publish stream events to a data stream from which it accepts stream events as input.","As used herein, the term \u201cstream computation\u201d refers to a computation performed in real-time on an input that is received from a real-time data stream. That is, the input received by the stream computation may be dynamic and may change over time even as the stream computation is being performed. A stream computation may generate an output that takes the form of a stream event that is published to a real-time data stream, or a data structure that is updated in real-time based on the computation. A stream computation may be performed by one or more map operations and one or more update operations. Exemplary stream computations may include, but are not limited to, determining one or more \u201chot\u201d or popular topics on Twitter\u2122, determining the time of the last post published by a Twitter\u2122 user, performing K-rank computations to determine a user's influence on other users, performing analytics on data published on a website, determining a user's current interests based on their postings on social networking websites, grouping web page view events into \u201cvisits\u201d and generating aggregate statistics over \u201cvisits\u201d (such as, a rate at which the web page view is terminated, the number of page views per \u201cvisit\u201d), determining different sets of links on a web page to identify a set that maximizes the click-through rate (CTR), and the like.","As used herein, the term \u201cdistributed\u201d refers to a system or framework in which a data computation layer and\/or a data storage layer may be implemented so that different portions of the data computation or different portions of a data storage are distributed over a plurality of computing devices, e.g., commodity nodes, worker nodes, etc. The computing devices may be geographically proximal to or remote from one another.","As used herein, the term \u201ccomputer-readable medium\u201d refers to a non-transitory storage hardware, non-transitory storage device or non-transitory computer system memory that may be accessed by a computational system or a module of a computational system to encode thereon computer-executable instructions or software programs. The \u201ccomputer-readable medium\u201d may be accessed by a computational system or a module of a computational system to retrieve and\/or execute the computer-executable instructions or software programs encoded on the medium. The non-transitory computer-readable media may include, but are not limited to, one or more types of hardware memory, non-transitory tangible media (for example, one or more magnetic storage disks, one or more optical disks, one or more USB flash drives), computer system memory or random access memory (such as, DRAM, SRAM, EDO RAM, etc.) and the like.","Exemplary embodiments are described below with reference to the drawings. One of ordinary skill in the art will recognize that exemplary embodiments are not limited to the illustrative embodiments, and that components of exemplary systems, devices and methods are not limited to the illustrative embodiments described below.","Exemplary embodiments provide one or more data types suitable for real-time data stream processing including, but not limited to, data streams, stream events and slates.","A stream event is a unit of data in a real-time data stream. An exemplary event may be implemented in any suitable data structure or format. An exemplary event data structure may include one or more attributes and corresponding attribute values. In exemplary embodiments, the attributes may be atomic and the attributes values may be atomic or collection types, e.g., sets, lists, etc.","In an object-oriented implementation, an \u201cEvent\u201d class or object may be defined to represent stream events. Exemplary embodiments may provide functionality to create one or more new stream event objects, and to access information contained in the one or more event objects, for example, using get methods in an object-oriented implementation. In an exemplary embodiment, events may be immutable, i.e., may not be altered once created. In this embodiment, if it is necessary to add or alter an attribute of an event, exemplary embodiments may create a new event copied from the existing event, add or alter the attribute, and publish the new event to an appropriate data stream. In another exemplary embodiment, events may be mutable, i.e., may be altered. In this embodiment, exemplary embodiments may provide functionality to alter one or more attributes of an event, for example, using set methods in an object-oriented implementation.",{"@attributes":{"id":"p-0375","num":"0377"},"figref":"FIG. 25","b":["2500","2500","2502","2500","2504","2504"]},"In exemplary embodiments, a stream event  may include a timestamp attribute  having a value indicating the time at which the event was generated. In an exemplary embodiment, the time recorded in the timestamp attribute value may be a global time that is applicable uniformly across all real-time data streams of interest, e.g., Twitter\u2122 and Facebook\u2122 data streams. That is, the global timestamp attribute value may be generated by the system, and not by each data stream individually. In an exemplary embodiment, each data stream may also add a local time relative to the stream to the timestamp attribute value. The timestamp attribute values may monotonically increase in some exemplary embodiments.","Exemplary events may include one or more additional attribute-value pairs  based on the type of the data streams or the type of the events. For example, \u201ctweet\u201d events may include Twitter\u2122-specific attributes and corresponding values, e.g., a text attribute that has as its value the entire text of a particular \u201ctweet.\u201d",{"@attributes":{"id":"p-0378","num":"0380"},"figref":"FIG. 26","b":["2600","2600","2602","2600","2604","2600","2606","2600","2608"]},"A set of one or more stream events may be modeled and implemented as a data stream having a streamid attribute with the same value as that of the streamid attributes of its constituent events. That is, a data stream includes one or more stream events having the same streamid attribute value indicating that the events belong to the same data stream. In an object-oriented implementation, a \u201cStream\u201d class or object may be defined to represent data streams. An input data stream may be generated by and received from an external application, e.g., Twitter\u2122, Facebook\u2122, etc. An intermediate data stream may be generated by and received from a map operation and\/or update operation provided in accordance with exemplary embodiments. In an exemplary embodiment, all of the data streams (input and intermediate data streams) may be provided in a collective manner in a stream bus that may be accessed by any operation or computation provided in accordance with exemplary embodiments.","Exemplary data streams may include, but are not limited to, streams of text files, html files, profiles, updates and posts from social networking websites (e.g., the Twitter\u2122, Facebook\u2122, MySpace\u2122 social networking websites), video and photo publishing websites (e.g., the Flickr\u2122, Youtube\u2122 content publishing websites), blog publishing websites (e.g., the Blogger\u2122 publishing website), transactional data streams (e.g., purchase data, inventory data), updates or feeds from any suitable dynamic data repository, logs, maps, RSS feeds, combinations of any of the above, and the like. An exemplary data stream may include more than one type of stream events, for example, both text publications, photos and videos.",{"@attributes":{"id":"p-0381","num":"0383"},"figref":["FIG. 27","FIG. 25"],"b":["2700","2702","2704","2706","2700"]},{"@attributes":{"id":"p-0382","num":"0384"},"figref":"FIG. 28","b":["2800","2800","2800","2802","2804","2806","2802","2804","2806"]},"A slate is a static data structure that may be used by update operations to record data about a set of one or more related stream events. A slate may be implemented in any suitable data structure or format. In an exemplary embodiment, a slate data structure may include a collection of one or more attribute-value pairs. A plurality of stream events may be related based on one or more suitable characteristics. For example, a slate may be defined for \u201ctweet\u201d events that all mention a particular webpage link or that are all related to a particular news story or topic. A slate may be stored corresponding to its unique slatekey attribute value and corresponding to an update operation that updates the slate.","In an object-oriented implementation, a \u201cSlate\u201d class or object may be defined to represent slates. Exemplary embodiments may provide functionality to create one or more new slate objects, and to access information contained in one or more slate objects, for example, using get methods in an object-oriented implementation. In an exemplary embodiment, slates may be mutable, i.e., may be altered. In this embodiment, exemplary embodiments may provide functionality to alter one or more attributes of a slate, for example, using set methods in an object-oriented implementation.",{"@attributes":{"id":"p-0385","num":"0387"},"figref":"FIG. 29","b":["2900","2900","2902","2904"]},"In an exemplary embodiment, slates may be accessed by one or more applications that implement one or more stream computations. In one example, a K-rank computation application may use slates in a disk storage to store influence ranks of each user publishing stream events. In another example, a clustering application may use slates in a disk storage to store the actual text contained in stream events and metadata about individual clusters of text.","In an exemplary embodiment, a special type of slate named \u201capplication slate\u201d may be implemented to store data accessible by applications, while the general data type named \u201cslate\u201d may only be accessible at the system-level. Isolation between the system slates and application slates may be maintained by using separate keyspaces. A keyspace may be specified by a prefix placed in front of a key with a colon separating the keyspace name and the key. For example, \u201cfoo:bar\u201d denotes the key \u201cbar\u201d in keyspace \u201cfoo.\u201d Only the system may create slates in the \u201csystem:\u201d namespace, while applications may create slates in any other namespace.","Update operations may create, access and modify application slates by the key. In an exemplary application of slates and keyspaces, a K-rank computation may store an individual user's k-scores separately in the disk storage indexed by a key which is the user ID. In an exemplary embodiment, the system may use keyspaces to provide information on improving execution, for example, designating the same worker node as the primary worker node for all the keys in an application keyspace.","Map operations are stream computations performed on one or more stream events in one or more real-time data streams to generate zero, one or more new stream events for publishing to zero, one or more data streams. Exemplary map operations may be implemented in any suitable programming language, for example, a scripting programming language, an object-oriented programming language (e.g., Java), and the like. Map operations may be started, paused and stopped at any suitable time.","A map operation may subscribe to receive as input stream events from one or more real-time data streams (input data streams and\/or intermediate data streams), and may be invoked for every stream event in the subscribed data streams. In exemplary embodiments, the streamid attribute value of a data stream to which a map operation is subscribed or to which a map operation publishes may be defined in a static manner, e.g., in a configuration file including any suitable parameters that may be necessary for an application. The configuration file may include tunables that provide instructions or guidance to the system on how to allocate resources among the various map and update operations.","A map operation may perform one or more real-time computations on a received stream event, and may publish zero or more new stream events to zero or more intermediate data streams. In an exemplary embodiment, the intermediate data streams may be provided in an aggregated real-time data stream bus that provides in a collective manner all of the input and intermediate data streams, so that any map or update operation may subscribe to receive stream events from any of the data streams in the stream bus.","In exemplary embodiments, an \u201cat-least-once\u201d guarantee may be provided to ensure that, regardless of hardware failures and software errors, every map operation subscribed to a data stream will receive every event in the stream and will successfully execute computations for that event, at least once.","In exemplary embodiments, map operations may be stateless computation units, i.e., do not store state. A generic map operation may be denoted as: map(event) (event)*","An exemplary stream event may be defined as:\n\n","where the destination stream s represents a set of operators that have subscribed to receive the event, the key k represents one or more keys or attributes of the events, and the value v represents one or more values associated with the keys.","An exemplary map operator F may be defined as a function on a subset of all possible events E:","F:s,k,v\u03b5\u2192(e, e, e, where e\u03b5E",{"@attributes":{"id":"p-0398","num":"0401"},"figref":"FIG. 30","b":["3000","3000","3004","3002","3000","3006","3002"]},{"@attributes":{"id":"p-0399","num":"0402"},"figref":"FIG. 31","b":"3102"},"In step , the map operation may receive a stream event contained in the subscribed data stream, e.g., a \u201ctweet\u201d contained in a Twitter\u2122 data stream. Since map operations are stateless operations, i.e., do not store state, a plurality of map operations may be allowed to concurrently receive and process events in the same stream.","In step , the map operation may perform one or more computations on the received stream event, e.g., determine the topic discussed in the received \u201ctweet.\u201d In step , the map operation may continue to receive each additional stream event in the subscribed data stream.","In step , the map operation may generate a new stream event based on the computation, e.g., a stream event that indicates the topic of the \u201ctweet.\u201d In step , the map operation may, in some embodiments, publish the new stream event to one or more intermediate data streams. The intermediate data stream may be provided in conjunction with all other data streams in the system in a stream bus so that the stream events in the intermediate data stream may be received by other map and update operations. In step , the map operation may continue to receive each additional stream event in the subscribed data stream.","Exemplary map operations may be implemented in any suitable programming language, for example, a scripting programming language, an object-oriented programming language (e.g., Java), and the like. In an exemplary object-oriented implementation, a general Mapper class or interface may be defined by the system to generally specify attributes and functionality of a generic map operation. For each desired map operation, a sub-class may be created based on the Mapper class. For example, a TopicTagger class may be sub-classed from the Mapper class to define a specific map operation that processes a Twitter\u2122 data stream and extracts topics associated with the \u201ctweets\u201d in the Twitter\u2122 data stream. The TopicTagger operation may subscribe to the Twitter\u2122 data stream and may publish events to a separate data stream, each published event including the topic extracted from a \u201ctweet\u201d and the hour of the day during which the topic was extracted. One or more object instances may be created from each sub-class at a worker node, for example, a TopicTagger object may be instantiated from the TopicTagger class.",{"@attributes":{"id":"p-0404","num":"0407"},"figref":["FIG. 32","FIG. 32"],"b":["3200","3200"]},"The Mapper class  may include zero, one or more attributes associated with properties or characteristics of sub-classes. Each sub-class based on the Mapper class may include the zero, one or more attributes associated with properties or characteristics of the class objects. The attribute values may be specified for a particular object instantiation of the class. In an exemplary embodiment, in the Mapper class , a \u201csubscription\u201d attribute may be provided to indicate one or more data streams to which an object instantiation is subscribed, e.g., a Twitter\u2122 data stream S. Similarly, in an exemplary embodiment, in the Mapper class , a \u201cpublication\u201d attribute may be provided to indicate one or more data streams to which an object instantiation may publish stream events, e.g., an intermediate data stream S. In other exemplary embodiments, the Mapper class  may not include the \u201csubscription\u201d and\/or \u201cpublication\u201d attributes.","The Mapper class  may include zero, one or more methods associated with the behavior of an object instantiation at run-time. Each sub-class may include the zero, one or more specific methods associated with the behavior of the object instantiations of the sub-class at run-time.","Since exemplary embodiments operate in a streaming model, new stream events may trigger the performance of one or more operations, e.g., a map operation. In order to implement the streaming model, a map operation may subscribe to receive events from one or more real-time data streams and may publish events to one or more real-time data streams. In the Mapper class , a subscribe method may be provided to allow an object instantiation to subscribe to one or more data streams in order to receive stream events from the data streams. The subscribe method may accept as input a value of the attribute streamid which identifies a data stream to which an object instantiation subscribes. The subscribe method may be a system-defined and system-provided method. When an object instantiation of a Mapper sub-class subscribes to one or more data streams, information on the subscriptions may be stored in the system and consulted by a conductor to transmits stream events in the data streams to those objects that are subscribed to those data streams. In an exemplary static event-flow configuration, applications may not need to call the subscribe method and this method may not be necessary.","In the Mapper class , a publish method may be provided to publish one or more stream events generated by an object instantiation to one or more intermediate data streams. The publish method may accept as input a value of the attribute streamid which identifies a data stream to which an object instantiation publishes stream events.","The Mapper class  may include a map method that encapsulates the functionality of a generic map operation. In an exemplary embodiment, in the Mapper class , the map method may generally indicate a stream event and a stream event as input parameters of the method, and may not specify the functionality of a specific Map operation. One or more sub-classes of the Mapper class  may further define the map method specific to the sub-classes. For example, a TopicTagger sub-class (that determines the topic of an incoming stream event) may include a map method that accepts a stream event from a subscribed real-time data stream as input and that invokes doctagger which is capable of extracting one or more topics from textual data in the stream event.","Exemplary embodiments may provide a code generation module for generating code associated with the methods of any of the classes provided in exemplary embodiments. The code may be executed at run time to perform the functionality encapsulated in the methods of the classes.","Update operations are stream computational units or methods performed on one or more stream events from one or more real-time data streams to create and\/or update one or more slate data structures for persistent storage. Update operations may be implemented in a thread-safe manner in any suitable computer programming language, for example, a scripting programming language, an object-oriented programming language (e.g., Java), and the like. Update operations may be started, paused and stopped at any suitable time.","An update operation may subscribe to receive as input stream events from one or more real-time data streams (input data streams and\/or intermediate data streams), and may be invoked for every stream event in the subscribed data streams. In exemplary embodiments, an \u201cat-least-once\u201d guarantee may be provided to ensure that, regardless of hardware failures and software errors, every update operation subscribed to a data stream will receive every event in the stream and will successfully execute computations for that event, at least once. An update operation may also receive one or more slates corresponding to one or more stream events, in particular, slates whose slatekey attribute values matches the eventkey attribute values of the corresponding events.","Since exemplary embodiments operate in a streaming model, new stream events may trigger the performance of one or more operations, e.g., an update operation. In order to implement the streaming model, an update operation may subscribe to receive events from one or more real-time data streams and may publish events to one or more real-time data streams. An update operation may perform one or more real-time computations on a received stream event and\/or slate, and may publish zero or more new stream events to zero or more intermediate data streams. In an exemplary embodiment, the intermediate data streams may be provided in an aggregated real-time data stream bus that includes all of the input and intermediate data streams, so that any map or update operation may subscribe to receive stream events from any of the data streams in the stream bus.","The update operation may also create and\/or update one or more slates associated with the stream events processed by the update operation. The slates may be stored in a persistent manner on a disk storage. In exemplary embodiments, a \u201cpersistent update\u201d guarantee may be provided to ensure that, after successful completion of an update operation, any changes made by the operation to one or more slates are stored in a persistent manner. In an exemplary embodiment, one or more slates may be scheduled to expire from the disk storage after a pre-defined period of time, e.g., one hour. In some exemplary embodiments, the update operation may store one or more slates (e.g., last accessed slates, most active slates, etc.) in memory for easy access.","In exemplary embodiments, a \u201cper-slate in-order\u201d guarantee may be provided to ensure that, when an update operation receives an event, one or more slates corresponding to the update operation will reflect all and only those updates that are due to all events with the same eventkey attribute value and earlier timestamp attribute values. This ensures that events are operated on in the order of their timestamps. In some exemplary embodiments, the \u201cper-slate in-order\u201d guarantee may be relaxed to provide for a more distributed update computation. The update operation may, for example, combine slates that represent the processing of different subsets of input events. The update operation may then process separate subsets of input events separately and may subsequently merge them. Such exemplary update operations may be expressed as:","update (Slate*)->Event*","update (Slate, Slate)->Event*","In some exemplary embodiments, slate processing by the update method may be amortized over a plurality of stream events. As such, the update method may be represented as update (Event* event*, Slate slate). Other update methods may operate on multiple events and\/or multiple slates to generate a plurality of events, and may be represented as:","update (Event, Event, Slate)->Event*","update (Event, Slate, Slate)->Event*","In exemplary embodiments, update operations may be stateful computation units, i.e., may store state. A generic update operation may be denoted as: update(event, slate)  (event)*","An exemplary stream event may be defined as:",{"@attributes":{"id":"p-0423","num":"0426"},"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00007","he":"3.13mm","wi":"0.68mm","file":"US08595234-20131126-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00008","he":"3.13mm","wi":"0.68mm","file":"US08595234-20131126-P00002.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}]},"where the destination stream s represents a set of operators that have subscribed to receive the event, the key k represents one or more keys or attributes of the events, and the value v represents one or more values associated with the keys.","An exemplary update operator F may be defined as a function on a subset of all possible events E:","F:s, k,v\u03b5E\u2192e, e, e. . .  where e\u03b5E","In an exemplary embodiment, if the operator F is an updater U, the operator may receive an intermediate event from an output data stream, and perform one or more operations on data contained in the intermediate event to generate output data. In an exemplary embodiment, the updater U may also create or read and modify a slate having key <U, k> as part of its operation.",{"@attributes":{"id":"p-0428","num":"0431"},"figref":"FIG. 33","b":["3300","3300","3304","3302","3300","3308","3308","3312","3300"]},"The update operation  performs one or more computations on the stream events  and\/or the slates , for example, one stream event and a corresponding slate at a time. The update operation  may generate zero, one or more stream events  for publishing to zero, one or more real-time intermediate data streams. The intermediate data streams may be provided in the same stream bus  as the input data streams. The Update operation  may also save one or more new or updated slates  associated with the stream event processed by the Update operation. The slates  may be stored in a persistent manner on the disk storage .","In the exemplary block diagram of , the eventkey attribute value of the input stream event(s) , the slatekey attribute value of the stored slate  and the slatekey attribute value of the new or updated slate  are the same.",{"@attributes":{"id":"p-0431","num":"0434"},"figref":"FIG. 34","b":"3402"},"In step , the update operation may receive a stream event contained in the subscribed data stream, e.g., a \u201ctweet\u201d contained in a Twitter\u2122 data stream. Since update operations are stateful operations, i.e., store state, concurrency problems may be caused by a plurality of update operations processing events for the same stream. In order to avoid these concurrency problems, in an exemplary embodiment, the entire execution of an update operation may be atomic. The atomic execution of an update operation may be ensured by preventing two update operations for input events having the same eventkey attribute value from running concurrently. In another exemplary embodiment, a lock method may be defined to lock the state of a slate during critical stages in an operation. Exemplary embodiments may schedule a plurality of update operations on the same slate concurrently since the state of the slate will be locked during critical stages. This mechanism allows for great concurrently, especially if the update operations are read-only in most cases. In an exemplary embodiment, a Reader sub-class of an Updater class (corresponding to a specific type of update operation) may be defined so that multiple Reader operations may be scheduled concurrently.","In step , the update operation may determine if the stream event received from the subscribed data stream is the first event having a particular eventkey attribute value. If so, in step , the update operation may create one or more new slates having a slatekey attribute value set equal to the eventkey attribute value of the first event received.","In step , the update operation may initialize the slate, for example, by calling an init method. In an exemplary embodiment, the slate may be initialized to include application-specific data structures in the slate. In exemplary embodiments, initialization of the slate may include scheduling the slate to be in existence for a predefined period of time (i.e., a time-to-live or TTL), for example, using a set_ttl method. If the slate is not accessed (i.e., read or written to) for a period of time that equals or is greater than the predefined TTL, the system may automatically destroy the slate and remove it from the disk storage. The TTL may be set in a static manner, e.g., in a configuration file including any suitable parameters that may be necessary for an application. The configuration file may include tunables that provide instructions or guidance to the system on how to allocate resources among the various map and update operations. It is advantageous to set the predefined TTL and to automatically remove slates based on the TTL, because this allows the system to \u201cforget\u201d very old data, e.g., old clusters, and prevents the stored stream data from growing without limit.","In another exemplary embodiment, a predefined TTL may not be set or may be set to infinity so that the slate persists forever. The TTL may subsequently be set to any suitable number.","In exemplary embodiments, a slate may be scheduled to expire by setting an explicit expiry time, for example, using a set_expiry method. In an exemplary embodiment, a finalize method may be called by the set_expiry method on a particular slate to remove the slate from the system.","In step , the update operation may perform one or more computations on the received stream event, e.g., determine the topic discussed in the received \u201ctweet.\u201d In step , the update operation may update one or more associated slates based on the computation. In step , the update operation may store the updated slate in memory on a temporary basis and persistently in disk storage.","In step , the update operation may continue to receive each additional stream event in the subscribed data stream.","In an exemplary embodiment, in step  the update operation may generate a new stream event based on the computation, e.g., a stream event that indicates the number of occurrences of a topic in a stream of \u201ctweets.\u201d In step , the update operation may publish the new stream event to one or more intermediate data streams. The intermediate data stream may be provided in conjunction with all other data streams in the system in a stream bus so that the stream events in the intermediate data stream may be received by other map and update operations. In step , the update operation may continue to receive each additional stream event in the subscribed data stream.","Exemplary update operations may be implemented in any suitable programming language, for example, a scripting programming language, an object-oriented programming language (e.g., Java), and the like. In an exemplary object-oriented implementation, a general Updater class or interface may be defined by the system to generally specify attributes and functionality of a generic update operation. For each desired update operation, a sub-class may be created based on the Updater class. For example, a TopicCounter class may be sub-classed from the Updater class to define an Update operation that processes a Twitter\u2122 data stream and counts the occurrences of one or more topics associated with the \u201ctweets\u201d in the Twitter\u2122 data stream. The TopicCounter operation may subscribe to the Twitter\u2122 data stream and may publish events to a separate data stream, each published event including the number of occurrences in the Twitter\u2122 data stream of a topic corresponding the currently processed \u201ctweet\u201d and the hour of the day during which the \u201ctweet\u201d was generated. One or more object instances may be created from each sub-class at a worker node, for example, a TopicCounter object may be instantiated from the TopicCounter class.",{"@attributes":{"id":"p-0441","num":"0444"},"figref":["FIG. 35","FIG. 35"],"b":["3500","3500"]},"The Updater class  may include zero, one or more attributes associated with properties or characteristics of sub-classes. Each sub-class based on the Updater class may include the zero, one or more attributes associated with properties or characteristics of the class objects. The attribute values may be specified for a particular object instantiation of the class. In an exemplary embodiment, in the Updater class , a \u201csubscription\u201d attribute may be provided to indicate one or more data streams to which an object instantiation is subscribed, e.g., a Twitter\u2122 data stream S, an intermediate data stream S. Similarly, in an exemplary embodiment, in the Updater class , a \u201cpublication\u201d attribute may be provided to indicate one or more data streams to which an object instantiation may publish stream events, e.g., an intermediate data stream S. In other exemplary embodiments, the Updater class  may not include the \u201csubscription\u201d and\/or \u201cpublication\u201d attributes.","The Updater class  may include zero, one or more methods associated with the behavior of a class instantiation at run-time. Each sub-class may include the zero, one or more specific methods associated with the run-time behavior. In the Updater class , a subscribe method may be provided to allow an object instantiation to subscribe to one or more data streams in order to receive stream events from the data streams. The subscribe method may accept as input a value of the attribute streamid which identifies a data stream to which an object instantiation subscribes. The subscribe method may be a system-defined and system-provided method. When an object instantiation of an Updater sub-class subscribes to one or more data streams, information on the subscriptions may be stored in the system and consulted by a conductor to transmits stream events in the data streams to those objects that are subscribed to those data streams. In an exemplary static event-flow configuration, applications may not need to call the subscribe method and this method may not be necessary.","In the Updater class , a publish method may be provided to publish one or more stream events generated by an object instantiation to one or more intermediate data streams. The publish method may accept as input a stream event and a value of the attribute streamid which identifies a data stream to which an object instantiation publishes the event.","The Updater class  may include a createSlate method that may accept as input a stream event and create one or more new slates with the slatekey attribute value of the slate being set equal to the eventkey attribute value of the stream event. The Updater class  may also include an init method that may accept a slate as input and initialize the state of the slate, e.g., by setting a predefine time-to-live or an expiry time of the slate. When a slate expires, a finalize method may be called to remove or delete the slate from disk storage.","The Updater class  may include an update method that encapsulates the functionality a generic update operation. In an exemplary embodiment, the Updater class , the update method may generally indicate a stream event and a slate as input parameters of the method, and may not specify the functionality of a specific update operation. One or more sub-classes of the Updater class  may further define the update method specific to the sub-classes. For example, a TopicCounter sub-class (that counts the number of occurrences of a topic in a data stream) may include an update method that accepts as input a stream event from a subscribed real-time data stream and a slate that corresponds to an hour of day and a particular topic, e.g., a topic determined by a TopicTagger sub-class or object derived from the Updater class. The update method may maintain a variable count in the slate that counts the number of occurrences of the particular topic in a particular hour of the day. That is, upon receiving a stream event corresponding to the same hour of day and the same topic, the update method may increment the variable count by one in the corresponding slate. In an exemplary embodiment, the update method may call an additional method, e.g., a method called updateSlate, to perform its functionality.","Exemplary embodiments may provide a code generation module for generating code associated with the methods of any of the classes provided in exemplary embodiments. The code may be executed at run time to perform the functionality encapsulated in the methods of the classes.","Exemplary stream computation mechanisms may be implemented in any suitable computing hardware and software architecture that includes a scalable, fault-tolerant and durable storage layer that is available at all times for storing slates used by exemplary map and update operators. Exemplary embodiments may provide a cluster of one or more commodity nodes interconnected by communication means, e.g., Ethernet, in order to process real-time data streams in a distributed manner. Exemplary stream computational mechanisms may be less disk-heavy and more memory-heavy than conventional mechanisms like the MapReduce software framework. This is because exemplary data stream computations may read a stream as it flows by, maintain in durable disk storage data structures pertaining to the stream, and maintain in memory one or more certain data structures to facilitate fast and efficient access of the data structures.",{"@attributes":{"id":"p-0449","num":"0452"},"figref":"FIG. 36","b":["3600","3600","3606","3602"]},"The stream bus  may reformat stream events received from an external application to a suitable format, e.g., by adding suitable attribute-value pairs to the stream events. In an exemplary embodiments, an application programming interface (API) may be provided to interface with any source of data streams to receive stream events. The stream bus  may interface with one or more external application  for providing one or more real-time data streams to the external applications. The stream bus  may reformat stream events for transmission to an external application to a suitable format. For example, exemplary embodiments may provide a stream containing real-time information on popular topics in one or more data streams, a streaming containing popular or trending videos in one or more data streams, and the like.","The stream bus  may provide one or more real-time data streams in a collective manner for access by one or more components of the system, for example, by a receiver, a conductor, and\/or one or more operations running at worker nodes. The components of the system may subscribe to receive stream events from one or more data streams provided by the stream bus . In an exemplary embodiment, all map and update operations may share the same stream bus . In an exemplary embodiment, the stream bus  may resend a stream event to a client module (e.g., a receiver, a conductor, or a worker node) until the event is successfully received and processed. The stream bus  may also buffer stream events in the real-time data streams to ensure that events are not lost. The stream bus  may also include an archival system to store portions or entirety of one or more data streams for a predefined period of time or for an unlimited time. For example, the last stream event in each stream may be archived at all times at the stream bus  or at any other component in the system, e.g., in a slate in disk storage. The stream bus  may replay a data stream from any selected timestamp, for example, from the archival system.","An exemplary stream bus  may be implemented using any suitable application framework including, but not limited to, the Gearman application framework for distributed processing written in Perl. Servers in the Gearman framework run on bus hosts, i.e., machines suitable for hosting Gearman servers. In an exemplary embodiment in which the Gearman framework is used to provide the stream bus, each instance of the map-update system may have at least two Gearman servers for redundancy running on separate bus hosts. In an exemplary embodiment, different Gearman servers may be maintained for different event sources and applications to avoid slowing down the event sources.","In an exemplary embodiment, a single stream bus may be provided. In other exemplary embodiments, a plurality of stream buses may be provided, for example, as a set of event-queue servers, each responsible for a subset of events in transit among the map and update operations. In an exemplary embodiment, the subsets may be disjoint partitions.","Exemplary system  may include one or more receivers  that interface with the real-time data streams  to continually receive stream events in the data streams in a real-time manner as the data streams flow past the systems. The receiver  may include one or more buffers  for buffering the stream events as they flow into the receiver  in order to prevent loss of the stream events. In some exemplary embodiments in which a stream computation is mission-critical, the buffer  of the receiver  may be configured as a message queue, e.g., using Java Message Service, in which the stream events placed in the buffer  are stored until the stream events are retrieved. In an exemplary embodiment, the buffer may be provided at the conductor  and\/or the stream bus .","In exemplary embodiments, an \u201cat-least-once\u201d guarantee may be provided to ensure that, regardless of hardware failures and software errors, every map operation subscribed to a data stream will receive every event in the stream and will successfully execute computations for that event, at least once. To ensure at-least-once event processing, the buffer  may buffer the data streams so that the events are not lost. In some exemplary embodiments, \u201cat-most-once\u201d event processing may be provided even under overload conditions so that each event is processed no more than once, for example, by allowing the system to selectively prune its buffers (e.g., a buffer at the stream bus , the receiver , or the conductor ) to control the event load. In some exemplary embodiments, some events may be prioritized over others by allowing the system (e.g., the stream bus , the receiver , the conductor , or the worker nodes) to reorder events accordingly.","Exemplary system  may include one or more conductors  that may interface with the receiver  to continually receive the stream events from the receiver  in a real-time manner. The conductor  may act as a task scheduling mechanism to provide instructions to designate worker nodes for performing map and update operations. The conductor  may also transmit stream events to the worker nodes that are subscribed to receive the stream events. In an exemplary embodiment, the conductor  may protect a worker node from bad or faulty events that cause repeated failures, for example, by discarding the faulty events from subscription to the operation running on the worker node.","In an exemplary embodiment, the conductor  may provided as a separate component from the worker processes. In another exemplary embodiment, the conductor  may be provided so that each worker process is provided as an extension of a conductor class, thereby making the conductor effectively distributed and multi-threaded.","The conductor  may have visibility into the performance of the worker nodes and may perform load balancing by reassigning tasks to the worker nodes. In an exemplary embodiment, the conductor  may read and write slates in a disk storage and\/or in memory. In an exemplary embodiment, the conductor  may record the last event processed for each data stream when a worker completes processing the event.","The conductor  may maintain metadata about the available worker nodes in the system including, but not limited to, the computational specifications of the worker nodes, the current status of each worker node (e.g., whether it is operational, is in a failed state, etc.), the current processing load at each worker node, the data streams from which each worker node are subscribed to receive stream events, the data streams to which each worker node publishes events, the particular slatekey that is the primary slatekey handled by each worker node, and the like.","In cases in which the conductor  may fall behind the influx of the stream events or in cases in which the conductor  may suffer a software error or a hardware failure, the buffer  of the receiver  prevents loss of stream events.","In an exemplary embodiment including multiple conductors, a super-conductor (not pictured) may be provided to coordinate the operation of the conductors and to set up and provide instructions to the conductors. Message broadcasting services may be implemented over the multiple conductors so that outage or failure of a conductor may be announced to the other conductors. The operation of the failed conductor may be transferred to another functional conductor.","Exemplary system  may include'one or more worker nodes , , ,  that provide a pool of one or more worker processes for performing computations on real-time data streams. The worker nodes may interface with the conductor  to receive stream events in a real-time manner in order to perform real-time computations on the stream events. The worker nodes may be assigned to perform one or more stream computations concurrently at a given time so that a desired functionality may be achieved by distributing different tasks over the nodes.","This distributed implementation provides scalability, wherein one or more additional worker nodes may be added to perform additional map and update operations and to accommodate increased computational requirements, additional data streams, increased data stream flows, and the like. The system overhead is minimal and does not increase with the scale of the system. Information on the new worker nodes may be transmitted to the conductor and may be stored by the conductor as meta-data. The conductor may assign stream processing operations to the new worker nodes and may transmit stream events to the new worker nodes.","The distributed implementation also provides fault-tolerance so that there is no single point of failure, wherein a task at a failed worker node may be assigned to a different worker node without affecting the entire distributed system.","In an exemplary embodiment, each worker node may include and may be capable of running one or more worker processes. For example, each worker node process may include all necessary computer-implemented instructions, i.e., software code, for running any map and update operator in the system, and may be capable of running any map and update operator in the system. In another exemplary embodiment, each worker node may receive computer-implemented instructions for running a specific map or update operation when the operation is scheduled to run on the worker node. The computer-implemented instructions may be provided to the worker node in a binary file format that may be loaded onto a process running on the worker node.","The worker nodes may receive instructions from the conductor  which determine the operations that the nodes will perform. In an exemplary embodiment, a worker node may perform a single map or update operation at a time. In another exemplary embodiment, a worker node may perform a plurality of map and\/or update operations at a time, for example, using multiple processors, multiple cores or multiple threads.","The worker nodes may be provided in a distributed manner at a plurality of computing devices that may be geographically remote from one another, or may be provided as separate modules or cores in the same computing device.","The map and\/or update operation that is run by a worker node process at a particular time may be determined based on the instructions received from the conductor . Upon selection of a particular map and\/or update operator for running on a worker node process, the worker node may automatically determine one or more data streams from which stream events should be received for performing the operator. Alternatively, one or more data streams necessary for a particular map or update operator may be pre-identified and stored in association with the operator. The worker node may subscribe to the one or more data streams required by the selected operator by sending a subscription request to the conductor . Upon registering the subscription request, the conductor  may begin to send stream events in the requested data streams to the worker node.","That is, the data on which the assigned map and\/or update operator is run at a worker node process may be determined by the stream events transmitted to the worker node from the conductor . In an exemplary embodiment, the conductor  manages subscriptions of the worker nodes to different data streams. The conductor may store the subscription information associated with the worker node and an identification of the data streams requested by the worker node, and may transmit input stream events corresponding to the requested data streams to the worker node that subscribed to the requested data streams. In this case, the conductor  may store a table of mappings between each worker and one or more data streams from which the worker is subscribed to receive stream events. For each stream event received by the conductor , the conductor may consult the table of mappings to determine which worker nodes are to receive the stream event.","Upon performing a computational operation, a worker node may generate one or more stream events to be published to one or more intermediate data streams . In an exemplary embodiment, one or more map operations performed by worker nodes may result in the generation of stream events published to one or more intermediate data streams . The intermediate data streams  may be provided in a manner similar to the input data streams  in the stream bus  so that the receiver  may receive stream events from the intermediate data streams  as well. One or more worker nodes may be subscribed to receive stream events from one or more intermediate data streams  through the receiver  and the conductor .","In addition or alternatively, upon performing a computational operation, a worker node running an update operation may generate static output data, for example, slates that are stored as key-value combinations. The slates may be stored temporarily in memory and persistently in a durable disk storage . Each slate generated may be indexed by its slatekey and a corresponding update operation in the disk storage . A worker node running an update operation may have exclusive access to a slate while it is performing the operation to prevent inconsistencies in the data stored in the slate.","In an exemplary embodiment, the worker nodes may access the disk storage  to retrieve and\/or store slates, and may store one or more slates on a temporary basis in memory, e.g., a write-through cache. In an exemplary embodiment, each worker node may maintain a least recently used (LRU) cache of slates. The storage of one or more slates in memory at worker nodes allows scheduling computation near the data.","To fetch data maintained in a map-update application, the system may provide a slate-fetch operation so that requests from outside the application may retrieve a slate for any <update operation, key> value. To reduce the network requirements and computational costs of applications using data saved in the disk storage , exemplary embodiments may provide a slate-postprocess operation so that requests from outside an application may retrieve a slate for any <update operation, key> value and may run a particular function on the slate before returning it to the application. In one example, such a slate-postprocess operation may select only individual attributes of interest, thereby returning less data that is stored in the slate. For example, the operation may compute an aggregate of select attributes in the slate. In another example, if the slate contains information on two numbers, a slate-postprocess operation may provide the average of the numbers to an external application.","To provide a consistent interface to a map-update application's data even as its implementation changes, some exemplary embodiments may provide a node-fetch operation that runs a particular function (implemented by the application) to return a desired result. The node-fetch operation may execute slate-fetch operations and slate-postprocess operations as well as its own code to \u201cnormalize\u201d the data maintained in the application to generate a result. In exemplary embodiments, the node-fetch operation may also perform other processing and optimization operations.","To provide a consistent interface to a map-update application's data even as its implementation changes, some exemplary embodiments may provide a view-fetch operation that runs a particular function (implemented over the application) to return a desired result. The view-fetch operation may execute node-fetch operations as well as its own code to \u201cnormalize\u201d the data maintained in the applications to generate a result. In exemplary embodiments, the view-fetch operation may also perform other processing and optimization operations.","In an exemplary embodiment, a worker node may be preferentially assigned to perform computations on stream events with a particular eventkey that is equal to the slatekey for which the node is a primary worker node. A worker node that is the primary worker node for a particular slatekey may be capable of handling all events associated with the slatekey, i.e., with the particular slate, and may store in memory, e.g., cache, all slates corresponding to the slatekey. Each worker node may maintain an in-memory cache of slates, i.e., key-value combinations, for which the worker node is the \u201cprimary\u201d worker node. The cache of slates may be saved, for example, in a solid-state drive (SSD) that stores persistent accessible data. In exemplary embodiments, the cache may be write-through in which write operations performed on the cache by an operation running on the worker node is written back to the disk storage. In an exemplary embodiment, write operations performed on the cache may be written through to the disk storage immediately. In another exemplary embodiment, write operations performed on the cache may be written through to the disk storage after a time delay. A write-delay parameter may be configured to adjust the time delay to control the write-through behavior of the cache. The write-delay parameter may relax the immediate write-through behavior of the cache and may allow the cached slate to be written back at certain times, for example, every few seconds.","The storage of the slates in memory minimizes the number of disk read operations that need to be performed to access slates. This is because, when an Update operation is scheduled on a slate, the operation is scheduled on a worker node that is the primary worker node for the slate. As such, it is likely that the most recent value of the slate is stored in the cache of the primary worker node. This makes it unnecessary for the worker node to perform a read operation on the disk storage in order to determine the most recent value of the slate, and may instead look up the value in its own cache.","The large number of slate accesses required in some stream computations adversely affect performance. For example, in a data stream of N events\/second, each event may trigger K slate accesses in which each slate may have a size of S bytes. Therefore, the system must support NK slate accesses\/second and a data volume of NKS bytes over the network. For exemplary values of 10,000 events\/second for N,  slate accesses for K, and 10 KB for S, the system must support at least 100K lookups\/second and a flow of 8 Gbps. An exemplary implementation that allows computation near the data at worker nodes lowers the number of slate accesses in disk storage that must be performed, and lowers the serialization overhead involved in accessing and storing slates in disk storage. Similarly, the number of slate write operations to the disk storage may be reduced by batching the write operations.","Data streams are subject to spiky behavior in which bursts of activity may arise for stream events corresponding to the same eventkey value. Implementation of a write-delay parameter and assigning worker nodes as primary worker nodes allows the system to harness spiky bursts of activity to improve system performance and efficiency. A slate for a hot or popular or very active eventkey value may remain in memory, e.g., in cache, at one or more worker nodes that are the primary worker nodes assigned to that eventkey value. As such, for every access to the disk storage for the slate, the slate may be read and written several times in memory, thus saving the time and computations, e.g., serialization, that would otherwise be required in multiple read and write operations to the disk storage.","In some cases, due to hot spots in the flow of incoming stream events, a computational load at a worker node may increase beyond a certain threshold. In order to avoid such increased loads, the conductor may periodically determine load data for the worker nodes, e.g., by polling the worker nodes. In order to schedule an update operation associated with a stream event, the conductor may schedule the update operation to run on the primary worker node associated with the event's key only if the primary node has a load less than a specified threshold, e.g., 80% of the threshold. Otherwise, the conductor may select another worker node with the lightest computational load as the new primary worker node for the key. The conductor may wait for a time period slightly longer than the write-delay parameter before scheduling subsequent update operations for the key on the new primary worker node. This ensures that any update operations from the old primary worker node have already updated the disk storage, before subsequent update operations are scheduled on the new primary worker node. The new primary worker node thus receives the most recent slate value from the disk storage.","In an exemplary embodiment, a storage layer  may be implemented in a distributed manner, e.g., over multiple storage devices that may be geographically remote from one another. For example, an exemplary storage layer may be implemented using Cassandra which is a distributed storage system. A distributed storage layer may provide a high available service with no single point of failure, and may be accessible to the plurality of worker nodes in the system. In an exemplary embodiment, the storage layer may be provided at the worker nodes in a distributed manner. In addition to the ability to persist data, the distributed storage layer may have one or more additional characteristics including, but not limited to, scalable and robust solutions for load balancing, replica synchronization, membership and failure detection, failure recovery, overload handling, state transfer, concurrency and job scheduling, request marshalling, request routing, system monitoring and alarming, configuration management, and the like. In an exemplary embodiment, the disk storage  may be provided in a distributed manner run on a set of two or more nodes that are separate from the worker nodes in some exemplary embodiments, and that are the worker nodes in other exemplary embodiments. That is, in some exemplary embodiments, the nodes providing the disk storage  may be separate from the nodes providing the map and update operations. The two or more nodes running the disk storage  may be provided on separate computing devices and\/or provided at separate geographical locations.","The worker nodes may have access to the disk storage  to retrieve and store slates on the disk storage. Slates may be maintained in the disk storage  and\/or in memory at worker nodes and\/or at the conductor at any suitable time granularity, e.g., hourly, daily, weekly, monthly. Versioning may be applied to maintain and identify different states of the slates at different times. Older states of a slate may be stored or archived for a predefined time or for an unlimited time as the slate is updated. The disk storage  may also store information received or processed by the conductor, for example, metadata pertaining to the worker nodes.","Exemplary system  may allow one or more external applications  to interface with the system to receive the static output data. The external applications  may interface with the disk storage  to receive static output data stored on the disk storage. The external applications  may be any suitable external data consumers, e.g., a web application that displays the Top N topics in a Twitter\u2122 feed at a given time. In this example, the web application may retrieve a key-value combination stored in the disk storage  that provides the values of the Top N topics in a Twitter\u2122 feed at a given time.","The different components of the system  may be coupled to each other using any suitable communication mechanism, e.g., gigabit Ethernet.",{"@attributes":{"id":"p-0485","num":"0488"},"figref":"FIG. 37","b":["3702","3704","3706","3708","3710","3712","3714","3704","3706","3708","3710","3712","3714"]},"The system may include one or more disk storage devices , e.g., in the form of a distributed storage layer, for storing one or more slates. In some exemplary embodiments, the disk storage  may be provided in a distributed manner over the conductors or the worker nodes, or separately therefrom.","The system may include one or more conductors running one or more conductor processes . In exemplary embodiments, during an initial setup stage, the conductor process  may delegate one or more map operations to one or more worker nodes (so that the worker nodes are primarily responding for performing the map operations) and\/or one or more update operations to one or more other worker nodes (so that the worker nodes are primarily responding for performing the update operations). In exemplary embodiments, the conductor process  may receive and transmit stream events to appropriate worker nodes that are subscribed to receive events from the stream. In an exemplary embodiment, the conductor process  may itself be a task that is initiated and instructed by a super-conductor process (not pictured).","The system may include one or more worker processes running on one or more worker nodes , ,  and . Each worker node may be capable of running one or more processes for performing one or more map operations (M) and\/or one or more update operations (U). For example, each worker node may be able to access instructions for performing the operations. Each process thread at a worker node may be invoked based on the particular task assigned to the worker node. In an exemplary embodiment, the number of worker processes may be equal to the number of worker nodes or machines available in the system, i.e., one worker process per machine. In another exemplary embodiment, two or more worker processes may be used in each of the worker nodes or machines in the system. If a worker process fails, its task may be reassigned to another worker process by the conductor process  and measures may be taken to repair or replace the failed worker process.","In an exemplary embodiment, the worker node  may be designated a primary worker for performing a first map operation (M). The worker node  may be subscribed to receive event  from the stream bus , may run a worker process to perform the first Map operation (M) on the event, and may publish intermediate event  to one or more streams in the stream bus . Similarly, the worker node  may be designated a primary worker for performing a second map operation (M). The worker node  may be subscribed to receive event  from the stream bus , may run a worker process to perform the first map operation (M) on the event, and may publish intermediate event  to one or more streams in the stream bus .","In an exemplary embodiment, the worker node  may be designated a primary worker for performing a first update operation (U). The worker node  may be subscribed to receive event  from the stream bus  and one or more slates from the disk storage . The worker node  may run a worker process to perform the first update operation (U) on the events and\/or slates. The worker node  may publish intermediate event  to one or more streams in the stream bus  and\/or save new and\/or updated slates to the disk storage . Similarly, the worker node  may be designated a primary worker for performing a second update operation (U). The worker node  may be subscribed to receive event  from the stream bus  and one or more slates from the disk storage . The worker node  may run a worker process to perform the second update operation (U) on the events and\/or slates. The worker node  may publish intermediate event  to one or more streams in the stream bus  and\/or save new and\/or updated slates to the disk storage .",{"@attributes":{"id":"p-0491","num":"0494"},"figref":["FIG. 38","FIG. 36","FIGS. 40 and 41"],"b":"3802"},"Upon selection of a particular map and\/or update operator for running on a worker node process in step , the worker node may automatically determine one or more data streams from which stream events should be received for performing the operator. Alternatively, one or more data streams necessary for a particular map or update operator may be pre-identified and stored in association with the operator. The worker node may subscribe to the one or more data streams required by the selected operator by sending a subscription request to the conductor.","In an exemplary embodiment, step  may be performed at start-up of the system, and may be repeated to provided updated instructions to the worker nodes.","In step , one or more receivers may receive one more real-time input data streams. The receiver may extract one or more stream events from each data stream and place the stream events in one or more buffers.","In step , the receiver may transmit the stream events from the buffer in a real-time manner to one or more conductors.","In step , for each stream event that the conductor receives, the conductor may determine the data stream to which the stream event belongs. The conductor may then determine which worker nodes, if any, are subscribed to receive stream events in that data stream. The conductor may then transmit the received stream event to the worker nodes subscribed to the data stream corresponding to the stream event.","In step , the worker nodes may perform map and\/or update operations in a continual real-time manner on the stream events received from the conductor. Each worker node may generate one or more stream events for publishing on intermediate data streams and\/or static output data.","In step , a worker node may generate a stream event. In step , the stream event may be published to an intermediate real-time data stream by the worker node. In step , the intermediate data stream may be provided to the receiver in the same manner as the input data streams.","In step , a worker node may generate static output data. In step , the static output data may be stored durably on a disk storage. In step , one or more external applications may interface with and access the static output data stored on the disk storage.",{"@attributes":{"id":"p-0500","num":"0503"},"figref":["FIG. 39","FIG. 37"],"b":["3902","3904","3906","3908"]},"In step , a second worker process may receive the first intermediate stream event from the first real-time intermediate data stream. In step , the second worker process may process the first intermediate output data in the first intermediate stream event in a first update operation to generate first final output data. In step , the second worker process may store the first final output data in a first data structure associated with the first intermediate output data on a storage device. The first data structure may be generated by the second worker process, or an existing data structure may be updated with the first final output data. One of ordinary skill will recognize that one or more additional worker processes may be scheduled to run additional instances of the first update operation or one or more additional update operations, for example, concurrently with the second worker process. The computational load for an update operation may be distributed among multiple instances of the operation in an exemplary embodiment.","In some embodiments, one or more additional worker processes may be scheduled to run additional update operations. For example, in step , the second worker process may transform the first final output data to generate a second intermediate stream event corresponding to the first intermediate stream event and comprising the first final output data. In step , the second worker process may publish the second intermediate stream event to a second real-time intermediate data stream. In step , a third worker process, may receive the second intermediate stream event in the second real-time intermediate data stream. In step , the third worker process may transform the first final output data in the second intermediate stream event in a second update operation to generate second final output data. In step , the third worker process may store the second final output data in a second data structure associated with the second intermediate output data on a storage device.","An exemplary task scheduling mechanism implemented at a conductor may be used to assign one or more map operations and\/or one or more update operations to worker nodes in a distributed system based on a suitable task scheduling policy. Exemplary task scheduling policies include, but are not limited to, random assignment, round robin assignment, assignment first to worker nodes with the lightest computational load, assignment to minimize communication costs, assignment to minimize disk accesses, and the like.",{"@attributes":{"id":"p-0504","num":"0507"},"figref":"FIG. 40","b":["4002","4004","4006","4008"]},"In an exemplary embodiment, in step , the conductor may schedule the map and\/or update operations associated with the incoming stream event in a round robin fashion among available worker nodes. That is, a first map or update operation may be scheduled to run on a first worker node, a second map or update operation may be scheduled to run on a second worker node, and the like. The round robin task scheduling may allocate a roughly equal computational load to the worker nodes at most points in time.","In another exemplary embodiment, in step , the conductor may schedule the map and\/or update operations associated with the incoming stream event in a manner that balances the computational load among the worker nodes. In an exemplary embodiment, the conductor may receive information on their current computational loads at any suitable time. For example, the conductor may poll the worker nodes at step  or at pre-defined intervals of time. In another exemplary embodiment, the worker nodes may automatically transmit their load information to the conductor, for example, at pre-defined periods of time or upon prompting by the conductor. Upon receiving load information from the worker nodes, the conductor may schedule the map and\/or update operations associated with the incoming stream event on the worker nodes with the lowest computational loads in step .","In another exemplary embodiment, a conductor may schedule a map operation and\/or an update operation in a random manner among the available worker nodes.","The exemplary task scheduling method illustrated in  may give rise to issues in maintaining consistency of state among update operations performed by different worker nodes since update operations are stateful operations, i.e., they store state at the end of each operation. To ensure atomicity in the system, every time an update operation is scheduled, the operation reads its associated slate from the disk storage on start-up. Upon performing the update operation, the operation writes back the updated slate to the disk storage if any updates are made during the operation. The slates have to be written to the distributed disk storage accessible by all of the worker nodes, because the next update operation may be scheduled on any worker node and must be able to access the latest state in the disk storage. As a result, in some exemplary embodiments, scheduling different update operations to worker nodes in a round robin fashion may require many data read and write operations in the disk storage performed by different worker nodes, which may lead to inefficiencies and bottlenecks in the system.","For example, assuming that an exemplary system processes n stream events per second, that each stream event accesses k slates, and that each slate is s bytes in size, a total of nk key-value operations per second must be performed on the disk storage. The nk key-value operations may transfer nks bytes of data per second between the disk storage and the worker nodes.","In an example in which the exemplary system uses input data streams from Twitter\u2122, an exemplary value for n may be about 10,000 (i.e., a Twitter\u2122 data stream contains about 10,000 Twitter\u2122 updates per second), an exemplary value for k may be about 10 (i.e., each Twitter\u2122 update accesses about 10 slates), and an exemplary value for s may be about 10 KB (i.e., each slate has a size of about 10 KB). These values yield about 100,000 key-value operations per second, which is at the outer limits of the capabilities of conventional disk storage devices. The data transferred between the disk storage and the worker nodes is about one (1) gigabyte per second, i.e., eight (8) gigabits per second, which would require network communication mechanisms capable of supporting at least ten (10) gigabytes of data. Conventional commodity nodes are typically equipped with network communication mechanisms capable of supporting up to one (1) gigabyte of data. Thus, the task scheduling method illustrated in  may create inefficiencies and bottlenecks due to the large amount of data being read from and written to the disk storage and the high rate at which data is being read from and written to the disk storage.","However, the exemplary task scheduling illustrated in  does not give rise to the same issue when scheduling map operations, because map operations are stateless operations and do not access or store state in the disk storage.",{"@attributes":{"id":"p-0512","num":"0515"},"figref":["FIG. 41","FIG. 40","FIG. 40"]},"Since map operations are stateless operations, they may be scheduled to run on worker nodes in accordance with method  of . Exemplary task scheduling policies that may be used to assign map operations to worker nodes may include, but are not limited to, random assignment, round robin assignment, assignment to worker nodes with the lightest computational loads, assignment to worker nodes to minimize communication costs, and the like.","In another exemplary embodiment, a conductor may assign map operations among the worker nodes in a manner that minimizes the cost of communications between the conductor and the worker nodes. For example, a conductor may assign one or more map operations \u201cclose\u201d to the conductor (i.e., at worker nodes that have short communication paths to the conductor) in order to reduce communication costs, like serialization costs or network costs. This task scheduling policy is suitable for assigning map operations, as map operations are stateless and may be assigned to worker nodes anywhere, including at worker nodes that are \u201cclose\u201d to a conductor.","The exemplary scalable method of  moves the update operations performed by the worker nodes closer to the data read and written by the worker nodes. More specifically, for each slatekey associated with stream events, a single worker node is designated as the \u201cprimary\u201d or preferred worker node for performing update operations on slates having the slatekey. The conductor may store mappings between each slatekey and its associated primary worker node. That is, an update operation that receives a stream event is scheduled to run on the primary worker node associated with the slatekey value of the stream event.","In step , the conductor may receive a stream event in real-time from a receiver. In step , the conductor may determine the identification of the data stream that included the stream event, for example, by looking up the value of the streamid attribute in the stream event. The conductor may then determine one or more map and\/or update operations that are subscribed to receive stream events in the data streams having the streamid attribute value in the stream event.","If a map operation is subscribed to receive the stream event, the conductor may determine which worker node should be scheduled to run the map operation associated with the incoming stream event, in step . In an exemplary embodiment, in step , the conductor may schedule map operations associated with the incoming stream event in a round robin fashion among the worker nodes. Alternatively, in another exemplary embodiment, the conductor may schedule the map operations associated with the incoming stream event in a manner that balances the computational load among the worker nodes. In an exemplary embodiment, the conductor may receive information on the current computational loads at the worker nodes at any suitable time. For example, the conductor may poll the worker nodes at step  or at pre-defined intervals of time. In another exemplary embodiment, the worker nodes may automatically transmit their load information to the conductor, for example, at pre-defined periods of time or upon prompting by the conductor. Upon receiving load information from the worker nodes, in step , the conductor may schedule the map operations associated with the incoming stream event on the worker nodes with the lowest computational loads.","Update operations associated with slates having a particular slatekey attribute value may be scheduled on one or more worker nodes designated to be the primary worker nodes for that slatekey attribute value. This allows the primary worker nodes to store the slates in memory, which allows fast and efficient access of the slates. If an update operation is subscribed to receive the stream event, in step , the conductor may determine the value of the slatekey attribute of the stream event. In step , the conductor may determine the primary worker node assigned to perform update operations associated with the given slatekey value. The conductor may look up the primary worker node in a table of mappings between slatekey values and their associated primary worker nodes. In step , the conductor may schedule the Update operation to the primary worker node associated with the given slatekey value and may transmit the stream event to the worker node.","Exemplary embodiments provide failure handling mechanisms for handling software errors and hardware failures at any of the worker nodes in the system. In an exemplary embodiment, a conductor may poll the worker nodes at predetermined intervals of time for load data and to detect failures. In an exemplary embodiment, the worker nodes may send load data and information on software errors and hardware failures to the conductor at predetermined intervals of time. Upon receiving information that a worker node has experienced a software error or hardware failure, the conductor may mark the worker node as failed, e.g., in meta-data associated with the worker node. In some embodiments, the system may restart or attempt to repair the worker node and\/or the operation running on the worker node.","When a stream event arrives at the conductor with a eventkey attribute value for which the failed worker node is the primary worker node, the conductor may select another worker node to be the primary worker node for the key. In an exemplary embodiment, one or more new worker nodes may be added to the system to replace the failed worker node. Information on the new worker nodes may be transmitted to the conductor and may be stored by the conductor as meta-data. The conductor may assign stream processing operations to the new worker nodes and may transmit stream events to the new worker nodes.","To ensure consistency, the conductor may wait for a predefined period of time that is slightly longer than the write-delay once the failure is detected before scheduling update operations for the events associated with the failed worker node. This allows the events to be buffered at the receiver or the conductor for a period of time equal to the write-delay.","When a worker node fails, there is a risk that the system may lose any data in memory at the worker node (e.g., in cache) that has not yet been written to the disk storage. The system may also lose the stream events that the failed worker node was processing at the time of failure. However, such losses are not catastrophic in applications of exemplary embodiments. In exemplary embodiments, redundancy in data storage and storage of events (e.g., at other worker nodes) may be provided to prevent such losses in cases of worker node failure.","Exemplary embodiments provide failure handling systems and methods for handling software errors and hardware failures at a conductor in the system. In an exemplary embodiment, the conductor may maintain metadata about the available worker nodes in the system including, but not limited to, the computational specifications of the worker nodes, the current status of each worker node (e.g., whether it is operational, is in a failed state, etc.), the current processing load at each worker node, the data streams from which each worker node are subscribed to receive stream events, the data streams to which each worker node publishes events, the particular slatekey that is the primary slatekey handled by each worker node, and the like.","In exemplary embodiments, the meta-data stored at the conductor may change at a slow rate compared to the rate of the real-time data streams being processed. As such, the conductor may use a pure write-through cache with no write delay for the meta-data. If the conductor experiences a software error or a hardware failure, a new conductor may be started (e.g., by initiating a new conductor process on the same or a different machine) that reads the meta-data from the disk storage and continues the operation of the failed conductor. During the time between the failure of the conductor and the handling of events by the new conductor, the receiver may buffer events so that the only events lost are those that were in the process of being scheduled by the failed conductor. In order to avoid issues regarding designating worker nodes as being primary worker nodes for certain eventkey attribute values and to ensure consistency, the conductor may wait for a predefined period of time equal to and\/or greater than the write delay before scheduling new tasks.","Exemplary embodiments may provide replay equivalence to ensure that a particular event processing occurs exactly once. For example, if no software crashes or hardware failures occur, then every event is processed once and the results of the update operations are saved to the persistent disk storage. If a software crash or hardware failure occurs, the input data streams may be replayed (e.g., may be rewound to a previous point in time and played from that previous point again), and the slates of the update operations may be saved in snapshots so that the effects of every event is either preserved or replayed.","To ensure replay equivalence, every update operation must receive all of its stream events for a key attribute k in a well-defined consistent order within each and between all external stream events. In an exemplary embodiment, a stronger guarantee may be provided that all events must be delivered to their destination operations in a consistent order. This stronger guarantee may be implemented by creating a complete ordering of all operations in an application.","For an application in which the flow of events through operations forms a directed line, the complete ordering is equivalent to the enumeration of that line's operations. For an application in which the flow of events through operations forms a tree or directed acyclic graph (DAG), the complete ordering is an arbitrary but fixed (i.e., unspecified) topological sort of the flow. Because the topological sort of a cyclic graph is not well-defined, this approach does not apply to cyclic-event-flow-graph applications even if the event flow for all external events is otherwise guaranteed to termination.","The exemplary pseudocode represents an exemplary method for running an application. Methods enqueue(Q, v) and dequeue(Q) represent order-preserving queue operations. One queue is used for each defined operation, one queue is used for each update operation with more than one state, and two queues are used for each instance of each operation (one queue for events into the instance for processing and one for return values after processing). All enqueue (U) calls in line 3 of the pseudocode may run in parallel without affecting correctness.",{"@attributes":{"id":"p-0529","num":"0532"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Algorithm 1 run_application"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"Require: Fis the operator that receives incoming events (with key 0)."},{"entry":"Require: seqno is a sequence number for the first incoming external"},{"entry":"event (e.g., 0)."},{"entry":"\u20021: epoch \u2190 current_epoch(application) {For simplicity, define"},{"entry":"\u2002epoch \u2190 0.}"},{"entry":"\u20022: for all U \u2208 updaters with multiple states do"},{"entry":"\u20023: \u2003enqueue(U, nil) {Allow updaters to start execution. (See Algorithm"},{"entry":"\u20024, run_updater.)}"},{"entry":"\u20024: end for"},{"entry":"\u20025: for all external events do"},{"entry":"\u20026: \u2003e \u2190\u2009\u2009 \u2009F, k =\u2009\u2009 \u2009epoch, seqno\u2009 \u2009, v = external event data\u2009 "},{"entry":"\u20027: \u2003e_seq \u2190\u2009\u2009 \u2009e\u2009 "},{"entry":"\u20028: \u2003enqueue(F, e_seq)"},{"entry":"\u20029: \u2003seqno \u2190 seqno + 1"},{"entry":"10: end for"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"The exemplary pseudocode represents an exemplary method for running an exemplary operation F.",{"@attributes":{"id":"p-0531","num":"0534"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Algorithm 2 run_operator for operator F"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u20021: if F is a state of an updater with multiple states then"},{"entry":"\u20022: \u2003U \u2190 updater for operator F"},{"entry":"\u20023: else"},{"entry":"\u20024: \u2003U \u2190 nil"},{"entry":"\u20025: end if"},{"entry":"\u20026: loop"},{"entry":"\u20027: \u2003if U \u2260 nil and F is the first state of U then"},{"entry":"\u20028: \u2003\u2003dequeue(U) {i.e., wait until previous external event is done with"},{"entry":"\u2002U.}"},{"entry":"\u20029: \u2003end if"},{"entry":"10: \u2003in \u2190 dequeue(F)"},{"entry":"11: \u2003assert in is a (possibly empty) sequence of events"},{"entry":"12: \u2003out \u2190\u2009\u2009 \u2009\u2009 "},{"entry":"13: \u2003for all\u2009\u2009 \u2009s, k, v\u2009 \u2009\u2208 in do"},{"entry":"14: \u2003\u2003if F subscribes to s then"},{"entry":"15: \u2003\u2003\u2003instance \u2190 instance of F for key k"},{"entry":"16: \u2003\u2003\u2003enqueue(instance in, k, v)"},{"entry":"17: \u2003\u2003end if"},{"entry":"18: \u2003end for"},{"entry":"19: \u2003for all\u2009\u2009 \u2009s, k, v\u2009 \u2009\u2208 in do {in the same order as the above for"},{"entry":"loop}"},{"entry":"20: \u2003\u2003if F subscribes to s then"},{"entry":"21: \u2003\u2003\u2003events \u2190 dequeue(instance out)"},{"entry":"22: \u2003\u2003\u2003out \u2190 out + events"},{"entry":"23: \u2003\u2003else"},{"entry":"24: \u2003\u2003\u2003out \u2190 out +\u2009\u2009 \u2009s, k, v\u2009 "},{"entry":"25: \u2003\u2003end if"},{"entry":"26: \u2003end for"},{"entry":"27: \u2003G \u2190 succ(F) in the operator ordering for this application"},{"entry":"28: \u2003if G is not nil then"},{"entry":"29: \u2003\u2003enqueue(G, out)"},{"entry":"30: \u2003else"},{"entry":"31: \u2003\u2003assert out =\u2009\u2009 \u2009\u2009 "},{"entry":"32: \u2003end if"},{"entry":"33: \u2003if U \u2260 nil and F is the last state of U then"},{"entry":"34: \u2003\u2003enqueue(U, nil) {i.e., allow next external event to execute in U.}"},{"entry":"35: \u2003end if"},{"entry":"36: end loop"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"If the enqueue and dequeue loops are merged in the method, the method may become a strictly serial (blocking) execution of each external event, rather than a slightly parallel(izable) execution. If the enqueue and dequeue loops in the method are split further into separate threads of execution, then execution of multiple external events for an operation F may be slightly overlapped, for example, in a sufficiently parallel environment.","The exemplary pseudocode represents an exemplary method for running an exemplary map operation.",{"@attributes":{"id":"p-0534","num":"0537"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Algorithm 3 run_mapper for each instance of mapper F is trivial."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"1: loop"]},{"entry":[{},"2: \u2003in \u2190 dequeue(instance in)"]},{"entry":[{},"3: \u2003assert in is an event"]},{"entry":[{},"4: \u2003\u2009 \u2009s, k, v\u2009 \u2009\u2190 in"]},{"entry":[{},"5: \u2003assert F subscribes to s"]},{"entry":[{},"6: \u2003out \u2190 map(k, v) {Run the actual application code.}"]},{"entry":[{},"7: \u2003enqueue(instance out, out)"]},{"entry":[{},"8: end loop"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}]}}},"The exemplary pseudocode represents an exemplary method for running an exemplary update operation.",{"@attributes":{"id":"p-0536","num":"0539"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Algorithm 4 run_updater for each instance of updater F is easy"},{"entry":"(only) because its input is already queued (in required order of execution)."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u20021: loop"},{"entry":"\u20022: \u2003in \u2190 dequeue(instance in)"},{"entry":"\u20023: \u2003assert in is an event"},{"entry":"\u20024: \u2003\u2009 \u2009s, k, v\u2009 \u2009\u2190 in"},{"entry":"\u20025: \u2003assert F subscribes to s"},{"entry":"\u20026: \u2003slate \u2190 exclusive reference to mutable slate of key \u2009 \u2009U, k\u2009 "},{"entry":"\u20027: \u2003out \u2190 update(k, v, slate) {Run the actual application code.}"},{"entry":"\u20028: \u2003if slate at slate has been modified in updatethen"},{"entry":"\u20029: \u2003\u2003Add slate to list of dirty slates (if not already present)."},{"entry":"10: \u2003end if"},{"entry":"11: \u2003enqueue(instance out, out)"},{"entry":"12: end loop"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}]}}},"Additional optimizations may be implemented to any of the above methods. In an exemplary embodiment, in a tree-event-flow application, separate branches of operators may run in parallel if distinct branches never share slates. If the distinct branches share slates, then each queue(U) may need to be expanded into a full token ring threading all slates of U in some order. In an exemplary embodiment, the stronger guarantee of full-ordering for all operators may not be necessary for map operations which are stateless and, therefore, may not be implemented in some exemplary embodiments.","Exemplary embodiments may provide replay equivalence to ensure that a particular event processing occurs exactly once. For example, if no software crashes or hardware failures occur, then every event is processed once and the results of the update operations are saved to the persistent disk storage. If a software crash or hardware failure occurs, the input data streams may be replayed (e.g., may be rewound to a previous point in time and played from that previous point again), and the slates of the update operations may be saved in snapshots so that the effects of every event is either preserved or replayed.","Application-state snapshots including, for example, external stream events, may be saved on demand and\/or at periodic time intervals so that the saved slates represent the output of processing exactly all external events up to a particular one. Exemplary embodiments may replay the saved snapshots on demand, such as, after a software crash. Exemplary implementations of snapshots may be based on an event-ordered implementation.","A snapshot state may be stored in a durable disk storage by defining a snapshot index. An exemplary snapshot index may be formatted as variables epoch, seqno and status. The variable epoch may be an ordered identifier for a snapshot or a snapshot attempt that distinguishes one snapshot or snapshot attempt from any other snapshots or snapshot attempts. A snapshot attempt is an incomplete or failed snapshot. In an exemplary embodiment, values for the variable epoch may be monotonically increasing integers. The variable seqno may be the sequence number of the external event up to which an application-state snapshot will be saved. The value of the variable seqno thereby demarcates the external events whose effects are included in a snapshot from subsequent external events whose effects are not included in the snapshot. The variable status indicates whether a snapshot has been successfully, i.e., completely saved. If a snapshot has been completely and successfully saved, the value of the variable status is set to \u201ccomplete.\u201d If a snapshot has not been completely saved, the value of the variable status may, in some exemplary embodiments, indicate a set of operators that have successfully saved their snapshots thus far in the process.","An exemplary dummy snapshot index is represented below. The dummy tuple <0, 0, { } may be omitted when constructing a minimal snapshot index value to run a new application. The minimal snapshot index value may be merely < >, i.e., the empty list.",{"@attributes":{"id":"p-0542","num":"0545"},"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00035","he":"3.13mm","wi":"0.68mm","file":"US08595234-20131126-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00036","he":"3.13mm","wi":"0.68mm","file":"US08595234-20131126-P00002.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00037","he":"3.13mm","wi":"1.78mm","file":"US08595234-20131126-P00005.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00038","he":"3.13mm","wi":"1.78mm","file":"US08595234-20131126-P00006.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}]},"The value of the snapshot index may identify all snapshots and may be updated as new snapshots are written. A \u201ctimestamp\u201d may be defined as a <epoch, seqno> pair. The \u201clatest\u201d of a set of timestamps is the one with the largest epoch; if multiple timestamps share the largest epoch, then the one with the largest seqno is latest. For example, the latest <epoch, seqno, status> tuple in the snapshot index is the one with the largest epoch value. A tuple indicates a fully written usable snapshot only if its status value indicates \u201ccomplete.\u201d A write log may be maintained in durable disk storage to track a snapshot in process so that a partially failed snapshot may be fully reversed and repaired. To permit replay\/restart of the snapshot without first repairing a failed snapshot, an application key may be defined as follows:",{"@attributes":{"id":"p-0544","num":"0547"},"img":[{"@attributes":{"id":"CUSTOM-CHARACTER-00039","he":"3.13mm","wi":"0.68mm","file":"US08595234-20131126-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00040","he":"3.13mm","wi":"0.68mm","file":"US08595234-20131126-P00002.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00041","he":"3.13mm","wi":"0.68mm","file":"US08595234-20131126-P00001.TIF","alt":"custom character","img-content":"character","img-format":"tif"}},{"@attributes":{"id":"CUSTOM-CHARACTER-00042","he":"3.13mm","wi":"0.68mm","file":"US08595234-20131126-P00002.TIF","alt":"custom character","img-content":"character","img-format":"tif"}}]},"To ensure that a new snapshot includes processing up to a particular event and no processing of any subsequent events, the snapshot request is triggered in exemplary embodiments only between successive external events. For example at line 9 of Algorithm 1 entitled \u201crun_application,\u201d the following call may be inserted before incrementing seqno. This initiates a request to save all processing up to and including external event seqno. A \u201csync_request\u201d queue entry\/message must be distinguishable from an event.","1: Append new tuple <epoch, seqno, status={ }> to the snapshot-index value.","2: enqueue(F, sync_request(epoch, seqno))","Once a new snapshot request is triggered, a sync request propagates to each slate, i.e., to each update operation instance, in the same way as events, which ensures that the request arrives in order consistent with event processing. In particular, the sync request arrives in exemplary embodiments at each update operation when its slates are in the desired state, e.g., right after processing external event seqno and right before processing external event seqno+1. In order to implement the desired propagation of the sync request, Algorithm 2 entitled \u201crun_operator\u201d may be modified at line 11 so that the method can handle sync requests as well as events. The following pseudocode represents the following modification to Algorithm 2.",{"@attributes":{"id":"p-0549","num":"0552"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"203pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"\u20021: if in is a sync_request then"]},{"entry":[{},"\u20022: \u2003if F is an updater state then"]},{"entry":[{},"\u20023: \u2003\u2003for all instance \u2190 instance of F do"]},{"entry":[{},"\u20024: \u2003\u2003\u2003enqueue(instance in, in)"]},{"entry":[{},"\u20025: \u2003\u2003end for"]},{"entry":[{},"\u20026: \u2003\u2003for all instance \u2190 instance of F do"]},{"entry":[{},"\u20027: \u2003\u2003\u2003r \u2190 dequeue(instance in, in)"]},{"entry":[{},"\u20028: \u2003\u2003\u2003assert r = true"]},{"entry":[{},"\u20029: \u2003\u2003end for"]},{"entry":[{},"10: \u2003end if"]},{"entry":[{},"11: \u2003if G is nil then"]},{"entry":[{},"12: \u2003\u2003\u2009 \u2009epoch, seqno\u2009 \u2009\u2190 in"]},{"entry":[{},"13: \u2003\u2003status \u2190 snapshot-index value for \u2009 \u2009epoch, seqno\u2009 "]},{"entry":[{},"14: \u2003\u2003if status \u222a F = {all operator sinks in application} then"]},{"entry":[{},"15: \u2003\u2003\u2003Replace status \u2190 \u201ccomplete\u201d in snapshot-index value."]},{"entry":[{},"16: \u2003\u2003else"]},{"entry":[{},"17: \u2003\u2003\u2003Replace status \u2190 status \u222a {F} in snapshot-index value."]},{"entry":[{},"18: \u2003\u2003end if"]},{"entry":[{},"19: \u2003else"]},{"entry":[{},"20: \u2003\u2003enqueue(G, in)"]},{"entry":[{},"21: \u2003end if"]},{"entry":[{},"22: \u2003restart loop"]},{"entry":[{},"23: end if"]},{"entry":[{},"24: assert in is a (possibly empty) sequence of events"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"A corresponding modification is made to Algorithm 4 entitled \u201crun_updater\u201d at line 3 so that \u201crun_updater\u201d actually writes the snapshot in response to a sync request. The following pseudocode represents this modification to Algorithm 4.",{"@attributes":{"id":"p-0551","num":"0554"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u20021: U \u2190 the updater corresponding to operator instance F"},{"entry":"\u20022: if in is a sync_request then"},{"entry":"\u20023: \u2003\u2009 \u2009epoch, seqno\u2009 \u2009\u2190 in"},{"entry":"\u20024: \u2003for all slate \u2208 list of dirty slates do"},{"entry":"\u20025: \u2003\u2003key \u2190 slate key"},{"entry":"\u20026: \u2003\u2003Log impending write for \u2009 \u2009epoch, seqno, key, U\u2009 \u2009."},{"entry":"\u20027: \u2003\u2003Append \u2009 \u2009epoch, seqno, slate data\u2009 \u2009to durable key-value storage"},{"entry":"\u2002for key \u2009 \u2009key, U\u2009 \u2009."},{"entry":"\u20028: \u2003\u2003Mark slate clean."},{"entry":"\u20029: \u2003end for"},{"entry":"10: \u2003enqueue(instance out, true)"},{"entry":"11: \u2003restart loop"},{"entry":"12: end if"},{"entry":"13: assert in is an event"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The \u201cfor\u201d loop in the above \u201crun_updater\u201d method for enumerating dirty slates may be parallelized. As long as log writes are atomic, all slate data write operations may occur in parallel.","To restart an application for any reason, an exemplary embodiment may follow the following exemplary steps. The snapshot-index value may be read to determine the <epoch, seqno> of the latest snapshot having status=\u201ccomplete.\u201d If there is no tuple in the snapshot index in which the status value is equal to \u201ccomplete,\u201d epoch=\u22121 and seqno=\u22121 may be selected. The log of impending writes may be read to remove all slate data whose <epoch, seqno> is later than the selected tuple. current_epoch=epoch+1 may be written into the application-key value. The \u201crun_application\u201d method shown in Algorithm 1 may be restarted from external event seqno+1 onwards, configured so that its current_epoch method in line 1 returns epoch+1. In reading a slate for <key k, updater U> from durable disk storage, if key <k, U> has no value in the durable disk storage, then no such slate exists, and if key <k, U> has a value in the durable disk storage, the slate data with the latest timestamp is returned.","In another exemplary embodiment, an application may be restarted without reversing incomplete syncs as long as epoch numbers are never reused. This alternative may provide a faster restart by deferring the repair operation in environments where epoch numbers neither run out nor wrap around. An exemplary embodiment may follow the following exemplary steps. The snapshot-index value may be read to determine the seqno of the latest snapshot having status=\u201ccomplete.\u201d If there is no tuple in the snapshot index in which the status value is equal to \u201ccomplete,\u201d seqno=0 may be selected. The application-key value may be read to determine the last current_epoch and increment it. The new current_epoch may be written into the application-key value. The \u201crun_application\u201d method shown in Algorithm 1 may be restarted from external event seqno+1 onwards, configured so that its current_epoch method in line 1 returns the new current_epoch. In reading a slate for <key k, updater U> from durable disk storage, if key <k, U> has a value in the durable disk storage, the first one of the following options is selected: (a) select the latest slate data whose epoch=current_epoch, (b) select the slate data whose timestamp matches that of the latest status=\u201ccomplete\u201d snapshot. If no slate data has been selected, the system determines that no such slate exists.","Additional improvements may be made to the application-state snapshot storage and replay mechanism. In an exemplary embodiment, if an update operation is used multiple times (i.e. has multiple states) in an application, each state may flush all dirty slates to storage even though only the last state of that update operation to run needs to flush the dirty slates. In an exemplary embodiment, in linear-event-flow applications, there may be only one event sink the entire application. For such applications, status may simply be a Boolean flag and does not need to hold a set of operators. In an exemplary embodiment, the snapshot-index value, individual slates and write logs may have obsolete or old history discarded automatically, for example, at periodic intervals of time. A tuple may be considered obsolete and may be discarded safely if its timestamp satisfies either of the following conditions: (a) the timestamp is earlier than the latest status=\u201ccomplete\u201d snapshot timestamp, or (b) the timestamp epoch is larger than that of the latest status=\u201ccomplete\u201d snapshot and is smaller than current_epoch.","Exemplary embodiments may be used to determine and archive the last stream event in a real-time data stream, e.g., the last \u201ctweet\u201d in a user's Twitter\u2122 stream. One of ordinary skill in the art will readily recognize that archival of the last stream event is an exemplary implementation of exemplary embodiments, and that exemplary embodiments are not limited to this illustrative implementation. In an exemplary embodiment, an update operation may subscribe to a selected data stream and may store the last successfully processed stream event in a slate that is maintained for the stream in a persistent manner.","Exemplary embodiments may be used to determine the time of the last stream event published in a real-time data stream, e.g., the time of publication of the last \u201ctweet\u201d in a user's Twitter\u2122 stream. One of ordinary skill in the art will readily recognize that real-time detection of popular topics is an exemplary implementation of exemplary embodiments, and that exemplary embodiments are not limited to this illustrative implementation.","In an exemplary embodiment, a map operation may subscribe to receive \u201ctweets\u201d in a Twitter\u2122 stream T. The map operation may process each \u201ctweet\u201d in a real-time manner and publish a stream event to an intermediate real-time data stream S. The output stream event may have an eventkey attribute that is the user id of the Twitter\u2122 who published the \u201ctweet.\u201d The value of the eventkey attribute may be the time of publication of the \u201ctweet.\u201d","An update operation may subscribe to the intermediate real-time data stream S and may extract the publication time for each user ID. The update operation may update a slate in disk storage having a slatekey attribute set to the eventkey attribute and a slatekey attribute value set to the eventkey attribute value. That is, the slate may store the last publication time for \u201ctweets\u201d published by the user identified in the slatekey attribute. A slate for a desired Twitter\u2122 user may be looked up in disk storage by the slatekey attribute which designates the user ID.","Exemplary embodiments may be used to perform real-time detection of an unusually high level of interest in a topic discussed in one or more real-time data streams. One of ordinary skill in the art will readily recognize that real-time detection of popular topics is an exemplary implementation of exemplary embodiments, and that exemplary embodiments are not limited to this illustrative implementation.","In an exemplary embodiment, interest in a particular topic T may be indicated by the number of stream events that mention the topic Tin a certain amount of time, e.g., in the last hour, divided by the average number of stream events that mention the topic Tin the same hour of the day. In another exemplary embodiment, interest in a particular topic T may be indicated by a z-score that takes into account both the mean and the standard deviation of hourly mentions of the topic T.","In an exemplary approach, a TopicTagger map operation may be performed to determine the topics discussed in the stream events. A TopicCounter update operation may be performed to count the number of occurrences of a particular topic in the stream events. A TopicThermometer update operation may be performed to indicate those topics that have an unusually high interest indicated by the interest exceeding a predefined threshold interest. A TopKTopic update operation may be performed to determine the top K topics at a time of day.","An exemplary TopicTagger map operation may subscribe to a real-time input data stream S, e.g., a Twitter\u2122 stream. A stream event in the exemplary Twitter\u2122 stream may have an eventkey attribute value the user ID of a Twitter\u2122 user, and a text attribute value containing the full text of the \u201ctweet\u201d event. The TopicTagger map operation may receive a stream event from the subscribed data stream and run a document parsing mechanism on the text attribute value of the \u201ctweet\u201d event. In an exemplary embodiment, the doctagger operator may be run on the text attribute value to extract a set of one or more topics (KCIDs) mentioned in the \u201ctweet.\u201d For each KCID in the \u201ctweet,\u201d the TopicTagger map operation may create and publish a new event on an intermediate real-time data stream S. The eventkey attribute value of the new event may be a collection or combination of the KCID and the time at which the \u201ctweet\u201d was generated, e.g., {KCID, time_of day}. The new event may also include a KCID attribute whose value is the KCID corresponding to the event, and a timestamp attribute whose value is the time at which the \u201ctweet\u201d was generated. The intermediate data stream S may be provided in a stream bus so that any of the map and update operations may access the new events.","The following pseudo-code represents an exemplary object-oriented class TopicTagger that may be used to implemented the TopicTagger map operation.",{"@attributes":{"id":"p-0565","num":"0568"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class TopicTagger(Mapper):"]},{"entry":[{},"\u2003def map(event):"]},{"entry":[{},"\u2003\u2003kcids = doctag(event.text)"]},{"entry":[{},"\u2003\u2003h = date( ).hh( ) \/\/ hour in hh format"]},{"entry":[{},"\u2003\u2003for kcid in kcids:"]},{"entry":[{},"\u2003\u2003\u2003self.publish(\u201cs1\u201d, Event(key:hh+kcid, topic:kcid))"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"An exemplary TopicCounter update operation may subscribe to the real-time intermediate data stream S. For a particular topic and a time of day associated with a stream event in the data stream S, the TopicCounter update operation may be called on a slate S corresponding to the topic and the time of day. The slate S may be expired in a predefined period of time, e.g., one hour. The TopicCounter update operation may maintain a variable count in the slate that counts the number of occurrences of the topic at the time of day associated with the slate. When the slate expires, the TopicCounter update operation may create and publish to a real-time intermediate data stream S a new stream event whose eventkey attribute is a collection or combination of the topic KCID and the time at which the \u201ctweet\u201d was generated, e.g., {KCID, time_of_day}. The value of the eventkey attribute may be the value of the count variable that indicates the number of occurrences of the topic at the time of day. The new stream event may be created and published by a finalize method of the TopicCounter update operation.","The following pseudo-code represents an exemplary object-oriented class TopicCounter that may be used to implemented the TopicCounter update operation.",{"@attributes":{"id":"p-0568","num":"0571"},"tables":{"@attributes":{"id":"TABLE-US-00008","num":"00008"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class TopicCounter(Updater):"]},{"entry":[{},"\u2003def init(slate):"]},{"entry":[{},"\u2003\u2003slate.count = 0 \/\/ total number of mentions"]},{"entry":[{},"\u2003\u2003slate.set_expiry(next_hour( ))"]},{"entry":[{},"\u2003\u2003\/\/ assume we've written a utility fn to compute the"]},{"entry":[{},"\u2003\u2003\/\/ timestamp of the next hour"]},{"entry":[{},"\u2003def update(event, slate):"]},{"entry":[{},"\u2003\u2003slate.count += 1"]},{"entry":[{},"\u2003def finalize(slate):"]},{"entry":[{},"\u2003\u2003self.publish(\u201cs2\u201d, Event(key:slate.key, value:count))"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"An exemplary TopicThermometer update operation may subscribe to the real-time intermediate data stream S. The update operation may be invoked with a slate S corresponding to a particular topic KCID and time of day. The TopicThermometer update operation may maintain the following variables: variable N that includes the total number of mentions of the topic at the time of day, variable D that includes the number of days that the information has been tracked, variable avg that includes the average number of mentions of the topic (i.e., N\/D), and variable interest that includes an indication of the interest in the topic determined as count\/avg. If the value of the interest variable is equal to and\/or above a predefined threshold, the TopicThermometer update operation may create and publish to a real-time intermediate data stream S a new stream event with the topic KCID as the eventkey attribute and the interest level as the eventkey attribute value.","The following pseudo-code represents an exemplary object-oriented class TopicThermometer that may be used to implemented the TopicThermometer update operation.",{"@attributes":{"id":"p-0571","num":"0574"},"tables":{"@attributes":{"id":"TABLE-US-00009","num":"00009"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class TopicThermometer(Updater):"]},{"entry":[{},"\u2003def init(slate):"]},{"entry":[{},"\u2003\u2003slate.n = 0"]},{"entry":[{},"\u2003\u2003slate.d = 0"]},{"entry":[{},"\u2003def update(event, slate):"]},{"entry":[{},"\u2003\u2003avg = (slate.n+1) \/ (slate.d+1) \/\/ avoid zero div"]},{"entry":[{},"\u2003\u2003intrst = event.count \/ avg"]},{"entry":[{},"\u2003\u2003if intrst > threshold:"]},{"entry":[{},"\u2003\u2003\u2003publish(\u201cs3\u201d,Event(key:slate.kcid,interest:intrst))"]},{"entry":[{},"\u2003\u2003\/\/ update stats"]},{"entry":[{},"\u2003\u2003slate.n += event.count"]},{"entry":[{},"\u2003\u2003slate.d += 1"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"In an exemplary embodiment, a data structure may be maintained to record the top K topics at any time of the day. A TopKTopic update operation may be used to maintain this data structure. The TopKTopic update operation may subscribe to the real-time intermediate data stream S and may use a slate to maintain a priority queue that tracks the top K interest scores in the events of stream S. The TopKTopic update operation may also track the top K topics by location and\/or category.","Exemplary embodiments may be used to perform real-time computation of K-ranks that indicate the degree of influence of content published by a particular user on other users. The computation may be based on stream events in a real-time input data stream, e.g., a Twitter\u2122 stream. The stream events in the input data stream may have a streamid attribute value of S, an eventkey attribute value of the user ID, and a text attribute value of the text of the \u201ctweet.\u201d The output may be a hashtable in which the key is the user ID and the value is the K-rank of the user, i.e., <user ID, score>. All K-ranks may be initialized at time zero, e.g., to 1000. In an exemplary embodiment, a map operation named LinkPartitioner, a first update operation named GamePlayer and a second update operation named ScoreUpdater may be used to implement the K-rank computation functionality. One of ordinary skill in the art will readily recognize that real-time detection of popular topics is an exemplary implementation of exemplary embodiments, and that exemplary embodiments are not limited to this illustrative implementation.","In an exemplary embodiment, the LinkPartitioner map operation may subscribe to the input data stream S and may determine if the text of each stream event contains a link. The map operation may, for example, process the text attribute value of the stream event to determine if any portion of the text matches the format of a link. If the map operation determines that the stream event does not include a link, the map operation may not output anything. However, if the stream event is determined to include a link, the map operation may canonicalize the link and generate a new stream event in which the eventkey attribute is the canonicalized link and the value is the user ID of the user who published the input stream event. The map operation may publish the new stream event to a real-time intermediate data stream S.","The following pseudo-code represents an exemplary object-oriented class LinkPartitioner that may be used to implemented the LinkPartitioner map operation.",{"@attributes":{"id":"p-0576","num":"0579"},"tables":{"@attributes":{"id":"TABLE-US-00010","num":"00010"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"168pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class LinkPartitioner(Mapper):"]},{"entry":[{},"\u2003def map(event):"]},{"entry":[{},"\u2003\u2003link = extractLink(event.text)"]},{"entry":[{},"\u2003\u2003if link:"]},{"entry":[{},"\u2003\u2003\u2003ev = event.copy( )"]},{"entry":[{},"\u2003\u2003\u2003ev.key = canonicalize(link)"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003self.publish(\u201cs1\u201d, ev)"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"In an exemplary embodiment, the GamePlayer update operation may subscribe to receive stream events from the real-time intermediate data stream S. The GamePlayer update operation may be invoked with a slate S with slatekey attribute L and a stream event whose eventkey attribute is a link L and whose value is a user ID. The slate S may have an additional attribute named users with a value that holds an ordered list of the users who have published the link L. Every user V in the ordered list of users has in essence \u201cwon\u201d a game against user U, i.e., have been preceded by user U in publishing the link L. In order to model this information, the GamePlayer update operation may generate a new stream event who eventkey attribute is a fixed value and whose value is the ordered pair of users, e.g., (U, V), indicating that \u201cV defeated U.\u201dThe GamePlayer update operation may publish the new stream event to a real-time intermediate data stream S. In addition, the GamePlayer update operation may create a slate S or, if slate S already exists, may append U to the ordered list of users stored in the value of the users attribute in the slate S. A time-to-live parameter may be set for the slate S, e.g., for a day, which ensures that the slate S will be deleted if a link is not seen by the LinkPartitioner map operation in twenty-four hours.","The following pseudo-code represents an exemplary object-oriented class GamePlayer that may be used to implemented the GamePlayer update operation.",{"@attributes":{"id":"p-0579","num":"0582"},"tables":{"@attributes":{"id":"TABLE-US-00011","num":"00011"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class GamePlayer(Updater):"]},{"entry":[{},"\u2003def init(slate):"]},{"entry":[{},"\u2003\u2003slate.users = [ ]"]},{"entry":[{},"\u2003\u2003slate.set_ttl(24*60*60) \/\/ set TTL to be 1 day"]},{"entry":[{},"\u2003def update(event, slate):"]},{"entry":[{},"\u2003\u2003u = event.users"]},{"entry":[{},"\u2003\u2003for v in slate.users:"]},{"entry":[{},"\u2003\u2003\u2003e = Event(key:\u201dx\u201d, winner: v, loser: u)"]},{"entry":[{},"\u2003\u2003\u2003self.publish(\u201cs2\u201d, e)"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003slate.users.append(u)"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"In an exemplary embodiment, the ScoreUpdater update operation may subscribe to receive stream events from the real-time intermediate data stream S. The ScoreUpdater update operation may create a slate or, if the slate already exists, may update the slate containing a single attribute named scores which is a hashtable with a key attribute of user ID and value of the K-score associated with the user ID. The ScoreUpdater update may receive the result of every pairwise game performed by the GamePlayer update operation and may update the K-scores stored in the hashtable associated with each user ID. Any suitable rating system may be used in updating the K-scores, e.g., the Elo rating system.","The following Pseudo-code represents an exemplary object-oriented class ScoreUpdater that may be used to implemented the ScoreUpdater update operation.",{"@attributes":{"id":"p-0582","num":"0585"},"tables":{"@attributes":{"id":"TABLE-US-00012","num":"00012"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class ScoreUpdater(Updater):"]},{"entry":[{},"\u2003def init(slate):"]},{"entry":[{},"\u2003\u2003slate.scores = Hashtable( )"]},{"entry":[{},"\u2003def update(event, slate):"]},{"entry":[{},"\u2003\u2003(win, lose) = (event[\u201cwinner\u201d], event[\u201closer\u201d])"]},{"entry":[{},"\u2003\u2003s = slate.scores"]},{"entry":[{},"\u2003\u2003\/\/ Assume a function ELO that takes old scores of"]},{"entry":[{},"\u2003\u2003\/\/ winner and loser and returns their new scores"]},{"entry":[{},"\u2003\u2003\u2003\u2003\u2003\u2003(s[win],s[lose]) = elo(s[win],s[lose])"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"In an exemplary embodiment which uses application slates and keyspaces, a K-rank computation may store an individual user's K-scores separately in the disk storage indexed by the user ID. A modification may be made to the ScoreUpdater update operation to create a keyspace \u201ckscore.\u201d For every user ID u, the ScoreUpdater update operation may create an application slate with key \u201ckscore:u\u201d which stores the score associated with user ID u. These slates may be set up with a delayed write time, e.g., sixty seconds. The disk storage may be used to store the results of the stream computations and may allow efficient real-time access for applications that use the results. Any application, whether built using the map-update framework, may access the K-score of a user, correct to the last minute, by looking up the key \u201ckscore:u\u201d in the disk storage. In an exemplary embodiment, the system may use keyspaces as information on improving execution, for example, designating the same worker node as the primary worker node for all the keys in an application keyspace.","The following pseudo-code represents an exemplary object-oriented class ScoreUpdater class modified to implement application slates and keyspaces.",{"@attributes":{"id":"p-0585","num":"0588"},"tables":{"@attributes":{"id":"TABLE-US-00013","num":"00013"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"1","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"class ScoreUpdater(Updater):"]},{"entry":[{},"\u2003def gets(userid): \/\/ utility method"]},{"entry":[{},"\u2003\u2003try:"]},{"entry":[{},"\u2003\u2003\u2003\/* get_slate( ) gets a slate by key. If no slate"]},{"entry":[{},"\u2003\u2003\u2003exists for the key, it raises KeyError *\/"]},{"entry":[{},"\u2003\u2003\u2003return self.get_slate(\u201ckscore:\u201d + userid)"]},{"entry":[{},"\u2003\u2003except KeyError:"]},{"entry":[{},"\u2003\u2003\u2003\/* create a new app slate and initialize it *\/"]},{"entry":[{},"\u2003\u2003\u2003s = Slate((\u201ckscore:\u201d + userid)"]},{"entry":[{},"\u2003\u2003\u2003s.score = 1000 \u2003\/\/ initial ELO score"]},{"entry":[{},"\u2003\u2003\u2003s.set_write_delay(60) \/\/ 60-second write delay"]},{"entry":[{},"\u2003\u2003\u2003return s"]},{"entry":[{},"\u2003\u2003def update(event, slate)"]},{"entry":[{},"\u2003\u2003\u2003winner, loser = (event.winner, event.loser)"]},{"entry":[{},"\u2003\u2003\u2003wins, loses = (self.gets(winner), self.gets(loser))"]},{"entry":[{},"\u2003\u2003\u2003wins.score, loses.score = elo(wins.score,loses.score)"]},{"entry":[{},"\u2003\u2003\u2003wins.update( )"]},{"entry":[{},"\u2003\u2003\u2003loses.update( )"]},{"entry":{"@attributes":{"namest":"1","nameend":"2","align":"center","rowsep":"1"}}}]}}}}},"Exemplary embodiments may be used to cluster stream events in real-time data streams based on a taxonomy of one or more topic categories. Exemplary stream clustering mechanisms may be used to cluster stream events in any desired data streams. In an exemplary application of a clustering search engine, a spider may crawl the web and categorize the web pages it gathers into topic pages. A \u201chome page\u201d or information repository may be provided for each topic to serve as a doorway to all of the most valuable information on the topic found on the web. Exemplary topics of interest may include, but are not limited to, health, cancer, travel, Hawaii vacation, autos, and the like.","In an exemplary application, stream clustering may be applied to a subset of stream events (e.g., \u201ctweets\u201d obtained from a Twitter\u2122 stream) that contain links to external articles. Exemplary embodiments may cluster the external articles into news \u201cstories.\u201d As the data stream flows, new stores may emerge, existing stories may divide into sub-stories, and certain stories may increase and diminish in importance. Exemplary embodiments may apply the stream clustering mechanisms to identify the top N stories at any time. Exemplary embodiments may also identify the top N stories in different topic categories. Exemplary embodiments may also generate a real-time story stream.","A taxonomy may be provided in exemplary embodiments to categorize information in stream events hierarchically. The taxonomy may provide a plurality of categories for categorizing information at different levels of granularity. In an exemplary embodiment, the information in each stream event may be analyzed and categorized based on one or more categories, for example, first, second and third-level categories indicating increasing granularities of categorization. For example, a first-level category may indicate a high-level concept associated with the information in a stream event, e.g., news. A second-level category may indicate an intermediate-level concept, e.g., politics. A third-level category may indicate a specific concept, e.g., American politics. One of ordinary skill in the art will recognize that additional levels of categories may be used and that, in an alternative embodiment, the granularity of categorization may decrease with increasing category levels.","In exemplary embodiments, the taxonomy may also reflect one or more relationships including, but not limited to, is-a relationships (e.g., San Francisco is-a city), member-of relationships (e.g., James Hetfield is a member-of Metallica), capital-of relationships (e.g., Can berra is the capital-of Australia), and the like. The resulting hierarchical structure may be implemented as a directed acyclic graph (DAG).","An exemplary stream clustering computation may be divided into two phases for ease of implementation. In a first phase of the stream clustering computation, stream events may be distributed among worker nodes in such a manner that if events A and B can be part of the same cluster, the events are routed to the same worker node. In order to implement this event routing mechanism, each stream event may be distributed to k different worker nodes corresponding to k different second or third-level topic categories corresponding to the stream event. If there are M second-level topic categories, M update operations may be executed, each update operation maintaining topic clusters in parallel. An assumption in this implementation is that stream events cannot cluster together unless they agree on at least one of their k second-level topic categories.","In an exemplary embodiment, the first phase of the stream clustering computation may be implemented with a map operation named DocTagger and an update operation named CategoryCluster. In an exemplary embodiment, the DocTagger map operation may run a document categorization engine named doctagger on the text contained in stream events. The DocTagger map operation may analyze the text of each stream event and generate a cluster vector of topic categories corresponding to the text in the stream event. The DocTagger map operation may also generate high-level topic categories corresponding to the text in the stream event (e.g., second or third-level topic categories in an exemplary taxonomy). For each high-level topic category, the DocTagger map operation may create a new stream event whose eventkey attribute is the topic category. The new stream event may include other attributes including, but not limited to, a docvector attribute containing the cluster vector and other attributes specific to the source that generated the input stream event, e.g., Twitter\u2122. The DocTagger map operation may publish the new stream event to a real-time intermediate data stream S.","In an exemplary embodiment, the CategoryCluster update operation may subscribe to the real-time intermediate data stream S, and may be invoked with each stream event in the data stream S and a slate whose slatekey attribute is the topic category in the stream event. The CategoryCluster update operation may run a suitable clustering engine to add the stream event to the clusters maintained in the slate. For each cluster, only the metadata may be stored in the slate, and application slates with suitable time-to-live parameter values may be used to store the actual contents of the cluster and the stream event information. The CategoryCluster update operation may create a new stream event for each updated cluster with the eventkey attribute set to the cluster ID and the value set to the cluster vector and other cluster metadata. The CategoryCluster update operation may publish the new stream event to a real-time intermediate data stream S.","In a second phase of the stream clustering computation, the clusters from the M different clusterings may be examined, and duplicates and near-duplicates are eliminated or merged. In an exemplary embodiment, each cluster may have a cluster vector of topic categories. An assumption in this implementation is that if two clusters are near-duplicates, the clusters will agree on their top-j topic category sets, i.e., the topic categories that have the j highest scores in the cluster vector viewed as a set (e.g., j\u22123). The cluster metadata may be distributed so that candidate near-duplicate clusters are routed to the same node where they may be merged or combined.","In some other exemplary embodiments, duplicates and near-duplicates may not be removed or merged, and may be tracked separately.","In an exemplary embodiment, the second phase of the stream clustering computation may be implemented with a map operation named KCIDGrouper, a first update operation named ClusterMerger, and a second update operation named OutputStreamer. In an exemplary embodiment, the KCIDGrouper map operation may subscribe to receive stream events from the real-time intermediate data stream S. For every received stream event, the KCIDGrouper map operation may examiner the cluster vector and create an eventkey attribute with a value that combines the k highest-level topic categories in the cluster vector. The KODGrouper map operation may create a new stream event having the newly created eventkey attribute and value. The new stream event may have one or more additional attributes, e.g., corresponding to those of the received stream event in the data stream S. The KCIDGrouper map operation may publish the created stream event to a real-time intermediate data stream S.","In an exemplary embodiment, the ClusterManager update operation may subscribe to receive stream events from the real-time intermediate data stream S. The ClusterManager update operation may run a suitable hierarchical clustering engine on the clusters in the received stream event to merge near-duplicate clusters. The ClusterManager update operation may create a new stream event corresponding to every second-level cluster. The ClusterManager may publish the new stream event to a real-time intermediate data stream S.","In an exemplary embodiment, the OutputStreamer update operation may subscribe to receive stream events from the real-time intermediate data stream S. The OutputStreamer update operation may examiner each second-level cluster and, based on predefined threshold levels, may publish stream events to one or more output data streams in which one data stream is provided for each stream speed. In an exemplary embodiment, slower data streams may have higher predefined threshold levels.",{"@attributes":{"id":"p-0598","num":"0601"},"figref":"FIG. 42","b":["4200","4200"]},"The computing device  includes one or more non-transitory computer-readable media having encoded thereon one or more computer-executable instructions or software for implementing exemplary methods. The non-transitory computer-readable media may include, but are not limited to, one or more types of hardware memory, non-transitory tangible media (for example, one or more magnetic storage disks, one or more optical disks, one or more USB flash drives), and the like. For example, memory  included in the computing device  may store computer-readable and computer-executable instructions or software for implementing exemplary embodiments. The computing device  also includes processor  and associated core , and in some embodiments, one or more additional processor(s) \u2032 and associated core(s) \u2032 (for example, in the case of computer systems having multiple processors\/cores), for executing computer-readable and computer-executable instructions or software stored in the memory  and other programs for controlling system hardware. Processor  and processor(s) \u2032 may each be a single core processor or multiple core ( and \u2032) processor.","Virtualization may be employed in the computing device  so that infrastructure and resources in the computing device may be shared dynamically. A virtual machine  may be provided to handle a process running on multiple processors so that the process appears to be using only one computing resource rather than multiple computing resources. Multiple virtual machines may also be used with one processor.","Memory  may include a computer system memory or random access memory, such as DRAM, SRAM, EDO RAM, and the like. Memory  may include other types of memory as well, or combinations thereof. Memory  may be used to store one or more slates on a temporary basis, for example, in cache.","A user may interact with the computing device  through a visual display device , such as a screen or monitor, that may display one or more user interfaces  that may be provided in accordance with exemplary embodiments. The visual display device  may also display other aspects, elements and\/or information or data associated with exemplary embodiments. The computing device  may include other I\/O devices for receiving input from a user, for example, a keyboard or any suitable multi-point touch interface , a pointing device  (e.g., a mouse, a user's finger interfacing directly with a display device, etc.). The keyboard  and the pointing device  may be coupled to the visual display device . The computing device  may include other suitable conventional I\/O peripherals.","The computing device  may include one or more audio input devices , such as one or more microphones, that may be used by a user to provide one or more audio input streams.","The computing device  may include one or more storage devices , such as a durable disk storage (which may include any suitable optical or magnetic durable storage device, e.g., RAM, ROM, Flash, USB drive, or other semiconductor-based storage medium), a hard-drive, CD-ROM, or other computer readable media, for storing data and computer-readable instructions and\/or software that implement exemplary embodiments as taught herein. For example, the storage device  may provide a slate storage  for storing slates, and may store computer-executable instructions for implementing, for example, a receiver module , a conductor module , one or more map modules , and one or more update modules . Exemplary receiver, conductor, map and update modules may be programmatically implemented by a computer process as described in connection with . The storage device  may be provided on the computing device  or provided separately or remotely from the computing device . The storage device  may be used to store one or more slates in a durable manner.","The computing device  may include a network interface  configured to interface via one or more network devices  with one or more networks, for example, Local Area Network (LAN), Wide Area Network (WAN) or the Internet through a variety of connections including, but not limited to, standard telephone lines, LAN or WAN links (for example, 802.11, T1, T3, 56 kb, X.25), broadband connections (for example, ISDN, Frame Relay, ATM), wireless connections, controller area network (CAN), or some combination of any or all of the above. The network interface  may include a built-in network adapter, network interface card, PCMCIA network card, card bus network adapter, wireless network adapter, USB network adapter, modem or any other device suitable for interfacing the computing device  to any type of network capable of communication and performing the operations described herein. The network device  may include one or more suitable devices for receiving and transmitting communications over the network including, but not limited to, one or more receivers, one or more transmitters, one or more transceivers, one or more antennae, and the like.","The computing device  may run any operating system , such as any of the versions of the Microsoft\u00ae Windows\u00ae operating systems, the different releases of the Unix and Linux operating systems, any version of the MacOS\u00ae for Macintosh computers, any embedded operating system, any real-time operating system, any open source operating system, any proprietary operating system, any operating systems for mobile computing devices, or any other operating system capable of running on the computing device and performing the operations described herein. In exemplary embodiments, the operating system  may be run in native mode or emulated mode. In an exemplary embodiment, the operating system  may be run on one or more cloud machine instances.","Exemplary computer-executable methods, systems and devices taught herein may be used in various computer applications and to implement further computer-executable methods and techniques. For example, exemplary computer-executable methods, systems and devices taught herein may be used to populate and process data structures taught in U.S. Provisional Patent Application No. 61\/415,279 entitled \u201cSocial Genome,\u201d filed Nov. 18, 2010 and in a U.S. non-provisional patent application Ser. No. 13\/300,519 entitled \u201cSocial Genome,\u201d filed Nov. 18, 2011. Exemplary computer-executable methods, systems and devices taught herein may be used to perform analytics as taught in a U.S. non-provisional patent application Ser. No. 13\/300,523 entitled \u201cReal-time Analytics of Streaming Data,\u201d filed Nov. 18, 2011. Exemplary computer-executable methods, systems and devices taught herein may be used to process and provide data for methods taught in a U.S. non-provisional patent application Ser. No. 13\/300,473 entitled \u201cMethods, Systems and Devices for Recommending Products and Services,\u201d filed Nov. 18, 2011.",{"@attributes":{"id":"p-0608","num":"0611"},"figref":"FIG. 43","b":["4300","4300","4302","4304","4306","4308","4310","4212","4222","4200","4302","4304","4306","4308","4310","4310","4310"]},"In an exemplary embodiment, the servers  and  may provide the clients  and  with computer-readable and\/or computer-executable components or products or data under a particular condition, such as a license agreement. In an exemplary embodiment, the clients  and  may provide the servers  and  with computer-readable and\/or computer-executable components or products or data under a particular condition, such as a license agreement.","In an exemplary embodiment, one or more of the servers  and  and clients  and  may implement a computational system, such as system  or one or more modules thereof shown in , in order to provide a distributed mechanism for performing the exemplary methods described herein. For example, servers  and  may implement computational systems \u2032 and \u2033, respectively, and clients  and  may implement computational systems \u2032\u2033 and \u2033\u2033, respectively.","In an exemplary distributed implementation for processing real-time data streams, a stream bus comprising one or more real-time data streams may be provided at a computational system \u2032 on a server . One or more receiver and\/or one or more conductor modules may be provided at a computational system \u2033 on a server . The receiver and\/or conductor modules may access one or more data streams provided by the server , may transmit stream events in the data streams to one or more worker processes running on client machines. For example, a computational system \u2032\u2033 on a client  may run a first worker process to perform a first stream computation, e.g., a map operation and\/or an update operation. Similarly, a computational system \u2033\u2033 on a client  may run a second worker process to perform a second stream computation, e.g., a map operation and\/or an update operation.","In an exemplary embodiment, the first worker process running on the client  may receive one or more stream events from the conductor running on the server , and may perform the first stream computation. The first worker process may generate an output stream event as a result of the first stream computation, which may be published to a data stream maintained at the stream bus on the server .","In an exemplary embodiment, the second worker process running on the client  may receive one or more stream events from the conductor running on the server , and may perform the second stream computation. The second worker process may create or update one or more slate data structures, and may persistently store the slates at the computational system \u2033\u2033 on the client  in a distributed manner and\/or at a central data structure provided on a different server or client. The second worker process may also store the slates in memory at the computational system \u2033\u2033 on the client . Storage of a slate locally in memory at a worker node where the worker node is the primary worker node for the slatekey of the slate reduces the number of disk storage accesses performed during the stream computation and, thereby, reduces the time and computational requirements of the stream computation. The second worker process may, additionally or alternatively, generate an output stream event as a result of the second stream computation, which may be published to a data stream maintained at the stream bus on the server .","In describing exemplary embodiments, specific terminology is used for the sake of clarity. For purposes of description, each specific term is intended to at least include all technical and functional equivalents that operate in a similar manner to accomplish a similar purpose. Additionally, in some instances where a particular exemplary embodiment includes a plurality of system elements, device components or method steps, those elements, components or steps may be replaced with a single element, component or step. Likewise, a single element, component or step may be replaced with a plurality of elements, components or steps that serve the same purpose. Moreover, while exemplary embodiments have been shown and described with references to particular embodiments thereof, those of ordinary skill in the art will understand that various substitutions and alterations in form and detail may be made therein without departing from the scope of the invention. Further still, other aspects, functions and advantages are also within the scope of the invention.","Exemplary flowcharts are provided herein for illustrative purposes and are non-limiting examples of methods. One of ordinary skill in the art will recognize that exemplary methods may include more or fewer steps than those illustrated in the exemplary flowcharts, and that the steps in the exemplary flowcharts may be performed in a different order than the order shown in the illustrative flowcharts. Method steps in the exemplary flowcharts represented in dashed lines are steps that are provided in some embodiments and not in other embodiments."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The foregoing and other objects, aspects, features and advantages of exemplary embodiments will be more fully understood from the following description when read together with the accompanying drawings, in which:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2A"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2B"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 19A"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 19B"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 19C"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 19D"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 25"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 26"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 27"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 28"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 29"},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 30"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 31"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 32"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 33"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 34"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 35"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 36"},{"@attributes":{"id":"p-0051","num":"0050"},"figref":["FIG. 37","FIG. 36"]},{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIG. 38","FIG. 36"]},{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 39","FIG. 37"]},{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 40"},{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 41"},{"@attributes":{"id":"p-0056","num":"0055"},"figref":"FIG. 42"},{"@attributes":{"id":"p-0057","num":"0056"},"figref":"FIG. 43"}]},"DETDESC":[{},{}]}
