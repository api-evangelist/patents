---
title: Method and system for motion compensated target detection using acoustical focusing
abstract: An improved method and system for removing time-varying Doppler shifts and the effects of turbulence from data comprising at least one processor operating to estimate the average instantaneous frequency; reduce or remove noise from the state space variables estimates describing the frequency of the target; compensate for the motion of the target to obtain motion compensated data and increase the coherency of the data, and reduce or remove the noise from the state space variables describing the frequency of the target using a filter or smoother. Alternately, the method and system may comprise at least one processor operating to estimate the average instantaneous frequency of the first harmonic of a moving target; the average instantaneous frequency being inputted into an error reduction subroutine; using state space estimates of the frequency, calculating a time warping to remove the effect of the Doppler shift; and focusing the data using a modified PGA.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09223021&OS=09223021&RS=09223021
owner: The United States of America as represented by the Secretary of the Army
number: 09223021
owner_city: Washington
owner_country: US
publication_date: 20121022
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["STATEMENT OF GOVERNMENT INTEREST","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS"],"p":["The embodiments herein may be manufactured, used, and\/or licensed by or for the United States Government without the payment of royalties thereon.","There exists an interest in classifying, tracking, and canceling the signals from military assets using passive acoustic sensors. Goals for battlefield acoustics include localization, tracking, identification, motion compensation\/Autofocus. preprocessor, focus spectrum (classification algorithms, nulling algorithms, and small improvement localization algorithms). As to autofocus, phase gradient autofocus (PGA) algorithm is the subject of P. H Eichel. and C. V. Jakowatz, \u201cPhase gradient algorithm as an optimal estimator of the phase derivative,\u201d Optics Letters, Vol. 14, No. 20, 1101-1103, (1989) and P. H Eichel, D. C. Ghiglia, and C. V. Jakowatz, Jr., \u201cSpeckle processing method for synthetic aperture radar phase correction,\u201d Optics Letters, Vol. 14, 1101-1103, (1989), both of which are hereby incorporated by reference.","During the classifying, tracking, and\/or canceling of signals from military assets using passive acoustic sensors, many targets have acoustic signatures with large peaks in their spectrum that can be exploited by signal processing algorithms. However, target motion and turbulence in the atmosphere can distort the transmitted signal and degrade the performance of these signal processing algorithms. Preprocessing the data using motion compensation and autofocus algorithms can focus the signature of the target, and thereby provide longer coherent processing interval durations and improved performance of previously developed algorithms.","The present invention is directed to an algorithm that, inter alia, focuses the frequency spectrum of moving targets such as, for example, a maneuvering rotorcraft. In a preferred embodiment, the acoustic spectrum data is motion compensated by tracking the time-varying Doppler shift generated by the main rotor blade, then a modified PGA algorithm is applied to the data.","A preferred methodology for improving the sensing of data associated with a target on a processor comprising: estimating the average instantaneous frequency; reducing or removing noise from the average instantaneous frequency; compensating for the motion of the target to obtain motion compensated data and focusing the motion compensated data; performing a discrete fourier transform on the focused motion compensated data. Optionally, the reducing or removing noise from the average instantaneous frequency comprises using one of a filter or smoother. Optionally, the focusing of the motion compensated data comprises utilizes a phase gradient autofocus algorithm applied to the acoustic signature of a maneuvering rotorcraft. Optionally, the focusing of the motion compensated data utilizes a modified phase gradient autofocus algorithm Optionally, the step of estimating the average instantaneous frequency comprises: (a) performing a fast fourier transform on the data; (b) applying a window function; (c) converting back to the time domain (d) applying a cross correlation function; (e) finding a location of a peak; and (f) calculating the fundamental frequency. Optionally, the step of estimating the average instantaneous frequency comprises finding a peak location of a weighted autocorrelation; the weighting being based upon a Wiener filter. Optionally, the removing of noise from the average instantaneous frequency data comprises (a) initializing state space variables values and covariance in a matrix; b) obtaining frequency estimates; c) calculating innovation; d) updating state space variables and covariance in the matrix; e) repeating steps b) through d) until the estimation of state variables is completed.","A preferred embodiment methodology comprises estimating the average instantaneous frequency of the first harmonic of a moving target using at least one processor; inputting the average instantaneous frequency into an error reduction subroutine; using state space estimates of the frequency, calculating a time warping that will remove the effect of the time-varying Doppler shift from the data; focusing the data using a modified phase gradient autofocus algorithm. Optionally, the error reduction subroutine comprises a fixed lag smoother. Optionally, the system further comprises performing a discrete fourier transform on the focused data. Optionally, the reducing or removing of noise from the average instantaneous frequency comprises using one of a filter or smoother. Optionally, the focusing of the motion compensated data comprises utilizing a phase gradient autofocus algorithm applied to the acoustic signature of a maneuvering rotorcraft. Optionally, the focusing of the motion compensated data comprises using a modified phase gradient autofocus algorithm. Optionally, the estimating of the average instantaneous frequency comprises: performing a fast fourier transform on the data; applying a window function; applying a cross correlation function; finding a location of a peak; and calculating the fundamental frequency.","A preferred embodiment system for improving the sensing of data associated with a target comprising at least one processor, the at least one processor operating to perform the steps of: estimating the average instantaneous frequency; reducing or removing noise from the average instantaneous frequency; compensating for the motion of the target to obtain motion compensated data; focusing the motion compensated data; and performing a discrete Fourier transform on the focused motion compensated data.","The embodiments herein and the various features and advantageous details thereof are explained more fully with reference to the non-limiting embodiments that are illustrated in the accompanying drawings and detailed in the following description. Descriptions of well-known components and processing techniques are omitted so as to not unnecessarily obscure the embodiments herein. The examples used herein are intended merely to facilitate an understanding of ways in which the embodiments herein may be practiced and to further enable those of skill in the art to practice the embodiments herein. Accordingly, the examples should not be construed as limiting the scope of the embodiments herein.","The embodiments of the invention and the various features and advantageous details thereof are explained more fully with reference to the non-limiting embodiments that are illustrated in the accompanying drawings and detailed in the following description. It should be noted that the features illustrated in the drawings are not necessarily drawn to scale. Descriptions of well-known components and processing techniques are omitted so as to not unnecessarily obscure the embodiments of the invention. The examples used herein are intended merely to facilitate an understanding of ways in which the embodiments of the invention may be practiced and to further enable those of skilled in the art to practice the embodiments of the invention. Accordingly, the examples should not be construed as limiting the scope of the embodiments of the invention.","The terminology used herein is for the purpose of describing particular embodiments only and is not intended to limit the full scope of the invention. As used herein, the singular forms \u201ca\u201d, \u201can\u201d and \u201cthe\u201d are intended to include the plural forms as well, unless the context clearly indicates otherwise. It will be further understood that the terms \u201ccomprises\u201d and\/or \u201ccomprising,\u201d when used in this specification, specify the presence of stated features, integers, steps, operations, elements, and\/or components, but do not preclude the presence or addition of one or more other features, integers, steps, operations, elements, components, and\/or groups thereof.","It will be understood that when an element such as an object, layer, region or substrate is referred to as being \u201con\u201d or extending \u201conto\u201d another element, it can be directly on or extend directly onto the other element or intervening elements may also be present. In contrast, when an element is referred to as being \u201cdirectly on\u201d or extending \u201cdirectly onto\u201d another element, there are no intervening elements present. It will also be understood that when an element is referred to as being \u201cconnected\u201d or \u201ccoupled\u201d to another element, it can be directly connected or coupled to the other element or intervening elements may be present. In contrast, when an element is referred to as being \u201cdirectly connected\u201d or \u201cdirectly coupled\u201d to another element, there are no intervening elements present.","It will be understood that, although the terms first, second, etc. may be used herein to describe various elements, components, regions, layers and\/or sections, these elements, components, regions, layers and\/or sections should not be limited by these terms. Thus, a first element, component, region, layer or section discussed below could be termed a second element, component, region, layer or section without departing from the teachings of the present invention.","Furthermore, relative terms, such as \u201clower\u201d or \u201cbottom\u201d and \u201cupper\u201d or \u201ctop,\u201d may be used herein to describe one element's relationship to other elements as illustrated in the Figures. It will be understood that relative terms are intended to encompass different orientations of the device in addition to the orientation depicted in the Figures. For example, if the device in the Figures is turned over, elements described as being on the \u201clower\u201d side of other elements would then be oriented on \u201cupper\u201d sides of the other elements. The exemplary term \u201clower\u201d, can therefore, encompass both an orientation of \u201clower\u201d and \u201cupper,\u201d depending of the particular orientation of the figure. Similarly, if the device in one of the figures is turned over, elements described as \u201cbelow\u201d or \u201cbeneath\u201d other elements would then be oriented \u201cabove\u201d the other elements. The exemplary terms \u201cbelow\u201d or \u201cbeneath\u201d can, therefore, encompass both an orientation of above and below. Furthermore, the term \u201couter\u201d may be used to refer to a surface and\/or layer that is farthest away from a substrate.","Unless otherwise defined, all terms (including technical and scientific terms) used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this invention belongs. It will be further understood that terms, such as those defined in commonly used dictionaries, should be interpreted as having a meaning that is consistent with their meaning in the context of the relevant art and will not be interpreted in an idealized or overly formal sense unless expressly so defined herein.","It will also be appreciated by those of skill in the art that references to a structure or feature that is disposed \u201cadjacent\u201d another feature may have portions that overlap or underlie the adjacent feature.","The target signature or signal may be modeled by d(t)=h(\u03ba(t))+n(t), where d(t) is the measured acoustic signal of the target as a function of time, h(t) is the signal emitted by the target, \u03ba(t) is a function that distorts the signal due to target motion, and n(t) is noise. For rotorcraft:\n\n()=real(\u03a3)+()\n\nwhere h(t) is the acoustic signal emitted from the rotorcraft at time t; Al and \u03c6l are the amplitude and phase for the 1harmonic; L is the number of harmonics; j is the square root of \u22121; v is the fundamental frequency; and f(t) is an unknown function.\n","During the classifying, tracking, and\/or canceling of signals from military assets using passive acoustic sensors, many targets have acoustic signatures with large peaks in their spectrum that can be exploited by signal processing algorithms. However, target motion and turbulence in the atmosphere can distort the transmitted signal and degrade the performance of these algorithms. Preprocessing the data using motion compensation and autofocus algorithms can focus the signature of the target, and thereby provide longer coherent processing interval durations and improved performance of previously developed algorithms.","Coherent focusing algorithms are widely used in the field of radar signal processing. For example, when a synthetic aperture radar (SAR) image is generated the motion of the platform is typically accounted for by multiplying the received data by the complex conjugate of the phase of the signal returned by an isotropic point scatterer located in the center of the image scene. This requires knowledge of the velocity of the aircraft (platform for the SAR radar) and the transmitted waveform. For passive acoustic sensors, the velocity of the target and the waveform of the signal are typically unknown. However, for many targets of interest, information about the structure of the waveform is known. For example, the rotation rate of the blades on a rotorcraft or the propellers on an airplane is typically fixed, and it generates acoustic waveforms with multiple spectral peaks with stable frequencies. For these targets, time-varying Doppler shifts can be estimated and used to calculate a time warping that will remove these effects from the data.","A preferred embodiment algorithm of the present invention may be utilized to focus the acoustic spectrum of a maneuvering rotorcraft. First, the data may be motion compensated based upon the estimates of the fundamental frequency of the signal generated by the main rotor blade. State space estimates of the frequency may be to calculate a time warping that removes the effect of the time-varying Doppler shift from the data. Then, the motion compensated data may be further focused using a modified phase gradient autofocus (PGA) algorithm.","To this end, a preferred embodiment algorithm was evaluated by analyzing the increase in the amplitude of the harmonics in the spectrum of a rotorcraft. The results depended upon the frequency of the harmonics, processing interval duration, target dynamics, and atmospheric conditions. Under good conditions, the results for the fundamental frequency of the target (\u02dc11 Hz) almost achieved the predicted upper bound. The results for higher frequency harmonics had larger increases in the amplitude of the peaks, but smaller improvements than the predicted upper bounds. The preferred embodiment algorithm can be used to preprocess data for classification, tracking, and nulling algorithms.","Once the SAR image is generated, it is typically further processed using an autofocus algorithm. Most autofocus algorithms assume there are isotropic scattering centers in the scene that are blurred by errors not corrected for in the motion compensation algorithm. A standard technique to focus SAR images is the phase gradient autofocus (PGA) algorithm. For an acoustic signal generated by a rotorcraft, there are multiple harmonics that are distorted by the motion of the target and atmospheric effects. The same techniques used in radar to focus a point scatterer in a scene can be applied to atmospheric acoustics to focus the spectrum of target with some modifications.","Focusing algorithms have been developed for many acoustic applications. For example, techniques have been developed that reduce the error in time-of-arrival estimates for moving targets by accounting for the effect of the Doppler shift in the signal processing. As used herein, the terminology \u201cDoppler\u201d shift\u201d is the change in frequency of a wave occurring when the observer is moving relative to the source of the origin of the wave or when the source is moving relative to the observer. Moreover, \u201cDoppler Shift\u201d includes Bistatic Doppler shift which occurs when the receiver and transmitter of a radar or sonar system are separated. According to Wikipedia, the Doppler shift is due to the component of motion of the object in the direction of the transmitter, plus the component of motion of the object in the direction of the receiver. Equivalently, it can be considered as proportional to the rate of change of bistatic range.","In a bistatic radar with wavelength \u03bb, where the distance between transmitter and target is Rtx and distance between receiver and target is Rrx, the received bistatic Doppler frequency shift is calculated as:",{"@attributes":{"id":"p-0046","num":"0045"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"f","mo":"=","mrow":{"mfrac":[{"mn":"1","mi":"\u03bb"},{"mi":["d","dt"]}],"mo":["\u2062","\u2062"],"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["R","tx"]},{"mi":["R","rx"]}],"mo":"+"}}}}}}},"Algorithms have also been developed that take advantage of the Doppler shift to track the speed and height of fixed-wing aircraft. Another area where removing the effect of Doppler shifts is important is in underwater communication. For example, B. S. Sharif, \u201cA Computationally Efficient Doppler Compensation. System for Underwater Acoustic Communications,\u201d IEEE J. Oceanic Eng., 25 (1), (2000) uses a bank of matched filters to estimate and reduce the effect of Doppler shifts on communication waveforms caused by changing environmental conditions. The present invention is directed to developing an algorithm to preprocess data for several applications. It should improve the performance of classification algorithms by focusing the signature of the target and improving the results of nulling algorithms by allowing narrowband techniques to be applied to peaks in the spectrum of the target.","A major issue associated with most motion compensation algorithms is the tradeoff between accuracy and computational efficiency. The maximum likelihood estimate (MLE), which is an asymptotically efficient estimator, can usually be computed to compensate for the effect of target motion. However, it is usually computationally expensive to implement. Most of the papers in the literature have focused on developing suboptimal techniques that are computationally efficient, which is also a goal of the present invention.","The algorithm developed in accordance with the principles of the present invention processes data in three stages. First, the average instantaneous frequency of the first harmonic of a rotorcraft is estimated and input to a fixed-lag smoother. Then, the state space estimates of the frequency are used to calculate a time warping that will remove the effect of the Doppler shift from the data. Lastly, the data is further focused using a modified phase gradient autofocus (PGA) algorithm.","The algorithm developed in accordance with the principles of the present invention was tested using acoustic data from a rotorcraft measured with a single microphone. It was evaluated using metrics based upon the increase in the peak levels of the harmonics in the spectrum. Both the percentage of peaks that increased in amplitude after motion compensation and the amount of their improvement were analyzed. These results were compared to theoretical predictions based on coherent processing gain and estimates of the instantaneous frequency of the target.","For ease of reading, the general organization of this disclosure may be summarized as introducing the problem, describing a target model for the acoustic signature of the target, describing the resampling algorithm, describing the phase gradient autofocus (PGA) algorithm and the data collection. Then, the fixed-lag smoothing algorithm that is used to estimate the frequency of the target is next explained and the data processing is described and the results are analyzed, and then summarized.","An example of a phase gradient autofocus (PGA) algorithm is further described in P. H Eichel. and C. V. Jakowatz, \u201cPhase gradient algorithm as an optimal estimator of the phase derivative,\u201d Optics Letters, Vol. 14, No. 20, 1101-1103, (1989), which is hereby incorporated by reference.","A simple model that describes the acoustic signal measured on the ground with a microphone for a moving target is\n\n()=(\u03ba())+(),\u2003\u2003(1)\n\nwhere d(t) is the measured acoustic signal of the target as a function of time, h(t) is the signal emitted by the target, \u03ba(t) is a function that distorts the signal due to target motion, and n(t) is noise. For a target such as a rotorcraft, the model can be expanded into the signal generated by a dominant harmonic source, such as the main rotor blades and everything else. The signal from the main rotor blades can be modeled as a harmonic signal with a constant fundamental frequency, with amplitude weights on each harmonic. The signal model for the target can be described by\n\n()=\u03a3(), for 0<\u2003\u2003(2)\n\nwhere h(t) is the acoustic signal emitted from the rotorcraft at time t; Aand \u03c6are the amplitude and phase for the harmonic, respectively; L is the number of harmonics; j is the square root of \u22121; v is the fundamental frequency; and f(t) is an unknown function, and T is the processing time interval.\n","The model assumes that the signal propagates under ideal atmospheric conditions and spherical propagation losses are incorporated into the coefficients.","The effect of target motion on the measured signal can be modeled using d(t)=h(t\u2212\u03c4)\u03c4(t)), where \u03c4(t) is the propagation delay from the target to the measurement location at a given time. Its effect can be approximated by performing a Taylor series expansion on \u03c4(t) with respect to time. The coefficients of the parameters in the expansion are not known without knowledge of the target dynamics, but they can be described using a polynomial equation. The propagation delay can be described using\n\n\u03c4()=+\u03c6() for 0<\u2003\u2003(3)\n\nwhere b-bare constants, and \u03a6(t) represents a small error term. For a signal with a stable spectral peaks, such as a waveform with harmonic structure, the instantaneous frequency can be computed by substituting (3) into the first term in (2), setting l=1, then taking the derivative of the phase. The result is a second-order polynomial\n\n\u03c9()=\u03c9() for 0<\u2003\u2003(4)\n\nwhere \u03c9is the fundamental frequency of the target plus a Doppler shift, and B and C are constants associated with the time varying Doppler shift and D is a constant associated the derivative of the error term. Although a constant Doppler shift cannot be estimated by tracking the fundamental frequency of the target without prior knowledge, B and C can be estimated from the spectrum of the data and used to motion compensate the data. In addition, the error term can be estimated from the blurring in the spectrum using autofocus techniques.\n\nMotion Compensation Algorithm\n","Conceptually, the effect of the Doppler shift can be removed by resampling the data using\n\n()=(()),\u2003\u2003(5)\n\nwhere m(t)=\u03ba(t)and \u22121 denotes the inverse. Rather than calculating the inverse of \u03ba(t), an alternative procedure is to warp the time scale of the data so that the function that distorts the signal is removed when the data are resampled to a time scale with uniform increments.\n","According to Wikipedia, Dynamic time warping (DTW) is an algorithm for measuring similarity between two sequences which may vary in time or speed.","If the signal is significantly oversampled in time relative to the Nyquist rate, then signal can be resampled using interpolation algorithms with minimal errors in reconstructing the original signal. For a further discussion, see B. S. Sharif, \u201cA Computationally Efficient Doppler Compensation. System for Underwater Acoustic Communications,\u201d IEEE J. Oceanic Eng., 25 (1), (2000) (hereby incorporated by reference). This procedure can be applied to any higher-order polynomial function describing the distortion. The time scale associated with the discretely sampled data that are modeled using the second-order polynomial shown in (4) can be warped using",{"@attributes":{"id":"p-0059","num":"0058"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"\u03b3","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"mrow":{"mfrac":{"mrow":[{"mi":["n","\u0394"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mrow":{"mi":"t","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":"1","mo":["+","+"],"mfrac":{"mrow":{"mi":["B","n","\u0394","t"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]},"msub":{"mi":"\u03c9","mn":"0"}},"mrow":{"mfrac":{"mi":"C","msub":{"mi":"\u03c9","mn":"0"}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["n","\u0394","t"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]}},"mn":"2"}}}}}},{"mo":["(",")"],"mrow":{"mn":"1","mo":["+","+"],"mrow":[{"mfrac":{"mi":"B","msub":{"mi":"\u03c9","mn":"0"}},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":"N","mo":"-","mn":"1"}},"mo":["\u2062","\u2062","\u2062"],"mi":["\u0394","t"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},{"mfrac":{"mi":"C","msub":{"mi":"\u03c9","mn":"0"}},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":"N","mo":"-","mn":"1"}},"mo":["\u2062","\u2062","\u2062"],"mi":["\u0394","t"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mn":"2"}}]}}]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":["for","n"]},"mo":"=","mn":"0"}],"mo":"="},{"mi":"N","mo":"-","mn":"1"}],"mo":[",","\u2062",",",","],"mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}},{"mrow":{"mo":["(",")"],"mn":"6"}}]}}}},"br":{}},"To motion compensate the data over longer time periods, several consecutive estimates of the time-warping function shown in (6) can be combined. The index associated with each warping function is determined by finding the smallest integer i=\u250ct\/T\u2510 that is not less than t\/T where T is the processing interval time. For post-processing algorithms that require a coherent signal, the time-warping functions need to be generated relative to a common reference frequency and have a consistent time offset between consecutive processing intervals. The reference frequency for data starting at the iprocessing interval is denoted by \u03c9. The time offset between processing intervals can be represented as a phase offset multiplied by the reference frequency. The starting phase offset at the i+1 processing interval can be determined by evaluating (3) at T=N\u0394t. The resulting phase offset for the i+1 processing interval (where \u03a8is the accumulated phase) is\n\n\u03a8=\u03c9.\u2003\u2003(7)\n\nwhere Band Care constants associated with the iprocessing interval. Now, the algorithm can process data collected over a longer time period by concatenating together the results from several shorter processing interval times. The time scale of the data can be warped using\n",{"@attributes":{"id":"p-0061","num":"0060"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"G","mrow":{"mi":["i","M","N"],"mo":[",",","]}},"mo":"\u2061","mrow":{"mo":["(","\u00b7",")"]}},{"mo":"(","mrow":{"mrow":[{"msub":{"mi":"g","mrow":{"mi":["i","i","N"],"mo":[",",","]}},"mo":"\u2061","mrow":{"mo":["(","\u00b7",")"]}},{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mi":"g","mrow":{"mi":["i","N"],"mo":[",",","],"mrow":{"mi":"i","mo":"+","mn":"1"}}},"mo":"\u2061","mrow":{"mo":["(","\u00b7",")"]}}},{"mo":"\uf603","mrow":{"mrow":{"msub":{"mi":"g","mrow":{"mi":["i","N"],"mo":[",",","],"mrow":{"mi":["i","I"],"mo":["+","-"],"mn":"1"}}},"mo":"\u2061","mrow":{"mo":["(","\u00b7",")"]}},"mo":[",","\u2062"],"mstyle":{"mtext":{}},"mi":"where"}}],"mo":["\u2062","\u2062","\u2062"],"mi":"\u2026"}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"8"}}]},{"mtd":[{"mrow":{"mrow":[{"mrow":[{"msub":{"mi":"g","mrow":{"mi":["i","j","N"],"mo":[",",","]}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":["n","\u0394"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mrow":{"mi":"t","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":{"msub":[{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"j"}},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]},"mo":["+","+"],"mrow":[{"mfrac":{"msub":[{"mi":["B","j"]},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]},"mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mi":["n","\u0394","t"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]},{"mfrac":{"msub":[{"mi":["C","j"]},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["n","\u0394","t"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]}},"mn":"2"}}]}}}},"mo":"+","mfrac":{"msub":[{"mi":"\u0393","mrow":{"mi":["i","j"],"mo":","}},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]}}},"mo":"\/","msub":{"mi":"K","mn":"2"}}],"mo":"="},{"mrow":[{"mrow":{"mi":["for","n"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},"mo":"=","mn":"0"},{"mi":"N","mo":"-","mn":"1"}],"mo":[",","\u2062",",",","],"mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"9"}}]}]}}}},{"@attributes":{"id":"p-0062","num":"0061"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":"\u0393","mrow":{"mi":["i","j"],"mo":","}},"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":[{"mi":["k","i"],"mo":"="},{"mi":"k","mo":"=","mrow":{"mi":"j","mo":"-","mn":"1"}}]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["\u03a8","k"]}}},"mo":","}}},"br":{},"sub":"i,j ","sup":["th ","th "]},{"@attributes":{"id":"p-0063","num":"0062"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":"K","mn":"2"},"mo":"=","mfrac":{"mrow":[{"mo":["(",")"],"mrow":{"mfrac":{"msub":[{"mi":"\u0393","mrow":{"mi":["i","M"],"mo":","}},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]},"mo":"+","mrow":{"mrow":[{"mo":["(",")"],"mrow":{"mi":"N","mo":"-","mn":"1"}},{"mi":"t","mo":"\u2061","mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"mfrac":{"msub":[{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mrow":{"mi":["i","M"],"mo":["+","-"],"mn":"1"}}},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]},"mo":["+","+"],"mrow":{"mfrac":{"msub":[{"mi":"B","mrow":{"mi":["i","M"],"mo":["+","-"],"mn":"1"}},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mrow":{"mo":["(",")"],"mrow":{"mi":"N","mo":"-","mn":"1"}},"mi":["\u0394","t"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}},{"mtd":{"mrow":{"mfrac":{"msub":[{"mi":"C","mrow":{"mi":["i","M"],"mo":["+","-"],"mn":"1"}},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mo":["(",")"],"mrow":{"mi":"N","mo":"-","mn":"1"}},"mo":["\u2062","\u2062","\u2062"],"mi":["\u0394","t"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mn":"2"}}}}]}}}],"mo":["\u2062","\u2062","\u2062"],"mi":"\u0394","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"MN","mo":"-","mn":"1"}},"mo":["\u2062","\u2062","\u2062"],"mi":["\u0394","t"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}]}},"mo":","}}},"br":[{},{}],"sub":"i,M,N "},"The phase gradient autofocus (PGA) algorithm was modified to further focus the spectrum of the target. The PGA algorithm assumes that the processed signal from a single scattering center in a range bin in a stripmap SAR image can be described by\n\n()=for 0<\u2003\u2003(10)\n\nwhere Ais the amplitude of the pscattering center, \u03c9is the frequency, \u03c6is an arbitrary phase offset, and \u03b8(t) is an unknown phase error. This signal is demodulated to baseband and isolated using a window function to obtain\n\n()=()\u2003\u2003(11)\n\nwhere  represents convolution and W(t) is a window function. The derivative of the phase error for this signal can be estimated using\n",{"@attributes":{"id":"p-0065","num":"0064"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mover":{"mi":"\u03b8","mo":"."},"mi":"e"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"munderover":{"mo":"\u2211","mi":"P","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mfrac":{"mrow":{"mrow":[{"mi":"Im","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mover":{"mi":"q","mo":"."},"mi":"w"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["p","t"],"mo":","}}}}},{"msubsup":{"mi":["q","w"],"mo":"*"},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["p","t"],"mo":","}}}],"mo":"\u2062"},"msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mi":["q","w"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["p","t"],"mo":","}}}},"mn":"2"}}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"12"}}]}}}}},"For improved performance, the procedure can be applied iteratively to the image. The model for the acoustic signal generated by the main rotor blades after motion compensation is\n\n\u2032()=\u2003\u2003(13)\n\nwhere\n\n\u03b8\u2032()=\u03b8(\u03ba()),\n\n\u03c9is caused by an unknown Doppler shift and interpolation effects, The error term is warped by the motion compensation algorithm, but its effect on the autofocus algorithm is not important since its modifying an unknown error. This signal is demodulated to baseband for each harmonic then transformed into the Fourier domain and the phase error is isolated using a window function.\n\n()=()\u2003\u2003(14)\n","The window function selected for different harmonics is a rectangular window for frequencies between \u00b1Fwhere\n\n(1+log())\u2003\u2003(15)\n\nand Fis the frequency span for the fundamental frequency. Ideally, the window function would increase linearly with frequency for harmonics with equal signal-to-clutter ratios, however, this can result in more than one harmonic being contained in a single window. To prevent this, a logarithmic window was selected.\n","If the phase errors obtained in Equation (15) are divided by the harmonic number, then the standard phase gradient autofocus (PGA) algorithm can applied to the acoustic data as shown below:",{"@attributes":{"id":"p-0069","num":"0068"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msubsup":{"mover":{"mi":"\u03b8","mo":"."},"mi":["e","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"munderover":{"mo":"\u2211","mi":"L","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mfrac":{"mrow":[{"mi":"Im","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":[{"mo":["(",")"],"mrow":{"msubsup":{"mover":{"mi":"q","mo":"."},"mi":["w","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["l","t"],"mo":","}}}},{"msubsup":{"mi":["q","w"],"msup":{"mi":"\u2032","mo":"*"}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["l","t"],"mo":","}}}]},{"mi":"l","mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msubsup":{"mi":["q","w","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["l","t"],"mo":","}}}},"mn":"2"}}]}}],"mo":"="}},{"mrow":{"mo":["(",")"],"mn":"16"}}]}}}},"br":{}},{"@attributes":{"id":"p-0070","num":"0069"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":{"msup":{"mi":["\u03b3","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},"mo":"=","mfrac":{"mrow":[{"mrow":[{"mi":["n","\u0394","t"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]},{"mrow":{"msubsup":{"mi":["\u03b8","e","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},"mo":"\/","msub":{"mi":"\u03c9","mrow":{"mn":["0","1"],"mo":","}}}],"mo":"+"},{"mn":"1","mo":"+","mrow":{"mrow":[{"msubsup":{"mi":["\u03b8","e","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"NM","mo":"-","mn":"1"}}},{"mo":["(",")"],"mrow":{"msub":{"mi":"\u03c9","mrow":{"mn":["0","1"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"NM","mo":"-","mn":"1"}}}}],"mo":"\/"}}]}},{"mrow":[{"mrow":{"mi":["for","n"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},"mo":"=","mn":"0"},{"mi":"MN","mo":"-","mn":"1"}],"mo":[",","\u2062",",",","],"mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"17"}}]}}}},"br":[{},{}]},"The algorithm was tested using acoustic data that were collected as a rotorcraft flew around a microphone that was 1 m above the ground in the grid and in circular patterns, as shown in , which is an illustration of a 2-D flight path of a rotocraft. The approximate height of the rotorcraft during the grid pattern part of the flight was 800 m, and the height during the circular pattern started at approximately 900 m and ended at 250 m after approximately five loops. The data were collected in the afternoon and the outside temperature was approximately 33\u00b0 C. The position of the rotorcraft was recorded and time-stamped using a global positioning system (GPS)\/inertial navigation system (INS) receiver at a rate of 1 Hz. The acoustic data were sampled at rate of 1.0016 KHz with a 24-bit ADC. The fundamental frequency associated with the main rotor blades was approximately 11 Hz.","Frequency Tracking Algorithm","Tracking the harmonics of a rotorcraft can be a challenging problem. At low frequencies, noise from the wind can be large, and at high frequencies, attenuation from the atmosphere can be large. See in this regard, F Skode, \u201cWindscreening of Outdoor Microphones,\u201d Bruel and Kjaer Tech. Rev. 1, (1966). Also, there are multiple harmonic and non-harmonic signals present in the signature of rotorcrafts, which are related to the fundamental frequency generated by the main rotor blades. These factors affect the tracking algorithm results.","The fundamental frequency of the rotorcraft can be estimated using techniques based upon autocorrelation. For targets that have a harmonic structure and a constant Doppler shift, the location of the peak in the autocorrelation result is inversely proportional to the fundamental frequency of the target. For further discussion, see D. Gerhard, \u201cPitch Extraction and Fundamental Frequency: History and Current Techniques,\u201d in Technical report TR-CS 2003-06, (Dept. of Computer Science, University of Regina), (2003), hereby incorporated by reference. Variations in the frequency as a function of time will cause the location of the peak in the autocorrelation result to translate and smear. Its location can be determined by performing a Fourier transform on\n\n|()| for 0<\u2003\u2003(18)\n\nwhere F denotes the Fourier transform and |\u2022| denotes absolute value, and then finding the frequency associated with its maximum amplitude. The frequency estimated from a Fourier transform of the data is inversely proportional to period estimated using autocorrelation. For BT<<1 and CT<<1, the location of the peak in the discrete Fourier transform (DFT) is proportional to the average instantaneous frequency given by \u03c9+BT+T.This result is used by the frequency tracking algorithm.\n","The frequency of the target was tracked using a third-order, fixed-lag smoother with a lag of one sample and a white-noise jerk model. A further information in this regard may be found in A B. D. O Anderson and J. B. Moore, Optimal Filtering, (Prentice-Hall, Englewood Cliffs, N.J., 1979), Chap 7 and R. Li and V. P. Jilkov, \u201cSurvey of maneuvering target tracking. Part I: Dynamic Models\u201d IEEE Trans on AES, 39, 1333-1364, (2003), both of which are hereby incorporated by reference. The continuous-time model characterizing the fundamental frequency is given by",{"@attributes":{"id":"p-0075","num":"0074"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":{"mrow":[{"mover":{"mover":{"mi":"x","mo":"\u2192"},"mo":"."},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mrow":[{"mi":"A","mo":"\u2062","mrow":{"mover":{"mi":"x","mo":"\u2192"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}},{"mi":"B","mo":"\u2062","mrow":{"mover":{"mi":"u","mo":"\u2192"},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}}],"mo":"+"}],"mo":"="},"mo":[",","\u2062"],"mstyle":{"mtext":{}},"mi":"where"},{"mi":"A","mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"}]}]}}},{"mi":"B","mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mn":"0"}},{"mtd":{"mn":"0"}},{"mtd":{"mn":"1"}}]}}},{"mover":{"mi":"x","mo":"\u2192"},"mo":"=","mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":"x","mn":"1"}}},{"mtd":{"msub":{"mi":"x","mn":"2"}}},{"mtd":{"msub":{"mi":"x","mn":"3"}}}]}}}],"mo":["\u2062","\u2062",",","\u2062",",","\u2062",","],"mstyle":[{"mtext":{}},{"mtext":{}},{"mtext":{}}]}},{"mrow":{"mo":["(",")"],"mn":"19"}}]}}}},"br":{},"sub":["0","1","2","3"]},"Measurements of the average instantaneous frequency of the target are described by\n\n()=()+noise,\u2003\u2003(20)\n\nwhere H=[1 T\/2 T\/6], T is the processing interval time, and the noise is assumed to be independent and Gaussian-distributed.\n","The average instantaneous frequency of the target is estimated using a weighted autocorrelation of the data. First, a fast Fourier transform (FFT) is performed on data collected over a processing interval time of approximately 2.05 s. Then, the spectrum is truncated between 9 and 120 Hz and a weighting based upon a non-causal Wiener filter is applied. For a discrete signal, the weights can be approximated using",{"@attributes":{"id":"p-0078","num":"0077"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"msubsup":{"mi":["Y","i","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}},{"mfrac":[{"msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mi":["S","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},"mn":"2"},"mrow":{"msup":[{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mi":["S","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},"mn":"2"},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},"mn":"2"}],"mo":"+"}},{"mrow":{"msup":[{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mi":["Y","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},"mn":"2"},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},"mn":"2"}],"mo":"-"},"msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mi":["Y","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},"mn":"2"}}],"mo":"\u2248"}],"mo":"="},{"mrow":[{"mrow":{"mi":"for","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mi":["Y","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},"mn":"2"}},"mo":">","msup":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":"N","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},"mn":"2"}},{"mi":"k","mo":"=","mn":"0"},{"mrow":{"mrow":{"mn":"1","mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":["\u2026","N"]},"mo":"-","mn":"1"},"mo":";"}],"mo":[",","\u2062",","],"mstyle":{"mtext":{}}},{"mrow":{"mrow":{"mi":"otherwise","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"msubsup":{"mi":["Y","i","\u2032"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"k"}}},"mo":"=","mn":"0"},"mo":","}],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mtext":{}},{"mtext":{}}]}},{"mrow":{"mo":["(",")"],"mn":"21"}}]}}}},"br":{},"sub":["i","i"],"sup":["th ","th ","th "]},"An outlier rejection capability was added to the frequency tracking algorithm. If the measured frequency was larger than four standard deviations away from the value predicted by the target model, then the location of the largest peak in the spectrum was used to estimate the frequency. This measurement was divided by all possible harmonic numbers, and then the value that was consistent with the predicted frequency was selected. If no values were consistent, then the state variables were updated based upon model predictions without any input from the measurement data. If the frequency of the largest peak were stable, then it could be used directly as input to the tracking algorithm.","An analysis of the motion-compensation algorithm was performed by comparing the peak levels in the measured and simulated spectrums of the rotorcraft processed with and without motion-compensated data for several processing interval durations. The algorithm was implemented using estimates from the frequency tracking algorithm to warp the time scale using (8), then the data were resampled using spline-based interpolation. Linear interpolation was also tested, but the performance was lower and results were not reported. Since the sample rate of 1002 Hz is much larger than the average value of the highest frequency of interest, 77 Hz (7\u00d711), interpolation should have a minimal impact on signal reconstruction errors. Again, in this regard, see. S. Sharif, \u201cA Computationally Efficient Doppler Compensation. System for Underwater Acoustic Communications,\u201d IEEE J. Oceanic Eng., 25 (1), (2000). Next, the spectra of the data were computed and the peaks of the harmonics were estimated. First, the average instantaneous fundamental frequency for both the motion-compensated and uncompensated data were initially estimated using the same frequency tracking algorithm described in section 5. These two estimates needed to be consistent to within \u00b10.5% to be included in the analysis. Greater than 99% of the results were consistent. At higher frequencies, the spacing between harmonics slightly deviated from a constant. To compensate for this effect, the peak values of the harmonics were determined by searching within \u00b11% of the values centered on estimates calculated using the average instantaneous fundamental frequency. To reduce the effect of scalloping errors, the spectrums were computed using an FFT with data arrays that were padded by a factor of six.","Results\u2014Frequency Tracking Results","The first step in the processing is to estimate the state variables associated with the fundamental frequency of the main rotor blades. They were calculated using the frequency tracking algorithm described in section 5.0, using approximately 913 s of data. These results were compared to estimates calculated using the GPS position and velocity data collected on the rotorcraft. For a target with constant velocity, the Doppler frequency shift is",{"@attributes":{"id":"p-0082","num":"0081"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":{"msub":{"mi":["f","d"]},"mo":"=","mfrac":{"mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mover":{"mi":"v","mo":"\u2192"}},{"mo":["(",")"],"mi":"\u03b8"}],"mo":["\u2062","\u2062","\u2062"],"mi":"cos","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mi":"\u03bb"}},"mo":[",","\u2062"],"mstyle":{"mtext":{}},"mi":"where"},{"mrow":{"mrow":{"mi":"cos","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mo":["(",")"],"mi":"\u03b8"}},"mo":"=","mfrac":{"mrow":[{"mover":[{"mi":"r","mo":"\u2192"},{"mi":"v","mo":"\u2192"}],"mo":"\u00b7"},{"mrow":[{"mo":["\uf603","\uf604"],"mover":{"mi":"r","mo":"\u2192"}},{"mo":["\uf603","\uf604"],"mover":{"mi":"v","mo":"\u2192"}}],"mo":"\u2062"}]}},"mo":","}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"22"}}]}}}},"br":{}},"A portion of the frequency tracking results are shown in , where the text \u201cmeas\u201d in the legend corresponds to the line associated with the measured frequency input to the smoother, \u201csmooth\u201d corresponds to the frequency estimated from the fixed-lag smoother then processed using the model described equation (19), and \u201cGPS\u201d corresponds to the Doppler frequency estimated using equation (22). The GPS results have been compensated for acoustic propagation delay. In  the fundamental frequency of the helicopter was estimated, filtered, then smoothed at 2-second intervals. The results are shown where \u2018x\u2019 denotes the measured fundamental frequency, and \u2018smooth\u2019 denotes the fundamental frequency estimated using an RTS smoother.","The smoothed estimates of the average instantaneous frequency shown in  usually tracked the Doppler frequency estimates obtained using the GPS data; however, there are some visual discrepancies. The discontinuities suggest that the GPS estimated frequency is often less accurate than the frequency estimated using the acoustic data. This is probably caused by the GPS receiver losing and reestablishing satellite lock during the flight. The acoustic frequency measurements also had visual outliers near the peaks and troughs of the graph in , but with smaller deviations than the GPS estimates.","A simple statistical analysis was performed on the smoothed frequency tracking results. The minimum, average, and maximum of the estimated average instantaneous frequency are 9.6, 10.9 and 12.5 Hz, respectively, and the root mean square value of its derivative is 0.039 s.","Results\u2014Focusing Algorithm","The focusing algorithm was tested on the data collected for a rotorcraft flying the path shown in . The algorithm was run on six processing interval durations ranging from 2.05-12.3 s in 2.05-s increments. The data corresponding to each processing interval duration were selected by moving the time intervals forward 2.05 s, or equivalently, 2048-point increments. For data processed using a 2.05-s processing interval duration, a total of 448 spectrums were computed and there is no data overlap. For data processed using k times larger processing interval durations, k fewer spectrums were computed and there is data overlap.","The phase gradient autofocus (PGA) algorithm was implemented using two sets of parameters. First, it was run using data from harmonics 3, 4, 6, and 7 with a frequency span for the PGA window, F, of 10 percent of the estimated fundamental frequency. The 1st harmonic was not used since wind noise and other engine noise were larger and the 5th harmonic was not used since it was difficult to isolate from the harmonic from the tail rotor.","The phase gradient autofocus (PGA) algorithm was also implemented using data from only the 3harmonic with a window size based upon 20 percent of the estimated fundamental frequency. The 3harmonic was selected because it had a good SNR and it was near the middle of the frequencies being evaluated. The results for the other harmonics should not be biased by noise and interference near the 3harmonic being potentially transformed into signal.","Several methods were used to evaluate the algorithms. First, an example of the results for a single spectrum is analyzed.  shows spectra of the rotorcraft calculated without motion compensation, with motion compensation, and with motion compensation and autofocus using 5 harmonic for approximately 8.2 s of data. They are denoted in the legend as \u201craw\u201d, \u201cmc\u201d, and :pga\u201d, respectively. The data were motion compensated using the frequency tracking results for four consecutive processing interval times of 2.05 s. The spectrum calculated using the motion-compensated data is more focused and has higher peaks than the uncompensated spectrum and the spectrum calculated with the PGA compensated data is more focused than the spectrums calculated using the motion compensated data. Several harmonics from the main rotor blade are labeled by their number in . Data near the 5harmonic and a harmonic from tail rotor blade are displayed in greater detail in . The peaks at frequencies of approximately 53 and 54 Hz are resolvable in the motion-compensated and PGA focused spectrums, but are blurred in the \u201craw\u201d data.","A quantitative analysis of the motion-compensation algorithm was performed using measured data and compared to upper bounds generated using simulated data and predictions based upon coherent processing gain. First, the spectra of the measured data were processed without motion compensation, with motion compensated data, and with PGA compensated data and their amplitudes were compared for each processing interval duration and harmonic number.  show the percent of the peaks in the spectra calculated using measured data processed with the motion compensation algorithm and phase gradient autofocus (PGA) algorithm that were higher in amplitude than the peaks in the spectra processed using data processed without motion compensation for different processing interval durations and harmonic numbers. In , the phase gradient autofocus (PGA) algorithm is based upon harmonics 2, 3, 4, 5, and 7, the Fin (14) is 10 percent of the estimated fundamental frequency. To improve the readability of the plots, only the results for harmonic numbers 1, 3, 5, and 7 are shown. The results for the other harmonics were similar.","As expected, the results improved as the processing interval duration was increased. For a 2.05-s processing interval duration, the percent improvement for the motion-compensated data was only slightly greater than 50%. As the processing interval duration was increased from 2.05 to 12.3 s, the percent improvement increased. For the fundamental frequency, the results increased from 55% to 93%. For processing intervals greater than or equal to 4.1 s, the results for both phase gradient autofocus (PGA) algorithms always improved results. As expected, the results for the PGA algorithm based only on the 3harmonic were best for the third harmonic. The results for the other harmonics in  also improved, which is validation that the model to describe the signal is reasonable. Overall, the difference between the percent improvement of the two realizations of the PGA algorithms is small.","These results indicate that for shorter duration processing intervals, the algorithm did not significantly affect the peaks in the spectra of the rotorcraft. Unfortunately, even for some higher frequencies and longer processing interval durations, the algorithm did not always increase the peak levels in the spectrum.","There are several target and environment factors not included in the signal model that could reduce the performance of the algorithm. Target maneuvers could slightly slow down the blade rotation rate and change the fundamental frequency of the rotorcraft. Also, turbulence in the atmosphere caused by nature and downwash from the rotorcraft will affect the frequency, amplitude, and coherency of the signal. See, in this regard, S. L. Collier and a D. K. Wilson, \u201cPerformance bounds for passive sensor arrays operating in a turbulent medium: Plane-wave analysis,\u201d J. Acoust. Soc. Am. 113, 2704-2718, (2003, hereby incorporated by reference. These effects are difficult to isolate and quantify, but it is expected that they will have an impact on the results. If these effects are large during a processing interval, the results from the algorithm are questionable and should be discarded. One method to determine whether to use the results from the algorithm is to calculate the spectra for data that are motion compensated and for data that are not, and then select the method that has the highest peaks.","For the remaining analysis, any spectra calculated using motion-compensation data that did not increase the peak levels in the 3harmonic were not included. The 3harmonic was selected because it had the highest average signal-to-noise ratio and the peak levels are reasonably sensitivity to target motion. In reality, the difference between good and bad data is not a binary decision, so the performance of the algorithm would still be affected by environmental and target factors, even when the algorithm is evaluated using only \u201cgood\u201d data.","The amount the algorithm increased the peak levels for the \u201cgood\u201d data was analyzed and compared to predicted results. To more equally weight the results calculated at different times, an analysis was performed in dB. The ratio of the peak levels of the harmonics processed with motion-compensated data to the peak levels of the harmonics processed using data that were not motion compensation was averaged in dB for each processing interval duration and harmonic number using",{"@attributes":{"id":"p-0096","num":"0095"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":"r","mrow":{"mi":["k","j"],"mo":","}},"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":["i","\u025b"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"msub":{"mi":["I","j"]}},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mn":"20","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mrow":[{"msub":{"mi":"log","mn":"10"},"mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":"p","mrow":{"mi":["k","i","j"],"mo":[",",","]}},{"mi":"q","mrow":{"mi":["k","i","j"],"mo":[",",","]}}]}}},{"mo":["\uf603","\uf604"],"msub":{"mi":["I","j"]}}],"mo":"\/"}}}},"mo":","}},{"mrow":{"mo":["(",")"],"mn":"23"}}]}}}},"br":{},"sub":["k,i,j ","k,i,j, ","j ","j"],"sup":["th ","th ","th ","th "]},"Simulated data were generated using the output of the frequency tracking algorithm and the models described in (1)-(3) and (8):",{"@attributes":{"id":"p-0098","num":"0097"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mi":"\u03be","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"munderover":{"mo":"\u2211","mrow":{"mi":"l","mo":"=","mn":"1"},"mi":"L"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mi":"\u2147","mrow":{"mo":["(",")"],"mrow":{"mi":["j","l"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"msub":{"mi":"\u03c9","mrow":{"mn":["0","1"],"mo":","}},"mrow":{"msub":{"mi":"G","mrow":{"mi":["l","P"],"mo":","}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}}}}],"mo":"="},{"mrow":[{"mrow":{"mi":["for","n"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}},"mo":"=","mn":"0"},{"mi":"NP","mo":"-","mn":"1."}],"mo":[",","\u2062",","],"mi":"\u2026","mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mo":["(",")"],"mn":"24"}}]}}}},"br":{},"sub":["0,1 ","0,i"]},"The results for motion compensated data, phase gradient autofocus (PGA) algorithm compensated data processed using only the 3harmonic and their UB are shown in  for four harmonics. The results for the phase gradient autofocus (PGA) algorithm calculated using six harmonics was only marginally better and are not shown.","As expected, the results indicate that for short processing interval durations and low harmonic numbers, motion compensation and phase gradient autofocus (PGA) algorithm had a minimal impact on the peaks levels in the spectrums. As the harmonic number and processing interval duration increased, the average improvement became larger, but the loss in performance relative to the predicted UB also increased. The results for the first harmonic almost achieved the predicted UB. For lower processing interval durations, the results for motion compensated and PGA compensated spectrum for the 3harmonic occasionally surpassed the predicted UB and do not represent a valid measure of performance. This result for the motion compensated data is probably caused by the noise randomly changing the peak levels in the spectrum. When the noise resulted in a favorable outcome, the data associated with the 3harmonic were included in the analysis and discarded when it did not. This resulted in a small positive bias. The result for the phase gradient autofocus (PGA) algorithm compensated data for the 3harmonic is probably higher than the UB due to small levels of noise and interference being adjusted so that they coherently added to the signal. As expected, these biases are not present in the results for the other harmonics.","The results from  indicate that the increase in the peak levels due to motion compensation and the PGA-based compensation almost achieved the predicted UB for the fundamental frequency and the predicted coherent processing gain. The difference between the measured average improvement for the motion compensated data and the UB for the processing interval duration of 12.2 s shown in  is 0.55 dB and slightly better for the PGA compensated data. Motion compensation and PGA-based compensation increased the peak levels in the spectrum more for the higher harmonics, but the differences between these results and the predicted results also increased. The discrepancies are probably due to both target and environmental effects, which defocus the spectrum. Small fluctuations in the rotation rate of the main blades will cause errors in the fundamental frequency estimate, which will reduce performance, particularly for higher frequency harmonics. Also, turbulence in the atmosphere will reduce the coherence of higher frequency signals more than lower frequency signals. For more of a description of turbulent effects, see S. L. Collier and D. K. Wilson, \u201cPerformance bounds for passive sensor arrays operating in a turbulent medium: Plane-wave analysis,\u201d J. Acoust. Soc. Am. 113, 2704-2718, (2003).","The discrepancies between the measured and the predicted results were difficult to associate with particular phenomena, but are probably due to fluctuations in the fundamental frequency and amplitude of the signal emitted by the target, errors in the fundamental frequency tracking algorithm, multipath effects, and temporal and spatially varying turbulence. For many scenarios, preprocessing the data using a motion compensating algorithm will focus the signature of the target and allow for longer coherent processing times. This may improve the performance of classification, tracking, and cancellation algorithms",{"@attributes":{"id":"p-0103","num":"0102"},"figref":"FIG. 5","b":["11","12","13","14"]},"The first step (box ) in the signal processing algorithm is to track the fundamental frequency of the helicopter, which is initially estimated by autocorrelating the spectrum of the helicopter. The location of the peak corresponds to the estimated fundamental frequency. These estimates are input to a third-order Kalman filter. To further improve the estimates of the fundamental frequency, the output from the Kalman filter may be processed using a Rauch-Tung-Striebel (RTS) smoother.","In summary, the spectrum of a rotorcraft was focused using the estimated Doppler shift and an autofocus algorithm. Under good conditions, full coherent processing gain was almost achieved for the fundamental frequency. Peak levels in the higher frequency harmonics improved more than the fundamental frequency, but less than the predicted upper bounds. The discrepancies between the measured and predicted upper bounds are difficult to associate with a particular Phenomenology, but may be due to: (a) fluctuations in the fundamental frequency of the target, (b) fluctuations in the amplitude of the harmonics, (c) atmospheric dispersion, (d) multipath effects, terrain and target. The algorithm can be used as a preprocessor to improve the performance of classification and nulling algorithms.","The above lends open the possibility of the fusion of multiple sensors such as coherent fusion of multiple sensors, as for example: acoustics and radar.","Evaluation criteria included the following. The ratio of the peak levels of the harmonics processed with motion-compensated data and PGA compensated data to the peak levels of the harmonics processed using data that were not motion compensation.",{"@attributes":{"id":"p-0108","num":"0107"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":"r","mrow":{"mi":["k","j"],"mo":","}},"mo":"=","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":["i","\u025b"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"msub":{"mi":["I","j"]}},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mn":"20","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mrow":[{"msub":{"mi":"log","mn":"10"},"mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":"p","mrow":{"mi":["k","i","j"],"mo":[",",","]}},{"mi":"q","mrow":{"mi":["k","i","j"],"mo":[",",","]}}]}}},{"mo":["\uf603","\uf604"],"msub":{"mi":["I","j"]}}],"mo":"\/"}}}}}},"br":{}},"The simulated results are shown in  using simulated data by warping time in the target model",{"@attributes":{"id":"p-0110","num":"0109"},"maths":[{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"h","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"mi":"real","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mo":["(",")"],"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"l","mo":"=","mn":"1"},"mi":"L"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msup":{"mi":"\u2147","mrow":{"mi":"j","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":"lvg","mrow":{"mi":["i","j","N"],"mo":[",",","]}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}}}}}}}],"mo":"="}}},{"@attributes":{"id":"MATH-US-00015-2","num":"00015.2"},"math":{"@attributes":{"overflow":"scroll"},"mi":"where"}},{"@attributes":{"id":"MATH-US-00015-3","num":"00015.3"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":"g","mrow":{"mi":["i","j","N"],"mo":[",",","]}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"n"}},{"mrow":{"mo":["(",")"],"mrow":{"mrow":{"mi":["n","\u0394"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mrow":{"mi":"t","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":{"msub":[{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"j"}},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]},"mo":["+","+"],"mrow":[{"mfrac":{"msub":[{"mi":["B","j"]},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]},"mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mi":["n","\u0394","t"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]},{"mfrac":{"msub":[{"mi":["C","j"]},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]},"mo":"\u2062","msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["n","\u0394","t"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}]}},"mn":"2"}}]}}}},"mo":"+","mfrac":{"msub":[{"mi":"\u0393","mrow":{"mi":["i","j"],"mo":","}},{"mi":"\u03c9","mrow":{"mn":"0","mo":",","mi":"i"}}]}}},"mo":"\/","msub":{"mi":"K","mn":"2"}}],"mo":"="}}}],"br":{},"sub":"2 "},"Peak levels in simulated spectrum are calculated using\n\n()=|(())|\n\nand the results are shown in .\n","As used herein, the terminology \u201ctarget\u201d means a person or persons, or portion thereof, animal or animals, thing, object, or a combination thereof.","As used herein the terminology \u201cpoint of interest\u201d or \u201cpoints of interest\u201d refer to an signature or area in the image which appears to be a target but may or may not be a target; i.e., potentially the point of interest may be a target; subject to further processing or testing.","As used herein the terminology \u201cprocessor\u201d includes computer, controller, CPU, microprocessor; multiprocessor, minicomputer, main frame, personal computer, PC, coprocessor, and combinations thereof or any machine similar to a computer or processor which is capable of processing algorithms.","As used herein the terminology the terminology \u201cprocess\u201d means: an algorithm, software, subroutine, computer program, or methodology.","As used herein the terminology \u201ctarget signature\u201d means the characteristic pattern of a target displayed by detection and identification equipment.","As used herein, the terminology \u201calgorithm\u201d or \u201csubroutine\u201d means: sequence of steps using computer software, process, software, computer program, or methodology.","The foregoing description of the specific embodiments are intended to reveal the general nature of the embodiments herein that others can, by applying current knowledge, readily modify and\/or adapt for various applications such specific embodiments without departing from the generic concept, and, therefore, such adaptations and modifications should and are intended to be comprehended within the meaning and range of equivalents of the disclosed embodiments. It is to be understood that the phraseology or terminology employed herein is for the purpose of description and not of limitation. Therefore, while the embodiments herein have been described in terms of preferred embodiments, those skilled in the art will recognize that the embodiments herein can be practiced with modification within the spirit and scope of the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The embodiments herein will be better understood from the following detailed description with reference to the drawings, in which:",{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":["FIG. 2","FIG. 2"]},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4B","sup":"rd "},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 7A"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 7B"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8A"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 8B"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 8C"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 8","i":"d "},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 9A"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9B"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 9C"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0029","num":"0028"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
