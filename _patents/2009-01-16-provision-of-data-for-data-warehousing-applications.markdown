---
title: Provision of data for data warehousing applications
abstract: A computer network architecture for making procurement-related information that has been generated on a transaction level available to data warehousing techniques is described. The network includes a transaction processing layer with at least one accounting component with a general ledger data base for centrally storing information contained in accounted-related data sets, a data warehousing layer and an additional data sourcing layer. A duplicator receives the data sets that will be or have been stored in the general ledger data base and delivers duplicates of those data sets that fulfil a predefined criteria in a procurement context. A source data base stores the duplicated data sets on a data line level. An extractor of the data sourcing layer interfaces with the data warehousing layer and selectively moves data contained in data lines or sets of data lines from the source data base to the data warehousing layer.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08315974&OS=08315974&RS=08315974
owner: SAP AG
number: 08315974
owner_city: Walldorf
owner_country: DE
publication_date: 20090116
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"p":["This application is a division of U.S. application Ser. No. 10\/935,404, filed Sep. 2, 2004, which issued as U.S. Pat. No. 7,480,671 on Jan. 20, 2009, and which claimed priority to European Patent Office (EPO) application No. 03 019 592.9 filed on Sep. 3, 2003.","The invention relates to data warehousing. More specifically, the invention relates to the interaction between one or more transaction-based computer systems and a computer system that is configured to perform data warehousing tasks.","Modern data acquisition and processing techniques have boosted the amount of data that has to be managed and evaluated in business environments. The introduction of faster and increasingly sophisticated hardware accelerates this development. Hence, the provision of complete and consistent information becomes an increasingly complex task.","In larger enterprises, enterprise resource planning (ERP) systems like SAP R\/3 are commonly used to manage business transactions in a standardized manner. Although conventional ERP systems often have to handle millions of business transactions each day, each individual business transaction usually generates only very little amounts of data. Thus, conventional ERP systems are configured as online transaction processing (OLTP) systems. OLTP systems are optimized as regards the well-defined and fast processing of very small amounts of detailed data. OLTP systems are however generally not suited for analytical tasks that involve the ad-hoc analysis of large data amounts, i.e. require online analytical processing (OLAP).","In the past, various concepts have been deployed to tackle such analytical tasks. One of the most promising concepts is OLAP-based data warehousing. Data warehousing solutions focus on gathering information from various information sources and on providing tools for analyzing the gathered data. Taking into account the advantages of data warehousing it is not surprising that this solution has been incorporated in all kinds of computer networks and in particular in computer networks that include ERP functionalities.","It is obvious that the completeness and consistency of the information delivered by data warehousing techniques is strongly dependent on the completeness and consistency of the data provided to the data warehouse by the individual data sources like ERP systems. Problems as regards the completeness of information delivered to data warehousing applications are often encountered in context with electronic procurement (EP) environments.","EP denotes the electronic generation and transfer of procurement-related data sets in a computer network that includes one or more computers on a buyer's side and one or more computers on the side of each supplier. The information generated and transferred in the computer network include data sets relating to purchase orders, goods delivery, invoicing, etc.","In spite of the advantages associated with EP systems as regards the implementation of standardized and controllable purchase mechanisms, it still happens that employees order directly from a supplier via e-mail, telephone or facsimile, skipping the installed and ready-to-operate EP mechanisms. It is clear that any purchase that has not been performed via the EP system will not be included in the data bases of the EP system and can not be considered by data warehousing mechanisms using these EP data bases as information source. Hence, tasks like analyzing the complete spend paid to suppliers (spend analysis), which is the most important basis for strategic sourcing and for contract negotiations, become inaccurate and error-prone.","In has been found that in many cases up to 30% of all purchases are not performed via the EP environment. This means that data warehousing mechanisms can not reliably be applied to analyze procurement transactions, at least if the EP system is used as single source of information.","In an attempt to make data warehousing mechanisms applicable for the analysis of procurement transactions it has been found that information about procurements performed via EP channels as well as procurements performed via other channels is in many cases already available to the data warehousing applications. The reason for this is the fact that procurement-related information is often included as \u201cby-product\u201d in accounting-related data that have been received in the data warehouse from accounting applications of ERP systems. Accounting-related data are generated for each procurement transaction because regardless of the procurement channel invoices and credit memos are generated and corresponding transactional data sets including accounting data will have to be posted by an ERP accounting component. However, since the accounting data comprise the procurement-related data often in an accumulated format, procurement transactions can only be analyzed very coarsely by data warehousing techniques. Moreover, the informational content of the accounting-related data as regards the analysis of procurement transactions and in particular as regards spend analysis is not sufficient.","In order to improve the analysis accuracy, a technical approach as shown in  might be chosen. Conventionally, accounting related data sets are extracted from an OLTP-based accounting component  acting as data source to an OLAP-based data warehousing layer  for data gathering and analysis. The data warehousing layer  may implement a staged data base approach including a data base  for storing the accounting-related data sets that have been extracted from the data source  and a further data base  that is updated by the first data base  and contains the accumulated accounting information comprised in the plurality of extracted data sets.","Based on the not yet accumulated information, i.e. the individual accounting-related data sets included in the data base , a parallel data base branch ,  could be used for storing and analyzing procurement-related information contained in the accounting related data sets included in the data base . The content (data sets) of the data base  could be transferred according to a pre-defined strategy to the data base . The data base  in turn could then update the data base  to accumulate procurement-related information for analysis purposes.","Since the informational content included in the accounting-related data sets as regards procurement analysis is usually not sufficient for a detailed procurement analysis, the accounting-related data sets provided by the data source  could be enriched with procurement-related information prior to being extracted. However, such an approach would have the drawback that large amounts of data will have to be transferred between the data source  and the data warehousing layer , although only 10 to 20% of the information included in the enriched accounting-related data sets will eventually be needed for procurement (e.g. spend) analysis. But not only high network traffic would result, additionally storage and performance problems would occur in view of the fact that very often several millions of accounting-related data sets per day will have to be enriched, extracted and transferred from the data base  to the data base .","There is thus a need for a technical implementation that facilitates data warehousing for procurement-related information. More specifically, there is a need for a technical implementation which makes procurement-related information that has been generated on a transaction level available to data warehousing techniques while keeping the required network and processing resources low.","The computer network architecture of the present invention comprises a transaction processing layer as well as a data warehousing layer for gathering and accumulating information provided by the transaction processing layer. The transaction processing layer includes at least one accounting component with a general ledger data base for centrally storing information contained in accounting-related data sets that are comprised of one or more data lines. A duplicator receives the accounting-related data sets that will be or have been stored in the general ledger data base and delivers duplicates of such accounting-related data sets that fulfill a predefined criteria in a procurement context. A source data base is provided for storing the duplicated data sets on a data line level. An extractor interfacing the data warehouse layer selectively moves data contained in sets of data lines (e.g. in a duplicated data set) or in individual data lines from the source data base to the data warehousing layer.","The combination of an intelligent duplicator and a source data base selectively filled with procurement-related data of a high granularity (data line level) and arranged below the data warehouse layer allows for a reduction of network traffic. In contrast to the possible technical implementation of , only selected data sets need to be extracted, transferred, processed and stored in context with making procurement-related information that has been generated on a transaction level available for data warehousing. Since the additional components provided by the present invention may be arranged in the form of a separate data sourcing layer between the transaction processing layer on the one hand and the data warehousing layer on the other hand the invention can easily be utilized in combination with conventional ERP and data warehousing applications. Particularly, the invention provides an efficient mechanism for selectively transferring information available in a dispersed manner on a transaction level to a data warehousing level.","The computer network architecture of the present invention may additionally comprise an analyzer for analyzing the duplicated data sets delivered by the duplicator and for adding transfer information to the duplicated data sets. The analyzer may for example be arranged between the duplicator and the source data base or between the source data base and the extractor.","The analyzer may add the transfer information in various ways. It may for example append the transfer information in the form of additional data fields to the duplicated data sets or it may write the transfer information in existing data fields of the duplicated data sets. The transfer information may take the form of a flag setting, a receiver address or the like. The transfer information may hence control the further route of a duplicated data set. For example, the transfer information may control at least one of the extraction of data from the source data base and the transfer of extracted data in the warehousing layer. According to one variant of the invention, the transfer information is utilized as a selection criteria for selectively moving data contained in the source data base to the data warehousing layer.","The transfer information may be added in dependence of the relevancy of an individual duplicated data set in regard of a particular analysis task like spend analysis or any other procurement-related analysis that is to be performed by the data warehousing layer. The transfer information may thus be utilized as a further selection criteria besides the predefined criteria applied by the duplicator for selectively delivering duplicates of accounting-related data sets.","The data warehousing layer may have various configurations. It may for example include an information data base for accumulating information contained in the extracted data. In order to assist the OLAP tasks of the data warehousing layer, the information data base may be configured to allow for a multi-dimensional data analysis. To this end, the information data base may comprise at least one fact table and one or more associated dimension tables in a star schema.","Additionally or alternatively, the data warehousing layer may include an operational data base that is used for storing on a data line level information contained in the extracted data. The information stored in the operational data base may have a higher granularity than the information stored in the information data base. The operational data base may be used for updating the information data base. Such an updating may include an accumulation of information onto existing or newly created entries of the information data base.","The operational data base may be filled with data that has been extracted from the source data base and\/or any other data base included in the transaction processing layer (e.g. the general ledger data base) or in the data sourcing layer. Also, the operational data base may be filled with data transferred from one or more additional operational data bases provided in the data warehousing layer. The transfer or extraction of data to the operational data base may be controlled by the transfer information that has previously been added to the duplicated data sets. The transfer information may for example specify the individual data sets contained in a source data base that are to be extracted into the operational data base.","Whereas the transfer information can be utilized as a rather fine selection criteria, the duplicator may apply a selection criteria that is comparatively coarser. This coarser selection criteria could be the presence or setting of a procurement-related identifier (e.g. a specific code or flag) included in the accounting-related data sets received by the duplicator.","The duplicator may have various configurations. According to a first option, the duplicator may include a combination of a duplicating component and a filter. The duplicating component may be configured to duplicate all accounting-related data sets that will be or have been stored in the general ledger data base. In this context the duplicating component need not perform any data analysis tasks and may thus be included in the transaction processing layer without any adverse affects on the efficiency of the online data processing performed there. The duplicated data sets may be output via a dedicated interface of the transaction processing layer. Any required analytical tasks may be performed by the filter that could for example be arranged in the data sourcing layer. The filter may be configured to be selectively transmissive for such duplicated data sets that fulfill the previously defined procurement-related criteria.","According to a further variant of the invention, the duplicator may completely be arranged in the transaction processing layer and may include an analyzing component as well as a duplicating component. The analyzing component may be configured to analyze all accounting-related data sets that will be or have been stored in the general ledger data base with respect to the predefined procurement-related criteria. Depending on the result of the analysis, the duplicating component may selectively duplicate such accounting-related data sets that fulfill the predefined criteria. The selectively duplicated data sets may be output via a dedicated interface of the transaction processing layer.","The duplicated data sets provided by the duplicator may be fed to a formatting component that may for example be included in the transaction processing layer or in the data sourcing layer. The formatting component may be configured to format the duplicated data sets on a data line level. Such a formatting may for example include inheriting to all data lines of an individual duplicated data set a procurement-related identifier included somewhere in this duplicated data set. The inherited procurement-related identifier may for example be constituted by a specific account code, posting key or creditor identifier. The procurement-related selection criteria applied by the duplicator may be identical with the procurement-related identifier inherited by the formatting component or may be different therefrom. The formatting component may be provided in addition to or instead of the previously mentioned analyzer that adds transfer information to the duplicated data sets.","Once the duplicated data sets have been stored in the source data base, they may be retrieved completely or partially by the extractor interfacing the data warehousing layer. The extractor may be configured to additionally perform at least one of formatting and pre-processing tasks with respect to the extracted data. If, for example, the duplicated data sets stored in the source data base include several numerical values in a single data line, the extractor may be configured to re-format an extracted data set by splitting such a data line into two or more individual data lines containing a single numerical value each. Thus, the extractor may increase the number of data lines of an extracted data set compared to the \u201cparent\u201d data set stored in the source data base. Such an approach facilitates the further processing of an extracted data set in the data warehousing layer.","The operational data base may be updated by the extractor in various ways, The extractor may for example apply a so-called delta updating approach according to which during an update only such data sets contained in the source data base are considered which have been stored in the source data base since the last update. To this end a time stamp may be used. Additionally or alternatively, the complete content of the source data base may be considered for an update. Such an approach is especially advantageous during an initialization step for uploading via the source data base historical data included in the general ledger data base to the data warehousing layer.","In addition to the accounting component the transaction processing layer may include at least one of an EP component and a logistics component. In such a case the data delivered from the various components included in the transaction processing layer may be combined. The data combination may be performed in the data sourcing layer, in the data warehousing layer and\/or upon data extraction. According to one variant of the invention, the extractor merges data provided by at least one of the EP component and the logistics component with data extracted from the source data base.","According to a further aspect of the invention, a data sourcing layer interfacing a transaction processing layer and a data warehousing layer that gathers information provided by the transaction processing layer is provided. The data sourcing layer may comprise a filter receiving from the transaction processing layer duplicates of accounting-related data sets that will be or have been stored in a general ledger data base of the transaction layer. The data sourcing layer of the present invention further comprises a source data base for storing on a data line level the duplicated data sets that fulfill a predefined criteria in a procurement context, e.g. include a pre-defined procurement-related identifier. Furthermore, an extractor interfacing the data warehousing layer is provided. The extractor is configured to selectively move data contained in data lines or sets of data lines from the source data base to the data warehousing layer.","According to a still further aspect, the invention relates to a method of making procurement-related and in particular spend-relevant information that has been generated on a transaction level available to data warehousing techniques. The method comprises providing on a transaction processing level accounting-related data sets that will be or have been centrally stored and that are comprised of one or more data lines. The method further comprises generating duplicates of such accounting-related data sets that fulfill a pre-defined criteria in a procurement context, storing the duplicated data sets on a data line level in a source data base, selectively extracting data contained in data lines or sets of data lines (e.g. complete data sets) from the source data base to the data warehousing layer, and gathering and accumulating the extracted data in the data warehousing layer.","Additionally, the method may comprise adding transfer information to the duplicated data sets. The transfer information may control at least one of the extraction of data from the source data base and the transfer of extracted data within the data warehousing layer. Adding transfer information to the duplicated data sets may be performed in dependence of the relevancy of an individual duplicated data set for e.g. a spend analysis that is to be performed using the data warehousing layer.","The present invention may be implemented as software, as one or more pieces of hardware, or as a combination thereof. Hence, the invention also relates to a computer program product with program code portions for performing the individual steps of the invention when the computer program product is run on one or more components of a computer network. The computer program product may be stored on a computer readable recording medium.","Where appropriate, the same reference numbers will be used throughout this detailed description in conjunction with the drawings to refer to the same or like parts.",{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 2","b":["100","101","102","190","100","101","102"]},"Each network component , , , etc. comprises a processor , a memory , a bus , and, optionally, one or more input devices  and output devices  (I\/O devices) acting as user interface , interoperating in a conventionally known manner. The present invention may be embodied in a computer program product (hereinafter CPP) residing on a program carrier  and\/or in the memory , and generating program signals , collectively called a \u201cprogram\u201d.","The network components , , etc. typically may comprise many or all of the elements described with respect to the network component . Hence, the elements  to  in the network component  collectively illustrate also corresponding elements in the other network components , , etc. of the network .","Although the memory  is conveniently illustrated as a part of the network component , a memory function can also be implemented as an independent node in the network , in the other components of the network, in the processor  itself (e.g., cache, register), or elsewhere. Portions of the memory  can be removable or non-removable with respect to a particular network component. The memory  can store software program support modules such as, for example, a basic input output system (BIOS), an operating system (OS), a program library, a compiler, an interpreter, communication programs, drivers, protocol converters, application software programs, (Internet-) Browsers, or data base applications. Although the CPP is illustrated as being stored in memory , the CPP can also be located elsewhere. For example, the CPP can also be embodied on the program carrier .","The CPP comprises program instructions and\u2014optionally\u2014data or variables that cause processor  to execute the steps forming the methodology of the present invention. The method steps are explained in greater detail below. The CPP defines and controls the operation of the network component  and its interaction in the network system . For example, and without the intention to be limiting, the CPP can be available as source code in any programming language, and as object code (\u201cbinary code\u201d) in a compiled presentation. Persons of ordinary skill in the art can use the CPP in connection with any of the above mentioned support modules. The functionalities of one or more of the network components , , , etc. and of the CPP are closely related. Phrases, such as \u201cthe computer provides\u201d or \u201cthe program provides\u201d, are used hereinafter to express actions by one or more network nodes that is\/are controlled by the CPP in accordance with the invention.","The program carrier  is illustrated as being outside the network component . For communicating the CPP to the network component , the program carrier  is conveniently inserted into the input device . The carrier  is implemented as any computer readable medium. Generally, the program carrier  is an article of manufacture comprising a computer readable medium having computer readable program code means embodied therein for executing the method of the present invention. Further, the program signals  can also embody the CPP. The signals  travel on the computer network  to and from the network component . The steps of the computer program product CPP can be executed solely in the network component , in which case the computer network  may be omitted, or can be executed in a distributed manner in one or more of the components of the computer network .","The bus  and the computer network  provide logical and physical connections by conveying instructions and data signals. While connections and communications inside the network component  are conveniently handled by the bus , connections and communications between different network components are handled by the network . Optionally, the network  comprises gateways and routers being computers that are dedicatedly programmed to effect data transmission and protocol conversion. The input\/output devices  and  are coupled to the network component  by the bus  (as illustrated) or by the network  (optional). While the signals inside the network component  can be mostly electrical signals, the signals in the network can be electrical, magnetic, optical or wireless (radio) signals.","The network  can include one or more of an office-wide computer network, an enterprise-wide computer network, an intranet or the Internet (i.e. world wide web). The world wide web (www) represents all of the computers on the Internet that offer users access to information on the Internet via interactive documents or Web pages. Web information resides on Web servers on the Internet or within company or community networks (intranets). Network  can include a wired or a wireless network, such as, for example, a local area network (LAN), a wide area network (WAN), a wireless LAN (WLAN), a public switched telephone network (PSTN), an integrated services digital network (ISDN), an infra-red (IR) or Bluetooth link, a radio link e.g. according to the Universal Mobile Telecommunications System (UMTS), the Global System for Mobile Communication (GSM), a Code Division Multiple Access (CDMA) system, or satellite link.","Transmission protocols, mechanisms and data formats to effect communications between network components which are connected to and by the network  are known, for example, as transmission control protocol\/internet protocol (TCP\/IP), hyper text transfer protocol (HTTP), secure HTTP, wireless application protocol (wap), unique resource locator (URL), unique resource identifier (URI), hyper text markup language HTML, extensible markup language (XML), extensible hyper text markup language (XHTML), wireless application markup language (WML), electronic data interchange (EDI), which is an electronic exchange of business information between or inside organizations and their information technology (IT) infrastructure in a structured format, remote function call (RFC), or via an application programming interface (API), etc.","Interfaces coupled between individual elements and components are also well known in the art. For simplicity, interfaces are not illustrated. An interface can be, for example, a serial port interface, a parallel port interface, a game port, a universal serial bus (USB) interface, an internal or external modem, a video adapter, or a sound card.","The CPP according to the present invention can be part of a complex software system embedded in a hardware structure. The cooperation of the software system and the hardware structure is sometimes referred to as IT backbone system. The backbone system can have a layered structure with individual software components acting in accordance with the client\/server concept as service providers, service requesters, or both. For example an application software can include software components that provide services for presentation, acting as a server. But at the same time the application software also can act as service requester of data base services provided by a lower layer. The layered components can communicate with each other via predefined (hardware and software) interfaces.","As regards a possible implementation of a layered software structure, a lower layer may include network-related functionalities, a physical data base and an operating system for the network components. A middle layer that interfaces with the lower layer integrates software applications in the upper layer above it. This middle layer may include components like software tools, system administration tools, data handling tools, authorization and security management tools, cross-application modules, and a system kernel. The system kernel can use communications and application program interfaces to access components like application software in the upper layer or the operating system, the data base, and the network in the lower layer. This system kernel can operate independently from the applications and is located \u201cunder\u201d the application software and the data layers of the software system. The upper layer contains the different software applications for controlling and monitoring processes relating for example to the management of human resources, sales and distribution, financials, materials, manufacturing, electronic procurement etc.","One possible client\/server configuration in which the present invention can be carried out is a so-called three-tiered network architecture which separates a network system's components into three functional groups: presentation, application, and data base. This is illustrated in  in a hardware-related view. As can be seen from , the three-tiered architecture comprises one or more data base servers , one or more application servers  and one or more presentation servers .","With the three-tiered architecture shown in , each hardware group can be set up to support demands of its functions. The one or more data base servers  include the data sources. Application servers  interfacing the data base servers  include the main processing logic as regards data warehousing. The tasks related to data presentation are handled by presentation servers , which can typically be personal computers or work stations. External presentation servers  may be connected to the application servers  via the Internet and Web servers\/Internet transaction servers. Communication among the three tiers can be accomplished using for example the standard protocol services mentioned above, such as the ones provided by TCT\/IP or CPIC. CPIC stands for Common Programming Interface Communication and includes standard functions and services for program-to-program communication.","The three-tiered network architecture depicted in  is shown in  in a functional, software-related view. As becomes apparent from , the software components utilized in context with the present invention include a data base layer , an application layer  and a presentation layer .","The data base layer  includes an OLTP based transaction processing layer  with several ERP components like an accounting component , a logistics component and an electronic procurement (EP) component . It should be noted that although in context with the data warehousing approach of the present invention the transaction processing layer  serves as data source and is thus included in the data base layer , it may internally also be based on a three-tiered architecture like the one shown in  including associated data bases, applications (accounting, logistics, EP, etc.) and user interfaces for data presentation.","As becomes apparent from , the data base layer  additionally includes a data sourcing layer  that is arranged between the transaction processing layer  and the application layer . The data sourcing layer  constitutes one of the core aspects of the present invention and will be described in more detail below with reference to . The data base layer  including the transaction processing layer  and the data sourcing layer  constitutes the network architecture's bottom layer that in the context of this embodiment mainly performs data sourcing tasks.","The middle layer, i.e. the OLAP based data warehousing layer , basically carries out three tasks: it administers the data warehouse system, stores the data extracted from the data base layer  and provides requested data to the presentation layer . As can be seen from , the data warehousing layer  receives two different data streams. As indicated by arrow , the data warehousing layer  receives a first data stream directly from the individual components , , arranged in the transaction processing layer . Additionally, the data warehousing layer  receives a second data stream indicated by arrow  from the data sourcing layer . The data sourcing layer  in turn receives a data stream indicated by arrow  from the transaction processing layer  and in particular from the accounting component . As can be seen from , the first data stream (arrow ) bypasses the data sourcing layer  for reasons that will be explained in more detail below.","As indicated by arrow , the data warehousing layer  provides data for the top layer, i.e. the presentation layer . The presentation layer  constitutes a reporting environment. In the implementation depicted in  the presentation layer  includes two individual components, namely a browser and an analyzer. The browser works much like an information center, allowing to organize and access all kinds of information. The analyzer can be a conventional data analysis tool like Microsoft Excel or a similar application.","The configuration of the data base layer  of  is shown in more detail in . As becomes apparent from , both the accounting component A included in the transaction processing layer  and the data sourcing layer  comprise a plurality of individual components. The accounting component A includes a general ledger data base  and a part of a duplicator , which spans the transaction processing layer  and the data sourcing layer . The data sourcing layer  includes a further part of the duplicator  and a component  for pre-analyzing and enhancing (e.g. formatting) the data received from the duplicator . Additionally, the data sourcing layer  includes a source data base , also called special ledger (SL) data base, and an extractor . Although the extractor  is schematically shown in  as part of the data sourcing layer , one or more functional entities of the extractor  could also be part of the data warehousing layer .","In the following, the co-operation of the accounting component and the data sourcing layer  as well as the tasks performed by the data sourcing layer  will be considered in more detail.","In the exemplary embodiment described hereinafter, the provision of procurement-related information that may be used for global spend analysis in the data warehousing layer  will exemplarily be described. It should be noted, however, that the individual technical components and technical mechanisms described hereinafter are to a large extent independent from the specific analysis task that is to be performed using the data warehousing layer . More specifically, the invention can generally be employed in data warehousing scenarios for efficiently transferring information available in a dispersed manner on an OLTP level to an OLAP-based data warehousing application.","As becomes apparent from , the accounting component A continuously processes a stream of transaction-based accounting-related data sets. Although accounting-related data sets can be received from outside the accounting component , the stream of accounting-related data sets may also include data sets that have been generated within the accounting component itself. Within the accounting component , the individual data sets are posted and finally stored in the central data base of the accounting component , i.e. in the general ledger data base .","The accounting-related data sets include data sets relating to invoices, credit memos and their cancellations (reverse invoice\/reverse credit memo) coming from the logistics component , the EP component , from the accounting component itself and\/or any other component included in the transactional processing layer . Associated account payable information is directly generated by means of an accounting transaction within the accounting component ","The accounting-related data sets concerning invoices, credit memos and their cancellations are generally procurement-related and available to the accounting component regardless of the individual procurement channel. This means that for example an accounting-related data set for an invoice will be processed within the accounting component regardless of the fact whether the associated procurement involved the EP component or any traditional procurement approach like ordering goods or services via telephone. It should be noted that the accounting-related data sets that will have to be posted and stored by the accounting component also include data sets that are not procurement-related but have to be processed in e.g. a sales accounting or asset accounting context.","Regardless of their relevancy in a procurement context, all accounting-related data sets that will eventually be stored in the general ledger data base  are first received by the duplicator , which is arranged in the data path before the general ledger data base . The duplicator  is configured to additionally or alternatively receive accounting-related data sets that have been retrieved from the general ledger data base , i.e. that have been stored earlier. The duplicating component  duplicates the accounting-related data sets before they are stored in the general ledger data base  or after they have been retrieved from the general ledger data base .","The duplicator  includes two separate functional entities, namely a duplicating component  and a filter . In the embodiment depicted in  the filter  is arranged in the data sourcing layer  whereas the duplicating component  is arranged in a transaction processing layer  and more specifically in the accounting component before the general ledger data base .","In order to avoid any processing delays within the accounting component , the duplicating component  simply generates copies of the received accounting-related data sets without performing any data analysis or data enrichment tasks. The duplicates of the accounting-related data sets received by the duplicator  are output to the data sourcing layer  via a dedicated accounting interface (not shown) of the accounting component . The original accounting-related data sets are simply forwarded by the duplicating component  for being processed further within the accounting component and for being finally stored in the general ledger data base .","It should be noted that the distinction between duplicated data sets and original data sets is somewhat artificially chosen in order to illustrate the mechanism performed by the duplicator . In the actual implementation duplicates and originals can often not be distinguished at the output of the duplicating component . For the sake of clarity, however, the accounting-related data sets transferred from the transaction processing layer  to the data sourcing layer  are referred to as \u201cduplicated\u201d data sets here.","The duplicated accounting-related data sets output via the accounting interface (not shown) in the transaction processing layer  are transferred to the data sourcing layer . More specifically, the duplicated data sets are fed to the filter  of the duplicator . The filter  is selectively transmissive for such duplicated data sets that fulfill a predefined criteria in a procurement context. In the present embodiment, the filter  analyzes the duplicated data sets with respect to account type codes related to creditors that may or may not be included in the duplicated data sets. As will be explained below with reference to , the filter  is configured to output only such duplicated data sets that contain the creditor type code \u201cK\u201d, the creditor type code \u201cK\u201d being in the present embodiment indicative of the duplicated data set's procurement relevancy. The remaining duplicated data sets having no procurement relevancy may be discarded. The combination of duplicating component  and filter  thus selectively outputs only duplicates of such accounting-related data sets that include one or more pre-defined account codes and that are to be handled further within the data sourcing layer .",{"@attributes":{"id":"p-0075","num":"0074"},"figref":["FIG. 5B","FIG. 5B","FIG. 5B","FIG. 5A","FIG. 5B"],"b":["32","32","48","16","48","48","18","48","16","32","16","18"],"i":"a"},"Returning to , the duplicated data sets output by the duplicator  are fed to a component  for data pre-analysis and data enhancement. The individual tasks performed by the component  may be implemented in a customized manner. The component  may thus append, delete and\/or fill data fields belonging to the duplicated data sets in accordance with a user-defined mechanism. To this end the component  is provided with a dedicated user interface.","As regards data analysis tasks, the component  analyzes the duplicated data sets received from the duplicator  with respect to the specific data analysis that is to be performed using the data warehouse. As mentioned above, in the present embodiment the procurement-related, duplicated data sets are analyzed to determine whether or not they are relevant for global spend reporting. Depending on the result of this analysis, the component  selectively adds transfer information in the form of e.g. a flag setting that is characteristic of duplicated data sets that are spend relevant. As will be described in more detail with reference to , only such duplicated data sets are marked spend relevant that include a pre-defined posting key or that have been specifically identified (using e.g. a particular user flag setting that is already included in the duplicated data set as identifier).","As has been mentioned above, transfer information is added to all spend-relevant duplicated data sets. To that end, one or more additional data fields are appended to the spend-relevant data sets and an appropriate flag is written into the one or more appended data fields. The flag setting will later be used as control information for extracting data from the source data base . It should be noted here, however, that the duplicated data sets output by the duplicator  are stored in the source data base  regardless of whether or not (or which) transfer information has been added. In other words, in the present embodiment the transfer information does not specify whether or not a duplicated data set is to be stored in the source data base  but determines whether or not data contained a data set stored in the source data base  is actually extracted to the data warehousing layer . The source data base  thus also includes procurement-related data sets have not been marked as spend relevant.","The component  is not only configured to add transfer information to a duplicated data set but additionally allows to format the duplicated data sets. The individual formatting mechanisms strongly depend on the original format in which duplicated data sets are provided. If the duplicated data sets are provided in the form of one or more individual data lines, the formatting may take place on a data field or on a data line level. Since any further transfer and processing of a duplicated data set may be performed on a data line level, formatting of the duplicated data sets on a data line level already in the data sourcing layer is advantageous as regards evenly distributing the processing tasks among the individual layers of the computer network architecture of the present invention.","The individual data sets output by the component  are stored on a data line level, i.e. with a high granularity, in the source data base . The source data base  is configured as a single item table and exclusively used in context with the particular procurement-related analysis that is to be performed in the data warehousing layer , i.e. spend analysis.","From the source data base  the extractor  extracts individual data sets or data lines into the data warehousing layer  in dependence of the transfer information that has been added to the data sets by the component . This means in the present embodiment that only such data sets or data lines stored in the data source  will be transferred from the data sourcing layer  to the data warehousing layer  that have the appropriate flag setting \u201cspend relevant\u201d. The remaining data sets that have not been marked as relevant for this particular analysis task need not be extracted and can be deleted or archived (if necessary together with the extracted data sets) in regular time intervals.","The extractor  has two different modes of operation. In the first operational mode the extractor  updates the data warehousing layer  according to a so-called delta update mechanism. This means that the extractor  batch-wise extracts only such data sets or data lines from the source data base  which have been stored in the source data base  since the last updating process and which additionally have the appropriate flag setting. In order to facilitate implementation of the delta updating process each data set stored in the source data base  may be provided with a time stamp. The delta updating process described above is advantageous as regards extraction of data sets from the source data base  that correspond to such accounting-related data sets on the transactional level that have newly been created and that have been duplicated by the duplicator  prior to having entered the general ledger data base  (direct posting).","For historical set ups of the source data base  with information directly retrieved from the general ledger data base  a different updating approach may be implemented (second operational mode of the extractor ). This updating approach includes transferring historical accounting-related data sets or corresponding information from the general ledger data base  via the duplicator  to the source data base  (subsequent posting) and extracting the complete content of the source data base  to the data warehousing layer .","The extraction mechanism used to transfer data from the source data base  to the data warehousing layer  as well as the construction and function of the data warehousing layer  will now be described in more detail with reference to . As becomes apparent from , the extractor  in the present embodiment not only belongs to the data sourcing layer  but spans both the data sourcing layer  and the data warehousing layer . More specifically, the extractor  includes on the data sourcing level a data source  that is replicated on the data warehousing layer (reference numeral \u2032) and an information source  that is arranged in the data warehousing layer  and loaded with data from the replicated data source \u2032.","The information source  may be configured to also load information provided from one or more additional data sources . These additional data sources  may for example contain data provided directly from the transaction processing layer  depicted in  (arrow ). Hence, the further data sources  may include data provided from the logistics component B or the EP component C. The extractor  may thus merge (\u201cenrich\u201d) data extracted from the source data base  with data extracted from data bases arranged in the transaction processing layer  of .","Besides several components of the extractor  and the one or more additional data sources , the data warehousing layer  includes a meta data repository  that contains information about the data warehouse, at least one operational data base  (also called operational data store, ODS), at least one information data base  (also called Info Cube), and an OLAP processor . The operational data base  is used for updating the information data base . In contrast to the information data base , the operation data base  stores the data provided by the extractor  in a non-aggregated manner on a data line level. The operational data base is primarily used for detail reporting, rather than for dimensional analysis like the information data base . The information data base , on the other hand, is configured to aggregate data received from the operational data base  and to allow for a multi-dimensional data analysis.","The extraction of data from the source data base  into the operational data base  and the updating of the information data base  on the basis of the data contained in the operational data base  will now be described in more detail.","As becomes apparent from , the data source , which belongs to the extractor  and is arranged in the data sourcing layer , includes an extract structure  and a transfer structure . Data retrieved by the extractor  from the source data base  are first loaded into the extract structure . The extract structure has a predefined flat format specific for the source data base . The data contained in the source data base  are loaded on a data set-to-data set basis into the extract structure . The loading of data into the extract structure  includes the processing of extracted data according to a data format specified by the extract structure.","From the extract structure  the data are loaded into the transfer structure , which determines the content of the data source . In contrast to the extract structure , the transfer structure  allows to append further information (data fields) to the data provided by the extract structure . Thus, the transfer structure is a another option for merging data from further components of the transaction processing layer with data retrieved via the extract structure  from the source data base . Using the functionalities of either one or both of the transfer structure  and the one or more additional data sources , the extractor  allows to combine specific procurement-related data like data contained in purchase order data sets (purchaser, material, material group etc.) provided by the logistics component B or the EP component of  with the associated accounting-related data provided by the accounting component via the data sourcing layer .","The transfer structure  provides data in a format that is required or advantageous as regards the tasks performed in the data warehousing layer . In the present embodiment, the data set formatting performed by the transfer structure  includes splitting such data lines retrieved from the source data base  that contain several specific numerical values (e.g. a transaction value in different currencies) into two or more individual data lines, each data line containing a single numerical value. Although this formatting increases the number of data lines associated with a particular data set extracted from the source data base , it helps to accelerate and facilitate the aggregation and accumulation tasks performed in the data warehousing layer .","Meta data specifying details about the data source , i.e. the extract structure  and the transfer structure , are stored in the data sourcing layer . In order to define a data flow within the data warehousing layer  on the basis of the data source , the meta data characteristic of the data source  are replicated from the data sourcing layer  to the data warehousing layer . The replicated meta data are stored in the meta data repository  of the data warehousing layer  and define the data source \u2032 in the data warehousing layer .","From the replicated data source \u2032 arranged in data warehousing layer  the data are loaded according to predefined transfer rules into the information source . The information source  specifies a target structure of homogenized and consolidated data that logically form a single unit. The data provided by the information source  thus have a format which allows transferring the data in a predefined data model and using the data for data analysis.","The core features of the information source  are on the one hand the target structure in which the data are to be transferred during homogenization and on the other hand transfer rules that specify how this target structure can be reached using the information provided by one or more data sources \u2032, . In the present embodiment, the transfer rules specify that only data pertaining to data sets that include appropriate transfer information are loaded from the transaction structure of the data source \u2032 into the target structure of the information source . As has been mentioned above, this transfer information includes the setting of a flag indicating the relevancy of a particular data set for spend analysis (see ). The transfer rules are thus used in combination with the transfer information for filtering the data sets stored in the source data base . Meta data specifying the transfer rules and the target structure used by the information source  are stored in the meta data repository .","The operational data base  is updated by the information loaded into the information source . More specifically, the data pertaining to a particular data set extracted from the source data base  are loaded from the target structure of the information source into an ODS object having the same structure as the target structure. Update rules may be defined that specify the transfer of data from the information source  to the operational data base  in more detail. The update rules are stored in the meta data repository .","After loading extracted data into an ODS object in the operational data base , the data included in the ODS object may be aggregated according to predefined update rules in the information data base  for multi dimensional analysis.","The structure of the information data base is schematically depicted in . As becomes apparent from , the information data base  is based on a star schema including a fact table appearing in the middle of  as well as several surrounding dimension tables. The central fact table is rather large (several gigabytes) and is used to retrieve the data requested by the OLAP processor . The size of the dimension tables amounts to only a few percent of the size of the central fact table. As is known in the art, foreign keys are used to tie the fact table to the dimension tables. The special design technique of the information data base shown in  greatly facilitates data retrieval for the analytical processing to be performed by the OLAP processor .","Now, the exemplary flow of an accounting-related data set comprised of several data lines from the accounting interface of the transaction processing layer to the information data base  will be described with reference to the functional components depicted in  on the one hand and the data set transformation depicted in  on the other hand.","The upper half of  shows a duplicated accounting-related data set output via the accounting interface in the transaction processing layer . This accounting-related data set is comprised of three data lines associated with the individual items that are to be posted. Each data line comprises several data fields that specify an account type code, a debit\/credit indicator, a posting key, an account code, a value in a transaction currency, a specification of the transaction currency, an amount in a company currency, a specification of the company currency, a creditor code and a reference to a purchase order data set associated with the particular accounting-related data set.","The filter  of the data sourcing layer  is coupled to the accounting interface and configured to be transmissive for such duplicated data sets that contain the account type code \u201cK\u201d for \u201cKreditor\u201d (and are thus assumed to be procurement relevant). The duplicated data set depicted in the upper half of  includes the account type code \u201cK\u201d in the first data line and consequently passes the filter , which feeds component  for data pre-analysis and data formatting. It should be noted that not only the individual data line containing the account type code \u201cK\u201d is selected but the whole data set including the remaining data lines containing the account type code \u201cS\u201d for \u201cSachkonto\u201d.","The component  analyzes the posting key assigned to the duplicated data set received from the filter . Depending on the posting key, the component  marks a duplicated data set as spend relevant. In the present embodiment a duplicated data set is considered to be spend relevant if the posting key indicates that the duplicated data set relates to an invoice data set, a credit memo data set, a reverse invoice data set or a reverse credit memo data set (in the present embodiment the posting keys , ,  and , respectively, have been assigned to these data sets). In the case depicted in  the duplicated data set includes the posting key  and is thus considered to be spend relevant. Accordingly, the component  appends to the individual lines of the duplicated data set an additional data field titled \u201cspend relevant\u201d and fills this field line-wise by setting a flag \u201cX\u201d indicating spend relevancy. Instead of analyzing a posting key, the component  may be configured to analyze additional or alternative information included in the duplicated data set. Such information may relate to a user flag setting \u201csales related\u201d (not depicted for the accounting-related data set shown in ).","Besides appending further data fields and setting the associated flag, the component  inherits the creditor code originally included in only one data line of the duplicated data set to the remaining two data lines. This facilitates the line-wise processing in the data warehousing layer. Moreover, the component  column-wise moves individual data fields and enriches the duplicated data set with data fields relating to values in a transactional currency and in a company group currency. This data enrichment in the data sourcing layer  allows for a more detailed spend analysis in the data warehousing layer . The data set thus obtained (see lower half of ) is output by the component  and stored in the source data base .","Since the newly stored data set contains the appropriate flag setting in the appended data field \u201cspend relevancy\u201d, it will be extracted from the source data base  as explained before during the next extraction process, formatted, enriched (if necessary) and used to update the operational data base . The extraction process involves the data source \u2032 and the information source . In context with the overall object of providing information for spend analysis, the extracted data set contains more information than is actually needed. Thus, the data transfer rules specify that only the relevant fields of data sets originally provided by the source data base  are mapped from the data source  to the information source .","The data fields mapped to the information source are stored as ODS object in the operational data base  in the format shown in . As becomes apparent from , the individual lines of the data set stored in the source data base  have additionally been split such that each individual line of the data set stored in the operational data base  includes only a single value per data line. More specifically, each data line extracted from the source data base  has been split in three data lines, a first data line specifying a value in a transaction currency, a second data line specifying a value in a company currency and a third line specifying a value in a company group currency. As becomes apparent from , the data sets stored in the operational data base  are of a rather high granularity, i.e. contain rather detailed information. Data granularity of the operational data bases includes data set level and day (posting date and other dates). For reporting purposes the operational data base  is directly accessible from the OLAP processor .","The information contained for a specific data set in the operational data base  is used to update the information data base . To this end the individual amounts contained in the plurality of data sets stored in the operational data base  are accumulated for individual account types. The update rules from the operational data base  to the information data base  specify that the spend volume be calculated for each currency type in an individual line. The data structure of a data set stored in the information data base  is exemplarily shown in . It should be noted that the structure shown in  is based on the assumption that only a single data set has yet been retrieved from the operational data base . Consequently, no actual accumulation of individual values has yet been performed.","The information data base  contains the whole spend volume of a company or company group. It is configured to allow e.g. for an analysis for which material, material group, account or account group the company spend money in a specific period of time per vendor. The global spend is provided in three currencies (transaction currency, company currency, group currency). The information data base  is configured to allow reporting on various levels, including creditor, plant, cost center, material etc. Data granularity of the information data base  includes month, calendar quarter, calendar year and fiscal periods.","Based on the data contained in the information data base , the OLAP processor  may compose reports for being presented by the analyzer  as depicted in . As becomes apparent from , the invention allows to make detailed procurement-related information that has been generated on a transaction level available to data warehousing techniques without (solely) relying on the information provided by an EP component. By using the information generated by an accounting component on a transaction level and enriching this information, if required, with further transactional information provided for example by a logistics component or an EP component, data warehousing becomes applicable for spend analysis or other analysis tasks in a procurement context. As becomes apparent from , it is now possible to analyze for example information related to the purchase of individual materials (office materials\/direct materials) in a quick and comfortable manner. Such information would be very difficult to obtain if an approach as depicted in  or a similar approach would have been pursued.","Although embodiments of the present invention have been illustrated in the accompanying drawings and described in the aforegoing description, it will be understood that the invention is not limited to the embodiments disclosed. The invention is capable of numerous rearrangements, modifications and substitutions without departing from the spirit of the invention as set forth and defined by the following claims."],"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DESCRIPTION OF THE EMBODIMENTS"],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["Further details, embodiments, modifications and enhancements of the present invention may be obtained from consideration of the following description of various illustrative embodiments of the invention in conjunction with the drawings, in which:",{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0037","num":"0036"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIGS. 5A-5C","FIG. 4"]},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIGS. 7-9"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
