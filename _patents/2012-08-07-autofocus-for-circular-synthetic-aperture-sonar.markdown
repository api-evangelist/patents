---
title: Auto-focus for circular synthetic aperture sonar
abstract: A method of focusing fully-coherent circular synthetic aperture sonar (CSAS) imagery is provided. A k-space representation of the CSAS image is generated using the two dimensional Fast-Fourier Transform (FFT). Sub-aperture images are generated by windowing the k-space representation and applying the two dimensional inverse FFT to the windowed spectrum. All adjacent complex sub-aperture images are correlated, the correlation peaks are detected and the relative shifts in X and Y as a function of look-angle are recorded. The relative shifts between adjacent sub-apertures are integrated and the means are subtracted to find the absolute shift as a function of look-angle. A motion-solution is calculated by exploiting the relationship between apparent scene shift and actual vehicle sway. The motion estimation is used to generate a phase-correction matrix that is multiplied by the k-space representation of the fully-coherent image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08937849&OS=08937849&RS=08937849
owner: The United States of America as represented by the Secretary of the Navy
number: 08937849
owner_city: Washington
owner_country: US
publication_date: 20120807
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["STATEMENT OF GOVERNMENT INTEREST","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DESCRIPTION OF THE INVENTION"],"p":["The invention described herein may be manufactured and used by or for the Government of the United States of America for governmental purposes without the payment of any royalties.","(1) Field of the Invention","The present invention relates to circular synthetic aperture sonar. More particularly, the present invention relates to a method of focusing fully-coherent circular synthetic aperture imagery without the aid of a navigation beacon.","(2) Description of the Prior Art","Circular synthetic aperture sonar (CSAS) is a specific modality of synthetic aperture sonar in which individual pings from a sonar device having a circular trajectory are coherently processed to generate an image having a full 360\u00b0 of backscattered aspect information. In contrast, \u201clinear-scan\u201d synthetic aperture sonar coherently processes backscattered echoes from a narrow range of aspects, typically in the low tens of degrees, to generate an image.","Circular synthetic aperture sonar images are useful because of the large amount of information recovered for a particular scene, and echoes backscattered from all aspects can be used to generate target outlines and high resolution imagery. While theoretically very useful, focused CSAS images are difficult to obtain due to motion constraints. A major source of defocusing in CSAS imagery are deviations of the sonar platform from a circular trajectory, such as caused by wave action, path tracking errors and the like.","As noted, a CSAS image is an image generated using the entire set of backscattered echoes gathered from a platform moving around a circular aperture. Sub-aperture (SA) images, which are distinct from CSAS images, can be generated using any limited portion of the circular aperture (e.g., an image can be made using the set of look angles spanning from 30\u00b0 to 50\u00b0). Sway error, which is unique for individual sub-apertures, tends to cause the scene to shift as a function of look-angle.","One auto-focus method known in the art works by generating multiple SA intensity images, typically numbering in the low tens. The algorithm attempts to optimally shift and sum these images to counteract for the scene shift caused by platform motion. To do this, each of these SA images is correlated with the others, an operation requiring N*(N\u22121)\/2 image correlations.","The relative locations of the correlation peaks in the X and Y coordinates of the sub-aperture image and the signal-to-noise values gathered from the correlation peaks are used to generate a robust least-squares polynomial expression for the scene shift. The resulting polynomial is used to estimate the optimal scene shift that can be applied to each sub-aperture to align them all before summing.","While the algorithm appears to be fairly robust, there are two major drawbacks to this method. First, it is a non-iterative algorithm that provides no motion solution. The relationship between the scene shift and the actual platform motion in a CSAS scenario is essential for making a navigational correction which could potentially result in a fully-coherent, high-resolution CSAS image. However, the relationship is not obvious and has not been outlined in the literature.","The second drawback to the multiple SA method is that the order of the polynomial expression is often much too small to accurately model the platform motion. A fundamental assumption in the outlined algorithm is that the motion error within any of the sub-apertures can be approximated as negligible.","Because of the large number or correlations that must occur relative to the actual number of apertures utilized, (N*(N\u22121)\/2, N=number of sub-apertures), and the tendency for coefficients of the polynomial solution to quickly exceed machine precision, the number of sub-apertures remains limited in order. One published example of the multiple SA method uses thirty (N=30) sub-apertures (H. J. Callow, R. E. Hanson, S. Synnes, and T. O. Saebo, \u201cCircular synthetic aperture sonar without a beacon,\u201d Proceedings of the 3International Conference & Exhibition on Underwater Acoustic Measurements, June 2009). For many synthetic aperture sonar parameters and environments, this limited number of sub-apertures remains insufficient to accurately model platform motion.","A second auto-focus method known in the art uses a maximum a-posteriori (MAP) estimator to attempt to simultaneously focus a CSAS image and determine scene bathymetry, decoupling scene elevation from platform motion (H. J. Callow, S. Synnes, T. O. Saebo, R. E. Hanson \u201cAutofocus for circular synthetic aperture imaging,\u201d Proceedings of Synthetic Aperture Sonar and Synthetic Aperture Radar (SAS\/SAR) 2010, Lerici, Italy, September 2010). While the concepts in this approach are directly applicable to CSAS, the data sets used in the published example of this method were obtained from four looks along the cardinal directions at the same scene using four independent line-scans rather than a circular path trajectory.","As described in the literature, the approach offers no method for recovering a platform motion estimate. Accordingly, the efficacy of this approach in the context of an actual CSAS scenario, in which a platform undergoes rapid motion error, remains to be demonstrated.","Methods used in circular synthetic aperture radar (CSAR) may be adapted to CSAS. While most examples of CSAR use error-free data recorded from a fixed source and rotating platform, there are known in the art examples of CSAR imagery recorded from an aircraft rather than a fixed system. Some of these examples mention Phase Gradient Autofocus\/Phase Curvature Autofocus based focusing methods.","The draw-back of these methods is that they require prominent points with uniform angular response. In the examples known in the art, the prominent points were provided by artificially placing bright, point-like targets in the scene before imaging took place. These methods also assume a-priori that the blurring of the targets is small enough that they remain distinct from adjacent scatterers. Such assumptions do not hold well in many CSAS imaging scenarios.","Another auto-focus method pertaining to CSAR is a correlation based map-drift algorithm similar to the multiple SA method described previously. This CSAR method operates by forming a large number of small apertures. The image shifts are found by correlating each sub-aperture with the accumulated sum of the aligned versions of all previous apertures, starting with the first look angle.","This saves considerable time from a correlation standpoint. However, to calculate the associated trajectory, a set of linear equations relating each apparent location to all other locations is established and singular-value-decomposition (SVD) is used to solve for the navigation correction. This method applies the navigation correction to the raw data which is then re-beamformed. The algorithm used in the method can be iterated.","While this method has a speed advantage with respect to the multiple SA method described previously, the navigation solution must be applied to the raw data, requiring multiple iterated instances of beamforming, reducing computational efficiency. Furthermore, this method of sub-aperture scene tracking lacks a direct measurement of phase curvature error, resulting in sub-optimal precision for high frequency error estimation.","Thus, a need has been recognized in the state of the art to provide a method of focusing fully-coherent circular synthetic aperture imagery without the aid of a navigation beacon. The method needs to be iterative in order to accurately model platform motion. The method should be applicable without the need to use prominent points within the field that have uniform angular response. Further, the method should be computationally efficient without requiring re-beamforming.","It is therefore a general purpose and primary object of the present invention to provide a method of focusing fully-coherent circular synthetic aperture imagery. A fully complex CSAS image is first generated using raw echo data that has uncompensated motion errors. A k-space representation of the image is generated using the two dimensional Fast-Fourier Transform (FFT).","Sub-aperture images are then generated and all adjacent complex sub-aperture images are correlated and the correlation peaks are detected. In order to generate the sub-aperture images, the k-space representation of the image is windowed and the two dimensional inverse FFT (iFFT) is applied to the windowed spectrum.","The relative shifts in X and Y as a function of look-angle are recorded and the relative shifts between adjacent sub-apertures in X and Y are integrated. The means are subtracted to find the absolute shift in X and Y of the scene as a function of look-angle.","A motion-solution is calculated by exploiting the relationship between apparent scene shift and actual vehicle sway, where sway is defined as motion of the platform normal to the circular path used for motion compensation. The motion estimation is used to generate a phase-correction matrix that is multiplied by the k-space representation of the fully-coherent image. The process is iterated if necessary.","In one embodiment, a method of focusing a circular synthetic aperture sonar image of a scene taken from a platform includes generating a k-space representation of the sonar image, generating sub-aperture images based on windowing the k-space representation over chosen look-angles and correlating adjacent ones of the sub-aperture images. The method also includes detecting correlation peaks based on the correlations and obtaining absolute shifts of the scene as a function of the look-angles. The absolute shifts are based on the correlation peaks. The method additionally includes calculating a sway motion estimation of the platform based on the absolute shifts, generating a phase-correction matrix based on the sway motion estimation and applying the phase-correction matrix to the sonar image to recover a focused image of the scene.","In one embodiment the method further includes iteratively returning to generating sub-aperture images utilizing a k-space representation of the focused image. The step of generating sub-aperture images further includes applying an inverse Fast Fourier Transform to each windowed k-space representation.","In one embodiment, the method first includes generating the sonar image using a phase-preserving method applied to the raw echo data of the scene that can have uncompensated motion errors. Various phase-preserving methods can be used including projection-slice imaging and time-delay and sum imaging.","In one embodiment, the step of detecting correlation peaks further includes interpolating and filtering correlated sub-aperture images. The step of obtaining absolute shifts can include expressing the correlation peaks as a function of the look angles so as to obtain relative shifts. The mean can be subtracted from the relative shifts and the relative shifts accumulated.","In one embodiment, the step of calculating a sway motion estimation can include calculating axial scene shifts based on the absolute shifts and integrating and scaling the axial scene shifts to obtain a scalar function A(\u03b8), wherein platform sway is proportional to A(\u03b8) and wherein \u03b8 corresponds to an angle in the spatial coordinates X and Y of the scene. The scalar function is obtained from the expression:",{"@attributes":{"id":"p-0031","num":"0030"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["\u03b8","n"]}}},{"mi":"C","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"-","mn":"1"},"mi":"N"},"mo":"\u2062","mfrac":{"mrow":{"msqrt":{"mrow":{"msubsup":[{"mi":["X","n"],"mn":"2"},{"mi":["Y","n"],"mn":"2"}],"mo":"+"}},"mo":"*","mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"+","mrow":{"mi":"arc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"tan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["Y","n"]},{"mi":["X","n"]}]}}}}}}}},"mi":"N"}},{"mn":"2","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mn":"1","mi":"n"},"mo":"\u2062","mfrac":{"mrow":[{"msqrt":{"mrow":{"msubsup":[{"mi":["X","n"],"mn":"2"},{"mi":["Y","n"],"mn":"2"}],"mo":"+"}},"mo":"*","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"+","mrow":{"mi":"arc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"tan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["Y","n"]},{"mi":["X","n"]}]}}}}}}}},{"mi":"csc","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mrow":{"mi":["\u0394","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mn":"2"}}}]}}}],"mo":"+"}}}],"mo":"="},"mo":","}}},"br":{}},"The phase-correction matrix is obtained by evaluating a polar phase function S(|k|,\u03b8)=e, wherein |k| is a Pythagorean sum of kand k, which are coordinates in the k-space. The step of applying the phase-correction matrix can include multiplying the k-space representation by a conjugate of the polar phase function to obtain the k-space representation of the focused image and taking an inverse spatial Fourier transform of the k-space representation of the focused image.","In one embodiment, a method of focusing a circular synthetic aperture sonar image of a scene taken from a platform includes the step of generating the sonar image using a phase-preserving method applied to the raw echo data of the scene, which can have uncompensated motion errors. Further steps include generating a k-space representation of the sonar image, generating reference sub-aperture images from a number, M, of evenly spaced look-angles over 2\u03c0 and generating relative sub-aperture images from a number, N, of evenly spaced look-angles, wherein N>>M.","Additionally, the method includes correlating a set of the relative sub-aperture images located between \u00b1 a span angle of a look angle corresponding to a particular one of the reference sub-aperture images with the particular reference sub-aperture image, detecting correlation peaks and shifting the set of relative images based on the correlation peaks to form a semi-coherent image representing the scene from look-angles corresponding to \u00b1 the span angle. The semi-coherent image is centered on the look angle corresponding to the particular reference sub-aperture image. Also, the method includes iteratively performing the steps of correlating, detecting and shifting for each of the reference sub-aperture images.","The method further includes determining a polynomial expression relating locations of the semi-coherent images with each other based on multiple-aperture map-drift methodology. Based on the polynomial expression, peak-shift measurements made between the relative sub-aperture images and the reference sub-aperture images are positioned to obtain absolute shifts. A sway motion estimation of the platform is calculated based on the absolute shifts, a phase-correction matrix is generated based on the sway motion estimation and the phase-correction matrix is applied to the sonar image to recover a focused image of the scene.","In one embodiment, the method includes iteratively returning to generating reference sub-aperture images utilizing a k-space representation of the focused image. In one embodiment, the step of calculating a sway motion estimation includes calculating axial scene shifts based on the absolute shifts and integrating and scaling the axial scene shifts to obtain a scalar function A(\u03b8), wherein platform sway is proportional to A(\u03b8) and wherein \u03b8 corresponds to an angle in spatial coordinates X and Y of the scene.","The scalar function is obtained from the expression:",{"@attributes":{"id":"p-0038","num":"0037"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["\u03b8","n"]}}},{"mi":"C","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"-","mn":"1"},"mi":"N"},"mo":"\u2062","mfrac":{"mrow":{"msqrt":{"mrow":{"msubsup":[{"mi":["X","i"],"mn":"2"},{"mi":["Y","i"],"mn":"2"}],"mo":"+"}},"mo":"*","mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","i"]},"mo":"+","mrow":{"mi":"arc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"tan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["Y","i"]},{"mi":["X","i"]}]}}}}}}}},"mi":"N"}},{"mn":"2","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":"\u2062","mfrac":{"mrow":[{"msqrt":{"mrow":{"msubsup":[{"mi":["X","i"],"mn":"2"},{"mi":["Y","i"],"mn":"2"}],"mo":"+"}},"mo":"*","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","i"]},"mo":"+","mrow":{"mi":"arc","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mi":"tan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["Y","i"]},{"mi":["X","i"]}]}}}}}}}},{"mi":"csc","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mrow":{"mi":["\u0394","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mn":"2"}}}]}}}],"mo":"+"}}}],"mo":"="},"mo":","}}},"br":{},"sup":"j*A(\u03b8)|k|","sub":["x ","y"]},"In one embodiment, the span angle is \u03c0\/M. In one embodiment, the span angle is greater than \u03c0\/M, such that the semi-coherent images overlap. In this case, the overlapping shift solutions are differentiated, averaged and re-integrated to form a continuous solution of semi-coherent images. In one embodiment, the phase-preserving methods can include projection-slice imaging and time-delay and sum imaging. In one embodiment, the step of detecting correlation peaks can include interpolating and filtering the correlated sub-aperture images.","Circular Synthetic Aperture Sonar (CSAS) utilizes the backscattered echoes from sonar mounted on a platform moving in a circular trajectory around a scene. Deviations of the sonar platform from a circular trajectory are a major source of defocusing in CSAS imagery. If the platform motion and its deviation from a circular trajectory are known, these errors can be corrected by appropriately time-shifting the raw backscattered echo data before image reconstruction.","While a CSAS image makes use of the back-scattered data from the entire aperture, the processing used to generate a CSAS image can be applied to a limited portion of the circular aperture to generate a \u201csub-aperture\u201d (SA) image. Because the aperture sizes of SA images tend to be much smaller than the total circular aperture, traditional motion-compensation techniques used by the sonar community for linear synthetic aperture scenarios can be reformulated and applied to retain reasonable focus of these smaller SA images.","The residual, uncompensated error appears as a relative scene shift in both X and Y (the coordinates of the imaging plane) between SA images. These absolute shifts in X and Y can be used to calculate a motion estimation for the platform which may be applied directly to the beamfomed image in k-space, (the two-dimensional Fourier transform of the image, also referred to herein as spectrum).","To successfully perform this operation requires that the estimation of the platform motion be adequately sampled. In shallow water scenarios the platform tends to deviate from the circular path in a rapid manner, requiring a large number of samples to be utilized for accurate motion estimation. Because a real, truncated signal has infinite bandwidth, low-pass filtering is applied to the estimation before measuring, and this is accomplished by slightly overlapping the boundaries of the SA windows.","Referring now to , there is shown a block diagram of method  for focusing a CSAS image as previously described in a general manner hereinbefore. At block , a fully complex CSAS image is generated using raw echo data that has uncompensated motion errors. Block  utilizes a phase-preserving method for forming the image.","As is known in the art, many different methods are available for forming an image using raw echo data. By using a phase-preserving method, the result of block  is a well-sampled image that has an un-aliased k-space spectrum. As known examples to those of skill in the art, but not for limitation, fully-coherent, phase preserving methods for image reconstruction can include projection-slice imaging and time-delay and sum imaging.","As is known to those of skill in the art, an image reconstructed using a phase-preserving method can be represented in wavenumber (k) space by taking the Fourier Transform in the spatial dimensions (X and Y) of the scene. The limited bandwidth of a sonar system often results in a spectral annulus when viewed in k-space. At block , a k-space representation of the image is generated using the two dimensional Fast-Fourier Transform (FFT).","At block , N sub-aperture (SA) images are generated by applying a two dimensional inverse FFT (iFFT) to windowed portions of the full circular aperture and spectrum. The number N can be chosen to balance the convergence of method  against the computational intensity of method , as will be explained in further detail hereinafter.","Referring now to , there is shown a detailed block diagram of step  for generating the SA images. To start, the number N is chosen at block  and the window look angles, \u03b8, for the SA images are determined (block ) from \u03b8=2\u03c0\/N, n=1,N. At block , a window preserving the spectral information spanning look angle \u03b8to look angle \u03b8is applied to the k-space representation of the image.","The iFFT is applied to the windowed data to recover the SA image in spatial coordinates (block ). The absolute value of this complex SA image is used to generate an intensity image, in the manner known to those of skill in the art. If the full circular aperture and spectrum has not been windowed, i.e., the number of windows is less than N, as determined at block , the window is incremented to the next look angle (e.g., spanning \u03b8to \u03b8) at block . When the full circular aperture and spectrum has been windowed (block ), method  continues, as indicated at block .","Referring back to , once the N SA images are generated at block  (representing look angles from 0 to (2\u03c0\u22122\u03c0\/N) radians), adjacent complex SA images are correlated (block ). N correlations are computed between SA images representing adjacent look angles. For example, if SA, SA, . . . , SArepresent sub-aperture images at look angles 0*(2\u03c0\/N), 1*(2\u03c0\/N), . . . , (N\u22121)*(2\u03c0\/N), then SA, is correlated with SA, and SAis correlated with SA, etc.","The results of the correlations between image pairs are two dimensional functions with peaks at (P,P), where Pand Prepresent the relative shift in X and Y between the image pairs. The relative shifts can be expressed as a function of the average look-angle between image pairs. At block , the correlation peaks (P,P) are detected for each image pair, providing the relative shift between each image pair. Interpolation and filtering can be used to obtain more accurate estimates of Pand P. At block , the relative shifts in X and Y as a function of look-angle are recorded.","The relative shifts obtained at block  are measurements of the differential movement of the scene shift as a function of look-angle. Since the circular aperture is closed (i.e. the beginning and ending points of the circular path are the same), the absolute shifts are constrained to be zero-mean. To obtain the absolute shifts of the scene in X and Y, as at block , the relative shifts recorded at block  have the mean subtracted and are accumulated. By having the mean subtracted before accumulation, linear offsets from noise and\/or discretization errors can be avoided.","At block , a motion-solution is calculated by exploiting the relationship between apparent scene shift and actual vehicle sway, where sway is defined as motion of the platform normal to the circular path. This relationship can be derived by supposing an image is corrupted by sway errors resulting in blurred image L(X,Y), approximated to have the spectrum:\n\n()}=()=()*\u2003\u2003[1]\n\nwhere F is the two-dimensional Fourier transform operator, L(k,k) is the spatial spectrum of the uncorrupted image L(X,Y) and S is a function determined by the sway error induced by platform motion.\n","The function S is a polar phase function modeled by\n\n()=,\u2003\u2003[2]\n\nwhere \u03b8 is the arctangent of (k\/k), |k| is the Pythagorean sum of kand k, and A(\u03b8) is a scalar function of \u03b8. Consider a patch Min L, defined to be the region between\n",{"@attributes":{"id":"p-0059","num":"0058"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"-","mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}},"br":{}},{"@attributes":{"id":"p-0060","num":"0059"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"+","mfrac":{"mrow":{"mi":["\u0394","\u03b8"],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mn":"2"}},"mo":","}}},"br":{},"sub":["n ","n "]},{"@attributes":{"id":"p-0061","num":"0060"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"-","mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}},{"mo":["\uf603","\uf604"],"mi":"k"}],"mo":"\u2062"}}},"br":{}},{"@attributes":{"id":"p-0062","num":"0061"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"+","mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}},{"mo":["\uf603","\uf604"],"mi":"k"}],"mo":"\u2062"},"mo":","}}},"br":{}},"The inverse spatial Fourier transform of patch Mis a sub-aperture image M(SA)formed from the pings located between",{"@attributes":{"id":"p-0064","num":"0063"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"-","mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}},"br":{}},{"@attributes":{"id":"p-0065","num":"0064"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"+","mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}},"br":{},"sub":["n ","n ","x ","y "]},"In k space, an angle \u03b8=arctan(k\/k) is equivalent in spatial coordinates to \u03b8=arctan(Y\/X). The shifts Xand Yexperienced by M(SA)may be redefined in terms of a radial shift in the direction \u03b8, the mean angle of the rays bounding patch M(SA)and an axial shift in the direction \u03b8=\u03c0\/2. The scalar value A(\u03b8) may be directly computed from a measurement of the radial shift in X and Y coordinates, which from simple geometry is found to be:",{"@attributes":{"id":"p-0067","num":"0066"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["H","radial"]},"mo":"=","mrow":{"msqrt":{"mrow":{"msubsup":[{"mi":["X","n"],"mn":"2"},{"mi":["Y","n"],"mn":"2"}],"mo":"+"}},"mo":"*","mrow":{"mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"-","mrow":{"mi":"arctan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["Y","n"]},{"mi":["X","n"]}]}}}}}},"mo":"."}}}},{"mrow":{"mo":["[","]"],"mn":"3"}}]}}}},"br":{}},{"@attributes":{"id":"p-0068","num":"0067"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["H","axial"]},"mo":"=","mrow":{"msqrt":{"mrow":{"msubsup":[{"mi":["X","n"],"mn":"2"},{"mi":["Y","n"],"mn":"2"}],"mo":"+"}},"mo":"*","mrow":{"mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"-","mrow":{"mi":"arctan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["Y","n"]},{"mi":["X","n"]}]}}}}}},"mo":"."}}}},{"mrow":{"mo":["[","]"],"mn":"4"}}]}}}}},"Practical implementation of the correlation operations results in shift measurements having a large amount of digitization error in the radial direction. More useful is an indirect computation of A(\u03b8) by first measuring the axial shift and exploiting the relationship between the axial and radial shift. Recalling that patch Mis defined by two bounding rays, the shift in the axial direction is determined by the slope of plane Pin the axial direction:",{"@attributes":{"id":"p-0070","num":"0069"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mi":["H","axial"]},"mo":"\u221d","mfrac":{"mrow":[{"mrow":[{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"+","mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}},{"mo":["\uf603","\uf604"],"mi":"k"}],"mo":"\u2062"},{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"-","mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}},{"mo":["\uf603","\uf604"],"mi":"k"}],"mo":"\u2062"}],"mo":"-"},{"mn":"2","mo":["\u2062","\u2062"],"mrow":[{"mo":["\uf603","\uf604"],"mi":"k"},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}]}]}},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0071","num":"0070"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"msub":{"mi":["H","axial"]},"mo":"\u221d","mrow":{"mfrac":{"mrow":[{"mi":"\u0394","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"msub":{"mi":["A","n"]}},{"mn":"2","mo":"\u2062","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}}]},"mo":"."}}}}},"The axial shift of sub-aperture scene M(SA)at angle \u03b8is therefore related to the change in slope \u0394Aby the scalar",{"@attributes":{"id":"p-0073","num":"0072"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mn":"1","mo":"\/","mrow":{"mrow":{"mo":["(",")"],"mrow":{"mn":"2","mo":"\u2062","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}}},"mo":"."}}}},"br":{}},{"@attributes":{"id":"p-0074","num":"0073"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["\u03b8","n"]}}},{"mi":"C","mo":"\u2061","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":"n","mo":"-","mn":"1"},"mi":"N"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mfrac":{"mrow":{"msqrt":{"mrow":{"msubsup":[{"mi":["X","n"],"mn":"2"},{"mi":["Y","n"],"mn":"2"}],"mo":"+"}},"mo":"*","mrow":{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"+","mrow":{"mi":"arctan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["Y","n"]},{"mi":["X","n"]}]}}}}}}},"mi":"N"}},{"mn":"2","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mi":["l","n"]},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mfrac":{"mrow":[{"msqrt":{"mrow":{"msubsup":[{"mi":["X","n"],"mn":"2"},{"mi":["Y","n"],"mn":"2"}],"mo":"+"}},"mo":"*","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["\u03b8","n"]},"mo":"+","mrow":{"mi":"arctan","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"msub":[{"mi":["Y","n"]},{"mi":["X","n"]}]}}}}}}},{"mi":"csc","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}]}}}],"mo":["+","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}}}],"mo":"="},"mo":","}},{"mrow":{"mo":["[","]"],"mn":"6"}}]}}}},"br":{}},"The integration constant, lost by the axial measurement, is recovered by using the mean of the solution found using the radial measurements. Equation [6] can be interpreted as meaning that the axial scene shift at any given angle is directly related to the derivative of the sway function, and the sway function can be recovered (to within a constant) by integrating and scaling the axial scene shift.","Furthermore, the factor",{"@attributes":{"id":"p-0077","num":"0076"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mn":"1","mo":"\/","mrow":{"mo":["(",")"],"mrow":{"mn":"2","mo":"\u2062","mrow":{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mfrac":{"mi":"\u0394\u03b8","mn":"2"}}}}}}}},"br":{}},"The motion estimation is used to generate a phase-correction matrix (block ), which is multiplied by the k-space representation of the fully-coherent image. As calculated at block , the vehicle sway is proportional to the scalar function A(\u03b8), where \u03b8 corresponds to angle in k-space, angle in the spatial coordinates of the scene and the angles of the circular aperture. The corrupting effects of the sway on the spectrum of the complex scene are approximated by Equation [1].","A(\u03b8) was found in block  using the sub-aperture scene shifts in the axial direction. S(\u03b8) is calculated from A(\u03b8) using the relationship identified in Equation [2] for all values of kand k. At block , the blurring effect of S(\u03b8) is removed by multiplying Lby the conjugate of S(\u03b8):\n\n()=()(\u03b8)*(\u03b8)=()*(\u03b8)\u2003\u2003[7]\n\nThe de-blurred scene is recovered by taking the inverse spatial Fourier transform:\n\n()=()*(\u03b8)}\u2003\u2003[8]\n","As indicated at block , the process can be repeated an arbitrary number of times, based on a chosen tolerance. For each iteration, method  returns to block  to generate the sub-aperture images based on windowing the k-space representation of the image, L(k,k), as determined from Equation [7].","What has thus been described is an auto-focus method, method , for fully-coherent CSAS imagery generated using raw echo data that has uncompensated motion errors (). A k-space representation of the CSAS image is generated using the two dimensional Fast-Fourier Transform (). Sub-aperture images are generated by windowing the k-space representation and applying the two dimensional inverse FFT to the windowed spectrum ().","All adjacent complex sub-aperture images are correlated () and the correlation peaks are detected (). The relative shifts in X and Y as a function of look-angle are then recorded (). The relative shifts between adjacent sub-apertures are integrated and the means are subtracted to find the absolute shift as a function of look-angle ().","A motion-solution is calculated () by exploiting the relationship between apparent scene shift and actual vehicle sway. The motion estimation is used to generate a phase-correction matrix () that is multiplied by the k-space representation of the fully-coherent image (). The process is iterated as necessary to obtain a chosen tolerance.","A major advantage of the described technique is that an actual, well-sampled estimation for platform motion is derived from X and Y shift coordinates. Previous auto-focusing methods did not obtain this estimation or the estimation was done in a very slow and computationally intensive manner. In contrast, the present method is nearly instantaneous. This allows for algorithm iteration and the generation of focused, fully coherent CSAS imagery in a very efficient manner.","Further in comparison with present methods, method  omits a polynomial descriptor for the scene shift and reduces the number of correlation operations. This allows for the number of sub-aperture images to be increased by over an order of magnitude as compared to the previous methods, without increasing the computational burden of the auto-focus operation. Additionally, the generation of sub-aperture windows using k-space windowing rather than by directly beam forming limited portions of raw data alleviates a large portion of the computational burden.","When compared to auto-focus methods described by the radar community, method  shows greater robustness to scene type. As described previously, point-based focusing methods used by the SAR community assume the presence of point-like scatterers that have a uniform scattering response as a function of angle. Such targets may or may not be present in a real scenario. If they are, they may not be bright enough, or their responses may not be defined well enough to separate them from surrounding clutter and use them to derive a motion solution.","Method  does not require the presence of point-like scatterers in the scene. Rather, method  assumes that the correlation between adjacent sub-apertures is high enough to result in a well-defined correlation peak. Such an assumption holds for most realistic CSAS imaging scenarios.","Further, method  has a number of advantages over the previously described drift based method used by the SAR community. Method  uses a simpler process for finding the absolute X and Y shift values and uses a simpler and orders-of-magnitude faster process for calculating the navigation solution. This allows a navigation solution to be computed from potentially an arbitrary number of sub-apertures with negligible variation in computation time.","Also, method  includes the means by which the navigation solution can be applied directly to the beamformed image in k-space so that the image can be focused. Additionally, method  provides for iteration without requiring the data to be re-beamformed.","Obviously many modifications and variations of the present invention may become apparent in light of the above teachings. For example, method  can be modified to be more robust to errors that correlation-based methods are prone to. In realistic situations, for example, adjacent sub-aperture images may de-correlate due to the presence of biologics, such as large clouds of fish. Also, adjacent sub-aperture images may de-correlate due to excessive motion like roll. With excessive roll motion, the beam may be steered completely away from the ocean bottom resulting in no appreciable back-scattered signal.","As illustrated in phantom in , block  provides an alternative method for generating sub-aperture images and obtaining absolute coordinate shifts, i.e., an alternative method for steps  through  of . Referring now to , there is shown a block diagram of alternative method  for generating well-sampled motion error estimates in the event that particular sub-apertures do not correlate well.","Method  begins by selecting a small number M (e.g., M=10) of evenly spaced look-angles over 2\u03c0 and generating narrow sub-aperture images from these look-angles (block ), referred to as reference images for purposes of method . At block , a large number N of evenly spaced look-angles (e.g. N=360) are selected and sub-aperture images are generated for these look-angles, referred to as relative images for purposes of method .","All relative images located between \u2212\u03c0\/M and \u03c0\/M of the look angle (referred to as a cell) corresponding to a particular reference image are correlated with the reference image (block ) and the correlation peaks are tracked (block ). At block , the locations of the correlation peaks are used to shift the relative images in the cell to form a semi-coherent image representing the scene from look-angles \u2212\u03c0\/M to \u03c0\/M, centered on the look angle of that particular reference image. The process is repeated for all M reference images, as indicated at blocks ,  and returning to block .","If relative image correlations have been performed for all M reference images, as determined at block , a weighted, robust, polynomial expression relating the locations of the M semi-coherent images with each other is found using the known multiple-aperture map-drift method (block ). At block , the polynomial from block  is used to appropriately position the M sets of peak-shift measurements made between the relative and reference images.","Method  returns to block  () to obtain the sway correction estimate based on the absolute shifts found at block . As is the case with method , method  can be iterated to refine the de-blurred scene, as indicated in phantom in  between block  and block . However, if the use of method  results in well-correlated sub-aperture images, further iterations can be performed by returning to block , as described previously with respect to .","The use of method  eliminates the errors that may propagate through the solution when relative shifts between adjacent sub-apertures are integrated to find the absolute shifts. The error is eliminated by skipping the integration process all-together and directly arriving at an estimation for the absolute shift in X and Y. Unlike previously described correlation based methods that take advantage of robust multiple-aperture-map drift auto-focusing techniques, however, method  still results in a motion estimation that is orders of magnitude higher than that allowable by the previously described methods, and can do so with fewer correlation operations.","Increased robustness can also be found by modifying block  so as to contain overlap between cells. As shown in phantom in , the X and Y shift solutions obtained at block  for the overlapping cells can be differentiated (block ). The overlapping solutions can be averaged and then re-integrated (at blocks  and , respectively) to form a continuous solution.","Still further variants of the methods described herein can use correlations between sub-aperture height-maps obtained from interferometric sensors rather than using intensity images. Also, the robustness of the integration operation through noisy aperture segments can be increased using known optimal adaptive filters such as Kalman filters. Such variants can provide realistic estimations of the platform location in such low correlation regions.","It will be understood that many additional changes in details, steps and arrangements thereof, which have been described herein and illustrated in order to explain the nature of the invention, may be made by those skilled in the art within the principle and scope of the invention as expressed in the appended claims."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["A more complete understanding of the invention and many of the attendant advantages thereto will be readily appreciated as the same becomes better understood by reference to the following detailed description when considered in conjunction with the accompanying drawings wherein like references numerals and symbols designate identical or corresponding parts throughout the several views and wherein:",{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 3"}]},"DETDESC":[{},{}]}
