---
title: Voice code conversion method and apparatus
abstract: It is so arranged that a voice code can be converted even between voice encoding schemes having different subframe lengths. A voice code conversion apparatus demultiplexes a plurality of code components (Lsp Lag Gain Cb), which are necessary to reconstruct a voice signal, from voice code in a first voice encoding scheme, dequantizes the codes of each of the components and converts the dequantized values of code components other than an algebraic code component to code components (Lsp Lag Gp) of a voice code in a second voice encoding scheme. Further, the voice code conversion apparatus reproduces voice from the dequantized values, dequantizes codes that have been converted to codes in the second voice encoding scheme, generates a target signal using the dequantized values and reproduced voice, inputs the target signal to an algebraic code converter and obtains an algebraic code (Cb) in the second voice encoding scheme.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07590532&OS=07590532&RS=07590532
owner: Fujitsu Limited
number: 07590532
owner_city: Kawasaki
owner_country: JP
publication_date: 20021202
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DESCRIPTION OF THE PREFERRED EMBODIMENTS","(A) Overview of the Present Invention","(B) First Embodiment","(C) Second Embodiment","(D) Third Embodiment","(E) Fourth Embodiment"],"p":["This invention relates to a voice code conversion method and apparatus for converting voice code obtained by encoding performed by a first voice encoding scheme to voice code of a second voice encoding scheme. More particularly, the invention relates to a voice code conversion method and apparatus for converting voice code, which has been obtained by encoding voice by a first voice encoding scheme used over the Internet or by a cellular telephone system, etc., to voice code of a second encoding scheme that is different from the first voice encoding scheme.","There has been an explosive increase in subscribers to cellular telephones in recent years and it is predicted that the number of such users will continue to grow in the future. Voice communication using the Internet (Voice over IP, or VoIP) is coming into increasingly greater use in intracorporate IP networks (intranets) and for the provision of long-distance telephone service. In voice communication systems such as cellular telephone systems and VoIP, use is made of voice encoding technology for compressing voice in order to utilize the communication channel effectively.","In the case of cellular telephones, the voice encoding technology used differs depending upon the country or system. With regard to cdma 2000 expected to be employed as the next-generation cellular telephone system, EVRC (Enhanced Variable-Rate Codec) has been adopted as a voice encoding scheme. With VoIP, on the other hand, a scheme compliant with ITU-T Recommendation G.729A is being used widely as the voice encoding method. An overview of G.729A and EVRC will be described first.","(1) Description of G.729A","Encoder Structure and Operation",{"@attributes":{"id":"p-0007","num":"0006"},"figref":["FIG. 15","FIG. 15"],"b":["1","1","1"],"br":[{},{}],"in-line-formulae":[{},{}],"i":["H","z","i\u00b7z","i","P"],"sup":"\u2212i"},"A parameter converter  converts the LPC coefficients to LSP (Line Spectrum Pair) parameters. An LSP parameter is a parameter of a frequency region in which mutual conversion with LPC coefficients is possible. Since a quantization characteristic is superior to LPC coefficients, quantization is performed in the LSP domain. An LSP quantizer  quantizes an LSP parameter obtained by the conversion and obtains an LSP code and an LSP dequantized value. An LSP interpolator  obtains an LSP interpolated value from the LSP dequantized value found in the present frame and the LSP dequantized value found in the previous frame. More specifically, one frame is divided into two subframes, namely first and second subframes, of 5 ms each, and the LPC analyzer  determines the LPC coefficients of the second subframe but not of the first subframe. Using the LSP dequantized value found in the present frame and the LSP dequantized value found in the previous frame, the LSP interpolator  predicts the LSP dequantized value of the first subframe by interpolation.","A parameter deconverter  converts the LSP dequantized value and the LSP interpolated value to LPC coefficients and sets these coefficients in an LPC synthesis filter . In this case, the LPC coefficients converted from the LSP interpolated values in the first subframe of the frame and the LPC coefficients converted from the LSP dequantized values in the second subframe are used as the filter coefficients of the LPC synthesis filter . In the description that follows, the \u201cl\u201d in items having an index attached to the \u201cl\u201d, e.g., lspi, li, . . . , is the letter \u201cl\u201d in the alphabet.","After LSP parameters lspi (i=1, . . . , P) are quantized by scalar quantization or vector quantization in the LSP quantizer , the quantization indices (LSP codes) are sent to the decoder side.  is a diagram useful in describing the quantization method. Here sets of large numbers of quantization LSP parameters have been stored in a quantization table in correspondence with index numbers 1 to n. A distance calculation unit calculates distance in accordance with the following equation:",{"@attributes":{"id":"p-0011","num":"0010"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mi":"d","mo":"=","mrow":{"munder":{"mo":"\u2211","mi":"i"},"mo":"\u2062","mrow":{"msup":{"mrow":{"mo":["{","}"],"mrow":{"mrow":{"mi":"l","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"msub":{"mi":["sp","q"]},"mo":"\u2062","mrow":{"mo":["(",")"],"mi":"i"}}},"mo":"-","mi":"lspi"}},"mn":"2"},"mo":"\u2062","mrow":{"mo":["(",")"],"mrow":{"mi":"i","mo":"=","mrow":{"mn":"1","mo":"\u223c","mi":"P"}}}}}}}},"br":{},"b":"3","i":"c "},"Next, sound-source and gain search processing is executed. Sound source and gain are processed on a per-subframe basis. First, a sound-source signal is divided into a pitch-period component and a noise component, an adaptive codebook  storing a sequence of past sound-source signals is used to quantize the pitch-period component and an algebraic codebook or noise codebook is used to quantize the noise component. Described below will be voice encoding using the adaptive codebook  and an algebraic codebook  as sound-source codebooks.","The adaptive codebook  is adapted to output N samples of sound-source signals (referred to as \u201cperiodicity signals\u201d), which are delayed successively by one sample, in association with indices 1 to L.  is a diagram showing the structure of the adaptive codebook  in the case of a subframe of 40 samples (N=40). The adaptive codebook is constituted by a buffer BF for storing the pitch-period component of the latest (L+39) samples. A periodicity signal comprising 1 to 40 samples is specified by index 1, a periodicity signal comprising 2 to 41 samples is specified by index 2, . . . , and a periodicity signal comprising L to L+39 samples is specified by index L. In the initial state, the content of the adaptive codebook  is such that all signals have amplitudes of zero. Operation is such that a subframe length of the oldest signals is discarded subframe by subframe so that the sound-source signal obtained in the present frame will be stored in the adaptive codebook .","An adaptive-codebook search identifies the periodicity component of the sound-source signal using the adaptive codebook  storing past sound-source signals. That is, a subframe length (=40 samples) of past sound-source signals in the adaptive codebook  are extracted while changing, one sample at a time, the point at which read-out from the adaptive codebook  starts, and the sound-source signals are input to the LPC synthesis filter  to create a pitch synthesis signal \u03b2AP, where Prepresents a past periodicity signal (adaptive code vector), which corresponds to delay L, extracted from the adaptive codebook , A the impulse response of the LPC synthesis filter , and \u03b2 the gain of the adaptive codebook.","An arithmetic unit  finds an error power Ebetween the input voice X and \u03b2APin accordance with the following equation:\n\n|\u2003\u2003(2)\n","If we let APrepresent a weighted synthesized output from the adaptive codebook, Rpp the autocorrelation of APand Rxp the cross-correlation between APand the input signal X, then an adaptive code vector Pat a pitch lag Lopt for which the error power of Equation (2) is minimum will be expressed by the following equation:\n\nmax()\u2003\u2003(3)\n\nThat is, the optimum starting point for read-out from the codebook is that at which the value obtained by normalizing the cross-correlation Rxp between the pitch synthesis signal APand the input signal X by the autocorrelation Rpp of the pitch synthesis signal is largest. Accordingly, an error-power evaluation unit  finds the pitch lag Lopt that satisfies Equation (3). Optimum pitch gain \u03b2opt is given by the following equation:\n\n\u2003\u2003(4)\n","Next, the noise component contained in the sound-source signal is quantized using the algebraic codebook . The latter is constituted by a plurality of pulses of amplitude 1 or \u22121. By way of example,  illustrates pulse positions for a case where frame length is 40 samples. The algebraic codebook  divides the N (=40) sampling points constituting one frame into a plurality of pulse-system groups 1 to 4 and, for all combinations obtained by extracting one sampling point from each of the pulse-system groups, successively outputs, as noise components, pulsed signals having a +1 or a \u22121 pulse at each sampling point. In this example, basically four pulses are deployed per frame.  is a diagram useful in describing sampling points assigned to each of the pulse-system groups 1 to 4.","(1) Eight sampling points 0, 5, 10, 15, 20, 25, 30, 35 are assigned to the pulse-system group 1;","(2) eight sampling points 1, 6, 11, 16, 21, 26, 31, 36 are assigned to the pulse-system group 2;","(3) eight sampling points 2, 7, 12, 17, 22, 27, 32, 37 are assigned to the pulse-system group 3; and","(4) 16 sampling points 3, 4, 8, 9, 13, 14, 18, 19, 23, 24, 28, 29, 33, 34, 38, 39 are assigned to the pulse-system group 4.","Three bits are required to express the sampling points in pulse-system groups 1 to 3 and one bit is required to express the sign of a pulse, for a total of four bits. Further, four bits are required to express the sampling points in pulse-system group  and one bit is required to express the sign of a pulse, for a total of five bits. Accordingly, 17 bits are necessary to specify a pulsed signal output from the noise codebook  having the pulse placement of , and 2types of pulsed signals exist.","The pulse positions of each of the pulse systems are limited, as illustrated in . In the algebraic codebook search, a combination of pulses for which the error power relative to the input voice is minimized in the reconstruction region is decided from among the combinations of pulse positions of each of the pulse systems. More specifically, with \u03b2opt as the optimum pitch gain found by the adaptive-codebook search, the output Pof the adoptive codebook is multiplied by \u03b2opt and the product is input to an adder . At the same time, the pulsed signals are input successively to the adder  from the algebraic codebook  and a pulsed signal is specified that will minimize the difference between the input signal X and a reproduced signal obtained by inputting the adder output to the LPC synthesis filter . More specifically, first a target vector X\u2032 for an algebraic codebook search is generated in accordance with the following equation from the optimum adaptive codebook output Pand optimum pitch gain \u03b2opt obtained from the input signal X by the adaptive-codebook search:\n\n\u2003\u2003(5)\n","In this example, pulse position and amplitude (sign) are expressed by 17 bits and therefore 2combinations exist. Accordingly, letting Crepresent a kth algebraic-code output vector, a code vector Cthat will minimize an evaluation-function error power D in the following equation is found by a search of the algebraic codebook:\n\n|\u2003\u2003(6)\n\nwhere Grepresents the gain of the algebraic codebook. In the algebraic codebook search, the error-power evaluation unit  searches for the combination of pulse position and polarity that will afford the largest normalized cross-correlation value (Rcx*Rcx\/Rcc) obtained by normalizing the square of a cross-correlation value Rcx between an algebraic synthesis signal ACand input signal X\u2032 by an autocorrelation value Rcc of the algebraic synthesis signal. The result output from the algebraic codebook search is the position and sign (positive or negative) of each pulse. These results shall be referred to collectively as algebraic code.\n","Gain quantization will be described next. With the G.729A system, algebraic codebook gain is not quantized directly. Rather, the adaptive codebook gain G(=\u03b2opt) and a correction coefficient \u03b3 of the algebraic codebook gain Gare vector quantized. The algebraic codebook gain Gand the correction coefficient y are related as follows:\n\n\n\nwhere g\u2032 represents the gain of the present frame predicted from the logarithmic gains of the four past subframes.\n","A gain quantizer  has a gain quantization table (gain codebook), not shown, for which there are prepared 128 (=2) combinations of adaptive codebook gain Gand correction coefficients \u03b3 for algebraic codebook gain. The method of the gain codebook search includes {circle around (1)} extracting one set of table values from the gain quantization table with regard to an output vector from the adaptive codebook and an output vector from the algebraic codebook and setting these values in gain varying units , , respectively; {circle around (2)} multiplying these vectors by gains G, Gusing the gain varying units , , respectively, and inputting the products to the LPC synthesis filter ; and {circle around (3)} selecting, by way of the error-power evaluation unit , the combination for which the error power relative to the input signal X is minimized.","A channel encoder  creates channel data by multiplexing {circle around (1)} an LSP code, which is the quantization index of the LSP, {circle around (2)} a pitch-lag code Lopt, {circle around (3)} an algebraic code, which is an algebraic codebook index, and {circle around (4)} a gain code, which is a quantization index of gain. The channel encoder  sends this channel data to a decoder.","Thus, as described above, the G.729A encoding system produces a model of the speech generation process, quantizes the characteristic parameters of this model and transmits the parameters, thereby making it possible to compress speech efficiently.","Decoder Structure and Operation",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 20","b":"21"},"Upon receiving the LSP code as an input, an LSP dequantizer  applies dequantization and outputs an LSP dequantized value. An LSP interpolator  interpolates an LSP dequantized value of the first subframe of the present frame from the LSP dequantized value in the second subframe of the present frame and the LSP dequantized value in the second subframe of the previous frame. Next, a parameter deconverter  converts the LSP interpolated value and the LSP dequantized value to LPC synthesis filter coefficients. A G.729A-compliant synthesis filter  uses the LPC coefficient converted from the LSP interpolated value in the initial first subframe and uses the LPC coefficient converted from the LSP dequantized value in the ensuing second subframe.","An adaptive codebook  outputs a pitch signal of subframe length (=40 samples) from a read-out starting point specified by a pitch-lag code, and a noise codebook  outputs a pulse position and pulse polarity from a read-out position that corresponds to an algebraic code. A gain dequantizer  calculates an adaptive codebook gain dequantized value and an algebraic codebook gain dequantized value from the gain code applied thereto and sets these vales in gain varying units , , respectively. An adder  creates a sound-source signal by adding a signal, which is obtained by multiplying the output of the adaptive codebook by the adaptive codebook gain dequantized value, and a signal obtained by multiplying the output of the algebraic codebook by the algebraic codebook gain dequantized value. The sound-source signal is input to an LPC synthesis filter . As a result, reconstructed speech can be obtained from the LPC synthesis filter .","In the initial state, the content of the adaptive codebook  on the decoder side is such that all signals have amplitudes of zero. Operation is such that a subframe length of the oldest signals is discarded subframe by subframe so that the sound-source signal obtained in the present frame will be stored in the adaptive codebook . In other words, the adaptive codebook  of the encoder and the adaptive codebook  of the decoder are always maintained in the identical, latest state.","(2) Description of EVRC","EVRC is characterized in that the number of bits transmitted per frame is varied in dependence upon the nature of the input signal. More specifically, bit rate is raised in steady segments such as vowel segments and the number of transmitted bits is lowered in silent or transient segments, thereby reducing the average bit rate over time. EVRC bit rates are shown in Table 1.",{"@attributes":{"id":"p-0036","num":"0035"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"7pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"left"}}],"thead":{"row":{"entry":[{},"TABLE 1"]}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]},{"entry":[{},{},"BIT RATE",{},"VOICE SEGMENT"]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"MODE","bits\/frame","kbits\/s","OF INTEREST"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"14pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"3","colwidth":"42pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"FULL RATE","171","8.55","STEADY SEGMENT"]},{"entry":[{},"HALF RATE","80","4.0","VARIABLE"]},{"entry":[{},{},{},{},"SEGMENT"]},{"entry":[{},"\u215b RATE","16","0.8","SILENT SEGMENT"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"4","align":"center","rowsep":"1"}}]}]}}]}}},"With EVRC, the rate of the input signal of the present frame is determined. The rate determination involves dividing the frequency region of an input speech signal into high and low regions and calculating power in each region, comparing the power values of each of these regions with two predetermined threshold values, selecting the full rate if the low-region power and the high-region power exceed the threshold values, selecting the half rate if only the low-region power or high-region power exceeds the threshold value, and selecting the \u215b rate if the low- and high-region power values are both lower than the threshold values.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0039","num":"0038"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"4"},"colspec":[{"@attributes":{"colname":"1","colwidth":"112pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"center"}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"center"}}],"thead":{"row":[{"entry":"TABLE 2"},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}},{"entry":["SUBFRAME NO.","1","2","3"]},{"entry":{"@attributes":{"namest":"1","nameend":"4","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":{}}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"4","colwidth":"35pt","align":"char","char":"."}},{"@attributes":{"colname":"5","colwidth":"35pt","align":"char","char":"."}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["SUBFRAME","NUMBER OF","53","53","54"]},{"entry":["LENGTH","SAMPLES"]},{"entry":[{},"MILLISECONDS","6.625","6.625","6.750"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"As shown in , an LPC (Linear Prediction Coefficient) analyzer  obtains LPC coefficients by LPC analysis using 160 samples of the input signal of the present frame and 80 samples of the pre-read segment, for a total of 240 samples. An LSP quantizer  converts the LPC coefficients to LSP parameters and then performs quantization to obtain LSP code. An LSP dequantizer  obtains an LSP dequantized value from the LSP code. Using the LSP dequantized value found in the present frame (the LSP dequantized value of the third subframe) and the LSP dequantized value found in the previous frame, an LSP interpolator  predicts the LSP dequantized value of the 0, 1and 2subframes of the present frame by linear interpolation.","Next, a pitch analyzer  obtains the pitch lag and pitch gain of the present frame. According to EVRC, pitch analysis is performed twice per frame. The position of the analytical window of pitch analysis is as shown in . The procedure of pitch analysis is as follows:","(1) The input signal of the present frame and the pre-read signal are input to an LPC inverse filter composed of the above-mentioned LPC coefficients, whereby an LPC residual signal is obtained. If H(z) represents the LPC synthesis filter, then the LPC inverse filter is 1\/H(z).","(2) The autocorrelation function of the LPC residual filter is found, and the pitch lag and pitch gain for which the autocorrelation function will be maximized are obtained.","(3) The above-described processing is executed at two analytical window positions. Let Lag and Gain represent the pitch lag and pitch gain found by the first analysis, respectively, and let Lag and Gain represent the pitch lag and pitch gain found by the second analysis, respectively.","(4) When the difference between Gain and Gain is equal to or greater than a predetermined threshold value, Gain and Lag are adopted as the pitch gain and pitch lag, respectively, of the present frame. When the difference between Gain and Gain is less than the predetermined threshold value, Gain and Lag are adopted as the pitch gain and pitch lag, respectively, of the present frame.","The pitch lag and pitch gain are found by the above-described procedure. A pitch-gain quantizer  quantizes the pitch gain using a quantization table and outputs pitch-gain code. A pitch-gain dequantizer  dequantizes the pitch-gain code and inputs the result to a gain varying unit . Whereas pitch lag and pitch gain are obtained on a per-subframe basis with G.729A, EVRC differs in that pitch lag and pitch gain are obtained on a per-frame basis.","Further, EVRC differs in that an input-voice correction unit  corrects the input signal in dependence upon the pitch-lag code. That is, rather than finding the pitch lag and pitch gain for which error relative to the input signal is smallest, as is done in accordance with G.729A, the input-voice correction unit  in EVRC corrects the input signal in such a manner that it will approach closest to the output of the adaptive codebook decided by the pitch lag and pitch gain found by pitch analysis. More specifically, the input-voice correction unit  converts the input signal to a residual signal by an LPC inverse filter and time-shifts the position of the pitch peak in the region of the residual signal in such a manner that the position will be the same as the pitch-peak position in the output of an adaptive codebook .","Next, a noise-like sound-source signal and gain are decided on a per-subframe basis. First, an adaptive-codebook synthesized signal obtained by passing the output of an adaptive codebook  through the gain varying unit  and an LPC synthesis filter  is subtracted from the corrected input signal, which is output from the input-voice correction unit , by an arithmetic unit , thereby generating a target signal X\u2032 of an algebraic codebook search. An EVRC adaptive codebook  is composed of a plurality of pulses, in a manner similar to that of G.729A, and 35 bits per subframe are allocated in the full-rate case. Table 3 below illustrates the full-rate pulse positions.",{"@attributes":{"id":"p-0049","num":"0048"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 3"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"EVRC ALGEBRAIC CODEBOOK (FULL RATE)"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"84pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["PULSE SYSTEM","PULSE POSITION","POLARITY"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["T0","0, 5, 10, 15, 20, 25,","+\/\u2212"]},{"entry":[{},"30, 35, 40, 45, 50"]},{"entry":["T1","1, 6, 11, 16, 21, 26,","+\/\u2212"]},{"entry":[{},"31, 36, 41, 46, 51"]},{"entry":["T2","2, 7, 12, 17, 22, 27,","+\/\u2212"]},{"entry":[{},"32, 37, 42, 47, 52"]},{"entry":["T3","3, 8, 13, 18, 23, 28,","+\/\u2212"]},{"entry":[{},"33, 38, 43, 48, 53"]},{"entry":["T4","4, 9, 14, 19, 24, 29,","+\/\u2212"]},{"entry":[{},"34, 39, 44, 49, 54"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"The method of searching the algebraic codebook is similar to that of G.729A, though the number of pulses selected from each pulse system differs. Two pulses are assigned to three of the five pulse systems, and one pulse is assigned to two of the five pulse systems. Combinations of systems that assign one pulse are limited to four, namely T3-T4, T4-T0, T0-T1 and T1-T2. Accordingly, combinations of pulse systems and pulse numbers are as shown in Table 4 below.",{"@attributes":{"id":"p-0051","num":"0050"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 4"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"PULSE-SYSTEM COMBINATIONS"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"ONE-PULSE","TWO-PULSE"]},{"entry":[{},"SYSTEMS","SYSTEMS"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"77pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["(1)","T3, T4","T0, T1, T2"]},{"entry":["(2)","T4, T0","T1, T2, T3"]},{"entry":["(3)","T0, T1","T2, T3, T4"]},{"entry":["(4)","T1, T2","T3, T4, T0"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"Thus, since there are systems that assign one pulse and systems that assign two pulses, the number of bits allocated to each pulse system differs depending upon the number of pulses. Table 5 below indicates the bit distribution of the algebraic codebook in the full-rate case.",{"@attributes":{"id":"p-0053","num":"0052"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 5"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"BIT DISTRIBUTION OF EVRC ALGEBRAIC CODEBOOK"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["NUMBER OF",{},"BIT"]},{"entry":["PULSES","INFORMATION","DISTRIBUTION"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["ONE PULSE","COMBINATIONS","\u20022 BITS (FOUR)"]},{"entry":[{},"PULSE POSITIONS","\u20027 BITS (11 \u00d7 11) ="]},{"entry":[{},{},"121 < 128"]},{"entry":[{},"POLARITY","\u20022 BITS"]},{"entry":["TWO PULSES","PULSE POSITIONS","21 BITS (7 \u00d7 3)"]},{"entry":[{},"POLARITY (SAME AS","\u20023 BITS (3 \u00d7 1)"]},{"entry":[{},"THAT OF ONE-PULSE"]},{"entry":[{},"SYSTEM",{}]},{"entry":[{},"TOTAL","35 BITS"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"Since combinations of one-pulse systems are four in number, two bits are necessary. If 11 pulse positions in two pulse systems in which the number of pulses is one are arrayed in the X and Y directions, an 11\u00d711 grid can be formed and a pulse position in the two pulse systems can be specified by one grid point. Accordingly, seven bits are necessary to specify a pulse position in two pulse systems in which the number of pulses is one, and two bits are necessary to express the polarity of a pulse in two pulse systems in which the number of pulses is one. Further, 7\u00d73 bits are necessary to specify a pulse position in three pulse systems in which the number of pulses is two, and 1\u00d73 bits are necessary to express the polarity of a pulse in three pulse systems in which the number of pulses is two. It should be noted that the polarity of pulses in the one-pulse systems is the same. Thus, in EVRC, an algebraic codebook can be expressed by a total of 35 bits.","In the algebraic codebook search, the algebraic codebook  generates an algebraic synthesis signal by successively inputting pulsed signals to a gain multiplier  and LPC synthesis filter , and an arithmetic unit  calculates the difference between the algebraic synthesis signal and target signal X\u2032 and obtains the code vector Ck that will minimize the evaluation-function error power D in the following equation:\n\n|\n\nwhere Grepresents the gain of the algebraic codebook. In the algebraic codebook search, an error-power evaluation unit  searches for the combination of pulse position and polarity that will afford the largest normalized cross-correlation value (Rcx*Rcx\/Rcc) obtained by normalizing the square of a cross-correlation value Rcx between the algebraic synthesis signal ACand target signal X\u2032 by an autocorrelation value Rcc of the algebraic synthesis signal.\n","Algebraic codebook gain is not quantized directly. Rather, the correction coefficient \u03b3 of the algebraic codebook gain is scalar quantized by five bits per subframe. The correction coefficient \u03b3 is a value (\u03b3=Gc\/g\u2032) obtained by normalizing algebraic codebook gain Gc by g\u2032, where g\u2032 represents gain predicted from past subframes.","A channel multiplexer  creates channel data by multiplexing {circle around (1)} an LSP code, which is the quantization index of the LSP, {circle around (2)} a pitch-lag code, {circle around (3)} an algebraic code, which is an algebraic codebook index, {circle around (4)} a pitch-gain code, which is the quantization index of the pitch gain, and {circle around (5)} an algebraic codebook gain code, which is the quantization index of algebraic codebook gain. The multiplexer  sends the channel data to a decoder.","It should be noted that the decoder is so adapted as to decode the LSP code, pitch-lag code, algebraic code, pitch-gain code and algebraic codebook gain code sent from the encoder. The EVRC decoder can be created in a manner similar to that in which a G.729 decoder is created to deal with a G.729 encoder. The EVRC decoder, therefore, need not be described here.","(3) Conversion of Voice Code According to the Prior Art","It is believed that the growing popularity of the Internet and cellular telephones will lead to ever increasing voice traffic by Internet users and users of cellular telephone networks. However, communication between a cellular telephone network and the Internet cannot take place if a voice encoding scheme used by the cellular telephone network and a voice encoding scheme used by the Internet differ.",{"@attributes":{"id":"p-0061","num":"0060"},"figref":"FIG. 30","b":["71","72","71","71","1","72","72","2"],"i":["a ","a "]},"Voice that has been produced by user A on the transmitting side is input to the encoder of encoding scheme  incorporated in terminal . The encoder encodes the input speech signal to a voice code of the encoding scheme  and outputs this code to a transmission path . When the voice code enters via the transmission path , a decoder of the voice code converter  decodes reproduced voice from the voice code of encoding scheme . An encoder of the voice code converter  then converts the reconstructed speech signal to voice code of the encoding scheme  and sends this voice code to a transmission path . The voice code of the encoding scheme  is input to the terminal  through the transmission path . Upon receiving the voice code as an input, the decoder decodes reconstructed speech from the voice code of the encoding scheme . As a result, the user B on the receiving side is capable of hearing the reconstructed speech. Processing for decoding voice that has first been encoded and then re-encoding the decoded voice is referred to as \u201ctandem connection\u201d.","With the implementation of prior art 1, as described above, the practice is to rely upon the tandem connection in which a voice code that has been encoded by voice encoding scheme  is decoded into voice temporarily, after which the decoded voice is re-encoded by voice encoding scheme . Problems arise as a consequence, namely a pronounced decline in the quality of reconstructed speech and an increase in delay. In other words, voice (reconstructed speech) that has been encoded and compressed in terms of information content is voice having less information than that of the original voice (original sound). Hence the sound quality of the reconstructed speech is much poorer than that of the original sound. In particular, with recent low-bit-rate voice encoding schemes typified by G.729A and EVRC, encoding is performed while discarding a great deal of information contained in the input voice in order to realize a high compression rate. When use is made of a tandem connection in which encoding and decoding are repeated, the quality of reconstructed speed undergoes a market decline.","A technique proposed as a method of solving this problem of the tandem connection decomposes voice code into parameter codes such as LSP code and pitch-lag code without returning the voice code to a speech signal, and converts each parameter code separately to a code of a separate voice encoding scheme (see the specification of Japanese Patent Application No. 2001-75427).  is a diagram illustrating the principle of this proposal, which shall be referred to as \u201cprior art 2\u201d below.","Encoder of encoding scheme  incorporated in terminal  encodes a speech signal produced by user A to a voice code of encoding scheme  and sends this voice code to transmission path . A voice code conversion unit  converts the voice code of encoding scheme  that has entered from the transmission path to a voice code of encoding scheme  and sends this voice code to transmission path . Decoder in terminal  decodes reconstructed speech from the voice code of encoding scheme  that enters via the transmission path , and user B is capable of hearing the reconstructed speech.","The encoding scheme  encodes a speech signal by {circle around (1)} a first LSP code obtained by quantizing LSP parameters, which are found from linear prediction coefficients (LPC) obtained by frame-by-frame linear prediction analysis; {circle around (2)} a first pitch-lag code, which specifies the output signal of an adaptive codebook that is for outputting a periodic sound-source signal; {circle around (3)} a first algebraic code (noise code), which specifies the output signal of an algebraic codebook (or noise codebook) that is for outputting a noise-like sound-source signal; and {circle around (4)} a first gain code obtained by quantizing pitch gain, which represents the amplitude of the output signal of the adaptive codebook, and algebraic codebook gain, which represents the amplitude of the output signal of the algebraic codebook. The encoding scheme  encodes a speech signal by {circle around (1)} a second LPC code, {circle around (2)} a second pitch-lag code, {circle around (3)} a second algebraic code (noise code) and {circle around (4)} a second gain code, which are obtained by quantization in accordance with a quantization method different from that of voice encoding scheme .","The voice code conversion unit  has a code demultiplexer , an LSP code converter , a pitch-lag code converter , an algebraic code converter a gain code converter and a code multiplexer The code demultiplexer demultiplexes the voice code of voice encoding scheme , which code enters from the encoder of terminal  via the transmission path , into codes of a plurality of components necessary to reconstruct a speech signal, namely {circle around (1)} LSP code, {circle around (2)} pitch-lag code, {circle around (3)} algebraic code and {circle around (4)} gain code. These codes are input to the code converters , and , respectively. The latter convert the entered LSP code, pitch-lag code, algebraic code and gain code of voice encoding scheme  to LSP code, pitch-lag code, algebraic code and gain code of voice encoding scheme , and the code multiplexer multiplexes these codes of voice encoding scheme  and sends the multiplexed signal to the transmission path ",{"@attributes":{"id":"p-0068","num":"0067"},"figref":["FIG. 25","FIG. 25"],"b":["74","74","74","24","74","1","1","1","1","1","1","74","74","74","74"],"i":["b ","e ","a ","b","c, ","d ","e"]},"The LSP code converter has an LSP dequantizer for dequantizing the LSP code  of encoding scheme  and outputting an LSP dequantized value, and an LSP quantizer for quantizing the LSP dequantized value using an algebraic code quantization table of encoding scheme  and outputting an LSP code . The pitch-lag code converter has a pitch-lag dequantizer for dequantizing the pitch-lag code  of encoding scheme  and outputting a pitch-lag dequantized value, and a pitch-lag quantizer for quantizing the pitch-lag dequantized value by encoding scheme  and outputting a pitch-lag code . The algebraic code converter has an algebraic dequantizer for dequantizing the algebraic code  of encoding scheme  and outputting an algebraic dequantized value, and an algebraic quantizer for quantizing the algebraic dequantized value using an algebraic code quantization table of encoding scheme  and outputting an algebraic code . The gain code converter has a gain dequantizer for dequantizing the gain code  of encoding scheme  and outputting a gain dequantized value, and a gain quantizer for quantizing the gain dequantized value using a gain quantization table of encoding scheme  and outputting a gain code .","The code multiplexer multiplexes the LSP code , pitch-lag code , algebraic code  and gain code , which are output from the quantizers , , and , respectively, thereby creating a voice code based upon encoding scheme , and sends this code to the transmission path from an output terminal #.","The tandem connection scheme (prior art 1) of FIG.  receives an input of reproduced speech, which is obtained by temporarily decoding, to voice, voice code that has been encoded by encoding scheme , and executes encoding and decoding again. As a result, voice parameters are extracted from reproduced speech in which the amount of information is much less than that of the original sound owing to re-execution of encoding (namely compression of voice information). Consequently, the voice code thus obtained is not necessarily the best. By contrast, in accordance with the voice encoding apparatus of prior art 2 shown in , voice code of encoding scheme  is converted to voice code of encoding scheme  via the process of dequantization and quantization. This makes it possible to perform voice code conversion in which there is much less degradation in comparison with the tandem connection of prior art 1. Further, since it is unnecessary to decode to voice even once for the sake of voice code conversion, another advantage is that delay, which is a problem with the tandem connection, is reduced.","In a VoIP network, G.729A is used as the voice encoding scheme. In a cdma 2000 network, on the other hand, which is expected to served as a next-generation cellular telephone system, EVRC is adopted. Table 6 below indicates results obtained by comparing the main specifications of G.729A and EVRC.",{"@attributes":{"id":"p-0073","num":"0072"},"tables":{"@attributes":{"id":"TABLE-US-00006","num":"00006"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 6"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"COMPARISON OF G.729A AND EVRC MAIN SPECIFICATIONS"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"42pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"G.729A","EVRC"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"2","align":"center","rowsep":"1"}}]}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"5"},"colspec":[{"@attributes":{"colname":"1","colwidth":"91pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"21pt","align":"right"}},{"@attributes":{"colname":"3","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"4","colwidth":"56pt","align":"right"}},{"@attributes":{"colname":"5","colwidth":"28pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["SAMPLING FREQUENCY","8","kHz","8","kHz"]},{"entry":["FRAME LENGTH","10","ms","20","ms"]},{"entry":["SUBFRAME LENGTH","5","ms","6.625\/6.625\/6.75","ms"]},{"entry":["NUMBER OF SUBFRAMES","2",{},"3"]},{"entry":{"@attributes":{"namest":"1","nameend":"5","align":"center","rowsep":"1"}}}]}}]}}},"Frame length and subframe length according to G.729A are 10 ms and 5 ms, respectively, while EVRC frame length is 20 ms and is segmented into three subframes. This means that EVRC subframe length is 6.625 ms (only the final subframe has a length of 6.75 ms), and that both frame length and subframe length differ from those of G.729A. Table 7 below indicates the results obtained by comparing bit allocation of G.729A with that of EVRC.",{"@attributes":{"id":"p-0075","num":"0074"},"tables":{"@attributes":{"id":"TABLE-US-00007","num":"00007"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"thead":{"row":{"entry":"TABLE 7"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"G.729A AND EVRC BIT ALLOCATION"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"center"}},{"@attributes":{"colname":"3","colwidth":"70pt","align":"center"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"G.729A","EVRC (FULL RATE)"]},{"entry":["PARAMETER","SUBFRAME\/FRAME","SUBFRAME\/FRAME"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["LSP CODE","\u2014\/18","\u2014\/29"]},{"entry":["PITCH-LAG CODE","8, 5\/13","\u2014\/12"]},{"entry":["PITCH-GAIN CODE","\u2014","3, 3, 3\/9"]},{"entry":["ALGEBRAIC CODE","17, 17\/34","35, 35, 35\/105"]},{"entry":["ALGEBRAIC CODE","\u2014","5, 5, 5\/15"]},{"entry":"GAIN CODE"},{"entry":["GAIN CODE","7, 7\/14","\u2014"]},{"entry":["NOT ASSIGNED","\u2014","\u2014\/1"]},{"entry":["TOTAL","80 BITS\/10 ms","171 BITS\/20 ms"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}}},"In a case where voice communication is performed between a VoIP network and a network compliant with cdma 2000, a voice code conversion technique for converting one voice code to another voice code is required. The above-described examples of prior art 1 and prior art 2 are known as techniques used in such case.","With prior art 1, speech is reconstructed temporarily from voice code according to voice encoding scheme , and the reconstructed speech is applied as an input and encoded again according to voice encoding scheme . This makes it possible to convert code without being affected by the difference between the two encoding schemes. However, when the re-encoding is performed according to this method, certain problems arise, namely pre-reading (i.e., delay) of signals owing to LPC analysis and pitch analysis, and a major decline in sound quality.","With voice code conversion according to prior art 2, a conversion to voice code is made on the assumption that subframe length in encoding scheme  and subframe length in encoding scheme  are equal, and therefore a problem arises in code conversion in a case where the subframe lengths of the two encoding schemes differ. That is, since the algebraic codebook is such that pulse position candidates are decided in accordance with subframe length, pulse positions are completely different between schemes (G.729A and EVRC) having different subframe lengths, and it is difficult to make pulse positions correspond on a one-to-one basis.","Accordingly, an object of the present invention is to make it possible to perform a voice code conversion even between voice encoding schemes having different subframe lengths.","Another object of the present invention is to make it possible to reduce a decline in sound quality and, moreover, to shorten delay time.","According to a first aspect of the present invention, the foregoing objects are attained by providing a voice code conversion system for converting a voice code obtained by encoding performed by a first voice encoding scheme to a voice code of a second voice encoding scheme. The voice code conversion system includes a code demultiplexer for demultiplexing, from the voice code based on the first voice encoding scheme, a plurality of code components necessary to reconstruct a voice signal; and a code converter for dequantizing the codes of each of the components, outputting dequantized values and converting the dequantized values of code components other than an algebraic code to code components of a voice code of the second voice encoding scheme. Further, a voice reproducing unit reproduces voice using each of the dequantized value, a target generating unit dequantizes each code component of the second voice encoding scheme and generates a target signal using each dequantized value and reproduced voice, and an algebraic code converter obtains an algebraic code of the second voice encoding scheme using the target signal. In addition, a code multiplexer multiplexes and outputs code components in the second voice encoding scheme.","More specifically, the first aspect of the present invention is a voice code conversion system for converting a first voice code, which has been obtained by encoding a voice signal by an LSP code, pitch-lag code, algebraic code and gain code based upon a first voice encoding scheme, to a second voice code based upon a second voice encoding scheme. According to this voice code conversion system, LSP code, pitch-lag code and gain code of the first voice code are dequantized and the dequantized values are quantized by the second voice encoding scheme to acquire LSP code, pitch-lag code and gain code of the second voice code. Next, a pitch-periodicity synthesis signal is generated using the dequantized values of the LSP code, pitch-lag code and gain code of the second voice encoding scheme, a voice signal is reproduced from the first voice code, and a difference signal between the reproduced voice signal and pitch-periodicity synthesis signal is generated as a target signal. Thereafter, an algebraic synthesis signal is generated using any algebraic code in the second voice encoding scheme and a dequantized value of LSP code of the second voice code, and an algebraic code in the second voice encoding scheme that minimizes the difference between the target signal and the algebraic synthesis signal is acquired. The acquired LSP code, pitch-lag code, algebraic code and gain code in the second voice encoding scheme are multiplexed and output.","If this arrangement is adopted, it is possible to perform a voice code conversion even between voice encoding schemes having different subframe lengths. Moreover, a decline in sound quality can be reduced and delay time shortened. More specifically, voice code according to the G.729A encoding scheme can be converted to voice code according to the EVRC encoding scheme.","According to a second aspect of the present invention, the foregoing objects are attained by providing a voice code conversion system for converting a first voice code, which has been obtained by encoding a speech signal by LSP code, pitch-lag code, algebraic code, pitch-gain code and algebraic codebook gain code based upon a first voice encoding scheme, to a second voice code based upon a second voice encoding scheme. According to this voice code conversion system, each code constituting the first voice code is dequantized and dequantized values of LSP code and pitch-lag code and gain code of the first voice code are quantized by the second voice encoding scheme to acquire LSP code and pitch-lag code of the second voice code. Further, a dequantized value of pitch-gain code of the second voice code is calculated by interpolation processing using a dequantized value of pitch-gain code of the first voice code. Next, a pitch-periodicity synthesis signal is generated using the dequantized values of the LSP code, pitch-lag code and pitch gain of the second voice code, a voice signal is reproduced from the first voice code, and a difference signal between the reproduced voice signal and pitch-periodicity synthesis signal is generated as a target signal. Thereafter, an algebraic synthesis signal is generated using any algebraic code in the second voice encoding scheme and a dequantized value of LSP code of the second voice code, and an algebraic code in the second voice encoding scheme that will minimize the difference between the target signal and the algebraic synthesis signal is acquired. Next, gain code of the second voice code obtained by combining the pitch gain and algebraic codebook gain is acquired by the second voice encoding scheme using the dequantized value of the LSP code of the second voice code, the pitch-lag code and algebraic code of the second voice code, and the target signal. The acquired LSP code, pitch-lag code, algebraic code and gain code in the second voice encoding scheme are output.","If the arrangement described above is adopted, it is possible to perform a voice code conversion even between voice encoding schemes having different subframe lengths. Moreover, a decline in sound quality can be reduced and delay time shortened. More specifically, voice code according to the EVRC encoding scheme can be converted to voice code according to the G.729A encoding scheme.","Other features and advantages of the present invention will be apparent from the following description taken in conjunction with the accompanying drawings.",{"@attributes":{"id":"p-0112","num":"0111"},"figref":["FIG. 1","FIG. 1"],"b":["1","1","2","2"]},"The present invention converts LSP code, pitch-lag code and pitch-gain code from encoding scheme  to encoding scheme  in a quantization parameter region through a method similar to that of prior art 2, creates a target signal from reproduced voice and a pitch-periodicity synthesis signal, and obtains an algebraic code and algebraic codebook gain in such a manner that error between the target signal and algebraic synthesis signal is minimized. Thus the invention is characterized in that a conversion is made from encoding scheme  to encoding scheme . The details of the conversion procedure will now be described.","When voice code CODE according to encoding scheme  (G.729A) is input to a code demultiplexer , the latter demultiplexes the voice code CODE into the parameter codes of an LSP code Lsp, pitch-lag code Lag, pitch-gain code Gain and algebraic code Cb, and inputs these parameter codes to an LSP code converter , pitch-lag converter , pitch-gain converter  and speech reproduction unit , respectively.","The LSP code converter  converts the LSP code Lsp to LSP code Lsp of encoding scheme , the pitch-lag converter  converts the pitch-lag code Lag to pitch-lag code Lag of encoding scheme , and the pitch-gain converter  obtains a pitch-gain dequantized value from the pitch-gain code Gain and converts the pitch-gain dequantized value to a pitch-gain code Gp of encoding scheme .","The speech reproduction unit  reproduces a speech signal Sp using the LSP code Lsp, pitch-lag code Lag, pitch-gain code Gain and algebraic code Cb, which are the code components of the voice code CODE. A target creation unit  creates a pitch-periodicity synthesis signal of encoding scheme  from the LSP code Lsp, pitch-lag code Lag and pitch-gain code Gp of voice encoding scheme . The target creation unit  then subtracts the pitch-periodicity synthesis signal from the speech signal Sp to create a target signal Target.","An algebraic code converter  generates an algebraic synthesis signal using any algebraic code in the voice encoding scheme  and a dequantized value of the LSP code Lsp of voice encoding scheme  and decides an algebraic code Cb of voice encoding scheme  that will minimize the difference between the target signal Target and this algebraic synthesis signal.","An algebraic codebook gain converter  inputs an algebraic codebook output signal that conforms to the algebraic code Cb of voice encoding scheme  to an LPC synthesis filter constituted by the dequantized value of the LSP code Lsp, thereby creating an algebraic synthesis signal, decides algebraic codebook gain from this algebraic synthesis signal and the target signal, and generates algebraic codebook gain code Gc using a quantization table compliant with encoding scheme .","A code multiplexer  multiplexes the LSP code Lsp, pitch-lag code Lag, pitch-gain code Gp, algebraic code Cb and algebraic codebook gain code Gc of encoding scheme  obtained as set forth above, and outputs these codes as voice code CODE of encoding scheme .",{"@attributes":{"id":"p-0120","num":"0119"},"figref":["FIG. 2","FIG. 2","FIG. 1"],"b":["1","2"]},"Since frame length is 10 ms in G.729A and 20 ms in EVRC, two frames of voice code in G.729A is converted one frame of voice code in EVRC. A case will now be described in which voice code of an nth frame and (n+1)th frame of G.729A shown in (a) of  is converted to voice code of an mth frame in EVRC shown in (b) of .","In , an nth frame of voice code (channel data) CODE(n) is input from a G.729A-compliant encoder (not shown) to a terminal # via a transmission path. The code demultiplexer  demultiplexes LSP code Lsp(n), pitch-lag code Lag(n,j), gain code Gain(n,j) and algebraic code Cb(n,j) from the voice code CODE(n) and inputs these codes to the converters , ,  and an algebraic code dequantizer , respectively. The index \u201cj\u201d within the parentheses represents the number of a subframe [see (a) in ] and takes on a value of 0 or 1.","The LSP code converter 102 has an LSP dequantizer and an LSP quantizer . As mentioned above, the G.729A frame length is 10 ms, and a G.729A encoder quantizes an LSP parameter, which has been obtained from an input signal of the first subframe, only once in 10 ms. By contrast, EVRC frame length is 20 ms, and an EVRC encoder quantizes an LSP parameter, which has been obtained from an input signal of the second subframe and pre-read segment, once every 20 ms. In other words, if the same 20 ms is considered as the unit time, the G.729A encoder performs LSP quantization twice whereas the EVRC encoder performs quantization only once. As a consequence, two consecutive frames of LSP code in G.729A cannot be converted to EVRC-compliant LSP code as is.","Accordingly, in the first embodiment, the arrangement is such that only LSP code in a G.729A-compliant odd-numbered frame [(n+1)th frame] is converted to EVRC-compliant LSP code; LSP code in a G.729A-compliant even-numbered frame (nth frame) is not converted. However, it can also be so arranged that LSP code in a G.729A-compliant even-numbered frame is converted to EVRC-compliant LSP code, while LSP code in a G.729A-compliant odd-numbered frame is not converted.","When the LSP code Lsp(n) is input to the LSP dequantizer , the latter dequantizes this code and outputs an LSP dequantized value lsp, where lsp is a vector comprising ten coefficients. Further, the LSP dequantizer performs an operation similar to that of the dequantizer used in a G.729A-compliant decoder.","When the LSP dequantized value lsp of an odd-numbered frame enters the LSP quantizer , the latter performs quantization in accordance with the EVRC-compliant LSP quantization method and outputs an LSP code Lsp(m). Though the LSP quantizer need not necessarily be exactly the same as the quantizer used in the EVRC encoder, at least its LSP quantization table is the same as the EVRC quantization table. It should be noted that an LSP dequantized value of an even-numbered frame is not used in LSP code conversion. Further, the LSP dequantized value lsp is used as a coefficient of an LPC synthesis filter in the speech reproduction unit , described later.","Next, using linear interpolation, the LSP quantizer obtains LSP parameters lsp(k) (k=0, 1, 2) in three subframes of the present frame from an LSP dequantized value, which is obtained by decoding the LSP code Lsp(m) resulting from the conversion, and an LSP dequantized value obtained by decoding an LSP code Lsp(m\u22121) of the preceding frame. Here lsp(k) is used by the target creation unit , etc., described later, and is a 10-dimensional vector.","The pitch-lag converter  has a pitch-lag dequantizer and a pitch-lag quantizer According to the G.729A scheme, pitch lag is quantized every 5-ms subframe. With EVRC, on the other hand, pitch lag is quantized once in one frame. If 20 ms is considered as the unit time, G.729A quantizes four pitch lags, while EVRC quantizes only one. Accordingly, in a case where G.729A voice code is converted to EVRC voice code, all pitch lags in G.729A cannot be converted to EVRC pitch lag.","Accordingly, in the first embodiment, pitch lag lag is found by quantizing pitch-lag code Lag(n+1, 1) in the final subframe (first subframe) of a G.729A (n+1)th frame by the G.729A pitch-lag dequantizer and the pitch lag lag is quantized by the pitch-lag quantizer to obtain the pitch-lag code Lag(m) in the second subframe of the mth frame. Further, the pitch-lag quantizer interpolates pitch lag by a method similar to that of the encoder and decoder of the EVRC scheme. That is, the pitch-lag quantizer finds pitch-lag interpolated values lag(k) (k=0, 1, 2) of each of the subframes by linear interpolation between a pitch-lag dequantized value of the second subframe obtained by dequantizing Lag(m) and a pitch-lag dequantized value of the second subframe of the preceding frame. These pitch-lag interpolated values are used by the target creation unit , described later.","The pitch-gain converter  has a pitch-gain dequantizer and a pitch-gain quantizer According to G.729A, pitch gain is quantized every 5-ms subframe. If 20 ms is considered to be the unit time, therefore, G.729A quantizes four pitch gains in one frame, while EVRC quantizes three pitch gains in one frame. Accordingly, in a case where G.729A voice code is converted to EVRC voice code, all pitch gains in G.729A cannot be converted to EVRC pitch gains. Hence, in the first embodiment, gain conversion is carried out by the method shown in . Specifically, pitch gain is synthesized in accordance with the following equations:\n\ngp2(0)=gp1(0)\n\n2(1)1(1)(2)]\/2\n\ngp2(2)=gp1(3)\n\nwhere gp(), gp(), gp(), gp() represent the pitch gains of two consecutive frames in G.729A. The synthesized pitch gains gp(k) (k=0, 1, 2) are scalar quantized using an EVRC pitch-gain quantization table, whereby pitch-gain code Gp(m,k) is obtained. The pitch gains gp(k) (k=0, 1, 2) are used by the target creation unit , described later.\n","The algebraic code dequantizer  dequantizes an algebraic code Cb(n,j) and inputs an algebraic code dequantized value cb(j) obtained to the speech reproduction unit .","The speech reproduction unit  creates G.729A-compliant reproduced speech Sp(n,h) in an nth frame and G.729A-compliant reproduced speech Sp(n+1,h) in an (n+1)th frame. The method of creating reproduced speech is the same as the operation performed by a G.729A decoder and has already been described in the section pertaining to the prior art; no further description is given here. The number of dimensions of the reproduced speech Sp(n,h) and Sp(n+1,h) is 80 samples (h=1 to 80), which is the same as the G.729A frame length, and there are 160 samples in all. This is the number of samples per frame according to EVRC. The speech reproduction unit  partitions the reproduced speech Sp(n,h) and Sp(n+1,h) thus created into three vectors Sp(,i), Sp(,i), Sp(,i), as shown in , and outputs the vectors. Here i is 1 to 53 in 0and 1subframes and 1 to 54 in the 2subframe.","The target creation unit  creates a target signal Target(k,i) used as a reference signal in the algebraic code converter  and algebraic codebook gain converter .  is a block diagram of the target creation unit . An adaptive codebook outputs N sample signals acb(k,i) (i=0 to N\u22121) corresponding to the pitch lag lag(k) obtained by the pitch-lag converter . Here k represents the EVRC subframe number, and N stands for the EVRC subframe length, which is 53 in 0and 1subframes and 54 in the 2subframe. Unless stated otherwise, the index i is 53 or 54. Numeral denotes an adaptive codebook updater.","A gain multiplier multiplies the adaptive codebook output acb(k,i) by pitch gain gp(k) and inputs the product to an LPC synthesis filter The latter is constituted by the dequantized value lsp(k) of the LSP code and outputs an adaptive codebook synthesis signal syn(k,i). A multiplier obtains a target signal Target(k,i) by subtracting the adaptive codebook synthesis signal syn(k,i) from the speech signal Sp(k,i), which has been partitioned into three parts. The signal Target(k,i) is used in the algebraic code converter  and algebraic codebook gain converter , described below.","The algebraic code converter  executes processing exactly the same as that of an algebraic code search in EVRC.  is a block diagram of the algebraic code converter . An algebraic codebook outputs any pulsed sound-source signal that can be produced by a combination of pulse positions and polarity shown in Table 3. Specifically, if output of a pulsed sound-source signal conforming to a prescribed algebraic code is specified by an error evaluation unit , the algebraic codebook inputs a pulsed sound-source signal conforming to the specified algebraic code to an LPC synthesis filter . When the algebraic codebook output signal is input to the LPC synthesis filter , the latter, which is constituted by the dequantized value lsp(k) of the LSP code, creates and outputs an algebraic synthesis signal alg(k,i). The error evaluation unit calculates a cross-correlation value Rcx between the algebraic synthesis signal alg(k,i) and target signal Target(k,i) as well as an autocorrelation value Rcc of the algebraic synthesis signal, searches for an algebraic code Cb(m,k) that will afford the largest normalized cross-correlation value (Rcx\u00b7Rcx\/Rcc) obtained by normalizing the square of Rcx by Rcc, and outputs this algebraic code.","The algebraic codebook gain converter  has the structure shown in . An algebraic codebook generates a pulsed sound-source signal that corresponds to the algebraic code Cb(m,k) obtained by the algebraic code converter , and inputs this signal to an LPC synthesis filter . When the algebraic codebook output signal is input to the LPC synthesis filter , the latter, which is constituted by the dequantized value lsp(k) of the LSP code, creates and outputs an algebraic synthesis signal gan(k,i). An algebraic codebook gain calculation unit obtains a cross-correlation value Rcx between the algebraic synthesis signal gan(k,i) and target signal Target(k,i) as well as an autocorrelation value Rcc of the algebraic synthesis signal, then normalizes Rcx by Rcc to find algebraic codebook gain gc(k) (=Rcx\/Rcc). An algebraic codebook gain quantizer scalar quantizes the algebraic codebook gain gc(k) using an EVRC algebraic codebook gain quantization table According to EVRC, 5 bits (32 patterns) per subframe are allocated as quantization bits of algebraic codebook gain. Accordingly, a table value closest to gc(k) is found from among these 32 table values and the index value prevailing at this time is adopted as an algebraic codebook gain code Gc(m,k) resulting from the conversion.","The adaptive codebook () is updated after the conversion of pitch-lag code, pitch-gain code, algebraic code and algebraic codebook gain code with regard to one subframe in EVRC. In the initial state, signals all having an amplitude of zero are stored in the adaptive codebook . When the processing for subframe conversion is completed, the adaptive codebook updater discards a subframe length of the oldest signals from the adaptive codebook, shifts the remaining signals by the subframe length and stores the latest sound-source signal prevailing immediately after conversion in the adaptive codebook. The latest sound-source signal is a sound-source signal that is the result of combining a periodicity sound-source signal conforming to the pitch-lag code lag(k) and pitch gain gp(k) after conversion and a noise-like sound-source signal conforming to the algebraic code Cb(m,k) and algebraic codebook gain gc(k) after conversion.","Thus, if the LSP code Lsp(m), pitch-lag code Lag(m), pitch-gain code Gp(m,k), algebraic code Cb(m,k) and algebraic codebook gain code Gc(m,k) in the EVRC scheme are found, then the code multiplexer  multiplexes these codes, combines them into a single code and outputs this code as a voice code CODE(m) of encoding scheme .","According to the first embodiment, the LSP code, pitch-lag code and pitch-gain code are converted in the quantization parameter region. As a result, in comparison with the case where reproduced speech is subjected to LPC analysis and pitch analysis again, analytical error is reduced and parameter conversion with less degradation of sound quality can be carried out. Further, since reproduced speech is not subjected to LSP analysis and pitch analysis again, the problem of prior art 1, namely delay ascribable to code conversion, is solved.","On the other hand, with regard to algebraic code and algebraic codebook gain code, a target signal is created from reproduced speech and a conversion is made so as to minimize error with respect to the target signal. As a result, code conversion with little degradation of sound quality can be performed even in a case where the structure of the algebraic codebook in encoding scheme  differs greatly from that of encoding scheme . This is a problem that arises in prior art 2.",{"@attributes":{"id":"p-0141","num":"0140"},"figref":["FIG. 9","FIG. 9","FIG. 2"],"b":["108","111"]},"In the second embodiment, only the method of converting the algebraic codebook gain code differs from that of the first embodiment. The method of converting the algebraic codebook gain code according to the second embodiment will now be described.","In G.729A, algebraic codebook gain is quantized ever 5-ms subframe. If 20 ms is considered as the unit time, therefore, G.729A quantizes four algebraic codebook gains in one frame, while EVRC quantizes only three in one frame. Accordingly, in a case where G.729A voice code is converted to EVRC voice code, all algebraic codebook gains in G.729A cannot be converted to EVRC algebraic codebook gain. Accordingly, in the second embodiment, gain conversion is performed by the method illustrated in . Specifically, algebraic codebook gain is synthesized in accordance with the following equations:\n\ngc2(0)=gc1(0)\n\n2(1)1(1)(2)]\/2\n\ngc2(2)=gc1(3)\n\nwhere gc(), gc(), gc(), gc() represent the algebraic codebook gains of two consecutive frames in G.729A. The synthesized algebraic codebook gains gc(k) (k=0, 1, 2) are scalar quantized using an EVRC algebraic codebook gain quantization table, whereby algebraic codebook gain code Gc(m,k) is obtained.\n","According to the second embodiment, the LSP code, pitch-lag code, pitch-gain code and algebraic codebook gain code are converted in the quantization parameter region. As a result, in comparison with the case where reproduced speech is subjected to LPC analysis and pitch analysis again, analytical error is reduced and parameter conversion with less degradation of sound quality can be carried out. Further, since reproduced speech is not subjected to LSP analysis and pitch analysis again, the problem of prior art 1, namely delay ascribable to code conversion, is solved.","On the other hand, with regard to algebraic code, a target signal is created from reproduced speech and a conversion is made so as to minimize error with respect to the target signal. As a result, code conversion with little degradation of sound quality can be performed even in a case where the structure of the algebraic codebook in encoding scheme  differs greatly from that of encoding scheme . This is a problem that arises in prior art 2.",{"@attributes":{"id":"p-0146","num":"0145"},"figref":["FIG. 11","FIG. 11"],"b":["201","201","201","201","1","2","202","203","204"]},"Voice Code Converter for Full Rate",{"@attributes":{"id":"p-0148","num":"0147"},"figref":"FIG. 12","b":"202"},"An mth frame of voice code (channel data) CODE(m) is input from an EVRC-compliant encoder (not shown) to terminal # via a transmission path. A code demultiplexer  demultiplexes LSP code Lsp(m), pitch-lag code Lag(m), pitch-gain code Gp(m,k), algebraic code Cb(m,k) and algebraic codebook gain code Gc(m,k) from the voice code CODE(m) and inputs these codes to dequantizers , , ,  and , respectively. Here \u201ck\u201d represents the number of a subframe in EVRC and takes on a value of 0, 1 or 2.","The LSP dequantizer  obtains a dequantized value lsp(m,2) of the LSP code Lsp(m) in subframe No. . It should be noted that the LSP dequantizer  has a quantization table identical with that of the EVRC decoder. Next, by linear interpolation, the LSP dequantizer  obtains dequantized values lsp(m,0) and lsp(m,1) of subframe Nos. ,  using a dequantized value lsp(m\u22121,2) of subframe No.  obtained similarly in the preceding frame [(m\u22121)th frame), and the above-mentioned dequantized value lsp(m,2), and inputs the dequantized value lsp(m,1) of subframe No.  to an LSP quantizer . Using the quantization table of encoding scheme  (G.729A), the LSP quantizer  quantizes the dequantized value lsp(m,1) to obtain LSP code Lsp(n) of encoding scheme , and obtains the LSP dequantized value lsp(n,1) thereof. Similarly, when the LSP quantizer  inputs the dequantized value lsp(m,2) of subframe No.  to the LSP quantizer , the latter obtains LSP code Lsp(n+1) of encoding scheme  and finds the LSP dequantized value lsp(n+1,1) thereof. Here it is assumed that the LSP dequantizer  has a quantization table identical with that of G.729A.","Next, the LSP quantizer  finds the dequantized value lsp(n,0) of subframe No.  by linear interpolation between the dequantized value lsp(n\u22121,1) obtained in the preceding frame [(n\u22121)th frame] and the dequantized value lsp(n,1) of the present frame. Further, the LSP quantizer  finds the dequantized value lsp(n+1,0) of subframe No.  by linear interpolation between the dequantized value lsp(n,1) and the dequantized value lsp(nb+1,1). These dequantized values lsp(n,j) are used in creation of the target signal and in conversion of the algebraic code and gain code.","The pitch-lag dequantizer  obtains a dequantized value lag(m,2) of the pitch-lag code Lag(m) in subframe No. , then obtains dequantized values lag(m,0) and lag(m,1) of subframe Nos. ,  by linear interpolation between the dequantized value lag(m,2) and a dequantized value lag(m\u22121,2) of subframe No.  obtained in the (m\u22121)th frame. Next, the pitch-lag dequantizer  inputs the dequantized value lag(m,1) to a pitch-lag quantizer . Using the quantization table of encoding scheme  (G.729A), the pitch-lag quantizer  obtains pitch-lag code Lag(n) of encoding scheme  corresponding to the dequantized value lag(m,1) and obtains the dequantized value lag(n,1) thereof. Similarly, the pitch-lag dequantizer  inputs the dequantized value lag(m,2) to the pitch-lag quantizer , and the latter obtains pitch-lag code Lag(n+1) and finds the LSP dequantized value lag(n+1,1) thereof. Here it is assumed that the pitch-lag quantizer  has a quantization table identical with that of G.729A.","Next, the pitch-lag quantizer  finds the dequantized value lag(n,0) of subframe No.  by linear interpolation between the dequantized value lag(n\u22121,1) obtained in the preceding frame [(n\u22121)th frame] and the dequantized value lag(n,1) of the present frame. Further, the pitch-lag quantizer  finds the dequantized value lag(n+1,0) of subframe No.  by linear interpolation between the dequantized value lag(n,1) and the dequantized value lag(n+1,1). These dequantized values lag(n,j) are used in creation of the target signal and in conversion of the gain code.","The pitch-gain dequantizer  obtains dequantized values gp(m,k) of three pitch gains Gp(m,k) (k=0, 1, 2) in the mth frame of EVRC and inputs these dequantized values to a pitch-gain interpolator . Using the dequantized values gp(m,k), the pitch-gain interpolator  obtains, by interpolation, pitch-gain dequantized values gp(n,j) (j=0, 1), gp(n+1,j) (j=0, 1) in encoding scheme  (G.729A) in accordance with the following equations:\n\ngp2(n,0)=gp1(m,0)\u2003\u2003(1)\n\n2(1)1(0)1(1)]\/2\u2003\u2003(2)\n\n2(1,0)1(1)1(2)]\/2\u2003\u2003(3)\n\ngp2(n+1,1)=gp1(m,2)\u2003\u2003(4)\n\nIt should be noted that the pitch-gain dequantized values gp(n,j) are not directly required in conversion of the gain code but are used in the generation of the target signal.\n","The dequantized values lsp(m,k), lag(m,k), gp(m,k), cb(m,k) and gc(m,k) of each of the EVRC codes are input to the speech reproducing unit , which creates EVRC-compliant reproduced speech SP(k,i) of a total of 160 samples in the mth frame, partitions these regenerated signals into two G.729A-speech signals Sp(n,h), Sp(n+1,h), of 80 samples each, and outputs the signals. The method of creating reproduced speech is the same as that of an EVRC decoder and is well known; no further description is given here.","A target generator  has a structure similar to that of the target generator (see ) according to the first embodiment and creates target signals Target(n,h), Target(n+1,h) used by an algebraic code converter  and algebraic codebook gain converter . Specifically, the target generator  first obtains an adaptive codebook output that corresponds to pitch lag lag(n,j) found by the pitch-lag quantizer  and multiplies this by pitch gain gp(n,j) to create a sound-source signal. Next, the target generator  inputs the sound-source signal to an LPC synthesis filter constituted by the LSP dequantized value lsp(n,j), thereby creating an adaptive codebook synthesis signal syn(n,h). The target generator  then subtracts the adaptive codebook synthesis signal syn(n,h) from the reproduced speech Sp(n,h) created by the speech reproducing unit , thereby obtaining the target signal Target(n,h). Similarly, the target generator  creates the target signal Target(n+1,h) of the (n+1)th frame.","The algebraic code converter , which has a structure similar to that of the algebraic code converter (see ) according to the first embodiment, executes processing exactly the same as that of an algebraic codebook search in G.729A. First, the algebraic code converter  inputs an algebraic codebook output signal that can be produced by a combination of pulse positions and polarity shown in  to an LPC synthesis filter constituted by the LSP dequantized value lsp(n,j), thereby creating an algebraic synthesis signal. Next, the algebraic code converter  calculates a cross-correlation value Rcx between the algebraic synthesis signal and target signal as well as an autocorrelation value Rcc of the algebraic synthesis signal, and searches for an algebraic code Cb(n,j) that will afford the largest normalized cross-correlation value Rcx\u00b7Rcx\/Rcc obtained by normalizing the square of Rcx by Rcc. The algebraic code converter  obtains algebraic code Cb(n+1,j) in similar fashion.","The gain converter  performs gain conversion using the target signal Target(n,h), pitch lag lag(n,j), algebraic code Cb(n,j) and LSP dequantized value lsp(n,j). The conversion method is the same as that of gain quantization performed in a G.729A encoder. The procedure is as follows:","(1) Extract a set of table values (pitch gain and correction coefficient \u03b3 of algebraic codebook gain) from a G.729A gain quantization table;","(2) multiply an adaptive codebook output by the table value of the pitch gain, thereby creating a signal X;","(3) multiply an algebraic codebook output by the correction coefficient \u03b3 and a gain prediction value g\u2032, thereby creating a signal Y;","(4) input a signal, which is obtained by adding signal X and signal Y, to an LPC synthesis filter constituted by an LSP dequantized value lsp(n,j), thereby creating a synthesized signal Z;","(5) calculate error power E between the target signal and synthesized signal Z; and","(6) apply the processing of (1) to (5) above to all table values of the gain quantization table, decide a table value that will minimize the error power E, and adopt the index thereof as gain code Gain(n,j). Similarly, gain code Gain(n+1,j) is found from target signal Target(n+1,h), pitch lag lag(n+1,j), algebraic code Cb(n+1,j) and LSP dequantized value lsp(n+1,j).","Thereafter, a code multiplexer  multiplexes the LSP code Lsp(n), pitch-lag code Lag(n), algebraic code Cb(n,j) and gain code Gain(n,j) and outputs the voice code CODE in the nth frame. Further, the code multiplexer  multiplexes LSP code Lsp(n+1), pitch-lag code Lag(n+1), algebraic code Cb(n+1,j) and gain code Gain(n+1,j) and outputs the voice code CODE in the (n+1)th frame of G.729A.","In accordance with the third embodiment, as described above, EVRC (full-rate) voice code can be converted to G.729A voice code.","Voice Code Converter for Half Rate","A full-rate coder\/decoder and a half-rate coder\/decoder differ only in the sizes of their quantization tables; they are almost identical in structure. Accordingly, the half-rate voice code converter  also can be constructed in a manner similar to that of the above-described full-rate voice code converter , and half-rate voice code can be converted to G.729A voice code in a similar manner.","Voice Code Converter for \u215b Rate",{"@attributes":{"id":"p-0170","num":"0169"},"figref":"FIG. 13","b":"204"},"When voice code CODE(m) in an mth frame of EVRC (\u215b rate) is input to a code demultiplexer  in , the latter demultiplexes the LSP code Lsp(m) and gain code Gc(m). An LSP dequantizer  and an LSP quantizer  convert the LSP code Lsp(m) in EVRC to LSP code Lsp(n) in G.729A in a manner similar to that of the full-rate case shown in . The LSP dequantizer  obtains an LSP-code dequantized value lsp(m,k), and the LSP quantizer  outputs the G.729A LSP code Lsp(n) and finds an LSP-code dequantized value lsp(n,j).","A gain dequantizer  finds a gain quantized value gc(m,k) of the gain code Gc(m). It should be noted that only gain with respect to a noise-like sound-source signal is used in the \u215b-rate mode; gain (pitch gain) with respect to a periodic sound source is not used in the \u215b-rate mode.","In the case of the \u215b rate, the sound-source signal is used upon being generated randomly within the encoder and decoder. Accordingly, in the voice code converter for the \u215b rate, a sound-source generator  generates a random signal in a manner similar to that of the EVRC encoder and decoder, and a signal so adjusted that the amplitude of this random signal will become a Gaussian distribution is output as a sound-source signal Cb(m,k). The method of generating the random signal and the method of adjustment for obtaining the Gaussian distribution are methods similar to those used in EVRC.","A gain multiplier  multiplies Cb(m,k) by the gain dequantized value gc(m,k) and inputs the product to an LPC synthesis filter  to create target signals Target(n,h), Target(n+1,h). The LPC synthesis filter  is constituted by the LSP-code dequantized value lsp(m,k).","An algebraic code converter  performs an algebraic code conversion in a manner similar to that of the full-rate case in  and outputs G.729A-compliant algebraic code Cb(n,j).","Since the EVRC \u215b rate is used in unvoiced intervals such as silent or noise segments that exhibit almost no periodicity, a pitch-lag code does not exist. Accordingly, a pitch-lag code for G.729A is generated by the following method: The \u215b-rate voice code converter  extracts G.729A pitch-lag code obtained by the pitch-lag quantizer  of the full-rate or half-rate voice code converter  or  and stores the code in a pitch-lag buffer . If the \u215b rate is selected in the present frame (nth frame), pitch-lag code Lag(n,j) in the pitch-lag buffer  is output. The content stored in the pitch-lag buffer , however, is not changed. On the other hand, if the \u215b rate is not selected in the present frame, then G.729A pitch-lag code obtained by the pitch-lag quantizer  of the voice code converter  or  of the selected rate (full rate or half rate) is stored in the buffer .","A gain converter  performs a gain code conversion similar to that of the full-rate case in  and outputs the gain code Gc(n,j).","Thereafter, a code multiplexer  multiplexes the LSP code Lsp(n), pitch-lag code Lag(n), algebraic code Cb(n,j) and gain code Gain(n,j) and outputs the voice code CODE(n+1) in the nth frame of G.729A.","Thus, as set forth above, EVRC (\u215b-rate) voice code can be converted to G.729A voice code.",{"@attributes":{"id":"p-0180","num":"0179"},"figref":["FIG. 14","FIG. 14","FIG. 2"],"b":["501","511","512","513","514","102","103","104","110"],"i":["a","a, ","a "]},"When input voice xin is applied to an encoder  according to encoding scheme  (G.729A), the encoder  generates voice code sp according to encoding scheme . The voice code sp is input to the voice code conversion apparatus through a transmission path such as a wireless channel or wired channel (Internet, etc.). If channel error ERR develops before the voice code sp is input to the voice code conversion apparatus, the voice code sp is distorted to voice code sp\u2032 that contains channel error. The pattern of channel error ERR depends upon the system, and the error takes on various patterns such as random bit error and bursty error. It should be noted that sp\u2032 and sp become exactly the same code if the voice code contains no error. The voice code sp\u2032 is input to the code demultiplexer , which demultiplexes LSP code Lsp(n), pitch-lag code Lag(n,j), algebraic code Cb (n,j) and pitch-gain code Gain(n,j). Further, the voice code sp\u2032 is input to the channel error detector , which detects whether channel error is present or not by a well-known method. For example, channel error can be detected by adding a CRC code onto the voice code sp.","If error-free LSP code Lsp(n) enters the LSP code correction unit , the latter outputs the LSP dequantized value lsp by executing processing similar to that executed by the LSP dequantizer of the first embodiment. On the other hand, if a correct Lsp code cannot be received in the present frame owing to channel error or a lost frame, then the LSP code correction unit  outputs the LSP dequantized value lsp using the last four frames of good Lsp code received.","If there is no channel error or loss of frames, the pitch-lag correction unit  outputs the dequantized value lag of the pitch-lag code in the present frame received. If channel error or loss of frames occurs, however, the pitch-lag correction unit  outputs a dequantized value of the pitch-lag code of the last good frame received. It is known that pitch lag generally varies smoothly in a voiced segment. In a voiced segment, therefore, there is almost no decline in sound quality even if pitch lag of the preceding frame is substituted. Further, it is known that pitch lag varies greatly in an unvoiced segment. However, since the rate of contribution of an adaptive codebook in an unvoiced segment is small (the pitch gain is small), there is almost no decline in sound quality ascribable to the above-described method.","If there is no channel error or loss of frames, the gain-code correction unit  obtains the pitch gain gp(j) and algebraic codebook gain gc(j) from the received gain code Gain(n,j) of the present frame in a manner similar to that of the first embodiment. In the case of channel error or frame loss, on the other hand, the gain code of the present frame cannot be used. Accordingly, the gain-code correction unit  attenuates the stored gain that prevailed one subframe earlier in accordance with the following equations:\n\n(0)(\u22121,1)\n\n(1)(\u22121,0)\n\n(0)(\u22121,1)\n\n(1)(\u22121,0)\n\nobtains pitch gain gp(n,j) and algebraic codebook gain gc(n,j) and outputs these gains. Here \u03b1, \u03b2 represent constants of less than 1.\n","If there is no channel error or loss of frames, the algebraic-code correction unit  outputs the dequantized value cbi(j) of the algebraic code of the present frame received. If there is channel error or loss of frames, then the algebraic-code correction unit  outputs the dequantized value of the algebraic code of the last good frame received and stored.","Thus, in accordance with the present invention, an LSP code, pitch-lag code and pitch-gain code are converted in a quantization parameter region or an LSP code, pitch-lag code, pitch-gain code and algebraic codebook gain code are converted in the quantization parameter region. As a result, it is possible to perform parameter conversion with less analytical error and less decline in sound quality in comparison with a case where reproduced speech is subjected to LPC analysis and pitch analysis again.","Further, in accordance with the present invention, reproduced speech is not subjected to LPC analysis and pitch analysis again. This solves the problem of prior art , namely the problem of delay ascribable to code conversion.","In accordance with the present invention, the arrangement is such that a target signal is created from reproduced speech in regard to algebraic code and algebraic codebook gain code, and the conversion is made so as to minimize the error between the target signal and algebraic synthesis signal. As a result, a code conversion with little decline in sound quality can be performed even in a case where the structure of the algebraic codebook in encoding scheme  differs greatly from that of the algebraic codebook in encoding scheme . This is a problem that could not be solved in prior art 2.","Further, in accordance with the present invention, voice code can be converted between the G.729A encoding scheme and the EVRC encoding scheme.","Furthermore, in accordance with the present invention, normal code components that have been demultiplexed are used to output dequantized values if transmission-path error has not occurred. If an error develops in the transmission path, normal code components that prevail in the past are used to output dequantized values. As a result, a decline in sound quality ascribable to channel error is reduced and it is possible to provide excellent reproduced speech after conversion.","As many apparently widely different embodiments of the present invention can be made without departing from the spirit and scope thereof, it is to be understood that the invention is not limited to the specific embodiments thereof except as defined in the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0087","num":"0086"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0088","num":"0087"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0089","num":"0088"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0091","num":"0090"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0092","num":"0091"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0093","num":"0092"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0094","num":"0093"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0095","num":"0094"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0096","num":"0095"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0097","num":"0096"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0098","num":"0097"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0099","num":"0098"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0100","num":"0099"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0101","num":"0100"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0102","num":"0101"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0103","num":"0102"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0104","num":"0103"},"figref":"FIG. 18"},{"@attributes":{"id":"p-0105","num":"0104"},"figref":"FIG. 19"},{"@attributes":{"id":"p-0106","num":"0105"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0107","num":"0106"},"figref":"FIG. 21"},{"@attributes":{"id":"p-0108","num":"0107"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0109","num":"0108"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0110","num":"0109"},"figref":"FIG. 24"},{"@attributes":{"id":"p-0111","num":"0110"},"figref":"FIG. 25"}]},"DETDESC":[{},{}]}
