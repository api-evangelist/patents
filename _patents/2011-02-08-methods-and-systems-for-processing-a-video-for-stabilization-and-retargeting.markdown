---
title: Methods and systems for processing a video for stabilization and retargeting
abstract: Methods and systems for processing a video for stabilization and retargeting are described. A recorded video may be stabilized by removing shake introduced in the video, and a video may be retargeted by modifying the video to fit to a different aspect ratio. Constraints can be imposed that require a modified video to contain pixels from the original video and/or to preserve salient regions. In one example, a video may be processed to estimate an original path of a camera that recorded the video, to estimate a new camera path, and to recast the video from the original path to the new camera path. To estimate a new camera path, a virtual crop window can be designated. A difference transformation between the original and new camera path can be applied to the video using the crop window to recast the recorded video from the smooth camera path.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08531535&OS=08531535&RS=08531535
owner: Google Inc.
number: 08531535
owner_city: Mountain View
owner_country: US
publication_date: 20110208
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CROSS REFERENCE TO RELATED APPLICATION","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["The present application claims priority to U.S. provisional patent application Ser. No. 61\/407,630, filed on Oct. 28, 2010, the entire contents of which are herein incorporated by reference as if fully set forth in this description.","Image stabilization includes many techniques used to reduce blurring associated with motion of a camera during exposure. Image stabilization techniques may compensate for pan and tilt (angular movement) of a camera or other imaging device. With still cameras, camera shake can be problematic at slow shutter speeds or with long focal length (telephoto) lenses, and image stabilization techniques can be used to improve a still picture.","Similarly, video stabilization techniques may be used to improve recorded videos. With video cameras, camera shake can cause visible frame-to-frame jitter in a recorded video. For example, handheld camera or handheld video recording is a film and video technique in which a camera is held in the camera operator's hands, and a handheld recorded video may be perceptibly shakier than a video recorded using a tripod-mounted camera (or other stabilization equipment, such as camera dollies or steady-cams) due to motion of the operator holding the camera during recording. However, recording videos using handheld video recording may enable more opportunities for filming.","Video stabilization techniques may be used to create a stable version of a casually shot video (e.g., a video recorded on a device with little or no stabilization equipment). Video stabilization techniques generally attempt to render the recorded video as the video would have been recorded from a smooth or stable camera path.","The present application discloses embodiments of systems and methods for processing a video for stabilization and retargeting. In one aspect, a method for processing a video is described. The method may comprise estimating an original motion path of a camera that recorded a video. The method may also comprise determining at each time t a substantially constant path, a substantially constant velocity, or a substantially constant acceleration of the original motion path of the camera. The method also may comprise determining a modified motion camera path of the original motion path of the camera including for each time t the substantially constant path, the substantially constant velocity, or the substantially constant acceleration of the original motion path of the camera. The method may further comprise based on the modified motion camera path and the original motion path of the camera, determining a crop window transform that describes how to modify the original motion path of the camera to the modified motion camera path, and the crop window transform may be determined according to at least one constraint limiting changes to the original motion path of the camera. The method may further comprise applying the crop window transform to the video to recast the video from a viewpoint of the original motion path of the camera to a viewpoint of the modified motion camera path.","In another aspect, a non-transitory computer readable medium having stored therein instructions executable by a computing device to cause the computing device to perform functions is described. The functions may comprise estimating an original motion path of a camera that recorded a video. The function may further comprise determining at each time t a substantially constant path, a substantially constant velocity, or a substantially constant acceleration of the original motion path of the camera. The functions also may comprise determining a modified motion camera path of the original motion path of the camera including for each time t the substantially constant path, the substantially constant velocity, or the substantially constant acceleration of the original motion path of the camera. The functions further may comprise based on the modified motion camera path and the original motion path of the camera, determining a crop window transform that describes how to modify the original motion path of the camera to the modified motion camera path, the crop window transform determined according to at least one constraint limiting changes to the original motion path of the camera. The functions further may comprise applying the crop window transform to the video to recast the video from a viewpoint of the original motion path of the camera to a viewpoint of the modified motion camera path.","In still another aspect, a camera path translation system is provided that comprises a camera path estimation engine, a video stabilization and retargeting engine, and a video translation engine. The camera path estimation engine may be configured to receive a video, and to estimate an original motion path of a camera that recorded the video based on motion of objects within the video. The video stabilization and retargeting engine may be configured to determine a crop window transform that describes how to modify the original motion path of the camera to a modified motion camera path, and the crop window transform may be determined according to at least one constraint limiting changes to the original motion path of the camera. The video translation engine may be configured to apply the crop window transform to the video to recast the video from a viewpoint of the original motion path of the camera to a viewpoint of the modified motion camera path.","The foregoing summary is illustrative only and is not intended to be in any way limiting. In addition to the illustrative aspects, embodiments, and features described above, further aspects, embodiments, and features will become apparent by reference to the figures and the following detailed description.","The following detailed description describes various features and functions of the disclosed systems and methods with reference to the accompanying figures. In the figures, similar symbols identify similar components, unless context dictates otherwise. The illustrative system and method embodiments described herein are not meant to be limiting. It may be readily understood that certain aspects of the disclosed systems and methods can be arranged and combined in a wide variety of different configurations, all of which are contemplated herein.","This disclosure may disclose, inter alia, systems and methods for stabilizing and retargeting recorded videos. For example, a recorded video may be stabilized by removing at least a portion of shake introduced in the video, and a video may be retargeted by modifying the video to fit to a different aspect ratio. The disclosure describes examples for stabilizing and retargeting recorded video by imposing constraints that require a modified video to contain valid pixels from the original recorded video and\/or to preserve salient regions and objects, for example.","In one example, a video may be stabilized by performing post-processing techniques. The video may be processed to estimate an original path (e.g., motion) of a camera that recorded the video, to estimate a new steady\/smooth camera path, and to recast the video from the original path to the smooth camera path. In one example, to estimate a new camera path, a virtual crop window of a pre-defined scale less than one with respect to an original frame size can be designated. A difference transformation between the original and smooth camera path can be applied to the recorded video using the crop window to recast the recorded video as if the video had been recorded from the smooth camera path to remove shake from the recorded video, for example. If the crop window does not fit in the original frame, in one example, undefined areas may be filled using motion-in-painting. In another example, constraints can be imposed to prevent undefined areas from occurring.","I. Example Camera Path Translation System","Referring now to , a block diagram of a camera path translation system  is illustrated. The camera path translation system  includes a camera path estimation engine , a video stabilization and retargeting engine , and a video translation engine . The camera path translation system  may be configured to receive a video, and to perform video stabilization processes on the video. For example, the camera path estimation engine  may estimate a path of a camera that recorded the video based on motion of objects within the received video. The video stabilization and retargeting engine  may then estimate a new steady\/smooth camera path, and the video translation engine  may recast the received video from a viewpoint of the smooth camera path determined by the video stabilization and retargeting engine .","One or more of the described functions or components of the system  may be divided up into additional functional or physical components, or combined into fewer functional or physical components. In some further examples, additional functional and\/or physical components may be added to the examples illustrated by . Still further, any of the camera path estimation engine , the video stabilization and retargeting engine , and\/or the video translation engine  may include or be provided in the form of a processor (e.g., a micro processor, a digital signal processor (DSP), etc.) configured to execute program code including one or more instructions for implementing logical functions described herein. The system  may further include any type of computer readable medium (non-transitory medium), for example, such as a storage device including a disk or hard drive, to store the program code. In other examples, the camera path translation system  may be included within other systems.",{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 2","b":["200","202","204","200","200","200","204","206","200","204"]},"Turning to the individual entities illustrated on , each client A-N may be used by a user to request video hosting services. For example, a user can use the client A to send a request for uploading a video for sharing, or playing a video. The clients A-N can be any type of computer device, such as a personal computer (e.g., desktop, notebook, tablet, laptop) computer, as well as devices such as a mobile telephone, personal digital assistant, or IP enabled video player. The clients A-N may include a processor, a display device (or output to a display device), and a local storage, such as a hard drive or flash memory device to which the clients A-N store data used by the user in performing tasks, and a network interface for coupling to the video hosting service  via the network .","The clients A-N may include a video player A-N (e.g., the Flash\u2122 player from Adobe Systems, Inc., or a proprietary one) for playing a video stream. The video player A-N may be a standalone application, or a plug-in to another application such as a network or Internet browser. Where the client A-N is a general purpose device (e.g., a desktop computer, mobile phone), the player A-N may be implemented as software executed by the computer. Where the client A-N is a dedicated device (e.g., a dedicated video player), the player A-N may be implemented in hardware, or a combination of hardware and software. The player A-N may include user interface controls (and corresponding application programming interfaces) for selecting a video feed, starting, stopping, and rewinding a video feed. Also, the player A-N can include in a user interface a video display format selection configured to indicate a video display format (e.g., a standard definition TV or a high-definition TV). Other types of user interface controls (e.g., buttons, keyboard controls) can be used as well to control the playback and video format selection functionality of the player A-N.","The network  enables communications between the clients A-N and the video hosting service . In one embodiment, the network  is the Internet, and uses standardized internetworking communications technologies and protocols, known now or subsequently developed that enable the clients A-N to communicate with the video hosting service . In another embodiment, the network  may be a wireless cellular network that enables wireless communication between the clients A-N and the video hosting service .","The video hosting service  comprises the camera path translation system , a video server , an ingest server , and a video database . The video server  may be configured to serve videos from the video database  in response to user video hosting service requests. The ingest server  may be configured to receive user uploaded videos and store the videos in the video database . The video database  may be configured to store user uploaded videos and videos processed by the camera path translation system . In one embodiment, the video database  stores a large video corpus.","The camera path translation system  may include a camera path estimation engine , a video stabilization and retargeting engine , and a video translation engine . The camera path translation system  may be configured to receive user uploaded videos from the ingest server , and to perform video stabilization of the videos.","II. Video Stabilization","In one example, the camera path estimation engine  may estimate a path of a camera that recorded the video based on motion of objects or images within the received video. A camera path may be estimated by extracting trackable features in frames of the video, matching features, and performing local outlier rejection to remove spurious matches that may distort motion estimation. Linear motion models (e.g., translation, similarity, affine) may be fit to the tracked features to estimate a motion of the camera between two frames, and the motion models can be transformed to a common coordinate system and concatenated to yield an estimated original camera path over all frames of the video.","The video stabilization and retargeting engine  may then estimate a new steady\/smooth camera path based on constraints. For example, a base vertical line may be established for desired vertical camera path motion, and constraints can be established to allow a camera path to be modified by a constrained amount (e.g., if camera motion moves downward, pixels in images are moved upward to align with a previous frame and bottom row(s) of pixels can be removed or cropped out to an extent as allowed by the constraints).","A smooth camera path can be estimated using minimization of derivatives of the original camera path as estimated by the camera path estimation engine . For example, a constant path may represent a static camera,",{"@attributes":{"id":"p-0040","num":"0039"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mi":["i","e"],"mo":[".",".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mfrac":{"mrow":[{"mo":"\u2146","mi":"P"},{"mo":"\u2146","mi":"t"}]}},{"mn":"0","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mrow":{"mi":["where","P","is","a","function","representing","the","camera","path"],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]}}}],"mo":"="},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0041","num":"0040"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":{"mi":["i","e"],"mo":[".",".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"2"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","msup":{"mi":"t","mn":"2"}}]}},"mo":"=","mn":"0"},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0042","num":"0041"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"3"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","msup":{"mi":"t","mn":"3"}}]},"mo":"=","mn":"0."}}},"br":{}},"In one example, to estimate a camera path P(t) comprising segments of constant, linear, and parabolic motion, an optimization may be performed as a constrained L1 minimization solution. For example, an N-dimensional vector norm of order p is defined as",{"@attributes":{"id":"p-0044","num":"0043"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"msub":{"mrow":{"mo":["\uf603","\uf604"],"mi":"x"},"mi":"p"},"mo":"=","msup":{"mrow":{"mo":["(",")"],"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"N"},"mo":"\u2062","msup":{"mrow":{"mo":["\uf603","\uf604"],"msub":{"mi":["x","i"]}},"mi":"p"}}},"mfrac":{"mn":"1","mi":"p"}}},"mo":","}}},"br":{}},"In addition, a camera path P(t) can be determined that minimizes the above derivatives while satisfying constraints. A variety of constraints may be used such as an inclusion, proximity, and saliency constraints. An inclusion constraint requires a crop window transformed by the path P(t) to always or substantially always be contained in an original frame rectangle transformed by C(t), the camera path. A proximity constraint includes a new camera path P(t) preserving (or substantially preserve) the original intent of the movie, e.g., if the original path contained segments of zooming, the new camera path may follow this motion. A saliency constraint includes salient points (e.g., obtained by a face detector or general mode finding in a saliency map) within all or a part of a crop window transformed by P(t). Many other constraints may be used as well.","The video translation engine  may recast the received video from a viewpoint of the smooth camera path determined by the video stabilization and retargeting engine  by applying a transformation to the video to produce a cropped video with less shake, for example. Thus, in one embodiment, video stabilization may be performed by (1) estimating per-frame motion transforms F, (2) determining an optimal camera path P=CB(where Cis based on the motion transforms Fand Bis a crop window transform estimated as described below) and (3) stabilizing the video by warping according to B.",{"@attributes":{"id":"p-0047","num":"0046"},"figref":["FIG. 3","FIG. 3"],"b":["300","100","200","300","302","304","306","308","310"]},"In addition, for the method  and other processes and methods disclosed herein, the flowchart shows functionality and operation of one possible implementation of present embodiments. In this regard, each block may represent a module, a segment, or a portion of program code, which includes one or more instructions executable by a processor for implementing specific logical functions or steps in the process. The program code may be stored on any type of computer readable medium, for example, such as a storage device including a disk or hard drive. The computer readable medium may include a non-transitory computer readable medium, for example, such as computer-readable media that stores data for short periods of time like register memory, processor cache and Random Access Memory (RAM). The computer readable medium may also include non-transitory media, such as secondary or persistent long term storage, like read only memory (ROM), optical or magnetic disks, compact-disc read only memory (CD-ROM), for example. The computer readable media may also be any other volatile or non-volatile storage systems. The computer readable medium may be considered a computer readable storage medium, a tangible storage device, or other article of manufacture, for example.","In addition, for the method  and other processes and methods disclosed herein, each block in  may represent circuitry that is wired to perform the specific logical functions in the process.","At block , a recorded video is received. At block , trackable feature matches in frames of the video are extracted. For example, trackable features in each frame of the video are extracted, or trackable features in substantially all frames of the video are extracted. Trackable features in frames of the video may be extracted using feature tracking software, such as the pyramidal Lucas-Kanade feature tracking as implemented in OpenCV. Features may be tracked from frame to frame using any number of methods. Example features for extracting include corners of an image in which intensity changes along the x and y dimension of an image. In another example, trackable features between two frames may be extracted by extracting a number of features in a first video frame (e.g., based on x and y location) and tracking the extracted features in a next video frame. For example, if the video is a sequence of images, I, I, . . . I, video frame pairs may be (I, I), and feature pairs between video frames may be extracted (e.g., for each feature x in frame I, a corresponding feature y at the same point in space as the feature x is found in frame I). With small intra-frame motions and changes in illumination, brightness values of a small image patch (e.g., 7\u00d77 pixels) centered around the feature point x in Iand its matching point y in Imay be nearly identical. For each feature x in I, a displacement vector d may be determined such that the I(x)=I(x+d), and therefore x+d=y using the previous notation (e.g., that is feature matches (x<->y)). This expression can be linearized by Taylor Series expansion around x, yielding DI(x)*d=I(x)\u2212I(x) which is linear in the unknown displacement vector d. An over determined linear system of equations may be determined of the form A*d=b that can be then solved by using normal equations (i.e., solving the symmetric linear system AA d=Ab by Gaussian Elimination, where Adenotes the transpose of A). This process may be referred to as pyramidical Lucas-Kanade Tracking.","During feature tracking from one frame to the next frame, errors may accumulate. To detect potentially poor feature matches, images in a window around the feature in the current frame can be monitored to determine if the images are similar to the images around the feature in the first frame. Features may be tracked over many frames, and the image content can change. For a consistency verification, translational mapping that is used for feature tracking from frame to frame may be performed, in addition to a similarity or an affine mapping.","This process may be performed for all video frames of the video to determine multiple pairs of feature correspondences, i.e., each pair corresponding to a feature location in a first and a second frame, respectively.","At block , local outlier rejection may performed to remove spurious extracted feature matches or feature-pairs that may distort motion estimation (rather than or in addition to global outlier rejection to account for multiple independent motion layers). Some of the feature-pair matches between video frames may be incorrect and can be removed. To remove feature-pairs matches that may have been incorrectly identified as a corresponding pairs, an algorithm, such as random sample consensus (RANSAC), may be used. The algorithm may identify outliers within a set of observed data. For example, all feature-pairs may be initialized as inliers, i.e., data whose distribution can be explained by a set of model parameters. An average mathematical translation (e.g., moving every point a constant distance in a specified direction) can be computed based on inlier pairs. Pairs whose translation differs from the average translation by more than a threshold amount can be removed from the inlier set and classified as \u201coutliers\u201d that are data that do not fit the model. The threshold amount may be determined based on observed results. A smaller threshold can be used to remove a larger number of feature-pairs, and a larger threshold can be used to remove a smaller number of feature-pairs. The algorithm may be performed iteratively (e.g., with a fixed number of iterations) by determining an average mathematical translation of feature-pairs that were not removed from the inlier set.","In another example, to perform local outlier rejection to remove spurious feature matches, a model may be fit to the feature-pairs. The model may be formed by a mathematical translation or other linear transformations as well. If a feature-pair fits the model, the feature-pair is considered an inlier. The model may be reasonably sufficient if a number of points have been classified as inliers. The model can be reestimated from all feature-pairs that are now considered inliers. This procedure can be repeated a fixed number of times, and each time may produce either a model which is rejected because too few points are classified as inliers or a refined model together with a corresponding error measure.","To account for independent moving objects, the local outlier rejection can be performed by leveraging per-frame segmentation and imposing a local 2D translation motion model on each region for each feature-pair. To reduce overhead introduced by using per-frame segmentation, an estimation-mode may be used that replaces segmentation regions with square regions of similar block sizes onto each frame, for example.","In addition, feature-pairs can be removed from moving objects in a foreground region. For example, local-outlier rejected feature-pairs can be classified into independent moving foreground and static background regions by estimating a fundamental Matrix (F) using RANSAC from the feature-pairs, where the fundamental matrix F is a 3\u00d73 matrix that relates corresponding points in stereo images (e.g., with homogeneous image coordinates, x and x\u2032, of corresponding points in a stereo image pair, Fx describes a line (an epipolar line) on which the corresponding point x\u2032 on the other image lies). Regions that adhere to the fundamental matrix constraint can be labeled background regions, and regions that violate the constraint can be labeled foreground regions.","In still another example, to perform local outlier rejection to remove spurious feature matches, features may be discretized into a grid of 50\u00d750 pixels and RANSAC may be performed on each grid cell to estimate a translational model in which matches that agree within a specific threshold distance (e.g., <2 pixels) with an estimated model may be retained.","In still another example, to perform local outlier rejection, neighboring features may be required to have similar displacement vectors. This can be achieved by partitioning an image into regions (e.g., using grid based regions or perceptually homogeneous regions obtained from image segmentation). For each region R, a random displacement vector d is selected that falls into this region, and a number of displacement vectors in R that are within a specified distance (e.g., 2 pixels) to the selected vector d can be determined (referred to as \u201cinliers\u201d). This process can be repeated several times and a largest inlier set. This process can be applied to each region, for example.","At block , two-dimensional (2D) linear motion models (e.g., translation, similarity, affine) can be fit to the trackable feature-matches to describe motion of the camera between video frames or between two consecutive video frames. For example, the video may be a sequence of images I, I, . . . I, and each frame-pair (I, I) can be associated with a linear motion model F(x) modeling the motion of feature points x from Ito I. A least square fit can be determined for a linear transform that maps feature matches from one frame to the next (e.g., to describe motion of pixels between frames\u2014such as feature moved 10 pixels to the right, equivalent to movement of the camera to the left by 10 pixels). For a mathematical translation, the least square fit can be an average of translations for each feature pair match.","As one example, an estimate of the original camera path (C(t)) can be determined by fitting linear motion models to the tracked feature pair matches resulting in a linear transform for each feature pair (e.g., a linear transform describing motion of the feature of the matched feature-pair from one video frame to the next video frame). Features in a first frame may be denoted as {x, . . . , x} and corresponding features in a second frame may be denoted as {x\u2032, . . . , x\u2032}. A linear transform F can be found such that\n\n\u2003\u2003Equation (1)\n","The linear transform F may be the function minimizing",{"@attributes":{"id":"p-0062","num":"0061"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["min","p"]},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"n"},"mo":"\u2062","msup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","i"]},"mo":";","mi":"p"}}},"mo":"-","msubsup":{"mi":["x","i","\u2032"]}}},"mn":"2"}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"2"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0063","num":"0062"},"maths":{"@attributes":{"id":"MATH-US-00006","num":"00006"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","i"]},"mo":";","mi":"p"}}},{"mrow":[{"mrow":[{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","i"]},"mo":";","mn":"0"}}},{"mfrac":{"mo":"\u2146","mrow":{"mo":"\u2146","mi":"p"}},"mo":["\u2062","*"],"mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","i"]},"mo":";","mn":"0"}}},"mi":"p"}],"mo":"+"},{"mfrac":{"mo":"\u2146","mrow":{"mo":"\u2146","mi":"p"}},"mo":["\u2062","*"],"mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","i"]},"mo":",","mn":"0"}}},"mi":"p"}],"mo":"="}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"3"}}}]}}}},"br":{},"sub":["i ","i "]},{"@attributes":{"id":"p-0064","num":"0063"},"maths":{"@attributes":{"id":"MATH-US-00007","num":"00007"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mfrac":{"mo":"\u2146","mrow":{"mo":"\u2146","mi":"p"}},"mo":"\u2062","mrow":{"mi":"F","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","i"]},"mo":";","mn":"0"}}}},{"mi":"J","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["x","i"]}}}],"mo":"="},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0065","num":"0064"},"maths":{"@attributes":{"id":"MATH-US-00008","num":"00008"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"msub":{"mi":["min","p"]},"mo":"\u2062","munder":{"mo":"\u2211","mi":"i"}},"mo":"=","msup":{"mrow":{"mo":["\uf605","\uf606"],"mrow":{"mrow":{"mrow":{"mi":"J","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["x","i"]}}},"mo":"*","mi":"p"},"mo":"-","msubsup":{"mi":["x","i","\u2032"]}}},"mn":"2"}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"4"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0066","num":"0065"},"maths":{"@attributes":{"id":"MATH-US-00009","num":"00009"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mn":"1","mi":"S"},"mo":"\u2062","mrow":{"mi":"FS","mo":"."}}}},"br":{}},"Equation (4) can be solved for a number of linear motion models for each of the video frames of the video (or for any number of the video frames of the video). Many linear motion models may be used, such as a translation model {F(x; t)=x+t}, a similarity model {F(x; t, a, b)=[a\u2212b; b a]*x+t}, and an affine model {F(x; t, a, b, c, d)=[a b; c d]*x+t}. In one example, Equation (4) may be written in matrix from as",{"@attributes":{"id":"p-0068","num":"0067"},"maths":{"@attributes":{"id":"MATH-US-00010","num":"00010"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mrow":[{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"mrow":{"mi":"J","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"x","mn":"1"}}}}},{"mtd":{"mrow":{"mi":"J","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"x","mn":"2"}}}}},{"mtd":{"mi":"\u2026"}},{"mtd":{"mrow":{"mi":"J","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["x","n"]}}}}}]}},"mo":"\u2062","mi":"p"},{"mo":["[","]"],"mtable":{"mtr":[{"mtd":{"msubsup":{"mi":["x","\u2032"],"mn":"1"}}},{"mtd":{"msubsup":{"mi":["x","\u2032"],"mn":"2"}}},{"mtd":{"mi":"\u2026"}},{"mtd":{"msubsup":{"mi":["x","n","\u2032"]}}}]}}],"mo":"="},"mo":","}}},"br":{}},"Additional methods for determining two-dimensional (2D) linear motion models (e.g., translation, similarity, affine) for the trackable feature-matches are also possible. For example, a parametric motion model can be fit to the locally outlier rejected feature matches, i.e. a motion that can be described by a set of parameters or degrees of freedom (DOF) such as a translation (2 DOF), similarity (2 DOF translation, 1 DOF scale, 1 DOF rotation), affine (6 DOF) or a homography (8 DOF). A linear model can be expressed as matrix multiplication with a location x, i.e., y=A[p]*x, with A being a matrix and p the parameterization. For example, for a similarity, p=[dx, dy, s (scale), r (cos of rotation)] and A[p] would be the 3\u00d73 matrix",{"@attributes":{"id":"p-0070","num":"0069"},"maths":{"@attributes":{"id":"MATH-US-00011","num":"00011"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mo":"\u2003","mrow":{"mrow":{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mi":"s"},{"mrow":{"mo":"-","mi":"r"}},{"mrow":{"mo":"\u2146","mi":"x"}}]},{"mtd":[{"mi":"r"},{"mi":"s"},{"mrow":{"mo":"\u2146","mi":"y"}}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"}]}]}},"mo":"."}}}},"br":{},"sup":["T","T ","T"],"sub":["{L2}","x","x","y","y","{L1}","x","y","{L2}","{L2}"]},"In one example, unreliable motion models may be detected by requiring at least a certain number of feature matches per frame-pair (e.g., N=30), otherwise the frame may be flagged as unreliable). In another example, estimates from lower to higher dimension motion models (e.g., similarity\u2192homography) may be performed using matches for the higher dimension model that agree with the lower dimension within a threshold (e.g., 4 pixels) to detect unreliable motion models. In still another example, if a highest dimension motion model is deemed unreliable (e.g., too much rotation, scale or perspective) other computed models may be flagged as unreliable. A heuristic may be used that labels each frame's motion model as reliable or unreliable. Unreliable motion models can be discarded and set to identity. Additional hard constraints can be added to the optimal L1 camera path estimation to force the path to be stationary in the vicinity of unreliable frame motion models, for example. In those instances, the optimized camera path is identical with the original shaky path in these segments. In these instances, if parts of video data are too corrupted that reliable motion estimation is not possible (or is not determined), the original shaky video data can be used for this portion of the video, for example.","At block , the linear motion models (F) for each feature-pair are transformed to a common coordinate system and are concatenated to yield an estimate of the original camera path. For example, concatenation of all linear motion models for each feature-pair may describe motion between each of the frames of the video resulting in an estimate of the original camera path. A camera path is a cumulative path, and thus, if a camera path moved to the left by 10 pixels between two successive frames, and so on, by the time a fifth frame is reached, the camera may have moved 50 total pixels in distance, for example.","An inverse of the transform (F) between feature-pairs of video frames Iand I, G=F, can be used as a coordinate transform. Note that the transform Gcan be computed with respect to the coordinate system defined by frame ITherefore, to transform each Gto a common coordinate system to be able to concatenate all linear motion models, a coordinate system can be arbitrarily chosen, such as the coordinate system of G, for example.","An estimate of the original camera path can then be obtained by concatenating the frame-pair transforms G, G, . . . , G, where m denotes the number of frames. The camera path C=(C, . . . , C) can be iteratively estimated as:\n\nand\n\n()\u2003\u2003Equation (5)\n\nAn estimation of per-frame linear motion models can lead to an accumulation of error over time, and thus, each frame can be tracked with respect to a previous N frames, where N is fixed (e.g., N may be about 3 to about 5 for a speed vs. accuracy trade-off). In another example, all parameters can be estimated for all frames jointly.\n","Thus, C(t) is an estimate of the original camera path and is described by a parametric linear motion model at each instance of time. For example, the video may be a sequence of images I, I, . . . I, and each frame-pair (I, I) may be associated with a linear motion model F(x) modeling the motion of feature points x from Ito I.","Using the method  in , an estimate of the original motion of the camera or original camera path for the video recording can be made. Following, an estimate of a new steady or smooth camera path can be determined. The steady or smooth camera path may dampen high-frequency jitter and remove low-frequency distortions that occur during handheld panning shots or videos recorded by a person walking.",{"@attributes":{"id":"p-0077","num":"0076"},"figref":["FIG. 4","FIG. 4"],"b":["400","100","200","400","402","410"]},"At block , an estimate of the original camera path motion is received. At block , constraints limiting changes to the original camera path motion are received. Example constraints include an inclusion constraint that requires a frame in the smooth motion to always be contained in a frame of the original camera path motion, a proximity constraint that requires the smooth camera path motion to preserve an original intent of the recorded video (e.g., if the original camera path motion contained segments of zooming, the smooth camera path motion may also contain zooming), and a saliency constraint that requires salient points (e.g., obtained by a face detector or general mode finding in a saliency map) may be included within all or a portion of a new frame in the smooth camera path motion. As another example, the constraints may indicate that the updated camera path motion results in a video frame window that fits inside a video frame window of the original camera path motion at all times.","At block , a cost function is received and minimization is performed. For example, the smooth or optimal camera path (P) can be partitioned into three segments, where only one may be present at each time t: a constant path, representing a static camera, i.e.,",{"@attributes":{"id":"p-0080","num":"0079"},"maths":{"@attributes":{"id":"MATH-US-00012","num":"00012"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mfrac":{"mrow":[{"mo":"\u2146","mi":"P"},{"mo":"\u2146","mi":"t"}]},"mo":"=","mn":"0"},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0081","num":"0080"},"maths":{"@attributes":{"id":"MATH-US-00013","num":"00013"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"2"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","msup":{"mi":"t","mn":"2"}}]},"mo":"=","mn":"0"},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0082","num":"0081"},"maths":{"@attributes":{"id":"MATH-US-00014","num":"00014"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"3"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","msup":{"mi":"t","mn":"3"}}]},"mo":"=","mn":"0."}}},"br":[{},{},{}],"in-line-formulae":[{},{}],"i":["P","t","C","t","B","t"],"sup":"\u22121"},{"@attributes":{"id":"p-0083","num":"0082"},"maths":{"@attributes":{"id":"MATH-US-00015","num":"00015"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"a","mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"mo":"\u2146","mi":"P"},{"mo":"\u2146","mi":"t"}]}}},{"mi":"b","mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"msup":{"mi":"d","mn":"2"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","msup":{"mi":"t","mn":"2"}}]}}},{"mi":"c","mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"3"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","mi":"t"}]}}}],"mo":["+","+"]}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"7"}}}]}}}},"br":{}},"In one embodiment, weights of the cost function in Equation (7) can be preset. Alternatively, values of the weights may be determined from professional footage. For example, professional videos have different kinds of camera motions, and if jitter is added to the motion, the video stabilization algorithm may be performed to retrieve an original smooth camera path. Weights that result in a close match to the original path can be determined.","As another example, to determine weights for the cost function in Equation (7), if only one of the three derivative constraints is minimized, the original path can be approximated by either constant non-continuous paths, linear paths with jerks, or smooth parabolas with non-zero motion.  illustrate example graphs of an optimal camera path  determined based on a synthetic original camera path .  illustrates the optimal camera path  including constant non-continuous paths with weights chosen such that a=1, and b=c=0.  illustrates the optimal camera path  including linear paths with abrupt changes with weights chosen such that a=c=0 and b=1.  illustrates the optimal camera path  including smooth parabolas and non-zero motion using weights chosen such that a=b=0 and c=1.","In one embodiment, all three objectives in Equation (7) can be minimized simultaneously. Twitching motions may be noticeable in stabilized video and can be minimized when weight c is chosen to be an order of magnitude larger than a maximum of weights a and b. For example,  illustrates the optimal camera path  with weights chosen such that a=10, b=1, and c=100. Further, a choice of the underlying linear motion model has an effect on the stabilized video. Using affine transforms instead of similarities, for example, has a benefit of two added degrees of freedom, but may introduce errors in skew that lead to effects of non-rigidity. However, similarities (like affine transformation) may not be able to model a non-linear inter-frame motion or rolling shutter effects, which may result in noticeable residual wobble.","To minimize",{"@attributes":{"id":"p-0088","num":"0087"},"maths":{"@attributes":{"id":"MATH-US-00016","num":"00016"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mfrac":{"mrow":[{"mo":"\u2146","mi":"P"},{"mo":"\u2146","mi":"t"}]},"mo":"=","mn":"0"},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0089","num":"0088"},"maths":{"@attributes":{"id":"MATH-US-00017","num":"00017"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mrow":[{"mo":"\u2146","mi":"P"},{"mo":"\u2146","mi":"t"}]},"mo":"=","mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":"P","mrow":{"mi":"t","mo":"+","mn":"1"}},{"mi":["P","t"]}],"mo":"-"}},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"msub":[{"mi":"C","mrow":{"mi":"t","mo":"+","mn":"1"}},{"mi":"B","mrow":{"mi":"t","mo":"+","mn":"1"}}],"mo":"\u2062"},{"msub":[{"mi":["C","t"]},{"mi":["B","t"]}],"mo":"\u2062"}],"mo":"-"}},"mo":"."}],"mo":"="}}}},"br":{},"sub":"t "},{"@attributes":{"id":"p-0090","num":"0089"},"maths":{"@attributes":{"id":"MATH-US-00018","num":"00018"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mfrac":{"mrow":[{"mo":"\u2146","mi":"P"},{"mo":"\u2146","mi":"t"}]},"mo":"=","mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"msub":[{"mi":["C","t"]},{"mi":"F","mrow":{"mi":"t","mo":"+","mn":"1"}},{"mi":"B","mrow":{"mi":"t","mo":"+","mn":"1"}}],"mo":["\u2062","\u2062"]},{"msub":[{"mi":["C","t"]},{"mi":["B","t"]}],"mo":"\u2062"}],"mo":"-"}},{"mrow":[{"mo":["\uf603","\uf604"],"msub":{"mi":["C","t"]}},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":{"msub":[{"mi":"F","mrow":{"mi":"t","mo":"+","mn":"1"}},{"mi":"B","mrow":{"mi":"t","mo":"+","mn":"1"}}],"mo":"\u2062"},"mo":"-","msub":{"mi":["B","t"]}}},"mo":"."}],"mo":"\u2062"}],"mo":"\u2264"}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"8"}}}]}}}},"br":[{},{}],"sub":["t ","t","t","t","t+1","t+1","t"],"in-line-formulae":[{},{}],"i":["R",":=F","B","\u2212B"]},"Similarly, to minimize",{"@attributes":{"id":"p-0092","num":"0091"},"maths":{"@attributes":{"id":"MATH-US-00019","num":"00019"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"2"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","msup":{"mi":"t","mn":"2"}}]},"mo":"=","mn":"0"},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0093","num":"0092"},"maths":{"@attributes":{"id":"MATH-US-00020","num":"00020"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"2"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","msup":{"mi":"t","mn":"2"}}]},"mo":"=","mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mfrac":{"mo":"\u2146","mrow":{"mo":"\u2146","mi":"t"}},"mo":"\u2062","msub":{"mi":"P","mrow":{"mi":"t","mo":"+","mn":"2"}}},{"mfrac":{"mo":"\u2146","mrow":{"mo":"\u2146","mi":"t"}},"mo":"\u2062","msub":{"mi":"P","mrow":{"mi":"t","mo":"+","mn":"1"}}}],"mo":"-"}},{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":"P","mrow":{"mi":"t","mo":"+","mn":"2"}},{"mi":["P","t"]}],"mo":["-","+"],"mrow":{"mn":"2","mo":"\u2062","msub":{"mi":"P","mrow":{"mi":"t","mo":"+","mn":"1"}}}}},"mo":"."}],"mo":"="}}}},"br":[{},{}],"sub":["t+1","t","t+1","t","t+2","t+2","t+1","t+1","t"],"in-line-formulae":[{},{}],"i":["R","\u2212R","|=|F","B","I+F","B","+B"]},"Similarly, minimizing",{"@attributes":{"id":"p-0095","num":"0094"},"maths":{"@attributes":{"id":"MATH-US-00021","num":"00021"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"3"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","msup":{"mi":"t","mn":"3"}}]},"mo":"=","mn":"0"},"mo":","}}},"br":[{},{}],"in-line-formulae":[{},{}],"i":["R","R","+R","|=|F","B","I+","F","B","I+F","B","\u2212B"],"sub":["t+2","t+1","t","t+3","t+3","t+2","t+2","t+1","t+1","t"]},"The known frame-pair transforms Fare represented by linear motion models. For example, Fcan be given as six degrees of freedom (DOF) affine transformation",{"@attributes":{"id":"p-0097","num":"0096"},"maths":{"@attributes":{"id":"MATH-US-00022","num":"00022"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"msub":{"mi":["F","t"]},"mo":"=","mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"x","mo":";","msub":{"mi":["p","t"]}}}},{"mrow":[{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":[{"msub":{"mi":["a","t"]}},{"msub":{"mi":["b","t"]}}]},{"mtd":[{"msub":{"mi":["c","t"]}},{"msub":{"mi":["d","t"]}}]}]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":"x","mn":"1"}}},{"mtd":{"msub":{"mi":"x","mn":"2"}}}]}}],"mo":"\u2062"},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"mo":"\u2146","msub":{"mi":["x","t"]}}}},{"mtd":{"mrow":{"mo":"\u2146","msub":{"mi":["y","t"]}}}}]}}],"mo":"+"}],"mo":"="}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"12"}}}]}}}},"br":[{},{},{},{},{}],"sub":["t ","t","t","t","t","t","t","t","t","t ","t","t","t ","t","t","t+1","t+1","t","t+1","t+1","t+1 ","t+1","t+1","t"],"sup":["T","T"],"in-line-formulae":[{},{},{},{}],"i":["R","p","M","F","p","\u2212p","e\u2266M","F","p","\u2212p","\u2266e"]},"Using linear programming, constraints can be imposed on the optimal camera path so that Equation (7) is minimized subject to constraints. Recall, that prepresents the parameterization of the crop window transform B(t), which is the transform of the crop window centered in the frame rectangle. The crop window transform B(t) can be constrained so as to limit how much B(t) can deviate from the original camera path motion to preserve an intent of the original video. Therefore, strict bounds can be placed on the affine portion of the parameterization p, which according to one example of Equation (14) may include:\n\n(1)0.9\u22661.1\n\n(2)\u22120.1\u22660.1\n\n(3)\u22120.05\u22660.05\n\n(4)\u22120.1\u22660.1\u2003\u2003Equation (15)\n\nThe first two constraints in Equation (15) limit a range of change in zoom and rotation, and the latter two constraints in Equation (15) give the affine transform rigidity by limiting an amount of skew and non-uniform scale. Therefore, for each p(e.g., affine, translation, etc.), there is an upper bound (ub) and lower bound (lb) that can be written as lowerbound\u2266Up\u2266upperbound for suitable linear combinations specified by U (e.g., U is a notation placeholder, which in the example in Equation (15), lowerbound would be the vector [0.9, 0.9, \u22120.1, \u22120.1, \u22120.05, \u22120.1] and U is a matrix\n",{"@attributes":{"id":"p-0099","num":"0098"},"maths":{"@attributes":{"id":"MATH-US-00023","num":"00023"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mo":["[","]"],"mtable":{"mtr":[{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"1"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mn":"0"},{"mrow":{"mo":"-","mn":"1"}}]}]}},{"mstyle":{"mtext":")"},"mo":"."}],"mo":"\u2062"}}}},"In one example, the upper bound and lower bound for the translation parameterization may be as shown below in Equation (16):",{"@attributes":{"id":"p-0101","num":"0100"},"maths":{"@attributes":{"id":"MATH-US-00024","num":"00024"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":"e","mn":"1"},"mo":"\u2265","mn":"0"},{"msub":[{"mi":"e","mn":"2"},{"mi":"x","mn":"1"},{"mi":"x","mn":"2"},{"mi":"e","mn":"2"}],"mo":["\u2265","\u2264","\u2264","\u2264","\u2264"],"mrow":[{"mn":"0","mo":["\u2062","-"],"mstyle":{"mtext":{}},"msub":{"mi":"e","mn":"1"}},{"msub":[{"mi":"e","mn":"1"},{"mi":"e","mn":"2"}],"mo":["\u2062","-"],"mstyle":{"mtext":{}}}]}],"mo":["\u2062","\u2062"],"mstyle":{"mtext":{}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"16"}}}]}}}}},"As another example, to achieve the inclusion constraint, all four corners c=(c,c), i=1, . . . , 4 of the crop window transformed by the crop window transformation B(t) can be required to reside inside the original frame rectangle.  illustrates an example video frame rectangle and a crop window rectangle. As shown in , all four corners of the crop rectangle transformed by B(t) are within the original frame rectangle of coordinates [0,w] by [0,h].","Additional constraints may be imposed for smoothness constraints on similarity and affine linear motion model transformations. For example, in a similarity transform, a combination of scale, rotation and translation can be used. A smoothness constraint can be imposed on P(t) using weights a and b for the similarity transformation [F(x; t, a, b)=[a\u2212b; b a]*x+t]. While t corresponds to translation, scale and rotation are related to a,b as:\n\nScale: =\u221a{square root over (())}\u2003\u2003Equation (17)\n\nRotation angle: \u03b8=tan()\u2003\u2003Equation (18)\n\nWhile constraining smoothness on a,b, rotation and scale may not remain smooth. Since imposing smoothness constraints on s and theta may be non-linear, the estimated camera path can be used to ensure that s and theta do not deviate too much. For example, constraints on scale and rotation may be as follows:\n\nscale_low<<scale_hi\u2003\u2003Equation (19)\n\nTo linearize Equation (19), aand bfrom the estimated camera transform C(t) are used to get:\n\nscale_low<<scale_hi\u2003\u2003Equation (20)\n\nThe low and hi bounds can be calculated as:\n",{"@attributes":{"id":"p-0104","num":"0103"},"maths":{"@attributes":{"id":"MATH-US-00025","num":"00025"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mi":"scale_low","mo":"=","mfrac":{"mrow":{"mo":["(",")"],"mrow":{"msubsup":[{"mi":"a","mn":["0","2"]},{"mi":"b","mn":["0","2"]}],"mo":"+"}},"mi":"k"}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"21"}}}]},{"mtd":[{"mrow":{"mi":"scale_hi","mo":"=","mrow":{"mrow":{"mo":["(",")"],"mrow":{"msubsup":[{"mi":"a","mn":["0","2"]},{"mi":"b","mn":["0","2"]}],"mo":"+"}},"mo":"*","mi":"k"}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"22"}}}]}]}}},"br":{}},{"@attributes":{"id":"p-0105","num":"0104"},"maths":{"@attributes":{"id":"MATH-US-00026","num":"00026"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mrow":[{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":{"msub":[{"mi":"a","mn":"0"},{"mi":"s","mn":"0"}]},"mo":"-","msub":{"mi":"\u025b","mn":"1"}}}},{"mi":"cos","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":{"msub":[{"mi":"a","mn":"0"},{"mi":"s","mn":"0"}]},"mo":"+","msub":{"mi":"\u025b","mn":"1"}}}}],"mo":["<","<"],"mi":"a"}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"23"}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":{"msub":[{"mi":"b","mn":"0"},{"mi":"s","mn":"0"}]},"mo":"-","msub":{"mi":"\u025b","mn":"2"}}}},{"mi":"sin","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mfrac":{"msub":[{"mi":"b","mn":"0"},{"mi":"s","mn":"0"}]},"mo":"+","msub":{"mi":"\u025b","mn":"2"}}}}],"mo":["<","<"],"mi":"b"}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"24"}}}]}]}}},"br":{},"sub":["1 ","2 "]},"In one embodiment, hard constraints can be modeled in a form of \u201ctransformed points in convex shape\u201d. For example, for an affine parameterization of p, constraints may be as shown below in Equation (25):",{"@attributes":{"id":"p-0107","num":"0106"},"maths":{"@attributes":{"id":"MATH-US-00027","num":"00027"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mn":"0"}},{"mtd":{"mn":"0"}}]}},{"mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"msubsup":{"mi":["c","i","x"]}},{"msubsup":{"mi":["c","i","y"]}},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"msubsup":{"mi":["c","i","x"]}},{"msubsup":{"mi":["c","i","y"]}}]}]}},"mo":"\u2062","msub":{"mi":["p","t"]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mi":"w"}},{"mtd":{"mi":"h"}}]}}],"mo":["\u2264","\u2264"]}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"25"}}}]}}}},"br":{},"figref":"FIG. 6"},"Referring back to the method  in , at block , a crop window transformation B(t) of a pre-defined scale less than one with respect to the original frame size is determined subject to the constraints and minimizations of the residuals. In one example, P(t)=C(t)*B(t), as shown in Equation (6) above, and B(t) is the crop window transform. The crop window transform may be determined by minimizing (ce), with respect to the parameterization vector p, where\n\n=(),=()\n\n=()\u2003\u2003Equation (26)\n\nwhere e is the upper and lower bound as shown in Equation (14) and w are weights. To minimize the L1 norm of the residual, the L1 norm of the slack variable e can be minimized. In vector form, for example, the minimization can be written as the dot product of c\u00b7e (or ce) with c being the vector of all 1. In other examples, c may contain the weights a, b, c from Equation (7) for the corresponding components.\n","The function (ce) may be minimized subject to various constraints, such as:\n\nSmoothness: ()\u2266\n\n()\u2212()\u2266\n\n()\u22122()+()\u2266\n\n\u22670\u2003\u2003Equation (27)\n\nProximity: lowerbound\u2266Up\u2266upperbound\u2003\u2003Equation (28)\n\nInclusion: (0,0)\u2266()\u2003\u2003Equation (29)\n\nIn one example, although the objective ce is minimized, in a linear program all variables in the constraints may be determined (a linear combination of values according to smoothness, proximity and inclusion may be modeled via slack variables). Therefore, for each frame t, corresponding parameters pcan be determined, and B(t)=A(x; p) as in Equation (12).\n","At block , after determining the crop window transformation, B(t), the crop window transformation is applied to the original video to reformat the video or to stabilize the video. For example, the crop window transform may be applied to a crop window of fixed size within domain (or frame size) of the original video. By copying the pixel within the crop window, that is applying the crop, the original video is recast from a viewpoint of the smooth camera path. In other examples, the copying can be supplemented with bi-linear or bi-cubic blending to achieve subpixel accuracy.","When recasting the video, original camera motions may result in equivalent smooth motion of feature points with certain assumptions. For example, for camera translation, if a distance from the camera to objects is much greater than a velocity in any direction, then a static camera results in static feature points, a constant velocity lateral to camera results in constant feature point velocity, a constant velocity in depth approximately results in a constant feature point velocity, and the same approximations can be made for accelerations. As another example, for camera zoom, a constant velocity zoom results in a constant feature point velocity. As still another example, for camera rotation, feature point motion derivatives may diminish as a square of angular velocity.",{"@attributes":{"id":"p-0112","num":"0111"},"figref":["FIG. 7","FIG. 7","FIG. 7","FIG. 4"],"sub":["t","1","2","3 ","1 ","2","2 ","1 ","2 ","1"]},{"@attributes":{"id":"p-0113","num":"0112"},"figref":["FIGS. 8A-8B","FIG. 8A","FIG. 8A"],"b":["802","804","802"]},{"@attributes":{"id":"p-0114","num":"0113"},"maths":{"@attributes":{"id":"MATH-US-00028","num":"00028"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mfrac":{"mrow":[{"mo":"\u2146","mi":"P"},{"mo":"\u2146","mi":"t"}]},"mo":"=","mn":"0"},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0115","num":"0114"},"maths":{"@attributes":{"id":"MATH-US-00029","num":"00029"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"2"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","msup":{"mi":"t","mn":"2"}}]},"mo":"=","mn":"0"},"mo":","}}},"br":{}},{"@attributes":{"id":"p-0116","num":"0115"},"maths":{"@attributes":{"id":"MATH-US-00030","num":"00030"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"2"},"mo":"\u2062","mi":"P"},{"mo":"\u2146","msup":{"mi":"t","mn":"3"}}]},"mo":"=","mn":"0."}}},"br":{},"figref":"FIG. 8B"},"As described above using the example methods shown in , a 2D original camera path motion C(t) may be first estimated, and a new path P(t) can be determined. The camera stabilization crop transform B(t) can then be determined that stabilizes C(t) resulting in P(t). In one embodiment, instead of solving for P(t) in two steps by first estimating C(t) and then optimizing for the path P(t), both steps can be performed simultaneously by directly optimizing for the stabilization transform from feature correspondences. In other examples, minimization of residuals may not require C(t), and the per-frame transforms F(t) may be sufficient. Similarly, P(t) may not be computed, but rather B(t) may be obtained. However, in some examples, C(t) and P(t) can be computed via concatenation.","In the example methods shown above in , the estimation of the original camera path motion C(t) can be determined using frame pairs and relying on first order derivatives. The methods are based on N frames, which requires concatenation of camera path derivatives and can lead to error accumulation.","As described above using the example methods shown in , the original camera path motion is approximately an inverse of an average feature path transformation (e.g., as a camera moves to the left, the image pixel content or features move to the right). The average can be computed over robust feature points. As another example, the estimation of the original camera path motion and determination of the new optimal camera path can be performed to simultaneously stabilize all (or several) feature points. For example, using L1 minimization over all features (e.g., for the translation model) results in a \u201cmedian\u201d of feature tracks as opposed to an average, which can be more robust. A frame stabilization transform, A(t), can be estimated at each frame. A(t) transforms each video frame (and equivalently features in the frame) as opposed to transforming the camera path or crop window as above in the methods of . For example,",{"@attributes":{"id":"p-0120","num":"0119"},"maths":{"@attributes":{"id":"MATH-US-00031","num":"00031"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},"mo":"=","mfrac":{"mn":"1","mrow":{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"30"}}}]}}}},"br":[{},{},{},{}],"b":["0","1"],"in-line-formulae":[{},{},{},{}],"i":["G","=A","t","F","[k","G","=A","*F","[i"],"sub":["k(t)","k(t)","ki","i","ki","k "]},{"@attributes":{"id":"p-0121","num":"0120"},"maths":{"@attributes":{"id":"MATH-US-00032","num":"00032"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"munderover":{"mo":"\u2211","mi":"t","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mi":"k","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"mo":["[","]"],"mrow":{"mrow":[{"mi":"a","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mfrac":{"mrow":[{"mo":"\u2146","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mo":"\u2146","mi":"t"}]},"mo":"\u2062","msub":{"mi":"G","mrow":{"mi":"k","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}}}}},{"mi":"b","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"2"},"mo":"\u2062","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mo":"\u2146","msup":{"mi":"t","mn":"2"}}]},"mo":"\u2062","msub":{"mi":"G","mrow":{"mi":"k","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}}}}},{"mi":"c","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mfrac":{"msup":{"mo":"\u2146","mn":"3"},"mrow":{"mo":"\u2146","msup":{"mi":"t","mn":"3"}}},"mo":"\u2062","msub":{"mi":"G","mrow":{"mi":"k","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}}}}}],"mo":["+","+"]}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"31"}}}]}}}},"br":{}},{"@attributes":{"id":"p-0122","num":"0121"},"maths":{"@attributes":{"id":"MATH-US-00033","num":"00033"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"munderover":{"mo":"\u2211","mi":"t","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mi":"k","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"mi":"a","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}},{"msub":{"mi":["F","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}}],"mo":"\u2062"},{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":"F","mrow":{"mi":"k","mo":"\u2062","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}}},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}],"mo":"\u2062"}],"mo":"-"}}}}},{"mi":"b","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}},{"msub":{"mi":["F","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}}],"mo":"\u2062"},{"mn":"2","mo":["\u2062","\u2062"],"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":["F","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]},{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mn":"1"}}},{"msub":{"mi":["F","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mn":"1"}}}],"mo":"\u2062"}],"mo":["-","+"]}}},{"mi":"c","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"2"}}},{"msub":{"mi":["F","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"2"}}}],"mo":"\u2062"},{"mn":"3","mo":["\u2062","\u2062"],"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}},{"msub":{"mi":["F","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}}]},{"mn":"3","mo":["\u2062","\u2062"],"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":["F","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]},{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mn":"1"}}},{"msub":{"mi":["F","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mn":"1"}}}],"mo":"\u2062"}],"mo":["-","+","-"]}}}],"mo":["+","+"]}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"32"}}}]}}}},"br":{},"sub":["k","k"]},{"@attributes":{"id":"p-0123","num":"0122"},"maths":{"@attributes":{"id":"MATH-US-00034","num":"00034"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["J","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mfrac":{"mrow":[{"mo":"\u2146","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mo":"\u2146","mi":"t"}]},"mo":["\u2062","\u2062"],"mrow":[{"mi":"pA","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"msub":{"mi":["F","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]}],"mo":"="}}},"br":{}},{"@attributes":{"id":"p-0124","num":"0123"},"maths":{"@attributes":{"id":"MATH-US-00035","num":"00035"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"munderover":{"mo":"\u2211","mi":"t","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mi":"k","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"mi":"a","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mrow":[{"msub":{"mi":["J","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}}],"mo":"\u2062"},{"mrow":[{"msub":{"mi":["J","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}],"mo":"\u2062"}],"mo":"-"}}}}},{"mi":"b","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mrow":[{"msub":{"mi":["J","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}}],"mo":"\u2062"},{"mn":"2","mo":["\u2062","\u2062"],"mrow":[{"msub":{"mi":["J","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]},{"mrow":[{"msub":{"mi":["J","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mn":"1"}}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mn":"1"}}}],"mo":"\u2062"}],"mo":["-","+"]}}},{"mi":"c","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mrow":[{"msub":{"mi":["J","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"2"}}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"2"}}}],"mo":"\u2062"},{"mn":"3","mo":["\u2062","\u2062"],"mrow":[{"msub":{"mi":["J","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"+","mn":"1"}}}]},{"mn":"3","mo":["\u2062","\u2062"],"mrow":[{"msub":{"mi":["J","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}]},{"mrow":[{"msub":{"mi":["J","k"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mn":"1"}}},{"mi":"p","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","mn":"1"}}}],"mo":"\u2062"}],"mo":["-","+","-"]}}}],"mo":["+","+"]},{"mrow":[{"munderover":{"mo":"\u2211","mrow":{"mi":["t","k"],"mo":","},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"mi":"a","mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mfrac":{"mrow":[{"mo":"\u2146","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mo":"\u2146","mi":"t"}]},"mo":"\u2062","mi":"Jp"}}}},{"mi":"b","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"2"},"mo":"\u2062","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mo":"\u2146","msup":{"mi":"t","mn":"2"}}]},"mo":"\u2062","mi":"Jp"}}},{"mi":"c","mo":"*","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"3"},"mo":"\u2062","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"mo":"\u2146","msup":{"mi":"t","mn":"3"}}]},"mo":"\u2062","mi":"Jp"}}}],"mo":["+","+"]}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"33"}}}]}}}}},"Note that Equation (33) may be a summation over all feature points as opposed to just the camera path. The constraints required to ensure that the crop window remains within the original frame can be handled in an alternate manner. For example, applying the constraints as before would result in constraint equations as shown in Equation (34):",{"@attributes":{"id":"p-0126","num":"0125"},"maths":{"@attributes":{"id":"MATH-US-00036","num":"00036"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mn":["0","1"],"mo":["<","<"],"mrow":{"mrow":{"mi":"B","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},"mo":"*","mi":"w"}},{"mn":["0","1"],"mo":["<","<"],"mrow":{"mfrac":{"mn":"1","mrow":{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}},"mo":"*","mi":"w"}}],"mo":"\u2192"}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"34"}}}]}}}},"br":{},"sub":["l","t","b","r"]},{"@attributes":{"id":"p-0127","num":"0126"},"maths":{"@attributes":{"id":"MATH-US-00037","num":"00037"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["0","0"],"mo":","}}},{"mo":["(",")"],"mi":"x"}],"mo":"\u2062"},"mo":"<","msub":{"mi":["c","l"]}},{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["0","0"],"mo":","}}},{"mo":["(",")"],"mi":"y"}],"mo":"\u2062"},"mo":"<","msub":{"mi":["c","t"]}},{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["1","0"],"mo":","}}},{"mo":["(",")"],"mi":"x"}],"mo":"\u2062"},"mo":">","msub":{"mi":["c","r"]}},{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["1","0"],"mo":","}}},{"mo":["(",")"],"mi":"y"}],"mo":"\u2062"},"mo":"<","msub":{"mi":["c","t"]}},{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["0","1"],"mo":","}}},{"mo":["(",")"],"mi":"x"}],"mo":"\u2062"},"mo":"<","msub":{"mi":["c","l"]}},{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["0","1"],"mo":","}}},{"mo":["(",")"],"mi":"y"}],"mo":"\u2062"},"mo":">","msub":{"mi":["c","b"]}},{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["1","1"],"mo":","}}},{"mo":["(",")"],"mi":"x"}],"mo":"\u2062"},"mo":">","msub":{"mi":["c","r"]}},{"mrow":{"mrow":[{"mi":"A","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mn":["1","1"],"mo":","}}},{"mo":["(",")"],"mi":"y"}],"mo":"\u2062"},"mo":">","msub":{"mi":["c","b"]}}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mtext":{}},{"mtext":{}},{"mtext":{}},{"mtext":{}},{"mtext":{}},{"mtext":{}},{"mtext":{}}]}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"35"}}}]}}}},"br":[{},{},{}],"in-line-formulae":[{},{}],"i":"Avn","sup":"t"},{"@attributes":{"id":"p-0128","num":"0127"},"figref":["FIGS. 9A-9B","FIG. 4","FIGS. 9A-9B"],"b":["900","902"]},"As still another example, the estimation of the original camera path motion and determination of the new optimal camera path can be performed to stabilize using more than a single transform between frame pairs and less than using all feature points. For example, a small number of transforms between a frame pair can be used, and each of transforms may correspond to different regions in an image that may be moving differently. Each region may correspond to a different transform, and therefore a different M matrix in Equation (13) above. Equation (13) may become:",{"@attributes":{"id":"p-0130","num":"0129"},"maths":{"@attributes":{"id":"MATH-US-00038","num":"00038"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"munderover":{"mo":"\u2211","mi":"k","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":{"msub":[{"mi":["M","k"]},{"mi":"p","mn":"1"}],"mo":"*"},"mo":"-","msub":{"mi":"p","mn":"2"}}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"37"}}}]}}}},"br":{}},"Each of the transforms could also be weighted differently depending upon various factors, such as, for example, foreground\/background separation (stabilize foreground more than background), a size of regions (stabilize larger regions more than smaller regions), and texturedness (stabilize textured regions over untextured regions). The camera path optimization may then determine a stabilization that minimizes the L1 norm of path smoothness over all transforms. The optimization may lead to selecting a set of transforms to smooth while leaving regions unstable. The choice of which transforms are smoothed may be determined by a combination of individual importance (weights).","III. Content-Aware Video Stabilization and Video Retargeting","Within embodiments, any number of linear constraints may be added for forcing or limiting a modification of the recorded video in some way. For example, constraints can be added to ensure that the crop window remain inside an original video frame. Other types of constraints may be used for content aware constraints, such as maintaining a face (e.g., from a face detector) or other salient (or user-marked) objects\/regions within an original video frame. Content-aware constraints may be specified as regions that remain in the cropped frame entirely (e.g., hard constraint) or to some degree (e.g., soft constraint). The constraints may also be specified on a per-frame basis as the estimated smooth camera path may propagate the constraints from key-frames to other frames.","In one example, if a region of interest is represented using a bounding polygon, such as a bounding box, then one constraint for containment may be that each vertex of the polygon lie within the cropping window, e.g., require that specific salient points reside within the crop window. If v is a vertex of the polygon, then in the camera path optimization framework, the constraint is opposite of Equation (36) and may be represented by:\n\n()\u22670\u2003\u2003Equation (38)\n\nThis may be considered a hard constraint and may limit the region of interest to remain inside the cropping window.\n","As another example, a more relaxed constraint is a soft \u201cone-sided\u201d constraint that penalizes any vertices that move out of the cropping window. As described above, the L1 minimization can be converted to a linear program by adding slack variables, which are minimized, and modified constraints that bound the original constraint within lowerbound\u2266Up\u2266upperbound. A similar procedure may be used to bound the constraints from one side. Specifically, the objective cost function may include:",{"@attributes":{"id":"p-0136","num":"0135"},"maths":{"@attributes":{"id":"MATH-US-00039","num":"00039"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"munderover":{"mo":"\u2211","mi":"k","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"msub":[{"mi":["w","k"]},{"mi":["d","k"]}],"mo":"*"}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"39"}}}]}}}},"br":[{},{},{}],"in-line-formulae":[{},{}],"i":["A","t","v","n","\u2267\u2212d"],"sub":["k","k","k","k"],"sup":"t"},"In one example, to require that specific salient points reside within the crop window, an optimization is performed that is the inverse of stabilization transform F, i.e., a feature transform W(e.g., warp transform) can be applied to a set of features in each frame I. An inverse of Fis denoted by G=F. Instead of transforming the crop window by B, a transform Wof the current features such that motion within a static crop window is composed of static, linear, or parabolic motion is determined. The transform is then given as B=W.",{"@attributes":{"id":"p-0138","num":"0137"},"figref":"FIG. 10"},"The corresponding objectives for minimization of the warp transform (similar to Equation (7) above) may be as follows:",{"@attributes":{"id":"p-0140","num":"0139"},"maths":{"@attributes":{"id":"MATH-US-00040","num":"00040"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":[{"mtd":[{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"4.4em","height":"4.4ex"}}},"mo":"\u2062","mrow":{"mrow":[{"mi":"Minimize","mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"1.1em","height":"1.1ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":[{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"mo":"\u2146","mi":"W"},{"mo":"\u2146","mi":"t"}]}},{"mo":["\uf603","\uf604"],"msub":{"mi":["R","t"]}}]},{"mo":["\uf603","\uf604"],"mrow":{"msub":{"mi":["W","t"]},"mo":"-","mrow":{"msub":[{"mi":"W","mrow":{"mi":"t","mo":"+","mn":"1"}},{"mi":"G","mrow":{"mi":"t","mo":"+","mn":"1"}}],"mo":"\u2062"}}}],"mo":"="}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"41"}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"Minimize","mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":[{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"2"},"mo":"\u2062","mi":"W"},{"mo":"\u2146","msup":{"mi":"t","mn":"2"}}]}},{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":"R","mrow":{"mi":"t","mo":"+","mn":"1"}},{"mi":["R","t"]}],"mo":"-"}}]},{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"msub":[{"mi":"W","mrow":{"mi":"t","mo":"+","mn":"3"}},{"mi":"G","mrow":{"mi":"t","mo":"+","mn":"3"}},{"mi":"G","mrow":{"mi":"t","mo":"+","mn":"2"}}],"mo":["\u2062","\u2062"]},{"mn":"2","mo":["\u2062","\u2062"],"msub":[{"mi":"W","mrow":{"mi":"t","mo":"+","mn":"1"}},{"mi":"G","mrow":{"mi":"t","mo":"+","mn":"1"}}]}],"mo":["-","+"],"msub":{"mi":["W","t"]}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"42"}}}]},{"mtd":[{"mrow":{"mrow":[{"mi":"Minimize","mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mrow":[{"mo":["\uf603","\uf604"],"mfrac":{"mrow":[{"msup":{"mo":"\u2146","mn":"3"},"mo":"\u2062","mi":"W"},{"mo":"\u2146","msup":{"mi":"t","mn":"3"}}]}},{"mo":["\uf603","\uf604"],"mrow":{"msub":[{"mi":"R","mrow":{"mi":"t","mo":"+","mn":"2"}},{"mi":["R","t"]}],"mo":["-","-"],"mrow":{"mn":"2","mo":"\u2062","msub":{"mi":"R","mrow":{"mi":"t","mo":"+","mn":"1"}}}}}]},{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"msub":[{"mi":"W","mrow":{"mi":"t","mo":"+","mn":"4"}},{"mi":"G","mrow":{"mi":"t","mo":"+","mn":"4"}},{"mi":"G","mrow":{"mi":"t","mo":"+","mn":"3"}},{"mi":"G","mrow":{"mi":"t","mo":"+","mn":"2"}}],"mo":["\u2062","\u2062","\u2062"]},{"mn":"3","mo":["\u2062","\u2062","\u2062"],"msub":[{"mi":"W","mrow":{"mi":"t","mo":"+","mn":"3"}},{"mi":"G","mrow":{"mi":"t","mo":"+","mn":"3"}},{"mi":"G","mrow":{"mi":"t","mo":"+","mn":"2"}}]},{"mn":"3","mo":["\u2062","\u2062"],"msub":[{"mi":"W","mrow":{"mi":"t","mo":"+","mn":"1"}},{"mi":"G","mrow":{"mi":"t","mo":"+","mn":"1"}}]}],"mo":["-","+","-"],"msub":{"mi":["W","t"]}}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"43"}}}]}]}}}},"In one example, saliency constraints may be specified as well using the warp transform. For example, a specific point (e.g., mode in a saliency map) or convex region (e.g., from a face detector) may be constrained to remain within the crop window. A set of salient points in frame Imay be denoted by s. To estimate the feature transform (e.g., instead of the crop window transform), a one-sided bound (instead of a two-sided bounds for inclusion constraints as in Equation (29)) can be introduced on stransformed by A(p):",{"@attributes":{"id":"p-0142","num":"0141"},"maths":{"@attributes":{"id":"MATH-US-00041","num":"00041"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mrow":[{"mrow":{"mo":["(",")"],"mtable":{"mtr":[{"mtd":[{"mn":"1"},{"mn":"0"},{"msubsup":{"mi":["s","i","x"]}},{"msubsup":{"mi":["s","i","y"]}},{"mn":"0"},{"mn":"0"}]},{"mtd":[{"mn":"0"},{"mn":"1"},{"mn":"0"},{"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},{"msubsup":{"mi":["s","i","x"]}},{"msubsup":{"mi":["s","i","y"]}}]}]}},"mo":"\u2062","msub":{"mi":["p","t"]}},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"msub":{"mi":["b","x"]}}},{"mtd":{"msub":{"mi":["b","y"]}}}]}}],"mo":"-"},{"mo":["(",")"],"mtable":{"mtr":[{"mtd":{"mrow":{"mo":"-","msub":{"mi":["\u025b","x"]}}}},{"mtd":{"mrow":{"mo":"-","msub":{"mi":["\u025b","y"]}}}}]}}],"mo":"\u2265"}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"44"}}}]}}}},"br":{},"sub":["x","y","k","y"]},{"@attributes":{"id":"p-0143","num":"0142"},"figref":["FIG. 11","FIG. 11"],"b":["1100","1102","1100","1100","1102"],"sub":["x","x ","y","y ","i ","x","x","x","y","x ","y "],"sup":"T"},"Inclusion constraint can be used and adjusted from those described above, as the crop window points can be transformed by the inverse of the optimized feature transform. In one example, transformed frame corners may be required to lie within a rectangular area around a crop rectangle, as illustrated in  above, for example. An estimation of the optimal feature paths can be achieved from feature points fin frame I, i.e., without a need to compute G, for example. In this setting, instead of minimizing the L1 norm of the parameterized residual R(p), the L1 norm of the feature distance can be minimized. Thus, Rbecomes;",{"@attributes":{"id":"p-0145","num":"0144"},"maths":{"@attributes":{"id":"MATH-US-00042","num":"00042"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mo":["\uf603","\uf604"],"msub":{"mi":["R","t"]}},{"munderover":{"mo":"\u2211","msub":{"mi":"f","mrow":{"mi":["k","featurematches"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},{"mtext":":"},{"mspace":{"@attributes":{"width":"0.6em","height":"0.6ex"}}}]}},"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","msub":{"mrow":{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mrow":{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":["p","t"]}}},"mo":"\u2062","msubsup":{"mi":["f","k","t"]}},{"mrow":{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"msub":{"mi":"p","mrow":{"mi":"t","mo":"+","mn":"1"}}}},"mo":"\u2062","msubsup":{"mi":["f","k"],"mrow":{"mi":"t","mo":"+","mn":"1"}}}],"mo":"-"}},"mn":"1"}}],"mo":"="}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"45"}}}]}}}},"br":{},"sub":["t ","t+1","k","k","t "],"sup":["t","t+1"]},"IV. Residual Motion (Wobble and Rolling Shutter) Removal","To model inter-frame motion for shake-removal, motion models with a higher number of DOFs than similarities may be needed. In one embodiment, a hybrid approach can be used with similarities Sto construct an optimal camera path. The optimal camera path can be determined for every k=30 key frames of a recorded video using higher dimensional homographies Hto account for mis-alignments.",{"@attributes":{"id":"p-0148","num":"0147"},"figref":["FIG. 12","FIG. 12"],"sub":["1","2 ","2 ","t ","2 ","2 ","2","1 ","2 ","1 ","2 "],"sup":"\u22121"},"For an example camera path in , C=C*F. In , Fis referred to as Sto indicate that the transformation is similarity (e.g., C=C*S). To determine the relationship between optimal path transforms Pand P, in one example, if the video could be stabilized perfectly P=P*S, which may indicate that the residual in the L1 minimization is zero. In general, however, this may not occur, and thus, the transform from Pto Pcan be referred to as a similarity and a residual motion T, such that P=P*S*T. Thus, the motion T=SPP.","In one example, the Tmay be considered a smooth additional motion layered on top of the stabilization transform Sto account for various constraints introduced. The path transform Pcan be re-computed by substituting Swith a higher parametric motion model H(e.g., homography) in the equation for Presulting in P\u2032=P*H*T. This may result in a more stabilized result (e.g., more degrees of freedom can adapt to rolling shutter, etc.), and may also lead to drift (e.g., instabilities due to concatenation in skew, perspective, etc.). To remove or compensate for drift, the computed P(e.g., free of drift as based on similarities) may be used at key frames (e.g., every 30frame), and the substitution of Hmay be used in between. In one example, the substitution may be employed from the previous and next key frame to determine P\u2032and P\u2033. A new wobble reduced camera path can then obtained as a weighted average of a\u2032 P\u2032+a\u2033 P\u2033. A linear weight may be used based on a distance to the key frames, e.g., a\u2032 is 1 and a\u2033=0 at the previous key frame and a\u2032=0 and a\u2033=1 at the next frame, linear in between.","V. Video Retargeting","Content-aware constraints may also be used for retargeting in addition to or rather than stabilization. Retargeting refers modifying a recorded video to fit a device with a different resolution aspect-ratio than the recorded video. Using methods described herein, a cropping window can be matched to an aspect ratio of a target device, for example. Further, content aware constraints can be used to ensure that salient content stays within the crop window. Optionally, stabilization of feature points can be performed as well.","In one embodiment, to perform retargeting, instead of estimating a forward feature transform F between every pair of frames and using the resulting M matrices (e.g., as for performing stabilization), a number of matrices M=I (identity), which corresponds to minimizing\n\n||\u2003\u2003Equation (46)\n\ninstead of minimizing Equation (13) (including higher order terms) as for performing stabilization, for example.\n","Video Retargeting may change the aspect ratio of a video while preserving salient, i.e., visually prominent regions.","A crop window may have a fixed predetermined size. For example, a scale may be predetermined by first performing a video stabilization and then expanding the crop window to a maximum possible size that fits within the transformed frame windows over all frames, i.e., determine A(t)*v, where v are the frame window corners for all frames t. A largest rectangle (represented by lines m) can be determined, such that:\n\n()0\u2003\u2003Equation (47)\n\nNote that since m may be axis aligned, computing this rectangle can be accomplished by identifying minimum and maximum values of the frame window coordinates over all times.\n","In one embodiment, constraints may be added to the one-sided constraints above such that the frame transforms, A(t), result in as large a frame window as possible. A corresponding objective and constraint may be of the form:",{"@attributes":{"id":"p-0157","num":"0156"},"maths":{"@attributes":{"id":"MATH-US-00043","num":"00043"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mi":"Min","mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mi":"k","mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}},"mo":"\u2062","mrow":{"msub":[{"mi":["w","k"]},{"mi":["d","k"]}],"mo":"\u2062"}}}},{"mrow":{"mi":"Equation","mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mo":["(",")"],"mn":"48"}}}]}}}},"br":{},"sup":"t","sub":["k","k","k ","k "]},"VI. Example Systems and Computer Program Products",{"@attributes":{"id":"p-0159","num":"0158"},"figref":["FIG. 13","FIGS. 1-2"],"b":["1300","1302","1300","1310","1320","1330","1310","1320","1310","1315","1310","1315","1310"]},"Depending on the desired configuration, the system memory  can be of any type including but not limited to volatile memory (such as RAM), non-volatile memory (such as ROM, flash memory, etc.) or any combination thereof. System memory  may include one or more applications , and program data . Application  may include an video stabilization algorithm  that is arranged to provide inputs to the electronic circuits, in accordance with the present disclosure. Program Data  may include video content information  that could be directed to any number of types of data. In some example embodiments, application  can be arranged to operate with program data  on an operating system.","Computing device  can have additional features or functionality, and additional interfaces to facilitate communications between the basic configuration  and any devices and interfaces. For example, data storage devices  can be provided including removable storage devices , non-removable storage devices , or a combination thereof. Examples of removable storage and non-removable storage devices include magnetic disk devices such as flexible disk drives and hard-disk drives (HDD), optical disk drives such as compact disk (CD) drives or digital versatile disk (DVD) drives, solid state drives (SSD), and tape drives to name a few. Computer storage media can include volatile and nonvolatile, non-transitory, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, or other data.","System memory  and storage devices  are examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media can be part of device .","Computing device  can also include output interfaces  that may include a graphics processing unit , which can be configured to communicate to various external devices such as display devices  or speakers via one or more A\/V ports  or a communication interface . The communication interface  may include a network controller , which can be arranged to facilitate communications with one or more other computing devices  over a network communication via one or more communication ports . The communication connection is one example of a communication media. Communication media may be embodied by computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media. A modulated data signal can be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media can include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency (RF), infrared (IR) and other wireless media.","Computing device  can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions. Computing device  can also be implemented as a personal computer including both laptop computer and non-laptop computer configurations.","In some embodiments, the disclosed methods may be implemented as computer program instructions encoded on a computer-readable storage media in a machine-readable format, or on other non-transitory media or articles of manufacture.  is a schematic illustrating a conceptual partial view of an example computer program product  that includes a computer program for executing a computer process on a computing device, arranged according to at least some embodiments presented herein. In one embodiment, the example computer program product  is provided using a signal bearing medium . The signal bearing medium  may include one or more program instructions  that, when executed by one or more processors may provide functionality or portions of the functionality described above with respect to . Thus, for example, referring to the embodiments shown in , one or more features of blocks - and\/or blocks - may be undertaken by one or more instructions associated with the signal bearing medium . In addition, the program instructions  in  describe example instructions as well.","In some examples, the signal bearing medium  may encompass a computer-readable medium , such as, but not limited to, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, memory, etc. In some implementations, the signal bearing medium  may encompass a computer recordable medium , such as, but not limited to, memory, read\/write (R\/W) CDs, R\/W DVDs, etc. In some implementations, the signal bearing medium  may encompass a communications medium , such as, but not limited to, a digital and\/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.). Thus, for example, the signal bearing medium  may be conveyed by a wireless form of the communications medium  (e.g., a wireless communications medium conforming with the IEEE 802.11 standard or other transmission protocol).","The one or more programming instructions  may be, for example, computer executable and\/or logic implemented instructions. In some examples, a computing device such as the computing device  of  may be configured to provide various operations, functions, or actions in response to the programming instructions  conveyed to the computing device  by one or more of the computer readable medium , the computer recordable medium , and\/or the communications medium .","It should be understood that arrangements described herein are for purposes of example only. As such, those skilled in the art will appreciate that other arrangements and other elements (e.g. machines, interfaces, functions, orders, and groupings of functions, etc.) can be used instead, and some elements may be omitted altogether according to the desired results. Further, many of the elements that are described are functional entities that may be implemented as discrete or distributed components or in conjunction with other components, in any suitable combination and location.","While various aspects and embodiments have been disclosed herein, other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting, with the true scope being indicated by the following claims, along with the full scope of equivalents to which such claims are entitled. It is also to be understood that the terminology used herein is for the purpose of describing particular embodiments only, and is not intended to be limiting."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE FIGURES","p":[{"@attributes":{"id":"p-0010","num":"0009"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIGS. 5A-5D"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIGS. 8A-8B"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIGS. 9A-9B"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 14"}]},"DETDESC":[{},{}]}
