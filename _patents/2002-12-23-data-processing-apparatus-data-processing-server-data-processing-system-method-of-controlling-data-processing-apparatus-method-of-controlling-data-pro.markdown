---
title: Data processing apparatus, data processing server, data processing system, method of controlling data processing apparatus, method of controlling data processing server, computer program, and computer readable storage medium
abstract: This invention provides a data processing apparatus, data processing server, and data processing system, which can easily edit data by utilizing features of object-based coding, and can easily generate object-based encoded multimedia data. A multimedia edit & playback terminal () issues an edit instruction of multimedia data to a multimedia edit server () that edits multimedia data consisting of a plurality of object data. A communication client () receives layout information of multimedia data. A playback unit () displays the acquired layout information, and an edit designation unit () designates desired one of the displayed layout information. The designated layout information is output via the communication client ().
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07865833&OS=07865833&RS=07865833
owner: Canon Kabushiki Kaisha
number: 07865833
owner_city: Tokyo
owner_country: JP
publication_date: 20021223
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS"],"p":["The present invention relates to a data processing apparatus, a data processing server, a data processing system, a method of controlling a data processing apparatus, a method of controlling a data processing server, a computer program, and a computer readable storage medium, which are used to edit multimedia data which have been multimedia-encoded by MPEG-4 (Moving Picture Expert Group Phase 4) coding, multimedia coding having an object description function, and the like.","In recent years, as digital data broadcast and digital video have prevailed, end users can handle multimedia data with ease. Also, prevalence of mobile communication devices such as portable phones, and the like allows the user to easily make wireless communications at a place where he or she visited, and an environment that allows network connections is in order. Hence, as a result of easy accessibility to multimedia data, mobile communication device such as a so-called third-generation portable phone and the like, which can handle multimedia data, have appeared.","However, a conventional portable terminal device does not always have sufficient processor performance and storage area to attain size and weight reductions. Hence, in order to process multimedia data, it is a common practice to, e.g., drop the resolution of an image or the frame rate (the number of frames per unit time) of a moving image.","Yet, a conventional portable terminal device does not perform any processes that fully utilize features of multimedia data to be handled. For this reason, in a portable terminal device as a typical compact, lightweight mobile communication device, various devices are made to attain size and weight reductions and to process multimedia data within its limited data processing performance and memory or within a limited bandwidth upon communications, so as to utilize its features. As one of such devices, low-bitrate, high-compression multimedia coding such as MPEG-4 may be used.","Object-based coding such as MPEG-4 can form one multimedia data by a plurality of objects. To these objects, data of various formats such as a moving image, static image, computer graphics (or vector graphics), text, audio, and the like can be applied. These objects can be held together with layout information of a tree structure.","However, the current specifications associated with multimedia data have very complicated format, and it is difficult to edit multimedia data under many restrictions.","Conventionally, upon editing such complicated multimedia data, it is a common practice to ask a third party, who saves and edit data in a personal computer or the like, which has less restrictions, or possesses a dedicated data edit machine, to do the actual job. Hence, services that execute an edit process by a server with a data edit function on the Internet and return the edit result to a client are provided, and techniques associated with such services have been studied.","At the present time, a simple multimedia e-mail service that composites a static image, sent to a server on the Internet, with a photo frame, music, message, or the like to generate composite data, and returns a URL (Uniform Resource Locators, RFC1738) indicating that processing result has been made available. That is, user's edit operations are made on another machine with sufficient processing performance, which is connected via a communication line or the like, due to limitations on the processing performance of the terminal device.","As described above, the process for making a server on the Internet edit data, and returning the processing result can composite a static image or a simple rectangular moving image by HTML (HyperText Markup Language). However, a process that edits multimedia data which has been encoded by object-based coding, and allows the user to acquire the edit result as object-based encoded data is not available.","On the other hand, the current specifications associated with multimedia data have very complicated format, and it is difficult to edit multimedia data under many restrictions. In this manner, since it is hard to edit multimedia data on a portable terminal with limited processing performance, the user must carry out a procedure for saving multimedia data on a personal computer as an apparatus having higher performance than the portable terminal, saving the edit result on the portable terminal again, and playing it back.","Conventionally, upon editing such complicated multimedia data, it is a common practice to ask a third party, who saves and edit data in a personal computer or the like, which has less restrictions, or possesses a dedicated data edit machine, to do the job. Based on this, services that execute an edit process by a server with a data edit function on the Internet and return the edit result to a client are provided, and techniques associated with such services have been proposed.","For example, according to Japanese Patent No. 3208116, a method of generating indices for audio and moving image data, and searching for a scene using such indices has been proposed. With this method, a location to be edited can be specified without playing back multimedia data.","Also, according to Japanese Patent Laid-Open No. 10-6608, a method that combines macro and micro searches and allows the user to conduct an easy moving image search has been proposed. In order to solve the aforementioned problems, this technique allows to easily search for a moving image saved in a WWW server, and to edit on the server side by designating edit conditions such as edit start and edit instructions from a WWW browser.","However, when every data edit processes are executed by a personal computer or the like which has less restrictions, another problem, i.e., a long data communication time, is posed. On the other hand, even a terminal device such as a portable terminal which has very limited processor performance and storage area can execute simple processes such as a process for extracting a part of a moving image.","The present invention has been proposed to solve the conventional problems, and has as its object to provide a data processing apparatus, data processing server, and data processing system, which allow even a portable terminal with limited processing performance to easily edit data by utilizing features of object-based coding, and to easily generate object-based encoded multimedia data by connecting a server which can edit multimedia data and issuing edit instructions to that server.","In order to achieve the above object, a data processing apparatus according to the present invention is directed to a data processing apparatus which can be connected, via a network, to a data processing server that edits multimedia data consisting of predetermined object data, comprising reception means for receiving templates of edit processes for the multimedia data from the data processing server, designation means for designating one of the templates received by the reception means, and transmission means for transmitting information indicating the template designated by the designation means and the multimedia data to the data processing server so as to execute a desired edit process for the multimedia data.","A data processing apparatus according to the present invention is directed to a data processing apparatus which can be connected, via a network, to a data processing server that generates multimedia data consisting of predetermined object data, comprising reception means for receiving templates of edit processes for the multimedia data from the data processing server, designation means for designating one of the templates received by the reception means, and transmission means for transmitting information indicating the template designated by the designation means and predetermined object data to the data processing server so as to generate desired multimedia data.","A data processing server according to the present invention is directed to a data processing server which can be connected, via a network, to a data processing apparatus that generates multimedia data consisting of predetermined object data, comprising reception means for receiving multimedia data, and information indicating a template of an edit process for the multimedia data from the data processing apparatus, split means for splitting the multimedia data received by the reception means into object data that form the multimedia data, and edit means for generating new multimedia data using the object data split by the split means, and the information indicating the template of the edit process received by the reception means.","A data processing server according to the present invention is directed to a data processing server which can be connected, via a network, to a data processing apparatus that generates predetermined object data, comprising reception means for receiving predetermined object data, and information indicating a template of an edit process, which generates desired multimedia data using the predetermined object data, from the data processing apparatus, and edit means for generating multimedia data using the object data and the information indicating the template of the edit process received by the reception means.","A method of controlling a data processing apparatus according to the present invention is directed to a method of controlling a data processing apparatus which can be connected, via a network, to a data processing server that edits multimedia data consisting of predetermined object data, comprising the reception step of receiving templates of edit processes for the multimedia data from the data processing server, the designation step of designating one of the templates received in the reception step, and the transmission step of transmitting information indicating the template designated in the designation step and the multimedia data to the data processing server so as to execute a desired edit process for the multimedia data.","A method of controlling a data processing apparatus according to the present invention is directed to a method of controlling a data processing apparatus which can be connected, via a network, to a data processing server that generates multimedia data consisting of predetermined object data, comprising the reception step of receiving templates of edit processes for the multimedia data from the data processing server, the designation step of designating one of the templates received in the reception step, and the transmission step of transmitting information indicating the template designated in the designation step and predetermined object data to the data processing server so as to generate desired multimedia data.","A method of controlling a data processing server according to the present invention is directed to a method of controlling a data processing server which can be connected, via a network, to a data processing apparatus that generates multimedia data consisting of predetermined object data, comprising the reception step of receiving multimedia data, and information indicating a template of an edit process for the multimedia data from the data processing apparatus, the split step of splitting the multimedia data received in the reception step into object data that form the multimedia data, and the edit step of generating new multimedia data using the object data split in the split step, and the information indicating the template of the edit process received in the reception step.","A method of controlling a data processing server according to the present invention is directed to a method of controlling a data processing server which can be connected, via a network, to a data processing apparatus that generates predetermined object data, comprising the reception step of receiving predetermined object data, and information indicating a template of an edit process, which generates desired multimedia data using the predetermined object data, from the data processing apparatus, and the edit step of generating multimedia data using the object data and the information indicating the template of the edit process received in the reception step.","A computer program according to the present invention is directed to a computer program for controlling a data processing apparatus which can be connected, via a network, to a data processing server that edits multimedia data consisting of predetermined object data, comprising a code of the reception step of receiving templates of edit processes for the multimedia data from the data processing server, a code of the designation step of designating one of the templates received in the reception step, and a code of the transmission step of transmitting information indicating the template designated in the designation step and the multimedia data to the data processing server so as to execute a desired edit process for the multimedia data.","A computer program according to the present invention is directed to a computer program for controlling a data processing apparatus which can be connected, via a network, to a data processing server that generates multimedia data consisting of predetermined object data, comprising a code of the reception step of receiving templates of edit processes for the multimedia data from the data processing server, a code of the designation step of designating one of the templates received in the reception step, and a code of the transmission step of transmitting information indicating the template designated in the designation step and predetermined object data to the data processing server so as to generate desired multimedia data.","A computer program according to the present invention is directed to a computer program for controlling a data processing server which can be connected, via a network, to a data processing apparatus that generates multimedia data consisting of predetermined object data, comprising a code of the reception step of receiving multimedia data, and information indicating a template of an edit process for the multimedia data from the data processing apparatus, a code of the split step of splitting the multimedia data received in the reception step into object data that form the multimedia data, and a code of the edit step of generating new multimedia data using the object data split in the split step, and the information indicating the template of the edit process received in the reception step.","A computer program according to the present invention is directed to a computer program for controlling a data processing server which can be connected, via a network, to a data processing apparatus that generates predetermined object data, comprising a code of the reception step of receiving predetermined object data, and information indicating a template of an edit process, which generates desired multimedia data using the predetermined object data, from the data processing apparatus, and a code of the edit step of generating multimedia data using the object data and the information indicating the template of the edit process received in the reception step.","It is another object of the present invention to provide a data processing apparatus, a data processing server, a data processing system, a method of controlling a data processing apparatus, a method of controlling a data processing server, a computer program, and a computer readable storage medium, which can implement efficient edit processes for respective multimedia data objects by executing an edit process that can be processed by a terminal device on the terminal device side, and executing an edit process, which is hardly executed by the terminal device side due to limited CPU performance, memory size, battery, and the like of the terminal device, on the server side having higher performance.","In order to achieve the above object, a data processing apparatus according to the present invention is directed to a data processing apparatus which can be connected, via a network, to a data processing server that edits multimedia data consisting of predetermined object data, comprising input means for inputting multimedia data, edit process designation means for designating an edit process for the multimedia data, judgment means for judging an apparatus that executes the edit process designated by the edit process designation means, and transmission means for transmitting the multimedia data to the data processing server so as to apply the designated edit process to the multimedia data in accordance with an output from the judgment means.","A data processing server according to the present invention is directed to a data processing server which can be connected to the aforementioned data processing apparatus via a network, comprising input means for inputting predetermined multimedia data, and an edit instruction of the multimedia data from the data processing apparatus, and edit means for editing the multimedia data on the basis of the edit instruction.","A method of controlling a data processing apparatus according to the present invention is directed to a method of controlling a data processing apparatus which can be connected, via a network, to a data processing server that edits multimedia data consisting of predetermined object data, comprising the input step of inputting multimedia data, the edit process designation step of designating an edit process for the multimedia data, the judgment step of judging an apparatus that executes the edit process designated in the edit process designation step, and the transmission step of transmitting the multimedia data to the data processing server so as to apply the designated edit process to the multimedia data in accordance with a judgment result of the judgment step.","A method of controlling a data processing server according to the present invention is directed to a method of controlling a data processing server which can be connected to the aforementioned data processing apparatus via a network, comprising the input step of inputting predetermined multimedia data, and an edit instruction of the multimedia data from the data processing apparatus, and the edit step of editing the multimedia data on the basis of the edit instruction.","A computer program according to the present invention is directed to a computer program for controlling a data processing apparatus which can be connected, via a network, to a data processing server that edits multimedia data consisting of predetermined object data, comprising a code of the input step of inputting multimedia data, a code of the edit process designation step of designating an edit process for the multimedia data, a code of the judgment step of judging an apparatus that executes the edit process designated in the edit process designation step, and a code of the transmission step of transmitting the multimedia data to the data processing server so as to apply the designated edit process to the multimedia data in accordance with a judgment result of the judgment step.","A computer readable storage medium according to the present invention stores the computer program.","Other features and advantages of the present invention will be apparent from the following description taken in conjunction with the accompanying drawings, in which like reference characters designate the same or similar parts throughout the figures thereof.","Preferred embodiments of the present invention will now be described in detail in accordance with the accompanying drawings.","Prior to a description of the preferred embodiments of the present invention, an explanation that pertains to object-based coding will be given first. Object-based coding such as MPEG-4 can form one multimedia data by a plurality of objects. To these objects, data of various formats such as a moving image, static image, computer graphics (or vector graphics), text, audio, and the like can be applied. The multimedia data holds information associated with a combination among these objects as layout information (to be referred to as \u201cscene\u201d hereinafter) of a tree structure.",{"@attributes":{"id":"p-0056","num":"0055"},"figref":["FIG. 1","FIG. 1","FIG. 1","FIG. 1"],"b":["101","102","103","104","105","106","107","105"]},"In this manner, in object-based coding, respective objects themselves are independently present, and these objects are stored in one or more files or the like. For example, all objects are stored in a single file together in one system, or objects are stored in different formats using given units, and are played back together as if they were a single file in another system.","For example, in MPEG-4, a file format called MP4 is standardized as one of such storage methods (ISO\/IEC 14496-1\/2000.1 \u201cMPEG-4 3Edition\u201d 13. File Format). In the following description, as for the storage method of objects, assume that all objects are stored in a single file, for the sake of simplicity.","Upon editing object-based encoded multimedia data, as shown in , not only a function of editing each individual object itself, but also a function of editing the scene  that gives layout of individual objects must be taken into consideration.","Handling of object-based encoded multimedia data is complicated compared to that of conventional data that solely gives a moving image or static image. Therefore, editing the scene  also edits the positions of individual objects and their synchronization, and it may be difficult to attain such process depending on the processing performance of a terminal. Generation of multimedia data requires higher processing performance than playback of multimedia data.","<First Embodiment>","An embodiment that utilizes features of object-based coding, and easily edits multimedia data using a multimedia edit server which is independent from a terminal that plays back multimedia data, will be described first.",{"@attributes":{"id":"p-0062","num":"0061"},"figref":["FIG. 2","FIG. 2"],"b":["201","202","203"]},"The multimedia edit & playback terminal  comprises an edit instruction unit  for issuing instructions for an edit process and the like, a playback unit  for playing back and displaying intermediate and final results of the edit process, a client edit processor  for making a simple edit process, and a communication client  for making various data communications with the multimedia edit server . On the other hand, the multimedia edit server  comprises a communication server unit  for receiving data such as edit instructions and the like, and a server edit processor  for executing an edit process of multimedia data.","In the multimedia edit & playback terminal , the edit instruction unit  comprises, e.g., a GUI (Graphical User Interface) or the like, and has a function of accepting user's operations and issuing edit operation instructions; it executes general processes except for a function associated with playback of multimedia data in this embodiment.","The playback unit  plays back multimedia data; a device which has a function of decoding and displaying multimedia data. The client edit processor  is connected to the edit instruction unit and playback unit , and provides simple edit functions, i.e., various data edit functions within the processable range of the multimedia edit & playback terminal .","Furthermore, the communication client  is connected to the client edit processor, and is used to execute communication processes. That is, the communication client  has a function of sending various operations associated with edit operations instructed from the edit instruction unit  to the multimedia edit server  via the network . Also, the communication client  has a function of receiving multimedia data from the multimedia edit server  and supplying it to the playback unit  that presents the final and intermediate results of the edit process done by the multimedia edit server  in a user recognizable form.","On the other hand, in the multimedia edit server , the communication server  is connected to the network , and implements a communication processing function on the multimedia edit server  corresponding to the communication client  in the multimedia edit & playback terminal . The edit unit  executes an edit process of multimedia data on the basis of instructions from the edit instruction unit  of the multimedia edit & playback terminal .","Note that the network  can adopt various communication environments such as a wireless communication system represented by a communication environment based on PDC (Personal Digital Cellular), GSM (Global System for Mobile Communications), CDMA (Code Division Multiple Access) or the like, a wireless LAN (Local Area Network), a wired LAN represented by Ethernet, and the like.","The electrical arrangements of the multimedia edit & playback terminal  and multimedia edit server  will be described below.  is a schematic block diagram showing the electrical arrangement of the multimedia edit & playback terminal . As shown in , the multimedia edit & playback terminal  comprises a transmitter  and receiver  or a transceiver  as a combination of them, an input\/output operation unit , a display unit , a calculation & control unit , a memory unit , a coding processor , and an external data input\/output unit .","The transmitter  and receiver  or the transceiver  as a combination of them provides communication means for communicating with a mobile communication station when the multimedia edit & playback terminal  is, e.g., a mobile communication device. Or the transmitter  and receiver  or the transceiver  provides communication means such as IP protocol or the like when the multimedia edit & playback terminal  is connected via, e.g., a LAN or the like.","Information to be exchanged by the transmitter  and receiver  or the transceiver  as a combination of them includes, e.g., multimedia data themselves, their information processing requests such as a send instruction, edit instruction, and the like, and so forth.","The input\/output operation unit  is a pointing device, keypad, or the like, which is operated by the user. The input\/output operation unit  may include a lamp or loudspeaker, which is used to inform an operation state. That is, the input\/output operation unit  provides practical operation means and other device operation functions of a multimedia edit process to the user.","The display unit  provides a display function represented by an LCD (Liquid Crystal Display), and the user can view the operation contents and the playback result of multimedia data via this unit. Upon playing back multimedia data, audio data such as music, speech, and the like are often simultaneously expressed. In this case, an expression function of such data is represented by the display unit  for the sake of simplicity.","The calculation & control unit  comprises a microprocessor, clock, bus controller, and the like, and controls the overall multimedia edit & playback terminal . The control of the overall multimedia edit & playback terminal  includes, e.g., transfer of display data to the display unit , control of a refresh instruction, and the like.","The memory unit  is a storage medium for storing multimedia data, a basic program used to control the multimedia edit & playback terminal , an application program that provides edit functions, and the like. As the memory unit , an internal storage area assured on a semiconductor memory, a storage medium represented by a magnetic disk, and the like may be used. A portable terminal or the like normally uses a nonvolatile semiconductor memory or the like, and various kinds of storage media mentioned above may be combined.","The memory unit  may comprise a semiconductor disk or the like such as an IC card, which can be detachable from the internal memory of the device. When the memory unit  comprises a semiconductor disk such as a detachable IC card, data are input\/output via the external data input\/output unit  to be described later.","The coding processor  executes a coding or an decoding process and the like of multimedia data, e.g., a compression\/decompression process for coding\/decoding multimedia data. With a function associated with this compression\/decompression process, for example, if the multimedia edit & playback terminal  has a camera function, photographed information can be stored in the memory unit  via the coding processor . The external data input\/output unit  is used to input\/output data to\/from an external storage medium such as a semiconductor disk, magnetic disk, magnetooptical disk, or the like.",{"@attributes":{"id":"p-0078","num":"0077"},"figref":["FIG. 4","FIG. 4"],"b":["202","202","401","402","403","404","405","406","407","201"]},"The transmitter  and receiver  or the transceiver  as a combination of them provides communication means with the multimedia edit & playback terminal . For example, when the network  is the Internet, and the multimedia edit & playback terminal  is connected via an ISP (Internet Service Provider), the transmitter  and receiver  or the transceiver  corresponds to an Ethernet connection device connected to the backbone of the Internet.","The calculation & control unit , memory unit , and external storage device  respectively correspond to the calculation & control unit , memory unit , and external data input\/output unit  in the multimedia edit & playback terminal , and are substantially equivalent to those of an information processing apparatus such as a general computer or the like.","The coding processor  executes a coding or an decoding process and the like of multimedia data, and has, e.g., a compression\/decompression function of coding\/decoding multimedia data in some cases. Also, the coding processor  may have a calculation processing function required upon editing multimedia data. The coding processor  shown in  and the coding processor  shown in  execute the coding or the decoding process and the like of multimedia data.","Multimedia data processing often requires huge resources of an information processing apparatus, and a dedicated encoding processor is used for such purpose. However, as the processing performance of a calculation & control unit has improved in recent years, the calculation & control unit can process multimedia data. For this reason, in the present invention, the coding processors  and  may not be indispensable building components.","The multimedia edit server  may be constituted by a plurality of apparatuses in place of a single apparatus for the purpose of distributing the load. Note that parallel processors are included in this scope.","The arrangements of the multimedia edit & playback terminal  and multimedia edit server  have been explained. The edit instruction unit , playback unit , client edit processor , communication client , communication server unit , and server edit processor  in the block diagram of  that shows the logical arrangement correspond to logical operations upon actually executing the processing operation according to the present invention.","For example, when the edit instruction unit  executes an edit instruction process, data is input from the external data input\/output unit , the calculation & control unit  executes a process in response to an input from the input\/output operation unit , and the display unit  displays the operation contents.","The processing sequence upon editing multimedia data using the multimedia edit system which comprises the multimedia edit & playback terminal  and multimedia edit server  in this embodiment described above will be described below.",{"@attributes":{"id":"p-0087","num":"0086"},"figref":["FIG. 5","FIG. 1"],"b":["201","501","101","201"]},"After the multimedia edit server  connected via the network  confirms access from the multimedia edit & playback terminal , it reads a list of templates, which are used upon data edit and allow the user to picture the edit result, from a database or the like of the external storage device  or the like, and outputs it to the multimedia edit & playback terminal  (step S). The multimedia edit & playback terminal  acquires information associated with the output list of templates (step S).","Note that a template means configuration information of multimedia data, which contains a scene that indicates the positions and the like of individual objects which form multimedia data, an object such as pre-set computer graphics or the like, and so forth.","The user selects a desired template such as a template which is approximate to the layout of multimedia data that the user wants to edit from the acquired list of templates (step S). After the template has been selected, the multimedia edit & playback terminal  sends the multimedia data to be edited selected in step S and information that uniquely specifies the selected template to the multimedia edit server  (step S).","Note that the information that uniquely specifies a template may use a template ID formed by an arbitrary character string or the like, a URL (Uniform Resource Locators, RFC1738), or the like.","The multimedia edit server  receives the multimedia data and the information that uniquely specifies the selected template (step S). The multimedia edit server  starts an edit process of the multimedia data using the template.","In the edit process, the received multimedia data is split into objects (step S). This process utilizes a split function called an object splitter, and splits the multimedia data into various objects such as a moving image, static image, computer graphics (or vector graphics), text, audio, scene, and the like.","In object-based coding, data is split into individual objects in place of their types. That is, if one multimedia data contains three moving image data, the data is split into three moving image objects.","The split objects can be applied to an object configuration described in the template selected in step S. Then, an application process for compositing the object configuration of the selected template and the split objects is executed (step S).","Note that the object configuration set as the template does not always match that of the multimedia data to be edited. For this reason, in the template application process in step S, a template application state operation process that includes user's operations at the multimedia edit & playback terminal  may be executed (step S).","The objects and template are composited and new multimedia data is edited (step S). The new multimedia data as the edit result is returned to the multimedia edit & playback terminal  (step S).","The multimedia edit & playback terminal  receives the new multimedia data returned from the multimedia edit server  (step S), and can play back and save that data (step S).",{"@attributes":{"id":"p-0099","num":"0098"},"figref":["FIG. 6","FIG. 5","FIG. 6","FIG. 6"],"b":["601","501","602","201","503"]},"In the example shown in , the data configurations of the multimedia data  and data in the template list  are simple. When the multimedia data is split into objects, an object group  consists of moving image A, computer graphics A, background static image A, and scene A indicating their configuration. On the other hand, an object group  which forms the selected template (ID=2 in this case) consists of an object node that contains a moving image, computer graphics B, background static image B, and scene B indicating their configuration. Note that the object node means the original location of each object, and no object is actually present at that location in the object group .","In an edit result  obtained by editing these objects, this object node is replaced by the object of moving image A contained in the multimedia data  to be edited. Ina composite result  after object composition, objects other than that of moving image A contained in the multimedia data  to be edited are replaced by those of the selected template.","The application process (step S) for compositing the object configuration of the selected template and the split objects, and the composition process (step S) of the object group and template in the flow chart of  will be described in more detail below.","In general, when object-based coding is based on MPEG-4, a scene uses a language called VRML (Virtual Reality Modeling Language). As a scene of object-based coding, XML (extensible Markup Language), HTML (HyperText Markup Language), SMIL (Synchronized Multimedia Integration Language), MHEG (Multimedia and Hypermedia information coding Experts Group), and the like may be used. Furthermore, digital broadcast uses BML (Broadcast Markup Language), and various languages may be used to describe a scene.","Since it is difficult to describe about all these languages in reference to this embodiment, a case will be explained below wherein object-based coding is done based on MPEG-4, VRML is used as scene information, and object information is internally defined by a structure description language such as XML or the like.","When multimedia data to be edited is described by MPEG-4, each individual object data is linked to a scene via a value called ES_ID. For example, objects are linked in such a manner that ES_ID=1 is a moving image, ES_ID=2 is a first static image, ES_ID=3 is a second static image, ES_ID=4 is scene information itself, and so forth.","In the standard, each individual object is linked to a descriptor called OD (Object Descriptor), and the type of each object is set by a value called StreamType (ISO\/IEC 14496-1).","In this manner, when multimedia data to be edited is described by MPEG-4, the types of objects and the link positions of objects in a scene can be detected with reference to the aforementioned information upon splitting the multimedia data into objects. For example, moving image A in the example in  is described to have ES_ID=3 and StreamType=4.","On the other hand, in a template, a scene is described in VRML, and information associated with that scene is described in a structure description language. These pieces of information may be described as a single file, or may be present as data on different memories.  shows an example wherein a description of a scene expressed in VRML is partially extracted.","A scene  partially describes a scene described in VRML, and %PLACE_HOLDER% describes a reference to an object to be actually embedded. Information  associated with the scene describes information of a scene expressed in XML, and %PLACE_HOLDER% similarly describes a reference to an object to be actually embedded. As described within Decoder Config tags, \u201c4\u201d is set in StreamType, meaning the type of this object is 4.","Therefore, by cross-reference via this StreamType, how to set an object contained in multimedia data to be edited with respect to an object node present in a template can be determined.","Note that matching of the object types and the number of objects between individual objects in multimedia data to be edited, and object nodes contained in the template must be taken into consideration. For example, if the number of object nodes which are contained in the template and to which objects can be applied is larger than that in the edit source, an object may be omitted in the object composition process. In an opposite case, not all objects can be applied to the template. For this reason, in the template application state operation process (step S) that includes user's operations in the edit processing sequence shown in , an interactive process for solving the aforementioned problem may be executed.","The order of processes executed between the multimedia edit & playback terminal  operated by the user, and the multimedia edit server  will be explained below. In the processing sequence shown in , the order of step S of selecting multimedia data to be edited, and step S of acquiring template list information may be arbitrarily determined, and their order may be reversed to that in the above embodiment. Even when a template is selected from the template list information, and multimedia data to be edited is then selected, these processes are independent from each other, and do not influence each other.","Also, after multimedia data to be edited is output to the multimedia edit server  and is split into objects, a template may be selected. In such order of processes, since multimedia data has already been split into objects before selection of a template, only templates that match the number of objects of the multimedia data to be edited can be presented to the user.","As described above, since the multimedia edit server  stores templates of object-based encoded multimedia data, and multimedia data to be edited is sent to the multimedia edit server  and undergoes an edit process, object-based encoded data can be easily edited. Since an edit process based on a scene is executed in place of encoding individual objects, a subsidiary effect can be obtained, i.e., the processing contents (e.g., encoding of a moving image) that impose heavy processing load can be reduced as much as possible.","<Second Embodiment>","An embodiment that utilizes features of object-based coding, and simply edits multimedia data using a multimedia edit server which is independent from a terminal that plays back and edits multimedia data, will be described below.","The first embodiment has explained a case wherein the already generated object-based encoded multimedia data is selected and edited. Also, the present invention can be applied to a case wherein multimedia data is generated from individual objects.",{"@attributes":{"id":"p-0117","num":"0116"},"figref":["FIG. 8","FIG. 8"],"b":["801","802","803","802","803","801","201"]},"However, if input digital data is each individual object that does not contain any scene, the edit process of the already generated object-based encoded multimedia data described in the first embodiment cannot be applied. Instead, the multimedia edit & playback terminal  can output the moving image data  and static image data  as individual objects to the multimedia edit server .","The digital data which are sent to the multimedia edit server  are equivalent to objects obtained upon completion of the process (step S) for splitting multimedia data into objects in the flow chart shown in .","If the data sent () from the multimedia edit & playback terminal  can be used as objects that match a template , data edited via object composition is sent () to the multimedia edit & playback terminal , thus generating object-based encoded multimedia data. The multimedia data generated in this way can be played back and displayed (), and so-called rich multimedia data can be generated by a simple method by selecting a template.","Object formats in the process for generating multimedia data from individual objects will be additionally explained. An object encoder  is connected to the multimedia edit server  in the multimedia edit system shown in . This object encoder  is included as one building component of the multimedia edit server .","The object encoder  is a module for shaping each individual object sent from the multimedia edit & playback terminal  to the multimedia edit server  to a format suitable for object-based coding.","For example, assume that object-based coding of data to be generated is MPEG-4. If the format of object sent from the multimedia edit & playback terminal  is Motion-JPEG which is not handled in MPEG-4, a Motion-JPEG object must be encoded to a format that MPEG-4 can handle. In such case, the object encoder  is used. The object encoder  decodes, e.g., Motion-JPEG data into bitmap data, and encodes the bitmap data as an input into MPEG-4 moving image object data.","To attain the aforementioned process, a function of checking the format of each individual input object, and determining a format into which that object must be converted is required to be added.  shows an example of an object encoder decision table used to decide the object format. Referring to , an input format  indicates the format of a corresponding input object, and can be designated using a MIME (Multipurpose Internet Mail Extension, RFC2045 to 2049) type or file format.","An output format  indicates a format that the object encoder  must output, and may be similarly designated by a MIME type or an arbitrary, unique format. An object encoder  designates a value, library name, and the like to be given to a function entry or a decision routine that calls a function of the object encoder. Using the object encoder decision table shown in , each individual object sent from the multimedia edit & playback terminal  to the multimedia edit server  can be converted into an optimal format.","Note that the object encoder decision table shown in  may contain additional information such as a processing parameter or the like and a format in object coding, i.e., StreamType or the like described above in case of MPEG-4. Also, if the output format  is uniquely determined in advance depending on an object encoder, the output format  may be omitted by a tacit agreement.","Furthermore, the input format  may be checked by interpreting each individual object sent from the multimedia edit & playback terminal  to the multimedia edit server . Alternatively, the multimedia edit & playback terminal  may send a value to the multimedia edit server  in advance.","Note that a file format and bitstream that store objects contain a data format unique to each individual object type, and a method of determining the object type by interpreting object data is generally made. Normally, the multimedia edit & playback terminal  that outputs objects recognizes the type of object to be output, and can easily inform that type upon outputting the object.","As described above, according to the present invention, since not only the already generated multimedia data but also individual objects are sent from the multimedia edit & playback terminal  to the multimedia edit server , and undergo object composition using a template, even a multimedia edit & playback terminal which does not have sufficiently high multimedia data generation performance can easily generate multimedia data. Also, the present invention can be applied to a case wherein multimedia data has already been sent to the multimedia edit server .","<Third Embodiment>","In the first and second embodiments, the multimedia data edit process is completed when the edit result of the multimedia edit server  is returned to the multimedia edit & playback terminal . If the multimedia edit & playback terminal  does not require any edit result, the load on the multimedia edit & playback terminal  may be further reduced.","For example, the user may make only edit operations and confirmation of an edit result on the multimedia edit & playback terminal  under the condition that another terminal having a faster communication line finally acquires the edit result.",{"@attributes":{"id":"p-0132","num":"0131"},"figref":["FIG. 10","FIG. 10"],"b":["1001","401","202","1002","201","1001"]},"In the transmission process (step S) of the edit result in the flow chart shown in , it is not difficult to transmit multimedia data as the edit result using a stream server such as RTP or the like. Such stream server itself is prevalently used, and a feature of the present invention resides in application of such stream server and the like to the multimedia edit & playback terminal and multimedia edit server, and the multimedia edit system using them.","An example of an effect obtained upon implementing the multimedia edit system according to the present invention will be explained below. If the edit result is received as a file, the communication time becomes longer with increasing file size, thus imposing a heavier load on the multimedia edit & playback terminal . Hence, by streaming data, the user can view the edit result without any file transfer time although he or she can immediately receive the whole edit result.","An effect of such mechanism will be described in detail below. Assume that a given object is embedded in multimedia data serving as a template in advance in addition to an object which is set by the user, and the size of that object is 10 Mbytes. For example, if an object is a moving image, such object often has such size.","On the other hand, assume that an object to be edited set by the user is a 300-kbyte static image, and the user expects to edit a static image photographed by himself or herself as a multimedia object in combination with a moving image which is embedded in advance.","For example, if the communication performance of the multimedia edit & playback terminal  that the user possesses is as low as 64 kbps, the expected transmission time of the aforementioned object is around 40 sec, but the time required to acquire the edit result exceeds 20 min. Although the communication speed is becoming higher year by year along with the advance of technologies, such time difference is not preferable.","Hence, when a stream server is used to acquire the edit result, such acquisition time can be greatly reduced, and the limitation on a storage device required for the multimedia edit & playback terminal  is remarkably relaxed. That is, a quick edit process for the user is expected, and an edit process can be smoothly done on a portable terminal with limited processing performance.","Also, a method of playing back the edit result should be decided depending on user's advantages, i.e., whether the user requires the edited multimedia data itself on the multimedia edit & playback terminal  or requires to only confirm the edit result. Such decision can be implemented by providing choices on, e.g., an operation window of edit instructions or the like.","<Fourth Embodiment>","This embodiment will exemplify a process executed when the multimedia edit & playback terminal  has processing performance to such a degree that it can sequentially play back multimedia data along the time axis, and can extract encoded data at a significant frame position, but its performance is insufficient to execute a heavy-loaded edit process (e.g., conversion of moving image data into an oil-painting-touch image). Note that the multimedia edit & playback terminal  and the like in this embodiment use the apparatuses described in the first embodiment using .",{"@attributes":{"id":"p-0141","num":"0140"},"figref":["FIG. 11","FIG. 3","FIG. 11"],"b":["201","1109","305","1109","1101","1102","1103","1104","1105","1106"]},"Furthermore, the display device  has a cross-cursor key  and determination button , which correspond to the input\/output operation unit  that provides these button operations to the user. For example, when the user wants to execute an edit process for trimming a part of multimedia data to be edited (1 min) so as to obtain multimedia data of about 10 sec, he or she operates the cross-cursor key  and presses the start button , which is used to set a period, at the start frame position. The user then presses the end button  at the end frame position. After that, the user presses the button  used to issue a trim instruction, thus trimming designated frames.","When the user wants to convert a part of multimedia data to be edited into an oil-painting-touch image, he or she can press the button  used to issue an oil-painting-touch image instruction in place of the button  used to issue a trim instruction.","The processing sequence will be explained below using this window example.  is a flow chart showing the flow of the processing sequence of the multimedia edit & playback terminal  in this embodiment. Assume that multimedia data to be edited is pre-stored in a recording medium connected to the external data input\/output unit  in the multimedia edit & playback terminal , for the sake of simplicity.","The user operates the input\/output operation unit  to read out multimedia data from the recording medium, thus displaying the multimedia data on the display device  shown in  (step S).","The user sets a predetermined period of the readout multimedia data using the start and end buttons  and , which are used to set a period (step S). Assume that the period set by this operation normally reflects significant positions upon encoding in encoded data of the multimedia data. More specifically, encoding such as MPEG-4 or the like that can assure a high compression ratio adopts a complicated encoding algorithm (e.g., encoded data includes image frame data from which complete image data can be reconstructed, and differential frames which hold only differences before and after such image frame data) For this reason, when a differential frame is designated as the start position of a period to be set, or a middle position of frame data is designated, a heavy load is imposed on a data process, resulting in a complicated process.","As a method of searching for such significant frame positions, various methods (e.g., a method of designating a frame position using an index) may be adopted, but a description thereof will be omitted here. Also, assume that the trim process is implemented to allow a process on the multimedia edit & playback terminal , since the period to be processed is set using significant positions upon encoding and, hence, the load on a so-called decode process is small.","After the multimedia data is displayed on the display device  and the period setting process is complete, the set period is stored in a storage device such as the memory  or the like. A program implemented according to the present invention waits for a user's operation instruction while it is ready to read out the set period (step S). If user's operation has been made at the input\/output operation unit , the program acquires the operation contents (step S) and acquires only the set period (step ).","It is checked if the operation contents instruct a trim process (step S). If the operation instructs a trim process (YES), the calculation & control unit , coding processor , or the like executes the trim process (step S), and the trim result is displayed. After that, the flow returns to the standby state in step S.","On the other hand, if the operation contents do not instruct any trim process (NO), it is checked if the operation contents instruct oil-painting-touch conversion (step S). If the operation contents instruct oil-painting-touch conversion (YES), a command file containing the operation contents is generated (step S) The generated command file is sent to the multimedia edit server  (step S). Note that the command file designates data which gives an oil-painting-touch conversion instruction, and multimedia data to be converted. In some cases, it may take time until the result of the edit process requested to the multimedia edit server  is returned. To cope with such case, a message shown in  may be displayed.  shows an example of a message displayed on the display unit  of the multimedia edit & playback terminal .","After the command file is sent to the multimedia edit server , the program waits for the result returned from the multimedia edit server  (step S). It is then checked if the result returned from the multimedia edit server  is normal (step S). As a result, if the result is normal (YES), that result is displayed, and the flow returns to the standby state in step S. On the other hand, if the result is abnormal (NO), the process ends.","Although not described in the flow chart shown in , the multimedia edit & playback terminal  that has received the result from the multimedia edit server  can also execute playback & save processes of the edit result.","The command file will be explained below. The command file designates data which instructs edit contents of multimedia data, and multimedia data itself. As for this command file, data to be sent to the multimedia edit server  to instruct edit contents, i.e., data upon communication, is considered as a logical file, but a physical file is not always generated.","The command file contains at least three items. That is, the command file contains a command indicating the edit process contents of multimedia data, processing parameters required for that command, and multimedia data to be edited. The multimedia data need not always be data itself but may be a reference to multimedia data to be sent to the multimedia edit server  together with the command file. If the command that indicates the edit contents does not require any processing parameters, the processing parameters need not always be included.","Details of a format used to describe such command file, and a communication protocol to be used are not the essence of the present invention. However, as a characteristic method of effecting the essence of the present invention, a description method using a structure description language is known. An example of a description using this structure description language will be explained below.  shows an example of a command file used to edit multimedia data. As shown in , a command file  describes data in the structure description language. In this embodiment, the command file contains a command \u201cOilpaint\u201d  indicating the edit contents, a reference  to multimedia data , and an edit parameter . In this example, the multimedia data is to be referred to, but may be embedded in this command file.","In this way, the edit process contents, multimedia data to be edited, and edit parameter can be clearly described using the structure description language. Even when an edit parameter to be designated varies depending on the edit contents, when the contents to be designated as an edit parameter vary while the edit contents remain the same, or when a plurality of edit parameters are required or structured, such parameter can be flexibly described. Of course, if no edit parameter is required, the parameter need not be present.","The structure description language can easily use protocols and processing applications for data exchange and can easily build a system according to the present invention, since a format which has already been standardized and is generally available such as XML (extensible Markup Language) is present. In an actual operation, a multimedia data size, user authentication data required for processing of an application, and the like may be contained as additional information in addition to the aforementioned information. Such additional information does not influence the essence of the present invention.","A description of the decision parts (steps S and S) of the edit processes that have been explained in the flow of the process shown in the flow chart of  will be added. In the present invention, an edit process within the range of the processing performance of the multimedia edit & playback terminal  is executed by the multimedia edit & playback terminal  itself. As for an edit process beyond the range of the processing performance of the multimedia edit & playback terminal , an edit instruction is issued to the multimedia edit server  to fill up deficiency in processing performance. In this case, a decision for the processing performance must be made.","When an edit process is executed, whether or not that edit function is implemented is a self-evident condition upon determining the location of that process. If the multimedia edit & playback terminal  does not comprise a given edit function, it is obvious that the edit function is not available. However, the advance of technologies in recent years allows a so-called versatile processor to execute even a special image process, and it is possible to load a processing module that includes a new edit function from an external storage device or the like. In consideration of such circumstance, a processing condition table can be used to determine the location where the process is to be executed.",{"@attributes":{"id":"p-0160","num":"0159"},"figref":["FIG. 15","FIG. 15"],"b":["1501","1502","1503"]},"In the command , a value indicating an edit process such as \u201cTrim\u201d, \u201cOilpaint\u201d, or the like is set, and is used as a key when the program determines a user's operation instruction. In this embodiment, a character string is exemplified, but a message ID or the like expressed by a numerical value or the like may be used instead.","The processing location  holds a value indicating a processing location when a process that matches the command  is requested. The value may describe, e.g., an entry of a function, or a value to be passed to a conditional statement of a select routine that calls an entry of a function. When an edit process is executed on the multimedia edit server , that value may describe a call URL (Uniform Resource Locators, RFC1738) or a value to be passed to a conditional statement of a select routine that calls a function used to establish connection to the multimedia edit server .","The processing condition  is selectively used, and holds a condition upon calling. If the process is delegated to the multimedia edit server  only when the degree of oil-painting-touch conversion process is large, the processing condition  describes a value of a processing parameter that gives the degree of process, a condition, and the like. A field that gives the processing condition is not always required.","The processing condition may be determined based on an expected processing time required for an actual process. In such case, a time required for the process may be calculated using weight data calculated in advance on the basis of the size of data to be edited and the processing contents, and only when it is determined that a long processing time is required, the process may be delegated to the multimedia edit server . Alternatively, the processing condition may be determined based on whether or not the network  that makes a communication with the multimedia edit server  is ready, or the communication speed of the connected network .","With reference to such processing condition table, the decision parts (steps S and S) of the edit processes in the flow chart shown in  can make more flexible processes. If this processing condition table is updated when a processing module which includes a new edit function is loaded from an external storage device or the like, as described above, the processing condition can be changed, so that the new processing function is executed on the multimedia edit & playback terminal .","As described above, an edit process within the range of the processing performance of the multimedia edit & playback terminal  is executed by the multimedia edit & playback terminal  itself with which the user actually edits data, and an edit process beyond the range of the performance, i.e., an edit process which is difficult to attain in terms of the processing performance of the user's terminal, can be done by issuing an edit instruction to the multimedia edit server , thus providing convenience to the user.","Furthermore, with the method that sends a command indicating the edit process contents, its parameter, and multimedia data to be edited together upon issuing an edit instruction to the multimedia edit server , a secondary effect, i.e., a simple processing sequence, can be expected. That is, since only required information is sent to the multimedia edit server  at a required timing, inconvenience in procedure for sending multimedia data to the multimedia edit server  in advance, difficulty in holding consistency between original multimedia data, and multimedia data, which is undergoing an edit process in the multimedia edit server , and the like can be eliminated compared to a case wherein the process is executed by only the multimedia edit server .","The processing condition table is effective to make a flexible decision and to improve feasibility upon determining whether the edit process is executed by the multimedia edit & playback terminal  or multimedia edit server , to update an application program, and so forth.","In addition to the edit process itself, if the user wants to apply both the trim and oil-painting-touch conversion functions described in this embodiment, the multimedia edit & playback terminal  may execute the trim process in advance. Therefore, the size of multimedia data to be sent via the network  can be smaller than that in a case wherein the multimedia edit server  uniquely executes both the trim and oil-painting-touch conversion processes, and the processing load on a portable terminal or the like, and the load on the bandwidth or the like of a communication environment can be reduced.","<Fifth Embodiment>","In the fourth embodiment, the edit process of relatively simple moving image data among multimedia data has been explained. The trim and oil-painting-touch conversion processes of moving image data may be replaced by audio trim and voice conversion processes (conversion of sound quality using a low-frequency filter or the like).","This embodiment will explain an application to object-based encoded multi-object data in place of such relatively simple example. For example, MPEG-4 can form one multimedia data by a plurality of objects. To these objects, data of various formats such as a moving image, static image, computer graphics (or vector graphics), text, audio, and the like can be applied, and these objects can be held together with layout information (to be referred to as \u201cscene\u201d hereinafter) of a tree structure.","When these objects are edited, the processing method and the processing load on an edit apparatus vary depending on objects. For example, when a moving image in objects which form multimedia data undergoes oil-painting touch conversion or a blur process of only an image surrounding portion, a heavy-load process for decoding a moving image, executing an image conversion process, and encoding the processed image again is required.","On the other hand, when a character string of text need only be changed from \u201clandscape of Kyoto\u201d to \u201clandscape of Tokyo\u201d, even when text data has been converted into binary data, the processing load is very smaller than that on the aforementioned moving image conversion process. Again, when the position of an object described as a scene is corrected to move a moving image which is displayed on the upper right position on a frame to the lower left position, the processing load is similarly small.","In this embodiment, a case will be described in detail below wherein an edit process is executed in correspondence with such processing load for each object unique to object-based coding.  is a block diagram of a program that edits object-based encoded multimedia data.","As shown in , a program in this embodiment comprises an object split module  for splitting multimedia data  into objects, conversion modules  for editing\/converting each individual object data  split by the object splitting module, an object composition module  for compositing object data  which have undergone the process of the conversion module again, an edit control module  for managing multimedia data  as an output edit result, and these modules and data, and the like.","A given conversion module  executes an actual conversion process to an oil-painting-touch image, and the edit control module  has a function of making the overall control. Note that modules which pertain to user's operations, a display function to the user, and the like are not shown in .","When the user wants to change a character string of text using the program shown in , the modules shown in  operate as follows. Initially, the object split module  splits a text object from multimedia data  in accordance with user's operation. If original multimedia data contains moving image and audio objects, moving image and audio objects are split to a minimum extent within a range consistent to object-based coding.","The conversion module  converts a text character string in accordance with a user's instruction. Note that if this edit process falls within the performance range of the multimedia edit & playback terminal , as described in the fourth embodiment, it can be internally processed by the multimedia edit & playback terminal . More specifically, in this case, conversion is executed inside the conversion module . Note that the processing location is determined, as has been explained in the fourth embodiment.","Upon completion of conversion, the split objects are composited again by the object composition module , thus ending the edit process. The above description has been given under the condition that the processing load upon changing a text character string is small, and such process can be sufficiently executed inside the multimedia edit & playback terminal .","A case will be explained below wherein an oil-painting-touch conversion process is executed for only a specific moving image object. Until the objects are split, and the given conversion module  executes an oil-painting-touch conversion process, the same procedure as in conversion of the text character string is taken. In this case, the processing location is selected, as has been described in the fourth embodiment. This selection may be made using the processing condition table shown in . If it is selected to execute an oil-painting-touch conversion process in the multimedia edit server , the conversion module  does not execute any process by itself, entrusts to the edit control module  sending of a command file to the multimedia edit server , and waits for the result.","Upon reception of data that has been converted by the multimedia edit server , the objects are composited by the object composition module , thus ending the edit process. Note that multimedia data to be sent to the multimedia edit server  is only the split moving image object to be edited. In object-based coding, a plurality of moving image objects can be stored in one multimedia data. Since only one of these objects is sent to the multimedia edit server , the data size to be sent can be greatly reduced.","For example, when given multimedia data consists of two 500-kbyte moving image data, one 500 k-byte static image data, one 300-kbyte audio data, and 1-kbyte scene data, and one of the moving image objects is to be edited, only 500 kbytes of multimedia data of a total of 1801 kbytes need only be sent, and the data size to be sent is about 30% of the entire multimedia data.","In this manner, when the present invention is applied to object-based encoded multimedia data, a very large reduction of the processing load on communication can be expected depending on the edit contents and data to be edited. Furthermore, an edit process that must be done at the cost of image quality by reducing the data size of multimedia data to be edited in terms of a communication line and processing performance is more likely to be executed without dropping the image quality. Hence, a secondary effects can be expected in terms of the quality of multimedia data.","In the description of the above embodiment, whether the edit process is executed by the multimedia edit & playback terminal  or multimedia edit server  is decided by one conversion module . In addition, this decision may be made by the edit control module . Or this decision may be made by a module which controls a user interface.","In fact, the question about where this decision is made is a matter of implementation, and is not essential to the present invention, since various module configurations are available. Also, upon splitting objects, only an object to be edited need only be extracted if it is possible, and not all objects need be split.","In general, individual objects are managed in units called channels or elementary streams, and the split range varies depending on whether these objects are multiplexed and recorded or are separately recorded. If individual objects are recorded without being multiplexed, and the edit contents fall within the range that does not change the playback time of the multimedia data or the time stamp which specifies the processing timing, an object to be edited need only be split. These processes depend on the generation format of multimedia data to be edited and the like, and may be determined in correspondence to a system to which the present invention is applied.","As described above, whether an edit process for each object of object-based encoded multimedia data is executed by the multimedia edit & playback terminal  or multimedia edit server  is determined. In this manner, an edit process which can further reduce the processing load, and can avoid a problem of deterioration of image quality or the like as much as possible can be made.","<Other Embodiments>","The network and device arrangement that connect communication devices in the present invention are not limited to the Internet and mobile communication field. The present invention may be applied to various other networks such as so-called a home LAN, a wireless communication network with a limited communication distance called Bluetooth, and the like. Also, different multimedia edit servers  may be used depending on the edit processing contents or conditions in the processing condition table described using . More specifically, server A is used as the multimedia edit server  for an oil-painting-touch conversion process, and server B is used as the multimedia edit server  for a blur process.","For example, the present invention can be applied to a case wherein the multimedia edit server  also serves as a multimedia edit & playback terminal  (e.g., terminal B) which is different from the multimedia edit & playback terminal  (e.g., terminal A) which is used by the user. Also, when terminal B also serves the function of the multimedia edit server , and can execute an edit process that the terminal A cannot process, terminal B can act as the multimedia edit server .","More specifically, when terminal A is a compact portable terminal with very low performance, terminal B is a personal computer, and the multimedia edit server  is an apparatus which executes a special edit process by hardware and is connected to the Internet, a relatively simple edit process is executed by terminal A, an edit process with a relatively heavy load is executed by terminal B, and a special edit process that only the multimedia edit server  can do is executed by the multimedia edit server .","Furthermore, the present invention may be applied to either a system constituted by a plurality of devices (e.g., a host computer, interface device, reader, and the like), or an apparatus consisting of a single equipment (e.g., a portable phone).","The scope of the present invention includes a case wherein the functions of the embodiments are implemented by supplying a program code of software that implements the functions of the embodiments to a computer (or a CPU or MPU) in a system or apparatus, which is connected to various devices to make these devices implement the functions of the aforementioned embodiments, and making the computer of the system or apparatus control the devices in accordance with the stored program.","In this case, the program code itself of software implements the functions of the embodiments, and the program code itself, and means for supplying the program code to the computer (i.e., a storage medium which stores the program code) constitutes the present invention.","As the storage medium for storing such program code, for example, a floppy disk, hard disk, optical disk, magnetooptical disk, CD-ROM, magnetic tape, nonvolatile memory card, ROM, and the like may be used.","The program code is included in the embodiments of the present invention not only when the functions of the above embodiments are implemented by executing the supplied program code by the computer, but also when the functions of the embodiments are implemented by collaboration of the program and an OS (operating system) or another application software running on the computer. Furthermore, the present invention includes a case wherein the functions of the above embodiments are implemented by some or all of actual processing operations executed by a CPU or the like arranged in a function extension board or a function extension unit, which is inserted in or connected to the computer, after the supplied program code is written in a memory of the extension board or unit.","As described above, according to the present invention, even a multimedia edit & playback terminal with limited processing performance can easily execute an edit process that utilizes features of object-based coding, and can easily generate object-based encoded multimedia data in collaboration with a multimedia edit server. Also, it is easy to confirm the result of an edit process even for multimedia data with a relatively large size.","Also, according to the present invention, multimedia data to be edited can be sent to the multimedia edit server that can execute an edit process of the multimedia data to request it to edit the multimedia data via a communication and interactive process with the multimedia edit server. Since the terminal receives the multimedia data edited by the multimedia edit server, and plays back and saves that data, it can execute an edit process that can utilize features of object-based coding even when it has limited processing performance.","Furthermore, according to the present invention, edit layout information of multimedia data based on MPEG-4 (Moving Picture Expert Group Phase 4) that defines the contents of an edit process and a similar multimedia coding scheme having an object description function similar to MPEG-4, or a scheme simply called object-based coding can be stored. A plurality of pieces of edit layout information of multimedia data are sent as a list to the multimedia edit & playback terminal, multimedia data and an edit request sent from the multimedia edit & playback terminal are received, the edit\/generation process of multimedia data is executed, and the result can be sent to the multimedia edit & playback terminal.","Moreover, according to the present invention, the edit result from the multimedia edit server can be easily confirmed on the multimedia edit & playback terminal with limited communication performance and processing performance by streaming that result.","In addition, according to the present invention, multimedia data can be edited in such a manner that the multimedia edit & playback terminal selects edit layout information of multimedia data provided by the multimedia edit server, and sends the selected edit layout information of multimedia data and multimedia data to be edited, or each individual multimedia data which can be converted into an individual object in object-based coding, and the multimedia edit server splits the received multimedia data into objects, determines the type of each object, applies the object to the layout information in accordance with the corresponding type, and composites the objects.","Also, according to the present invention, a multimedia edit system which is formed by connecting the multimedia edit & playback terminal and multimedia edit server via a network provides a mechanism that effectively implements the present invention, and the user can make a more flexible multimedia edit process with high expandability.","Furthermore, according to the above embodiments, even the multimedia edit & playback terminal with limited processing performance can easily execute a multimedia edit process beyond the limitations in collaboration with the multimedia edit server, and the user can make a more flexible multimedia edit process with high expandability.","The multimedia edit & playback terminal of the above embodiment can check an edit processing condition, i.e., whether or not a specific edit process designated by the user is difficult to achieve under given conditions such as limitations on processing performance and processing functions. At the same time, the terminal can determine the multimedia edit server which can execute such edit process. Hence, the terminal can execute the edit process of the multimedia data, which is difficult to achieve, by sending multimedia data, an edit instruction, and an edit parameter to the multimedia edit server which can execute the edit process, and receiving edited multimedia data as a result.","When multimedia data to be edited is encoded by object-based coding, the multimedia edit & playback terminal of the above embodiment can edit multimedia data with a smaller load by splitting an object to be edited from that multimedia data, making a decision for the edit process condition and sending multimedia data for each split object, receiving the object as an edit result of the edit server, and compositing the edited object with those which are not edited again.","The multimedia edit server of the above embodiment can provide a function required to smoothly execute an edit process, which is limited in the multimedia edit & playback terminal, by receiving multimedia data sent from the multimedia edit & playback terminal, executing the edit process, and sending multimedia data as an edit result to the multimedia edit & playback terminal which requested the process.","The multimedia edit method of the above embodiment is characterized by referring to a processing condition table to decide an edit processing condition, and determining a location, where the process is done, on the basis of an instruction indicating the edit contents and edit condition or a value indicating one of them. Furthermore, the processing condition table is characterized by updating the processing conditions when it is updated, and comprises a condition decision method which is implemented by describing an entry of a function indicating the processing location, a URL indicating the processing location of a server, or a value to be given to a select routine used to call a function which provides such processing function. Hence, the multimedia edit & playback terminal and multimedia edit server can be updated flexibly.","The multimedia edit system as a combination of the multimedia edit & playback terminal, multimedia edit server, and multimedia edit method of the above embodiment can execute a multi-functional edit process while minimizing the processing load and the like on the multimedia edit & playback terminal.","As described above, according to the present invention, even a portable terminal with limited processing performance can easily make a data edit process that fully utilizes features of object-based coding, and generate object-based encoded multimedia data by connecting to a server that can edit multimedia data, and sending an edit instruction to that server.","As described above, according to the present invention, even a multimedia edit & playback terminal having many limitations can edit multimedia data beyond such limitations in collaboration with a multimedia edit server, and can implement a more flexible multimedia edit process with high expandability with a minimum load.","The present invention is not limited to the above embodiments and various changes and modifications can be made within the spirit and scope of the present inventions. Therefore, to apprise the public of the scope of the present invention, the following claims are made."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The accompanying drawings, which are incorporated in and constitute a part of the specification, illustrate embodiments of the invention and, together with the description, serve to explain the principles of the invention.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0039","num":"0038"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 3","b":"201"},{"@attributes":{"id":"p-0041","num":"0040"},"figref":"FIG. 4","b":"202"},{"@attributes":{"id":"p-0042","num":"0041"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIG. 6","FIG. 5"]},{"@attributes":{"id":"p-0044","num":"0043"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0045","num":"0044"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0047","num":"0046"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0048","num":"0047"},"figref":"FIG. 11","b":"201"},{"@attributes":{"id":"p-0049","num":"0048"},"figref":"FIG. 12","b":"201"},{"@attributes":{"id":"p-0050","num":"0049"},"figref":"FIG. 13","b":["305","201"]},{"@attributes":{"id":"p-0051","num":"0050"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0052","num":"0051"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0053","num":"0052"},"figref":"FIG. 16"}]},"DETDESC":[{},{}]}
