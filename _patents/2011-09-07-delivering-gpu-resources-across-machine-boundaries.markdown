---
title: Delivering GPU resources across machine boundaries
abstract: Described herein is providing GPU resources across machine boundaries. Data centers tend to have racks of servers that have limited access to GPUs. Accordingly, disclosed herein is providing GPU resources to computing devices that have limited access to GPUs across machine boundaries.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09135189&OS=09135189&RS=09135189
owner: Microsoft Technology Licensing, LLC
number: 09135189
owner_city: Redmond
owner_country: US
publication_date: 20110907
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["BACKGROUND","SUMMARY","DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS"],"p":["Graphics processing units (GPUs) have been standard offerings on most PCs for several years. The graphics processing units are usually specialized circuits designed to rapidly process information to accelerate the building of images in a frame buffer for display. GPUs are also becoming increasingly common in mobile phones and game systems. They are generally adapted to process computer graphics more effectively than general purpose central processing units (CPUs).","Data centers tend to have highly specialized hardware. Highly specialized hardware can be valuable for various reasons. First, the processing in data centers is historically centered on server workloads, such as filing and saving data. Thus, designers and manufacturers of data center servers focused hardware on those specific workloads. As hardware was focused on workloads, components that were unnecessary for those workloads were not included in the servers. It is also known that, if you have a rack of servers, it may be useful for physical space, heating, and power requirements to have specific type of hardware on a specific rack. If every component on a rack is a general CPU with basic supporting components, the power requirements, dimensions of the components and the like will all be simple and standard. As such, current data centers have been designed such that GPUs cannot be on the same rack as the servers.","Remote desktop applications such as Remote FX have a virtualized graphic device that lives in a child virtual machine that communicates with a host partition. The host partition has the physical GPU, and all of this is contained in one box. As such, although it is possible to provide a remote desktop with offerings like remote FX, data centers, server racks and current server design are not suited for GPU applications and\/or remote desktop applications.","There is a need for GPU resources in data centers. Further, there is a need for an architecture that integrates GPU resources with existing server systems that lack GPU resources. Included herein are GPU resources allocated across machine boundaries.","In an embodiment, a host computer in a data center may be running an application. The host computer may lack sufficient resources to perform one or more GPU tasks. The application may issue an instruction. The host computer may determine that the instruction is to be processed by one or more external GPUs. The host computer may send information indicative of a request for a GPU processing task to a graphics server manager. The graphics server manager may be associated with one or more GPU host machines. One or more of the GPU host machines may mount a state; process one or more GPU processing tasks and return the processed GPU task to the host computer.","In another embodiment, a data center comprises one or more servers. The one or more servers may be configured as a host machine for one or more virtual machines. Each virtual machine can communicate with a client computing device and each VM may be configured to run one or more applications on behalf of the client computing device. Applications run on behalf of a client computing system can include, as one example, a remote desktop session.","The one or more servers may not have GPUs integrated internally with the server. Accordingly, when a first virtual machine provides a first instruction that is to be processed by a GPU, the host machine may be configured to request GPU resources from a graphics server manager. The graphics server manager may be integrated with a Host GPU machine or it a computing device separate from the server and the graphics server manager can be associated with one or more GPU components. The host machine can send the first instruction to the graphics server manager. The graphics server manager receives the first instruction, and allocates one or more proxy graphics applications associated with one or more GPU components to perform the instructions. The proxy graphics applications may each have a graphics device driver that can be configured to work in the format specified by, for example, the virtual machine. The graphics device driver may be in communication with a graphics device driver in the kernel of the GPU resources component, which may cause GPU hardware to perform the instruction. The kernel level graphics device driver can send the processed instruction to the proxy graphics application, which, in turn sends the processed instruction to the graphics server manager, which send the instruction back to the host machine.","In an embodiment, a first set of one or more GPUs may be associated with a state and may be performing one or more GPU processing tasks for a server application on a host machine. As an example, the server application may be a virtual machine rendering a desktop for an end user. The one or more GPUs may be managed and monitored by a graphics server manager. The graphics server manager may determine that the resources allocated for the GPU processing task are insufficient to perform the task. In such an embodiment, the graphics server manager may allocate additional resources for the GPU processing task, mount a state of the first set of one or more GPUs on a second set of one or more GPUs, divide the GPU processing task and route one or more instructions to perform the GPU processing task to both the first and the second set of one or more GPUs. In another embodiment, the graphics server manager may send data to the host machine, the data configured to route graphics processing instructions to the first and second set of one or more proxy graphics applications after both the first and seconds set of proxy graphics applications are associated with the state.","In another embodiment, a first set of one or more GPUs may be associated with a state and may be performing one or more GPU processing tasks for a virtual machine running on a first set of one or more servers. The virtual machine running on the first set of one or more servers may migrate from the first set of one or more servers to a second set of one or more servers. In such an embodiment, the GPU processing state may be maintained on the first set of one or more GPUs. As such, migrating a virtual machine may not be associated with a glitch for setting up a state in a set of GPUs and switching sets of servers.","In an embodiment similar to the one above, one or more servers may be running a virtual machine. The one or more servers may not have GPUs integrated internally with the server. Accordingly, when a first virtual machine provides a first instruction that is to be processed by a GPU, the host machine may be configured to request GPU resources from a graphics server manager. The graphics server manager may be integrated with a host GPU machine or it may be separate from the server and the GPU host machine and may be associated with one or more GPU components. The host sends a request to the graphics server manager. The graphics server manager reads the request and allocates GPU resources for the host machine. The resources allocate include at least one proxy graphics application, each proxy graphics application comprising a graphics device driver. As one example, the graphics device driver may be associated with a specific driver for an application, such as Windows 7, Windows Vista and the like. The proxy graphics application may receive the instruction directly from a graphics device driver associated with the host and the virtual machine. The proxy graphics application may send the instruction to a kernel layer graphics device driver, which may cause the instruction to execute on GPU hardware. The processed instruction may be sent from the hardware through the kernel to the graphics device driver on the proxy graphics application, which in turn may send the processed instruction to the host computer, the graphics driver units on the host computer and\/or the virtual machine on the host computer.","A first virtual machine may be running on one or more host machines. The first virtual machine may be executing one or more processes that require a series of GPU processing tasks. For example, the first virtual machine may be rendering a desktop in real time for a thin client user. The GPU processing tasks may be executing on a remote GPU using a graphics server manager and a first set of one or more proxy graphics applications. In an embodiment, the graphics server manager, the host, or the proxy graphics application may determine that the GPU processing task is to be moved from the first set of one or more proxy graphics applications to a second set of one or more proxy graphics applications. In such an embodiment, a first set of one or more GPUs may be associated with one or more memories, the memories storing a state. Upon determining that the GPU processing task is to be moved from the first set of one or more proxy graphics applications to a second set of one or more proxy graphics applications, the state of the first set of one or more GPUs is copied by the graphics server manager and associated with a second set of one or more proxy graphics applications. After the state is prepared, the graphics processing task is dismounted from the first set of one or more proxy graphics applications and mounted on the second set of one or more proxy graphics applications. Accordingly, when shifting GPU resources, there is no glitch in the processing, preventing possible problems in rendering of a desktop, application, or even system crashes.","Certain specific details are set forth in the following description and figures to provide a thorough understanding of various embodiments of the disclosure. Certain well-known details often associated with computing and software technology are not set forth in the following disclosure to avoid unnecessarily obscuring the various embodiments of the disclosure. Further, those of ordinary skill in the relevant art will understand that they can practice other embodiments of the disclosure without one or more of the details described below. Finally, while various methods are described with reference to steps and sequences in the following disclosure, the description as such is for providing a clear implementation of embodiments of the disclosure, and the steps and sequences of steps should not be taken as required to practice this disclosure.","It should be understood that the various techniques described herein may be implemented in connection with hardware or software or, where appropriate, with a combination of both. Thus, the methods and apparatus of the disclosure, or certain aspects or portions thereof, may take the form of program code (i.e., instructions) embodied in tangible media, such as floppy diskettes, CD-ROMs, hard drives, or any other machine-readable storage medium wherein, when the program code is loaded into and executed by a machine, such as a computer, the machine becomes an apparatus for practicing the disclosure. In the case of program code execution on programmable computers, the computing device generally includes a processor, a storage medium readable by the processor (including volatile and non-volatile memory and\/or storage elements), at least one input device, and at least one output device. One or more programs that may implement or utilize the processes described in connection with the disclosure, e.g., through the use of an application programming interface (API), reusable controls, or the like. Such programs are preferably implemented in a high level procedural or object oriented programming language to communicate with a computer system. However, the program(s) can be implemented in assembly or machine language, if desired. In any case, the language may be a compiled or interpreted language, and combined with hardware implementations.","A remote desktop system is a computer system that maintains applications that can be remotely executed by client computer systems. Input is entered at a client computer system and transferred over a network (e.g., using protocols based on the International Telecommunications Union (ITU) T.120 family of protocols such as Remote Desktop Protocol (RDP)) to an application on a terminal server. The application processes the input as if the input were entered at the terminal server. The application generates output in response to the received input and the output is transferred over the network to the client.","Embodiments may execute on one or more computers.  and the following discussion are intended to provide a brief general description of a suitable computing environment in which the disclosure may be implemented. One skilled in the art can appreciate that computer system  can have some or all of the components described with respect to computer  of .",{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 1","b":["100","102","22","23","102","23","24","104","26","100","24","100","27","28","118","30","31","24","104","118","31","102","27","28","30","23","32","33","34","100","118","31"]},"A number of program modules may be stored on the hard disk, magnetic disk , optical disk , ROM  or RAM , including an operating system , one or more application programs , other program modules  and program data . A user may enter commands and information into the computer  through input devices such as a keyboard  and pointing device . Other input devices (not shown) may include a microphone, joystick, game pad, satellite disk, scanner or the like. These and other input devices are often connected to the logical processing unit  through a serial port interface  that is coupled to the system bus, but may be connected by other interfaces, such as a parallel port, game port or universal serial bus (USB). A display  or other type of display device can also be connected to the system bus  via an interface, such as a GPU\/video adapter . In addition to the display , computers typically include other peripheral output devices (not shown), such as speakers and printers. The system of  also includes a host adapter , Small Computer System Interface (SCSI) bus , and an external storage device  connected to the SCSI bus .","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be another computer, a server, a router, a network PC, a peer device or other common network node, a virtual machine, and typically can include many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in . The logical connections depicted in  can include a local area network (LAN)  and a network , which, as one example is a wide area network (WAN). Such networking environments are commonplace in offices, enterprise wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  can be connected to the LAN  through a network interface controller (NIC) or adapter . When used in a WAN networking environment, the computer  can typically include a modem  or other means for establishing communications over the network , such as the Internet. The modem , which may be internal or external, can be connected to the system bus  via the serial port interface . In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. It will be appreciated that the network connections shown are examples and other means of establishing a communications link between the computers may be used. Moreover, while it is envisioned that numerous embodiments of the disclosure are particularly well-suited for computer systems, nothing in this document is intended to limit the disclosure to such embodiments.","Turning to , illustrated are exemplary virtualization platforms that can be used to generate the virtual machines used for virtual desktop sessions. In this embodiment, hypervisor microkernel  can be configured to control and arbitrate access to the hardware of computer system . Hypervisor microkernel  can generate execution environments called partitions such as child partition  through child partition N (where N is an integer greater than 1). Here, a child partition is the basic unit of isolation supported by hypervisor microkernel . Hypervisor microkernel  can isolate processes in one partition from accessing another partition's resources. Each child partition can be mapped to a set of hardware resources, e.g., memory, devices, processor cycles, etc., that is under control of the hypervisor microkernel . In embodiments hypervisor microkernel  can be a stand-alone software product, a part of an operating system, embedded within firmware of the motherboard, specialized integrated circuits, or a combination thereof.","Hypervisor microkernel  can enforce partitioning by restricting a guest operating system's view of the memory in a physical computer system. When hypervisor microkernel  instantiates a virtual machine, it can allocate pages, e.g., fixed length blocks of memory with starting and ending addresses, of system physical memory (SPM) to the virtual machine as guest physical memory (GPM). Here, the guest's restricted view of system memory is controlled by hypervisor microkernel . The term guest physical memory is a shorthand way of describing a page of memory from the viewpoint of a virtual machine and the term system physical memory is shorthand way of describing a page of memory from the viewpoint of the physical system. Thus, a page of memory allocated to a virtual machine will have a guest physical address (the address used by the virtual machine) and a system physical address (the actual address of the page).","A guest operating system may virtualize guest physical memory. Virtual memory is a management technique that allows an operating system to over commit memory and to give an application sole access to a contiguous working memory. In a virtualized environment, a guest operating system can use one or more page tables to translate virtual addresses, known as virtual guest addresses into guest physical addresses. In this example, a memory address may have a guest virtual address, a guest physical address, and a system physical address.","In the depicted example, parent partition component, which can also be also thought of as similar to domain  of Xen's open source hypervisor can include a host . Host  can be an operating system (or a set of configuration utilities) and host  can be configured to provide resources to guest operating systems executing in the child partitions -N by using virtualization service providers  (VSPs). VSPs , which are typically referred to as back-end drivers in the open source community, can be used to multiplex the interfaces to the hardware resources by way of virtualization service clients (VSCs) (typically referred to as front-end drivers in the open source community or paravirtualized devices). As shown by the figures, virtualization service clients execute within the context of guest operating systems. However, these drivers are different than the rest of the drivers in the guest in that they may be supplied with a hypervisor, not with a guest. In an exemplary embodiment the path used to by virtualization service providers  to communicate with virtualization service clients  and  can be thought of as the virtualization path.","As shown by the figure, emulators , e.g., virtualized IDE devices, virtualized video adaptors, virtualized NICs, etc., can be configured to run within host  and are attached to resources available to guest operating systems  and . For example, when a guest OS touches a memory location mapped to where a register of a device would be or memory mapped device, hypervisor microkernel  can intercept the request and pass the values the guest attempted to write to an associated emulator. Here, the resources in this example can be thought of as where a virtual device is located. The use of emulators in this way can be considered the emulation path. The emulation path is inefficient compared to the virtualized path because it requires more CPU resources to emulate device than it does to pass messages between VSPs and VSCs. For example, the hundreds of actions on memory mapped to registers required in order to write a value to disk via the emulation path may be reduced to a single message passed from a VSC to a VSP in the virtualization path.","Each child partition can include one or more virtual processors ( and ) that guest operating systems ( and ) can manage and schedule threads to execute thereon. Generally, the virtual processors are executable instructions and associated state information that provides a representation of a physical processor with a specific architecture. For example, one virtual machine may have a virtual processor having characteristics of an Intel x86 processor, whereas another virtual processor may have the characteristics of a PowerPC processor. The virtual processors in this example can be mapped to processors of the computer system such that the instructions that effectuate the virtual processors will be backed by processors. Thus, in an embodiment including multiple processors, virtual processors can be simultaneously executed by processors while, for example, other processor execute hypervisor instructions. The combination of virtual processors and memory in a partition can be considered a virtual machine.","Guest operating systems ( and ) can be any operating system such as, for example, operating systems from Microsoft\u00ae, Apple\u00ae, the open source community, etc. The guest operating systems can include user\/kernel modes of operation and can have kernels that can include schedulers, memory managers, etc. Generally speaking, kernel mode can include an execution mode in a processor that grants access to at least privileged processor instructions. Each guest operating system can have associated file systems that can have applications stored thereon such as terminal servers, e-commerce servers, email servers, etc., and the guest operating systems themselves. The guest operating systems can schedule threads to execute on the virtual processors and instances of such applications can be effectuated.","Referring now to , it depicts similar components to those of ; however, in this example embodiment hypervisor  can include a microkernel component and components similar to those in host  of  such as the virtualization service providers  and device drivers , while management operating system  may contain, for example, configuration utilities used to configure hypervisor . In this architecture, hypervisor  can perform the same or similar functions as hypervisor microkernel  of  and host . Hypervisor  of  can be a standalone software product, a part of an operating system, embedded within firmware of a motherboard, and\/or a portion of hypervisor  can be effectuated by specialized integrated circuits.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":["FIG. 3","FIG. 3"],"b":["308","308","308"]},"Each type or configuration of computing resource may be available in different sizes. For example, a large resource configuration may consist of many processors, large amounts of memory, and\/or large storage capacity, and a small resource configuration may consist of fewer processors, smaller amounts of memory, and\/or smaller storage capacity. Users may choose to allocate a number of small processing resources as Web servers and\/or one large processing resource as a database server, for example.","The computing resources provided by the data centers  may be enabled by one or more individual data centers A-N (which may be referred herein singularly as \u201ca data center \u201d or in the plural as \u201cthe data centers \u201d). Computing resources in one or more data centers may be known as a cloud computing environment. The data centers  are facilities utilized to house and operate computer systems and associated components. The data centers  typically include redundant and backup power, communications, cooling, and security systems. The data centers  might also be located in geographically disparate locations. One illustrative configuration for a data center  that implements the concepts and technologies disclosed herein for scalably deploying a virtualized computing infrastructure will be described below with regard to .","The users and other consumers of the data centers  may access the computing resources provided by the cloud computing environment  over a network , which may be a wide-area network (\u201cWAN\u201d), a wireless network, a fiber optic network, a local area network, or any other network in the art, which may be similar to the network described above with respect to . Although a network, which is depicted as a WAN, is illustrated in , it should be appreciated that a local-area network (\u201cLAN\u201d), the Internet, or any other networking topology known in the art that connects the data centers  to remote consumers may be utilized. It should also be appreciated that combinations of such networks might also be utilized.","The user computing system  may be a computer utilized by a user or other consumer of the data centers . For instance, the user system  may be a server computer, a desktop or laptop personal computer, a tablet computer, a wireless telephone, a personal digital assistant (\u201cPDA\u201d), an e-reader, a game console, a set-top box, or any other computing device capable of accessing the data centers .","The user computing system  may be utilized to configure aspects of the computing resources provided by the data centers . In this regard, the data centers  might provide a Web interface through which aspects of its operation may be configured through the use of a Web browser application program executing on the user computing system . Alternatively, a stand-alone application program executing on the user computing system  might access an application programming interface (\u201cAPI\u201d) exposed by the data centers  for performing the configuration operations. Other mechanisms for configuring the operation of the data centers , including deploying updates to an application, might also be utilized.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":["FIG. 3","FIG. 3"],"b":["302","308","302","402","402","402","402","402","402","406","406"]},"In another embodiment, server computers A-N may be computing devices configured for specific functions. For example, a server may have a single type of processing unit and a small amount of cache memory only. As another example, memory storage server computers  may be memory severs comprising a large amount of data storage capability and very little processing capability. As a further example, one or more GPUs may be housed as GPU processing server device. Thus servers  may be provided with distinctive and\/or special purpose capabilities. The servers, memory storage server computers and GPU processing servers may be connected with each other via wired or wireless means across machine boundaries via a network.","As an example of the structure above, an application running in a data center may be run on a virtual machine that utilizes resources from one or more of the servers A, utilizing memory from one or more memory storage server  B, one or more GPU processing servers C, and so on. The virtual machine may migrate between physical devices, add devices and\/or subtract devices. Accordingly, the data center may include the functionality of computing systems  and  noted above with respect to FIGS. -(A-B) across machine boundaries. In an embodiment, sets of one or more computing devices may be managed by managing computing devices, such as a server manager, a memory manager, a GPU manager and the like. The managing devices may be used to determine when computing resources of a particular type need to be added or subtracted and may route information to devices that are performing processes.","In one embodiment, the processes A-N (which may be referred herein singularly as \u201ca process \u201d or in the plural as \u201cthe processes \u201d) may be virtual machine instances. A virtual machine instance may be an instance of a software implementation of a machine (i.e., a computer) that executes programs much like a physical machine executes programs. In the example of virtual machine instances, each of the servers A may be configured to execute an instance manager capable of executing the instances. The instance manager might be a hypervisor or another type of program configured to enable the execution of multiple processes  on a single server  A, utilizing resources from one or more memory storage servers B and one or more GPU servers C for example. As discussed above, each of the processes  may be configured to execute all or a portion of an application.","It should be appreciated that although some of the embodiments disclosed herein are discussed in the context of virtual machine instances, other types of instances can be utilized with the concepts and technologies disclosed herein. For example, the technologies disclosed herein might be utilized with instances of storage resources, processing resources, data communications resources, and with other types of resources. The embodiments disclosed herein might also be utilized with computing systems that do not utilize virtual machine instances i.e. that use a combination of physical machines and virtual machines.","The data center  A-N shown in  also may also include one or more managing computing devices  reserved for executing software components for managing the operation of the data center  A-N, the server computers A, memory storage server C, GPU servers C, and the resources associated with each . In particular, the managing computers  might execute a management component . As discussed above, a user of the data centers  might utilize the user computing system  to access the management component  to configure various aspects of the operation of data centers  and the instances  purchased by the user. For example, the user may purchase instances and make changes to the configuration of the instances. The user might also specify settings regarding how the purchased instances are to be scaled in response to demand.","In the example data center  shown in , an appropriate LAN  is utilized to interconnect the server computers A-N and the server computer . The LAN  is also connected to the network  illustrated in . It should be appreciated that the network topology illustrated in  has been greatly simplified and that many more networks and networking devices may be utilized to interconnect the various computing systems disclosed herein. Appropriate load balancing devices or software modules might also be utilized for balancing a load between each of the data centers A-N, between each of the server computers A-N in each data center , and between instances  purchased by each user of the data centers . These network topologies and devices should be apparent to those skilled in the art.","It should be appreciated that the data center  A-N described in  is merely illustrative and that other implementations might be utilized. Additionally, it should be appreciated that the functionality disclosed herein might be implemented in software, hardware, or a combination of software and hardware. Other implementations should be apparent to those skilled in the art.","Cloud computing generally refers to a computing environment for enabling on-demand network access to a shared pool of computing resources (e.g., applications, servers, and storage) such as those described above. Such a computing environment may be rapidly provisioned and released with minimal management effort or service provider interaction. Cloud computing services typically do not require end-user knowledge of the physical location and configuration of the system that delivers the services. The services may be consumption-based and delivered via the Internet. Many cloud computing services involve virtualized resources such as those described above and may take the form of web-based tools or applications that users can access and use through a web browser as if they were programs installed locally on their own computers.","Cloud computing services are typically built on some type of platform. For some applications, such as those running inside an organization's data center, this platform may include an operating system and a data storage service configured to store data. Applications running in the cloud may utilize a similar foundation.","In one embodiment and as further described in , a cloud service can implement an architecture comprising a stack of four layers as follows:\n\n",{"@attributes":{"id":"p-0057","num":"0060"},"figref":"FIG. 5","b":["304","100","200","1","2","52","302","501","501","501","302"]},"With regard to a remote desktop, a server may be associated with one or more applications requested by the client. The server access resources across one or more data centers and may render the entire desktop of the client with a virtual graphics driver. The desktop may then be flattened into a bitmap. The rendered bit can be compressed in one or more ways. As a first example, a bitmap may be compressed by comparing it to a previous rendering of a bitmap and determining the differences between the two bitmaps and only sending the differences. As another example, lossy or lossless compression formats may be used, such as run length encoding (RLE), BBC, WAH, COMPAX, PLWAH, CONCISE, LZW, LZMA, PPMII, BWT, AC, LZ, LZSS, Huff, f, ROLZ, CM, Ari, MTF, PPM, LZ77, JPEG, RDP, DMC, DM, SR, and bit reduction quantization. After compression, the server will send the compressed data in the form of payloads to the client. In response to receiving the payloads, the client may send a response to the server. The response may indicate that the client is ready to receive additional payloads or process more data.",{"@attributes":{"id":"p-0059","num":"0062"},"figref":["FIG. 6","FIG. 6","FIG. 6","FIGS. 1-2"],"b":["611","304","52","302","302","606","402","100","200","606","608","610"]},"The graphics device driver , the application , and\/or the host machine  may be associated with a graphics server manager  on a Host GPU machine  via a network (fiber channel, LAN, wireless, Ethernet, etc.) . The graphics device driver , the application , and\/or the host machine  may be able to send and receive instructions and data to and from the graphics server manager . As one example, the graphics device driver , the application , and\/or the host machine  may be able to send first data to the graphics server manager , the first data indicative of a request for GPU resources. The graphics server may send data to the graphics device driver , the application , and\/or the host machine , the second data indicating routing for GPU instructions from The graphics device driver , the application , and\/or the host machine .","The graphics server manager  may manage a first host GPU machine . The graphics host machine  may be a computer similar to computer systems  and  of FIGS. -(A-B) where the computer is specialized to function as a graphics server manager. graphics server manager  may be able to send instructions and data to components of the GPU machine  and may receive information and data as a response from components of the Host GPU machine . The GPU host machine  may be specialized for GPU hosting and processing. GPU host machine  may comprise the graphics server manager , a proxy graphics application , a kernel , and GPU hardware . The proxy graphics application  may be associated with a first graphics device driver , and the kernel  may be associated with a second graphics device driver . The graphics device driver  and  may translate, receive, and send data and information associated with graphics processing tasks. In one embodiment, the graphics device driver  and  are selected to translate between particular GPU hardware  and the applications, hardware, and operating systems operation on the graphics server machine , the host machine  and\/or the user computer .","In the embodiment , instructions associated with graphics processing tasks can flow through a series of layers, from the application  to the graphics server manager , to the proxy graphics application , to the Kernel , to the hardware . The processed information may follow the same path in reverse. While this may be effective, there may be a delay associated with sending the instructions and the processed information through back and forth through each element.","Accordingly, in , the network  is depicted having a separate graphics server manager and further connections between the host GPU machine  and the graphics device driver , a virtual machine , which may be the same a virtual machine noted above with respect to , mounted on the host machine . The virtual machine  may be associated with a user computer . In an embodiment, the graphic server manager receives a request for GPU resources from the host machine, the VM , and\/or the graphics device driver  mounted on the VM  of , and sends routing instructions, state instructions and the like to the host machine  and the host GPU machine . Thereafter, GPU tasks, processed information, and instructions may be sent directly between the host GPU machine  and the host machine . The graphics server manager may monitor the interactions and may perform other tasks related to the allocation of resources on a GPU such as GPU hardware .",{"@attributes":{"id":"p-0064","num":"0067"},"figref":"FIG. 8","b":["620","612","614","614","614","612","614","614"]},{"@attributes":{"id":"p-0065","num":"0068"},"figref":["FIG. 9","FIG. 2","FIG. 4"],"b":["902","902","402","100","200","1","2","902"]},"At step , providing GPU resources across machine boundaries may include issuing, by the virtual machine a first instruction. Instructions may be sent or received across local area networks and networks, such as network  and network  described above. These may be wired or wireless networks and may be connected to a Network OF such as Network I\/F  above, or any other input\/output device of a computer systems  and  of FIGS. -(A-B) or servers . Step  may also be performed as a means for issuing, by the virtual machine, a first instruction.","At step , providing GPU resources across machine boundaries may include determining, by the first host that the instruction is to be processed on a GPU. In one embodiment, a host may determine that a particular processing task is suited for a GPU. For example, an instruction from the VM may be evaluated by the host and based on, for example, the type of processing, the difficulty in processing, the type of request and the like, the host may determine that the instruction is suited for GPU processing. Step  may also be performed as a means for determining by the first host that the instruction is to be processed on a GPU.","At step , providing GPU resources across machine boundaries may include requesting by the host machine GPU resources from a graphics server manager. The server manager may be the graphics server manager  depicted above with respect to . In addition, the graphics server manager may be a server similar to sever B described above with respect to . Further, as noted above, the server may have one or more of the components noted above in computing systems  and  of FIGS. -(A-B). Accordingly, it will be understood that step  may also comprise a means for requesting, by the host machine, GPU resources from a graphics server manager.","At step , providing GPU resources across machine boundaries may include allocating, by the graphics server manager, one or more GPU hosts. GPU hosts may be the host GPU machine  described above with respect to . The GPU hosts may be a computer similar to computing systems  and  of FIGS. -(A-B). The GPU host machine may host proxy graphics applications, GPU components, graphics device drivers, a kernel and other components described above with respect to computing systems  and  of FIGS. -(A-B). Accordingly, it will be understood that step  may also comprise a means for allocating by the graphics server manager one or more GPU hosts.","At step , providing GPU resources across machine boundaries may include receiving, by a proxy graphics application on the GPU host the first instruction. The proxy graphics application may be similar to proxy graphics application  described above with respect to . The proxy graphics application may be configured to send and receive instructions and data. It may be configured to determine those device drivers that are appropriate for the system configurations and states of the GPU, VM, host machines, user machine and the like. It may preserve states and route information. The proxy graphics application may execute on one or more components of a computing system similar to computing systems  and  of FIGS. -(A-B). Accordingly, it will be understood that step  may also comprise means for receiving by a proxy graphics application on the GPU host the first instruction.","At step , providing GPU resources across machine boundaries may include processing the first instruction on GPU hardware. GPU hardware may can be, as one example, GPU hardware  described above with respect to . As a further example, GPU hardware may be similar to graphics processing unit  of  and components of  including video adapter , processing unit  and the like. Accordingly, it will be understood that step  may also be a means for processing the first instruction on GPU hardware.","At step , providing GPU resources across machine boundaries may include receiving by the first host, a processed first instruction. In one embodiment, the processed instruction may be received directly from the graphics server manager, while in another embodiment; the processed instruction may be received from the host GPU machine. For example, the instruction may be received from the proxy graphics application  of the host GPU machine. Accordingly, it will be understood that step  may also be a means for receiving by the first host, a processed first instruction. As noted above, components of the computing systems  and  of FIGS. -(A-B) may comprise components for sending and receiving instructions and data.",{"@attributes":{"id":"p-0073","num":"0076"},"figref":["FIG. 10","FIG. 2","FIG. 4"],"b":["1002","1002","402","100","200","1","2","1002"]},"At step , providing GPU resources across machine boundaries may include issuing, by the virtual machine a first instruction. Instructions may be sent or received across local area networks and networks, such as network  and network  described above. These may be wired or wireless networks and may be connected to a Network OF such as Network I\/F  above, or any other input\/output device of a computing systems  and  of FIGS. -(A-B) or servers . Step  may also be performed as a means for issuing, by the virtual machine, a first instruction.","At step , providing GPU resources across machine boundaries may include determining, by the first host that the instruction is to be processed on a GPU. In one embodiment, a host may determine that a particular processing task is suited for a GPU. For example, an instruction from the VM may be evaluated by the host and based on, for example, the type of processing, the difficulty in processing, the type of request and the like, the host may determine that the instruction is suited for GPU processing. Step  may also be performed as a means for determining by the first host that the instruction is to be processed on a GPU.","At step , providing GPU resources across machine boundaries may include requesting by the host machine GPU resources from a graphics server manager. The server manager may be the graphics server manager  depicted above with respect to . In addition, the graphics server manager may be a server similar to sever B described above with respect to . Further, as noted above, the server may have one or more of the components noted above in computing system  and  of FIGS. -(A-B). Accordingly, it will be understood that step  may also comprise a means for requesting, by the host machine, GPU resources from a graphics server manager.","At step , providing GPU resources across machine boundaries may include allocating, by the graphics server manager, one or more GPU hosts. GPU hosts may be the HOST GPU machine  described above with respect to . The GPU hosts may be a computer similar to computing systems  and  of FIGS. -(A-B). The GPU host machine may host proxy graphics applications, GPU components, graphics device drivers, a kernel and other components described above with respect to computer systems  and  of FIGS. -(A-B). Accordingly, it will be understood that step  may also comprise a means for allocating by the graphics server manager one or more GPU hosts.","At step , providing GPU resources across machine boundaries may include implementing a state for the proxy graphics application and graphics drivers . In an embodiment, a state may be a series of one or more configurations, settings, instructions, translations, data, and the like. The state may be implemented on the GPU host machine and may be associated with graphics drivers in a host machine, a GPU host, the GPU host kernel and the like. The state may configure components of the GPU host machine, which may be similar to those components described above with respect to computer systems  and  of FIGS. -(A-B). It will be understood that step  may also comprise a means for implementing a state for the proxy graphics application and graphics drivers.","At step , providing GPU resources across machine boundaries may include receiving, by a proxy graphics application on the GPU host the first instruction. The proxy graphics application may be similar to proxy graphics application  described above with respect to . The proxy graphics application may be configured to send and receive instructions and data. It may be configured to determine those device drivers that are appropriate for the system configurations and states of the GPU, VM, host machines, user machine and the like. It may preserve states and route information. The proxy graphics application may execute on one or more components of a computing system similar to computer systems  and  of FIGS. -(A-B). Accordingly, it will be understood that step  may also comprise means for receiving by a proxy graphics application on the GPU host the first instruction.","At step , providing GPU resources across machine boundaries may include processing the first instruction on GPU hardware. GPU hardware may can be, as one example, GPU hardware  described above with respect to . As a further example, GPU hardware may be similar to graphics processing unit  of  and components of  including video adapter , processing unit  and the like. Accordingly, it will be understood that step  may also be a means for processing the first instruction on GPU hardware.","At step , providing GPU resources across machine boundaries may include receiving by the first host, a processed first instruction. In one embodiment, the processed instruction may be received directly from the graphics server manager, while in another embodiment; the processed instruction may be received from the host GPU machine. For example, the instruction may be received from the proxy graphics application  of the host GPU machine. Accordingly, it will be understood that step  may also be a means for receiving by the first host, a processed first instruction. As noted above, components of the computer systems  and  of FIGS. -(A-B) may comprise components for sending and receiving instructions and data.","At step , providing GPU resources across machine boundaries may include maintaining the state at the GPU host and\/or at the graphics server manager. The GPU host and\/or the graphics server manager may include one or more memories which may store the state of a GPU for a particular VM or application running on a host. As such, if a VM or application is migrated from a first host to a second host, the state can be maintained in memory so that the GPU does not need to mount the state from the beginning, rather it is maintained. Step  may also comprise means for maintaining the state at the GPU host and\/or at the graphics server manager.","At step , providing GPU resources across machine boundaries may include migrating the one or more applications from a first virtual machine to a second virtual machine on a second host. In one embodiment, migrating from a first host to a second host may include migration module that copies, dismounts, and the mounts a virtual machine on a second set of computers. In general, the migration may be done in any manner known in the art. Step  may also comprise means for migrating the one or more applications from a first virtual machine to a second virtual machine on a second host ."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The systems, methods, and computer readable media for deploying a software application to multiple users in a virtualized computing environment in accordance with this specification are further described with reference to the accompanying drawings in which:",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 10"}]},"DETDESC":[{},{}]}
