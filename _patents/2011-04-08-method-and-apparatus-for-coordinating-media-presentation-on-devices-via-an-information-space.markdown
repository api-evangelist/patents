---
title: Method and apparatus for coordinating media presentation on devices via an information space
abstract: An approach is provided for coordinating media presentation on devices via an information space. In response to a request for presentation of media content, a media provision coordinating application retrieves from an information space raw media content corresponding to the request. The media provision coordinating application determines one or more first devices for pre-processing the raw media content and one or more second devices for presenting pre-processed media content based upon respective technical capabilities and availabilities of the first devices, the second devices, or a combination thereof, the first and second devices are connected to the information space.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09026609&OS=09026609&RS=09026609
owner: Nokia Corporation
number: 09026609
owner_city: Espoo
owner_country: FI
publication_date: 20110408
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["RELATED APPLICATIONS","BACKGROUND","SOME EXAMPLE EMBODIMENTS","DESCRIPTION OF SOME EMBODIMENTS"],"p":["This application claims the benefit of the earlier filing date under 35 U.S.C. \u00a7119(e) of U.S. Provisional Application Ser. No. 61\/322,669 filed Apr. 9, 2010, entitled \u201cMethod and Apparatus for Coordinating Media Presentation on Devices via an Information Space,\u201d the entirety of which is incorporated herein by reference.","Service providers (e.g., wireless, cellular, Internet, content, social network, etc.) and device manufacturers are continually challenged to deliver value and convenience to consumers by, for example, providing compelling network services and advancing the underlying technologies. One area of interest has been in ways to provide a broad range of media services available via user devices everywhere and anytime. As users continue to demand media services across a variety of user devices at different locations, such as at home, at office, in a car, in a train, etc., more media access and device coordination are required in the physical world and on the web. However, not all user devices (e.g., a stand-alone video projector) are connected to a coordinating device to be controlled and\/or coordinated for optimal user media services. In addition, not all user devices are connected to the web so as to be controlled and\/or coordinated by a coordinating device for optimal user media services when the user moves from one location to another location. Existing web services try to address to the issue; nevertheless, lack of control and\/or coordination mobility creates undesirable restrictions on user experience.","Therefore, there is a need for an approach for coordinating media presentation on devices via an information space.","According to one embodiment, a method comprises, in response to a request for presentation of media content, retrieving from an information space raw media content corresponding to the request. The method also comprises determining one or more first devices for pre-processing the raw media content and one or more second devices for presenting pre-processed media content based upon respective technical capabilities and availabilities of the first devices, the second devices, or a combination thereof, the first and second devices being connected to the information space.","According to another embodiment, an apparatus comprising at least one processor, and at least one memory including computer program code, the at least one memory and the computer program code configured to, with the at least one processor, cause, at least in part, the apparatus to, in response to a request for presentation of media content, retrieve from an information space raw media content corresponding to the request The apparatus is also caused to determine one or more first devices for pre-processing the raw media content and one or more second devices for presenting pre-processed media content based upon respective technical capabilities and availabilities of the first devices, the second devices, or a combination thereof, the first and second devices being connected to the information space.","According to another embodiment, a computer-readable storage medium carrying one or more sequences of one or more instructions which, when executed by one or more processors, cause, at least in part, an apparatus to, in response to a request for presentation of media content, retrieve from an information space raw media content corresponding to the request. The apparatus is also caused to determine one or more first devices for pre-processing the raw media content and one or more second devices for presenting pre-processed media content based upon respective technical capabilities and availabilities of the first devices, the second devices, or a combination thereof, the first and second devices being connected to the information space.","According to another embodiment, an apparatus comprises means for, in response to a request for presentation of media content, retrieving from an information space raw media content corresponding to the request. The apparatus also comprises means for determining one or more first devices for pre-processing the raw media content and one or more second devices for presenting pre-processed media content based upon respective technical capabilities and availabilities of the first devices, the second devices, or a combination thereof, the first and second devices being connected to the information space.","Still other aspects, features, and advantages of the invention are readily apparent from the following detailed description, simply by illustrating a number of particular embodiments and implementations, including the best mode contemplated for carrying out the invention. The invention is also capable of other and different embodiments, and its several details can be modified in various obvious respects, all without departing from the spirit and scope of the invention. Accordingly, the drawings and description are to be regarded as illustrative in nature, and not as restrictive.","A method and apparatus for coordinating media presentation on devices via an information space are disclosed. In the following description, for the purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the embodiments of the invention. It is apparent, however, to one skilled in the art that the embodiments of the invention may be practiced without these specific details or with an equivalent arrangement. In other instances, well-known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the embodiments of the invention.",{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 1","b":"100"},"The term \u201csemantic web\u201d refers to a universal medium for data, information, and knowledge exchange. This information exchange inserts documents with computer-comprehensible meaning (semantics) and makes them available on the semantic web. The semantic web is a \u201cweb of data\u201d instead of the \u201cweb of documents\u201d. Knowledge in the semantic web is structured and organized at a finer level of granularity than free-text document, and the vocabulary includes not only literal words but also universal identifiers.","As used herein, the term \u201cmedia\u201d refers to information and data or anything else capable of being defined in the semantic web and presented to an end-user\/audience in specific contexts in order provide value and\/or experience. Content may be delivered via any medium such as the internet, consumer electronics, CDs, and live events such as conferences and stage performances. Digital content may take the form of an electronic document, image, audio file, video file, multimedia file, service (e.g., \u201ctoday's financial news on the Stock Exchange\u201d), etc. Not all digital content is network retrievable.","The term \u201csmart space\u201d refers to a plurality of information spaces of different entities in a \u201csmart space architecture\u201d that allows the entities and different semantic web tools to access heterogeneous information embedded in different semantic domains available for different semantic web tools as described herein. The semantic web is designed to share information based upon common representation formats, ontologies and semantics, such that information would become globally ubiquitous and interoperable. However much of the information is not desired to ubiquitous, but remain hidden, private and is interpreted locally, such as personal information. To address to this issue, a smart space architecture (an entity focused structure) is developed such that a user can encapsulate all of personal information and interact with the information in the smart space according to the user's individual semantics and needs. The user can be a person, an organization, or other entity (e.g., legal entities, business entities, non-profit organizations, etc.). In the smart space, a user can use one or more nodes (e.g., mobile telephones, computers, consumer electronics, and similar terminals) to perform tasks without knowing anything about the nodes, and the nodes interoperate by communicating implicitly through smart spaces of different users without knowing each other. Such anonymity simplifies control, communication and coordination in the smart space, thereby reducing hardware and software operation time and costs. Cloud computing may be used with or in place of the smart space. By using just cloud computing, the user delegates control over the personal data to service providers, which could cause privacy issues.","A recent trend is providing connectivity among many types of consumer electronics. Many consumers electronics not traditionally associated with computer use (such as televisions or other audio or video equipment) are provided with options to connect to the web or to a computer in a home network providing access to digital content. By way of example, Internet connectivity is included in many devices using technologies such as Wi-Fi, Bluetooth, Ethernet, etc. When a conventional media content delivery system involves multiple devices, the system typically requires a management server (such as a personal computer, or a custom-made unit or appliance) to coordinate content delivery via the different devices. Even with such a management server, the user typically would have to manually select the device which can provide or deliver desired content. By way of example, in a typical content delivery environment of a home theater system, a user manually controls a central receiver to choose which device connected to the receiver (e.g., a set-top box, DVR or Blu-ray disc player) will be supplying content for display.","In another example, when obtaining online media content from a service provider, the operation often involves a conventional content delivery network or content distribution network (CDN) that includes computers or servers containing copies of data of text, audio, still images, animation, video, and interactivity content forms placed at various points so as to maximize bandwidth for access to the data from clients throughout the network. In one example, a client server accesses a copy of the data at a provider server near to the client server, as opposed to all clients accessing the same central server, so as to avoid bottleneck near that server. The conventional media presentation mechanisms assume separate use of data by each application. This approach is not always suitable for such areas as media services. There are a number of multimedia video services online. At best, they offer user devices with multimedia video services that either have standard format, quality, etc. regardless the presenting capabilities of the user devices, or have format, quality, etc. adjusted for the presenting capabilities of a requesting user device. There is no true solution that considers all user devices (e.g., personal electronics, etc.) available for the user at a special context (such as in a conference room, or at home), while delivering the best possible media presentation quality via the available devices. In other words, the conventional content delivery concept generally considers one user device (e.g., the content requesting device or a client server) and, therefore, other devices accessible to the user with potentially more capabilities or capabilities more suited to deliver the content can go unused.","To address these problems, the smart space  provides seamless connectivity among devices so as to detect their availability for the user as well as their capabilities to handle different a format, quality, etc. of requested media content. In one embodiment, the smart space  also coordinates the available and capable devices to pre-process and to present the requested media content. In particular, a media provision coordinating application (also known as a media manager) operating over a media management framework is designed to coordinate media service provision in the smart space , thereby building the media management framework on top of the smart space  to deploy different devices to present different media content (e.g., multimedia movies, advance virtual telescopes, augmented virtuality games, virtual reality training\/therapies, etc.). The media manger coordinates the tasks of pre-processing and the tasks of presenting among the available and capable devices based, at least in part, upon the format, quality, etc. of the media content as well as the user's physical accessibility to the devices and the capabilities of the accessible devices.","In one sample use case, the user is participating in a multimedia business conference to demonstrate a new three dimensional (3D) astronomical multiplayer game utilizing streaming 3D video, audio, and a whole new set of real time animation and user interactivity. In this example, the media manger retrieves astronomical media content from a public server (e.g., publicly available content maintained by the U.S. National Aeronautics and Space Administration (NASA)) to generate gaming data for the 3D astronomical multiplayer game. The media manger detects all devices that are, for instance, available to a user A such as a high definition television (HDTV) or projection system located in a conference room the user A is currently in, as well as a computer in the user's office. In one embodiment, the media manger coordinates the computer to pre-process the gaming data into visual and audio signals compatible with the HDTV (e.g., by converting the content from the public server into standard television broadcast format), and directs the HDTV to present the pre-processed signals. It is noted that other users at other locations may have different available and capable devices for the media manger to coordinate the presentation of the gaming data.","In one embodiment, the media management framework performs automatically and does not require human intervention to support the live game demonstration online for all attendees of the conference even if the attendees are participating in the demonstration at different remote locations. For example, for each attendee, the media manager detects available presentation devices at the respective remote location and devices that can process the signal the remote presentation devices.","In one embodiment, the media management framework extends the basic architecture of the smart space  with special modules to deliver media content (e.g., images, video, audio, etc.) via different devices serving the user. The user does not need to own these presentation or processing devices, but only to obtain usage rights of these devices via renting, leasing, borrowing, etc.","In addition, the media management framework manages user devices with significantly different capabilities and restrictions, to provide the user with a maximum or predetermined quality of media content (e.g., quality with respect to resolution, format, compression, etc.). This is especially important for multimedia services. For example, it is noted that delivery and processing of multimedia content generally require more technical know-how, power, bandwidth, etc. The media management framework maximizes efficiency of using the smart-space-compliant devices to improve user experience. The media management framework also provides mechanisms and means for efficient and effective distribution of the related work load thus minimizing network resources (e.g., by retrieving content from the most efficient provider). In one embodiment, the media management framework uses available pre-processing devices to conduct pre-processing in parallel, and then send the pre-processed data to the presenting devices. In another embodiment, the media management framework deploys cloud computing (e.g., via back-end servers) to handle the pre-processing.","The media management framework in the smart space  is content-centered. In the example of the multimedia business conference for demonstrating live a new 3D astronomical game, the conference is not driven by an agenda or predefined process. Instead, the conference emerges in a dynamic and opportunistic manner in reaction to the available and capable devices for presenting the media content. In one embodiment, if a digital projector suddenly breaks down, the media management framework switches the presentation to another display (e.g., an HDTV) at or near the same location and pre-process the media content to be compatible with the other display on the fly. An important aspect in the content-centered approach is the flexible and easy interleaving of conferencing with media presentations. The conferencing itself is flexible and can lead into vivid and dynamic interaction between attendees. Optionally, the media management frame framework personalizes the media content for the user, by monitoring the user preferences and deductively analyzing user context and preferences.","In yet another embodiment, the media management framework provides a great flexibility in design and easy-to-use tools for personalizing the user account and access media content as much as user desires. In other words, the media management framework provides a new paradigm of designing media services that proactively fulfills user needs, reuses data collected by other services, and integrates multi-modular applications into an interconnected service provision platform that can be used to control and\/or coordinate mobile devices, PCs, consumer electronics (digital projectors, HDTVs, telephones, MP3 players, audio equipment, calculators, GPS automotive navigation systems, digital cameras, playback and recording of video media such as DVDs, VHSs or camcorders, gaming devices, karaoke machines), etc.","As seen in , each smart space is distributed across at least one set of nodes (e.g., devices) belonging to at least one user. In this embodiment, the smart space  is distributed across multiple nodes -that each belong to multiple users. For example, nodes and belong to a first user, while nodes -belong to a second user. It is also contemplated that one or more of the nodes (e.g., node ) may belong to a centralized information provider. Nodes  are personal\/individual in that they perform tasks either directly decided by the user or autonomously for or on behalf of the user. For example, the nodes  can monitor predetermined situations or reason\/data-mine information available in the smart space .","A node  may connect to one or more smart spaces  at a time. Moreover, the specific smart spaces  and to which the node  is connected may vary over the lifetime of a node. Mobility of nodes  is provided by moving links to the smart space  rather than moving a physical running process of the smart space . The node  can save its state and become \u2018mobile\u2019 when another node  restores that state. Nodes  themselves are anonymous and independent of each other\u2014there is no explicit control flow between the nodes  other than that provided through preconditions to node actions. A coordination model based around expressing coordination structures as first-order entities and focusing on collecting reasoning and context. Control flow can be made outside of the smart space  through nodes  and the applications serving the nodes  explicitly sharing details of their external interfaces through the smart space . The responsibilities of nodes  range from user-interaction to reasoning and performing tasks such as truth maintenance, belief revision, information consistency management etc.","The nodes  access information in the smart space  through semantic information brokers (SIB) (e.g., SIBs -) by connecting to any of the SIBs  making up the smart space  by whatever connectivity mechanisms (e.g., connectivity over a data network, the Internet, etc.) the SIBs  offer. Usually, the connection is over some network (e.g., data network, wireless network, telephony network, service provider network, etc.), and the nodes  are running on various devices. For example, the node  may be supported on any type of mobile terminal, fixed terminal, or portable terminal including a mobile handset, station, unit, device, multimedia tablet, Internet node, communicator, desktop computer, laptop computer, Personal Digital Assistants (PDAs), or any combination thereof. It is also contemplated that the device supporting the node  can support any type of interface to the user (such as \u201cwearable\u201d circuitry, etc.).","Additionally, a communication network (not shown) capable of supporting the smart space  can include one or more networks such as a data network (not shown), a wireless network (not shown), a telephony network (not shown), or any combination thereof. It is contemplated that the data network may be any local area network (LAN), metropolitan area network (MAN), wide area network (WAN), a public data network (e.g., the Internet), or any other suitable packet-switched network, such as a commercially owned, proprietary packet-switched network, e.g., a proprietary cable or fiber-optic network. In addition, the wireless network may be, for example, a cellular network and may employ various technologies including enhanced data rates for global evolution (EDGE), general packet radio service (GPRS), global system for mobile communications (GSM), Internet protocol multimedia subsystem (IMS), universal mobile telecommunications system (UMTS), etc., as well as any other suitable wireless medium, e.g., microwave access (WiMAX), Long Term Evolution (LTE) networks, code division multiple access (CDMA), wideband code division multiple access (WCDMA), wireless fidelity (WiFi), satellite, mobile ad-hoc network (MANET), and the like.","Each SIB  is an entity performing information transaction operations, possibly co-operating with other SIBs , for the smart space . In one embodiment, an SIB  may be a concrete or virtual entity. Each SIB  supports nodes  interacting with other SIBs  through information transaction operations. In this embodiment, the smart space  includes SIBs -each connected to respective information stores -. Each information store  of the smart space  stores the information of the nodes , and any other information available over the smart space . This can include, for example, information of a current state or activity of the node , observations of the outside information world, maintenance information, and the like. Synchronization between these distributed, individual information stores  is asymmetric according to device and network capabilities as well as the user's needs in terms of security, privacy, etc. For example, private information about a user's family is stored at the user's home location where stricter information security policies can protect the information. The private information can then be augmented by non-private information at a website (e.g., a social networking website) without actually transferring the private information to the website. In this case, augmenting information is preferable to merging information due to, for instance, copyright and\/or privacy concerns.","A smart space  and the media management framework built on top of the smart space  transcends over many of the user's devices (e.g., mobile phones, media centers, personal computers, servers, routers, etc.) enabling the distribution of information and queries upon that information over any of the user's devices. For any node  accessing the information, the physical location of the node  and the location of the information are irrelevant, i.e., a node  sees the \u2018totality\u2019 of all information in that smart space . By way of example, the nodes  access the smart space  with basic operations including Insert (to insert information into a smart space), Remove (to remove information from a smart space), Update (to update information in a smart space, which is effectively an atomic remove and insert combination), Query (to query for information in a smart space), Subscribe (to set up a persistent query in a smart space such that a change in the query results is communicated to the subscribing node), etc. The nodes  communicate implicitly by inserting information to the smart space  and querying the information in the space .","Interaction among smart spaces  is nominally conducted by the nodes  which encapsulate fine grained functionality to be distributed across any number of devices that have access to one or more of the smart spaces . The smart spaces  themselves can interact through merging and projection thereby enabling larger smart spaces  to be constructed either on a permanent or temporary basis. Moreover, the smart space  may be a personal space, a share\/social space of at least two users, a group space, a public space of a community, a county, a state, or a county, etc., and the like. The aggregation of all smart spaces  constitutes the world of information (including the semantic web) which is also referred to as a smart space. A smart space  including the entire world of information also supports all services (including all platforms and vendors) available in the world, as well as all of the world's devices and equipment.","The rules of information usage (e.g., as provided in applications) for the smart space  are implemented in knowledge processors (KP) (e.g., KP and ) connected to the smart space  via SIBs . The responsibilities of KPs range from user-interaction to reasoning and performing tasks such as truth maintenance, belief revision, information consistency management, etc.  is a diagram  of the smart space logical architecture including knowledge processors, according to one embodiment. In one embodiment, the SIBs  are responsible for storing and sharing smart space information.","For example, as soon as an information unit becomes available for the SIB , the information unit also becomes available for every KP  served by the SIB . The KPs , for instance, are responsible for processing information obtained from the SIBs . A KP uses one or more partner KPs for sharing of content. This partnership arrangement implies that there is an agreed set of semantics among the KPs -for the used ontology. KPs and may run in different business domains (e.g., business domain and respectively) to allow the public or public entities to access the same information service regardless of which business domain  the public or public entities are located. In the smart space , a smart space access protocol (SSAP)  is used between the SIBs  and KPs , among SIBs , and among KPs  to, e.g., join, leave, insert, remove, update, query, subscribe, and\/or unsubscribe information.","The smart space  and the media management framework are interoperable over different information domains, different service platforms, and different devices and equipment. For example, the smart space  accommodates transmission control protocol\/Internet protocol (TCP\/IP), Unified Protocol (UniPro) created by the Mobile Industry Processor Interface (MIPI) Alliance, Bluetooth protocol Radio Frequency Communication (RFCOMM), IPv6 over Low power Wireless Personal Area Networks (6LoWPAN), etc. The smart space  also covers technologies used for discovering and using services, such as Bluetooth\/human interface device (HID) services, web services, services certified by the Digital Living Network Alliance (DLNA), the Network on Terminal Architecture (NoTA), etc. The smart space  constitutes an infrastructure that enables scalable producer-consumer transactions for information, and supports multiparts, multidevices and multivendors (M3), via a common representation of a set of concepts within a domain (such as a RDF domain) and the relationships between those concepts, i.e. ontologies. The smart space  as a logical architecture has no dependencies on any network architecture but it is implemented on top of practically any connectivity solution. Since there is no specific service level architecture in the smart space , the smart space  has no limitation in physical distance or transport. The smart space  architecture allows user devices purchased at different times and from different vendors to work together. For example, via the media management framework, the user can listen\/watch\/etc. to music\/movies\/etc. wherever the user is using one or more personal devices in the vicinity of high quality speakers or display. In addition, the smart space  architecture allows application developers to mash-up services in different domains, instead of trying to port an application to all platforms and configurations. The smart space architecture also allows device manufacturers to make interoperable products, so that consumers have no concern about compatibility of different products and accessories.","By way of example, RDF\/XML may be used in the smart space  to store media content in information stores -. RDF\/XML is a syntax that serializes an Resource Description Framework (RDF) graph as an Extensible Markup Language (XML) document. RDF allows joining data in vocabularies from different business domains and without having to negotiate structural differences between the vocabularies. Via the RDF\/XML, the smart space  merges the information of the embedded domains with the information on the semantic web, as well as makes the vast reasoning and ontology theories, practices and tools developed by the semantic web community available for application development in the smart space . The smart space  also makes the heterogeneous information in embedded domains available to the semantic web tools. It is contemplated that the approach described herein may be used with other semantic web tools, such as a variety of data interchange formats (e.g. N3, Turtle, N-Triples), and notations such as RDF Schema (RDFS) and the Web Ontology Language (OWL), which are intended to provide a formal description of concepts, terms, and relationships within a given knowledge domain. Instead of the smart space access protocol, the smart space  may use Simple Object Access Protocol (SOAP) for exchanging structured information and media content.","Various embodiments are described herein with respect to coordinating access to media content as well as presenting the media content in the semantic web and the smart space. Although multimedia is frequently used as an example, it is contemplated that the approach described herein may be used with other media content.",{"@attributes":{"id":"p-0050","num":"0049"},"figref":["FIG. 3","FIG. 3"],"b":["300","100","301","301","100","303","303","303"],"i":["a","b","n"]},"In one embodiment, the KP of the user  directly requests media content from one or more external media resources, e.g., , , . . . (without going through semantic information brokers SIB , SIB , . . . SIB ). As shown by a path , the request bypasses the SIB and reaches the media management framework. Logically, this media management framework can be presented by a single media management framework unit  as illustrated by . The media management framework unit  provides an interface for tasks distribution and resource management for all services (KPs) that process media content. The media management framework unit  then contacts an external media resources for the requested media content via a path . The requested media content is then passed to the media management framework unit  for processing, and then sent to one of more of the KPs for optimal presentation (not necessarily involving the KP ).","In another embodiment, the KP requests the media content through one of the semantic information broker, e.g., SIB . The SIB then passes the request to the media management framework unit  via a path . The media management framework unit  then contacts the external media resources for the requested media content via the path , and then receives, processes and transmits the media content as discussed above.",{"@attributes":{"id":"p-0053","num":"0052"},"figref":["FIG. 4","FIG. 12"],"b":["400","100","400","401","100","403","100"]},"Therefore, the media management framework handles the media content presentation request on the fly, without being tied to any predefined application hierarchy, user hierarchy, or resource hierarchy. The intrinsic characteristics of the media content requests involve characteristics of the application, users, and\/or resources which are essentially unlimited in numbers, difficult to pre-define, and complicated by nature. As results, the optimization based on factors of application\/user\/resource are cumbersome for administrators to implement, thus is better implemented by the media management framework.",{"@attributes":{"id":"p-0055","num":"0054"},"figref":"FIG. 5","b":["500","500","100","501","500","501","500","503","503","503","503","505"],"i":["a","b","n "]},"The media management framework  includes one designated media resource access KP  as an interface for each external media content resource. The media resource access KPs  are created by content providers and\/or application developers, and then reuse them when needed. The internal complexity of media resource access KPs vary depending on the format, organization, access restrictions and other factors concerning the relevant media resource. The media resource access KP  finds proper media content on the selected media resources and delivers the content to the smart space according to (or best possible approximation) a target quality level, coding, data format, etc.","The detector  detects which of user devices UE , UE , UE  are capable and available for presenting the media content. The detector  also detects which of media content processing devices (e.g., any processing power, storage, software or other computing services access to the user locally or via internet\/cloud) are available for preprocessing the media content collected from the resources. The media content processing devices can be any processing power, storage, software or other computing services access to the user locally or via internet\/cloud\/smart space. In particular, the detector  contacts media content processing KPs , , . . . corresponding to the media content processing devices to find out whether the respective device is available for pre-processing the media content. In addition, the detector  contacts a media profile KP of the UE , a media profile KP of the UE , . . . and a media profile KP of the UE  to find out whether the respective user device is available for presenting the media content.","The detector  is a special KP for registering and monitoring states of the user devices  with media presenting capabilities. When the media manager  receives a user request for serving new media content, in parallel to sending content requests to the media resource access KPs , the media manager  also sends a request to the detector  for available user devices . The request to the detector  defines what user devices can be used for delivering\/presenting media content to the user.","After receiving the device information from the detector , the media manager  selects the best set of devices for preprocessing, requests the selected pro-processing devices to process the collected media content, combines the resulted quality-optimized media content, and forwards the combined output to a media output manager . The media output manager  then outputs the pre-processed media content to presenting devices selected by the media manager  (e.g., digital projectors, HDTVs, audio equipment, playback and recording of video media, gaming devices, etc.) for presentation. The device selection is made based upon user context and\/or the device context (e.g., time. location, activities, etc.).","In one embodiment, the device selection is made based upon the location of the user, which usually limits the presenting devices that are accessible to the user. By way of example, when the media manager  determines or is informed that the user is at home, instead of using mobile devices for delivering a 3D multimedia game, the media manager  defines potential user devices as accessible at home, such as a game control console, a home digital TV, a home music center, etc. The media manager  may determine that the user is at home via data transmitted from a user device, a communication service platform, etc. In another embodiment, the media manager  is informed that the user is at home by a sensor built-in a user device, etc. With respect to the pre-processing devices, they can be located anywhere as long as they are connected to the smart space  and available for the user to use.","The device selection may be also limited by a time for presenting the media content, for example, if the availability of the user and\/or the devices is defined by time. The device selection may be further limited by activities of the user for presenting the media content, for example, if the user is cooking the kitchen while writing a paper on a desk computer, and wants to watch and\/or hear a cooking show in the kitchen as well as in the living room.","Based upon the media content presentation request defined by the media manager , the detector  checks availability of all multimedia-capable user devices in a given space\/location (e.g., home) and produces an optimized decision regarding which devices should be used to deliver the 3D multimedia game. In another embodiment, the detector  only checks availability of all multimedia-capable user devices, and then passes the list to the media manager  for deciding which devices to deliver the 3D multimedia game.","Optimization may be based on a number of factors, such as media content presentation quality, user-friendliness, energy-efficiency, resource-constrain, device constrain, management overhead, cost, etc. The detector  or the media manager  performs multi-factorial optimization based on the factor values of all the available multimedia-capable devices UE, UE, UE  and the available media content pre-processing devices , , . . . . The multi-factorial optimization comprising assigning a hierarchal rank to each device, providing a set of synthetic factor values (quality, speed, cost, etc.) to each device, and conducting an auction amongst devices using their synthetic factor values.","The media manager  may distribute service provision in time using a special type of delay flag set by a media resource access point. This flag indicates that a certain part of the media content is not essential (i.e., optional) to the media service, for example, as determined based upon a user experience model. In this embodiment, a decrease of user experience is modeled by a time dependent curve.  is a diagram of a user experienced quality curve , according to one embodiment. The curve  shows a quality of experience  (i.e., user experienced quality) changes along a time axis . By way of example, users have relatively low expectation for email reception timing, such that the users are not sensitive regarding the quality of their experience until the time has passed seven hours after they sent out emails. On the other hand, users have much higher expectation of responsiveness for chat rooms, media conferencing, etc. The manager  obtains additional freedom of operation by postponing non-essential features\/functions with a delay flag to optimize key parameters of the media service.","As shown in , the framework  includes one special media profile KP  for each multimedia-capable user device UE in the smart space . The media profile KP  is responsible for low level implementation of an availability check protocol by considering the application programming interface (API) and other specifics of a given device. The KP  also stores information of actual media service capabilities of the corresponding device, and available methods for content handling and processing thereon. The device applicability for the media service is defined by values of optimization factors, which may be specified independently for each type of user experience. By way of example, video processing techniques are specific for different devices, such as digital TV, VCRs, DVDs, video codecs, video players, etc. Nevertheless, user experience of video output depends on the allowed resolution, frame-rate, bit-rate, audio output, etc. The audio output optimization may involve all sorts of sound effects such as echo, flanger, phaser, chorus, equalization, filtering, overdrive, pitch shift, time stretching, resonators, synthesizer, modulation, compression, 3D audio effects, reverse echo, etc.","The framework  further includes one special media content processing KP  for each device that can be used for media content pre-processing. The media content collected from different resources need to be pre-processed to adapt to a particular media service as well as to the available presenting devices. The media content processing KP  is responsible for preparing a package of tasks and collecting results from the corresponding device. The media content processing KP  monitors a current state and availability of the corresponding pre-processing device. Based on the current state, availability, and the above-defined optimization factors, the KP  calculates the device priority level at a given moment of time. A formula for calculating the device priority level is specific for each particular device type and defined by the KP designer. The formula may include coefficients that reflect communication abilities of the device, associated costs, etc. By way of example, a formula for the performance of a video quality metric is evaluated by computing the correlation between the objective quality scores and the subjective user test results (e.g., mean opinion scores).","The media output manager  is responsible for packaging the resulted media content flow and directs the flow to selected output devices  (e.g., a game control console, a home digital TV, a home music center, etc). The output manager  also keeps a list and a scheduler for processing the delayed features\/functions of the media service. When proper conditions and time occur, the output manager  proactively launches the media service.",{"@attributes":{"id":"p-0068","num":"0067"},"figref":["FIG. 7","FIG. 3","FIG. 12","FIG. 3"],"b":["700","303","307","309","307","307","700","701","303","307","307","703","309","100","307","309","705","309","307","707","307","709"],"i":["n ","l ","l ","l ","n ","l ","l ","l ","l","l "]},"As shown in , when the SIB determines that the requested media content will not benefit from the media management framework unit , it skips setting a special \u201cmedia-supported\u201d flag for the request (Step ). It is up to a smart space designer to decide the conditions to involve the media management framework unit . Thereafter, the SIB directly requests media content from a media content resource (Step ), i.e., without involving the media management framework unit . By way of example, the SIB determines that the raw data is sufficient for the user's usage and\/or for the available presenting device. The user's usage may be for generating a bar chart in a PowerPoint slide. The available presenting device may be a mobile phone.","After receiving raw (i.e., not pre-processed) media content (Step ), the SIB transmits the raw media content to the KP (Step ) for presentation. The routes with and without involving the media management framework unit  can be taken in parallel to the pre-processing of media content requests.",{"@attributes":{"id":"p-0071","num":"0070"},"figref":["FIG. 8A","FIG. 12","FIG. 5"],"b":["800","500","800","801","501","500","501","803","815","817","501","505","805","807","501","809","811","501","507","813"]},"Some steps for selecting media presenting devices are omitted from  to simplify , and these steps are to be discussed in conjunction with . These steps includes that the media manager  requests the detector  to select one or more devices for presenting media content, and then receives a list of one or more media content presenting device. These steps occur sequentially or concurrently with Steps -.",{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 8B","b":["820","821","1","823","823","1","821","823","825","823","821","827","821","829","821","831"]},"The KP  further queries RDF graphs representing requests for capabilities of the UE  into the smart space with a Query command: Query (queryString_ON_mode, serialisation) in an operation . In particular, the query is in a String ON mode which requires that all query results to be sting along (i.e., serialized) as a carousel. The media manager  replies to the KP  with the query results in the require mode in an operation .","The KP  further subscribes to the query results (i.e., a persistent query such that a change in the query results is communicated to the KP) with a Subscribe command: Subscribe (queryString_requests, serialisation) in an operation . The subscription is also in a String ON mode which requires that all query results to be sting along (i.e., serialized) as a carousel. The media manager  replies to the KP  with a subscription ID in an operation . Thereafter, the media manager  updates the KP  query results in the require mode in an operation , whenever there is a change to the query results.","When the KP decides to unsubscribe, it sends out an Unsubscribe command: Unsubscribe (subscriptionID) in an operation . The media manager  replies to the KP  with an indication of success or fail in an operation .",{"@attributes":{"id":"p-0077","num":"0076"},"figref":["FIG. 9A","FIG. 12"],"b":["900","505","900","901","505","501"]},"The detector  forms a list of applicable media user devices based upon the definition (Step ). For example, the user needs a C-Band-sized satellite dish, and a Digital Video Broadcast (DVB)-compliant MPEG-2 Integrated Receiver Decoder, or IRD, to directly receive NASA's public channels. The detector  decides whether there is any idle device in the list that is available for deployment yet lack of technical specification information (Step ). If so, the detector  requests technical specification data from a corresponding user device profile KP (Step ), and then adds the technical specification data to the list (Step ). The Steps - are repeated until the technical specification data of all idle devices in the list has been collected. The detector  then selects a set of optimal user devices for presenting the media content based upon the factor values in the list (Step ). In addition, the detector  generates a list of one or more delay services which are not essential to the presentation of the requested media content (Step ). The detector  then transmits information of the set of optimal user devices and the delay services to the media manager . Sequentially or concurrently with the Steps -, the detector  prepares a list of the devices for pre-processing media content as discussed in conjunction with .","Referring back to the request of displaying NASA's media channels, according to the conventional media systems, if the user does not have a C-Band-sized satellite dish for receiving digital television signals, the user can only watch the channels online which quality is limited by the personal computer, PDA, etc. of the user. Even if the user has a C-Band-sized satellite dish, the user still needs a Digital Video Broadcast (DVB)-compliant MPEG-2 Integrated Receiver Decoder (IRD), to directly receive NASA's public channels. In addition, the user has to research on how to connect all these devices to work with the user's home theater so to view and interact with NASA's astronomical multimedia programs with the user's high resolution equipment. On the other hand, the media management framework  automatically handles media content with detecting, pro-processing, and presenting features as discussed, and does not require hardware adaptation and user intervention yet provides the best available solution to deliver media content to the user.","In addition, the user can access any devices connected to the smart space  as long as the user is authorized by a device owner. By way of example, the user's home theater can retrieve data of NASA's public channels from the user's neighbor's C-Band-sized satellite dish and IRD for display, as long as the user gets approval from the neighbor. Even if the user does not have a home theater, HDTV, or any high definition display, the user can have the media management framework  retrieve NASA's public channel data directly from a NASA server than display the media content (e.g., current events in astronomy like solar eclipse, and space exploration like unmanned mission to Mars, orbital test vehicles) with a big screen HDTV in the community room of the user's apartment building.",{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 9B","b":["920","921","923","921","921","923","925","923","921","927","921","929","921","931"]},"The detector  further queries RDF graphs representing capabilities of media devices into the smart space with a Query command: Query (queryString_Detector_Init, serialisation) in an operation . In particular, the query is in a String Detector mode which requires that all query results to be sting along (i.e., serialized) as a carousel to be sent to the director . The media manager  replies to the detector  with the query results in the require mode in an operation .","The detector  further queries RDF graphs representing requests for media content services into the smart space with a Query command: Query (queryString_M_service_req, serialisation) in an operation . The media manager  replies to the detector  with an indication of success or fail in an operation .","The detector  further subscribes to the query results (i.e., a persistent query such that a change in the query results is communicated to the detector) with a Subscribe command: Subscribe (queryString_device_req, serialisation) in an operation . The subscription is also in a String Detector mode which requires that all query results to be sting along (i.e., serialized) as a carousel. The media manager  replies to the detector  with a subscription ID in an operation . Thereafter, the media manager  updates the detector  query results in the require mode in an operation , whenever there is a change to the query results.","When the detector  decides to unsubscribe, it sends out an Unsubscribe command: Unsubscribe (subscriptionID) in an operation . The media manager  replies to the detector  with an indication of success or fail in an operation .",{"@attributes":{"id":"p-0086","num":"0085"},"figref":"FIG. 10","b":["1000","1001"]},"A list of optimization performance of different parameters (e.g., media content presentation quality, user-friendliness, user preference, energy-efficiency, resource constrain, device constrain, management overhead, cost, or a combination thereof) is always ready to be called up by the user. By way of example, when the user walks out of a home theater to the balcony to view live stars, the user may select (by touching, clicking, etc.) an icon  to display a list of optimization performance parameters  assembled by the media management framework that have changes due to the switch of viewing environments. In this case, the user does not have to take any action other than selecting the icon  to see the list of optimization performance parameters .","In one embodiment, a pop-up window with a short description of a performance parameter is opened by touch the text of the performance parameter, such as \u201cMEDIA CONTENT PRESENTATION QUALITY\u201d. By selecting a desired performance parameter, it is highlighted and\/or enlarged, such that the user may select a \u201cMORE\/GO\u201d icon\/button  to display more a detailed description of the performance parameter. The user can manually adjust a performance parameter by selecting \u201cADJUST\u201d . By way of example, the user can adjust the performance parameter \u201cMEDIA CONTENT PRESENTATION QUALITY\u201d by moving left and right of a lever  in a performance bar . The user can move back to the prior screen by selecting \u201cBACK\u201d .","In this way, the user explicitly indicates the user's preference with respect to the media content management performance. The user's selection or other feedback is monitored by the media management framework as implicit relevance feedback with respect to the media management service. Therefore, the media management framework refines\/trains itself to provide a better media management service meeting the user's need and preference.","In addition to detecting content scheduling and availability as well as optimizing media content delivery, the media management framework also supports digital rights management (DRM) content protection. The media management framework can enforce DRM via KPs  and SIBs , without encrypting interconnections between devices as implemented by the existing Digital Transmission Content Protection (DTCP).","By way of example, the user requests astronomical multimedia services that will be coordinated by the media manager . One of the astronomical multimedia services is a \u201cStarPedia\u201d service that presents to the user a scheme of stars in the sky observable at any given time and location. A current time and location of the user are selected by default based on time and geo-data of a location SIB . An important feature of the service is that the orientation of the star scheme is set in line with the current orientation of a user device  (e.g., a smart phone, PDA, etc.), so that it is easy for the user to map observable stars to the constellations and stars on the scheme, by using compass information in the location SIB . In another embodiment, by pointing a joystick cursor to an internal area of the constellation on the screen of the user device , the user gets information of the internal area, information of main stars in the internal area which form that constellation, and other related reference information (e.g., Ancient Greek myth about the stars). The information is stored in the SIBs  of the smart space , and can be easily updated from external SIBs , library servers, and other resources of multimedia content when needed. By pointing to a particular star on the scheme, the user gets all main facts about the star, including a name, brightness, distance, etc. A number of KPs  can be each used as an extension of the above-described functions, depending on user preferences. For example, short cartoons about Greek myth may be played for children, for them to remember a story behind names of the constellations and how they look on the sky. The short cartoons can be played at proper time and using the best set of devices, e.g., a laptop panel on site.","Another one of the astronomical multimedia services is a \u201cstars-identifier\u201d service. With this service, the user points a camera of the user device  to the stars, which results in corresponding change of the view of the star sky scheme on the screen. Data is retrieved from motion, compass and other sensors of the user device or form an SIB . The sensor data allow accurately defining the direction and the angle under which the camera is pointing to the sky. The direction and the angle can simplify and speed up recognition of images received from the camera in order to minimize processing time and to provide synchronous view movement in the star sky scheme. The user simply points the device  to a certain star in the sky and gets all relevant multimedia content, including pictures, documentary movies, etc. The media content (which can be live) can be presented in real time based upon available and applicable devices , or delayed for a later presentation. The delayed media content can be independently presented or presented as a part of information flow in other user applications. By way of example, when the user later starts a crossword puzzle application which is embedded with the words and facts corresponding to some pointed\/observed stars, the relevant media content is automatically selected and presented in conjunction with the crossword puzzle.","The astronomical multimedia services also include a service of a \u201cvirtual telescope\u201d. While the user is using the StarPedia or stars-identifier service, the user can select (by touching, clicking, etc.) a Zoom function to switch the user device into the virtual telescope service for an earlier selected area in the star sky. The virtual telescope service finds and\/or requests the corresponding latest multimedia content of the selected area, including images from content providers (e.g., NASA, Russian Federal Space Agency, observatories, etc.), telescope models, and so on. The user thus accesses to live astronomic content (images of galaxies, planets and moons in high resolution, etc.) at the given time. The virtual telescope service turns the user device or any selected presenting device into a virtual telescope that emulates a telescope without requiring accurate placing and handling as for an actual telescope. This service also provides the user the feeling of \u201ctaking\u201d photos of the far away stars and galaxies as using a mobile phone camera, with high quality from the best telescopes of the world and even from the orbit (such as images of craters on the Moon surface). The user can select an image on the screen of the user device a number of times to receive a number of actual pictures from different physical telescopes.","The astronomical multimedia services further include a service of archiving images of the stars sky. Due to small changes in the sky during individual lifetime, the archived images may be very similar, within resolution of the user device screen. However, a request for a live image of a given sector of the sky and the user coordinates is forwarded to a global astronomical smart space. The astronomical smart space finds the closest content provider of the requested content (e.g., a professional or personal telescope pointing to the same area of the sky at this time), with a predetermined error tolerance which considers user device sensor accuracy and presenting device output quality. The astronomical smart space calculates a shift of the area of interest depending on its own location and a current location of the user, and provides content to the user accordingly.","The above-described embodiments can be applied to view media presentations in person on stage, projected, transmitted, or played locally with user devices. A broadcast of media presentations may be a live, recorded, or a combination thereof using analog and\/or digital electronic media technology. Digital online multimedia may be downloaded or streamed (live or on-demand). The above-described embodiments can provide media games and simulations in a physical environment using offline devices, game systems, or simulators with special effects, to multiple users in an online network or locally. In addition to applications in entertainment, education, and business, the above-described embodiments can be used in various areas including, but not limited to, news, art, cinema, opera, engineering, medicine, mathematics, scientific research, advertisements, governmental services and nonprofit services, etc.","The involved service and content providers can charge fees for the media content services (e.g., astronomical multimedia services). In another embodiment, the astronomical multimedia services are implemented as a smart space extension of the existing positioning services, e.g., a map service, a navigation service, etc. to be deployed on existing user devices. As the capabilities of user devices increase, more star-dots and their brightness can be presented by the user devices.","The emergence of the cloud and other information spaces (e.g., smart spaces), provides means for controlling and\/or coordinating among different user devices to provide optimal media services. The above-described embodiments provide an efficient means for handling media content in smart spaces and maximize user experience based upon the optimal set of user devices. In addition, new types of media content services are provided to address user demand of live and dynamic media content provision, such as astronomical multimedia services, as useful educational and research tools.","The processes described herein for coordinating media presentation on devices via an information space may be advantageously implemented via software, hardware, firmware or a combination of software and\/or firmware and\/or hardware. For example, the processes described herein, including for providing user interface navigation information associated with the availability of services, may be advantageously implemented via processor(s), Digital Signal Processing (DSP) chip, an Application Specific Integrated Circuit (ASIC), Field Programmable Gate Arrays (FPGAs), etc. Such exemplary hardware for performing the described functions is detailed below.",{"@attributes":{"id":"p-0099","num":"0098"},"figref":["FIG. 11","FIG. 11"],"b":["1100","1100","1100","1100","1110","1100","1100"]},"A bus  includes one or more parallel conductors of information so that information is transferred quickly among devices coupled to the bus . One or more processors  for processing information are coupled with the bus .","A processor (or multiple processors)  performs a set of operations on information as specified by computer program code related to coordinate media presentation on devices via an information space. The computer program code is a set of instructions or statements providing instructions for the operation of the processor and\/or the computer system to perform specified functions. The code, for example, may be written in a computer programming language that is compiled into a native instruction set of the processor. The code may also be written directly using the native instruction set (e.g., machine language). The set of operations include bringing information in from the bus  and placing information on the bus . The set of operations also typically include comparing two or more units of information, shifting positions of units of information, and combining two or more units of information, such as by addition or multiplication or logical operations like OR, exclusive OR (XOR), and AND. Each operation of the set of operations that can be performed by the processor is represented to the processor by information called instructions, such as an operation code of one or more digits. A sequence of operations to be executed by the processor , such as a sequence of operation codes, constitute processor instructions, also called computer system instructions or, simply, computer instructions. Processors may be implemented as mechanical, electrical, magnetic, optical, chemical or quantum components, among others, alone or in combination.","Computer system  also includes a memory  coupled to bus . The memory , such as a random access memory (RAM) or other dynamic storage device, stores information including processor instructions for coordinating media presentation on devices via an information space. Dynamic memory allows information stored therein to be changed by the computer system . RAM allows a unit of information stored at a location called a memory address to be stored and retrieved independently of information at neighboring addresses. The memory  is also used by the processor  to store temporary values during execution of processor instructions. The computer system  also includes a read only memory (ROM)  or other static storage device coupled to the bus  for storing static information, including instructions, that is not changed by the computer system . Some memory is composed of volatile storage that loses the information stored thereon when power is lost. Also coupled to bus  is a non-volatile (persistent) storage device , such as a magnetic disk, optical disk or flash card, for storing information, including instructions, that persists even when the computer system  is turned off or otherwise loses power.","Information, including instructions for coordinating media presentation on devices via an information space, is provided to the bus  for use by the processor from an external input device , such as a keyboard containing alphanumeric keys operated by a human user, or a sensor. A sensor detects conditions in its vicinity and transforms those detections into physical expression compatible with the measurable phenomenon used to represent information in computer system . Other external devices coupled to bus , used primarily for interacting with humans, include a display device , such as a cathode ray tube (CRT) or a liquid crystal display (LCD), or plasma screen or printer for presenting text or images, and a pointing device , such as a mouse or a trackball or cursor direction keys, or motion sensor, for controlling a position of a small cursor image presented on the display  and issuing commands associated with graphical elements presented on the display . In some embodiments, for example, in embodiments in which the computer system  performs all functions automatically without human input, one or more of external input device , display device  and pointing device  is omitted.","In the illustrated embodiment, special purpose hardware, such as an application specific integrated circuit (ASIC) , is coupled to bus . The special purpose hardware is configured to perform operations not performed by processor  quickly enough for special purposes. Examples of application specific ICs include graphics accelerator cards for generating images for display , cryptographic boards for encrypting and decrypting messages sent over a network, speech recognition, and interfaces to special external devices, such as robotic arms and medical scanning equipment that repeatedly perform some complex sequence of operations that are more efficiently implemented in hardware.","Computer system  also includes one or more instances of a communications interface  coupled to bus . Communication interface  provides a one-way or two-way communication coupling to a variety of external devices that operate with their own processors, such as printers, scanners and external disks. In general the coupling is with a network link  that is connected to a local network  to which a variety of external devices with their own processors are connected. For example, communication interface  may be a parallel port or a serial port or a universal serial bus (USB) port on a personal computer. In some embodiments, communications interface  is an integrated services digital network (ISDN) card or a digital subscriber line (DSL) card or a telephone modem that provides an information communication connection to a corresponding type of telephone line. In some embodiments, a communication interface  is a cable modem that converts signals on bus  into signals for a communication connection over a coaxial cable or into optical signals for a communication connection over a fiber optic cable. As another example, communications interface  may be a local area network (LAN) card to provide a data communication connection to a compatible LAN, such as Ethernet. Wireless links may also be implemented. For wireless links, the communications interface  sends or receives or both sends and receives electrical, acoustic or electromagnetic signals, including infrared and optical signals, that carry information streams, such as digital data. For example, in wireless handheld devices, such as mobile telephones like cell phones, the communications interface  includes a radio band electromagnetic transmitter and receiver called a radio transceiver. In certain embodiments, the communications interface  enables connection from the user device to the information space.","The term \u201ccomputer-readable medium\u201d as used herein refers to any medium that participates in providing information to processor , including instructions for execution. Such a medium may take many forms, including, but not limited to computer-readable storage medium (e.g., non-volatile media, volatile media), and transmission media. Non-transitory media, such as non-volatile media, include, for example, optical or magnetic disks, such as storage device . Volatile media include, for example, dynamic memory . Transmission media include, for example, coaxial cables, copper wire, fiber optic cables, and carrier waves that travel through space without wires or cables, such as acoustic waves and electromagnetic waves, including radio, optical and infrared waves. Signals include man-made transient variations in amplitude, frequency, phase, polarization or other physical properties transmitted through the transmission media. Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, any other magnetic medium, a CD-ROM, CDRW, DVD, any other optical medium, punch cards, paper tape, optical mark sheets, any other physical medium with patterns of holes or other optically recognizable indicia, a RAM, a PROM, an EPROM, a FLASH-EPROM, any other memory chip or cartridge, a carrier wave, or any other medium from which a computer can read. The term computer-readable storage medium is used herein to refer to any computer-readable medium except transmission media.","Logic encoded in one or more tangible media includes one or both of processor instructions on a computer-readable storage media and special purpose hardware, such as ASIC .","Network link  typically provides information communication using transmission media through one or more networks to other devices that use or process the information. For example, network link  may provide a connection through local network  to a host computer  or to equipment  operated by an Internet Service Provider (ISP). ISP equipment  in turn provides data communication services through the public, world-wide packet-switching communication network of networks now commonly referred to as the Internet .","A computer called a server host  connected to the Internet hosts a process that provides a service in response to information received over the Internet. For example, server host  hosts a process that provides information representing video data for presentation at display . It is contemplated that the components of system  can be deployed in various configurations within other computer systems, e.g., host  and server .","At least some embodiments of the invention are related to the use of computer system  for implementing some or all of the techniques described herein. According to one embodiment of the invention, those techniques are performed by computer system  in response to processor  executing one or more sequences of one or more processor instructions contained in memory . Such instructions, also called computer instructions, software and program code, may be read into memory  from another computer-readable medium such as storage device  or network link . Execution of the sequences of instructions contained in memory  causes processor  to perform one or more of the method steps described herein. In alternative embodiments, hardware, such as ASIC , may be used in place of or in combination with software to implement the invention. Thus, embodiments of the invention are not limited to any specific combination of hardware and software, unless otherwise explicitly stated herein.","The signals transmitted over network link  and other networks through communications interface , carry information to and from computer system . Computer system  can send and receive information, including program code, through the networks ,  among others, through network link  and communications interface . In an example using the Internet , a server host  transmits program code for a particular application, requested by a message sent from computer , through Internet , ISP equipment , local network  and communications interface . The received code may be executed by processor  as it is received, or may be stored in memory  or in storage device  or other non-volatile storage for later execution, or both. In this manner, computer system  may obtain application program code in the form of signals on a carrier wave.","Various forms of computer readable media may be involved in carrying one or more sequence of instructions or data or both to processor  for execution. For example, instructions and data may initially be carried on a magnetic disk of a remote computer such as host . The remote computer loads the instructions and data into its dynamic memory and sends the instructions and data over a telephone line using a modem. A modem local to the computer system  receives the instructions and data on a telephone line and uses an infra-red transmitter to convert the instructions and data to a signal on an infra-red carrier wave serving as the network link . An infrared detector serving as communications interface  receives the instructions and data carried in the infrared signal and places information representing the instructions and data onto bus . Bus  carries the information to memory  from which processor  retrieves and executes the instructions using some of the data sent with the instructions. The instructions and data received in memory  may optionally be stored on storage device , either before or after execution by the processor .",{"@attributes":{"id":"p-0113","num":"0112"},"figref":["FIG. 12","FIG. 11"],"b":["1200","1200","1200","1200","1200","1200"]},"In one embodiment, the chip set or chip  includes a communication mechanism such as a bus  for passing information among the components of the chip set . A processor  has connectivity to the bus  to execute instructions and process information stored in, for example, a memory . The processor  may include one or more processing cores with each core configured to perform independently. A multi-core processor enables multiprocessing within a single physical package. Examples of a multi-core processor include two, four, eight, or greater numbers of processing cores. Alternatively or in addition, the processor  may include one or more microprocessors configured in tandem via the bus  to enable independent execution of instructions, pipelining, and multithreading. The processor  may also be accompanied with one or more specialized components to perform certain processing functions and tasks such as one or more digital signal processors (DSP) , or one or more application-specific integrated circuits (ASIC) . A DSP  typically is configured to process real-world signals (e.g., sound) in real time independently of the processor . Similarly, an ASIC  can be configured to performed specialized functions not easily performed by a more general purpose processor. Other specialized components to aid in performing the inventive functions described herein may include one or more field programmable gate arrays (FPGA) (not shown), one or more controllers (not shown), or one or more other special-purpose computer chips.","In one embodiment, the chip set or chip  includes merely one or more processors and some software and\/or firmware supporting and\/or relating to and\/or for the one or more processors.","The processor  and accompanying components have connectivity to the memory  via the bus . The memory  includes both dynamic memory (e.g., RAM, magnetic disk, writable optical disk, etc.) and static memory (e.g., ROM, CD-ROM, etc.) for storing executable instructions that when executed perform the inventive steps described herein to coordinate media presentation on devices via an information space. The memory  also stores the data associated with or generated by the execution of the inventive steps.",{"@attributes":{"id":"p-0117","num":"0116"},"figref":["FIG. 13","FIG. 1"],"b":"1300"},"Pertinent internal components of the telephone include a Main Control Unit (MCU) , a Digital Signal Processor (DSP) , and a receiver\/transmitter unit including a microphone gain control unit and a speaker gain control unit. A main display unit  provides a display to the user in support of various applications and mobile terminal functions that perform or support the steps of coordinating media presentation on devices via an information space. The display  includes display circuitry configured to display at least a portion of a user interface of the mobile terminal (e.g., mobile telephone). Additionally, the display  and display circuitry are configured to facilitate user control of at least some functions of the mobile terminal. An audio function circuitry  includes a microphone  and microphone amplifier that amplifies the speech signal output from the microphone . The amplified speech signal output from the microphone  is fed to a coder\/decoder (CODEC) .","A radio section  amplifies power and converts frequency in order to communicate with a base station, which is included in a mobile communication system, via antenna . The power amplifier (PA)  and the transmitter\/modulation circuitry are operationally responsive to the MCU , with an output from the PA  coupled to the duplexer  or circulator or antenna switch, as known in the art. The PA  also couples to a battery interface and power control unit .","In use, a user of mobile terminal  speaks into the microphone  and his or her voice along with any detected background noise is converted into an analog voltage. The analog voltage is then converted into a digital signal through the Analog to Digital Converter (ADC) . The control unit  routes the digital signal into the DSP  for processing therein, such as speech encoding, channel encoding, encrypting, and interleaving. In one embodiment, the processed voice signals are encoded, by units not separately shown, using a cellular transmission protocol such as global evolution (EDGE), general packet radio service (GPRS), global system for mobile communications (GSM), Internet protocol multimedia subsystem (IMS), universal mobile telecommunications system (UMTS), etc., as well as any other suitable wireless medium, e.g., microwave access (WiMAX), Long Term Evolution (LTE) networks, code division multiple access (CDMA), wideband code division multiple access (WCDMA), wireless fidelity (WiFi), satellite, and the like.","The encoded signals are then routed to an equalizer  for compensation of any frequency-dependent impairments that occur during transmission though the air such as phase and amplitude distortion. After equalizing the bit stream, the modulator  combines the signal with a RF signal generated in the RF interface . The modulator  generates a sine wave by way of frequency or phase modulation. In order to prepare the signal for transmission, an up-converter  combines the sine wave output from the modulator  with another sine wave generated by a synthesizer  to achieve the desired frequency of transmission. The signal is then sent through a PA  to increase the signal to an appropriate power level. In practical systems, the PA  acts as a variable gain amplifier whose gain is controlled by the DSP  from information received from a network base station. The signal is then filtered within the duplexer  and optionally sent to an antenna coupler  to match impedances to provide maximum power transfer. Finally, the signal is transmitted via antenna  to a local base station. An automatic gain control (AGC) can be supplied to control the gain of the final stages of the receiver. The signals may be forwarded from there to a remote telephone which may be another cellular telephone, other mobile phone or a land-line connected to a Public Switched Telephone Network (PSTN), or other telephony networks.","Voice signals transmitted to the mobile terminal  are received via antenna  and immediately amplified by a low noise amplifier (LNA) . A down-converter  lowers the carrier frequency while the demodulator  strips away the RF leaving only a digital bit stream. The signal then goes through the equalizer  and is processed by the DSP . A Digital to Analog Converter (DAC)  converts the signal and the resulting output is transmitted to the user through the speaker , all under control of a Main Control Unit (MCU) \u2014which can be implemented as a Central Processing Unit (CPU) (not shown).","The MCU  receives various signals including input signals from the keyboard . The keyboard  and\/or the MCU  in combination with other user input components (e.g., the microphone ) comprise a user interface circuitry for managing user input. The MCU  runs a user interface software to facilitate user control of at least some functions of the mobile terminal  to coordinate media presentation on devices via an information space. The MCU  also delivers a display command and a switch command to the display  and to the speech output switching controller, respectively. Further, the MCU  exchanges information with the DSP  and can access an optionally incorporated SIM card  and a memory . In addition, the MCU  executes various control functions required of the terminal. The DSP  may, depending upon the implementation, perform any of a variety of conventional digital processing functions on the voice signals. Additionally, DSP  determines the background noise level of the local environment from the signals detected by microphone  and sets the gain of microphone  to a level selected to compensate for the natural tendency of the user of the mobile terminal .","The CODEC  includes the ADC  and DAC . The memory  stores various data including call incoming tone data and is capable of storing other data including music data received via, e.g., the global Internet. The software module could reside in RAM memory, flash memory, registers, or any other form of writable storage medium known in the art. The memory device  may be, but not limited to, a single memory, CD, DVD, ROM, RAM, EEPROM, optical storage, or any other non-volatile storage medium capable of storing digital data.","An optionally incorporated SIM card  carries, for instance, important information, such as the cellular phone number, the carrier supplying service, subscription details, and security information. The SIM card  serves primarily to identify the mobile terminal  on a radio network. The card  also contains a memory for storing a personal telephone number registry, text messages, and user specific mobile terminal settings.","While the invention has been described in connection with a number of embodiments and implementations, the invention is not so limited but covers various obvious modifications and equivalent arrangements, which fall within the purview of the appended claims. Although features of the invention are expressed in certain combinations among the claims, it is contemplated that these features can be arranged in any combination and order."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The embodiments of the invention are illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 8A","FIG. 8B"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 9A","FIG. 9B"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 13"}]},"DETDESC":[{},{}]}
