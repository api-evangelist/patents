---
title: Reconstructed frame caching
abstract: Systems and methods for processing input media in a computing device are described. In one aspect, a reconstructed frame is cached according to a set of criteria. A request to scrub to a predictive frame of input media is received. Responsive to receiving the request, the predictive frame is decoded starting with the reconstructed frame.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07733962&OS=07733962&RS=07733962
owner: Microsoft Corporation
number: 07733962
owner_city: Redmond
owner_country: US
publication_date: 20031208
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","CONCLUSION"],"p":["The invention pertains to multimedia processing in a computing environment.","In multimedia editing and viewing applications, there are numerous scenarios where a user may want to closely review select portions of multimedia content via scrubbing. Scrubbing is the process of moving within a piece of multimedia content such as a video to locate and present a particular section of the video. The term originally comes from the days of reel-to-reel players, when rocking a reel would give the impression of scrubbing tape across the head. Many video scrub tools today present video in a window and allow the user to drag a cursor across a timeline scrollbar to present different sections of a video to the user. That is, as the cursor is dragged across the scrollbar, the scrub tool updates the display to present that frame of the video represented by the current cursor position. Such scrubbing activities include repeated playback of a small section of content in both forward and reverse directions, displaying individual frames at times controlled by the user, or playback whose rate is finely controlled by the user.","Numerous inter- and intra-frame compression systems compress and decode bitstreams based on groups of pictures (GOP). Each GOP starts with an intracoded (I) frame and includes any number of subsequent forward predictive (P) frames and\/or bidirectionally predictive (B) frames\u2014the I-frame is always the first picture in a GOP. To decode any P or B frame in a GOP, decoding always starts with the I-Frame and proceeds to decode each frame upon which the intervening frames depend, until the selected frame is encountered and decoded. Intervening frames are frames between the I-frame and the selected frame. In the context of media decoding, frames that need to be decompressed in order to decompress a particular GOP frame are called \u201cpre-roll frames.\u201d","Thus, the amount of time that it takes to decode a particular frame in a GOP that is not the I-frame is a function of the number of pre-roll frames that need to be decoded to decode the particular frame. In the worst case, the entire GOP must be decoded to decode the particular frame. The length of a GOP is generally based on the encoding settings and the content being encoded. For instance, a video with little or no movement between frames for significant amounts of time may have a GOP that is hundreds and even thousands of frames in length.","Application responsiveness, and by extension responsiveness of the underlying media platform, is crucial in providing a good user experience. Yet, in view of the above, to scrub to a select frame in a GOP, wherein the selected frame is not an I-frame, a scrub tool may have to perform many processing intensive and time consuming decoding operations to reach and decode a selected frame. This substantial limitation does not even take into consideration that after such a selected frame is decoded, the content of the frame may need to be transformed via one or more effects, which will increase the delay even more.","To make matters worse, some media decoders provide forward-only decompression, meaning that reverse playback rates of encoded media comprises of key and delta-frames is very slow. For instance, if a select video portion is to be scrubbed in reverse, the decoding delays already described will exponentially increase. This is because of the reverse iterative I-frame to P\/B frame decoding required. (An I-frame is a key frame). In particular, to scrub a portion of video in reverse order, wherein the portion begins with a select P\/B frame n, decoding progresses from the I-frame to decode all intervening frames until frame n is reached. Next, the process decodes the I-frame and all intervening frames until frame n\u22121 is reached. This iterative process continues until the selected portion has been scrubbed in reverse.","Accordingly, systems and methods to improve scrubbing tool performance are desired.","Systems and methods for processing input media in a computing device are described. In one aspect, a reconstructed frame is cached according to a set of criteria. A request to scrub to a predictive frame of input media is received. Responsive to receiving the request, the predictive frame is decoded starting with the reconstructed frame.","Overview","The following described systems and methods provide reconstructed frame caching. Reconstructed frame caching allows a media platform to cache decoded multimedia content frames (reconstructed frames) to minimize the number of frames for media pipeline decoding when a user scrubs to a portion of the content. To increase memory efficiency, one implementation of the system and method for reconstructed frame caching stores reconstructed frames as a function of destination display resolution, memory usage requests from the application, and\/or other configurable criteria. These and other aspects of the systems and methods for reconstructed frame caching are now described in greater detail.","An Exemplary System for Reconstructed Frame Caching","Turning to the drawings, wherein like reference numerals refer to like elements, the invention is illustrated as being implemented in a suitable computing environment. Although not required, the invention is described in the general context of computer-executable instructions, such as program modules, being executed by a personal computer. Program modules generally include routines, programs, objects, components, data structures, etc., that perform particular tasks or implement particular abstract data types.",{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 1","b":["100","100","100"]},"The methods and systems described herein are operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use include, but are not limited to, personal computers, server computers, multiprocessor systems, microprocessor-based systems, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and so on. Compact or subset versions of the framework may also be implemented in clients of limited resources, such as cellular phones, personal digital assistants, handheld computers, or other communication\/computing devices. The invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules and program data for reconstructed frame caching may be located in both local and remote memory storage devices.","As shown in , computing environment  includes a general-purpose computing device in the form of a computer . The components of computer  include, by are not limited to, one or more processors or processing units , a system memory , and a bus  that couples various system components including system memory  to processor .","The system bus  represents one or more of any of several types of bus structures, including a memory bus or memory controller, a peripheral bus, an accelerated graphics port, and a processor or local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnects (PCI) bus also known as Mezzanine bus.","Computer  typically includes a variety of computer readable media. Such media may be any available media that is accessible by computer , and it includes both volatile and non-volatile media, removable and non-removable media. In , system memory  includes computer readable media in the form of volatile memory, such as random access memory (RAM) , and\/or non-volatile memory, such as read only memory (ROM) . A basic input\/output system (BIOS) , containing the basic routines that help to transfer information between elements within computer , such as during start-up, is stored in ROM . RAM  contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processor .","Computer  may further include other removable\/non-removable, volatile\/non-volatile computer storage media. For example,  illustrates a hard disk drive  for reading from and writing to a non-removable, non-volatile magnetic media (not shown and typically called a \u201chard drive\u201d), a magnetic disk drive  for reading from and writing to a removable, non-volatile magnetic disk  (e.g., a \u201cfloppy disk\u201d), and an optical disk drive  for reading from or writing to a removable, non-volatile optical disk  such as a CD-ROM\/R\/RW, DVD-ROM\/R\/RW\/+R\/RAM or other optical media. Hard disk drive , magnetic disk drive  and optical disk drive  are each connected to bus  by one or more interfaces .","The drives and associated computer-readable media provide nonvolatile storage of computer readable instructions, data structures, program modules, and other data for computer . Although the exemplary environment described herein employs a hard disk, a removable magnetic disk  and a removable optical disk , it should be appreciated by those skilled in the art that other types of computer readable media can store data that is accessible by a computer, such as magnetic cassettes, flash memory cards, digital video disks, random access memory (RAM), read only memory (ROM), and the like, may also be used in the exemplary operating environment.","A user may provide commands and information into computer  through input devices such as keyboard  and pointing device  (such as a \u201cmouse\u201d). Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, serial port, scanner, camera, etc. These and other input devices are connected to the processing unit  through a user input interface  that is coupled to bus , but may be connected by other interface and bus structures, such as a parallel port, game port, or a universal serial bus (USB). A monitor  or other type of display device is also connected to bus  via an interface, such as a video adapter . In addition to monitor , personal computers typically include other peripheral output devices (not shown), such as speakers and printers, which may be connected through output peripheral interface .","Computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . Remote computer  may include many or all of the elements and features described herein relative to computer . Logical connections shown in  are a local area network (LAN)  and a general wide area network (WAN) . Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet.","When used in a LAN networking environment, computer  is connected to LAN  via network interface or adapter . When used in a WAN networking environment, the computer typically includes a modem  or other means for establishing communications over WAN . Modem , which may be internal or external, may be connected to system bus  via the user input interface  or other appropriate mechanism. Depicted in , is a specific implementation of a WAN via the Internet. Here, computer  employs modem  to establish communications with at least one remote computer  via the Internet .","In a networked environment, program modules depicted relative to computer , or portions thereof, may be stored in a remote memory storage device. Thus, e.g., as depicted in , remote application programs  may reside on a memory device of remote computer . It will be appreciated that the network connections shown and described are exemplary and other means of establishing a communications link between the computers may be used.","The systems and methods for reconstructed frame caching technology are described with reference to acts and symbolic representations of operations that are performed by one or more computing devices, unless indicated otherwise. As such, it is understood that such acts and operations are computer-executed in that they include the manipulation by a processing unit of electrical signals representing data in a structured form. This manipulation transforms the data or maintains it at locations in the memory system of the computing device, which reconfigures or otherwise alters the operation of the computing device The data structures where data is maintained are physical locations of the memory that have particular properties defined by the format of the data. However, while the systems and methods are being described in the foregoing context, acts and operations described hereinafter may also be implemented in hardware.","Exemplary Program Modules and Data for Reconstructed Frame Caching","A number of program modules are stored on the hard disk, magnetic disk , optical disk , in ROM , and\/or in RAM , including, e.g., an operating system (OS) , application(s) , media engine , media decoder(s) , other program modules , and program data . The OS provides a runtime environment via conventional functions such as file management, event handling, processes and threads, memory management, user interfaces (e.g., windowing, menus, dialogs, etc.), security, authentication, verification, and so on.","Application(s)  interface with media engine  and a number of media transform modules which include media decoder(s) . Media decoder(s)  decode input media , which includes any combination of audio, video, and image data. The media transform modules are represented by \u201cother program modules\u201d  and include, for example, objects that manipulate data. These transforms may include video, audio, and\/or image encoders, splitters, multiplexers, video and\/or audio processors. For instance, a transform module may be used to convert decoded image data from one data format to another format suitable for display on a monitor . The media engine  and media transform modules comprise a media platform that is independent of application(s) .","Application(s)  interface with media engine  via application programming interface (API)  to access media processing functionality of the media platform. Such media processing functionality is directed to the decoding and possible transformation of input media  for presentation to a media sink (e.g., video adapter , data media interfaces , and\/or the like). Details of API  are discussed below in the section titled \u201cAn Exemplary Reconstructed Frame Caching API.\u201d Responsive to receiving a request from an application  to process input media , the media engine  communicates with other modules of the media platform.","Input media  includes, for example, any multimedia content encoded according to an intra- and inter-frame compression technique. There are numerous known intra- and inter-frame compression algorithms such as those used to produce MPEG and WINDOWS Media Video files. As such, input media  includes multimedia content (e.g., frames) organized with respect to one or more groups of pictures (GOP), including I-frames, P-frames, and B-frames. In this implementation, input media  can be parsed, or searched for specific frames, and thereby provides frame-level access. For example, input media  is a video\/audio file stored locally in system memory .","To decode compressed input media , media engine  interfaces with one or more media decoders , for instance via a media processor . An exemplary such media processor  in a media platform architectural implementation alternate to that described with respect to , and within which the systems and methods for reconstructed frame caching described herein could be implemented, is described in U.S. patent application Ser. No. 10\/603,328, titled \u201cMedia Foundation Media Processor\u201d, filed on Jun. 25, 2003, commonly assigned herewith, and incorporated by reference. In terms of the overall media pipeline architecture of , and for purposes of this discussion, the media processor  is used in the context of the media engine .","In one implementation, a media decoder  is a plug in transform module for decoding a specific type of input media file such as a WMV or MPEG file. Media decoder(s)  process the input media  to generate decoded frame(s) . The data format of decoded frame(s)  can be any type of data format as a function of the specific implementation of the media decoder(s) . The media engine  sends decoded frame(s)  to one or more media sinks (e.g., the video adapter  for presentation of the decoded frame(s)  onto display device , and\/or the like) and\/or other type of media processing module such as a transformation\/effect module (i.e., respective ones of \u201cother program modules\u201d ).","A Reconstructed Frame Cache","The systems and methods for reconstructed frame caching provide media platform pipeline components to decode input media  and store select ones of the decoded and possibly effect transformed frames into reconstructed (\u201cR\u201d) frame cache  according to a set of criteria. Decoded input media  is represented as decoded frames . Each frame stored in the reconstructed (\u201cR\u201d) frame cache  is hereinafter referred to as a reconstructed frame .","In this implementation, by default, reconstructed frames  are cached after the decoding operation, at or by the media decoder(s) . This default operation populates frame cache  with decoded and uncompressed frame(s). However, an application  can override this default caching location by directing the media engine  to coordinate reconstructed frame caching anywhere in the media pipeline, for instance, as far downstream in the media pipeline from the media decoder(s)  as possible, and anywhere in between. Such coordination may involve the media engine  directing a specific component (e.g., effect transform module) of the media pipeline to cache the reconstructed frames  into frame cache  after data transform(s) have been applied to the decoded frames . Thus, even though reconstructed frame  was initially uncompressed and decoded by a media decoder , post-transformation the reconstructed frame  may be in an intermediate data format that is not ready for presentation without additional image processing. In this scenario, the reconstructed frame  may be partially decoded, partially compressed, and\/or so on. As such, the particular state of the reconstructed frame  in frame cache  is a function of the transform(s)\u2014if any\u2014applied by media platform component(s) to decoded data  before it is cached.","When a frame of decoded frame(s)  is not cached as a reconstructed frame , the frame is flushed from system memory  after being sent to a media sink such as data media interface , video adapter , and\/or the like. Accordingly, only a subset of the decoded frames frame(s) , independent of whether decoded frames are subsequently transformed via one or more effects, are cached into the frame cache .","Criteria for storing select ones of the decoded frame(s)  into the reconstructed frame cache  include, for example, caching reconstructed frames :\n\n","For example, if application  specifies that reconstructed frames  are only to be cached at a particular caching interval, then caching of reconstructed frames  occurs only at the application specified time intervals. Any combination of one or more of such criteria may be utilized.","In yet another example of criteria that may be used to store reconstructed frames , consider that typical multimedia viewers on a computer allow a user to move a scroll bar, usually located beneath and\/or beside a video presentation, from side to side. This allows the user to present specific forward and\/or backward video frames (scrubbing operations). How accurate the user can be in getting to a particular time point in the video (frame) using the scroll bar is dependent on the resolution of the display device screen.","This is because input media  is divided up into a multiple visual frames, each frame corresponding to a specific time relative to the beginning of the movie. The position of the scroll bar corresponds to a time frame of the movie. Move the scroll bar to the left edge, and the beginning of the movie is specified. Move the scroll bar to the right edge, and the end of the movie is specified. Move the scroll bar somewhere to the middle and somewhere in the middle of the movie. However, the user cannot move the scroll bar in such small increments that will actually specify\/select every frame in the movie because the resolution of the screen (the number of pixels) is limited. (If an infinite amount of screen pixels were available, and the user had a very steady hand, the user could inch the scroll bar over in tiny increments to get to each frame). With this in mind, only those reconstructed frames  that correspond to the decoded frames  that can actually be selected using the scroll bar given the resolution of the screen may be cached to the frame cache . Techniques for determining display screen resolution are known. In one implementation, this criterion may be combined with one or more other criteria to populate the frame cache .","Although a reconstructed frame  is not an I-frame, each is completely reconstructed, meaning that all decompression operations that require information in previously decompressed frames (the pre-roll frames) in order to reconstruct the frame have been performed. As such, when the reconstructed frame  is not in an intermediate data format effected by a transform module, a reconstructed frame  can be directly presented to a media sink (e.g., video adapter , a data media interface , etc.) for processing (e.g., display, storage, audition, etc.) independent of a need to subsequently derive information (e.g., motion compensation values, and\/or the like) from any other of the GOP's frames. However, and as indicated above, when a reconstructed frame is in an intermediate data format, additional processing of some sort may have to be performed before presenting to a media sink, the processing being a function of the particular effect transforms applied to the decoded data .","Caching of select ones of the decoded frames  into the reconstructed frame cache allows the described systems and methods for reconstructed frame caching to substantially reduce, and in some instances completely eliminate the amount of input media  that would otherwise need to be decoded responsive to a scrubbing request from an application . This is because frames in a GOP (a portion of input media ) that are subsequent to a cached reconstructed frame  can be decoded from the reconstructed frame . The media engine  looks up the desired presentation time in its frame cache . The latest reconstructed frame  available in the desired frame's GOP that precedes the desired frame is obtained from the frame cache  and used as the starting point for decoding. If no such reconstructed frame  is in the frame cache , then decoding simply starts at the nearest previous I-frame. Additionally, if a reconstructed frame  associated with an exact match for that presentation time is found in the frame cache , then the reconstructed frame  is given as the output, and decoding is avoided. Thus, after one or more reconstructed frames  have been cached for any particular GOP, the number of pre-roll frames that have to be decoded to decode a predictive frame of interest may be substantially reduced, and possibly avoided altogether.","This is in stark contrast to conventional systems and techniques that require, for example, responsive to a scrubbing request for a particular P or B frame, the decoder to decode all intervening frames from the GOP's I-frame (key frame) to the particular frame of interest. We now illustrate this contrast in the examples of .",{"@attributes":{"id":"p-0048","num":"0054"},"figref":"FIG. 2","b":["200","200","168","200","200","200","156","200","174"]},{"@attributes":{"id":"p-0049","num":"0055"},"figref":["FIG. 3","FIG. 3","FIG. 2"],"b":["300","300","168","300","30","200","200","158","170","300","158","170","174","172"]},"In the example of , reconstructed frames - through - are stored in the frame cache . Reconstructed frames - through - respectively represent frames  decoded at times t=2, t=4, and t=6. In one implementation, reconstructed frames  are cached in an uncompressed data format, for instance, after processing by a media decoder . In another implementation, reconstructed frames  are cached in an intermediate format other than a display format in which some processing may need to be performed on the intermediate format before the reconstructed frame can be presented. For instance, in one implementation, a reconstructed frame is in at least a partially compressed, or partially decoded data format after it has been processed by a media transform module.","If a user directs application  to present a particular frame between t=0 and t=8, the media engine  can either decode the particular frame directly from the I-frame (key frame), or if there are one or more reconstructed frames  cached in-between the particular frame and the I-frame, substantially reduce the number of frames that need to be decoded to decide the particular frame by decoding the particular frame starting at a select one of the cached reconstructed frames .","In one implementation of a system and method for reconstructed frame caching, for example, if a user requests to scrub to a particular frame in the GOP  at some time t, wherein t between 0 and 8, the media engine  evaluates the reconstructed frame cache  to determine if there is a reconstructed frame  that is latest and previous with respect to the input media  timeline and the time of the particular frame, the frame of interest. If such a reconstructed frame  is located, the media engine  determines if there is an I-frame in the input media  subsequent to the time of the located reconstructed frame  and before the frame of interest. If not, then media engine  extracts the located reconstructed frame  from frame cache  and passes the extracted reconstructed frame to media decoder(s) . Media decoder(s)  decode the frame of interest directly from the extracted reconstructed frame, rather than decoding the frame of interest from the GOP's I-frame. However, if there is an I-frame in the input media  subsequent to the time of the located reconstructed frame , then the media engine  passes the I-frame to media decoder(s)  for decoding of the frame of interest.","For instance, if a user requests to scrub to a particular frame in the GOP  at t=7 (or any time t), media engine  extracts the last reconstructed frame  on the timeline that has a time less than that of the frame of interest (t=7). In this example, and under these criteria, media engine  extracts reconstructed frame - from frame cache . The media engine  passes reconstructed frame - to media decoder(s) . Media decoder(s)  decode the frame of interest at t=7, directly from the reconstructed frame -\u2014not the GOP's I-frame. This is a substantial reduction in the number of frames that need to be decoded to decode the frame of interest. Recall that 210 frames needed to be decoded in the example of  to decode a frame at t=7. In contrast, and as illustrated in the example of , only 30 compressed frames of input media  from t=6 to t=7 are decoded to decode the frame of interest at t=7.","Any reconstructed frames  in-between a GOP's I-frame and an encoded predictive frame of interest may also be used to decode the frame of interest with a reduction in the number of frames to be decoded had decoding started instead with the I-frame. For instance, although the example of  selected reconstructed frame -, which is a previous but closest in time to the frame of interest at t=7, other reconstructed frames (e.g., reconstructed frames - or -) could also have been used with less decoding efficiency than what was achieved with use of reconstructed frame -, which was a previous but closest selection with respect to the frame of interest. Yet, in a GOP, use of any reconstructed frame  in the GOP that is between the GOP's I-Frame and the frame of interest in the GOP provides greater decoding efficiency than had decoding begun with the I-frame.","These exemplary operations to decode a frame of input media  using cached reconstructed frames are also shown in the exemplary procedure  of .","While an application  may cache frames, doing it inside a media platform makes scrubbing operations simpler to implement in the application, and further allows for efficient use of system memory  involved by caching only select reconstructed frames . For caching to be useful in the absence of reconstructed frame caching technology, the media platform or the application would need to cache full uncompressed frames for all 240 frames of the GOPs of . This alternative to reconstructed frame technology requires a substantially greater and potentially prohibitive amount of memory as compared to what is utilized by caching reconstructed frames .","For instance, and in view of the foregoing example of , simply caching an uncompressed frame at t=6 would not be helpful in the illustrated scenario. This is because it would still be necessary to start decoding at the head of the GOP to obtain any frame that is not the exact frame that was cached. (I.e., conventional systems do not have a decoding mechanism to start decoding at a cached full uncompressed frame that is not a key frame to get to a subsequent predictive frame). In other words, if a cache includes full uncompressed frames, and a particular frame is requested, a media processor will look to the desired presentation time in the cache to determine if a corresponding full uncompressed frame can be identified. If an exact match for the presentation time is found, the uncompressed frame is provided as output and decoding is avoided. However, if an exact match is not found decoding must begin at the GOP's key frame.","An Exemplary Reconstructed Frame Caching API","Referring to , media engine  exposes frame caching API . An application  utilizes the frame caching API  to obtain various features of the media platform's frame caching service, and thereby provide the application  with control of how frame caching is performed by the media platform.","In this implementation, the frame caching interface  includes, for example, the following interfaces:\n\n","EnableFrameCaching: The application  calls this interface to direct the media engine  to cache reconstructed frames . When turned on, the frame cache  is automatically be filled with select reconstructed frames  from playback frames. That is, once EnableFrameCaching has been called, application  can fill the frame cache , for example, from a ScrubStartPosition to a ScrubEndPosition, simply by playing the input media  for which it wants reconstructed frames cached. If an application wants to begin caching reconstructed frames prior to input media playback, the application can call another the ScrubbingDestination interface, which is described below.",{"@attributes":{"id":"p-0061","num":"0071"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"28pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"189pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"HRESULT FrameCacher::EnableFrameCaching("]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"42pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"175pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"[in] GUID guidMajorType,"]},{"entry":[{},"[in] const GUID *pguidTransform,"]},{"entry":[{},"[in] DWORD cbCacheSizeLimit ,"]},{"entry":[{},"[in] LONGLONG hnsCacheInterval"]},{"entry":[{},");"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{},"ul":{"@attributes":{"id":"ul0005","list-style":"none"},"li":{"@attributes":{"id":"ul0005-0001","num":"0000"},"ul":{"@attributes":{"id":"ul0006","list-style":"none"},"li":["guidMajorType\u2014A GUID, which is a substantially unique identifier, indicating which media type to cache. Media types include, for example, video, audio, etc. Since decoding of video is typically more CPU-intensive, then for example audio, this parameter is typically set to indicate video media type.","pguidTransform\u2014A NULL pointer indicates that the media engine  should make its best determination about where in the media pipeline to cache the frames. (Alternatives to caching reconstructed frames  immediately after decoding operations were described above). The application  can override this default behavior by specifying *pguidTransform to be the effect GUID of any effect (i.e., transform module) that it has added to the processing pipeline of the media platform. In this case, caching will occur at the output of the specified effect, whenever the transform is present. If the value of *pguidTransform is GUID_NULL, caching will occur directly upstream of all application  specified transforms.","cbCacheSizeLimit\u2014This parameter specifies a number indicating the maximum amount of memory that the application  is willing to have used for caching reconstructed frames . If this value is zero (0), then media engine  determines the limit, for example, based on some percentage of the available system memory , or other criteria. In this implementation, the size of the frame cache  is maintained on a most-recently-used basis; that is, as the cache approaches the size limit (cbCacheSizeLimit), the least recently used reconstructed frame  is ejected from the frame cache . In another implementation, selecting which reconstructed frame  to eject from the frame cache  is determined on other than a most-recently-used basis, such as with a first-in-first-out algorithm, as a function of targeted response time, system capabilities, and\/or any other type of buffer management technique.","hnsCacheInterval\u2014This is the interval at which an application  is requesting that reconstructed frames  be cached. In this implementation, the interval is specified in hundred-nanosecond time units, although other units could be utilized as a function of system architecture. A value of 0 means that every frame (subject to the cbCacheSizeLimit limit) should be cached in the frame cache . Application(s)  may specify a nonzero interval either to increase the coverage area of the cache or because it is known that the application will be interested only in certain frames, for instance, frames corresponding to the pixels on a visible work area on a monitor . When the input media  being scrubbed is a timeline, wherein the scrubbing area straddles multiple clips, the media engine , or the designated media platform module, can cache reconstructed frames  from several clips at once."]}}}},"In one implementation, unless EnableFrameCaching has been called, reconstructed frames  are not cached. In another implementation, when the media engine  detects a reverse playback operation, the media engine utilized reconstructed frame  caching regardless of whether the application  has enabled such caching.","FrameCacher::DisableFrameCaching: This API  allows the application  to turn off reconstructed frame caching. In one implementation, invoking this interface also causes the system to release any currently-cached reconstructed frames . For example, the DisableFrameCaching interface may be called by an application  when the application determines that a user has finished scrubbing input media .",{"@attributes":{"id":"p-0064","num":"0078"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"56pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"161pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"HRESULT DisableFrameCaching("]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"70pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"147pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"[in] \u2003\u2003guidMajorType"]},{"entry":[{},");"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{}},"IScrubbingDestination::SetPlaybackMode\u2014This method allows the application  to specify whether actual playback of the input media  should occur, or whether the frame cache  should simply be filled.",{"@attributes":{"id":"p-0066","num":"0080"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"HRESULT SetPlaybackMode("]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"140pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"[in] BOOL fPlayback"]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},");"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}}},"The parameter fPlayback, if TRUE, allows playback\/rendering of the decoded frames , which is the default mode. If fPlayback is set to FALSE, a destination provides media sinks that simulate playback, without actually rendering or otherwise playing the decoded frames  to fill the frame cache . A destination is an object represented by \u201cother program modules\u201d  of . A destination defines where decoded frames  are presented (e.g. a window, disk file, etc.). For instance, a destination may provide media sinks (e.g., data media interfaces  (), video adapter  (), etc.) into which decoded frame data  flows. Additionally, a destination can define that data is to be decoded, encoded, have effects applied thereto via transform module(s), be mixed with other data (e.g. stream mixing), and\/or so on.","For example, if application  wants to pre-populate frame cache  with reconstructed frame(s)  before playing back any decoded frames , then the application uses the described ScrubbingDestination interface. In one implementation, responsive to a set playback mode of false, media engine  (or alternately an effect transform module) forwards the decoded frames  to a NOP'd media sink, although the frames are decoded and (some of them) cached as reconstructed frames , as discussed. Caching reconstructed frames  without playback will likely result in faster processing of the input media  than had the input media been decoded and subsequently rendered in real-time.","ScrubbingDestination::GetPlaybackMode. This method allows application  to retrieve the current playback mode of the Scrubbing Destination.",{"@attributes":{"id":"p-0070","num":"0084"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"49pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"168pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"RESULT GetPlaybackMode("]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"63pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"154pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"[out] BOOL *pfPlayback"]},{"entry":[{},");"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{},"b":["170","172"]},"Creation function\u2014This interface creates is the creation function for Scrubbing Destinations.",{"@attributes":{"id":"p-0072","num":"0086"},"tables":{"@attributes":{"id":"TABLE-US-00005","num":"00005"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"21pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"196pt","align":"left"}}],"thead":{"row":{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}},"tbody":{"@attributes":{"valign":"top"},"row":{"entry":[{},"HRESULT CreateScrubbingDestination("]}}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"2"},"colspec":[{"@attributes":{"colname":"offset","colwidth":"35pt","align":"left"}},{"@attributes":{"colname":"1","colwidth":"182pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":[{},"[in] IDestination *pPlaybackDestination"]},{"entry":[{},"[out] IDestination **ppScrubbingDestination"]},{"entry":[{},");"]},{"entry":[{},{"@attributes":{"namest":"offset","nameend":"1","align":"center","rowsep":"1"}}]}]}}]}},"br":{},"b":"158"},"An Exemplary Media Decoder API","In one implementation, media decoder(s)  expose API  comprising methods that allow media decoder(s)  to access reconstructed frame buffer . In one implementation, API  is used in conjunction with a standard media decoder interface. For example, API  may be used with Microsoft Corporation's DirectShow\u00ae Media Object API. DirectShow\u00ae provides for playback of multimedia streams from local files or Internet servers, capture of multimedia streams from devices, and format conversion of multimedia streams.","In this implementation, API  includes, for example, the following interfaces:\n\n",{"@attributes":{"id":"p-0076","num":"0092"},"figref":["FIG. 5","FIG. 1"],"b":["500","166","176","502","158","156","174","168","160"]},"At block , the media engine , or a different media platform component specified by the media engine  (such specification possibly under direction of the application ), caches reconstructed frames  into the reconstructed frame cache  according to the specified criteria (e.g., at periodic time intervals and\/or other criteria, during or prior to playback). In parallel, the media engine  responds to any request by the Application  corresponding to the frame caching API . Such requests include, for example, Set\/Get Playback Mode requests, and so on. At block , responsive to receiving a request from the application  to disable reconstructed frame caching, and independent of whether media is being played back at that moment, the media engine  disables reconstructed frame caching operations.","It can be appreciated that the particular ones and sequences of APIs  called by an application  are a function of the particular application's implementation.","Although the invention has been described in language specific to structural features and\/or methodological operations or actions, it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or actions described. Rather, the specific features and actions are disclosed as exemplary forms of implementing the claimed invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["In the figures, the left-most digit of a component reference number identifies the particular figure in which the component first appears.",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":["FIG. 3","FIG. 3"]},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
