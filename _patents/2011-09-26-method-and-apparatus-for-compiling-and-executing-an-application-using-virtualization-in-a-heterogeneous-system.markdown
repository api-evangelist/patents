---
title: Method and apparatus for compiling and executing an application using virtualization in a heterogeneous system
abstract: A method and apparatus for compiling and executing an application including Central Processing Unit (CPU) source code and Graphic Processing Unit (GPU) source code. The apparatus includes a hardware device including a CPU and a GPU; a compiler that compiles the GPU source code into a GPU virtual instruction; and a hybrid virtualization block that executes an execution file by translating the GPU virtual instruction into GPU machine code.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09495720&OS=09495720&RS=09495720
owner: Samsung Electronics Co., Ltd
number: 09495720
owner_city: 
owner_country: KR
publication_date: 20110926
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["PRIORITY","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF EMBODIMENTS OF THE INVENTION"],"p":["This application claims priority under 35 U.S.C. \u00a7119(a) to an application filed in the Korean Intellectual Property Office on Sep. 27, 2010, and assigned Serial No. 10-2010-0093327, the content of which is incorporated herein by reference.","1. Field of the Invention","The present invention relates generally to a method and apparatus for compiling and executing an application with virtualization in a heterogeneous system integrating Central Processing Unit (CPU) and Graphic Processing Unit (GPU), and more particularly, to a method and apparatus for compiling and executing the application by compiling a GPU source code of the application into a GPU virtual instruction in a source code compiling process and translating the compiled GPU virtual instruction into a GPU machine code in a file execution process.","2. Description of the Related Art","Advances in GPU technology are bringing a number of changes to computing environments. More specifically, conventionally a GPU is a device designed for graphics processing and it has been dealt with as an auxiliary part for mitigating overload of the CPU, as the main part of a computer, when there is little use of graphic content. However, with the widespread popularization of High Definition (HD) video and games, and now even 3-Dimensional (3D) content, the role of the GPU is increasing. That is, the GPU has recently been spotlighted as a unit responsible for processing large volume of operations in place of CPU as well as graphics processing. Accordingly, as the role of GPU is expanded, there is a growing need to improve the utilization efficiency of the GPU.","Accordingly, the present invention is provided to address the above-mentioned problems and\/or disadvantages and to offer at least the advantages described below.","An aspect of the present invention is to provide a method and apparatus for compiling and executing an application using virtualization in a heterogeneous system integrating CPU and GPU.","Another aspect of the present invention to provide a method and apparatus that compiles GPU source code into a GPU virtual instruction when compiling the source codes included in the application and translates the compiled virtual GPU command to a GPU machine code directly, resulting in enhanced CPU and GPU utilization efficiency.","In accordance with an aspect of the present invention, a method for compiling and executing an application in a system including a Central Processing Unit (CPU) and a Graphic Processing Unit (GPU) is provided. The method includes receiving a request for compiling the application, the application including CPU source code and GPU source code; generating an execution file in response to the request for compiling by compiling the GPU source code into a GPU virtual instruction; receiving a request for executing the execution file; and executing the execution file by translating the GPU virtual instruction into GPU machine code, in response to the request for executing the execution file.","In accordance with another aspect of the present invention, an apparatus for compiling and executing an application including Central Processing Unit (CPU) source code and Graphic Processing Unit (GPU) source code is provided. The apparatus includes a hardware device including a CPU and a GPU; a compiler that compiles the GPU source code into a GPU virtual instruction; and a hybrid virtualization block that executes an execution file by translating the GPU virtual instruction into GPU machine code.","In accordance with another aspect of the present invention, an apparatus for compiling and executing an application including Central Processing Unit (CPU) source code and Graphic Processing Unit (GPU) source code is provided. The apparatus includes a hardware device including a CPU and a GPU; a compiler that compiles the GPU source code into a GPU virtual instruction; and an Operating System (OS) for executing an execution file by translating the GPU virtual instruction into GPU machine code.","Various embodiments of the present invention are described in detail below with reference to the accompanying drawings. In the following description, the matters defined in the description are provided to assist a comprehensive understanding of the present invention, and it is obvious to those of ordinary skill in the art that predetermined modifications or changes of the matters described herein can be made without departing from the scope of the invention. The same reference numbers are used throughout the drawings to refer to the same or like parts. Further, detailed descriptions of well-known functions and structures incorporated herein may be omitted to avoid obscuring the subject matter of the present invention.","In the following description, the term \u201capplication\u201d means an application program of original code or source code before being compiled. For example, the source code can be CPU source code for executing a CPU operation or GPU source code for executing a GPU operation. Additionally, the term \u201cexecution file\u201d means a file generated by a compiler when compiling an application.","Basically, a GPU can be used by an application (or application program) in two ways. The first way is for a system program, such as an OS, to provide a library for the application to use. The second way is to include a code to be used by GPU in the application in order for the GPU to directly execute the code in a program runtime.",{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 1"},"As illustrated in , the system includes an application layer having application programs, a hardware layer including physical processing units, such as a CPU and a GPU, a middleware layer, which is interposed between the application layer and the hardware layer, and an OS. In the system of , the OS provides a GPU library such that the application calls the GPU library directly to perform the corresponding function.","Open Graphics Library (OpenGL\u00ae) is a representative graphics standard for use in a system configuration as illustrated in . An application program can call the OpenGL\u00ae Application Programming Interface (API) to process 3D graphics with the GPU. The OpenGL\u00ae API is a standard API with which the applications are developed. For example, a representative OpenGL\u00ae-based application is a game program. However, this type of OpenGL\u00ae method has a shortcoming in that only the provided functions can be used.","For example, for implementing face recognition operations using a GPU, a standard face recognition API should be designated and implemented in a corresponding system in the form of a library. However, if the library for the face recognition operations is not provided, there is no way for the program developer to implement the operations.",{"@attributes":{"id":"p-0036","num":"0035"},"figref":"FIG. 2"},"Similar to , the system illustrated in  includes an application layer having application programs, a hardware layer including physical processing units, such as a CPU and a GPU, a middleware layer, which is interposed between the application layer and the hardware layer, and an OS. However, the system illustrated in  differs from the system illustrated in  in that a GPU code for driving the GPU is directly inserted into the application. For example, OpenCL\u00ae is a representative graphics standard for use in a system configuration as illustrated in .",{"@attributes":{"id":"p-0038","num":"0037"},"figref":"FIG. 3"},"Referring to , the application program is executed in step S. Herein, the expression \u201capplication is executed\u201d means that an execution file, which is generated by compiling the application, is run.","In step S, a CPU machine code of the execution file is executed. If the GPU is to be used while running the execution file, the code for the GPU is compiled at the source code level. In step S, a GPU machine code created as a compiling result is executed. After the completion of the GPU machine code execution, the CPU machine code is executed again in step S.","The GPU source code compiling process in step S, is illustrated in more detail in steps S-S, on right part of .","Specifically, once the GPU source code compile is initiated in step S, the GPU machine code is generated via lexical-syntax analysis in step S, preprocessing in step S, syntax analysis in step S, other analysis in step S, optimization in step S, code generation in step S, and GPU machine code creation in step S. This method is advantageous in that the corresponding GPU source code can be executed by the GPU, regardless of the GPU type (manufacturer). In this case, the common GPU source code is distributed to be compiled in the runtime and operate in the format of a certain GPU machine code.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":"FIG. 4"},"Referring to , the application includes codes that can be executed by the CPU and the GPU, simultaneously. In this case, the code referred to with \u201cmain\u201d is the code executed by CPU, and the code referred to with \u201cKernelSource\u201d is the code executed by GPU.","The code illustrated in  is compiled such that the CPU code part is converted into machine code. However, the GPU code part is inserted in to an execution file in the form of a character string or saved in an external source file without being compiled. As described above, the GPU source code is compiled and executed when the corresponding application program is executed.",{"@attributes":{"id":"p-0046","num":"0045"},"figref":"FIG. 5"},"Referring to , the execution file used in a system as illustrated in , in which the GPU code included in the application program is executed by the GPU in the program runtime, includes metadata such as a header (not shown), CPU machine code, and GPU source code.","As described above, as the role of the GPU is becoming more significant, there is a need for a method for expanding the use of the GPU more freely to overcome the restriction described above, wherein only the standardized API can be used. Accordingly, an aspect of the present invention is to provide an improved method for efficient GPU application use.","More specifically, a conventional technique, such as OpenCL\u00ae, has a drawback in that execution speed decreases significantly because a GPU source code is compiled in a program runtime. The compiling operation includes a plurality of intermediate steps and is complex, thereby causing significant problems in an embedded system lacking in computing power.","Further, there is a tradeoff in that the simplification of a process for compiling GPU machine code makes it difficult to generate an optimized GPU machine code, and the optimization of the GPU machine code increases the compiling operation complexity. Also, in a conventional method, such as OpenCL\u00ae, the GPU source code  is inserted into the data region of the execution file or exists in the form of an external script file, e.g., GPU source code , as illustrated in . The exposure of the GPU source to the outside causes potential security problems.","Accordingly, as aspect of the present invention is to provide a method and apparatus for efficiently utilizing a CPU and a GPU and to address the aforementioned problems of the prior art. That is, it is an aspect of the present invention to minimize a time delay caused by complex GPU compiling, to prevent the GPU source code from being exposed, and to provide GPU machine code that can be compiled, regardless of the type of GPU.","For this purpose, the present invention uses a code for GPU operation, which is compiled at an instruction level (or machine code level) rather than at a source code level. In the following description, the GPU source code compiled at instruction level is referred to as a GPU virtual instruction. The GPU virtual instruction is the virtual instruction, other than the machine code executed on the actual GPU hardware. The GPU virtual instruction is binary-translated to a GPU machine code in runtime to be executed. The GPU virtual instruction also can be executed on all the types of GPU hardware.","Because it is compiled into a virtual instruction, the GPU virtual instruction according to an embodiment of the present invention improves the execution speed in runtime and is robust in security.",{"@attributes":{"id":"p-0054","num":"0053"},"figref":"FIG. 6"},"As described above, in OpenGL\u00ae GPU source code is excluded when compiling the application. During a runtime of the binary image, the source code is compiled via lexical analysis, preprocessing, syntax analysis, and optimization; and GPU machine code, which is a result of the compiling, is then executed.","In accordance with an embodiment of the present invention, however, the GPU source code is compiled into a GPU virtual instruction at an instruction level. The GPU virtual instruction is then translated into a GPU machine code to be executed during a runtime of the execution file.","Unlike the conventional method in which the compiling process is performed from the GPU source code at the time when the GPU source code is executed, a method according to an embodiment of the present invention simplifies the procedure by translating the GPU virtual command, which has been already compiled and translated into a GPU machine code.",{"@attributes":{"id":"p-0058","num":"0057"},"figref":"FIG. 7"},"Referring to , the heterogeneous computing system includes an application , a compiler , and a hybrid virtualization block . The application  operates on the application layer and includes both CPU source code and GPU source code. For example, such an application program has been described above with reference to .","The compiler  compiles the CPU source code and GPU source code included in the application  into a machine code. Here, the compiler  compiles the CPU source code into a CPU machine code and compiles the GPU source code into a GPU virtual instruction. Accordingly, the compiler  generates an execution file including the CPU machine instruction and GPU virtual instruction. In the following description, the execution file generated as above is referred to as \u201ca hybrid binary image\u201d. A hybrid execution file is described in more detail below with reference to .","The hybrid virtualization block  is interposed between the application layer and the hardware layer to detect a GPU virtual command during the runtime and translate, when the GPU virtual command is detected, the GPU virtual instruction into GPU machine code. Further, the hybrid virtualization block  coordinates the application execution process.","The system illustrated in  includes two different OSs  for controlling the overall operations of the system. It should be noted, however, that the number of OSs is not limited to two.",{"@attributes":{"id":"p-0063","num":"0062"},"figref":"FIG. 8"},"Referring to , the hybrid execution file includes CPU machine codes and a virtual section  including GPU virtual instructions. Here, the GPU virtual section includes a virtual section header , a CPU machine code section , and GPU virtual instruction .","The virtual section header  includes a watermark for identifying the virtual section and execution information such as CPU and GPU execution times.","The CPU machine code section  includes the CPU machine codes to be executed when the CPU is to execute, e.g., because the system has no GPU or the GPU is busy processing another task.","The GPU virtual instruction region  includes instructions to be executed by the GPU. The GPU virtual instruction region  includes a virtual instruction header  and virtual instruction code . The virtual instruction header  includes information on addresses of a memory for input and output of the to execute a GPU operation and a number of recommended Processing Elements (PEs). The GPU virtual instruction code includes the virtualized information to be executed by the GPU. That is, the GPU virtual instruction code is the code to be translated into a GPU machine code in the runtime.",{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 9"},"Referring to , an application including a CPU and a GPU source codes is generated in step S. When a request for compiling the application is detected, the compiler  separately compiles the CPU source code and GPU source code in step S and S, respectively.","More specifically, when a CPU source code is detected, the compiler  compiles the CPU source code in step S and generates a CPU machine code that is executable by the CPU in step S. Further, when a GPU code is detected, the compiler  compiles the GPU code in step S and generates a GPU virtual instruction that is executable by a virtual GPU in step S. For example, the GPU virtual instruction is structured as illustrated in .","The compiler  links the created CPU machine code to the GPU virtual instruction in step S and generates a hybrid execution file (binary image) in step S.","As described above, the hybrid execution file includes CPU machine codes and a virtual section. When the hybrid execution file is executed, the CPU section and the GPU section are executed separately according to the coordination of the virtualization layer, as will be described below with reference to .",{"@attributes":{"id":"p-0073","num":"0072"},"figref":"FIG. 10"},"When the system is organized hierarchically,  assumes that a normal OS is placed on a virtualization layer proposed by an embodiment of the present invention. Further, the hybrid execution file can be executed without the virtualization layer proposed in the present invention as will be described later with reference to .","Referring to , an OS utilizes a system as if only the OS itself is running. First, because the hybrid execution file is normally executed through the OS, the OS is executed first in step S. In step S, the OS executes the hybrid execution file to which the GPU virtual instruction is inserted. If the virtual section is executed during the execution of the hybrid execution file, an exception occurs in the CPU in step S. In step S, the control to the system is handed over from the OS to the hybrid virtualization block  on the virtualization layer.","The hybrid virtualization block  checks a watermark of the virtual section to identify the virtual section in step S. If no virtual section is identified, the hybrid virtualization block  performs a conventional exception handling in step S and hands over the system control to the OS in step S.","However, if a virtual section is identified in step S, the hybrid virtualization block  translates the GPU virtual instruction to a GPU machine code in step S. In step S, the hybrid virtualization block  inserts the translated GPU machine code into the memory (or file) execution region, as illustrated in . In step S, the hybrid virtualization block  hands over the control to the OS. In step S, the OS executes the corresponding GPU machine code using the GPU.","If no exception occurs in step S, the OS determines whether a GPU branch is detected in step S. If a GPU branch is detected, the OS executes the GPU machine code in step S and, otherwise, the OS executes a CPU machine code in step S. Here, the GPU machine code executed through steps S and S is the GPU machine code translated in step S and existing in the memory (or file) that can be executed without an additional translation step.",{"@attributes":{"id":"p-0079","num":"0078"},"figref":"FIG. 12"},"Hereinabove, a description has been provided wherein the hybrid virtualization block  of the virtualization layer runs the hybrid execution file. Hereinbelow, a description will be made when an OS runs the hybrid execution file, without introduction of additional virtualization layer, with reference to . Because the compiling process for generating the GPU virtual instruction is identical, regardless of whether the virtualization layer is introduced or not, a detailed description thereon is omitted herein.","Once the hybrid execution file is executed in step S, the OS determines if an exception occurs in the CPU in step S. If the exception occurs, the OS checks the watermark in the virtual section to identify the virtual section in step S. If no virtual section is identified, the OS performs the conventional exception handling in step S and executes the CPU machine code in step S).","If a virtual section is identified in step S, the OS translates the GPU virtual instruction to a GPU machine code in step S, and inserts the translated GPU machine code into the memory (or file) execution region in step S, as illustrated in .","In step S, the OS executes the corresponding machine code using the GPU.","It no exception occurs in step S, the OS determines whether a GPU branch is detected in step S. If a GPU branch is detected, the OS executes the GPU machine code in step S and, otherwise, the OS executes the CPU machine code in step S. Here, the GPU machine code executed through steps S and S is the GPU machine code translated in step S and existing in the memory (or file) that can be executed without an additional translation step.","As described above, in accordance with an embodiment of the present invention, a GPU translates the GPU virtual instruction into the GPU machine code using a hybrid virtualization block located on a virtualization layer.  illustrates a system according to this embodiment of the present invention.","Referring to , a hybrid virtualization block is included on a virtualization layer , which is arranged below the OS between the application layer and the hardware layer. Using the hybrid virtualization block, the OS recognizes the currently executed hybrid execution file as a conventional execution file. That is, according to an embodiment of the present invention, the GPU virtual instruction can be executed without modification of higher OS.","As described above, according to another embodiment of the present invention, an OS translates a GPU virtual instruction into GPU machine code during a runtime.  illustrate a system according to this embodiment of the present invention.","Referring to , a hybrid virtualization block for executing the hybrid execution file is incorporated in the OS. For example, a first OS, as illustrated in , can be Windows OS\u00ae by Microsoft\u00ae, and the second OS, as illustrated in , can be OS X\u00ae by Apple\u00ae. According to this embodiment of the present invention, when an exception occurs, the OS translates GPU virtual instruction into GPU machine code.","As described above, an application execution method and apparatus in accordance with the embodiments of the present invention is capable of efficiently utilizing a CPU and a GPU simultaneously and improving GPU execution efficiency by solving problems of a conventional real time compiling method with a GPU.","The application execution method and apparatus of the present invention compiles GPU source code included in a source code of an application in a GPU virtual instruction and translates the compiled GPU virtual instruction to a GPU machine code, whereby it is possible to improve the utilization efficiency of the CPU and the GPU simultaneously and the GPU running efficiency by compensating for the problem of the real time compiling method for use of GPU.","Also, the application execution method and apparatus of the present invention is capable of preventing the GPU source code from exposure to the outside, resulting in improved security. Further, the application execution method and apparatus of the present invention introduces GPU virtual instructions, which are transparent to hardware, i.e., to be implemented independently without consideration of the GPU hardware manufacturer.","Although certain embodiments of the present invention have been described in detail hereinabove, it should be clearly understood that many variations and\/or modifications of the basic inventive concepts herein taught which may appear to those skilled in the present art will still fall within the spirit and scope of the present invention, as defined in the appended claims and any equivalents thereof."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The above and other aspects, advantages, and salient features of certain embodiments of the present invention will become apparent to those skilled in the art from the following detailed description, when taken in conjunction with the accompanying drawings, in which:",{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":"FIG. 15"}]},"DETDESC":[{},{}]}
