---
title: High fidelity data compression for acoustic arrays
abstract: Techniques include determining coefficients of a complex auto regression (AR) model to fit a complex average spectrum at a base frequency resolution of a set of one or more measured acoustic beams during a time block. Residuals derived by filtering actual data through an inverse of the AR model are determined at frequencies below a first threshold frequency. A quantized spectrum of the residuals is determined at the base frequency resolution. Magnitude, phase, and frequency bin at the base frequency resolution are determined for each peak of a set of one or more narrowband peaks above a second threshold frequency for the set of one or more measured acoustic beams. A message is sent, which indicates without loss the coefficients of the AR model, the quantized spectrum of the residuals, and the frequency bin, magnitude and phase for each peak of the set of one or more narrowband peaks.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08254210&OS=08254210&RS=08254210
owner: The Johns Hopkins University
number: 08254210
owner_city: Baltimore
owner_country: US
publication_date: 20091211
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["STATEMENT OF GOVERNMENTAL INTEREST","CROSS-REFERENCE TO RELATED APPLICATIONS","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION"],"p":["This invention was made with U.S. Government support under the Space and Naval Warfare Systems Command under contract number N0002403-D-6606. The U.S. Government has certain rights in the invention.","This application is related to prior filed Provisional Appln. 60\/539,657 filed Jan. 28, 2004; Provisional Appln. 60\/656,442 filed Feb. 24, 2005; and, Provisional Appln. 60\/786,239 filed Mar. 27, 2006, the entire contents of each of which are hereby incorporated by reference as if fully set forth herein.","1. Field of the Invention","The present invention relates to high fidelity acoustic data processing or compression.","2. Description of the Related Art","Directional acoustic data is useful for a wide range of applications from surveying underground structures to tracking bodies traveling underwater. This data usually comprises acoustic pressure measurements sampled to resolve acoustic frequencies between a few cycles per second (Hertz, Hz) to a few kiloHz (kHz, 1 kHz=10Hz) along each of multiple directions of arrival, called beams. Multiple beams are detectable by one dimensional (1D), two dimensional (2D) and three dimensional (3D) arrays of acoustic sensors, called acoustic arrays herein. Sampling rates approach counts of pressure samples per second at twice the highest frequency for each beam. Since a pressure measurement usually involves about 8 binary digits (bits) of data for each of tens to hundreds of beams, data rates can exceed 100 megabits per second (Mbps, 1 Mbps=10bits per second).","When the directional acoustic data is collected at remote sites, the data must be communicated to a processing station over a communications channel, such as a satellite communications channel, that might have a very limited bandwidth compared to the bandwidth of several hundred MegaHertz (MHz, 1 MHz=10Hz) needed to carry such high data rates, Therefore, it is desirable to represent the important features of the directional acoustic data in less than the full data rate, a process called compression. An acoustic compression technique well known in the art that preserves the human-perceptible nuances of speech and music is the Moving Picture Experts Group (MPEG) Audio Layer III (MP3) format for audio data. MP3 can achieve a compression ratio (ratio of uncompressed data rate to compressed data rate) of about 7:1 or 8:1. For some applications, however, including some applications for directional acoustic data, the MP3 compression ratio is insufficient; and compression ratios of 16:1 to 24:1 and greater are desirable. However, the compressed data should preserve important features for acoustically detecting or characterizing objects such as subsurface structures and underwater bodies.","Techniques are provided for high fidelity processing or data compression for acoustic arrays.","In a first set of embodiments, a method includes determining coefficients of a complex auto regression (AR) model to fit a complex average spectrum at a base frequency resolution of a set of one or more measured acoustic beams during a time block. Residuals derived by filtering actual data through an inverse of the AR model are determined at frequencies below a first threshold frequency. A quantized spectrum of the residuals is determined at the base frequency resolution. Magnitude, phase, and frequency bin at the base frequency resolution are determined for each peak of a set of one or more narrowband peaks above a second threshold frequency for the set of one or more measured acoustic beams. A message is sent, which indicates without loss the quantized coefficients of the AR model, the quantized spectrum of the residuals, and the frequency bin, quantized magnitude and quantized phase for each peak of the set of one or more narrowband peaks.","In a second set of embodiments, a method includes receiving a message that indicates without loss quantized coefficients of an auto regression (AR) model, a quantized spectrum of residuals and a set of one or more narrowband peaks. The AR model fits a complex average spectrum at a base frequency resolution of one or more measured acoustic beams during a time block. The residuals indicate the difference between the model and the measured acoustic beams. Each peak of the set of one or more narrowband peaks is indicated by a frequency bin and magnitude and phase. A composite complex spectrum is determined based on the coefficients, the quantized spectrum of residuals, and, for each peak of the set of one or more narrowband peaks, frequency bin and magnitude and phase. An approximation of the average of the one or more measured acoustic beams during the time block is generated by determining an inverse Fourier transform of the composite complex spectrum.","In another set of embodiments, a method includes receiving data that indicates multiple spectra derived from one or more measured acoustic beams during a time block. A greatest magnitude and corresponding phase among the plurality of spectra is determined for a frequency bin encompassed by each bandwidth of the plurality of spectra. A combined spectrum is determined, which includes in the frequency bin of the combined spectrum an amplitude based on the greatest magnitude and a phase based only on the corresponding phase.","In another set of embodiments, a method includes determining coefficients of a complex auto regression (AR) model to fit a complex average spectrum at a base frequency resolution of a set of one or more measured acoustic beams during a time block. Residuals between actual data and the AR model are determined at frequencies below a first threshold frequency. An average spectrum of the residuals at the base frequency resolution is determined. A reduced noise spectrum is determined based on the average spectrum of the residuals multiplied by a first weight and the model fit multiplied by a second weight. The first weight is greater than the second weight.","In various other embodiments, an apparatus or logic encoded in tangible media or computer-readable media is configured to cause an apparatus to perform one or more steps of the above methods.","Still other aspects, features, and advantages of the invention are readily apparent from the following detailed description, simply by illustrating a number of particular embodiments and implementations, including the best mode contemplated for carrying out the invention. The invention is also capable of other and different embodiments, and its several details can be modified in various obvious respects, all without departing from the spirit and scope of the invention. Accordingly, the drawings and description are to be regarded as illustrative in nature, and not as restrictive.","Techniques are described for high fidelity compression of acoustic array data. In the following description, for the purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the present invention. It will be apparent, however, to one skilled in the art that the present invention may be practiced without these specific details. In other instances, well-known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention.","Some embodiments of the invention are described below in the context of remote acoustic arrays for passive detection and characterization of underwater bodies based on signals received on acoustic beams. However, the invention is not limited to this context. In other embodiments acoustic data representing acoustic beams or individual or grouped sensors is compressed for acoustic arrays using seismic, low frequency or ultrasound frequencies to actively or passively detect or characterize moving or stationary objects that are underwater, underground, behind an opaque surface or below skin, e.g., during mineral prospecting, or biological prospecting, or search and rescue, or navigation, or medical procedures, among other endeavors.","1. Overview",{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 1","b":["100","100","114","112","116","116","120","130","132","190","100"]},"The apparatus  interprets the phased acoustic arrivals at displaced acoustic sensors  as acoustic pressure traces on each of one or more acoustic beams  for a known or assumed speed of sound in the medium. Each acoustic beam (also called simply a beam herein) is associated with sounds propagating to the array in a particular range of directions. The greater the number and dimensional extent of the acoustic sensors, the finer the beam angular resolution and the smaller the range of directions represented by a single beam, and the more different beams can be resolved. Sounds emanating or reflected from a body, e.g. subsurface structure , affect the acoustic signature on one or more beams .","The apparatus  is used to further process the data, e.g., with higher powered processors or in coordination with data from other remote acoustic arrays, not shown, to characterize the position or type, or both, of subsurface structure .","It is assumed for purposes of illustration that the communication link  does not have the bandwidth to carry all the data associated with acoustic beams  in real time, e.g., as fast as the data is collected. According to the illustrated embodiment, the compression module  in apparatus  extracts and preserves the most useful portion of the data associated with acoustic beams, compresses that information to fit in data packets that can be transmitted in real time (e.g., as fast as the data represented is collected), and sends those data packets for transmission over the communications link . According to the illustrated embodiment, the decompression module  in apparatus  decodes the received data packets and reconstructs the acoustic time series with the preserved features, also in real time.","In one embodiment, called the Passive Sonar Compression Algorithm (PSCA), signal analysis and synthesis is used to transmit the beam data in real time. PSCA analyzes the sonar signal, using the frequency spectra of the signal, and produces a small set of prioritized narrowband and broadband weights. The compressed information is transmitted over a limited bandwidth communication channel, and the transmitted weights are used to reconstruct the signal. The signal can then be processed in the same manner as if it were the original signal, at least for the features preserved by the analysis.",{"@attributes":{"id":"p-0040","num":"0039"},"figref":"FIG. 2","b":["202","204","210","130"]},"A complex frequency spectrum indicates the magnitude and phase associated with each frequency, which can be used as a weighting factor and time argument, respectively, of a sine or cosine function of the same frequency. The complex spectrum spans multiple frequencies and can be used to reconstruct an arbitrary signal over a limited time to an arbitrary degree of accuracy. The complex spectrum can be determined from a time series using the Fourier Transform, well know in the art. An efficient method to determine a discrete complex spectrum at a finite number of frequencies is determined for a time series of values at discrete times using, for example, the Fast Fourier Transform (FFT), also well known in the art.","The frequency resolution of the spectrum (smallest frequency change over which changes of amplitude and phase are detectable) is no finer than the reciprocal of the temporal duration of the time series. Therefore a block of time to handle together (called a time block of duration Thereinafter) is determined to be long enough to resolve the finest spectral features of interest for a particular purpose, called the finest frequency resolution, and represented by symbol \u0394F. For purposes of illustration it is assumed that a time block of T=8 seconds (s) is sufficient to resolve features of interest, thus \u0394F=1\/T=0.125 Hz. Many features of interest are broader than the finest features of interest and can be observed in spectra with coarser frequency resolutions, e.g., at 0.25 Hz, 0.5 Hz and 1 Hz. A discrete spectrum includes a magnitude and phase (or corresponding complex values made up of a real part and an orthogonal imaginary part) for each frequency bin of width equal to the frequency resolution.",{"@attributes":{"id":"p-0043","num":"0042"},"figref":["FIG. 3","FIG. 3"],"b":["302","304","310"]},"According to some embodiments, a base frequency resolution is selected that is able to indicate the presence of features of interest but is somewhat coarser than the finest spectral features of interest. It is found that frequency bins that are twice to four times the frequency width of the finest frequency feature can be used to indicate the presence of such features. It is assumed for purposes of illustration that the finest features of interest (e.g., narrowband peaks) are fully described by spectra with a 0.25 Hz resolution; so, a base resolution of 1 Hz is selected for these example embodiments. By using a coarser base resolution, the amount of data used to represent the whole spectrum is greatly reduced, and the few occurrences of the fine features are handled separately. Frequency analysis at finer resolutions than the base frequency resolution is possible by coherently integrating over a longer duration of time, e.g., over multiple concatenated blocks of data with size given by the inverse of the base frequency resolution.","2. Compression Methods",{"@attributes":{"id":"p-0045","num":"0044"},"figref":["FIG. 4A","FIG. 4A","FIG. 6A","FIG. 7A","FIG. 7B","FIG. 7C","FIG. 9"],"b":"400"},"In step , data is retrieved which indicates parameters that describe certain properties of the method, such as the base frequency resolution, the time block duration (which defines the finest frequency resolution), the communication link data rate (which determines how much the data must be compressed) and other properties described in more detail below. Any method may be used to retrieve this data, including receiving the data passively. For example, the data may be read from a read only memory (ROM) or other non-volatile storage in the device that implements the method. For example, in various embodiments, the data is included as a default value in software instructions, is received as manual input from a system administrator on the local or a remote node, is retrieved from a local file or database, or is sent from a different node on a communications network, either in response to a query or unsolicited, or the data is received using some combination of these methods.","In various embodiments, other parameters include: identifying an algorithm to use to derive autoregressive (AR) model coefficients; identifying an algorithm to losslessly encode arrays of integers; frequency bands on multiple beams that are correlated and need not be reported separately; the number of beams to combine a priori that need not be separated by the decompression module; scaling factors to convert floating point numbers to integers (quantization); a splitting frequency between a lower band and an upper band treated differently; the percent of the data packet to devote to describing low band features; the maximum number of narrowband peaks to describe features in the upper band; and, a clipping magnitude to condition a spectrum for AR modeling, among others.","In some embodiments, the cutoff between the lower and upper bands is dependent on signal density knowledge and transmission bandwidth considerations. With respect to signal density, for underwater applications the majority of signals are found in the lower frequencies due to larger transmission losses associated with higher frequency signals. A high quality method (residual encoding) is used to save the lower frequency data, while a highly compressive method (narrowband peak selection) is used to retain signals that appear in the upper frequencies. With respect to communication bandwidth considerations, lower band coding uses up communications link bandwidth in a manner that is directly proportional to the splitting frequency. If a large communications bandwidth exists, then the splitting frequency can be pushed higher to save a higher percentage of data with lower band coding. For lower communications link bandwidths, the splitting frequency can be set to lower values.","In some embodiments, various parameters are derived automatically from other parameters or the data itself. For example, spectra from various beams are correlated in various frequency bins to determine the frequency bins of correlated spectra that can be combined during compression. The splitting frequency is determined based on the number of narrowband peaks and accuracy of the wideband modeling achieved in past performance. The uses of these parameters are described in more detail with reference to the following steps described in this and subsequent flow diagrams.","In step , beam time series (BTS) data is received for one or more beams. Converting acoustic sensor data to beam time series data is well known in the art and any method may be used that is known when embodiments are implemented. In some embodiments, step  includes determining whether to initialize or re-initialize one or more parameters of the algorithms based on the data being received, e.g. due to a gap in the data or a change in one or more signal levels.","In step , the BTS for each beam is sampled in a single time block. In preparation for computing a complex spectrum, the BTS time block is sampled using a windowing function (e.g., with a Hamming window or Hanning window or any other windowing function well known in the art) to taper the beginning and end of the time block, which reduces leakage of energy into different frequency bins. The complex spectrum is then computed for several different frequency resolutions (layers) including the base resolution and one or more finer resolutions for each beam. The amplitudes are corrected for the known effects of the windowing function.","In step  multiple beams are combined a priori that will not be recovered on decompression. This provides an immediate M:1 compression ratio, where M is the number of beams combined a priori. The step involves averaging complex spectra below the splitting frequency and selecting the largest narrowband peaks above the splitting frequency, as described in more detail below with reference to . The selected narrowband peaks are combined at the base frequency resolution using coherent ORing developed for this purpose, and also described in more detail below with reference to . In some embodiments, M=1 and step  is omitted. As used here, remaining beams refer to one or more beams that remain after the a priori M:1 combination of beams performed in step .","In step , a wideband model of the complex spectrum at the base resolution is determined for each beam. The wideband model includes normalization parameters (e.g., bias and standard deviation of the complex spectrum), an autoregressive (AR) model to provide the impulse response, and residuals that combine with the impulse response to regenerate the time series below the splitting frequency. While autoregressive models are well known, they have not before been used with residuals to compress a portion of a spectrum below a splitting frequency separately from treatment above the splitting frequency. AR modeling is described in more detail below with reference to .","In step  the model coefficients are converted to integers (quantized) and the residuals are combined for correlated frequency bands, if any, in multiple beams. The combined residuals below the splitting frequency (lower frequency band) are determined based on their discrete cosine transform (DCT) to the frequency domain. The retained transformed residuals are also quantized in step , and described in more detail below with reference to .","In step , the N greatest narrowband peaks above the splitting frequency (i.e., in the upper frequency band) for all remaining beams (after a priori combination) are determined and converted to the base frequency resolution and associated bins using coherent ORing, as described below with reference to . The frequency bin number (indicating both the beam and frequency bin) amplitude and phase are quantized to integers for each peak.","In step , the quantized model coefficients, normalization parameters, residuals and peaks are losslessly encoded in a data packet of limited size. The data packet size can be the size limit or smaller. The size is limited by the product of the communications bandwidth (B) and the time block (T) and the communications protocol overhead for real time applications. For example, for B=1 Mbps and TB=8 s, the size limit is about 8 Megabits (Mb, 1 Mb=10bits) or 1 Megabyte (MB, 1 MB =10bytes, 1 byte=8 bits) less any communications protocol overhead.","Any lossless encoding may be used in step . In an example embodiment, Huffman encoding, well known in the art is used (see for example, Huffman, D. A. [1952]. \u201cA Method for the Construction of Minimum Redundancy Codes.\u201d Proc. IRE, vol. 40, no. 10, pp. 1098-1101, the entire contents of which are hereby incorporated by reference except for terminology that is inconsistent with that used herein). In an example embodiment, the quantized residual DCT values are coded with the Huffman encoder that optimizes lengths of the code words that represent symbols based on the probability of the symbols occurring. The narrowband peak indices are coded with a difference encoder. The AR model coefficients from beam to beam are coded with a difference encoder.","In step , the limited length data packet is sent over the communications link within one time block. The constraint for real time communication of acoustic array data is important for ongoing monitoring embodiments. In other embodiments of short term measurements, packets with a larger size limit may be used, and the packet can be sent in a time duration in excess of the time block. The data packet may be sent as one message packet over the communications link or as multiple message packets, as dictated by the communications link protocol. The communications protocol overhead data reduces the size of the data packet available for compressed acoustic data. For example, for communications protocols that involve a 10% overhead (header size to payload size), the size limit is reduced by 10%, e.g., to about 7.2 Mb.","Control passes back to step  and following to process and send the next time block of BTS data for all beams. In some embodiments, the execution time for steps  through  is excluded from the time to transmit the compressed data from one time block. If it is assumed for example that steps  through  can be accomplished within ten minutes, then the communication of compressed data is delayed by 10 minutes, but sufficient parallelization can keep up with the data sampling rate and does not fall father behind. In other embodiments, the processing time is also limited and further limits the time to send the data packet. For example, if the data packet is to be sent within the 8 seconds, and if the processing time is 2 seconds, then the size limit is the communications bandwidth (B) times the difference, e.g. 6 seconds. This may require extremely powerful and expensive parallel processors in the remote processor\/transmitter apparatus 116 to accomplish the processing within 2 seconds.","3. Structural Elements",{"@attributes":{"id":"p-0060","num":"0059"},"figref":["FIG. 4B","FIG. 1","FIG. 10","FIG. 11"],"b":["420","420","142","420","480","488","488","488","420"],"i":["a ","b"]},"Data shared between the compression module  and a decompression module, e.g., decompression module , are held in shared data data structure , This data is received or exchanged in a different communications link or time than the use of communications link  for transmitting limited sized packets . The data in shared data structure  includes all parameters used for the various algorithms implemented in the other modules, such as described above with reference to step .","The BTS streams are carried by a bus to a preprocessing module  where data are buffered in a storage component until a blocksize is reached, which is adequate to hold data from all beams for the time block. Based on the data, a determination is made whether to initialize or re-initialize one or more parameters of the algorithms. The complex spectrum is computed for multiple frequency resolutions (layers) including the base resolution. In some embodiments, M beams are combined a priori in beam combination module .","Output from module  is input to module  where AR modeling and model coefficient quantizing is performed. The wideband output from the AR modeling module is input to a residual coding module  and a frequency band splitting module . The frequency band splitting module sends the upper frequency band data to the peak selection module  and the lower frequency band data to the residual coding module . The residual coding module  uses the AR model coefficients to determine and quantize the residual DCT spectrum for the lower frequency band.","The peak selection module  determines and quantizes the base resolution frequency bin, amplitude and phase of the N largest peaks among all beams based on the multiple spectra layers and the wideband model.","The quantized (e.g., integer) output from the AR modeling module , residual coding module , and peak selection module  are input to the packet encoding module  that losslessly encodes the quantized values into a limited sized packet . The processor\/transmitter apparatus  then transmits the limited sized packet  over the communications link .","In some embodiments, an application programming interface (API)  is used to invoke compression module  from other modules or applications, exchange one or more values of the shared data, pass the beam time series streams  into the module, and return the limited sized packets .","Although particular data structure and sub-module components are shown in , and subsequent diagram B, as integral blocks in a particular arrangement for purposes of illustration, in other embodiments, one or more data structures or sub-modules or portions thereof may be distributed across multiple devices or chip sets to be invoked in series or parallel, or one or more components are omitted or additional components added, or the module is changed in some combination of ways.",{"@attributes":{"id":"p-0068","num":"0067"},"figref":"FIG. 5A","b":["500","500","502","510","520","530","540"]},"Although fields are depicted in data packet  as integral blocks in a particular order for purposes of illustration, in other embodiments one or more fields or portions thereof may be combined or arranged in a different order.","The header field  holds data that indicates any change to the shared data and includes an initialization flag field . The initialization flag field  indicates when the parameters of an algorithm or properties of the lossless encoding are to be initialized or re-initialized. For example, some encoding works by sending differences from previous or standard values, and on occasion the initial or standard value has to be reset. The data in the initialization flag indicates which parameters or values are being reset. For example, the initialization flag is simply used to force a hard reset in the case that buffers and parameters are desired to be reset.","In various embodiments header field  also includes one or more fields indicating one or more of the following: 1) Algorithm version flag (indicates which version of the compression algorithm to use); 2) Length of data packet value; 3) Quality index value (which offers a measure of expected quality of the compressed data); 4) Process type value (to denote which set of parameters to load based on the type of array and the mode of operation); 5) Combination factor value (indicates factor of beam combination to use); 6) Force reset flag (as indicated above); 7) Channels (i.e. beams) to process flag (indicates which beams are to be processed, either the full set of beams or a partial set of beams); 8) Transmission data rate ID (to indicate the band of transmission data rates that algorithm is operating in currently).","The encoded normalization field  holds losslessly encoded data that indicates bias and standard deviation values determined during normalization for each remaining beam. The encoded AR coefficients field  holds losslessly encoded data that indicates AR model coefficients that depict the impulse response of each remaining beam.","The encoded residuals field  includes a beam identifier (ID) field , beam ID field and others indicated by ellipsis , collectively referenced hereinafter as beam ID field . The encoded residuals field  includes a residuals field , residuals field and others indicated by ellipsis , collectively referenced hereinafter as residuals field . The beam ID field holds data that indicates a remaining beam for which residuals are included. The residuals field  holds data that losslessly indicates residuals in one or more frequency bands where the residuals are expected to be different from the residuals in the same frequency bands on other beams. The correlated frequency bands where residuals are expected to be similar, are predetermined and stored in the shared data structure for both the compression module and decompression module. In effect, this operation removes some redundancy.","The encoded peaks field includes a beam-frequency bin index field , amplitude field  and phase field  for each of up to N narrowband peaks, as indicated by ellipsis . The beam-frequency bin index field  holds losslessly encoded data that indicates which base resolution frequency bin includes a narrowband peak. The corresponding amplitude field  holds losslessy encoded data that indicates the amplitude for the bin (to be added to the modeled noise) and the phase field  holds losslessly encoded data that indicates the phase of the peak. Any method may be used to indicate the amplitude and phase, including real and complex parts of a complex number representing sine and cosine functions at the frequency.",{"@attributes":{"id":"p-0075","num":"0074"},"figref":"FIG. 5B","b":["550","550","552","554","560","570","580"]},"The time block field  holds data that indicates the duration of each time block (e.g., 8 s). The beams to be combined block  holds data that indicates the number M of beams to be combined a priori.","The frequency parameters field  includes a max frequency field , a split frequency field , a base resolution field , a target field , and for each beam with expected correlated portions of the complex spectra a frequency band field  and a correlated beams field , for one or more additional frequency bands indicated by ellipsis .","The max frequency field  holds data that indicates the maximum frequency of a processing range of interest for wideband applications, e.g., 1000 Hz and below for some underwater applications. The split frequency field  holds data that indicates the splitting frequency to divide the upper band from the lower band for separate processing, e.g., 100 Hz for some applications. In some embodiments the max frequency and the splitting frequency are the same, and field  is omitted. The base resolution field  holds data that indicates the base frequency resolution, e.g., 1 Hz. The targets field  holds data that indicates the frequency ranges where lower band features are of special interest, if any, for deciding which residual DCT amplitudes to quantize.","The frequency band field  indicates a frequency range in the lower band where correlation among adjacent beams is expected to be high and redundant data can be excluded. The correlated beams field  holds data that indicates beam IDs for beams that are highly correlated in the associated band indicated in field .","The data packet parameters field  includes a communications link rate field , a residuals space field  and a number of peaks field . The communications link rate field  holds data that indicates the available bandwidth over the communications link, excluding communications protocol overhead, this information is used to determine the size limit for the limited sized data packets, as described above. The residuals space field  holds data that indicates how much of the limited sized packet is to be used for the residuals. In some embodiments, this information is expressed as a percentage, e.g., 70%. The number of peaks field  indicates the number N of peaks, each with corresponding bin index, amplitude and phase, which can be fit in the limited sized data packet. In some embodiments, this information is expressed as a percentage of the size limit, e.g., 20%.","The model parameters field  includes a number of AR coefficients field , a clipping threshold field , and a DCT scaling field . The number of AR coefficients field , holds data that indicates the number of AR coefficient that are allowed to model each beam spectrum, i.e., order of the AR model, and still fit in the fixed size data packet. The clipping threshold field  holds data that indicates a clipping threshold used after normalization to condition the beam spectrum for AR modeling, as described in more detail below. The DCT scaling field  holds data that indicates how to scale the DCT spectral values of the residuals to quantize them before encoding. In some embodiments, other scaling factors are included in the model parameters field  or other fields of the shared data data structure .","Although fields are depicted in shared data data structure  as integral blocks of a single data structure in a particular order for purposes of illustration, in other embodiments one or more fields or portions thereof may be combined or arranged in a different order in one or more data structures or databases on one or more devices, or one or more fields are omitted, or one or more fields are added, or the data structure is changed in some combination of ways.","4. Decompression Methods",{"@attributes":{"id":"p-0083","num":"0082"},"figref":["FIG. 6A","FIG. 10","FIG. 11"],"b":["600","144"]},"In step , parameter settings are retrieved, as described above for step  in the compression module . In step , a limited sized data packet is received with encoded model coefficients, normalization values, residuals and peaks. In step , the encoded values are extracted from the data packet. In step , it is determined if the data packet indicates initialization or re-initialization of algorithm or encoding parameters. If so, then in step  buffers and other affected settings are initialized or re-initialized.","In step , the encoded values are decoded by applying the inverse encoding procedures. In step  a complex spectrum is generated for each beam based on the normalization, AR model and residuals as described in more detail below with reference to . In step  the narrowband peaks are added to the complex spectrum within the upper frequency band.","In step , an inverse Fourier transform (e.g., an inverse fast Fourier transform, IFFT) is applied to the complex spectrum to generate a beam time series (BTS) for each remaining beam.","In step , the BTS is appended to the BTS of corresponding remaining beams at previous time blocks. Control then passes to step  to receive the next limited sized data packet.","For real time output, it is desirable that each set of BTS time series is output every time block. It is acceptable for the process of steps  through  to take longer than that for the first time block as long as successive time blocks are output within the time block. This can be ensured with sufficient parallel processing capability. If it is assumed for example that steps  through  can be accomplished within two minutes, then the communication of BTS is delayed by these additional two minutes, but keeps up with the data sampling rate and does not fall father behind. Combining with execution time for compression, a BTS for each remaining beam is output every time block 12 minutes after the time block is received at the compression module and still satisfies the real time constraint.",{"@attributes":{"id":"p-0089","num":"0088"},"figref":["FIG. 6B","FIG. 1","FIG. 10","FIG. 11"],"b":["620","620","144","620","488","488","680","620","620"],"i":["a ","b"]},"Data shared between the compression module  and the decompression module,  are held in shared data data structure . This data is received or exchanged in a different communications link or time than the use of communications link  for transmitting limited sized packets . The data in shared data data structure  includes all parameters used for the various algorithms implemented in the other modules, such as described above with reference to step  and step .","The limited sized data packets  are carried by a bus to a preprocessing and disassembling module  where parameters are initialized and data is buffered until a full data packet is received. The output is passed to the packet decoding module  where the lossless encoding performed in the compression stage is decoded. The narrowband peak information is passed to a peak insertion module ; and the AR model coefficients, normalization data, and residual DCT amplitudes are passed to a wideband modeling module . The reconstruct spectrum module  reconstructs the complex spectra from the wideband spectra and the narrowband peaks for the remaining beams. The conversion time series module  generates a time series for each remaining beam, e.g., by applying an IFFT to the reconstructed complex spectra from module .","In some embodiments, an application programming interface (API)  is used to invoke decompression module  from other modules or applications, exchange one or more values of the shared data, pass the limited sized packets  into the module, and return the reconstructed beam time series streams .","These methods keep the general data shape using autoregressive (AR) modeling. A hybrid approach breaks data into a lower and an upper frequency band based on the following observations: most of the signals are in the lower band; and most of the data in the upper band is noise. In the lower band the entire spectrum is kept by coding the AR model residuals. High quality is maintained over the entire lower band at the cost of less compression. In the upper band high amplitude narrowband signals are kept by peak-picking. The AR model is able to model the rest of the information (non-narrowband signals). These methods maintain narrowband signals over a wide frequency band with low bits\/Hz ratio. Lossless encoding of quantized information from both bands attains a higher compression rate. Contrast enhancement and noise reduction are also invoked to improve perceptual performance, as described in more detail below.","5. Detailed Methods",{"@attributes":{"id":"p-0094","num":"0093"},"figref":["FIG. 7A","FIG. 4"],"b":["407","701","703"]},"In step  coherent ORing is performed on all peaks in each base resolution frequency bin above a particular frequency, such as the splitting frequency, as described in more detail below. In step  the complex spectra below the splitting frequency is joined to the coherently ORed peaks above the splitting frequency. Both stages return normalized data and phase angles. They are combined with an M-to-1 averaged noise estimate via a standard averaging operation. The result is beam frequency data that has been reduced in the number of beams by M-to-1. In step  an inverse Fourier transform (such as an IFFT) is performed to produce a single time series that represents all M combined beams. Thus, the processed data is converted back to the time domain to achieve the desired M-to-1 coherent beam reduction of the input BTS data.","In the illustrated embodiment, step  includes steps , ,  and . Multi-resolution narrowband peaks are ORed along narrowband bins down to the base frequency resolution. Peak picking over the ORed narrowband data for all base resolution upper band frequency bins selects the maximum values. The indices of the maximum values are used to index into the unwindowed frequency data to select the strongest signals over all resolutions and beams. Unwindowed frequency data is raw times series data converted to the frequency domain with a Fourier transform. No tapering window, such as a Hamming or Hanning window, is applied to time series prior to the Fourier transform operation.","In step , an estimate of background noise in the upper band is computed and the spectra are normalized relative to the background noise estimate. This step is included in an attempt to remove the spectral color of the background noise from the spectra; in effect, this step is a background noise whitening process. Any normalization procedure known in the art may be used (see for example, Waite, A, D., Sonar for Practicing Engineers, John Wiley & Sons, pp. 131, 2002; and Nielsen, R. O., Sonar Signal Processing, Artech House Publishers, pp. 145-146, 1991, the entire contents of each of which are hereby incorporated by reference except for terminology that is inconsistent with that used herein). The normalization process first produces an estimate of the background noise by replacing narrowband-like features with local noise estimates at the respective positions. Then, normalized data is computed as the magnitude of the frequency data divided by the noise estimate.","In step  an average noise estimate is determined for bins above the splitting frequency by performing M-to-1 averaging of spectral noise estimates computed by the normalization procedure described above.","In step , phase angles for M-to-1 combined frequency data are computed. First, for each M-to-1 combined base resolution frequency bin, an index I is selected as being the index of the largest magnitude peak in each base resolution frequency bin among the M-beam blocks of ORed multi-layer data. Then, the phase angle for each base resolution frequency bin is set to the phase angle of the base resolution frequency data at I.","In step , the complex value for the M-to-1 combined base resolution frequency bin I is the product of the phase angle at I times the normalized value at I times the average noise estimate for the bin. This is done to choose which original frequency bin to keep among those in the M-beam block and combine it with the average noise estimate for the bin so as to avoid doing any further signal modification to the data. Thus, features in the finer resolution data can be recovered in this manner when coherent time integration is applied on the decompressed data.",{"@attributes":{"id":"p-0101","num":"0100"},"figref":"FIG. 7B","b":["720","409","411","400","4"]},"In step  the complex spectrum of each remaining beam (=M-combined beams) is determined, e.g., by taking the FFT of the time series of each remaining beam.","In step  the spectrum is normalized to produce normalized spectral data relative to the noise estimate. Spectral normalization produces normalized data relative to the spectral noise estimate as described for step . (Note: in some applications, normalization removes a mean value and divides the differences by a maximum value or standard deviation. For example, magnitude-frequency data are scaled to lie between 0 and 1 before they are quantized and put into the compressed data packet. The standard score is computed from the residuals using a normalization process where the mean is subtracted and the result is divided by the standard deviation.)","In step , peaks in the normalized spectral data above a threshold amplitude are clipped, i.e., the value for the base resolution frequency bin is re-set to the value of the clipping threshold. Clipping the normalized data at the clipping threshold is used to prevent poor AR modeling behavior. The clipped normalized data, noise estimate, and original phase angles are combined to produce clipped frequency data.","In step  the spectrum above the maximum frequency of interest is removed from the model by truncating the spectral data starting at the first frequency bin that is greater than the maximum frequency of interest. This is analogous to down-sampling the data in the frequency domain. Thus, data above the desired processing range is removed. In step , an inverse Fourier transform (e.g., the IFFT) is applied to convert the clipped normalized spectrum to a clipped normalized time series in the time domain for each remaining beam.","In step  the coefficients of an autoregressive (AR) model are determined. In step  the AR model is used to derive the residuals and the residuals are quantized.","In the illustrated embodiment, step  includes step , step  and step . In step , the model coefficients for the clipped normalized time series are determined. The model comprises AR coefficients. AR coefficients are defined by the Equation 1.\n\n()=()+()\u2003\u2003(1)\n\nwhere X(i) indicates the value of the acoustic pressure time series at time sample i within the time block, K is a constant, \u03b5(i) is a noise estimate for time sample i, and the Cj are the AR coefficient for an AR model of order P. Thus the AR model coefficients are used to predict the next time sample given the most recent time samples. Any method may be used. For example, linear predictive coding (LPC) and Burg's algorithm have produced nearly identical results, and either can be applied to model the data. Both methods are described in Chapter 3 of: Stoica, Petre and Moses, Randolph, , Prentice Hall, Upper Saddle River, N.J., 1997 (hereinafter Stoica et al.); the entire contents of Chapter 3 are hereby incorporated by reference insofar as the terminology is not inconsistent with that used herein. Autoregressive (AR) parameters for LPC are based on solving the Yule-Walker equations, which can be done with the Levinson-Durbin recursion, the details of which are described on pages 89-97 of Stoica et al.. AR parameters can also be computed using Burg's method, which is described on pages 120-123 of Stoica et al..\n","In the illustrated embodiment an AR model of order between about 100 and about 200 is used. In step , the AR coefficients are converted to reflection coefficients, which have better quantization properties. Reflection coefficients are described on pages 120-123 of Stoica et al..","In step  the inverse filter corresponding to the AR model is determined. Any inverse AR filtering (also known as moving average, MA, filtering) procedure known in the art to get the residuals, also called prediction error, may be used (see for example, Rabiner L. R. and Schafer, R. W., Digital Processing of Speech Signals, Prentice Hall, pp. 421, 1978, the entire contents of which are hereby incorporated by reference except for terminology that is inconsistent with that used herein).","In step , the time series is passed through the inverse AR filter to produce residuals. The residuals have the property that if they are passed through the AR filter, then the original time series data can be recovered exactly. However, because the AR coefficients and the residuals are quantized for insertion into the limited sized data packet to achieve compression, the coefficient used during decompression are not exact and introduce a certain amount of signal degradation based on the level of quantization.","There are residuals for every time sample. The residuals can be thought of as the error between the actual BTS data and the AR model of the normalized clipped data. To achieve compression of the residuals, they are converted to the frequency domain in step  by determining the discrete cosine transform (DCT) of the residuals for the base resolution frequency bins below the splitting frequency. In addition, the DCT of the residuals allows greater control over the data that is saved, such as being able to recover data in specific frequency bands that best address the goals of an application, e.g., as indicated in the targets field  of the shared data data structure. The residuals tend to have a Gaussian distribution; and, therefore, the DCT of the residuals appears Gaussian distributed as well.","In step , the DCT amplitudes are combined for the correlated frequency bands in the correlated beams. As stated above, residuals between adjacent beams exhibit some correlation. At lower frequencies, the correlation is greater, so the amount that the residuals can be reduced is significant. As the frequencies become higher, there is less correlation in the residuals, so the amount that the residuals are reduced is decreased.","In step  the DCT values in the frequency bins to be retained (based on the target frequencies indicated in the targets field ) are quantized using scaling factors indicated in field  also in the shared data data structure . A scaling factor affects the precision to which the DCT of the residuals are quantized, which forms the tradeoff between bits\/residual value and quantization accuracy.",{"@attributes":{"id":"p-0114","num":"0113"},"figref":["FIG. 7C","FIG. 4"],"b":["750","413","400","751","705","700"]},"In step , peaks in the upper band from all remaining beams are sorted by magnitude in the base resolution. In step , the N highest peaks are selected, where N is chosen based on the data rate that is available to use, and the indices at these peaks are saved as described above. Since the data was sorted over all beams, this allows the algorithm to save off more signals on noisy beams and less data from quiet beams, where it is sufficient to use AR modeling to fill in the non-signal data. In step  the bin index and magnitude and phase of the N peaks are determined. For example, the values in the unwindowed FFT of the BTS data at the peak-picked bin indices are selected.","In step  the phase and normalized magnitude at the bins of the peaks are quantized. For example, the complex values are preserved by saving them in magnitude\/phase format. In and illustrated embodiments, phase angles are linearly quantized; and magnitudes are normalized to the range zero to one, and then non-linearly quantized using \u03bc-law companding. Companding algorithms reduce the dynamic range of an audio signal. In analog systems, this can increase the signal-to-noise ratio (SNR) achieved during transmission, and in the digital domain, it can reduce the quantization error (hence increasing signal to quantization noise ratio). These SNR increases can be traded instead for reduced bandwidth for equivalent SNR. The \u03bc-law companding is described by Equation 2.\n\n()=sgn()*1(1+\u03bc*||)\/1(1+\u03bc)\u2003\u2003(2)\n\nWhere F is the non-linear quantized representation of the normalized magnitude value x, sgn(x) indicates the sign of x, In is the natural logarithm and p. is the maximum value (e.g., 255 for eight bits).\n",{"@attributes":{"id":"p-0117","num":"0116"},"figref":["FIG. 8A","FIG. 8D","FIG. 8A","FIG. 8A"],"b":["810","802","804","814","812","810"]},"The clipped spectral data is created by multiplying the clipped normalized data with the noise estimate, producing the result depicted by . The resulting complex spectrum  is depicted in  with the same horizontal and vertical axes  and , respectively. Note that the features in the lower frequency portion of the spectrum  capture the features of the original spectrum , while higher frequency features are lost. Those will be restored by the narrowband peak selection and insertion, which take much less data to represent than would residuals throughout the upper band. The AR model without residuals estimates the background noise levels in the upper frequency band.",{"@attributes":{"id":"p-0119","num":"0118"},"figref":["FIG. 8C","FIG. 8D"],"b":["802","804","820","830","802","804","840","840","840","840","840","840","820","850"],"i":["a","b","c","d","e ","f"]},{"@attributes":{"id":"p-0120","num":"0119"},"figref":["FIG. 9","FIG. 6"],"b":["900","611","613"]},"In step , the wide frequency band is determined from quantized residuals in the lower band and scaled noise in the upper band. Step  includes steps  which encapsulates steps , ,  and . In step  the lower band residuals are passed through a non-linear contrast enhancement. This can be considered perceptual enhancement, which is used to counter signal loss due to quantization of AR model coefficients and residuals. The signs of residual values are kept.","In step , a set A of residuals is obtained by raising the magnitude of the residuals to the power given by a scalar parameter Ka (greater than 1). In step , a set B of residuals is obtained by multiplying the magnitudes of the residuals by a constant Kb (greater than 1). In step  the minima is determined between the two sets of A and B at each frequency bin. In step  the minimum is multiplied by the previously saved sign and is used as the new set of residual values for the lower band, as indicated by Equation 2.\n\n()=sign(())*min (()()*)\u2003\u2003(2)\n\nWhere r(f) is the contrast-enhanced residual at frequency bin f and R(f) is the restored residual at frequency bin f.\n","In step , an inverse DCT (IDCT) is applied to the restored residuals to produce a residuals time series. In step  the residuals time series is passed through the AR filter based on the quantized AR coefficients to produce a modeled time series. In step  the modeled time series is converted to a modeled complex spectrum. In step , the modeled complex spectrum is multiplied in the upper band by a factor less than one to reduce noise. In some embodiments, step  is omitted.","The remaining steps of method  add back in the narrowband peaks and complete the decompression as described above with reference to .","Experimental embodiments have achieved compression ratios of 16:1 and 24:1 up to 30:1 and 40:1 when more signal loss can be tolerated, while preserving features of interest in the reconstructed time series. Even higher compression ratios have been achieved using beam combination factors of two and four at the expense of directional resolution of signals of interest.","6. Hardware Overview",{"@attributes":{"id":"p-0126","num":"0125"},"figref":"FIG. 10","b":["1000","1000","1010","1000","1000"]},"A sequence of binary digits constitutes digital data that is used to represent a number or code for a character. A bus  includes many parallel conductors of information so that information is transferred quickly among devices coupled to the bus . One or more processors  for processing information are coupled with the bus . A processor  performs a set of operations on information. The set of operations include bringing information in from the bus  and placing information on the bus . The set of operations also typically include comparing two or more units of information, shifting positions of units of information, and combining two or more units of information, such as by addition or multiplication. A sequence of operations to be executed by the processor  constitutes computer instructions.","Computer system  also includes a memory  coupled to bus . The memory , such as a random access memory (RAM) or other dynamic storage device, stores information including computer instructions. Dynamic memory allows information stored therein to be changed by the computer system . RAM allows a unit of information stored at a location called a memory address to be stored and retrieved independently of information at neighboring addresses. The memory  is also used by the processor  to store temporary values during execution of computer instructions. The computer system  also includes a read only memory (ROM)  or other static storage device coupled to the bus  for storing static information, including instructions, that is not changed by the computer system . Also coupled to bus  is a non-volatile (persistent) storage device , such as a magnetic disk or optical disk, for storing information, including instructions, that persists even when the computer system  is turned off or otherwise loses power.","Information, including instructions, is provided to the bus  for use by the processor from an external input device , such as a keyboard containing alphanumeric keys operated by a human user, or a sensor. A sensor detects conditions in its vicinity and transforms those detections into signals compatible with the signals used to represent information in computer system . Other external devices coupled to bus , used primarily for interacting with humans, include a display device , such as a cathode ray tube (CRT) or a liquid crystal display (LCD), for presenting images, and a pointing device , such as a mouse or a trackball or cursor direction keys, for controlling a position of a small cursor image presented on the display  and issuing commands associated with graphical elements presented on the display .","In the illustrated embodiment, special purpose hardware, such as an application specific integrated circuit (IC) , is coupled to bus . The special purpose hardware is configured to perform operations not performed by processor  quickly enough for special purposes. Examples of application specific ICs include graphics accelerator cards for generating images for display , cryptographic boards for encrypting and decrypting messages sent over a network, speech recognition, and interfaces to special external devices, such as robotic arms and medical scanning equipment that repeatedly perform some complex sequence of operations that are more efficiently implemented in hardware.","Computer system  also includes one or more instances of a communications interface  coupled to bus . Communication interface  provides a two-way communication coupling to a variety of external devices that operate with their own processors, such as printers, scanners and external disks. In general the coupling is with a network link  that is connected to a local network  to which a variety of external devices with their own processors are connected. For example, communication interface  may be a parallel port or a serial port or a universal serial bus (USB) port on a personal computer. In some embodiments, communications interface  is an integrated services digital network (ISDN) card or a digital subscriber line (DSL) card or a telephone modem that provides an information communication connection to a corresponding type of telephone line. In some embodiments, a communication interface  is a cable modem that converts signals on bus  into signals for a communication connection over a coaxial cable or into optical signals for a communication connection over a fiber optic cable. As another example, communications interface  may be a local area network (LAN) card to provide a data communication connection to a compatible LAN, such as Ethernet. Wireless links may also be implemented. Carrier waves, such as acoustic waves and electromagnetic waves, including radio, optical and infrared waves travel through space without wires or cables. Signals include man-made variations in amplitude, frequency, phase, polarization or other physical properties of carrier waves. For wireless links, the communications interface  sends and receives electrical, acoustic or electromagnetic signals, including infrared and optical signals, that carry information streams, such as digital data.","The term computer-readable medium is used herein to refer to any medium that participates in providing information to processor , including instructions for execution. Such a medium may take many forms, including, but not limited to, non-volatile media, volatile media and transmission media. Non-volatile media include, for example, optical or magnetic disks, such as storage device . Volatile media include, for example, dynamic memory . Transmission media include, for example, coaxial cables, copper wire, fiber optic cables, and waves that travel through space without wires or cables, such as acoustic waves and electromagnetic waves, including radio, optical and infrared waves. The term computer-readable storage medium is used herein to refer to any medium that participates in providing information to processor , except for transmission media.","Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, a hard disk, a magnetic tape, or any other magnetic medium, a compact disk ROM (CD-ROM), a digital video disk (DVD) or any other optical medium, punch cards, paper tape, or any other physical medium with patterns of holes, a RAM, a programmable ROM (PROM), an erasable PROM (EPROM), a FLASH-EPROM, or any other memory chip or cartridge, a carrier wave, or any other medium from which a computer can read.","Logic encoded in one or more tangible media includes one or both of processor instructions on a computer-readable storage media and special purpose hardware, such as ASIC*.","Network link  typically provides information communication through one or more networks to other devices that use or process the information. For example, network link  may provide a connection through local network  to a host computer  or to equipment  operated by an Internet Service Provider (ISP). ISP equipment  in turn provides data communication services through the public, world-wide packet-switching communication network of networks now commonly referred to as the Internet . A computer called a server  connected to the Internet provides a service in response to information received over the Internet. For example, server  provides information representing video data for presentation at display .","The invention is related to the use of computer system  for implementing the techniques described herein. According to one embodiment of the invention, those techniques are performed by computer system  in response to processor  executing one or more sequences of one or more instructions contained in memory . Such instructions, also called software and program code, may be read into memory  from another computer-readable medium such as storage device . Execution of the sequences of instructions contained in memory  causes processor  to perform the method steps described herein. In alternative embodiments, hardware, such as application specific integrated circuit , may be used in place of or in combination with software to implement the invention. Thus, embodiments of the invention are not limited to any specific combination of hardware and software.","The signals transmitted over network link  and other networks through communications interface , carry information to and from computer system . Computer system  can send and receive information, including program code, through the networks ,  among others, through network link  and communications interface . In an example using the Internet , a server  transmits program code for a particular application, requested by a message sent from computer , through Internet , ISP equipment , local network  and communications interface . The received code may be executed by processor  as it is received, or may be stored in storage device  or other non-volatile storage for later execution, or both. In this manner, computer system  may obtain application program code in the form of a signal on a carrier wave.","Various forms of computer readable media may be involved in carrying one or more sequence of instructions or data or both to processor  for execution. For example, instructions and data may initially be carried on a magnetic disk of a remote computer such as host . The remote computer loads the instructions and data into its dynamic memory and sends the instructions and data over a telephone line using a modem. A modem local to the computer system  receives the instructions and data on a telephone line and uses an infra-red transmitter to convert the instructions and data to a signal on an infra-red a carrier wave serving as the network link . An infrared detector serving as communications interface  receives the instructions and data carried in the infrared signal and places information representing the instructions and data onto bus . Bus  carries the information to memory  from which processor  retrieves and executes the instructions using some of the data sent with the instructions. The instructions and data received in memory  may optionally be stored on storage device , either before or after execution by the processor .",{"@attributes":{"id":"p-0139","num":"0138"},"figref":["FIG. 11","FIG. 10"],"b":["1100","1100","1100"]},"In one embodiment, the chip set  includes a communication mechanism such as a bus  for passing information among the components of the chip set . A processor  has connectivity to the bus  to execute instructions and process information stored in, for example, a memory . The processor  may include one or more processing cores with each core configured to perform independently. A multi-core processor enables multiprocessing within a single physical package. Examples of a multi-core processor include two, four, eight, or greater numbers of processing cores. Alternatively or in addition, the processor  may include one or more microprocessors configured in tandem via the bus  to enable independent execution of instructions, pipelining, and multithreading. The processor  may also be accompanied with one or more specialized components to perform certain processing functions and tasks such as one or more digital signal processors (DSP) , or one or more application-specific integrated circuits (ASIC) . A DSP  typically is configured to process real-world signals (e.g., sound) in real time independently of the processor . Similarly, an ASIC  can be configured to performed specialized functions not easily performed by a general purposed processor. Other specialized components to aid in performing the inventive functions described herein include one or more field programmable gate arrays (FPGA) (not shown), one or more controllers (not shown), or one or more other special-purpose computer chips.","The processor  and accompanying components have connectivity to the memory  via the bus . The memory  includes both dynamic memory (e.g., RAM, magnetic disk, writable optical disk, etc.) and static memory (e.g., ROM, CD-ROM, etc.) for storing executable instructions that when executed perform one or more steps of a method described herein. The memory  also stores the data associated with or generated by the execution of one or more steps of the methods described herein.","7. Extensions and Alternatives.","In the foregoing specification, the invention has been described with reference to specific embodiments thereof. It will, however, be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention. The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings and in which like reference numerals refer to similar elements and in which:",{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 4A"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 4B"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 5A"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 5B"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 6A"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 6B"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 7A","FIG. 4"]},{"@attributes":{"id":"p-0027","num":"0026"},"figref":["FIG. 7B","FIG. 4"]},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 7C","FIG. 4"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 8A","FIG. 8D"]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":["FIG. 9","FIG. 6"]},{"@attributes":{"id":"p-0031","num":"0030"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 11"}]},"DETDESC":[{},{}]}
