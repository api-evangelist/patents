---
title: Automating user interface navigation
abstract: A system processes a set of instructions, each of which indicates an action to perform on a user interface. The system does not have prior information concerning the layout of the user interface, nor does the system interact with the user interface through an automation API. For each instruction in the set, the system automatically performs the indicated action on the user interface. To do so, the system identifies the selected control on an active window, and determines whether it is the control to activate in order to perform the indicated action. If so, the system generates an input signal configured to activate the selected control, and sends the input signal to the user interface. If not, the system selects a new control and determines whether it is the desired one. The system cycles through the controls to find the desired one to activate.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08171406&OS=08171406&RS=08171406
owner: Symantec Corporation
number: 08171406
owner_city: Mountain View
owner_country: US
publication_date: 20090819
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION"],"p":["This disclosure pertains generally to computer user interfaces, and more specifically to automating user interface navigation.","Computer software user interfaces are designed to be operated by human beings. Like so many tasks, controlling user interfaces can be simple for a live person, but difficult to automate. However, there are cases when it is desirable for an automated process to navigate a user interface without the help of a person. One case is an automated tool that interacts with third party user interfaces, for example on the Web. An example of such a system is a program that automatically searches the Web for malware (e.g., viruses, Trojan horses, etc.). Such a system would need to download and install many different software packages in order to examine their contents. Different Web based installation programs can have widely different user interfaces. Thus, it would be desirable if the system could automatically operate a wide variety of user interfaces.","Another case is an automated testing tool that needs to drive a user interface in order to test the underlying software. As developers create new software, it is common to do a lot of automated testing in this manner. Because the user interface can change between builds, it would be desirable for the automated test tool to be able to drive various user interface configurations and formats.","One way for an automated process to drive user interfaces is to build the automated process such that it includes specific information concerning the user interface it is to operate. However, this significantly limits the utility of the automated process. For example, it would be desirable for the above-described Web searching system to be able to operate the interfaces of the different installation programs it encounters on the Web, concerning which it would have no previous information. In a similar vein, if the automated testing tool must be build such that it includes detailed information about a user interface it is to operate, it would have to be re-scripted every time the user interfaces changes. These problems are made even more complex by the wide variety of technologies used to implement contemporary user interfaces, such as Win32, Java, variations of HTML, Flash, etc.","Application Programming Interfaces (APIs) exist that can be employed in a software user interface to allow automated processes to interrogate and drive it. An example of such an automation API is Microsoft Active Accessibility. However, user interfaces are not required to support such APIs, and as a result most user interfaces do not. There is no existing mechanism that allows an automated process to operate a user interface that does not support an automated API, unless the automated process has prior information of the user interface layout. It would be desirable to address these issues.","A user interface automated navigation system running on a computer automates user interface navigation. The user interface automated navigation system processes a set of instructions, each of which indicates an action to perform on a user interface. This set of instructions can be in the form of a script, supplied by, for example, a user or system administrator. The user interface automated navigation system does not have prior information concerning the layout of the user interface, nor does the user interface automated navigation system interact with the user interface by using an automation API.","For each instruction in the set, the user interface automated navigation system automatically performs the action on the user interface indicated by the instruction. To do so, the user interface automated navigation system identifies the selected control on an active window of the user interface, and determines whether it is the control to activate in order to perform the indicated action. If so, the user interface automated navigation system generates at least one input signal configured to activate the currently selected control, and sends the generated input signal(s) to the user interface. If the currently selected control is not the control to activate, the user interface automated navigation system selects a new control and determines whether the newly selected control is the desired one. The user interface automated navigation system can cycle through the controls on the windows until it finds the desired control to activate.","In order to identify the currently selected control on an active window of the user interface, the user interface automated navigation system can capture a first image of the active window of the user interface, generate at least one input signal configured to change the control focus, and send the generated input signal(s) to the user interface. The user interface automated navigation system can subsequently capture a second image of the active window of the user interface, and compare the two images.","To determine whether the currently selected control is the control to activate, the user interface automated navigation system can identify a label associated with the currently selected control, and compare the label to one or more indicator(s) of the control to activate. This comparison can be an image comparison, or the user interface automated navigation system can use OCR to convert the label to text and perform a text comparison.","The features and advantages described in this summary and in the following detailed description are not all-inclusive, and particularly, many additional features and advantages will be apparent to one of ordinary skill in the relevant art in view of the drawings, specification, and claims hereof. Moreover, it should be noted that the language used in the specification has been principally selected for readability and instructional purposes, and may not have been selected to delineate or circumscribe the inventive subject matter, resort to the claims being necessary to determine such inventive subject matter.","The Figures depict various embodiments for purposes of illustration only. One skilled in the art will readily recognize from the following discussion that alternative embodiments of the structures and methods illustrated herein may be employed without departing from the principles described herein.",{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 1","FIG. 1"],"b":["100","101","100","103","103","103","105","105","101","103","101","103","105","103","105"]},"Clients  and servers  can be implemented using computer systems  such as the one illustrated in  and described below. The clients  and servers  are communicatively coupled to a network , for example via a network interface  or modem  as described below in conjunction with . Clients  are able to access applicants and\/or data on servers  using, for example, a web browser or other client software (not shown).","Although  illustrates three clients and two servers as an example, in practice many more (or fewer) clients  and\/or servers  can be deployed. In one embodiment, the network  is in the form of the Internet. Other networks  or network-based environments can be used in other embodiments.",{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 2","b":["210","101","103","105","210","210","212","212","210","214","217","218","222","220","226","224","230","230","233","232","234","244","237","238","235","290","235","239","240","242","246","212","228","247","212","230","248","212"]},"Other components (not illustrated) may be connected in a similar manner (e.g., document scanners, digital cameras, printers, etc.). Conversely, all of the components illustrated in  need not be present. The components can be interconnected in different ways from that shown in .","The bus  allows data communication between the processor  and system memory , which, as noted above may include ROM and\/or flash memory as well as RAM. The RAM is typically the main memory into which the operating system and application programs are loaded. The ROM and\/or flash memory can contain, among other code, the Basic Input-Output system (BIOS) which controls certain basic hardware operations. Application programs can be stored on a local computer readable medium (e.g., hard disk , optical disk ) and loaded into system memory  and executed by the processor . Application programs can also be loaded into system memory  from a remote location (i.e., a remotely located computer system ), for example via the network interface  or modem . In , the user interface automated navigation system  is illustrated as residing in system memory . The workings of the user interface automated navigation system  are explained in greater detail below in conjunction with .","The storage interface  is coupled to one or more hard disks  (and\/or other standard storage media). The hard disk(s)  may be a part of computer system , or may be physically separate and accessed through other interface systems.","The network interface  and or modem  can be directly or indirectly communicatively coupled to a network  such as the Internet. Such coupling can be wired or wireless.",{"@attributes":{"id":"p-0026","num":"0025"},"figref":["FIG. 3","FIG. 3","FIG. 4"],"b":["101","217","210","101","210","101","103","105","210","101","107","101","101","101","101","217","210","214","210","210","101"]},"As illustrated in , the user interface automated navigation system  automatically drives a user interface  without the use of an automation API supported by the user interface , and without any prior information of the layout of the user interface . The user interface automated navigation system  accomplishes this by using a combination of input signals  (e.g., simulated keystrokes, pointing device operations such as mouse clicks, etc.) and image processing to identify the location and purpose of controls  (e.g., buttons, text boxes, prompts, etc.) on the user interface  it is controlling. Once a desired control  has been located, it can be activated by sending the proper input signal  (e.g., a mouse click or a series of keystrokes) to the active window of the user interface  that contains the control . As used herein, \u201cwindow\u201d means window or similar display object, depending upon the specific format of the user interface  in question. The present invention is not limited to any specific user interface .","To operate a user interface , the user interface automated navigation system  reads a script  or similar set of instructions, indicating what operations to perform on the user interface . Typically, each line of the script  directs the user interface automated navigation system  to perform a specific function by activating a given control  on a screen of the user interface . For example, suppose that the user interface automated navigation system  is processing a script  directing it to download and install a software program from a website. One line of the script  could indicate to activate a control  on the user interface  of the website that installs the software program. The script  could subsequently specify to check a \u201cYes\u201d box, and then click on an \u201cOkay to Proceed\u201d button. It is to be understood that a script  specifies a series of actions to take, typically on a succession of screens of a user interface . A script  can be provided, for example, by a user or systems administrator.","As noted above, the user interface automated navigation system  processing a script has no information concerning the layout of the user interface(s) it is to operate. To carry out a command in the script , the user interface automated navigation system  sends navigation related input signals  to the active user interface  window, and captures images (i.e., screenshots ) of the window between input signals . Each input signal  causes the window to display a visual indication that a new control  has the focus. By comparing the screenshots  taken before and after sending input signals , the user interface automated navigation system  is able to determine the location of the currently selected control  in the window of the user interface . For example, sending a tab key signal  to the active window shifts the focus to the next grouping of controls . Sending arrow key signals  navigates between the controls  in that group. Sending a spacebar down signal  activates the currently selected control , and subsequently sending an escape key signal  cancels the activation. In this manner, the user interface automated navigation system  can identify the currently selected control .","Once a specific control  is located, the user interface automated navigation system  determines whether the located control  is the one that the line of the script  being processed indicates to activate (i.e., the desired control ). To make this determination, the user interface automated navigation system  identifies the label  (e.g., text or image) associated with the control . The label  associated with a control  is often found inside the borders of the control , as identified by the selection highlighting. If not located there, the associated label  is likely located to the right of the control . The user interface automated navigation system  compares the label  associated with a found control  to a set of images (or text) indicating the desired control  (e.g., the install button to click, the yes box to check, the okay button to click, etc.). As explained in greater detail below, this comparison can be made by using optical character recognition (OCR) and\/or image comparison. Once the desired control  is identified, it can be activated by sending, for example, a mouse click signal  or appropriate keystroke signals  to the location of the control  in the window of the user interface .",{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 4","FIG. 4"],"b":["101","101","101"]},"As illustrated, a scripting module  processes a script  in order to drive a user interface . When the script  specifies to activate a particular control , the scripting module  calls a control identification module  to identify and locate the desired control . Once the desired control  is identified and located, the scripting module  calls a control activation module  to activate the control . The control activation module  sends pointing device operations and\/or keystrokes in order to activate the desired control .","In order to identify the desired control , the control identification module  calls a navigation module  to determine locations of the controls  in the active window of the user interface . The navigation module  generates input signals  to navigate the user interface , and sends them to the active window. As described above, this changes the control focus, and thus the visual indicators displayed on the active window.","Before and after calling the navigation module , the control identification module  calls a screen capture module , which captures an image of the screen. Thus, the control identification module  receives an image of the active window before and after a navigation input signal  is sent. The control identification module  calls a comparison module  to compare these two screenshots  of the window, to determine the location in the window of the control  that has been selected by the navigation.","The comparison module  also determines whether the selected control  is the one the script  specifies to activate (i.e., the desired control ). To do so, the comparison module  compares the label  of the selected control  to one or more images  indicative of the desired control , to see if it matches. For example, if the script  specifies to check a \u201cYes\u201d box, the comparison module  compares the label  of the selected control  to an image  (or to each of a set of images ) of a \u201cYes\u201d box label , to determine whether the selected control  is a match. The indicative images  to which to compare labels  of selected controls  can be supplied, for example, by a user or system administrator. A collection of such indicative images  can be maintained in, for example, a centrally located or local database (not illustrated).","In order to compare a label  of a selected control  to an image  indicative of a desired control , the comparison module  can simply perform an image comparison. In some embodiments, instead of or in addition to performing an image comparison, the comparison module  calls an OCR module . The OCR module  uses optical character recognition to translate the image of text associated with a control  from image format to text format. This allows the comparison module  to compare the translated text to the text specified by the script .","The above-described process of screen capture, navigation, screen capture and comparison is repeated until a desired control  is identified and located. The control activation module  then sends the appropriate input signal(s)  to activate the identified control . These steps are repeated for each instruction in the script , thereby carrying out the actions specified therein.",{"@attributes":{"id":"p-0038","num":"0037"},"figref":["FIG. 5","FIG. 1","FIG. 3","FIG. 4","FIG. 3","FIG. 3","FIG. 4","FIG. 3","FIG. 3","FIG. 4","FIG. 3","FIG. 3","FIG. 3","FIG. 4","FIG. 3","FIG. 3","FIG. 4","FIG. 3","FIG. 3","FIG. 3","FIG. 4","FIG. 3","FIG. 3","FIG. 4","FIG. 3","FIG. 3","FIG. 4","FIG. 3","FIG. 4","FIG. 4","FIG. 4"],"b":["101","305","401","501","307","301","409","503","309","301","407","505","303","301","507","303","409","509","309","303","411","511","309","513","305","303","413","515","311","305","411","517","311","305","415","305","413","411","411"]},"If the selected control  () matches the desired control  (), the control activation module  () sends  the appropriate input signal  () to activate the control  (). Otherwise, steps - are repeated, until the desired control  () is located in the active window. So long as there are more instructions in the script  (), steps - are repeated for each instruction.","As will be understood by those familiar with the art, the invention may be embodied in other specific forms without departing from the spirit or essential characteristics thereof. Likewise, the particular naming and division of the portions, modules, agents, managers, components, functions, procedures, actions, layers, features, attributes, methodologies, data structures and other aspects are not mandatory or significant, and the mechanisms that implement the invention or its features may have different names, divisions and\/or formats. The foregoing description, for purpose of explanation, has been described with reference to specific embodiments. However, the illustrative discussions above are not intended to be exhaustive or limiting to the precise forms disclosed. Many modifications and variations are possible in view of the above teachings. The embodiments were chosen and described in order to best explain relevant principles and their practical applications, to thereby enable others skilled in the art to best utilize various embodiments with or without various modifications as may be suited to the particular use contemplated."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 5"}]},"DETDESC":[{},{}]}
