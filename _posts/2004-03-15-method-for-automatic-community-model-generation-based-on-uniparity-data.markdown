---
title: Method for automatic community model generation based on uni-parity data
abstract: Method for automatic community model generation based on uni-parity data. Correlation analysis is employed to identify links within the community. Method may be particularized for solving specific problems such as determining the activities between individuals within a money laundering ring.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07756685&OS=07756685&RS=07756685
owner: The United States of America as represented by the Secretary of the Air Force
number: 07756685
owner_city: Washington
owner_country: US
publication_date: 20040315
---

{"@attributes":{"id":"description"},"GOVINT":[{},{}],"heading":["STATEMENT OF GOVERNMENT INTEREST","BACKGROUND OF THE INVENTION","OBJECTS AND SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE GENERALIZED EMBODIMENT","AN ILLUSTRATIVE EXAMPLE OF THE PREFERRED EMBODIMENT MONEY LAUNDERING CRIME"],"p":["The invention described herein may be manufactured and used by or for the Government of the United States for governmental purposes without the payment of any royalty thereon.","It can be very useful to know about activities between individuals. For example, what individuals are associated with other individuals? Which individuals communicate with other individuals? When two or more individuals get together is there an intended purpose? Who are the leaders or important individuals of a group? What is the organizational structure of the group? It can prove useful further yet to have the capability to actually model the above types of interactions and associations. To an extent, this type of social research has been addressed by employing the disciplines of data mining and community generation.","Examples of such problems include mining movie data to find out how actors\/actresses, directors, and producers are linked to different movies and how the movies are linked to different awards; mining on Web community or topic related documents to find out where the hubs and authorities or the related documents are and how they are linked together; mining the commercial merchandise sales data of a franchise store nation-wide to determine the associations (or correlations) among a group of merchandise items; mining customer search topic data collected over a period of time in a library to identify a group of related common interests and their relationships; and mining the traffic data collected from a wide network of geographical locations nation-wide or within a specific area (e.g., NY City) to find out the traffic accident pattern correlations among a group of locations. The government or civilian sector also has a number of requirements for such a capability. Such examples include the identification of terrorist cells, crime rings such as money laundering, drug interdiction and the identification of tactical units in the battlefield.","In some of the problems the data is given with existing links such as the movie data with actor-movie links and the Web data with Web links while in others the data is given completely in isolation and no link information is available such as sales data, customer search topic data collected from a library, or traffic records collected in different geographical locations. The goal then is to generate communities based on yet-to-be-determined links between the data items. Current research in community generation focuses on the former and is addressed under the area of relational data mining and learning in the literature. But what happens when you don't have explicit link\/relationship information? To our knowledge, nobody has systematically addressed this class of problems and in fact it has not even been identified as another paradigm within the community generation area let alone the data mining community. To this avail, we have entitled this set of problems as the Uni-party Data Community Generation (UDCG) problem. To facilitate the comparison, we call the former class of problems (where we know or are given the relationships) as Bi-party Data Community Generation (BDCG) problems.","It is therefore an object of the present invention to provide a methodology for solving a uni-party data community generation paradigm.","A further object of the present invention is to provide a method which employs automatic community model generation for solving a uni-party data community generation paradigm.","Yet another object of the present invention is to employ Link Discovery based on Correlation Analysis (LDCA) for generating an automatic community model.","A particular object of the present invention is to provide a method for solving a Money Laundering Crime (MLC) case.","Briefly stated, the present invention provides a method for automatic community model generation based on uni-parity data. Correlation analysis is employed to identify links within the community. Method may be particularized for solving specific problems such as determining the activities with a money laundering ring.","A generalized embodiment of the present invention, method for automatic community model generation based on uni-parity data, comprises the steps of hypothesizing a subset S of set U, wherein for any pair of items in subset S there exists a mathematical function C applicable to the pair of items so as to generate a correlation value and correlation relationship between any pair of items in subset S; generating correlation values by applying the function C to each of the pairs of items in subset S; graphing G(S,E), wherein E is the edge set of graph G with computed correlation values as weights; and mapping graph G to one of its subgraphs MG so as to generate a community.","A further embodiment of the present invention, method for solving a community generation problem, comprises the steps of converting documents to digital form and tagging the digitized documents; parsing the digitized and tagged documents to extract the transaction history vector for each individual; creating timelines of the transaction vectors so as to form a timeline map; determining the relevancy of the vectors; projecting the vectors along a time dimension so as to form as histogram; translating the vectors into groups of activities by histogram clustering; determining the local correlation between any pair of clusters in the timeline of two individuals; computing the global correlations between pairs of individuals; converting data to a graph as a function of all individuals extracted from the documents and the correlation values between individuals; generating models based on a search of all subgraphs with correlation values above a threshold; and outputting a group model.","A particular embodiment of the present invention for solving a money laundering problem comprises applying the \u201cone way nearest neighbor\u201d principle, wherein the \u201cone way nearest neighbor\u201d principle further comprises that for every person's name encountered, the first immediate time instance is the first time instance for a series of financial activities; the second immediate time instance is the second time instance for another series of financial activities, etc.; for every time instance encountered, all the subsequent financial activities are considered as the series of financial activities between this time instance and the next time instance; financial activities are identified in terms of money amount; money amount is neutral in terms of deposit or withdrawal; each person's time sequence of financial activities is updated if new financial activities of this person are encountered in other places of the same document or in other documents; and the financial activities of each time instance of a person is updated if new financial activities of this time instance of the same person are encountered in other places of the same document or in other documents.","To the accomplishment of the foregoing and related ends, the present invention, then, comprises the features hereinafter fully described and particularly pointed out in the claims. The following description and the annexed figures set forth in detail certain illustrative embodiments of the invention. These embodiments are indicative, however, of but a few of the various ways in which the principles of the invention may be employed. Other objects, advantages and novel features of the present invention will become apparent from the following detailed description of the invention when considered in conjunction with the figures.","In this section, we propose a general methodology, called Link Discovery based on Correlation Analysis (LDCA), as a solution to the general uni-party data community generation problem. LDCA uses a correlation measure to determine the \u201csimilarity\u201d of patterns between two data items to infer the strength of their linkage. The correlation measure may be defined in fuzzy logic to accommodate the typical impreciseness of the \u201csimilarity\u201d of patterns.","Referring to , the components of LDCA as well as the data flow of these components are depicted. In principle, LDCA consists of three basic steps. For each problem in the uni-party data community generation paradigm, assume that the data item set is U. A Link Hypothesis step  hypothesizes a subset S of U, such that for any pair of the items in S there exists a mathematical function (or a procedural algorithm) C that applies to this pair of items to generate a correlation value in the range of [0, 1], i.e., this step defines the correlation relationship between any pair of items in S:\n\n\u22000,1]\n\nA Link Generation step  then applies the function C to every pair of items in S to generate the correlation values. This results in a complete graph G(S,E) where E is the edge set of the graph with computed correlation values as the weights of the edges. Finally, a Link Identification step  defines another function P that maps the complete graph G to one of its subgraph MG as a generated community.\n","The Link Discovery based on Correlation Analysis (LDCA) methodology was applied to solving a specific community generation problem\u2014the identification of members within a Money Laundering Crime (MLC) Group. Specific algorithms are used in the LDCA process. Such algorithms have been implemented and tested in a prototype system which the present invention refers to as CORrelation AnaLysis (CORAL).","Preparing the Data","The input data to the MLC model generation problem is based on free text documents. The data is obtained from varying sources, such as bank statements, financial transaction records, personal communication letters (including emails), loan\/mortgage documents, as well as other related reports.","Referring to , the documents are converted  to a digital format using an OCR and key entities, (e.g., person names, organization names, financial transaction times and dates, location addresses, as well as transaction money amounts) are tagged  using an extraction tool using XML. No link information is tagged, thereby making the problem an excellent candidate for applying the LDCA methodology.","Once the data set is identified and acquired (i.e., obtained, converted and tagged), it must be developed to define an internal data structure. Due to the nature of the data and the lack of detailed meta-like data, a number of rules and assumptions are required. The rules and assumptions to be applied by the present invention are:\n\n","Based on the rules described above, whenever a new individual's name is encountered, a new PERSON event is created (see ); whenever a new time instance is encountered, a new TIME event is created under a PERSON event (see ); whenever a new financial transaction is encountered, a new TRANSACTION event is created linked to both corresponding TIME and PERSON events (see ). All the events are represented as vectors.  depicts the data structure created by the present invention.","Still referring to , timelines are created  as a result of parsing  the entire collection of documents and using the given data structure. Each timeline (see ) represents the financial transaction history vector of each individual. The time axis of the timelines is divided into discrete time instances. Each node in the timelines is called a \u201cmonetary vector\u201d that records the part of the financial transaction history of the corresponding person between the current time instance and the next time instance.","While the above \u201cone way nearest neighbor\u201d parsing principle may not be necessarily true in all the circumstances, it is believed to be the best for the following two reasons: (1) this is the best outcome in the absence of the actual association information in the data; (2) the experimental evaluations show that the generated models based on this principle are reasonably accurate.","The next part of this step is to determine relevancy  or, determine which monetary vectors are \u201cuseful\u201d, i.e., is an individual related to the money laundering case being investigated, and which vectors are just noise (e.g., a \u201cnormal\u201d financial transaction of an individual such as a \u201cnormal\u201d purchasing activity, or a false association between one's monetary activity and someone else due to the one way nearest neighbor parsing principle). Since the present invention does not know the relevancy of the data, a \u201cguess\u201d must be made. During the data collection process the investigators typically have the intention to collect all the documents that are related to suspects in the case, or those either suspiciously or routinely related to the case; thus, it is expected that for those individuals who might be involved in the crimes, the majorities of their monetary vectors should be well clustered into several \u201czones\u201d in the timeline axis (see ) where the actual MLCs are committed. This assumption is referred to as the \u201cfocus\u201d assumption. Based on the focus assumption, the present invention needs to pay attention to only the \u201cclusters\u201d of the monetary vectors in the timeline map, and can ignore those monetary vectors that are scattered over other places of the timeline map. This allows maximum filtering of the noise when determining the correlation between two individuals.","The present invention next projects  all the monetary vectors of all the individuals into the timeline axis to form a histogram (see ). Consequently, the clustering problem is reduced to a segmentation problem in the histogram to divide the entire timeline into different time zones, or called groups of activities .","A histogram is generated (see ) from all the monetary vectors along the timeline. Since the projection and the histogram segmentation may be performed in linear time in the timeline space, this clustering algorithm significantly improves the complexity and avoids the iterative search a \u201cnormal\u201d clustering algorithm such as the K-means algorithm would typically require. The resulted number of \u201chills\u201d (i.e., segments) in the histogram becomes the K clusters or time zones as groups of activities.","Link Hypothesis","At this point the present invention has formatted the data in a manner in which it can compute correlation values  among pairs of people. After clustering, each individual's financial transaction history vector may be represented as a timeline histogram partitioned into K clusters. The K clusters may in turn be represented as K histogram functions of time t: <f(t)>, (where f(t) is the financial transaction histogram of this individual in cluster i). The correlation between two individuals <x,y> is defined as an combined global correlation of all the local correlations between the two individuals, whereas the local correlation is defined as the correlation between two clusters of the timeline histograms of the two individuals.","Global correlation is determined  from local correlations between two individuals x and y (see ). The correlation is defined as this \u201ctwo level\u201d function due to the unique nature of the problem, i.e., individuals in the same MLC group may exhibit similar financial transaction patterns in different time \u201czones\u201d (which constrains the local correlation), but the difference in the timeline of their financial activities should not be too large (which constrains the global correlation). While the local correlation is defined following a standard approach in Pattern Recognition literature to determining a fuzzified \u201csimilarity\u201d between two functions, the global correlation is defined based on the unique nature of this problem to further constrain the overall \u201csimilarity\u201d between the financial transaction patterns along the timeline of two individuals.","In defining a reasonable correlation function, it should be noted that the concept of similar financial transaction patterns is always fuzzy. That is to say, if two individuals belong to the same crime group and are involved in the same MLC case, it is unlikely that they would conduct transactions related to the crime simultaneously at the exact time, nor is it likely that they would conduct transactions related to the crime at times that are of a year difference. It would be likely that they conduct the transactions at two different times close to each other. Consequently, we apply fuzzy logic in both definitions of the local and global correlations to accommodate the actual \u201cinaccuracy\u201d of the occurrences in the extracted financial transaction activities between different individuals at different times.","Local Correlation","The present invention defines fx(t) and fy(t) be the financial transaction histogram functions of individual x and y in cluster i and j, respectively. Following the standard practice to define a fuzzified correlation between two functions, it then uses the Gaussian function as the fuzzy resemblance function within cluster i between time instance a and b:",{"@attributes":{"id":"p-0037","num":"0045"},"maths":[{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["G","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["a","b"],"mo":","}}},{"mfrac":{"mn":"1","msqrt":{"mrow":{"mn":"2","mo":"\u2062","msub":{"mi":["\u03c0\u03c3","i"]}}}},"mo":"\u2062","msup":{"mi":"e","mrow":{"mo":"-","mfrac":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"mi":["a","b"],"mo":"-"}},"mn":"2"},"mrow":{"mn":"2","mo":"\u2062","msubsup":{"mi":["\u03c3","i"],"mn":"2"}}}}}}],"mo":"="}}},{"@attributes":{"id":"MATH-US-00001-2","num":"00001.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"3.1em","height":"3.1ex"}}},"mo":"\u2062","mrow":{"msub":{"mi":["\u03c3","i"]},"mo":"=","mrow":{"mfrac":{"mn":"2","mrow":{"msub":{"mi":["W","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["W","i"]},"mo":"-","mn":"1"}}}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"a","mo":"=","mn":"1"},"msub":{"mi":["W","i"]}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"munderover":{"mo":"\u2211","mrow":{"mi":"b","mo":"=","mrow":{"mi":"a","mo":"+","mn":"1"}},"msub":{"mi":["W","i"]}},"mo":"\u2062","mrow":{"mo":["\uf603","\uf604"],"mrow":{"mi":["a","b"],"mo":"-"}}}}}}}}}],"br":{},"sub":["i ","i "]},"The Gaussian function is used because it gives a natural decay over the time axis to represent the fuzzy resemblance between two functions. Consequently, two transactions of two individuals which occurred at closer times results in more resemblance than those which occurred at farther away times. It can be shown that after applying the fuzzy logic using the Gaussian function as the resemblance function, the resulting fuzzified histogram is the original one convolved with the fuzzy resemblance function.",{"@attributes":{"id":"p-0039","num":"0047"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"msub":{"mi":["gx","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"munderover":{"mo":"\u2211","mrow":{"msup":{"mi":["t","\u2032"]},"mo":"=","mn":"1"},"msub":{"mi":["W","i"]}},"mo":"\u2062","mrow":{"mrow":[{"msub":{"mi":["fx","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msup":{"mi":["t","\u2032"]}}},{"msub":{"mi":["G","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":",","msup":{"mi":["t","\u2032"]}}}}],"mo":"\u2062"}}],"mo":"="}}},"br":{},"b":"190","sub":["i","i"]},{"@attributes":{"id":"p-0040","num":"0048"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"g","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["x","i"]},{"mi":["y","j"]}],"mo":","}}},{"msubsup":{"mi":"max","mrow":{"mi":"t","mo":"=","mn":"0"},"msub":{"mi":["W","i"]}},"mo":"\u2062","mrow":{"munderover":{"mo":"\u2211","mrow":{"msup":{"mi":["t","\u2032"]},"mo":"=","mrow":{"mo":"-","msub":{"mi":["W","j"]}}},"msub":{"mi":["W","j"]}},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mrow":[{"msub":{"mi":["gx","i"]},"mo":"\u2061","mrow":{"mo":["(",")"],"msup":{"mi":["t","\u2032"]}}},{"msub":{"mi":["gy","j"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"t","mo":"-","msup":{"mi":["t","\u2032"]}}}}],"mo":"\u2062"}}}],"mo":"="}}},"br":{}},"The present invention assumes that the timeline axis is clustered into K segments. Based on the definition of the local correlation , for each individual x, at every cluster i, there is a set of K local correlations with individual y {g(x, y), j=1, . . . , K}. It then assigns the fuzzy weights to each of the elements of the set based on another Gaussian function to accommodate the rationale that strong correlations should occur between financial transactions of the same crime group closer in time than those farther away in time. Thus, the following series results:\n\n{(, )(), 1, . . . , \n\nwhere\n",{"@attributes":{"id":"p-0042","num":"0050"},"maths":{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"mi":"S","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["i","j"],"mo":","}}},"mo":"=","msup":{"mi":"e","mrow":{"mo":"-","mfrac":{"msup":{"mrow":{"mo":["(",")"],"mrow":{"msub":[{"mi":["c","i"]},{"mi":["c","j"]}],"mo":"-"}},"mn":"2"},"mrow":{"mn":"2","mo":"\u2062","msubsup":{"mi":["\u03c3","i"],"mn":"2"}}}}}}}},"br":{},"sub":["i ","j "]},"The correlation between individual x in cluster i and the whole financial transaction histogram of individual y is then defined based on the winner-take-all principle:\n\n()=max()()}\n\nDefining the vectors\n\n()=<(),=, . . . ,>\n\n()=<(),=1, . . . ,>\n\nthen computing global correlation  between x and y is defined by computing the dot product between the two vectors:\n",{"@attributes":{"id":"p-0044","num":"0052"},"maths":{"@attributes":{"id":"MATH-US-00005","num":"00005"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mi":"C","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["x","y"],"mo":","}}},{"mrow":[{"mrow":[{"mi":"Cy","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"x"}},{"mi":"Cx","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"y"}}],"mo":"\u00b7"},{"munderover":{"mo":"\u2211","mrow":{"mi":"i","mo":"=","mn":"1"},"mi":"K"},"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}},"mrow":{"mrow":[{"mi":"C","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["x","i"]},"mo":",","mi":"y"}}},{"mi":"C","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["y","i"]},"mo":",","mi":"x"}}}],"mo":"\u2062"}}],"mo":"="}],"mo":"="}}},"br":{}},"After applying the correlation function to determine the global correlation  to every pair of individuals in the data set U, the present invention obtains a complete graph G(V, E) , where V is the set of all the individuals extracted from the given collection of the documents, and E is the set of all the correlation values between individuals such that for any correlation C(x, y), there is a corresponding edge in G with the weight C between the two nodes x and y.","Link Identification","For the problem of MLC group model generation , the present invention defines the function P in Link Identification as a graph segmentation based on a minimum correlation threshold T. The specific value of T may be obtained based on a user's expertise (in this example a law enforcement investigator), which allows the user to validate different models based upon different thresholds and their expertise. Note that there may be multiple subgraphs M generated based on different values of T, indicating that there may possibly be multiple MLC groups identified in the given document collection. It is also possible that the original graph G(V, E) may not necessarily be connected (the complete graph G may have edges with correlation values 0, resulting in virtually an incomplete graph). Lastly, the generated models are output .","While the preferred embodiments have been described and illustrated, it should be understood that various substitutions, equivalents, adaptations and modifications of the invention may be made thereto by those skilled in the art without departing from the spirit and scope of the invention. Accordingly, it is to be understood that the present invention has been described by way of illustration and not limitation."],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
