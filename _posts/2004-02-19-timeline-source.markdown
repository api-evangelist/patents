---
title: Timeline source
abstract: A timeline source is described. In an implementation, a method includes examining a plurality of nodes within a media timeline, where at least two of the nodes reference respective media. The media timeline is for exposure over an API. The media timeline is divided into one or more presentations. Each presentation describes rendering of the media for a particular interval of time.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07941739&OS=07941739&RS=07941739
owner: Microsoft Corporation
number: 07941739
owner_city: Redmond
owner_country: US
publication_date: 20040219
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["TECHNICAL FIELD","BACKGROUND","SUMMARY","DETAILED DESCRIPTION","CONCLUSION"],"p":["The present invention generally relates to media, and more particularly relates to a timeline source for rendering a media timeline.","Users of computers, such as desktop PCs, set-top boxes, personal digital assistants (PDAs), and so on, have access to an ever increasing amount of media from an ever increasing variety of sources. For example, a user may interact with a desktop PC that executes a plurality of applications to provide media for output, such as home videos, songs, slideshow presentations, and so on. The user may also utilize a set-top box to receive traditional television programming that is broadcast to the set-top box over a broadcast network. Additionally, the set-top box may be configured as a digital video recorder (DVR) such that the user may store the broadcast content in memory on the set-top box for later playback. Further, the user may interact with a wireless phone that executes a plurality of applications such that the user may read and send email, play video games, view spreadsheets, and so forth.","Because of the wide variety of media sources and the wide variety of computers that may be utilized to provide and interact with media, traditional applications and computers were often configured to specifically address each particular type of media. For example, applications that were executed on a video-game console to output video-games were typically configured to provide an output of the applications to a television, and were not configured to provide the output that could be utilized by other computers and other devices. Therefore, presentation of media that was provided by the different media sources, such as computers and\/or applications, may involve multiple devices and\/or applications which may be both time and device intensive. Additionally, multiple applications that were executed on the same computer may be configured specifically to address the particular type of media provided by each respective application. For instance, a first audio playback application may be configured to output media configured as songs. A second audio playback application, however, may be configured for recording and playback in an audio format that is not compatible with the first audio playback application, such as an audio-dictation format.","A timeline provides a way for a user to define a presentation of media. For example, a media player can play songs chronologically organized into a timeline, which is commonly referred to as a \u201cplaylist\u201d. Traditional timelines, however, were limited by the types of media sources and computer configurations that were used to provide and interact with media. When desiring the output of media from different applications, for instance, each type of media would require a different timeline which involved the use of different applications. This use of different applications often resulted in an inefficient use of both hardware and software resources of the computer. Additionally, the different timelines made it difficult to coordinate the outputs from the respective timelines, such as where media was being output from the respective timelines concurrently.","Further, the execution of large timelines may result in the inefficient use of software and\/or hardware resources of the computer. When loading a large playlist of songs, for instance, each song in the playlist was loaded. Therefore, the initial loading of the playlist may consume a significant amount of hardware and\/or software resources, thereby resulting in a delay in the loading and playing of songs in the playlist.","Accordingly, there is a continuing need to provide improved rendering of timelines.","A timeline source for rendering a media timeline is described. A media timeline provides a technique for a user to define a presentation based on media. The media timeline may be utilized to express groupings and\/or combinations of media and provide compositional metadata utilized by the timeline source to provide a presentation of the media described by the media timeline. The timeline source may be configured in a variety of ways to address a variety of considerations, such as to support dynamic changes to the media timeline. In another example, the timeline source may \u201cpre-roll\u201d sources to minimize delays that arise in rendering content from two consecutive media sources. While content from one source is being rendered, for instance, a subsequent source may be loaded and made ready for immediate use.","In an implementation, a method includes examining a plurality of nodes within a media timeline, where at least one of the nodes reference respective media. The media timeline is for exposure over an application programming interface (API), such as to an application and\/or a rendering engine. The media timeline is divided into one or more presentations. Each presentation describes rendering of the media for a particular interval of time.","In an additional implementation, a method includes receiving a call from an application over an API for rendering a media timeline. The media timeline includes a plurality of nodes, at least one of which references respective media. The media timeline defines one or more presentations of the media. The media timeline is rendered to output each of the presentations.","The same numbers are used throughout the disclosure and figures to reference like components and features.","Overview","A timeline source for rendering a media timeline is described. The media timeline provides a technique for a user to define a presentation based on media, such as already existing media (e.g., stored media such as video, songs, documents, and so on) and\/or media that is output in \u201creal-time\u201d from a media source, such as streaming audio and\/or video. The media timeline may be utilized to express groupings and\/or combinations of media and provide compositional metadata utilized by the timeline source that renders the media timeline to provide a final presentation, based on a reference clock, which includes the media described by the media timeline.","The timeline source is responsible for managing a media presentation which is described by the media timeline and thereby eases the task of obtaining media from multiple sources at the same time. For example, previously, to obtain media from a plurality of sources at the same time, while keeping the media synchronized, involved substantial coding. Instead of providing separate coding for each application that desires the use of the media, the user can define a media timeline which references media sources that provide media to be played in parallel. The media timeline is then given to a timeline source, which interprets and executes the presentation without user intervention. The media timeline may describe complex presentations with multiple sources and effects applied to these sources at various times based on the configuration of the media timeline.","The media timeline may be configured in a variety of ways to address a variety of considerations. For example, the media timeline may be configured to provide a single timeline model for different multimedia applications, further discussion of which may be found in relation to . In an additional example, the media timelines are configured for storing metadata. Nodes of a media timeline, for instance, may include metadata that describe media referenced by the nodes, such as sources for the media, start and stop times for output of the media, effects to be applied to an output of the media, transitions between media outputs, and so on. Further discussion of media timelines and the metadata therein may be found in relation to .","In a further example, the media timeline may be configured to support dynamic changes to the media timeline. For example, nodes of the media timeline may be dynamically changed, such as modified, added, and\/or removed. Other nodes of the media timeline that are affected by these changes may be automatically updated by the media timeline. Additionally, the media timeline is configured for dynamic creation and\/or loading of the media timeline. Further discussion of media timelines that provide for dynamic creation and\/or loading of the nodes of the media timeline may be found in relation to .","In the following discussion, exemplary structures and components of the media timeline are first discussed in relation to . The timeline source which may be utilized to render the exemplary media timelines is described in relation to .","Exemplary Environment",{"@attributes":{"id":"p-0044","num":"0043"},"figref":["FIG. 1","FIG. 25"],"b":["100","102","102","102","102","102"]},"The computer  may obtain a variety of media from a variety of media sources. For example, the computer  may locally store a plurality of media (), . . . , (), . . . , (K). The plurality of media ()-(K) may include an assortment of audio and video content having various formats, such as WMV, WMA, MPEG 1, MPEG 2, MP3, and so on. Further, the media ()-(K) may be obtained from a variety of sources, such as from an input device, from execution of an application, and so on.","The computer , for instance, may include a plurality of applications (), . . . , (), . . . , (N). One or more of the plurality of applications ()-(N) may be executed to provide media, such as documents, spreadsheets, video, audio, and so on. Additionally, one or more of the plurality of applications ()-(N) may be configured to provide media interaction, such as encoding, editing, and\/or playback of the media ()-(K).","The computer  may also include a plurality of input devices (), . . . , (), . . . , (M). One or more of the plurality of input devices ()-(M) may be configured to provide media for input to the computer . Input device (), for instance, is illustrated as a microphone that is configured to provide an input of audio data, such as a voice of the user, a song at a concert, and so on. The plurality of input devices ()-(M) may also be configured for interaction by a user to provide inputs that control execution of the plurality of applications ()-(N). For example, input device () may be utilized to input voice commands from the user, such as to initiate execution of a particular one of the plurality of applications ()-(N), control execution of the plurality of applications ()-(N), and so forth. In another example, input device () is illustrated as a keyboard that is configured to provide inputs to control the computer , such as to adjust the settings of the computer .","Further, the computer  may include a plurality of output devices (), . . . , (), . . . , (J). The output devices ()-(J) may be configured to render media ()-(K) for output to the user. For instance, output device () is illustrated as a speaker for rendering audio data. Output device () is illustrated as a display device, such as a television, that is configured to render audio and\/or video data. Thus, one or more of the plurality of media ()-(K) may be provided by the input devices ()-(M) and stored locally by the computer . Although the plurality of input and output devices ()-(M), ()-(J) are illustrated separately, one or more of the input and output devices ()-(M), ()-(J) may be combined into a single device, such as a television having buttons for input, a display device, and a speaker.","The computer  may also be configured to communicate over a network  to obtain media that is available remotely over the network . The network  is illustrated as the Internet, and may include a variety of other networks, such as an intranet, a wired or wireless telephone network, a broadcast network, and other wide area networks. A remote computer  is communicatively coupled to the network  such that the remote computer  may provide media to the computer . For example, the remote computer  may include one or more applications and a video camera  that provides media, such as home movies. The remote computer  may also include an output device to output media, such as the display device  as illustrated. The media obtained by the computer  from the remote computer  over the network  may be stored locally with the media ()-(K). In other words, media ()-(K) may include locally stored copies of media obtained from the remote computer  over the network .","Thus, the computer  may obtain and store a plurality of media ()-(K) that may be provided both locally (e.g., through execution of the plurality of applications ()-(N) and\/or use of the plurality of input device ()-(M)), and remotely from the remote computer  (e.g., through execution of application and\/or use of input devices). Although the plurality of media ()-(K) has been described as stored on the computer , the media ()-(K) may also be provided in \u201creal-time\u201d. For example, audio data may be streamed from the input device (), which is illustrated as a microphone, without storing the audio data.","The computer  includes a timeline generator  that, when executed on the computer , generates a media timeline . For example, the timeline generator  may be configured as an application that exposes one or more software components that may be used to generate the media timeline , such as through a user interface by a user. As previously described, the media timeline  provides a technique for a user to define a presentation of stored and\/or real-time media from the plurality of media sources. For example, the media timeline  may describe a collection of media that was obtained from the input devices ()-(M), the applications ()-(N), and\/or the remote computer . The user may utilize one or more of the input devices ()-(M) to interact with the timeline generator  to define groupings and\/or combinations of the media ()-(K). The user may also define an order and effects for presentation of the media ()-(K). A timeline source  may then be executed on the computer  to render the media timeline . The media timeline , when rendered, provides the expressed groupings and\/or combinations of the media ()-(K) for rendering by one or more of the plurality of output devices ()-(J). Additionally, the timeline generator  may also programmatically generate the media timeline  as is described in greater detail in the following implementation.",{"@attributes":{"id":"p-0052","num":"0051"},"figref":["FIG. 2","FIG. 1"],"b":["200","200","202","204","206","204","206","206","206","104","1","104","106","1","106","108","1","108","110","1","110"],"i":["g","g","g","g"]},"The application , which may be the same as or different from applications ()-(N) of , interacts with a media engine  to control the media ()-(K). In at least some embodiments, the media engine  serves as a central focal point of the application  that desires to somehow participate in a presentation. A presentation, as used in this document, refers to or describes the handling of media. In the illustrated and described embodiment, a presentation is used to describe the format of the data on which the media engine  is to perform an operation. Thus, a presentation can result in visually and\/or audibly presenting media, such as a multimedia presentation in which both audio and accompanying video is presented to user within a window rendered on a display device, such as output device () of  that is illustrated as a display device that may be associated with a desk-top PC. A presentation can also result in writing media content to a computer-readable medium such as a disk file. Thus, a presentation is not limited to scenarios in which multimedia content is rendered on a computer. In some embodiments, operations such as decoding, encoding and various transforms (such as transitions, effects and the like), can take place as a result of a presentation.","In an embodiment, the media foundation  exposes one or more application program interfaces that can be called by the application  to interact with the media (). For example, the media foundation  may be thought of as existing at an \u201cinfrastructure\u201d level of software that is executed on the computer  of . In other words, the media foundation  is a software layer used by the application  to interact with the media (). The media foundation  may be utilized to control a number of aspects of the media (), such as output, rendering, storage, and so on. Thus, the media foundation  may be utilized such that each application  does not have to implement separate code for each type of media () that may be used in the system . In this way, the media foundation  provides a set of reusable software components to do media specific tasks.","The media foundation  may utilize several components among which include the media timeline , the timeline source , a media source , a media processor , a media session , the media engine , a source resolver , one or more transforms , one or more media sinks , , and so on. One advantage of various illustrated and described embodiments is that the system  is a pluggable model in the sense that a variety of different kinds of components can be utilized in connection with the systems described herein. Also included as a part of system  is a destination , which is discussed in more detail below. In at least one embodiment, however, the destination  is an object that defines where a presentation is to be presented (e.g. a window, disk file, and the like) and what happens to the presentation. That is, the destination may correspond to one or more of the media sinks ,  into which data flows.","The media timeline  employs a timeline object model which provides a way for a user to define a presentation based on media that is rendered by the timeline source . The media timeline  may range from a sequential list of media files to more complex forms. For example, the media timeline  may employ file structures, such as SMIL and AAF, to express media playback experiences that include transitions between media, effects, and so on. The application , for instance, may be configured as a media player that can play a list of songs, which is commonly referred to as a playlist. As another example, in an editing system a user may overlay one video over the other, clip a media, add effect to the media and so forth. Such groupings or combinations of media may be expressed using the media timeline . Further discussion of the media timeline  is found in relation to .","The media source  is utilized to abstract a provider of media. The media source , for instance, may be configured to read a particular type of media from a particular source. For example, one type of media source might capture video from the outside world (a camera), and another might capture audio (a microphone). Alternately or additionally, the media source  may read a compressed data stream from disk and separate the data stream into its compressed video and compressed audio components. Yet another media source  might obtain data from the network  of . Thus, the media source  may be utilized to provide a consistent interface to acquire media.","The media source  provides one or more media presentation  objects (media presentation). The media presentation  abstracts a description of a related set of media streams. For example, the media presentation  may provide a paired audio and video stream for a movie. Additionally, the media presentation  may describe the configuration of the media source  at a given point in time. The media presentation , for instance, may contain information about the media source  including descriptions of the available streams of the media source  and their media types, e.g. audio, video, MPEG, and so on.","The media source  may also provide a media stream  object (media stream) which may represent a single stream from the media source  which can be accessed by the application , i.e. exposed to the application . The media stream  thus allows the application  to retrieve samples of the media (). In an implementation, the media stream  is configured to provide a single coherent stream of data. For instance, in a WMV file, there may be one media stream for video data and another media stream for audio data and therefore two media streams object may be employed to provide the respective streams.","In the media foundation , therefore, the media source  is defined as a software component which outputs samples for a presentation. The timeline source  interprets the media timeline , but at the same time, may also act in a manner similar to the media source . For example, the timeline source  may be utilized to hide the intricacies of rendering the media timeline  to provide media described by the media timeline  from other components of the media foundation .","The media processor  manages data flow in a topology . The topology  defines how data flows through various components for a given presentation. A \u201cfull\u201d topology includes each of the components, e.g. software modules, used to manipulate the data such that the data flows with the correct format conversions between different components. When a topology is created, the user might choose to create it partially. This partial topology is not sufficient, by itself, to provide a final presentation. Therefore, a component called the topology loader  may take the partial topology and convert it into a full topology by adding the appropriate data conversion transforms between the components in the partial topology.","In the topology , for example, data generally originates at the media source , flows through one or more transforms , and proceeds into one or more media sinks , . Transforms  can include any suitable data handling components that are typically used in presentations. Such components can include those that uncompress compressed data and\/or operate on data in some way, such as by imparting an effect to the data, as will be appreciated by the skilled artisan. For example, for video data, transforms can include those that affect brightness, color conversion, and resizing. For audio data, transforms can include those that affect reverberation and re-sampling. Additionally, decoding and encoding can be considered as transforms.","Media sinks ,  are typically associated with a particular type of media content. Thus, audio content might have an associated audio sink such as an audio renderer. Likewise, video content might have an associated video sink such as a video renderer. Additional media sinks can send data to such things as computer-readable media, e.g. a disk file and the like.","The media session  is a component which may schedule multiple presentations. Therefore, the media processor  may be used to drive a given presentation, and the media session  utilized to schedule multiple presentations. The media session , for instance, may change topologies that are rendered by the media processor . For example, the media session  may change from a first topology that is rendered on the media processor  to a second topology such that there is no gap between the renderings of samples from the consecutive presentations that are described by the respective topologies. Thus, the media session  may provide a seamless user experience as the playback of the media moves from one presentation to another.","The source resolver  component may be utilized to create a media source  from URLs and\/or byte stream objects. The source resolver  may provide both synchronous and asynchronous ways of creating the media source  without requiring prior knowledge about the form of data product by the specified resource.","In at least one embodiment, the media foundation  is utilized to abstract away the specific details of the existence of and interactions between various components of the media foundation . That is, in some embodiments, the components that are seen to reside inside the media foundation  are not visible, in a programmatic sense, to the application . This permits the media foundation  to execute so-called \u201cblack box\u201d sessions. For example, the media engine  can interact with the media session  by providing the media session certain data, such as information associated with the media (e.g. a URL) and the destination , and can forward the application's  commands (e.g. open, start, stop and the like) to the media session . The media session  then takes the provided information and creates an appropriate presentation using the appropriate destination.","The media foundation  may also include a timeline plugin . The timeline plugin  may be utilized such that different media timeline file formats may be \u201cplugged-in\u201d to the media foundation . For example, a bytestream plugin  may be written for a format in question and registered with the media foundation . The source resolver  may then invoke a bytestream plugin  when a file of that type is opened. In turn the bytestream plugin  can parse the file, create a media timeline  representing the presentation described in the file, and create a timeline source  for it. In general, the bytestream plugin  is responsible for reading the raw bytestream and creating a media source  for it. In an implementation, the remaining components of media foundation  are not made aware that the media source created in this instance is a timeline source . Therefore, the timeline source  is treated like any other media source . In an implementation, a bytestream plugin  that can parse a media timeline  and create a timeline source  is referred to as a timeline plugin, which is described in greater detail in relation to .","The timeline plugin  may also provide an interface such that the application  may interact with the timeline plugin directly, such as to load and save the media timeline  from or to a file. For example, the timeline plugin  may be created and then called to initiate a load function to provide a bytestream. The timeline plugin  may then parse the file and create a root node and any additional nodes to create the media timeline , which will be described in greater detail in relation to . The timeline plugin  may also be used to persist the media timeline  to different formats. For example, the application  may create the media timeline  programmatically. In other words, the application may act as the timeline generator  of . The application  may then create a timeline plugin for ASX files, and ask the timeline plugin to save the media timeline  in the ASX format. In another example, a user can open an m3u file, i.e. a playlist file format for specifying multiple MP3 files, get the media timeline  from it, and then ask the timeline plugin to save the media timeline  in the ASX format. In this example, the timeline plugin acts as the timeline generator . Thus, the media foundation  may expose a plurality of software components that provide media functionality over an application programming interface for use by the application .",{"@attributes":{"id":"p-0069","num":"0068"},"figref":["FIG. 3","FIGS. 1 and 2"],"b":["300","300","122","302","312","302","312","314","322","304","306","304","316","304","316","306","308","306","308"]},"In an implementation, the media timeline  is not executable by itself to make decisions about a user interface (UI), playback or editing. Instead, the metadata - on the media timeline  is interpreted by a software and\/or hardware component that renders the media timeline , such as the timeline source  of . Additionally, applications that are utilized during rendering of the media timeline  may obtain relevant metadata for that particular application. For example, the application  of  may be configured as a playback engine that is only interested in the times at which each media referenced in the media timeline is to be started. On the other hand, another application, such as a media player, may be interested in just displaying the titles of the songs, which are stored as metadata on each node. In this way, the metadata may be utilized at the same time by one or more applications that utilize an output of the media.","The nodes -, as positioned on the media timeline , describe a basic layout of the media timeline . This layout may be utilized for displaying a timeline structure in a user interface, utilized by the timeline source  of  to order rendering of the nodes, and so forth. For instance, various types of nodes - may be provided such that a desired layout is achieved. The node type indicates how the children of that node are interpreted, such as a root node  and leaf nodes -. The root node  specifies a starting point for rendering the metadata timeline  and includes metadata  that describes how rendering is to be initiated.","In the illustrated implementation of , the leaf nodes , ,  of the media timeline  directly map to media. For example, the leaf nodes , ,  may have respective metadata , ,  that describes how to retrieve the media that each of the leaf nodes - represent. A leaf node may specify a path for an audio and\/or video file, point to a component which generates video frames programmatically during rendering of the media timeline , and so on. Leaf node , for instance, includes metadata  having a pointer  that maps to input device () that is configured as a microphone. Leaf node  includes metadata  having a pointer  that maps to an address of the media  in a storage device  that is included locally on the computer  of . Leaf node  includes metadata  having a pointer  that maps to a network address of the remote computer  on the network . The remote computer  includes the video camera  to provide media over the network  to the computer  of . Thus, in this implementation, the timeline  does not include the actual media, but rather references the media by using pointers , ,  that describe where and\/or how to locate the referenced media.","Nodes ,  may also describe additional nodes of the media timeline . For example, node  may be utilized to describe the order of execution for nodes , . In other words, node  acts as a \u201cjunction-type\u201d node to provide ordering and further description of its \u201cchildren\u201d. There are a variety of junction-type nodes that may be utilized in the media timeline , such as a sequence node and a parallel node.  describe exemplary semantics behind the sequential and parallel nodes.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 4","b":["400","402","404","406","408","402","402","402","410","404","408","404","406","408","404","408","412","414","416","418","420","422","424","426","428","402"]},"Although the child nodes of the sequence node  are configured as leaf nodes in this implementation, child nodes of the sequence node  may represent any other type of node. For example, child nodes may be utilized to provide a complex tree structure as shown in . Node  of , for instance, is the child of another junction-type node, i.e. node .",{"@attributes":{"id":"p-0076","num":"0075"},"figref":"FIG. 5","b":["500","502","504","506","502","504","506","504","506","508","510","512","514","510","504","502","516","502","506","508","504","502","504","506","516","510","504","518","512","506"]},"Specifying times ,  relative to the previous node allows for defining a sequence where duration output of media referenced by each child node in the sequence is not known. When the start time for a node is not specified, as shown by the metadata  of leaf node , it means that the node, i.e. leaf node , should be immediately start output after the previous node, i.e. leaf node , has finished output.",{"@attributes":{"id":"p-0078","num":"0077"},"figref":["FIG. 6","FIGS. 4 and 5"],"b":["600","602","604","606","608","602","602"]},"The children of the parallel node  may be rendered simultaneously. For example, leaf node  and leaf node  are children of parallel node . Each of the leaf nodes ,  includes respective metadata ,  having respective pointers ,  to respective media , . Each of the leaf nodes ,  includes a respective time ,  included in the respective metadata ,  that specifies when the respective leaf nodes ,  are to be rendered. The times ,  on the leaf nodes ,  are relative to the parallel node , i.e. the parent node. Each of the child nodes can represent any other type of node and combinations of nodes, providing for a complex tree structure with combined functionality. For example, a \u201cjunction\u201d type node may also reference media, and so forth. Although metadata including time data has been described, a variety of metadata may be included on nodes of the media timeline, an example of which is described in the following implementation.","Media Timelines that are Configured to Store Metadata",{"@attributes":{"id":"p-0081","num":"0080"},"figref":"FIG. 7","b":["700","700"]},"Additionally, authors of the media timeline may add custom metadata to the nodes. For example, the application  of  may be configured as a media player that stores album art for a CD track on the leaf node corresponding to that particular track. Standard properties and custom properties may be treated in the same manner so that there is no ambiguity when obtaining the metadata. Therefore, even if each property described by the metadata is provided by a different respective interface or source, the media timeline provides a mechanism to track the various properties.","Further, properties from different sources may be aggregated by treating the metadata in a consistent manner by the media timeline. For example, a playlist may include a plurality of tracks, each having a different composer. Each track of the playlist may be represented as a leaf node that is a child of a sequence node. The media timeline may aggregate the metadata such that a query to the sequence node, i.e. the parent node, returns the composers of all the media in the playlist from each leaf node, i.e. the child nodes. Consistent use of metadata may also provide sorting for each of the nodes. For example, if all properties on a node are treated as metadata, an application may sort the nodes based on any properties defined in the metadata in a consistent fashion.","A node  may include a variety of metadata , such as properties that define playback behaviors and attributes for the nodes. Examples of properties defined by the metadata  are described as follows.","URL ","This property holds the URL for the media. In the case of a file, the URL  property may provide the path to the file. For example, the URL  property may provide a path to a storage device to locate particular media.","SourceObject , SourceObjectID ","In some instances, the source for the media cannot be specified by a URL. For example, a media source for outputting black color frames may not be locatable by a URL. The SourceObject  and SourceObjectID  properties allow the user to specify the media source by specifying an object which can resolve to a media source, such as the media source itself or some other object. When a media source is specified as a source object, SourceObject  property provides a pointer to the media source and the SourceObjectID  property specifies a globally unique identifier of the source object. In an implementation, the SourceObject  property takes precedence over the URL  property in case both are defined.","Start Time , Stop Time ","The start and stop times ,  define at what time the node  is to be started and stopped with respect to the other nodes. For nodes that are children of a parallel node, for instance, the start and stop times ,  are defined relative to the parallel node, i.e. the parent of the children. For nodes that are children of a sequence node, the first child node includes start and stop times ,  that are defined relative to the sequence node. The remaining nodes each include start and stop times that are defined relative to a previous sibling. In an implementation, it is not necessary to define the start and stop times ,  for the node . For example, when the start and stop times ,  are not specified, the start time  is assumed to be zero and the node  is stopped when the rendering of the media referenced by the node  is completed.","Media Start , Media Stop ","Each node in a media timeline may reference media. The media start  and media stop  properties define a portion of the media that is to be output. For example, the node  may represent media from a file having a total length of 50 seconds. The user, however, might want to output only a portion of the media from 20 to 30 seconds in the file. To do this, the media start  may be specified as 20 seconds and the media stop  may be specified as 30 seconds.","The duration of the time period defined by the start time  and stop time  of the node, i.e. \u201cnodetime\u201d need not equal the duration of the time period defined by the media start  and the media stop , i.e. \u201cmediatime\u201d. For example, when the specified nodetime is greater than the mediatime, output of the media referenced by the node  may be slowed. Therefore, the portion of the media defined by the media start  and the media stop  may be output for the duration of the time period defined by the start and stop times ,  of the node, i.e. \u201cnodetime\u201d. In other words, output of the portion may be extended such that the nodetime is equal to the mediatime. In another example, a last frame of the media may be frozen until the nodetime elapses, a video frame can be made blank (e.g., black), and so on. Similarly, if the nodetime is less than the mediatime, the media may be output at a faster rate such that output is finished within the specified nodetime. In a further example, output of the media may be truncated. For instance, any portion of the segment defined by the mediatime that is greater than the nodetime is not output. In an implementation, the media timeline itself does not enforce these behaviors, but rather these behaviors are read by the timeline source  when rendering the media timeline  as described in relation to .","When the media stop  for the node  is not specified, the media referenced by the node  is output until completion. For example, in a player scenario, a user may desire the output of a playlist of media that does not have the duration of each media item referenced. Additionally, \u201cback to back\u201d output of the media included in the playlist may be desired. To represent this case on the media timeline, a sequence node may be created having leaf nodes that are children of the sequence node which do not have a specified media stop  properties.","Time Format ","The time-based properties described previously may have an accompanying time format  property (time format). Examples of time formats include 100 nanosecond units, frame number, time code, and so on. Thus, the time format  may specify the time format for the start time , stop time , media start  and media stop . Additionally, the time format  may specify different formats for each of the time-based properties. For instance, the start and stop times ,  may utilize a time format of 100 nanosecond units, while the media start  and media stop  time formats may utilize frame counts.","Stream Selection ","The stream selection  property can be utilized on the node  in a variety of ways. For example, the stream selection  property may act as a filter such that media having desired characteristics is provided. The node , for instance, may reference both audio and video streams of media, such as a television program. The user, however, may only be interested in only the video stream, even if the URL  specified on the node  points to both the audio and video streams. In such a case, the audio stream from the media is not exposed, such that it appears to the user that the node  provides only video media.","Format Based ","Format based  properties may be utilized to specify other properties such as frame rate, pixel aspect ratio, audio sampling rate, and so on, that are desired from the node . The appropriate transforms for converting to\/from these formats are then inserted into the rendered media timeline during playback.","Loop Count ","The loop count  property may be used to specify how many times the rendering of the node  is to be repeated. For example, if the loop count  property is negative, the output of the media referenced by the node  may be repeated infinitely.","Disabled ","The node  may be disabled by setting the disabled  property. For example, if the disabled  property is set to \u201ctrue\u201d, the node  is ignored during rendering of the media timeline. For instance, a sequence of three leaf nodes may be provided in a media timeline. If the second node in the media timeline is disabled, i.e. the disabled  property is set to \u201ctrue\u201d, output of the media referenced by the media timeline will appear as if the media timeline has only the first and third nodes.","NoSkip ","The NoSkip  property is a feature which can be used by timeline authors to specify media which cannot be skipped during rendering of the media timeline. When the node  is specified as a NoSkip node, i.e. the NoSkip property is set to \u201ctrue\u201d, the user cannot skip to another node after the specified node , and cannot fast forward the media being output as part of that node . The user, however, may skip to any node \u201cbefore\u201d that node . In another implementation, if the NoSkip  property is specified on a parent node, the user will not be able to skip any of the children in the subtree of that node. In a further implementation, the NoSkip  property applies only to a sequence node and its immediate children, e.g. children of the sequence node that directly follow the sequence node instead of being included in a another sequence node that is a child of that sequence node, and is not specified for a parallel node or its immediate children. For example, the NoSkip  property may be used to prevent the skipping of advertisements referenced by leaf nodes that are children of a first sequence node. A second sequence node may also be a child of the first sequence node, and include leaf nodes that reference media that can be skipped, such as a television program.","The NoSkip  property may also be utilized to define collections of nodes through which a user may navigate. For example, a media timeline may include a sequence of ten leaf nodes, with the third and seventh nodes being NoSkip nodes, i.e. the NoSkip property is set as \u201ctrue\u201d. Therefore, the user may skip the rendering of the first and second leaf nodes, but cannot skip to the fourth, fifth, sixth, seventh, eighth, ninth, or tenth nodes. Similarly during the rendering of the media timeline from node four to node seven, the user may skip to any node below the seventh node, but may not skip to a node \u201cabove\u201d the seventh node, i.e. the eighth, ninth and tenth nodes.","NoSkip Child ","Media timelines may support sparse children, i.e. all nodes are not loaded and\/or created on the media timeline when the media timeline is initially loaded. Therefore, the children may be loaded and\/or created as needed. Further discussion of dynamic loading and creation of nodes may be found in relation to . When loading the nodes in a media timeline in this instance, parent nodes may be loaded which have child nodes that are specified as \u201cNoSkip\u201d. To indicate that there is the NoSkip  property for a child node, the NoSkip child  property for the parent node may be used.","The NoSkip child  property may be set at a parent node to indicate whether the parent node includes a child node having the NoSkip  property set as \u201ctrue\u201d. During the rendering of the media timeline, the NoSkip child  is used to indicate that all the previous siblings of a node should be checked to determine if navigation to the node is valid. NoSkip child  may also be set on a parallel node. For example, if any node in a subtree of the parallel node has the NoSkip  property set as \u201ctrue\u201d. In this way, navigation between nodes may be provided that protects the use of the NoSkip  property.","When a node with the NoSkip  property set as \u201ctrue\u201d is added to the media timeline, the media timeline may automatically set the NoSkip Child  property as \u201ctrue\u201d on all the parents of the added node. This way a rendering engine, e.g. timeline source  of , can optimize which nodes of the media timeline to load and check to determine if the NoSkip  property is set as \u201ctrue\u201d.","Timeline Effects","Timeline effects allow the author of a media timeline to specify components which analyze and\/or change the appearance of the media. For example, the author might want to show a video in black & white, add echo to an audio file, show one video on top of another (e.g., picture in picture), and so on. In an implementation, an effect is not a separate node by itself. To provide the effect for the media, the author may specify effects in the metadata in the node. For example, the metadata may include an array of effects that are defined on the node. The array may specify a series of effects to be applied to the output of that node, i.e. when the media referenced by the node is rendered. In this implementation, the effect is not an object which actually implements the effect, but rather specifies properties and attributes which describe how to create and apply the effect. This is similar to how the node references the media in the previous implementations. For example, as discussed in relation to , the leaf nodes - themselves do no contain the media, but rather include respective metadata - having respective pointers , ,  which specify how to obtain the media. The component which actually implements the effect is loaded at runtime by the timeline source that executes the media timeline. Although metadata that includes effect has been described, the effects may also be specified separately. Additionally, in another implementation, the effect is provided by an object in the media timeline that implements the effect.","Effects specified on nodes of a media timeline may have times that are specified relative to the start time of that node. For example, an effect may be specified on a leaf node that has a start time of ten seconds. Therefore, the effect will be applied to the node, when rendered, after that node has begun output and ten seconds have elapsed.","Multiple effects can be specified on a node. Additionally, the author of the media timeline may also control the order in which these effects are applied. For example, the author may set a priority on the effect. There are a variety of effects that may be specified by a node. Examples of effects that can be specified on the media timeline include: (1) a simple effect; (2) a composite effect; and (3) a transition effect. Further discussion of these exemplary effects may be found in relation to .","Simple Effect","A simple effect represents a component which receives a single stream of audio\/video and outputs another stream. In other words, it is a one-in\/one-out component. For example, an echo effect may receive an audio stream and output a modified audio stream that echoes, provide a \u201cblack and white\u201d effect in which video is shown as black and white, an age effect in which video is made to appear as if it was captured several decades ago, and so on.",{"@attributes":{"id":"p-0118","num":"0117"},"figref":["FIG. 8","FIG. 8"],"b":["800","802","804","806","808","810","806","810","812","814","816","806","810","806","808","812","806","810"]},"In an implementation, the duration of the plurality of effects - does not change the duration of the media . For example, the processing of the plurality of effects - may be truncated at the time boundaries of the node . For instance, the rendering of the media  may have a duration of 10 seconds. The processing of the plurality of effects -, however, may have a duration of 20 seconds. In such an instance, the timeline source  of  may finish processing of the plurality of effects - for node  at 10 seconds.","When defining the effects -, the author of the timeline may explicitly specify the inputs and the outputs of each of the effects -. For example, each of the effects - may include data that describes which stream is connected to which effect input. Each of the effects - may also have respective data that describes the major type of the respective effect's - output, e.g. audio, video, and so on. Further, each of the effects - may include metadata that describes a start time and\/or a stop time of the effect within the node.","Composite Effects","A composite effect may be used to process media of the children of a parallel node to give a resultant output. For example,  is an illustration of an exemplary implementation  showing a parallel node  that provides a composite effect to the outputs of two or more child nodes. Parallel node  in this implementation is similar to the parallel node  that was described in relation to .","Parallel node  includes an array of composite effects , , . When specifying a composite effect, the author of the media timeline specifies how to connect the inputs of the effects - and also the major types for the outputs from the effects -. For example, leaf node  and leaf node  may be configured as the children of the parallel node . As previously described, each leaf node ,  includes respective metadata ,  having respective pointers ,  that reference respective media , . The leaf nodes , , when rendered, provide media ,  for output.","The effects , ,  are applied to the output of the media ,  that are specified by the parallel node . For example, the parallel node  may provide a rotating cube with a different media (e.g., video) on each face of the cube, a scrolling roll of film with different media playing in each frame of the film, and so forth.","Although parallel node  was described as applying the plurality of effects - to each of the leaf nodes , , in additional implementations the parallel node  might apply the effects - to only a few of the children of the parallel node . In other words, the effects - need not be applied to all of the nodes that are children of the parallel node . For example, the metadata  and\/or effects - may specify one or more particular nodes to apply one or more of the plurality of effects -.","Transition Effect",{"@attributes":{"id":"p-0127","num":"0126"},"figref":["FIG. 10","FIG. 10","FIG. 4"],"b":["1000","1002","402","1002","1004","1006","1008","1002","1004","1008","1014","1018","1020","1024","1026","1030"]},"The sequence node  include metadata  that describes a transition effect  that is to be employed between output of the media - referenced by the respective leaf nodes -. Thus, the transition effect  is applied to the media - originating from the children of the sequence node . The transition effect  is utilized to combine two or more media - into a single output. Additionally, the transition effect  may include data that specifies one or more of leaf nodes - to which the transition effect is to be applied. For example, the data may specify that the transition effect  is to be employed between the output of media , . The first input to the transition effect  is supplied by the node for which it is defined, i.e. leaf node . The next input to the transition effect  is the next node in the sequence, i.e. leaf node . Example of transition effects include an audio cross fade between two nodes that are output in sequence, a \u201cswipe\u201d of a first video with a second video, and so on.","The transition effect  has a duration . The duration  may be used to specify an amount of overlap desired between the two or more nodes in a sequence. For example, the second input in the sequence, i.e. media , may be output such that it overlaps for the duration  of the transition effect . Hence, an output duration of the sequence node  becomes a function of the times specified on the leaf nodes - and the overlap specified by the duration  of the transition effect .","Global effects may also be specified. For example, the transition effect  may specify a global transition for each of the children of that node, e.g. leaf nodes - of sequence node . Therefore, if the author of a media timeline desires the use of the same transition for all the leaf nodes -, the author may do so by specifying the transition effect  as a global transition. Thus, by specifying a global transition, the author need not specify a separate transition for each node.","Effect Metadata",{"@attributes":{"id":"p-0132","num":"0131"},"figref":["FIG. 11","FIG. 7"],"b":["1100","1102","1104","1106","704","702","1106","1106","1106","1106"]},"Effect Object GUID ","Similar to how nodes may reference media, an effect may reference a transform object that provides the effect. The effect object GUID  property specifies the GUID to be used to create the transform object that provides the effect. For example, during output of the media, the transform object referenced by the effect object GUID  may be created when needed to provide the effect.","Effect Object ","The node  may utilize the effect object  property as a pointer to reference an effect object that provides the effect. The referenced effect object may be used directly during output of the media of the node . The effect object  property takes precedence over the effect QUID, if both are specified.","Priority ","As previously described, when effects are concatenated together, the priority  property may be used to specify the ordering of the effects. If there is more than one effect with the same priority, the effects are applied in the order in which the effects were added to the node .","Start Time , Stop Time ","The start and stop times ,  are specified relative to the node  on which the effect is specified. The start and stop times ,  define the time at which the effect will be active. If these properties are not specified, the effect will be applied for the entire duration of the output of the media referenced by the node . These properties can be applied to both simple effects that were described in relation to  and composite effects that were described in relation to .","Time Format ","The start and stop times ,  may be specified in a variety of formats. The time format  property may be used to specify the format of these time values. A variety of time formats may be utilized, such as 100 nano-second units, frame numbers, time codes, and so on.","Duration ","As previously described in relation to , the duration  property may be used to specify the duration of a transition between the output of respective media. For example, the duration  may be used to specify an amount of overlap between the output of media referenced by two consecutive nodes.","Number of Inputs , Number of Outputs ","Simple effects utilize one input and one output, and therefore the number of inputs and outputs ,  may be set automatically in the media timeline for simple effects. A transition effect may employ two inputs and one output. Therefore, the number of inputs and outputs ,  may also be set automatically in the media timeline for transition effects. For composite effects, an author may define as many inputs and\/or outputs as desired. Therefore, the number of inputs and outputs ,  may be set by the author to reflect the number of inputs and outputs for the transform object that provides the effect.","Output Major Type ","The output major type  is specified for each output of the effect. Specifying output major type  property facilitates connecting the effect to other effects or destinations. For example, the author of a media timeline may readily determine the major type, i.e. audio, video, and so on, of the output and therefore efficiently specify connections between relevant effects, e.g. audio effect to audio effect.","Input Connections ","Once the effect has been defined, the author may specify media that is to be processed by the effect. The input connections  property may be used to identify the media to be connected to each of the effect inputs.","Dynamic Creation and Loading of Nodes of a Media Timeline","Dynamic creation and loading of nodes of a media timeline may be utilized for efficient rendering of the media timeline. By improving rendering efficiency, the media timeline may be utilized on low resource devices, such as devices having limited hardware and\/or software resources. For example, dynamic creation of the media timelines may include delayed creation of the nodes of the media timeline. The children of a parent node, for instance, need not be created until needed. The delayed creation of the nodes may be utilized to improve start-up and response times for media timelines having a significant number of nodes and\/or a large amount of data for each node. For instance, a media player may be utilized to create and playback a playlist from a media library that contains a significant number of selections. Creating such a playlist might require multiple queries to the media library, which may take a significant amount of time, processor and memory resources. By using delayed creation of the nodes, the playlist can be built on an \u201cas needed\u201d basis, thereby utilizing only as much processing and memory resources as required by the nodes needed at any one particular time. There are a wide variety of implementations that may be utilized for dynamic creation and\/or loading of nodes of a media timeline.",{"@attributes":{"id":"p-0153","num":"0152"},"figref":"FIG. 12","b":["1200","1200","1202","1204","1216","1202","1200","1202","1218","1218","1220","1204","1206","1202","1204","1206"]},"During or after the rendering of media referenced by the node , metadata  of node  is examined that specifies a second grouping  that includes node  and . Therefore, node  and  are loaded and media is output that is referenced by node . Likewise, the metadata  of node  specifies a third grouping  that includes nodes , , . Therefore, nodes , ,  are loaded to output data referenced by nodes ,  after the output of data referenced by node  is completed.",{"@attributes":{"id":"p-0155","num":"0154"},"figref":["FIG. 13","FIG. 12","FIG. 7","FIG. 1"],"b":["1300","1200","1302","1300","1300","1304","1302","1304","1304","1302","1306","1308","1306","1308","1310","1312","1306","1308","1304","1306","1308","1304","1306","1308","124"]},"Dynamic Changes to Nodes in a Media Timeline","In one or more implementations, the media timelines are configured to be dynamically changed. For example, nodes of the media timeline may be removed, added or changed during the rendering of the media timeline by a timeline source. To provide for dynamic changes to the nodes, each node can generate events.",{"@attributes":{"id":"p-0158","num":"0157"},"figref":"FIG. 14","b":["1400","1400","1400","1402","1404","1412","1402","1408","1410"]},"Each of the nodes - may generate events that may be utilized to inform other nodes of the media timeline  that may be affected by changes to the node and\/or changes to children of that node. For example, all events for node  and any children of the node , i.e. nodes -, may be communicated to the root node  and\/or the author of the media timeline . In other words, events in the media timeline  may progress \u201cup\u201d the tree to the root of the tree. In this way, eventing may be utilized inform various nodes of the media timeline  about dynamic changes to the timeline structure. Additionally, nodes of the media timeline  may subscribe to events initiated by other nodes of the media timeline. Node , for instance, may subscribe to receive events from node  even though node  is not a \u201cparent\u201d of the node . Furthermore, components using the timeline, e.g. the media foundation  components of , can register to receive events initiated by any of the nodes. A variety of events  may be supported by one or more nodes -, examples of which are described as follows.","Node Added ","This event is issued when a node is added to the media timeline . For example, node  may be added to the media timeline  to provide output of additional media referenced by the node . Node , when informed of the adding of node , may issue the node added  event such that it is communicated to the root node  through node . Thus, in this example, each node - that is a parent of the newly added node  is notified of events that are initiated by children of that node.","Node Removed ","The node removed  event is issued when a node is removed from the media timeline . Continuing with the previous example, node  may be removed from the media timeline  to remove the output of the media referenced by the node . Node , when informed of the removal of node , may issue the node removed  event such that it is communicated to the root node  through node . Thus, in this example, each node - that is a parent of the removed node  is also notified.","Node Changing ","The node changing  event is issued when metadata on a node of the media timeline  is being changed. Node , for instance, may include metadata, such as the metadata  described in relation to . Changes to the metadata may cause the node  to issue the node changing  event, which may be communicated to the application  of  and\/or parents of the node , i.e. nodes , . Thus, the node changing  event may be utilized to inform other nodes and\/or applications that utilize the node that changes are being made to the node , and therefore respond according, such as to wait to render the node until a node changed  event is received.","Node Changed ","The node changed  event is issued when metadata on a node of the media timeline  has been changed. Continuing with the previously example, node  issued the node changing  event such that other nodes and\/or applications are informed that changes are being made to the node . When the changes are complete, the node  may issue the node changed  event to inform the applications and\/or nodes that the changes have been completed. In this way, the node  may utilize the node changed  event to inform that it is ready for rendering.","Remove Children ","The remove children  event is issued when all of the children of a node are removed. Nodes , , for instance, may be removed from the media timeline . Node  issues the remove children  event to inform the root node  that the children, i.e. nodes , , of node  have been removed. Thus, the remove children  event may be utilized instead of issuing the node removed  for each of the nodes , .","Node Source Added , Node Source Removed ","The node source added  event is issued when a node source is added to a node, such as the node source  described in relation to . Likewise, the node source removed  event is issued when a node source is removed from a node.","Node Sorted ","The node sorted  event is issued when one or more nodes are sorted. For example, the media timeline  may support a function in which the nodes - are sorted according to one or more criteria, such as chronologically, based on dependencies, and so forth. Therefore, the node sorted  event may be initiated by the node  when that node and\/or children of the node  (e.g., nodes , ) are sorted.","Node Moved ","The node moved  event is issued when a node is moved. For example, the node  may be moved in the media timeline  such that the node  is a child of a different node, e.g. node . Therefore, the node moved  event may be initiated by the node  and\/or a parent of the node (e.g. the previous parent and\/or the new parent node) when node  is moved.","Read-Only Media Timelines","The author of a media timeline can mark all or a portion of the media timeline as read-only. This may be utilized to protect the functionality of the media timeline. In a first scenario, the author of the timeline does not want the user to change the media experience, such as to skip and\/or delete advertisements. In another scenario, the author might want to dynamically change the media timeline, but does not want other components to modify it. In yet another scenario, the author might allow other components to set custom metadata on the timeline nodes, but not add new children to the timeline.","The media timeline can be customized to suit one or all of these read-only scenarios. Read-only media timelines may be implemented by creating a read-only wrapper of a media timeline. The read-only wrapper contains nodes which mirror the structure of the original timeline, i.e. are \u201ccloned\u201d from the nodes of the original timeline. The cloned nodes of the read-only media timeline may contain pointers back into the original timeline's nodes. Additionally, each of the cloned nodes may be configured to subscribe to events generated on the nodes of the original timeline. This allows the cloned timeline's structure to be kept updated as the original media timeline changes, such as changes to the structure of the \u201ctree\u201d of the original media timeline.","The cloned nodes of the read-only media timeline may be configured to fail functions which allow the user to add\/remove nodes to the read-only media timeline. When creating a read-only timeline, the author may also specify whether metadata for the cloned nodes should be modifiable. This design allows the author of the media timeline to modify the media timeline as much as desired while other components, e.g. applications that execute the read-only media timeline, have read-only or restricted access to the media timeline structure.","In an implementation, metadata  of the root node  of the media timeline  of  may be marked such that the media timeline  may not be edited by a user. In another implementation, a particular node and\/or groupings of nodes of the media timeline may be marked as read-only. For example, referring again to , the metadata  of leaf node  may be marked as read-only. In another example, the metadata  of node  is marked as read-only such that node , leaf node  and leaf node  may not be edited.","Exemplary Media Timeline Implementations","The media timelines previously discussed may employ a variety of methods of storing and restoring timeline data, such as one or more Windows\u00ae Media Player Playlist files, eXecutable Temporal Language (XTL) files, and so on.","A media timeline, for instance, may be described as the following Windows\u00ae Media Player Playlist file identified by an ASX file extension.\n\n","Another example of a media timeline is shown in the following XTL file.",{"@attributes":{"id":"p-0185","num":"0195"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"<timeline>"},{"entry":"<group type=\u201cvideo\u201d>"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003<track>"},{"entry":"<clip src=\u201cV1.wmv\u201d start=\u201c0\u201d stop=\u201c30\u201d mstart=\u201c50\u201d mstop=\u201c80\u201d \/>"},{"entry":"<clip src=\u201cV2.wmv\u201d start=\u201c30\u201d stop=\u201c40\u201d mstart=\u201c0\u201d \/>"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003<\/track>"},{"entry":"<\/group>"},{"entry":"<group type=\u201caudio\u201d>"},{"entry":"\u2003\u2003\u2003\u2003\u2003\u2003<track>"},{"entry":"<clip src=\u201cAl.asf\u201d start=\u201c20\u201d stop=\u201c40\u201d mstart=\u201c0\u201d \/>"},{"entry":"<clip src=\u201cA2.asf\u201d start=\u201c40\u201d stop=\u201c60\u201d mstart=\u201c0\u201d \/>"},{"entry":"<\/track>"},{"entry":"<\/group>"},{"entry":"<\/timeline>"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}},"br":{}},"The XTL file may be represented by the media timeline  that is shown in  that includes a parallel node  having two child sequence nodes , . In this example, sequence node  has a major type  filter set as \u201cvideo\u201d and sequence node  has a major type  filter set as \u201caudio\u201d. Sequence node  has two child leaf nodes , . Leaf node  includes metadata that specifies a start time  of \u201c0\u201d, a stop time  of \u201c30\u201d, a media start  of \u201c50\u201d, and a media stop  as \u201c80\u201d. Leaf node  include metadata that specifies a start time  of \u201c30\u201d, a stop time  of \u201c40\u201d, and media start  as \u201c0\u201d. It should be noted that leaf node  does not include a media stop time, therefore the entire length of the media referenced by the leaf node  will be output.","Sequence node  also has two child leaf nodes , . Leaf node  includes metadata that specifies a start time  of \u201c20\u201d, a stop time  of \u201c40\u201d, and a media start  of \u201c0\u201d. Leaf node  include metadata that specifies a start time  of \u201c40\u201d, a stop time  of \u201c60\u201d, and media start  of \u201c0\u201d.",{"@attributes":{"id":"p-0188","num":"0198"},"figref":"FIG. 17","b":["1700","1702","1704","1702","1704","1706","1702","1704","1706","1702","1704","1706","1702","1702","1704","1706","1702","1704"]},{"@attributes":{"id":"p-0189","num":"0199"},"figref":["FIG. 18","FIG. 17"],"b":["1800","1706","1800","1802","1804","1806","1802","1808","1810","1802","1812","1804","1814","1816","1806","1818","1820"]},"Leaf node  also includes a pointer  that references the A1.asf  file described in relation of . Likewise, leaf node  includes a pointer  that references the A2.asf file  that was described in relation to . Thus, when the media timeline  is executed, the A1.asf  file and the A2.asf file  are output in a manner that employs the effect  as shown in .","Timeline Source",{"@attributes":{"id":"p-0192","num":"0202"},"figref":["FIG. 19","FIG. 2","FIG. 2"],"b":["1900","1900","208","214","124","204","202","124","122","210","124","122","204","214","212"]},"The timeline source  manages a media presentation by interpreting the media timeline  to determine which of the media () of  is to be output at any one particular time. For example, the timeline source  may determine a topology for providing a presentation described by the media timeline . As previously described, the topology defines how data flows through various components for a given presentation. A topology may be a \u201cfull\u201d topology that includes each of the components, e.g. software modules, used to manipulate the data such that the data flows with the correct format conversions between different components. A topology may also be a \u201cpartial\u201d topology which describes the media and a source for the media, but does not specify each component of the \u201cfull\u201d topology, such as appropriate data conversion transforms, destinations, and the like.","The timeline source , for instance, may pass the topologies, full or partial, generated by the timeline source  from the media timeline  to the media processor . The media processor  is responsible for managing data flow in a topology. If the topology received from the timeline source  is a partial topology, a topology loader may be utilized to resolve the partial topology into a full topology as previously described. For example, media stream ()-() components (media stream) may be utilized to represent separate streams of media. Similar numbers are utilized to indicate that the media stream components ()-() correspond to the media stream  of . Additionally, transform objects such as codecs (), (), may be employed to provide appropriate data conversions between software components. Further, software components for supplying effects ()-() specified by the media timeline  may also be provided as was described in relation to  may also be instantiated. Bitpumps (), () are provided to communicate mediate output from the media processor  to respective media sinks (), (). The media sinks (), () are utilized to represent \u201cwhere\u201d the presentation is to be presented (e.g. a window, disk file, and the like) and what happens to the presentation. Thus, through interpretation of the media timeline  by the timeline source , the timeline source  may provide one or more topologies that are suitable for providing a presentation of the media that is described by the media timeline , further discussion of which may be found in relation to .","Timeline Source as a Media Source","The timeline source is also a regular media source from which samples can be extracted. In other words, regular operations which can be performed by the media source  of  can also be performed on a timeline source. Example of media source operations include transport operations such as Start, Stop, Pause and other operations such as setting the rate, retrieving rate capabilities, and so on.","A timeline source can be created directly, such as by the application  of . The timeline source can also be created through the source resolver  as described in relation to . The source resolver  of , for instance, may utilize a URL, a byte stream, and so on, and creates the media source  and obtain media from it. A variety of media timeline formats may be resolved by a timeline source, such as ASX and XTL file formats that were described in relation to . An example of pseudo code for an exemplary method of creating a timeline source may be represented as follows:","IMFSourceResolver* pSourceResolver=NULL;","hr=MFCreateSourceResolver(&pSourceResolver);","\/\/error handling","hr=pSourceResolver->BeginCreateObjectFromURL(pwszURL, this, NULL);","\/\/error handling","It should be noted that the pseudo code may be the same as an author may utilized to create other media source. Through use of the timeline source, data can be sourced for complex presentations with the same ease as a simple media source for applications which do not have intricate knowledge about media timelines.","In an implementation, the timeline source uses other internal media sources of the media foundation, such as media source  of the media foundation  of , to retrieve media (). In other words, the timeline source is not the originator of the media, but rather abstracts the provision of the media such that other software components need not be aware of where or how the media was obtained. Thus, the timeline source may hide the underlying media sources, such as by wrapping the underlying media source's presentation descriptors into its own presentation descriptors and wrapping underlying streams of media into its own streams.","The timeline source may also wrap events initiated by media sources it references. Status of a media source referenced by the timeline source may be communicated through events. The timeline source \u201clistens\u201d to the events from the media sources it resolves and uses internally and communicates relevant events to software components which interact with the timeline source, e.g. the media session  of . The timeline source may also provide events which are initiated by the timeline source itself.","In an implementation, multiple sources may be referenced to provide a presentation. In such an instance, operations that are performed on the timeline source are communicated to the media sources, if relevant. For example, consider a Start( ) call. When Start( ) is called on a media source, the calling software component expects to receive one source started event from the media source. Because the timeline source may be configured to appear as a media source, the timeline source adheres to the same protocols. For instance, a media timeline may include a parallel node and three child nodes that are to be played together. The timeline source first resolves the media sources for each of the three child nodes. The timeline source then retrieves a presentation descriptor from each of the nodes and creates a new presentation descriptor that wraps all the streams of media referenced by the underlying media sources. When a start call is made on the timeline source with this presentation descriptor, the timeline source makes a start call on the three child nodes. In response to the three Start( ) calls, the timeline source receives three SourceStarted events, one from each of the child nodes. After receiving all three events, the timeline source initiates its own SourceStarted event. Thus, the software component that interacts with the timeline source receives only one event such that the three distinct sources of the media are hidden.","Timeline Source Service","Media sources may expose optional functionality through the use of services. The timeline source may also expose these services, as well as additional timeline source specific services through a timeline source interface, which will be referenced in the following discussion as \u201cIMFTimelineSource\u201d. This interface is primarily for retrieving information about the underlying timeline. It also provides control for execution of the timeline. The timeline service interface may provide a variety of methods, examples of which are described as follows.","IMFTimelineSource:: GetRootTimelineNode( )","The GetRootTimelineNode method provides a way for an application to obtain the root node of the media timeline being rendered by the timeline source.","IMFTimelineSource:: GetNodes( )","The GetNodes method returns the leaf nodes which are part of the given presentation.","IMFPresentationDescriptor","The timeline source initiates new presentations through the use of presentation descriptors. A presentation descriptor is represented by the IMFPresentationDescriptor interface. In an implementation, this interface does not provide media timeline specific information. Rather, the presentation descriptor of a presentation may be accessed, during rendering, from the media processor and\/or the media engine. In the case of a media timeline, however, an application may want to determine more than just which presentation is being rendered, but also which node of the media timeline is being rendered. A GetNodes function may be utilized to provide this capability. Thus, given a presentation descriptor, the GetNodes function may be utilized to locate nodes which correspond to the presentation.","IMFTimelineSource:: GePlaybackDuration( )","This function may utilized to provide an indication of a playback duration of a particular node. As previously described, the output duration for a node need not be specified on the media timeline. This information, however, may be available during playback. Therefore, this function may be utilized to inform the application of the output duration that is calculated when the presentation is rendered.","IMFTimelineSource:: GetLocalTime( )","The GetLocalTime method returns a time with respect to a given node. For example, when a media timeline is rendered, a presentation clock may be utilized to indicate a time for a particular presentation. This time, however, may not be sufficient for an application that interacts with a media timeline. For instance, the application may wish to determine progress of the rendering with respect to the entire media timeline. In another instance, the application may wish to determine a current duration of media that has been output by a particular node. Therefore, the GetLocalTime function may be utilized to provide a translation from a presentation time to a desired time with respect to a given node.","IMFTimelineSource:: BeginNodePreroll ( ) and IMFTimelineSource:: EndNodePreroll ( )","In the timeline source, prerolling refers to an operation of resolving a media source for a node and reading the media source for rendering. As the timeline source interprets the presentations defined on the media timeline, the timeline source prerolls the nodes in the order for rendering. BeginNodePreroll, EndNodePreroll are asynchronous functions which allow the user, e.g. the application  of , of the timeline source to preroll a node on demand. In an implementation, this is independent from prerolling which is already provided by the timeline source automatically. For instance, if the application desires to \u201cjump\u201d to a node which is not yet ready for playback, the applications may first preroll the node. When the node is ready, the application may then jump to it and expect a quick response from the timeline source.","Execution Plugin","The execution plugin allows the application to override the normal execution of the timeline source. For example the timeline source may render all the nodes in a sequence, one after the other. The application  of , however, may be configured as a media player that supports a shuffle mode, where nodes are randomly rendered. For such instances, the application may utilize the execution plugin to override the regular media timeline rendering by the timeline source. The execution plugin supports a variety of methods, examples of which are listed as follows:\n\n","Interpreting a Media Timeline by a Timeline Source","Given a media timeline, the timeline source may utilize a variety of techniques to divide the media timeline into distinct presentations. As previously described in relation to , a presentation refers to or describes the handling of media. A presentation can result in visually and\/or audibly presenting media, such as a multimedia presentation in which both audio and accompanying video is presented to user via a window executing on a display device. A presentation can also result in writing media to a computer-readable medium such as a disk file. Thus, a presentation may include a wide variety of media scenarios, such as decoding, encoding and various effects, can take place as a result of the presentation and is not limited to scenarios in which multimedia content is rendered on a computer. Each presentation includes a presentation descriptor and a topology. A segment can be described as a interval of time where the components in a topology do not change, e.g. components included in the topology are not added and\/or removed.",{"@attributes":{"id":"p-0225","num":"0239"},"figref":["FIG. 20","FIG. 4"],"b":["2000","2002","2004","2006","2002","402","2004","2006","2002","2004","2006","2008","2010","2012","2014","2016","2018"]},"Additionally, the sequence node  may include metadata  that describes a transition effect  to an output of the media ,  referenced by the leaf nodes , . The transition effect  is utilized to combine the media ,  into a single output. Thus, the first input to the transition effect  is supplied by leaf node  and the next input to the transition effect  is supplied by leaf node .",{"@attributes":{"id":"p-0227","num":"0241"},"figref":["FIG. 21","FIG. 20","FIG. 21","FIG. 20"],"b":["2100","2000","2004","2004","2006","2006","2016","2018","2004","2006"]},"The transition effect  is specified for output between the media referenced by leaf node  and the media referenced by leaf node . The transition effect , when executed, combines media referenced by the leaf nodes ,  to provide a single output of media having the applied effect.","The timeline source interprets the media timeline  of  by examining the media timeline  to determine individual presentations ()-() of the media timeline  during which software components utilized to render the media do not change for a particular interval of time. As illustrated, presentation () describes a time interval between \u201c0\u201d and \u201c10\u201d during which media referenced by leaf node  is rendered. Therefore, during presentation (), only software components utilized to render the media  are utilized. Likewise, presentation () describes a time interval between \u201c20\u201d and \u201c30\u201d during which media referenced by leaf node  is rendered. Therefore, for presentations (), (), software components utilized to render media referenced by respective leaf nodes ,  do not change during a respective time interval.","Presentations may also describe rendering of a plurality of media. Presentation (), for instance, specifies media for rendering that is referenced by both leaf nodes , . Additionally, presentation () also describes the transition effect  to be applied to the media - of . Even though a plurality of media is described for rendering according to a transition effect , software components utilized during the particular time interval, i.e. 10 to 20, corresponding to presentation () do not change. In this way, the timeline source may divide the timeline  of  into individual presentations ()-() such that each of the presentations ()-() describes rendering of media for a particular time interval during which software components utilized to provide the rendering do not change.","For each of the presentations ()-(), the timeline source may then generate a respective topology ()-() for providing the described rendering. For example, topology () references software components utilized to provide the rendering described by leaf node . Topology () references software components that are utilized to provide the rendering of leaf nodes ,  and the transition effect . Topology () references software components that are utilized to provide the rendering described by leaf node . The timeline source may then provide the topologies ()-() for rendering at the specified time interval, which is described in greater detail in the following implementation.",{"@attributes":{"id":"p-0232","num":"0246"},"figref":"FIG. 22","b":["2200","2202"]},"One technique which may be utilized to examine the media timeline utilizes a software module called the \u201cnode sorter\u201d. The node sorter walks the tree-structure of the media timeline and organizes the nodes and any corresponding effects into an array. For example, the nodes may be organized based on respective start and stop times that are specified in the metadata of each node, as was described in relation to . Every unique time value in the array identifies a particular interval of time. Nodes and\/or effects which have started before or at this time value are included in the particular interval of time.","At block , based on the examining, the media timeline is divided into one or more presentations. Each of the presentations describes rendering of media for a particular interval of time described by the media timeline. As previously described, each of the presentations may reference a respective interval of time, during which, software components utilized to provide the described rendering do not change.","At block , each software component referenced by a first one of the presentations is loaded. The first presentation, for instance, may be utilized to create a partial topology that references a source of desired media. The partial topology may be resolved to form a full topology that references each software component that, when executed, provide the media in the described manner. For example, the full topology may include transform objects, which were not specified in the partial topology, to provide data conversions. These topologies can then be given to the media processor to drive the data through the various components.","At block , the first presentation is rendered. For example, each software component referenced in the first presentation may be executed as described by the presentation to process media referenced by the presentation. At block , each software component referenced in a second one of the presentation is loaded. In an implementation, block  is performed during the rendering of the first presentation of block . At block , when the rendering of the first presentation is completed, the second presentation is rendered. In this way, the timeline source may provide successive topologies that include software components that, when executed, provide the described rendering for a particular interval of time. Thus, through utilization of the timeline source, each software component referenced by the media timeline need not be loaded and\/or created during loading of the media timeline, but rather may be created and\/or loaded on an \u201cas needed\u201d basis.","Timeline Source Interaction in the Media Foundation","The timeline source may interact with other media foundation components, such as the media foundation components that were described in relation to , to render the media timeline. In the following implementations that are described in relations to , generation and rendering of the media timeline is described that also references the software components of the media foundation that were described in relation to .",{"@attributes":{"id":"p-0239","num":"0253"},"figref":["FIG. 23","FIGS. 15-18"],"b":["2300","2302","202","208"]},"At block , the media engine  invokes the source resolver  to resolve the URL to a media source. At block , the source resolver  resolves the URL to a bytestream. At block , the source resolver  invokes the bytestream plugin  that is registered for the specified format of the bytestream. At block , the bytestream plugin  creates the media timeline  by parsing the bytestream.","At block , the bytestream plugin  creates the timeline source  and specifies the media timeline  as an input. As previously discussed, the timeline source  may act as a media source to provide media for rendering.","At block , the timeline source  interprets the media timeline  to identify a first presentation. For example, the timeline source  may examine the media timeline  and divide it into one or more presentations. At block , the timeline source  resolves media sources for the first presentation using the source resolver  and creates a presentation descriptor and a topology for the first presentation. The topology may include effects that are specified by the media timeline . The presentation descriptor may be utilized to distinguish each presentation, one from another. At block , the bytestream plugin  returns control of the timeline source  to the source resolver , and at block , the source resolver  returns control of the timeline source  to the media engine . Thus, the media engine  is ready to initiate rendering of the media timeline  by the timeline source , which is described in greater detail in the following implementation.",{"@attributes":{"id":"p-0243","num":"0257"},"figref":["FIG. 24","FIG. 22","FIG. 23"],"b":["2400","122","124","2402","124","2314"]},"At block , the media engine begins to resolve the partial topology by obtaining a destination for media referenced by the first presentation from the application . For example, the partial topology of block  may specify a source of the media, but may not supply a destination for the media. Therefore, the media engine  may obtain the destination  from the application . The destination  may be represented by the media engine  through one or more media sinks , . At block , the media engine  completes resolution of the partial topology to a full topology. The media engine , for instance, may supply one or more transform objects that provide data conversion, supply one or more effect objects to provide effects specified in the partial topology, and so forth.","At block , the media engine  sets the full topology on the media session . At block , the media session  sets the full topology on the media processor . As previously stated, the media processor  may be used to drive a given presentation, and the media session  utilized to schedule multiple presentations. The media session , for instance, may change topologies that are rendered by the media processor .","At block , the media processor  is configured to \u201cdrive\u201d the topology and calls \u201cstart\u201d on the timeline source . At block , the timeline source  initiates all media sources referenced in the current presentation, e.g. the first presentation. If multiple media sources are present, the timeline source  aggregates events from the multiple media sources to provide a single corresponding event to the media processor .","At block , the timeline source  determines a next presentation specified by the media timeline . For example, the timeline source  may obtain another presentation that was interpreted at block  of , interpret another presentation from the media timeline  during the execution of the media sources at block , and so forth. The timeline source , for instance, may create a presentation descriptor and a topology for the next presentation.","At block , the timeline source  initiates a \u201cnew presentation\u201d event to the media session  through the media processor . At block , the media session  queues the topology for the next presentation. At block , when the rendering of the current presentation is complete, e.g. media referenced by the first presentation has been processed by the software components as described, the next topology is set on the media processor  by the media session . At block , the timeline source  then receives another start call for the next presentation. Thus, the timeline source  may initiate the media sources as was previously described in relation to block . The procedure  is completed when each presentation is rendered.","Exemplary Operating Environment","The various components and functionality described herein are implemented with a number of individual computers.  shows components of a typical example of a computer environment , including a computer, referred by to reference numeral . The computer  may be the same as or different from computer  of . The components shown in  are only examples, and are not intended to suggest any limitation as to the scope of the functionality of the invention; the invention is not necessarily dependent on the features shown in .","Generally, various different general purpose or special purpose computing system configurations can be used. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, network-ready devices, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like.","The functionality of the computers is embodied in many cases by computer-executable instructions, such as software components, that are executed by the computers. Generally, software components include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Tasks might also be performed by remote processing devices that are linked through a communications network. In a distributed computing environment, software components may be located in both local and remote computer storage media.","The instructions and\/or software components are stored at different times in the various computer-readable media that are either part of the computer or that can be read by the computer. Programs are typically distributed, for example, on floppy disks, CD-ROMs, DVD, or some form of communication media such as a modulated signal. From there, they are installed or loaded into the secondary memory of a computer. At execution, they are loaded at least partially into the computer's primary electronic memory.","For purposes of illustration, programs and other executable program components such as the operating system are illustrated herein as discrete blocks, although it is recognized that such programs and components reside at various times in different storage components of the computer, and are executed by the data processor(s) of the computer.","With reference to , the components of computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISAA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as the Mezzanine bus.","Computer  typically includes a variety of computer-readable media. Computer-readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media. \u201cComputer storage media\u201d includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules, or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer . Communication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more if its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of any of the above should also be included within the scope of computer readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or software components that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation,  illustrates operating system , application programs , software components , and program data .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only,  illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through a non-removable memory interface such as data media interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface.","The drives and their associated computer storage media discussed above and illustrated in  provide storage of computer-readable instructions, data structures, software components, and other data for computer . In , for example, hard disk drive  is illustrated as storing operating system \u2032, application programs \u2032, software components \u2032, and program data \u2032. Note that these components can either be the same as or different from operating system , application programs , software components , and program data . Operating system \u2032, application programs \u2032, software components \u2032, and program data \u2032 are given different numbers here to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer  through input devices such as a keyboard , and pointing device (not shown), commonly referred to as a mouse, trackball, or touch pad. Other input devices may include source peripheral devices (such as a microphone  or camera  which provide streaming data), joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through an input\/output (I\/O) interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port, or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video adapter . In addition to the monitor , computers may also include other peripheral rendering devices (e.g., speakers) and one or more printers which may be connected through the I\/O interface .","The computer may operate in a networked environment using logical connections to one or more remote computers, such as a remote device . The remote device  may be a personal computer, a network-ready device, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to computer . The logical connections depicted in  include a local area network (LAN)  and a wide area network (WAN) . Although the WAN  shown in  is the Internet, the WAN  may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the like.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the Internet . The modem , which may be internal or external, may be connected to the system bus  via the I\/O interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote device . By way of example, and not limitation,  illustrates remote software components  as residing on remote device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","Although the invention has been described in language specific to structural features and\/or methodological acts, it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described. Rather, the specific features and acts are disclosed as exemplary forms of implementing the claimed invention."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":[{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0014","num":"0013"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0018","num":"0017"},"figref":"FIG. 8"},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 9"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 10"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 11"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 12"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 13"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 14"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 15"},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 16"},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 17"},{"@attributes":{"id":"p-0028","num":"0027"},"figref":["FIG. 18","FIG. 17"]},{"@attributes":{"id":"p-0029","num":"0028"},"figref":["FIG. 19","FIG. 2"]},{"@attributes":{"id":"p-0030","num":"0029"},"figref":"FIG. 20"},{"@attributes":{"id":"p-0031","num":"0030"},"figref":["FIG. 21","FIG. 20"]},{"@attributes":{"id":"p-0032","num":"0031"},"figref":"FIG. 22"},{"@attributes":{"id":"p-0033","num":"0032"},"figref":"FIG. 23"},{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 24","FIG. 22"]},{"@attributes":{"id":"p-0035","num":"0034"},"figref":"FIG. 25"}]},"DETDESC":[{},{}]}
