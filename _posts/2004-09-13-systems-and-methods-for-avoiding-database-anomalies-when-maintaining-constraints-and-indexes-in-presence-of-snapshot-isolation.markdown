---
title: Systems and methods for avoiding database anomalies when maintaining constraints and indexes in presence of snapshot isolation
abstract: A system and method avoids anomalies in presence of data manipulation language (DML) plans maintaining dependent objects and snapshot isolation. An anomaly due to using a snapshot isolation level within the transaction is detected within a database transaction and the transaction is aborted based upon that detection. Involved in making the anomaly detection is determining whether a view of particular data accessed during the transaction under a snapshot isolation view to ensure read consistency differs from a view of the data under another isolation level, such as the read committed isolation level. Then a detection is made that an anomaly may occur if it is determined that the view of the data accessed during the transaction under the snapshot isolation differs from the view of the data under the other isolation level. Such anomaly avoidance prevents an indexed view being maintained nor a referential integrity constraint validated based on incorrect data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07653665&OS=07653665&RS=07653665
owner: Microsoft Corporation
number: 07653665
owner_city: Redmond
owner_country: US
publication_date: 20040913
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["COPYRIGHT NOTICE AND PERMISSION","FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS","Examples and Sample Implementations"],"p":["A portion of the disclosure of this patent document may contain material that is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure, as it appears in the Patent and Trademark Office patent files or records, but otherwise reserves all copyright rights whatsoever. The following notice shall apply to this document: Copyright\u00a9 2004, Microsoft Corp.","This invention relates to database management systems. More particularly, this invention relates to systems and methods for modifying data in a database while ensuring data integrity and consistency.","A database management system (DBMS) is a collection of programs that enables one to store, modify, and extract information from a database. There are many different types of DBMSs, ranging from small systems that run locally on personal computers to large systems distributed across a network. DBMSs can differ widely. The terms relational, network, flat, and hierarchical all refer to the way a DBMS organizes information internally. The internal organization can affect how quickly and flexibly one can extract information. Requests for information from a database are made in the form of a query. Data modifications in DBMSs are made through data manipulation language (DML) statements. Such statements allow users to insert, update and delete rows from a table in a database, called the target table. The syntax of the insert statement allows defining the values for the columns of the rows to add to the table. The syntax of the delete statement allows for qualifying the rows to remove from the table. The syntax of update allows for both qualifying rows and specifying new values with which the columns will be modified.","The set of rules for constructing DML statements is known as a query language. Different DBMSs support different query languages, although there is a semi-standardized query language called structured query language (SQL). SQL is an ANSI (American National Standards Institute) standard computer language for accessing and manipulating database systems. SQL works with major database programs such as MICROSOFT ACCESS\u00ae, DB2\u00ae, INFORMIX\u00ae, MICROSOFT SQL SERVER\u00ae, ORACLE\u00ae, and SYBASE\u00ae, for example. There are many different versions of the SQL language, but to be in compliance with the ANSI standard, they must support the same major keywords in a similar manner (such as select, update, delete, insert, where, and others).","Transactions involving data manipulation language (DML) statements may experience some blocking and deadlocking due to reading data in presence of concurrent transactions performing data modifications. As a result, a newer type of isolation level called snapshot is designed to allow transactions to read possibly older but mutually consistent versions of data without blocking other transactions. In this way, snapshot isolation can preserve the consistency of query results while reducing the frequency of blocking and deadlocking. Snapshot isolation has, however, introduced new classes of anomalies that can occur when processing DML statements, that require accessing tables other than the target to validate referential integrity constraints or propagate changes to an indexed view (auxiliary scan), which need to be addressed using novel techniques.","In this regard, there is a need for systems and methods avoiding anomalies that occur due to ensuring read consistency with snapshot isolation in a way that will cause minimal service interruption, delay or impact on system performance.","In consideration of the above-identified shortcomings of the art, the invention provides systems and methods for detecting and avoiding anomalies in database transactions. It can be detected from a transaction that an anomaly may occur due to using a snapshot isolation level within the transaction. The transaction can be aborted based upon that detection. This may be performed in part by determining whether a view of particular data accessed during the transaction under the snapshot isolation view differs from a view of the data under another isolation level, such as the read committed (using locking) isolation level. (Note that references to read committed implies using locking). If such data does differ, the transaction may be aborted and rolled back. Otherwise, the transaction may be allowed to proceed. An indexed view will not be maintained, nor a referential integrity constraint validated, if it is detected from the transaction that an anomaly may occur.","An indication may be added to a set of rows resulting from an auxiliary table scan indicating whether each row differs from a view of the data under a snapshot isolation level. This added indication can be propagated in the in the query plan within the database transaction along with the set of rows resulting from the auxiliary table scan to a point before either an indexed view is maintained or a referential integrity constraint is validated. If the added indication indicates that at least one row remaining from the propagated set of rows resulting from the auxiliary table scan differs from a view of the data under a snapshot isolation level, then an anomaly may be determined to exist. Other advantages and features of the invention are described below.","Certain specific details are set forth in the following description and figures to provide a thorough understanding of various embodiments of the invention. Certain well-known details often associated with computing and software technology are not set forth in the following disclosure to avoid unnecessarily obscuring the various embodiments of the invention. Further, those of ordinary skill in the relevant art will understand that they can practice other embodiments of the invention without one or more of the details described below. Finally, while various methods are described with reference to steps and sequences in the following disclosure, the description as such is for providing a clear implementation of embodiments of the invention, and the steps and sequences of steps should not be taken as required to practice this invention.","Overview","Systems and methods are provided for avoiding the effect of anomalies that occur within database transactions due to ensuring read consistency with database systems operating using the snapshot isolation level. The primary way of accomplishing this is to efficiently identify and effectively stop transactions that would cause such anomalies to occur. The identification involves determining situations in which database transactions using a view of the data under snapshot isolation may not be consistent with more recent committed views of the data. In such situations, it is necessary to then verify whether the different views of the data do in fact conflict and then enter a transaction abortion process in which the user may try the transaction again. First, the transactions in which anomalies occur are described in conjunction with through . Next, the example methods and processes for accomplishing anomaly detection and avoidance are described in detail in conjunction with . Then example implementations and examples of such processes are described in detail in conjunction with through using the specific Timelines #2-4 of the sample transactions provided. Finally, and provide a computing and networked environment which will be recognized as generally suitable for use in connection with the systems and methods set forth herein. Because the material in and is generally for exemplary purposes, the corresponding description is reserved for the end of this specification, in the section entitled \u201cexemplary computing and network environment.\u201d","Anomalous Transactions","Referring first to , shown is a block diagram illustrating the processing of DML statements. Processing of DML statements, in MICROSOFT SQL SERVERS for example, is made of two phases. The first part  is read only, and responsible for determining which rows need to be inserted, updated or deleted, according to the type of statement. The second part  consumes the rows provided by the first, and performs the actual data modification.","Together with modifying the target table, the query processor of a DBMS has to ensure that data integrity is not compromised by the execution of the statement. This is achieved by a proper instrumentation of the DML query plan, with actions falling in two categories, either validating a constraint or maintaining a dependent data structure so that its content remains consistent with the target table. This allows subsequent data retrieval queries to receive the same results, independently from whether they read from the base table or a secondary structure. A DML statement can hence be seen as firing actions that were not explicitly described in the original syntax, but that are implicitly required in order to preserve data integrity. The most important and common implicit actions, described in further detail below, are:","Indexed view maintenance","Secondary index maintenance","Check and referential integrity constraint validation","Cascading actions","Full text notifications","Query notifications","A view is a virtual table whose contents are defined by a query. Like a real table, a view consists of a set of named columns and rows of data. However, a view does not exist as a stored set of data values in a database. The rows and columns of data come from tables referenced in the query defining the view and are produced dynamically when the view is referenced. However, indexed views (often referred to in literature as materialized views) are views whose results are persisted in the database and indexed for fast access. As with any other view, indexed views and secondary indexes depend on base tables for their data. Such dependency means that if one changes a base table contributing to an indexed view, the indexed view or secondary index must be updated (i.e., maintained). This is called indexed view maintenance. Also, data is usually spread across several tables, which are related to each other through key columns. Database normalization is used to avoid duplicates in a database, thus avoiding potential errors. Although it's true that database normalization minimizes the chance for errors, it doesn't eliminate them, there is still the need for a set of data-integrity rules that will enforce the relationships between tables and keep the database as consistent as possible.","For example, referring to , shown is a Customers table  and an Orders table . The Orders table  is related to the Customers table  through the Customer_ID key column. The Customer_ID provides the primary key for the Customers table  since there is a unique Customer_ID value for each record, or row, in the Customers table . In the Orders table , the Order_ID is the primary key and the Customer_ID in each row is referred to as a foreign key since it refers to the key of another table (the Customers table  in this case) and there may be the same Customer_ID for multiple different orders. Such is the case in the Orders table  where there are two orders (with Order_IDs  and ) associated with Customer C (having Customer_ID of 3). There may exist a rule (i.e., constraint) that one could not delete a customer while there still exists an order for that customer in the Orders table . The set of these types of rules is called referential integrity, and it is a part of the wider set of rules that enforce data integrity in general. The implementation and enforcement of such rules is called referential integrity constraint validation.","Likewise, cascading actions are actions that must be performed on a secondary table to compensate when a primary table is modified. An example of the relationship between a primary and a secondary table is a one-to-many relationship between a primary table and a secondary table. This is shown the Customers table  and the Orders table , where each customer in the Customers table may have one or more orders in the Orders table. If a Customer_ID of a customer is changed, it must also be reflected in all the customer's orders in the Orders table .","Other implicit actions taken as a result a processing a DML statement are notifications. This occurs when the DBMS supports requests that a notification be generated if executing the same command again produces different results from those obtained initially. One accomplishes this by using a dependency object that detects when the underlying data is changed. For example, these notifications are sent to notify external code when the results of a query changes due to database updates.","Referring next to , shown is a block diagram illustrating the processing of DML statements involving implicit actions. Due to locking and concurrency issues, all of the implicit update actions described above are generally performed  after modifying the base table  as shown in . Also, due to the implicit actions that may be taken when processing a DML plan, it is sometimes necessary to scan tables that were not explicitly referenced in the query statement, in order to preserve data integrity. Such auxiliary tables are introduced in DML query plans performing maintenance of indexed views whose definition contains either one or more tables or aggregates, in referential integrity constraint validation, and in cascading actions scenarios described above.","Auxiliary table scans are performed under the read committed isolation level, independently of the isolation level settings of the current transaction. The isolation level of read committed restricts DBMS transactions to reading only data that has been committed. This isolation level has the effect of blocking a transaction's read operation when the data is exclusively locked by another transaction. This prevents the DML plan from reading uncommitted data, as it would easily lead to data corruption. For example, this may occur when a transaction reads data that is being changed by another transaction that has not yet been committed or rolled back. Referring to the timeline below of a transaction on the database of , User 2 reads Customer A's address as Hickory St, when in fact, the User 1 transaction was changing Customer A's address and had not finished the transaction. User 1 would ultimately change Customer A's address back before committing. This caused User 2 to read, and possibly subsequently act on, incorrect data. This is commonly referred to as a \u201cdirty read.\u201d",{"@attributes":{"id":"p-0046","num":"0045"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Timeline #1"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Step","User 1","User 2"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["1","Begin Transaction",{}]},{"entry":["2",{},"Begin Transaction"]},{"entry":["3","Change customer"]},{"entry":[{},"A's address to"]},{"entry":[{},"Hickory St"]},{"entry":["4",{},"Read Customer A's"]},{"entry":[{},{},"address"]},{"entry":["5","Change customer"]},{"entry":[{},"A's address back"]},{"entry":[{},"to Main St"]},{"entry":["6","Commit"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"However, many DBMSs, such as MICROSOFT SQL SERVER\u00ae, for example, use a number of different isolation levels to govern the tradeoff between consistency of transactions and concurrency of multiple users. Historically, all transactions operated in the context of four isolation levels: read uncommitted, read committed, repeatable read, and serializable. These isolation levels affect the way that transactions take and hold shared locks on data resources. Shared locks are the locks taken when reading data; exclusive locks are the locks taken when changing data through an insert, update or delete statement. Exclusive locks are not compatible with other locks. If a first transaction updates a data row, no other transaction can update that row as long as that first transaction is still running and has not been committed or rolled back. With shared locks, a user may not read a row as long as that first transaction is still running and has not been committed or rolled back. However, without shared locks, a user may still read data that is currently being updated in another user's transaction. In this scenario, isolation levels may be used to prevent certain types of anomalies from occurring during a transaction due to these reads. As one raises a transaction's isolation level, however, one also increases the chances that a transaction's reads may block and deadlock with other transactions.","Even with the relatively low default read committed isolation level (described above), transactions may experience some blocking and deadlocking due to reading data. As a result, a newer type of isolation level called snapshot is designed to allow transactions to read older but consistent versions of data without being blocked by other transactions performing data modifications (as shared locks are always compatible with each other, and thus only updates can lead to blocking). In this way, snapshot isolation can preserve the consistency of the query result while reducing the frequency of blocking and deadlocking.","Snapshot isolation has, however, introduced new classes of anomalies, which need to be addressed using novel techniques. Since snapshot isolation allows a transaction to see a consistent view of the database as of its beginning, together with the transaction's own changes, it must create a virtual snapshot of the database at the beginning of the transaction, so to make concurrent changes made by other users invisible. The new anomalies caused by snapshot isolation are due to conflicting requirements when scanning the auxiliary tables in the DML query plan. In order to prevent corruption, it is necessary to access the currently committed data. Such data could however be different from what the current transaction would normally see under its snapshot if concurrent users have operated changes to the same table and committed them in the meanwhile.","For example, shown below is an anomaly that appears with having an indexed view to maintain. Assume a database has two tables T1 and T2, and an indexed view V defined as their join (a query that combines rows from two or more tables, views, or materialized views). Initially the tables, and consequently the view, are empty. Consider the following transaction timeline:",{"@attributes":{"id":"p-0051","num":"0050"},"tables":{"@attributes":{"id":"TABLE-US-00002","num":"00002"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Timeline #2"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Step","User 1","User 2"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["1","Begin Transaction",{}]},{"entry":["2",{},"Begin Transaction"]},{"entry":["3","Insert row into T1"]},{"entry":["4","Commit Transaction"]},{"entry":["5",{},"Insert row into T2"]},{"entry":["6",{},"Select from V"]},{"entry":["7",{},"Select from T1 join T2"]},{"entry":["8",{},"Commit Transaction"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Below is another example of an anomaly that occurs when using snapshot isolation. This time, the anomaly occurs when there is a referential integrity constraint to validate. Assume a database has two tables PK and FK, with FK referencing PK in a foreign key constraint. Initially the tables are empty. Let's consider the following timeline:",{"@attributes":{"id":"p-0053","num":"0052"},"tables":{"@attributes":{"id":"TABLE-US-00003","num":"00003"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Timeline #3"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"91pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Step","User 1","User 2"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"49pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"84pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["1","Begin Transaction",{}]},{"entry":["2",{},"Begin Transaction"]},{"entry":["3","Insert row into PK"]},{"entry":["4","Commit Transaction"]},{"entry":["5",{},"Insert row into FK"]},{"entry":["6",{},"Select from PK join FK"]},{"entry":["7",{},"Commit Transaction"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Scanning auxiliary tables under the current snapshot could however introduce data corruption in other scenarios, as illustrated in the next example. At the beginning of the following timeline, PK has a row and FK is empty.",{"@attributes":{"id":"p-0055","num":"0054"},"tables":{"@attributes":{"id":"TABLE-US-00004","num":"00004"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":[{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"center"}},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}},{"entry":"Timeline #4"}]}},{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"3"},"colspec":[{"@attributes":{"colname":"1","colwidth":"56pt","align":"center"}},{"@attributes":{"colname":"2","colwidth":"77pt","align":"left"}},{"@attributes":{"colname":"3","colwidth":"84pt","align":"left"}}],"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":["Step","User 1","User 2"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}},{"entry":["1","Begin Transaction",{}]},{"entry":["2",{},"Begin Transaction"]},{"entry":["3",{},"Insert row into FK"]},{"entry":["4",{},"Commit Transaction"]},{"entry":["5","Delete From PK"]},{"entry":["6","Commit Transaction"]},{"entry":{"@attributes":{"namest":"1","nameend":"3","align":"center","rowsep":"1"}}}]}}]}},"br":{}},"Anomaly Detection and Avoidance","Referring next to , is a flow chart illustrating a detailed view of a step in the processes of ,  and that occurs at compile time when building the DML plan. Illustrated is a detailed view of the act, occurring during compile time when building the DML plan, determining whether an auxiliary table scan is required  as a result of processing a DML statement. A single DML statement could be executing multiple different auxiliary scans on different tables, for the different kinds of objects that need to be maintained. For example, it could be necessary to scan a table to maintain a view, and to scan a different table to verify a foreign key constraint. Therefore, in the process of determining whether an auxiliary table scan is required , it is determined, as shown in , whether there is a referential integrity constraint , an indexed view to maintain , or a cascading action  required as a result of the current DML statement. If so, one or more auxiliary table scans will be required . The query plan is then augmented with appropriately flagged scans. This is accomplished by a flag being set for the auxiliary scan by a query processor of the corresponding DBMS such as MICROSOFT SQL SERVER\u00ae for example. However, it is to be understood that such an action, as well as other processes described herein may be implemented in hardware or software in any number of DBMSs such as MICROSOFT ACCESS\u00ae, DB2\u00ae, INFORMIX\u00ae, MICROSOFT SQL SERVER\u00ae, ORACLE\u00ae, and SYBASE\u00ae, for example, and their corresponding query languages. The query processor flag being set  for an auxiliary scan alerts the system (specifically the DBMS storage engine) that an anomaly may be present when performing the scan and that further processing is required  to detect it. Otherwise, the process can proceed  to the next DML statement, if any.","Referring next to , shown is a flow chart illustrating a high level view of an exemplary process within a database transaction for avoiding anomalies. Specifically, this process describes the actions taken in determining a query plan for processing a DML statement to avoid anomalies while the transaction is being performed under snapshot isolation. As described above, the new anomalies caused by snapshot isolation are due to conflicting requirements when scanning the auxiliary tables in the query plan. After a database transaction begins and during the processing of the DML statement, it is determined whether one or more auxiliary table scans are required . Whether one or more auxiliary table scans are required depends upon whether any implicit actions are required due to a number of factors having to do with preserving data integrity described in further detail with reference to  above. At compile time, i.e., when assembling the DML query plan, it is determined if one or more auxiliary table scans are required in order to implement implicit actions, such as updating an indexed view or performing a constraint validation. This is completed before any implicit actions, such as updating an indexed view or performing a constraint validation, are executed. At run time the query plan is executed. If there are no auxiliary table scans required, then the process skips to the step of determining whether the transaction has ended .","Once it is decided at compile time that one or more auxiliary table scans are required , it is determined at run time while executing the auxiliary scan whether an anomaly is detected  due to the use of the snapshot isolation level. If so, the transaction immediately enters the transaction abortion process  to avoid the anomaly. Otherwise, the implicit action required to maintain data integrity, such as updating an indexed view or performing a constraint validation, is executed . It is then determined whether the database transaction has ended . If so, the transaction is committed  such that the changes made are permanently reflected in the database and any locks are released. If there are still statements left to process in the transaction, then the transaction is continued  and the process starts over with determining whether one or more auxiliary table scans are required .","Referring next to , shown is a flow chart illustrating a lower level view of the process of . The anomaly detection step  of  is shown in greater detail as it is broken down further in . Additionally, the transaction abortion process  of  is also broken down and shown in greater detail. After it is determined that one or more auxiliary table scans are required , as described above, the corresponding auxiliary table scan or scans are performed . In performing the auxiliary table scan , the set of rows that are to be inserted, updated or deleted are read from the latest committed version of the corresponding auxiliary table and then compared  to those rows in the snapshot view of the table taken at the beginning of the transaction. This is performed by the storage engine of the DBMS and again it must be understood that this process may apply to and be implemented in any number of DBMSs such as MICROSOFT SQL SERVER\u00ae, MICROSOFT ACCESS\u00ae, DB2\u00ae, INFORMIX\u00ae, ORACLE\u00ae, and SYBASE\u00ae, for example. It is then determined whether the rows from the auxiliary table and the current transaction's snapshot view of the table differ . If they differ, then the transaction abortion process takes place. This comprises the storage engine generating an error  that is communicated to the user, the transaction itself being aborted , and the transaction then being rolled back  so as to remove any uncommitted changes. The user then has the opportunity to ret-try the transaction. By not allowing such anomalous transactions to complete, this process avoids the effects of such anomalies as described above associated with using the snapshot isolation level, while still ensuring data integrity and read consistency. However, if the compared rows from the auxiliary table and the current transaction's snapshot view of the table do not differ, then the process continues on to verify the constraint, maintain an indexed view, or both , as the case may be, as is described above with reference to .","In avoiding anomalies associated with using the snapshot isolation level, it is highly desirable to abort statements as infrequently as possible. That is, to abort the statement if and only if, an anomaly would otherwise be introduced, thus eliminating situations where statements are needlessly aborted, (i.e., avoiding false positives). If such were the case, it is expected that transaction abortions would be infrequent, as for them to occur it would be necessary that two concurrent transactions simultaneously perform DML operations over rows of different tables interacting with each other through a view or a constraint.","During query execution, the query processor of a DBMS generally has an overall knowledge of the entire DML query plan, while the storage engine of a DBMS generally has only the visibility of the scan being currently processed. This means that when performing an auxiliary scan, the storage engine will not know whether the rows being accessed will be terminally used to validate a constraint or maintain an indexed view, or still need to be processed through further joins or filters. As a result of that, false positives could be reported by the DBMS storage engine. This is due to the fact that when accessing a row as part of an auxiliary scan, the storage engine will not have the ability to tell whether it actually interacts with the rows that have been modified by the current statement in the primary target table. For example, referring to Timeline #3 in the above background section, an error should be raised if and only if the primary key corresponding to the row being inserted in the FK table has been changed by another user after the current transaction started. Changes to other rows in the PK table would not interfere with the current transaction, and should not cause errors to be generated.","Minimizing false positives can be achieved with a different, and slightly more complex, alternative approach. Since it is generally not possible for the DBMS storage engine to know immediately whether a row being read from an auxiliary scan is such to cause an anomaly, it is instead necessary to wait for the row to be processed through the various operators in the query plan. Then an error is raised only if the row actually makes it to the very end, that is, to the operator responsible either for the indexed view maintenance or constraint validation. Since auxiliary scans are performed under the read committed isolation level, if the row happens to be lost because of a filter or a join, it is guaranteed that it will not cause any anomaly for the current plan.","Referring next to , shown is a flow chart illustrating an exemplary alternative process within a database transaction for avoiding anomalies. First, as with the previous approach, it is determined whether one or more auxiliary table scans are required . If so, then the corresponding auxiliary table scan (or scans) are performed . Then according to the alternate approach, the DBMS storage engine adds a virtual column to the rows being returned from the auxiliary table scans . This virtual column contains a Boolean value indicating whether the view of the row under snapshot isolation was different from the read committed isolation level .","For example, referring next to , shown is an exemplary set of rows returned after performing an auxiliary table scan corresponding to the sample database of . In this example, if a current DML statement being processed was to either insert, update or delete rows  and  from the Customers table of , then these rows would be returned as is shown in . Also notice that the virtual column has also been added to the returned set of rows. If the snapshot isolation view of a row (that view saved at the beginning of the current transaction) differs from that under the read committed isolation level (that view as of the last committed transaction) this would be indicated in the virtual column as a 1, for example. Otherwise, if these views of the rows did not differ, it would be indicated by a 0 in the virtual column. For exemplary purposes, the 1 indicated in the virtual column for row  would indicate that the snapshot isolation view of this row differed from that view of the row under the read committed isolation level. The 0 indicated in the virtual column for row  would indicate that the snapshot isolation view of this row was the same as the view of the row under the read committed isolation level.","Referring back to , the virtual column then gets propagated together with the auxiliary table rows in the query plan through any filters and joins . The rows are then validated  before completing any required maintenance of indexed views or verifying any constraint. This is done by checking the virtual column and determining whether the snapshot isolation view of any of the propagated auxiliary table rows differed from that view of the row under the read committed isolation level. In the event that the any of the views of the propagated auxiliary rows do differ, then the transaction abortion process is entered with the DBMS storage engine or the query processor generating an error . The transaction is then aborted  and rolled back . If any of the rows returned from the initial auxiliary table scans are lost because of a filter or join, then it is not necessary to abort the transaction, whether the views of the row differed under snapshot isolation or not. The process described above will prevent this because only the rows propagated through the various operators in the query plan will be subject to validation. In case of aggregates in the query plan, their output will still contain the virtual column, and its value will be true if and only if true for at least one of the rows in input.","In event that the snapshot isolation view of the propagated auxiliary table rows do not differ from that view of the rows under the read committed isolation level, then the requisite constraints are verified and indexed views are maintained . The process then continues on to commit the transaction or continue, as the case may be, as is described above with reference to .","Referring next to through , shown are diagrams illustrating implementations of query plans for various exemplary anomalous transactions. By way of example, shows the \u201cinsert row into T2\u201d action performed at step 5 in Timeline #2 from the above background section, firing an implicit insert over the indexed view V. In this example, indexed view V joins tables T1 and T2. Changes either to T1 or T2 must be propagated to the view, if applicable, to guarantee data integrity. Normally the query plan to insert a row into table T2 would only contain the operator to perform this insertion (the \u201cInsert T2\u201d box  shown in ). However, in presence of indexed views to maintain, more operators must be added to maintain the view. In presence of views that join two tables, the rows that have been either inserted, updated or deleted in the primary target of the DML statement (T2 in this case) are joined  with the other table or tables in the view (shown as the flagged auxiliary scan of T1 , in this case). The result of the join returns the set of rows that must be inserted, updated, or deleted  in the view. Recall that the following select performed at step 6 will return the row from the indexed view, since it has been inserted by the current transaction. However, if the join query at step 7 will use a snapshot of T2 taken at the beginning of the transaction, when the table was still empty, then no row will be returned. This would cause the queries at steps 6 and 7 to return different results. This anomaly will be avoided according to the process of  because the actual insert into V  would only be committed if the snapshot isolation view of the set of rows returned from the auxiliary table scan do not differ from that view of the rows under the read committed isolation level.","Referring now specifically to , illustrated is the is the insert over FK at step 5 of Timeline #3 in the above background section, validating that the foreign key exists in the referenced table PK. Recall here that the query plan for the insert performed at step 5 will contain a scan of the PK table to verify that the values being inserted in FK references an existing row. The row that is to be inserted into FK  is joined  with those returned from the flagged auxiliary scan of PK . The resulting set of rows is used in performing the constraint validation of verifying that a row exists in the referenced table PK  having the foreign key of the row to be inserted into FK. If the scan of the PK table was performed under the read committed isolation level, then the insert would succeed. The following join performed at step 6, however, would return no rows, since PK would be read under the current snapshot, and appear empty. However, according to the process of , this anomaly would be avoided because the actual constraint validation  would only be completed if the snapshot isolation view of the set of rows returned from the scan of the PK table do not differ from that view of the rows under the read committed isolation level.","Referring now specifically to , shown is the delete from table PK at step 5 of the Timeline #4 in the above background section, validating that no matching foreign key exists in the referencing table FK. Recall here that the query plan at step 5 contains a scan of FK to verify that no row exists in the foreign table (FK) matching the one being deleted. The row that is to be deleted from PK  is joined  with those returned from the flagged auxiliary scan of FK . The resulting set of rows is used in performing the constraint validation of verifying that a row was not found  in the referenced table FK matching the primary key of the row being deleted from PK. If the scan of FK was performed under the current snapshot, the newly inserted row in FK would be missed, the delete would succeed, and data would be corrupted. However, according to the process of , the actual constraint validation  would only be completed if the snapshot isolation view of the set of rows returned from the flagged auxiliary scan of FK do not differ from that view of the rows under the read committed isolation level, thus avoiding the anomaly.","Referring next to , shown is a diagram illustrating implementation of a query plan for an exemplary anomalous transaction in which an indexed view contains aggregations.  refers to the \u201cinsert row into T2\u201d action performed at step 5 in Timeline #2 from the above background section. Recall in this example, indexed view V joins tables T1 and T2. Changes either to T1 or T2 must be propagated to the view, if applicable, to guarantee data integrity. In presence of aggregations in the indexed view V, joining T1 with T2 and running the aggregation on the result delivers the difference for the aggregate functions. For example, if a row is inserted into T2, and this row matches with 3 rows in T1, the join of these  will return 3 rows, and the result of the COUNT aggregation  will be 3. This means 3 must be added to the current count stored in the view. In order to do that, the view V is scanned  to determine the current count of the view V. It is then joined  with the previous aggregate , thereby adding 3 to it. Finally, view V is updated  with the new value. In this case, the anomaly of the queries at steps 6 and 7 returning different results could still exist. However, this anomaly would be avoided in the same way according to the process of  because the actual update of V  would only be committed if the snapshot isolation view of the set of rows that are included in the aggregate do not differ from that view of the rows under the read committed isolation level.","Referring next to through , shown are diagrams illustrating implementations of query plans for the various exemplary anomalous transactions of through , respectively, following the alternative process of . Notice that in each transaction, a virtual column is added  to the result of each of the auxiliary scans performed. This column would indicate, row by row, whether the snapshot isolation view of any of the rows from the scan of the auxiliary tables differed from that view of the row under the read committed isolation level. The virtual column then gets propagated together with the auxiliary table rows in the query plan through any filters and joins . Only then are the rows validated  before completing any required maintenance of indexed views or verifying any constraint. This prevents generating errors due to false positives because if the row happens to be lost because of a filter or a join, it is guaranteed that it will not cause any anomaly for the current plan.","For example, the scenario indicated in corresponds to the insert over FK at step 5 of Timeline #3 in the above background section, validating that the foreign key exists in the referenced table PK. Recall here that the query plan for the insert performed at step 5 will contain a scan of the PK table to verify that the values being inserted in FK references an existing row. The flagged auxiliary scan of PK would differ from the snapshot view due to the insert of a row at step 3 into PK from another user that was not captured in the snapshot. If utilizing the process of , this difference would immediately cause an error to be raised and the transaction aborted. However, if the row being inserted into PK did not have a primary key corresponding to the row being inserted into FK, this error would have been needless because it does not interact with the row being inserted into FK. Of course, in order for the operation to succeed, a valid key must exist in the primary table.","Alternatively, the process of as shown implemented in utilizes the virtual column as described above and then waits to perform the validation  until after the join  such that the row inserted into PK (having a true value in the virtual column) gets filtered out. As a result, there is no true value in the virtual column to cause an error being generated and the referential integrity constraint can then be verified .","Exemplary Computing and Network Environment","Referring to , shown is a block diagram representing an exemplary computing device suitable for use in conjunction with various aspects of the invention. For example, the computer executable instructions that carry out the processes and methods for avoiding anomalies that occur due to ensuring read consistency with snapshot isolation may reside and\/or be executed in such a computing environment as shown in . The computing system environment  is only one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention. Neither should the computing environment  be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in the exemplary operating environment .","Aspects of the invention are operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems, environments, and\/or configurations that may be suitable for use with the invention include, but are not limited to, personal computers, server computers, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, set top boxes, programmable consumer electronics, network PCs, minicomputers, mainframe computers, distributed computing environments that include any of the above systems or devices, and the like.","Aspects of the invention may be implemented in the general context of computer-executable instructions, such as program modules, being executed by a computer. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Aspects of the invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules may be located in both local and remote computer storage media including memory storage devices.","An exemplary system for implementing aspects of the invention includes a general purpose computing device in the form of a computer . Components of computer  may include, but are not limited to, a processing unit , a system memory , and a system bus  that couples various system components including the system memory to the processing unit . The system bus  may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. By way of example, and not limitation, such architectures include Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI) bus also known as Mezzanine bus.","Computer  typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer  and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media includes both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can accessed by computer . Communication media typically embodies computer readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term \u201cmodulated data signal\u201d means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.","The system memory  includes computer storage media in the form of volatile and\/or nonvolatile memory such as read only memory (ROM)  and random access memory (RAM) . A basic input\/output system  (BIOS), containing the basic routines that help to transfer information between elements within computer , such as during start-up, is typically stored in ROM . RAM  typically contains data and\/or program modules that are immediately accessible to and\/or presently being operated on by processing unit . By way of example, and not limitation, illustrates operating system , application programs , other program modules , and program data .","The computer  may also include other removable\/non-removable, volatile\/nonvolatile computer storage media. By way of example only, illustrates a hard disk drive  that reads from or writes to non-removable, nonvolatile magnetic media, a magnetic disk drive  that reads from or writes to a removable, nonvolatile magnetic disk , and an optical disk drive  that reads from or writes to a removable, nonvolatile optical disk  such as a CD ROM or other optical media. Other removable\/non-removable, volatile\/nonvolatile computer storage media that can be used in the exemplary operating environment include, but are not limited to, magnetic tape cassettes, flash memory cards, digital versatile disks, digital video tape, solid state RAM, solid state ROM, and the like. The hard disk drive  is typically connected to the system bus  through an non-removable memory interface such as interface , and magnetic disk drive  and optical disk drive  are typically connected to the system bus  by a removable memory interface, such as interface .","The drives and their associated computer storage media discussed above and illustrated in , provide storage of computer readable instructions, data structures, program modules and other data for the computer . In , for example, hard disk drive  is illustrated as storing operating system , application programs , other program modules , and program data . Note that these components can either be the same as or different from operating system , application programs , other program modules , and program data . Operating system , application programs , other program modules , and program data  are given different numbers here to illustrate that, at a minimum, they are different copies. A user may enter commands and information into the computer  through input devices such as a keyboard  and pointing device , commonly referred to as a mouse, trackball or touch pad. Other input devices (not shown) may include a microphone, joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit  through a user input interface  that is coupled to the system bus, but may be connected by other interface and bus structures, such as a parallel port, game port or a universal serial bus (USB). A monitor  or other type of display device is also connected to the system bus  via an interface, such as a video interface . In addition to the monitor, computers may also include other peripheral output devices such as speakers  and printer , which may be connected through a output peripheral interface .","The computer  may operate in a networked environment using logical connections to one or more remote computers, such as a remote computer . The remote computer  may be a personal computer, a server, a router, a network PC, a peer device or other common network node, and typically includes many or all of the elements described above relative to the computer , although only a memory storage device  has been illustrated in . The logical connections depicted in include a local area network (LAN)  and a wide area network (WAN) , but may also include other networks. Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets and the Internet.","When used in a LAN networking environment, the computer  is connected to the LAN  through a network interface or adapter . When used in a WAN networking environment, the computer  typically includes a modem  or other means for establishing communications over the WAN , such as the Internet. The modem , which may be internal or external, may be connected to the system bus  via the user input interface , or other appropriate mechanism. In a networked environment, program modules depicted relative to the computer , or portions thereof, may be stored in the remote memory storage device. By way of example, and not limitation, illustrates remote application programs  as residing on memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.","It should be understood that the various techniques described herein may be implemented in connection with hardware or software or, where appropriate, with a combination of both. Thus, the methods and apparatus of the invention, or certain aspects or portions thereof, may take the form of program code (i.e., instructions) embodied in tangible media, such as floppy diskettes, CD-ROMs, hard drives, or any other machine-readable storage medium wherein, when the program code is loaded into and executed by a machine, such as a computer, the machine becomes an apparatus for practicing the invention. In the case of program code execution on programmable computers, the computing device generally includes a processor, a storage medium readable by the processor (including volatile and non-volatile memory and\/or storage elements), at least one input device, and at least one output device. One or more programs that may implement or utilize the processes described in connection with the invention, e.g., through the use of an API, reusable controls, or the like. Such programs are preferably implemented in a high level procedural or object oriented programming language to communicate with a computer system. However, the program(s) can be implemented in assembly or machine language, if desired. In any case, the language may be a compiled or interpreted language, and combined with hardware implementations.","Although exemplary embodiments refer to utilizing aspects of the invention in the context of one or more stand-alone computer systems, the invention is not so limited, but rather may be implemented in connection with any computing environment, such as a network or distributed computing environment. Still further, aspects of the invention may be implemented in or across a plurality of processing chips or devices, and storage may similarly be effected across a plurality of devices. Such devices might include personal computers, network servers, handheld devices, supercomputers, or computers integrated into other systems such as automobiles and airplanes.","An exemplary networked computing environment is provided in . One of ordinary skill in the art can appreciate that networks can connect any computer or other client or server device, or in a distributed computing environment. In this regard, any computer system or environment having any number of processing, memory, or storage units, and any number of applications and processes occurring simultaneously is considered suitable for use in connection with the systems and methods provided.","Distributed computing provides sharing of computer resources and services by exchange between computing devices and systems. These resources and services include the exchange of information, cache storage and disk storage for files. Distributed computing takes advantage of network connectivity, allowing clients to leverage their collective power to benefit the entire enterprise. In this regard, a variety of devices may have applications, objects or resources that may implicate the processes described herein.",{"@attributes":{"id":"p-0090","num":"0089"},"figref":"FIG. 9","i":"b ","b":["271","272","276","277","273","274","275","278","271","272","273","274","275","276","277","278","271","272","273","274","275","276","277","278","271","272","273","274","275","276","277","278","271","272","273","274","275","276","277","278","270","278"]},"This network  may itself comprise other computing entities that provide services to the system of , and may itself represent multiple interconnected networks. In accordance with an aspect of the invention, each entity , , , , , ,  and  may contain discrete functional program modules that might make use of an API, or other object, software, firmware and\/or hardware, to request services of one or more of the other entities , , , , , ,  and .","It can also be appreciated that an object, such as , may be hosted on another computing device . Thus, although the physical environment depicted may show the connected devices as computers, such illustration is merely exemplary and the physical environment may alternatively be depicted or described comprising various digital devices such as PDAs, televisions, MP3 players, etc., software objects such as interfaces, COM objects and the like.","There are a variety of systems, components, and network configurations that support distributed computing environments. For example, computing systems may be connected together by wired or wireless systems, by local networks or widely distributed networks. Currently, many networks are coupled to the Internet, which provides an infrastructure for widely distributed computing and encompasses many different networks. Any such infrastructures, whether coupled to the Internet or not, may be used in conjunction with the systems and methods provided.","A network infrastructure may enable a host of network topologies such as client\/server, peer-to-peer, or hybrid architectures. The \u201cclient\u201d is a member of a class or group that uses the services of another class or group to which it is not related. In computing, a client is a process, i.e., roughly a set of instructions or tasks, that requests a service provided by another program. The client process utilizes the requested service without having to \u201cknow\u201d any working details about the other program or the service itself. In a client\/server architecture, particularly a networked system, a client is usually a computer that accesses shared network resources provided by another computer, e.g., a server. In the example of , any entity , , , , , ,  and  can be considered a client, a server, or both, depending on the circumstances.","A server is typically, though not necessarily, a remote computer system accessible over a remote or local network, such as the Internet. The client process may be active in a first computer system, and the server process may be active in a second computer system, communicating with one another over a communications medium, thus providing distributed functionality and allowing multiple clients to take advantage of the information-gathering capabilities of the server. Any software objects may be distributed across multiple computing devices or objects.","Client(s) and server(s) communicate with one another utilizing the functionality provided by protocol layer(s). For example, HyperText Transfer Protocol (HTTP) is a common protocol that is used in conjunction with the World Wide Web (WWW), or \u201cthe Web.\u201d Typically, a computer network address such as an Internet Protocol (IP) address or other reference such as a Universal Resource Locator (URL) can be used to identify the server or client computers to each other. The network address can be referred to as a URL address. Communication can be provided over a communications medium, e.g., client(s) and server(s) may be coupled to one another via TCP\/IP connection(s) for high-capacity communication.","In light of the diverse computing environments that may be built according to the general framework provided in and the further diversification that can occur in computing in a network environment such as that of , the systems and methods provided herein cannot be construed as limited in any way to a particular computing architecture. Instead, the invention should not be limited to any single embodiment, but rather should be construed in breadth and scope in accordance with the appended claims."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The systems and methods for avoiding anomalies in presence of DML plans maintaining dependent objects and snapshot isolation in accordance with the invention are further described with reference to the accompanying drawings in which:",{"@attributes":{"id":"p-0011","num":"0010"},"figref":"FIG. 1","i":"a "},{"@attributes":{"id":"p-0012","num":"0011"},"figref":"FIG. 1","i":"b "},{"@attributes":{"id":"p-0013","num":"0012"},"figref":"FIG. 1","i":"c "},{"@attributes":{"id":"p-0014","num":"0013"},"figref":["FIG. 2","FIGS. 3"],"b":["4","5"],"i":"a "},{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 3"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 4","FIG. 3"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":"FIG. 5","i":"a "},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 5","FIG. 1"],"i":["b ","b; "]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 6","i":"a "},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6","i":"b "},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 6","i":"c "},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 7"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":["FIG. 8","FIG. 6","FIG. 5"],"i":["a ","a ","a; "]},{"@attributes":{"id":"p-0024","num":"0023"},"figref":["FIG. 8","FIG. 6","FIG. 5"],"i":["b ","b ","a"]},{"@attributes":{"id":"p-0025","num":"0024"},"figref":["FIG. 8","FIG. 6","FIG. 5"],"i":["c ","c ","a. "]},{"@attributes":{"id":"p-0026","num":"0025"},"figref":"FIG. 9","i":"a "},{"@attributes":{"id":"p-0027","num":"0026"},"figref":"FIG. 9","i":"b "}]},"DETDESC":[{},{}]}
