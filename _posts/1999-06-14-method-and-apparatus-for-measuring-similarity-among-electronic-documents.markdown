---
title: Method and apparatus for measuring similarity among electronic documents
abstract: A method and apparatus are provided for determining when electronic documents stored in a large collection of documents are similar to one another. A plurality of similarity information is derived from the documents. The similarity information may be based on a variety of factors, including hyperlinks in the documents, text similarity, user click-through information, similarity in the titles of the documents or their location identifiers, and patterns of user viewing. The similarity information is fed to a combination function that synthesizes the various measures of similarity information into combined similarity information. Using the combined similarity information, an objective function is iteratively maximized in order to yield a generalized similarity value that expresses the similarity of particular pairs of documents. In an embodiment, the generalized similarity value is used to determine the proper category, among a taxonomy of categories in an index, cache or search system, into which certain documents belong.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=06990628&OS=06990628&RS=06990628
owner: Yahoo! Inc.
number: 06990628
owner_city: Sunnyvale
owner_country: US
publication_date: 19990614
---

{"@attributes":{"id":"description"},"BRFSUM":[{},{}],"heading":["FIELD OF THE INVENTION","BACKGROUND OF THE INVENTION","SUMMARY OF THE INVENTION","DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT","Overview of Generalized Document Similarity Process","Sources of Similarity Information","TABLE 1\u2014Example Contents of Log","Extracting Link Information","Combining Multiple Sources of Similarity Information","Computing the Global Similarity Objective Function","Training Process","Hardware Overview"],"p":["The present invention generally relates to data processing. The invention relates more specifically to determining whether an electronic document is similar to another among a large collection of such documents that are maintained by, for example, an indexing system or search-and-retrieval system.","Hypertext systems now enjoy wide use. One particular hypertext system, the World Wide Web (\u201cWeb\u201d), provides global access over public packet-switched networks to a large number of hypertext documents. The Web has grown to contain a staggering number of documents, and the number of documents continues to increase. The Web has been estimated to contain at least 450 million pages and is expected to expand exponentially over the foreseeable future.","The number of documents available through the Web is so large that to use the Web in a practical way almost always requires a search service, search engine, or similar service. The search engines use \u201cspider\u201d programs that \u201ccrawl\u201d to Web servers around the world, locate documents, index the documents, and follow hyperlinks in those documents to yet other documents. When a search query is entered, the search engine locates relevant documents and displays a set of search results that satisfy the query.","There is a fixed upper limit to the number of documents that a user is willing or able to review before fatigue or frustration result. For example, most people are unwilling to review more than 20\u2013100 documents in a set of search results. Accordingly, most search engines now use relevance criteria when selecting electronic documents to be placed in the search results. Using the relevance criteria, the search engine attempts to determine which of the documents in its index are most relevant to the search query. Normally the search results are presented in a list that is ranked by relevance. Use of relevance criteria is critical to enable the search engine to return to the user a reasonable number of electronic documents that are reasonably related to the query. Otherwise, the user would be unable to locate anything relevant among the millions of documents available online. Unfortunately, current technology does not provide a very sophisticated way to determine relevance.","In contrast, Web documents can be classified into a taxonomy of categories and presented in a browsable directory structure. Such a structure is particularly well-suited to easy navigation by novice users. In the past, classification of documents into categories has been carried out manually by large staffs of human classifiers. An example of a directory that uses such an approach is the Yahoo! search system. Clearly, there is a need for a way of leveraging human inputs to automatically classify large numbers of online electronic documents into a taxonomy of categories.","Extensive research has been done in the use of text analysis to classify text documents into categories. In the past few years, however, the number of text documents available online has grown sufficiently large that traditional text analysis approaches are inadequate. Many parties have worked with varied success at analyzing the text contents of electronic documents in order to classify them.","New approaches exploiting hyperlink structure of the Web are addressing this problem. For example, the CLEVER project of the IBM Almaden Research Center, San Jose, Calif. is developing a search engine and directory engine This work is based on the Hypertext Induced Topic Search process developed by Jon Kleinberg. Generally, in this process, a standard text search engine generates a Training Set of electronic documents that match a query subject or category. The process extends the Training Set to include all documents pointing to or pointed to by each document in the Training Set. Using information that describes the links between the documents, the process seeks the best Authorities and Hubs that match the query or category. Mathematically, the Authorities and Hubs are the principal Eigenvectors of matrices representing the link relations between the documents.","In another approach, the GOOGLE project uses a process of generating PageRanks. PageRanks are iteratively updated based on linked hypertext structures. The resulting PageRanks measure the general connectedness of documents on the Web, without regard to a particular category or query. The assumption is that more connected documents will tend to be of general interest to most users.","Both these approaches rely mathematically on the convergence of a similarity value to the principal Eigenvectors of the link matrices. The speed of convergence depends on the Eigenvalue ratio of the principal Eigenvector to the non-principal Eigenvectors. In the worst case, in which the absolute value of the ratio is close to \u201c1\u201d, iterations of the process can lead to oscillations between different Eigenstates. In that case, the interpretation of Authorities, Hubs, and PageRanks becomes indefinite, or at least slow to converge.","Accordingly, in this field there is a need for a system or mechanism that can iteratively improve the relevance scores of a result set of electronic documents using generalized similarities among electronic documents, without necessitating convergence to Eigenvectors.","There is also a general need for a system that can automatically determine whether one electronic document is similar to another electronic document, and that can create and store a numeric value that identifies the relative similarity of the electronic documents.","There is also a need for a way to automatically classify an electronic document in taxonomy of categories or classifications that are maintained by a document indexing system or search system.","There is a particular need for a way to combine multiple data sources to result in a more meaningful measure of the similarity of electronic documents.","The foregoing needs and objects, and other needs and objects that will become apparent from the following description, are addressed by the present invention, which comprises, in one aspect, a method and system that measures similarity of documents in a hypertext document system, by combining multiple types of indications of similarity of the documents. Each type of document similarity is represented by a separate graph of links. The graphs are combined into a combined graph representing generalized similarity of the documents. From this combined graph, the system computes a measure of document similarity. The measure of document similarity may be used to classify unclassified documents into category nodes of a taxonomy structure associated with a hypertext search system. The system uses the measure of document similarity, in combination with a comparison of a set of pre-classified training set of documents with a set of unclassified documents, to carry out classification.","Other aspects of the invention will become apparent from the following description and the appended claim.","The invention also encompasses a computer-readable medium, system, and apparatus that may be configured to carry out the foregoing steps.","A method and apparatus for determining when electronic documents are similar is described. In the following description, for the purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the present invention. It will be apparent, however, to one skilled in the art that the present invention may be practiced without these specific details. In other instances, well-known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention.","In a preferred embodiment, a process of similarity reinforcement iteratively improves the score of a document using the generalized similarity among two or more electronic documents.","While link information from hypertext structure is used, a Similarity among electronic documents is defined broadly to mean a relation between pages, including but not limited to hypertext links. Any information that characterizes a relationship between Web pages and is helpful in its classification is a Similarity. For example, a Similarity may derive from similarity in document text; a word vector may describe the distribution of word occurrences in a document, and the dot product of two word vectors may characterize the text similarity of two documents. A Similarity may also include equivalent images, audio components, or other multimedia elements. A Similarity may include equivalent component parts of URLs. A Similarity also may be based on user click information; for example, if one document is selected or clicked on often, from or following another document, then the process may determine that the documents are similar.","Thus, multiple data sources are combined to result in a best classification for a document.","The preferred process does not depend on convergence to Eigenvectors of transformation matrices. The process uses a global similarity objective function and maximizes it monotonically in each step of iterations. When the global similarity objective function is maximized, the sum of the distances between each pair of similar documents is minimized. As a result, the total sum of such distances is minimized.","The sum of the distances for a document is a confidence value or score. In a directory engine, the confidence value or score characterizes the confidence that a particular document falls within a particular category. In a search engine, the confidence value or score characterizes the relevance of a particular document to a given query. Normally, the confidence value or score would be sorted or ranked, and documents would be placed in a result set and displayed to a user according to their confidence value or score.","The preferred process has been found to obtain good results with little iteration. The process assures that in each iteration, the process monotonically approaches the optimal solution. Further, good results are obtained by computing only the relative ranking of documents, rather than the absolute values of the confidence scores.","A value representing the Similarity of one document to another preferably is obtained by combining multiple sources of relevance and similarity information.",{"@attributes":{"id":"p-0034","num":"0033"},"figref":["FIG. 1","FIG. 1"],"b":"110"},"1. Link similarity","Web documents, in contrast to documents in text files stored on a discrete or isolated computer, are part of an interconnected system that is used continuously by millions of people. Each day, many people may read a particular document at a Web site, and make judgments about it. It would be useful to harvest information about these judgments by observing actions taken after the judgments are made. Using this information, a system can infer measures of the similarity of any pair of documents, without necessarily considering the text contents of the documents at all.","One means of collecting such information is by observing the graph of hypertext links that connect documents available online or through the Web. Many such links are created by people based upon judgments about other electronic documents. A person may read a particular Web page and decide to make a link to it from their own Web page. In some cases, the person does this because the person judges that the page they are linking to is somehow similar to the page they are linking from. In this sense, a hypertext link indicates a form of similarity among two documents. Although similarity is highly subjective, such that not every individual judgment is useful to others, in practice it has been found that a significant number of judgments and resulting links are \u201cuseful\u201d, in the sense that the hints they provide can be distilled down and exploited to make accurate classification decisions.","As shown in , sources of similarity information may include hyperlink information , such as a graph of links between documents that point to one another.","Thus, hyperlink information may be used to help automatically classify documents. In this case, the similarity element W is assigned the value \u201c1\u201d if page i and page j are linked together, and \u201c0\u201d otherwise. In this context, \u201clinked together\u201d means that either page i is pointed by or points to page j using a hypertext link. When two pages are linked in either way, they are presumed to bear similarity to each other. For other types of similarity, we may use a floating point number between negative one (\u22121) and positive one (1) to indicate similarity or dissimilarity.","The process of assembling hyperlink information and using it in automatic categorization of electronic documents is called \u201clink analysis\u201d. In the preferred embodiment, multiple categories are processed at once. Accordingly, the preferred embodiment implements a process called \u201cmultivariable link analysis\u201d. The weight ascribed to one category is dictated in part by the weight ascribed to a second category.","2. Text Similarity","As shown in , text information  may be useful to classify electronic documents for later retrieval. Most currently available Internet and Web search engines use text to determine the contents of an index that is searched.","Many kinds of text features can be used to measure similarity between documents. The preferred approach is to create and store a word vector for each document and then compare the word vectors of two documents by computing the dot product of the vectors. A word vector is a sparse vector. For example, a word vector would comprise approximately 1,000 elements for a typical document that contains 1,000 unique words, e.g., the word \u201ccomputer\u201d six times, the phrase \u201ctext classification\u201d three times, etc. Comparing 100 million documents to one another would require about 10multiplication operations; using one 300 MHz processor, such computation could require on the order of 3*10seconds, or about 1,000 years. Therefore, a time-saving optimization is to first categorize each document and store category information in association with information about the document. For example, the categorization may be carried out using link analysis. To find textually similar documents, only documents in the same category are compared. To find dissimilar documents, only the documents in the most dissimilar categories are compared. As a result, the most similar and the most dissimilar pairs of documents tend to be obtained. For these pairs, positively weighted or negatively weighted text links are created and stored.","Assume that a hypertext system or search engine has created and stored such word vectors and they accurately describe properties of each document. The document similarity value W is measured using either dot product or norm of difference between the two word vectors for a pair of documents.","3. Multimedia Component Similarity","Multimedia Web pages are being actively developed and placed online. Accordingly, images, audio, and other multimedia components are increasingly found in the contents of electronic hypertext documents. Unfortunately, due to the large amount of memory typically required to store files, most Web crawlers do not fetch image information at all. This is a disadvantage, because this content contains rich information that can very useful for future document retrieval and Internet search systems if an efficient way is found to reduce it into an easily manipulated set of features.","In the preferred embodiment, a crawler of a hypertext search system identifies each multimedia component in an electronic document. The crawler compresses each component into a feature vector that uniquely represents its contents. The similarity of two documents is determined by comparing the values of the feature vectors of the multimedia components they contain.","In one embodiment, feature vectors could be constructed by partial Fourier coefficients from 2-D discrete Fourier transformation, or partial wavelet coefficients from various wavelet transformations. In this approach, the feature dimensions (or number of coefficients) generated by the Fourier transformation or wavelet transformation could be very large. Therefore, a dimension reduction process, such as principal component analysis, may be performed to extract the most discriminative features to result in smaller dimensions. In addition, various other image feature selection techniques such as moment analysis, texture analysis, histogram analysis and contour and edge analysis could be used. For example, image similarity could be very useful for detecting adult content in a document, or product catalog classifications involving a catalog that contains mainly pictures of different products. Other multimedia components, such as audio or video, can also be reduced to feature vectors, between which a similarity measurement can be made.","Alternatively, the names of multimedia files, or sub-components of their names can be used to detect similarity. In the preferred embodiment, the name of the file is broken up into sub-components and a vector similar to a word vector is generated from these sub-components. Similarity of path components is highly indicative of similarity of multimedia content.","In another approach, text can be extracted from images or video by optical character recognition techniques, and used to generate word vectors.","The resulting multimedia component similarity information  may be used in the system of  to imply similarity between two documents containing similar multimedia components.","4. Click Through Similarity","Information that describes a succession of electronic documents retrieved or browsed by a particular user in an online session is known as \u201cclick through information\u201d or simply \u201cclick throughs.\u201d User click through information is useful in determining the similarity of electronic documents. Referring again to , click-through information  may be one source of similarity information.","When a user is browsing electronic documents in an online session, the user may be viewed as an editor of a directory of documents in the Base Set. The user may use a search engine to obtain a set of search results from the Base Set. The search results comprise a list of documents that contain the words in the query, and may comprise a brief summary or abstract of each document. Normally the list of documents includes a hyperlink to each document in the list.","The user reads through the list of abstracts and selects documents that appear to match the user's needs. The user may then click through to the document by selecting a hyperlink associated with the document. Assuming that users generally click through to documents that are judged to be useful, and will not spend time on useless documents, and assuming that the user has one particular need in mind at a time, then the subset of documents that receive a click through by a particular user within a particular time window can be considered Similar.","A system or process may also observe and record the amount of time that the user spends viewing each electronic document. Since browsing electronic documents normally involves little monetary cost, users are generally sensitive to the cost in time of browsing. Thus, assuming that users spend more time on more useful pages, then when the user spends a long time browsing a particular document before returning to the results list, may indicate that the document is highly relevant to the user's needs. Conversely, if a user clicks through to a document, and then immediately selects the BACK button of a browser to return to the result set, then the system may determine that the selected document is not Similar to the user's request.","In addition, within a given time period, the user is likely to select a sequence of electronic documents that belong to the same category. The time period during which a user reviews a particular electronic document, and the sequence of pages the user visits, may be highly useful to determine the relevance and relations among the documents.","For instance, if one document is clicked often in the same time period as another, and both documents are viewed for a long period of time, the classification system may determine that the two pages are relevant to the user's interests and have Similarity. Two assumptions are made. First, the frequency at which a user changes his or her topic of interest is much slower than the frequency at which a user changes pages. Second, a user's interest in a page can be estimated by a function of the time that the user spends in viewing the page.","User click through information may be gathered and used to calculate the similarity matrix W. Assume that a hypertext document system includes a search engine and users who contact the search engine to request electronic documents. A first user issues a query, and the search engine returns a set of document identifiers. The user may perform one or more actions using the documents or the set of identifiers using a mouse or similar pointing device to select actions. The set of actions that are taken by the user is called a user-query session.","At another time, a second user may create another user-query session. Assume the query of the second user is the same, and returns the same set of document identifiers. As a result, two different user sessions are created and stored for the same set of documents.","In the preferred embodiment, the search engine records, for each user session, the identifiers that a user selects, and the time that the user spends viewing each selected document. This information may be used to create and store a document-by-session matrix S(i,j), in which the rows of the matrix represent documents and columns represent various user sessions collected over a certain period of time. The value of one entry S(i, j) represents the interest that user j has shown in document i, which is a function of the time that the user has spent viewing the page, for example.","Often, after viewing results for an initial query, the user may \u201crefine\u201d the initial query by changing or adding to the query keywords. Result sets corresponding to a sequence of such refined queries may be chained together to form an augmented matrix. The assumption is that the user is interested in the same topic, or and is more precisely specifying that topic, through the sequence of queries.","Once the document-by-session matrix is constructed, each row of the matrix may be chosen as a feature vector of the document, and the similarity of a pair of documents based on their feature vectors is measured. The dot product of this vector pair, for example, could serve as the similarity between the two documents. This could be expressed as \n\n","In another alternative, a probabilistic model based on two-way contingency tables is used for simultaneously clustering documents and sessions. Documents belonging to a cluster are then considered as similar, and a link is created between similar documents, which corresponds to an entry in W.","5. Title Similarity","The title of an electronic document provides additional information about it and about its relevance to other electronic documents. In the case of the Web, the HTML language definition includes a tag <\/TITLE> which is used to encode the title of a Web page. The title information is determined by the author of the Web page and stored in its HTML source file, and is often a particularly important indication, or summary, of the contents of the document.","Title information may be stored and used in computing Similarity in the same manner as text similarity. In one embodiment, a separate similarity matrix is constructed for title information. A separate similarity matrix is desirable because the word list used to build feature vectors for title information may be different from the word list used to build a matrix for body text of an electronic document. Further, the weight ascribed to title information, and therefore the value of f contributed to the overall similarity matrix W, could be different than the weight given to body text information.","6. URL Similarity","The location identifier of an electronic document is normally reported in search results by a search engine. In most Web search engines, a Uniform Resource Locator (URL) associated with a Web page normally is the first item of information displayed to the user for each Web page that is in the search results. Accordingly, location identifier or URL information may be useful in determining the Similarity of electronic documents, as indicated by URL Similarity information  of .","In the preferred embodiment, the URL is broken up into sub-components and a vector similar to a word vector generated from these sub-components. Similarity of path components is highly indicative of document similarity. For example, two documents from the Internet domain \u201cwww.inktomi.com\u201d are similar in that they both come from the Inktomi Corporation web site, and may therefore both discuss information related to Inktomi Corporation. Other parts of a URL than the domain name (the first part after the \u201chttp:\/\/) can also provide important hints of similarity.","7. Cache Hit Log Similarity","Another useful source of Similarity information is log information that may be generated by a hypertext system during its operation. A specific embodiment involves obtaining Similarity information from a cache log of a Web cache system.","Generally, a Web cache is a software system that attempts to deliver recently visited Web pages from a high-speed memory storage area rather than from the original source of the Web pages, which may be slow, unavailable, or distant. An example of a carrier-class Web cache is Traffic Server, which is commercially available from Inktomi Corporation, San Mateo, Calif. Traffic Server currently is in commercial use by America Online (AOL), which is the largest Internet Service Provider (ISP) in the world.",{"@attributes":{"id":"p-0074","num":"0073"},"figref":"FIG. 2","b":["200","202","202","202"]},"A human user of the client , or an agent executing in the client, instructs browser  to request a hypertext document according to a particular location identifier. For example, a Web browser of the client may request a Web document using its URL. Browser  submits the request to cache server . The cache server  determines whether the requested document is already in the cache . If it is, the cache server  delivers the requested document to the browser  from the cache . If it is not, cache server  uses a domain name service or similar network element of network  to determine the location of origin server . Cache server  then requests the document from origin server , via network . Finally, cache server  stores a copy of the document in cache , and passes a copy of the document back to browser . Thus, normally, all Web traffic directed from browser  passes through the cache server . The cache server is thereby in the ideal position to log users' requests for various Web documents.","As part of its normal operation, the cache creates and stores one or more logs, including log , which contain a record for each document request. Each log may be implemented as a file stored in a file system on a non-volatile storage file, a list in memory, or any other appropriate data structure or information storage mechanism.","In the preferred embodiment, each log record comprises a Time value, a User ID value, and a Location Identifier value. The Time value represents the time at which a document retrieval request occurred. The Time value acts as a timestamp for the record. It may be stored in Greenwich Mean Time format. The User ID value can represent either an individual person who requested an electronic document, or it can represent the workstation that the individual is using. In one embodiment, the User ID value is an Internet Protocol address (IP address) of the requesting client. The Location Identifier represents the name or location of the electronic document that was retrieved.","TABLE 1 depicts an example of the possible contents of a log .","Time, User ID, Location Identifier",{"@attributes":{"id":"p-0080","num":"0079"},"figref":"FIG. 6","b":"212"},"In this example, each record in the log  represents a request to access a particular document by a particular user at a particular moment in time. The log is created sequentially and chronologically, moving forward in time. Thus, each record has a successively increasing Time value, whereas the values of the User ID and Location Identifier depends on which User ID requests which document at a particular time.","Assuming that human users do not browse electronic documents randomly, it may be inferred that all documents retrieved or browsed by a particular user within a particular time period are Similar. The information derived from a cache log is particularly useful because it is based on all documents visited by users on the Web, not just those that appear in a result set from a search engine. Further, the information derived from such logs is more timely than information based on search engine results. In the case of the Web, the popularity of a particular hypertext document may vary greatly in a short time. Such changes in popularity are reflected rapidly in the logs. A search engine, however, may take several weeks to carry out a \u201crefresh crawl\u201d of the entire Web. New documents are not incorporated into the indices of the search engine until the next crawl cycle. Further, human users add their own hypertext links to electronic documents at a fairly slow rate. Thus, the cache logs are unique in their timeliness and breadth of coverage.","To extract Similarity information, in the preferred embodiment, a matrix is constructed having columns that represent the set of known documents, and having rows that represent a user session. For example, one row has entries for every document that a user has viewed within a session. In this context, \u201csession\u201d refers to a time period within which it is assumed that the user has one topic in mind. This time period is empirically derived for a given group of users. Based on a of documents that are known to be similar, and user behavior can be observed to determine the appropriate attention span for that user population. If this time period is too long, it cannot be said with confidence that successively retrieved documents are similar, because the user may have formulated a new search objective with the passage of time. The elements in this matrix represent the interest that the user is judged to have in the document clicked. This is a function of the time that the user spent viewing that page. This function is also empirically derived by watching the behavior of a population of users for a known set of documents.","The columns of this matrix may be compared to determine the similarity of the documents corresponding to the columns. Documents with similar patterns of user interest can be inferred to contain similar content. In addition, documents that an individual user is highly interested during the span of the user's attention to one topic may also be inferred to be similar. If all pairs of columns i and j are compared with each other, a second matrix Wcan be derived, for which the elements represent the similarity of document i and j as implied by the entries in the cache log. In the preferred embodiment, the comparison of the columns is done by taking their dot product. In another embodiment, the arithmetic difference is taken.","Rows of the matrix, which represent user sessions, can also be compared to profile users, and determine similarity of pairs of users. This can be useful for targeted sales and marketing purposes.","Analysis of hyperlink information requires an organized process of extracting a graph of links from a large database of electronic documents. In the preferred embodiment, a link graph is created and stored from the hypertext documents based on the links that are extracted from them. In an embodiment, the graph comprises a plurality of nodes. Each node is a pair of hash values, in which each hash value represents a Location Identifier. In one embodiment, the hash values are computed using the MD5 hash algorithm, which generates output values having a fixed bit length. In the preferred embodiment, the graph comprises three main parts. A first part is a data file which, for each hash that represents a first document, contains a list of all other hashes which represent documents that link to the first document; and a list of all other hashes which represent documents that are linked to by the first document. A second part is a URL file containing, for each hash, the URL from which it was generated (in order that one can map back from the hash to the URL). A third element is an index file, which lists all hashes in the graph, and for each hash pointer into its corresponding records in the data file, and the URL file.","Referring again to , each of the sources of similarity information , , , , , represented as a graph of links, is fed into a combination function  to produce a combined graph . This graph represents our idea of general similarity of documents taking into account many factors. In one implementation, this combination function make take the union of the separate graphs to produce the combined graph; i.e., if two documents are similar in terms of any of the different features, we consider them similar in the combined sense. In another implementation, the combination function make take the intersection of the separate graphs to produce the combined graph; i.e., a document must be similar in terms of all of the different features to be considered similar in the combined sense. Other combination functions are possible, depending on the nature of the features considered and the desired outcome.","The combined similarity graph  and the similarity objective function  are used to compute a generalized similarity value  for two exemplary documents ,  that are stored in a hypertext system.","Documents ,  are shown by way of example, and the processes and mechanisms described herein may be applied to any number of documents. The resulting generalized similarity value  is used in a variety of ways. In an embodiment, the generalized similarity value  is used to determine the proper category, among a taxonomy of categories in an index, cache or search system, into which documents ,  belong.","1. Foundation Concepts","For the purposes of clarity in the following description, assume that a hypertext system comprises a large group of electronic documents, called the Base Set. Within the Base Set, there is a subset, called a Training Set, of electronic documents that are known to be well classified within directory categories or well labeled with respect to contents. In this configuration, the basic problem addressed by the preferred embodiment is how to select documents in the Base Set that have Similarity to documents in each category of the Training Set, and how to rank the selected documents according to relevance to the categories in which they have been placed. For simplicity, assume that the Training Set comprises only one Category; extension of the process to multiple categories is straightforward.","According to the preferred embodiment, a Similarity Reinforcement process is carried out, based on optimization of a pre-defined global similarity objective function. The global similarity objective function is a way of combining and synthesizing Similarity information that is obtained from multiple sources. The function is termed \u201cglobal\u201d because combines numerous information sources into one value. The function is termed \u201cobjective\u201d because it yields a numeric value that represents Similarity.","The global similarity objective function may be written as: \n\n\nwherein the following definitions apply. One Category of electronic documents is assumed. The expression {x>=0, i=1, 2, . . . , N} represents the confidence values or scores for each electronic document in the Base Set that is classified in the Category. The size of the Base Set is N documents. The Similarity matrix is {W>=0, W<=Wm, i, j=1, 2, . . . , N}. The matrix variable Wrepresents the strength of the Similarity between document i and documents The positive number Wm is the upper bound of a value of an element of the Similarity matrix.\n","It is assumed that the total sum of the confidence scores is a constant, that is, \n\n\nAccordingly, the objective function P(x) is upper bounded by cWm and the optimization process becomes a maximization process.\n","A large value of the matrix variable Wmeans that document i and document j are strongly similar to one another, and if Wis zero, then document i and document j do not relate to one another at all.","The whole system together with its training process is similar to a relaxation system of the type used in the field of physics, such as simulated annealing or random field relaxation.","Here, the whole system consists of N elements and they interact with each other through the interaction force. If the classification confidence scores {x>=0, i=1, 2, . . . , N} represent the mass of the each element in the system and the similarity matrix {W, i, j=1, 2, . . . , N} represents the interaction force between each pair, the function \n\n\nwould represent the total \u201cinteraction energy\u201d in the system. Each term in the summation represents the interaction energy from the contribution of one pair. The system obeys the mass conservation law: \n\n\nHowever, the total interaction energy can increase through the interaction process. Initially, there are some elements serving as the \u201cseeds\u201d (with nozero mass). And, the other elements which have interaction with them but with less mass or zero mass will absorb some mass from the seeds. The stronger the interaction is, the more mass would be transfered. Eventually, the total energy reach maximum and the mass is distributed among seeds and the elements which have stronger interaction with the seeds.\n","Wmay represent the combination of multiple sources of Similarity hints (e.g., text similarity, link similarity). In the preferred embodiment, the value of the elements of the combined matrix Wmay be determined by: \n\n\nThe value Wis the combined similarity between document i and documents, and is some function \u0192 of the various individual types of document similarity between the two documents represented by Wto W\u2014for example, text similarity, link similarity, etc. The function \u0192, in one embodiment, may take the union of the nonzero elements of a pair of similarities Wand W, or in another embodiment, it might take the intersection of the nonzero elements of a pair of similarities Wand W. The function \u0192 that is chosen will depend on the character of the similarities being combined and the desired result.\n","2. Implementation Method",{"@attributes":{"id":"p-0100","num":"0099"},"figref":"FIG. 3A"},"For purposes of clarity, implementation of the method is illustrated by an example in which only text similarity and hyperlink similarity are used, and the gradient search algorithm is employed. Generally, the method includes four major steps, namely the Data Preparation step , Preprocessing step , Generalized Similarity Training step , and Post Processing step .","The Data Preparation Step  creates individual Similarity Matrices of different types, combines them into a Combined Similarity Matrix. This is described in further detail below in the discussion of .","The Pre-processing step  has the goal of calculating one or more Similarity Matrices for different types of similarity, such as text similarity and hyperlink similarity, and combining these matrices using the combination function to calculate the Combined Similarity Matrix.","The Generalized Similarity Training step  takes documents in the training set of each category, essentially finds similar documents to them, and classifies the similar documents into the category. An embodiment is described further in the section below labeled \u201cTRAINING PROCESS\u201d.","The Post-processing step  may generally involve clean up of the results by heuristic methods that have been found in practice to improve results somewhat. For example, Post-processing step  may involve removal of too many documents coming from the same host machine on the Internet, and removal of documents that have been determined to be \u201cspam\u201d documents by a wide variety of heuristic methods.",{"@attributes":{"id":"p-0106","num":"0105"},"figref":"FIG. 3B","b":["302","310"]},"Next, data used in Generalized Similarity Analysis is generated. For purposes of describing an example, assume that two types of data are used to determine similarity, namely hyperlinks among the documents in the training set, and extracted text features. A hyperlink graph is extracted from the documents and constructed in memory based on an expanded set of documents. The expanded set of documents is created by expanding the training set to include all the documents that the training documents point to or that point to the training set documents. A link graph is created and stored to represent the link relationship among all documents in the expanded set, as indicated by block .","In block , using the text contents of each document, possible single- and multiple-word phrases are extracted from the documents. From a training set of 50,000 documents, after expansion into the expanded set, about two million phrases may be derived. Feature analysis and extraction is also carried out on the documents. The text feature analysis and extraction are done using linguistic information about word types, and information gained from analysis of the known categorization within the training set.","A subset of the features that most strongly discriminate documents in one category from documents in another category are selected. For example, based on two million features, about one-half million most discriminative features or word phrases may be chosen. As shown in block , word vectors or feature vectors are constructed for each document in the expanded set. Each component of the feature vectors is the normalized value of the occurrence frequency of a particular feature in this document.","1. Foundation Concepts","After one or more similarity matrices are constructed, for use in Equation (II-3) as set forth above, a training algorithm is applied to maximize the objective function P(x). Use of a training algorithm may be used in Generalized Similarity Training step  of . In embodiments, several different training algorithms may be used. In the preferred embodiments, a gradient ascent learning algorithm or a growth transformation algorithm is applied.","A preferred gradient ascent algorithm has been derived by taking the partial derivatives of P(x) over each xunder constraint of \u03a3x=1 and {x>=0, i=1, 2, . . . , N}. The principle of this algorithm is to search the local maximum along the direction parallel to the gradient \u2207P(x) on the constrained space of x with these N+1 constraints.","Without constraints, the usual gradient search algorithm is represented as \u0394x\u221d\u2207P(x), or \n\n\nwhere xmeans the kiteration and icomponent of x \u03b7>0 is the learning rate, and \u2202P(x)\/\u2202xis the partial derivative of the objective function P(x) with respect to its variable x.\n","When there are constraints, the generalized objective function is \n\n\nwhere each B(x) represents one of the active constraints of \u03a3x=1, and {x,>=0, i=1, 2, . . . N} and \u03bbare Lagrangian multipliers.\n","The values of the Lagrangian multipliers are determined by the Kuhn-Tucker theorem, which requires that the gradient \u2207Q(x) is orthogonal to each \u2207B(x), i=1, 2, . . . , M, and then the search is along \u0394x\u221d\u2207Q(x). This procedure works for general constrained problems, especially for the cases where the objective function P(x) is not well defined beyond the constraints. In the present system, the problem is expected to be simpler. First, as defined, the objective function P(x) has positive gradient \u2207P(x) along all directions, therefore directly using the unconstrained algorithm Equation (II-5) would automatically guarantee all the N constraints {x>=0, i=1, 2, . . . , N}. Therefore, the only active constraint in Equation (II-6) is \u03a3x=1. However, because the quadratic function crosses the constraint boundary \u03a3x=1, the new values of x may be computed by applying Equation (II-5), even if \u03a3x=1 is not satisfied by the new x, and by normalizing it to \u03a3x=1 afterwards.","Therefore, the preferred gradient algorithm is \n\n\nThe efficiency of gradient learning algorithms depends on the choice of learning rate \u03b7. When the data is expected to be relatively uniform, a larger value for the learning rate may be chosen, which will speed up the learning. Normally, the gradient algorithm is valid only if the changes of both x and P(x) are infinitesimally small in each step. Using finite learning steps does not guarantee convergence to the optimal point, namely, the local maximum of P(x).\n","The Growth Transformation algorithm does converge to the optimum with a finite step in each iteration. Growth Transformation algorithms have been applied in the past to maximizing the constrained polynomial objective function, and re-estimation of statistical model parameters of hidden Markov models. An advantage of Growth Transformation is that it guarantees the monotonic increase of the objective function in a finite step, instead of infinitesimal step as most gradient algorithms do.","The mathematical proof and derivation of the preferred Growth Transformation is complex and is omitted for clarity. The preferred Growth Transformation algorithm is: \n\n","In the description above, as an example to illustrate the Similarity concept and derivation of algorithms, only one Category of electronic documents has been assumed. However, the Similarity Reinforcement approach described herein is easily generalized to multiple categories. Assuming that there are C Categories, the objective function is \n\n\nwhere x is the confidence score of idocument belonging to the \u03b2 category.\n","2. Implementation method","This is the major step of the Generalized Similarity Analysis. The goal is, for each document in the expanded set, to generate the classification confidence scores for each category: X(j, k), j=0, 1, . . . N\u22121, k=0, 1, 2, M\u22121, where N is the total number of categories and M the total number of documents in expanded set. The input is the training set (with its classification information marked) and the generalized similarity matrix, W(k, m), k, m=0, 1, 2, M\u22121. Since W(k,m) is a sparse matrix, we only allocate memory for the non-zero elements. During training, the equation of (II-5) is iteratively updated for each category and all documents. And, finally the classification scores are generated.",{"@attributes":{"id":"p-0122","num":"0121"},"figref":"FIG. 4"},"Generally, the method is directed toward generating, for each document in the expanded set, classification confidence scores for each category according to the relation\n\nX(j, k),j=0, 1, . . . N\u22121, k=0, 1, 2, M\u22121\n\nwhere N is the total number of categories and M the total number of documents in expanded set. The input is the training set, with its classification information marked, and the generalized similarity matrix, W(k, m), k, m=0, 1, 2, M\u22121. Since the generalized similarity matrix is a sparse matrix, it is sufficient to allocate memory only for the non-zero elements. During training, stored values that implement equation (II-5) are iteratively updated for each category and all documents. As a result, classification scores are generated.\n","Referring now to , in block , the process reads the training set, the link graph, and the similarity matrices are read into memory. This may involve reading these elements from one or more disk files.","In block , a classification confidence vector for each document is initialized. In one embodiment, the classification confidence vectors are represented as X(j, k)=1 if page k is a training document that belongs to category j; otherwise the vector element is set equal to In block , a loop is entered to carry out training iterations. A counter variable i is initialized to \u201c0\u201d. Block  also involves testing whether the value of i is less than a pre-determined maximum. If not, then training is complete, and the output is written to storage, as indicated by block .","In block , a loop is entered for each category. The purpose is, for a given category j, to update the score values x(j, k), for all documents, k=0, 1, 2, M\u22121. In block , the current value of x(j, k) is copied to a buffer x\u2032(k) that represents the updated new values. At block , a loop is entered for all the documents x(j, k) in this category. If the value of x(j, k) is zero, as tested in block , it will not affect other documents; therefore, control is passed back to block , in effect skipping all the documents with x(j, k)=0.","For each non-zero valued document, as shown in block , the process checks how many non-zero similarity elements it has. This non-zero similarity would cause the score to change for documents it is connected with, in such a way that x\u2032(m)=x\u2032(m)+a*W(k,m)*x(j,k), where a is a predefined \u201clearning rate\u201d. However, because the process provides simultaneous training for all categories, such that the whole document set contains \u201cone-hop away\u201d documents from the training set that contains all categories, two alternating processes are used, as indicated by block  and block . One process is the expanding process, where each training document will transfer its scores to every pages that linked with it, as shown by block . After the expanding stage, there is an updating step, in which only the scores for the documents that have already non-zero scores are updated. This is because the pages having zero scores are not \u201cone hop away\u201d from the training set of current category but \u201cone hop away\u201d from other categories.","After the loop for all categories, a \u201cconvergence check\u201d is carried out in block , in order to compare the difference between the new values and old values. The relative difference is used, that is, the total sum of absolute changes divided by the total sum of old values. If the relative difference is smaller than the predefined percentage value, say 1%, the system is considered converged and the training process terminates.",{"@attributes":{"id":"p-0129","num":"0128"},"figref":"FIG. 5","b":["500","500","502","504","502","500","506","502","504","506","504","500","508","502","504","510","502"]},"Computer system  may be coupled via bus  to a display , such as a cathode ray tube (CRT), for displaying information to a computer user. An input device , including alphanumeric and other keys, is coupled to bus  for communicating information and command selections to processor . Another type of user input device is cursor control , such as a mouse, a trackball, or cursor direction keys for communicating direction information and command selections to processor  and for controlling cursor movement on display . This input device typically has two degrees of freedom in two axes, a first axis (e.g., x) and a second axis (e.g., y), that allows the device to specify positions in a plane.","The invention is related to the use of computer system  for determining when electronic documents are similar. According to one embodiment of the invention, determining when electronic documents are similar is provided by computer system  in response to processor  executing one or more sequences of one or more instructions contained in main memory . Such instructions may be read into main memory  from another computer-readable medium, such as storage device . Execution of the sequences of instructions contained in main memory  causes processor  to perform the process steps described herein. In alternative embodiments, hard-wired circuitry may be used in place of or in combination with software instructions to implement the invention. Thus, embodiments of the invention are not limited to any specific combination of hardware circuitry and software.","The term \u201ccomputer-readable medium\u201d as used herein refers to any medium that participates in providing instructions to processor  for execution. Such a medium may take many forms, including but not limited to, non-volatile media, volatile media, and transmission media. Non-volatile media includes, for example, optical or magnetic disks, such as storage device . Volatile media includes dynamic memory, such as main memory . Transmission media includes coaxial cables, copper wire and fiber optics, including the wires that comprise bus . Transmission media can also take the form of acoustic or light waves, such as those generated during radio-wave and infra-red data communications.","Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, or any other magnetic medium, a CD-ROM, any other optical medium, punch cards, paper tape, any other physical medium with patterns of holes, a RAM, a PROM, and EPROM, a FLASH-EPROM, any other memory chip or cartridge, a carrier wave as described hereinafter, or any other medium from which a computer can read.","Various forms of computer readable media may be involved in carrying one or more sequences of one or more instructions to processor  for execution. For example, the instructions may initially be carried on a magnetic disk of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to computer system  can receive the data on the telephone line and use an infrared transmitter to convert the data to an infrared signal. An infrared detector can receive the data carried in the infrared signal and appropriate circuitry can place the data on bus . Bus  carries the data to main memory , from which processor  retrieves and executes the instructions. The instructions received by main memory  may optionally be stored on storage device  either before or after execution by processor .","Computer system  also includes a communication interface  coupled to bus . Communication interface  provides a two-way data communication coupling to a network link  that is connected to a local network . For example, communication interface  may be an integrated services digital network (ISDN) card or a modem to provide a data communication connection to a corresponding type of telephone line. As another example, communication interface  may be a local area network (LAN) card to provide a data communication connection to a compatible LAN. Wireless links may also be implemented. In any such implementation, communication interface  sends and receives electrical, electromagnetic or optical signals that carry digital data streams representing various types of information.","Network link  typically provides data communication through one or more networks to other data devices. For example, network link  may provide a connection through local network  to a host computer  or to data equipment operated by an Internet Service Provider (ISP) . ISP  in turn provides data communication services through the world wide packet data communication network now commonly referred to as the \u201cInternet\u201d . Local network  and Internet  both use electrical, electromagnetic or optical signals that carry digital data streams. The signals through the various networks and the signals on network link  and through communication interface , which carry the digital data to and from computer system , are exemplary forms of carrier waves transporting the information.","Computer system  can send messages and receive data, including program code, through the network(s), network link  and communication interface . In the Internet example, a server  might transmit a requested code for an application program through Internet , ISP , local network  and communication interface . In accordance with the invention, one such downloaded application provides for determining when electronic documents are similar as described herein.","The received code may be executed by processor  as it is received, and\/or stored in storage device , or other non-volatile storage for later execution. In this manner, computer system  may obtain application code in the form of a carrier wave.","In the foregoing specification, the invention has been described with reference to specific embodiments thereof. It will, however, be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention. The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense."],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"BRIEF DESCRIPTION OF THE DRAWINGS","p":["The present invention is illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings and in which like reference numerals refer to similar elements and in which:",{"@attributes":{"id":"p-0019","num":"0018"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 2"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIG. 3A"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIG. 3B"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIG. 4"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIG. 6"}]},"DETDESC":[{},{}]}
