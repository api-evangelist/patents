---
title: Fast image and video data propagation and blending using intrinsic distances
abstract: Images are colorized, recolorized, or otherwise manipulated by adding scribbles of a blending medium (such as chrominance) to a measurement medium (such as luminance) of the image. The blending medium propagates from the scribbles according to an intrinsic or geodesic distance that is a function of the measurement medium. Intrinsic distances may be weighted. An effect scribble may produce an effect, such as result data, in the blending medium according to a predefined function. A preprocessing scribble may be converted to one or more effect scribbles which are then propagated. A measurement scribble may propagate so as to alter the intrinsic distances of other scribbles.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07672509&OS=07672509&RS=07672509
owner: Regents of the University of Minnesota
number: 07672509
owner_city: St. Paul
owner_country: US
publication_date: 20060502
---

{"@attributes":{"id":"description"},"RELAPP":[{},{}],"heading":["CLAIM OF PRIORITY","GOVERNMENT INTEREST","TECHNICAL FIELD","BACKGROUND","SUMMARY","DESCRIPTION","Basic Colorizing","General Image Manipulation","ILLUSTRATIVE EMBODIMENTS","IMAGE EXAMPLES","CONCLUSION"],"p":["This Application claims priority to U.S. Provisional Application 60\/676,920, filed May 2, 2005.","This invention was made with Government support under grant N00014-03-1-0176 awarded by the Office of Naval Research, support under CCF-0429037 awarded by the National Science Foundation, or support under grant HM1582-04-1-2023 awarded by the National Geospatial-Intelligence Agency. The Government has certain rights in this invention.","The subject matter of this application relates to processing digital images and video, and more particularly concerns manipulating images in accordance with user-supplied data.","Colorization is the art of adding color to a monochrome image or movie. The idea of coloring photos and films is not new. Hand coloring of photographs is as old as photography itself. There exists such examples from 1842 and possibly earlier. It was practiced in motion pictures in the early 1900s by the French Company Path\u00e9, where many films were colored by hand. It was widely practiced also for filmstrips into the 1930s. A computer-assisted process was introduced in 1970 for adding colors to black and white movies.","Various early computer-based colorization techniques include straightforward approaches such as luminance keying. This method uses a user-defined look-up table which transforms gray-scale into color. Others extended this idea by matching luminance and texture rather than just the gray-scale values.","Manual segmentation has been employed to divide a gray-scale image into a set of layers and then to estimate an alpha channel using Bayesian image matting. The final image is constructed using alpha-blending. More recently, a segmentation method has been optimized for colorization of black-and-white cartoons.","Other approaches assume that homogeneity in the gray-scale image indicates homogeneity in the color. In other words, the geometry of the image is provided by the geometry of the gray-scale information. Often, in addition to the gray-scale data, color hints are provided by the user via scribbles in these methods. Probabilistic relaxation methods have been employed. Another researcher has solved an optimization problem that minimizes a quadratic cost function of the color difference between a pixel and its weighted average neighborhood colors. Another has proposed \u201cinpainting\u201d colors constrained by the gray-scale gradients and color scribbles that serve as boundary conditions. This method involves solving linear or non-linear Poisson equations.","The main shortcoming of these previous approaches is the intensive computational cost needed to obtain good-quality results. Some have addressed this issue with a faster algorithm that propagates colored seed pixels in all directions, where the coloring is done by choosing from a preselected list of color candidates. However, this method produces visible artifacts of block distortion, since no color blending is performed.","In addition to colorizing monochrome images, needs exist for recolorizing images that already contain color information. For example, advertisements may wish to emphasize products by showing a scene where only the product itself is in color. Sepia and related effects may create striking visual presentations. Online sales outlets may desire to allow a customer to visualize automobiles or clothing in different colors or styles on Web pages. Photographers may wish to selectively blend new colors with existing colors while retouching images. Beyond merely adding or replacing colors, photographers and artists commonly employ a number of effects or filters for manipulating images for various purposes.","Many of these applications are much more useful when images can be colored or manipulated accurately, with only a small input from the user, and quickly. Some applications are made practical only when the manipulation can be performed interactively in near real time\u2014that is, within a time interval short enough that users can feasibly wait for the results and perhaps provide changes or comparisons without having to interrupt their thoughts or move to another task.","Video images as well as still may profit from such manipulation, especially where the user inputs could be applied to only a relatively small number of frames in a sequence. In the past, however, colorizing video images has required complex and slow techniques such as optical flow, which calculates a velocity field that warps one image into another, usually very similar, image in a sequence. Besides being slow in itself, optical flows generally require execution of an algorithm in addition to already slow image-manipulation algorithm.","The present invention offers fast, accurate methods for manipulating images with relatively small inputs for adding or modifying a number of visual attributes, such as color. These inputs, called \u201cscribbles,\u201d indicate the nature and location of modifications\u2014or lack thereof\u2014within the image or in successive images. Effects of the scribbles propagate to other locations of the image according to an intrinsic distance that is defined as a function of a preselected characteristic or property of the image called a measurement channel or measurement medium. The effects occur in another characteristic\u2014or even in the same characteristic\u2014of the image, called a blending channel or medium. Effects from multiple scribbles blend with each other according to their relative intrinsic distances from their respective scribbles, rather than according to linear distances or values of neighboring pixels. In many applications, scribbles of multiple types may produce different effects, and may be placed on the same image.","The invention further includes computerized systems and media for manipulating images.","This section describes example methods where user mark-ups or scribbles represent colors to be applied to still or video images. The techniques, however, are general, and apply to other image effects as well. This illustrative description employs the YCbCr color space, although other color spaces such as YIQ or YUV may be used instead. Moreover, work may also be done directly on the RGB space. Let Y (x, y, \u03c4): \u03a9\u00d7[0, T]\u2192 be the given monochromatic image (T=0) or video (T>0) defined on a region \u03a9. Our goal is to complete the Cb and Cr channels Cb(x, y, \u03c4): \u03a9\u00d7[0, T]\u2192 and Cr(x, y, \u03c4): \u03a9\u00d7[0, T]\u2192 respectively. For clarity of exposition, we refer to both channels as the chrominance. The present technique also receives as input observed values of the chrominance channels in a region \u03a9\u2208\u03a9 which is significantly smaller than \u03a9. These values are often provided by the user or received from other data.","Let s and t be two points in \u03a9, and let C(p): [0, 1]\u2192\u03a9 be a curve in \u03a9. Let Crepresent a curve connecting s and t such that C(0)=s and C(1)=t. We define the intrinsic or geodesic distance between s and t by:",{"@attributes":{"id":"p-0028","num":"0027"},"maths":{"@attributes":{"id":"MATH-US-00001","num":"00001"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","t"],"mo":","}}},{"msubsup":{"mo":"\u222b","mn":["0","1"]},"mo":"\u2062","mrow":{"mrow":[{"mo":["\uf603","\uf604"],"mrow":{"mrow":[{"mo":"\u2207","mi":"Y"},{"mi":"C","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"p"}}],"mo":"\u00b7"}},{"mrow":{"mo":"\u2146","mi":"p"},"mo":"."}],"mo":["\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.2em","height":"0.2ex"}}}}}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mtext":"="}],"munder":{"mrow":{"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mo":"\u2062","mi":"min"},"msub":{"mi":"C","mrow":{"mi":["s","t"],"mo":","}}}}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"Eqn","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"1"}}}]}}}},"br":{},"sub":"s,t, "},"Geodesic distances of this type can be efficiently and accurately computed using a number of available fast numerical techniques. For many applications, even simpler techniques such as a \u201cbest first one\u201d, such as in E. Dijkstra, \u201cA note on two problems in connection with graphs,\u201d 1, pp. 269-271 (1959), are sufficient.","Even though a mapping between luminance and chrominance is not unique, a close relationship between the basic geometry of these channels is frequently observed in natural images. Sharp luminance changes are likely to indicate an edge in the chrominance, and a gradual change in luminance often indicates that the chrominance is also not likely to have an edge, but rather a moderate change. Exploiting this assumption, a change in luminance should cause a related change in chrominance. Consequently, for the present colorization approach we assume that the smaller the intrinsic distance d(s, t) between two points (s, t), the more similar chrominance they would have. It is important to note that the goal of colorization is not to restore the original colors of images or scenes (which are in general not available in any event), but rather to produce visually pleasant and compelling colored images.","Since the chrominance data are often given in whole regions and not necessarily in single isolated points, we would like to get an idea of the distance from a certain known chrominance \u201cscribbles\u201d having a given uniform color to any point t in \u03a9. We then define the intrinsic distance from a point t (to be colored) to a certain chrominance c, as the minimum distance from t to any point of the same chrominance c in \u03a9c:",{"@attributes":{"id":"p-0032","num":"0031"},"maths":{"@attributes":{"id":"MATH-US-00002","num":"00002"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":[{"msub":{"mi":["d","c"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},{"munder":{"mi":"min","mrow":{"mrow":{"mo":"\u2200","mrow":{"mi":"s","mo":"\u2208","mrow":{"msub":{"mi":["\u03a9","c"]},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mtext":":"},{"mspace":{"@attributes":{"width":"0.3em","height":"0.3ex"}}}],"mi":"chrom","mrow":{"mi":"inance","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"s"}}}}},"mo":"=","mi":"c"}},"mo":"\u2062","mrow":{"mrow":{"mi":"d","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":["s","t"],"mo":","}}},"mo":"."}}],"mo":["\u2062","\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mtext":":"},{"mtext":"="},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}]}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"Eqn","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"2"}}}]}}}},"br":{},"sub":"c "},"Our concept for colorization is to compute the Cb and Cr (chrominance) components of a point t in the region where they are missing (\u03a9\\\u03a9) by blending the different chrominance in \u03a9according to their intrinsic distance to t:",{"@attributes":{"id":"p-0034","num":"0033"},"maths":{"@attributes":{"id":"MATH-US-00003","num":"00003"},"math":{"@attributes":{"overflow":"scroll"},"mtable":{"mtr":{"mtd":[{"mrow":{"mrow":{"mrow":{"mi":"chrominance","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}},"mo":"\u2190","mfrac":{"mrow":[{"mo":"\u2211","mrow":{"mo":"\u2200","mrow":{"mi":"c","mo":["\u2208","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":["chrominances","c"],"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":[{"mo":["(",")"],"msub":{"mi":["\u03a9","c"]}},{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["d","c"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}}}]}}}},{"mo":"\u2211","mrow":{"mo":"\u2200","mrow":{"mi":"c","mo":["\u2208","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":{"mi":"chrominances","mo":["\u2062","\u2062","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mrow":[{"mo":["(",")"],"msub":{"mi":["\u03a9","c"]}},{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"msub":{"mi":["d","c"]},"mo":"\u2061","mrow":{"mo":["(",")"],"mi":"t"}}}}]}}}}]}},"mo":","}},{"mrow":{"mo":["(",")"],"mrow":{"mi":"Eqn","mo":[".","\u2062"],"mstyle":{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},"mn":"3"}}}]}}}},"br":{},"sub":["c","c","c","c"]},"The function W (\u2218) may have the following properties:",{"@attributes":{"id":"p-0036","num":"0035"},"maths":[{"@attributes":{"id":"MATH-US-00004","num":"00004"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":{"munder":{"mi":"lim","mrow":{"mi":"r","mo":"\u2192","mn":"0"}},"mo":"\u2062","mrow":{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}},"mo":"=","mi":"\u221e"}}},{"@attributes":{"id":"MATH-US-00004-2","num":"00004.2"},"math":{"@attributes":{"overflow":"scroll"},"mrow":{"mrow":[{"mrow":{"munder":{"mi":"lim","mrow":{"mi":["r","\u221e"],"mo":"\u2192"}},"mo":"\u2062","mrow":{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}},"mo":"=","mn":"0"},{"mrow":{"munder":{"mi":"lim","mrow":{"mi":["r","\u221e"],"mo":"\u2192"}},"mo":"\u2062","mrow":{"mrow":[{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mrow":{"mi":"r","mo":"+","msub":{"mi":"r","mn":"0"}}}},{"mi":"W","mo":"\u2061","mrow":{"mo":["(",")"],"mi":"r"}}],"mo":"\/"}},"mo":"=","mn":"1"},{"msub":{"mi":"r","mn":"0"},"mo":["\u2062","\u2062","\u2062","\u2062"],"mstyle":[{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}},{"mspace":{"@attributes":{"width":"0.8em","height":"0.8ex"}}}],"mi":"a","mrow":{"mi":"constant","mo":"."}}],"mo":[",","\u2062",","],"mstyle":{"mtext":{}}}}}],"br":[{},{}],"sup":"\u2212b"},"In theory, following the equations above, any point t to be colored will be influenced by all distinct colors c in \u03a9, since d(t)<\u221e.","When high speed or interactivity are desired, fast computation of intrinsic distances from Equation (1) becomes important. Geodesic distances of this type have been studied in the scientific computing community in general, as well as for specific technologies. Their popularity in other disciplines means that their efficient computation has been thoroughly investigated. Algorithms have been inspired by the classical Dijkstra graph algorithm (Dijkstra, above), fast sweeping techniques, and special data structures such as buckets and priority queues. For purposes of illustrating our algorithms, a straightforward, very fast, and accurate implementation involves using these fast techniques to compute, for every point to be colored t in \u03a9\\\u03a9, the distance d(t) to every distinct chrominance c in the given \u03a9, to obtain a set of weights needed for blending according to Eqn (3). We have found that many applications have little need to compute weighted distances as accurately as the abovementioned techniques; the simple classical Dijkstra algorithm is sufficient. Thus we create a graph where each image pixel is a vertex connected to its neighbors with edges that, following Equation (1), have weights equal to the absolute gray value derivatives between its neighbors. We then process this graph with Dijkstra's algorithm. Although more accurate distance computations might involve minimal additional cost, we have found that the increased accuracy is often not necessary to obtain high-quality results.","Table I below shows pseudo code that exemplifies one of the possible ways to efficiently implement a simple algorithm for Equations (1)-(3), based upon Dijkstra, above.",{"@attributes":{"id":"p-0040","num":"0039"},"tables":{"@attributes":{"id":"TABLE-US-00001","num":"00001"},"table":{"@attributes":{"frame":"none","colsep":"0","rowsep":"0"},"tgroup":{"@attributes":{"align":"left","colsep":"0","rowsep":"0","cols":"1"},"colspec":{"@attributes":{"colname":"1","colwidth":"217pt","align":"left"}},"thead":{"row":[{"entry":"TABLE I"},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]},"tbody":{"@attributes":{"valign":"top"},"row":[{"entry":"\u2003Input:"},{"entry":"Gray-scale video\/image."},{"entry":"List of observed pixels \u03a9and their chrominance (user provided scribbles)."},{"entry":"\u2003Output: Colored video\/image."},{"entry":"\u2003Definitions:"},{"entry":"For each pixel in \u03a9 a blend structure is created that contains:"},{"entry":"\u2003\u2003\u03c7 - list of chrominances (the chrominances that reached this blend)"},{"entry":"\u2003\u2003\u03c9 - list of distances (the corresponding intrinsic distance to each"},{"entry":"\u2003\u2003chrominance in \u03c7)"},{"entry":"A link structure contains:"},{"entry":"\u2003\u2003ptr - pointer to a pixel (the destination pixel of the link)"},{"entry":"\u2003\u2003c - a chrominance (the chrominance the link attempts to transfer)"},{"entry":"\u2003\u2003d - distance (the intrinsic distance from the chrominance origin in \u03a9)"},{"entry":"\u2003The basic algorithm:"},{"entry":"\u2003\u2002create an empty blend structure for each pixel in \u03a9"},{"entry":"\u2003\u2002L \u2190 \u00d8"},{"entry":"\u2003\u2002for each pixel p in \u03a9"},{"entry":"\u2003\u2003\u2003let cbe the chrominance of the scribble in p"},{"entry":"\u2003\u2003\u2003create link \u03bb"},{"entry":"\u2003\u2003\u2003(\u03bb.ptr,\u03bb.c,\u03bb.d) \u2190 (p,c,0)"},{"entry":"\u2003\u2003\u2003L \u2190 L\u222a\u03bb"},{"entry":"\u2003\u2003while L \u2260\u00d8"},{"entry":"\u2003\u2003\u03bb \u2190 the link with smallest distance in L (see Footnote (4))."},{"entry":"\u2003\u2003L \u2190 L\\\u03bb"},{"entry":"\u2003\u2003b \u2190 the blend structure of \u03bb.ptr"},{"entry":"\u2003\u2003if \u03bb.c \u2209b.\u03c7"},{"entry":"\u2003\u2003\u2003\u2003add \u03bb.c to b.\u03c7"},{"entry":"\u2003\u2003\u2003\u2003add \u03bb.d to b.\u03c9"},{"entry":"\u2003\u2003\u2003\u2003for all pixels q neighboring p"},{"entry":"\u2003\u2003\u2003\u2003\u2003create link \u03bb"},{"entry":"\u2003\u2003\u2003\u2003\u2003(\u03bb.ptr,\u03bb.c,\u03bb.d) \u2190 (q,\u03bb.c,\u03bb.d +"},{"entry":"\u2003\u2003\u2003\u2003\u2003distance(p,q))"},{"entry":"\u2003\u2003\u2003\u2003\u2003L \u2190 L \u222a \u03bb"},{"entry":"\u2003\u2003\u2002for all pixels in \u03a9; generate the chrominance channels by"},{"entry":"applying Equation (3) with the pixels' blend structures."},{"entry":{"@attributes":{"namest":"1","nameend":"1","align":"center","rowsep":"1"}}}]}}}}},"The described colorization algorithm has average time and space complexity of O(|\u03a9|\u2022|chro min ances(\u03a9)|). The algorithm passes over the image or video for each different chrominance observed in \u03a9and needs a memory in the order of the number of different chrominances observed in \u03a9times the input image\/video size. Although large numbers of scribbles may slow the algorithm or use more memory, this algorithm still appears to be more efficient than those previously reported in the literature.","Since humans perception of blending is limited, high blending accuracy is usually not necessary to obtain satisfactory results. Experimental results show that it is enough just to blend the most significant chrominance\u2014that is, the chrominance with the closest intrinsic distance to its observed source. We found that in natural images it is enough to blend only the two or three most significant chrominances to produce satisfactory results. Such a relaxation reduces both time and space complexity to O(|\u03a9|), thereby becoming linear with respect to the amount of data. Therefore, we may discard from a blend those chrominances having weights in the blending equation that are small relative to the total weight.","Additional quality improvements may be achieved by using adaptive thresholds such as MacAdam ellipses, as presented in D. MacAdam, SCS(MIT Press, Cambridge, Mass., 1970). Any color lying just outside an ellipse is at a just-noticeable-difference (jnd) level, which is the smallest perceivable color difference under the experimental conditions. An adaptive threshold may filter out chrominances that if added to the blend would not cause a jnd.","Relaxations that limit the number of contributors to the blending equation impart a tight restriction on how far the chrominance may propagate and still be included in a blend. Such restrictions may be easily implemented, for example by adding conditions to the loop beginning at \u201cif \u03bb\u00b7c\u2209b\u00b7\u03c7\u201d in Table I.","Our approach is robust with respect to the scribbles placement\u2014that is, the location of the set of scribbles \u03a9. Assume that we know the ideal position to place a scribble. What happens if, instead of placing this scribble, we place a different one. If the ideal scribble and the different one are both inside the same object and the region between them is relatively homogenous, then our gradient weighted metric makes the distance between the two scribbles relatively small. From the triangle inequality, we can then bound the distance from the different scribble to a given pixel to be colored as the sum of the distance from the ideal scribble to the given pixel and the distance between the scribbles. Since the latter is small, the distance from the ideal scribble and the one from the different one to the given pixel are nearly equal, and the result of the colorization algorithm is little changed. If the different scribble is located across an edge, or with high gradients between it and the ideal scribble, then of course the distance between the ideal and the placed scribbles will be large and the algorithm will produce very different results. However, this misplacement indicates a mistake by the user. Moreover, the high speed of our approach often permits the user to correct errors and to add or move scribbles as needed in an interactive manner, without spending excessive time.","The above section presents specific examples of a broader framework in which user-designated data, or effects based upon other data, may be propagated in an input image according to a geodesic or intrinsic distance over a selected aspect or medium of the image. The term \u201cimage\u201d herein includes images of any dimension, video, and collections of data that may be presented or visualized in image format. Images can be 2D, 3D (for example, a stack of computed-tomography scan slices), or even 4D or beyond. An image may have a time coordinate as well. Example manipulations may include:\n\n","The generalized framework employs a number of terms and categorizations. The following topics explain these, and present some non-limiting examples. Categories are for ease of understanding, and may be modified. Descriptions may refer to different broad stages of an algorithm for transforming an input image to a final image.","An optional first stage of the algorithm may preprocess the input image. A second stage measures intrinsic distances, which depend upon image characteristics that define scribble propagation. A third stages applies scribble effects and blends their data to form a final image to be output. This last stage uses the intrinsic distances as guiding factors for blending.","A measurement medium or channel is an aspect, characteristic, property, or attribute of an input image upon which an intrinsic distance is measured. It may comprise one or more channels of data in the input image, and is usually\u2014although not necessarily\u2014an array. The measuring medium might also come from other images or tables that serve as side information to direct the process, such as a depth map, or from a computed tomography (CT) scan that corresponds to a magnetic resonance imaging (MRI) medical image. For colorizing, the channel of luminance data may be the measurement medium. Chrominance may constitute such a medium, for example in recolorization. (Chrominance may refer to one or more channels of data denoting color; for example, RGB data, individually or collectively, may be referred to as a chrominance channel.) Angle, reflection, optical flow, or depth may be employed as a measurement medium or channel. A measurement medium may be a product of an operation upon image data, such as an edge-detection, texture, or style filter. Measurement media may encompass a metric for interframe motion in a video image, such as optical flow. Other measurement media, and functions or composites of a medium, are also possible measurement media.","The term \u201cintrinsic distance\u201d refers to a metric for calculating a minimum distance between two pixels in the input image as a function of a selected measurement medium. For example, colorizing may employ a luminance channel of an input image. Gradients of the luminance data serve as a sort of topographic map for specifying an intrinsic distance along a surface of the luminance map from one pixel to another. However, intrinsic distances may measure image data or properties other than luminance, and they may employ characteristics other than gradients of those properties. The term \u201cgeodesic,\u201d which generally refers to a shortest path between two points on any mathematically defined surface, may be used as another term for intrinsic distance. The previous section describes a representative calculation of an intrinsic distance d(s,t) between two points s and t over a measurement medium Y.","For some purposes, the concept of a neighboring pixel is useful. A neighbor of pixel P is one that directly adjoins pixel P in the particular representation of a digital image. For still images, neighbors may directly adjoin in X and Y directions of a matrix; other neighborhoods could include diagonal pixels as well, or some other configuration. For video images, neighbors may adjoin from frame to frame in the time dimension according to optical flow or some other convenient metric.","\u201cLocal\u201d distance from one pixel to a neighboring pixel in an image may assume different forms. A local-distance function specifies the representation of intrinsic distances from one pixel to the next in an image. A local distance function may be chosen to promote calculation speed. High accuracy is generally less important than speed in this context. Distance may be represented as a real number or as an integer, and may be defined on a coordinate system such as Cartesian. It may also be defined as (positive or negative) integers in only two directions on a finite grid, sometimes called Manhattan distance or taxicab geometry. When a finite grid is employed, rates of change of distance may also be limited to a bounded set of integers in the two directions. Known Dijkstra or fast geodesic computation techniques may also find utility here.","Calculation speed may also be enhanced with a \u201csignificance function\u201d of an intrinsic distance. The function returns a logical TRUE value if a distance from a scribble is small enough to include the scribble's effect in a blend structure for an image pixel, and returns FALSE otherwise. A significance function has the further advantage of blocking data from propagating too close to a different kind of scribble. For example, if the intrinsic distance of a candidate scribble is more than three times the intrinsic distance of the closest scribble to a particular image pixel, then data from the candidate scribble may be discarded from the blend for that pixel. Alternatively, the function may measure the change of the resulting blend that would occur by adding a candidate scribble. If the change would be insignificant, then the candidate scribble may be discarded from the blend, and not propagated further from that point. This function may require knowledge as to how blending is done, but distance estimates are usually sufficient, and the runtime speed is increased.","A blending medium or channel is an aspect, characteristic, property, or attribute that is supplied as result data from scribbles. It may comprise one or more channels of data, which might or might not be present in the original image. For example, color scribbles may produce a chrominance channel in a monochrome image having only a luminosity channel (for colorizing); or they may modify a chrominance channel already present in the input image (for recolorizing). The algorithm produces result data in the blending medium to form the final output image.","A scribble or hint comprises data supplied by a user or some other source to guide blending of the blending medium in forming a final image. A scribble occupies an area or location of the input image. It may be a single pixel or a region of any shape and size; in video images, it may also have a time dimension. A scribble may overlap other scribbles. Scribbles may be thought of as constraints, either hard or soft. The illustrative algorithm described below treats each pixel of a scribble as if it were a separate scribble.","Scribbles may be divided into different kinds. Different kinds of scribbles have different functions for producing a result in the blending algorithm. Scribbles of the same kind supply the blending algorithm with the same type of information, but at different locations of the image. For example, two brown color scribbles are of the same kind, but a green scribble has a kind different from a brown scribble. For efficiency, the processing algorithm may limit the number of different kinds that may participate in a blend at any single pixel.","For organizational purposes, scribble kinds may be divided into four broad categories or classes, generally according to where their results are produced in the algorithm.","Scribble kinds that belong to a result-data class represent different values of result data. For example, a color scribble for simple colorizing specifies a particular color or chrominance value to be propagated to and blended over other areas of an input image. Depth or intensity may be specified in a blended scribble to generate a depth map or an intensity or luminance channel over an image. Scribbles of the result-data class are intuitively simpler than those of other classes, and may be considered to be a simple case of effect class scribbles. The illustrative algorithm described herein processes both result-data and effect scribbles in the same way, as though they were of the same class.","Scribble kinds that belong to the effect class contain data that represent an image-processing operation directly or indirectly related to the measurement medium. Although an effect scribble may generate result data earlier in the algorithm, the generated data take effect only in the final blending stage of the algorithm. An example is a neutral scribble, also called a white scribble. The result of neutral scribbles is to neutralize the effects of other scribbles. That is, neutral scribbles propagate to other image pixels according to their intrinsic distances, but the effect of the neutral scribbles is to function as a mask that reduces the effects of changes to the original image colors from result-data scribbles. Another scribble in the effect class is a palette scribble. Such scribbles apply different colors or chrominance values from a certain palette according to the measurement medium of the image pixel. Other effect-scribble kinds may perform functions generally classed as filters or effect filters in graphics programs. For example, a blurring scribble may blur the input image progressively more weakly from the scribble, according to intrinsic distance based upon a measurement medium such as luminance. Other such scribbles may sharpen the image or add sepia, embossing, texture, or other styles to the image.","Scribble kinds that belong to a preprocessing class operate before the measurement stage begins. Preprocessing scribbles generate result-data or effect scribbles in the same image location as that of the preprocessing scribble. Thus, the measurement stage never receives the preprocessing scribbles themselves, but only corresponding result-data or effect scribbles. Copy scribbles, for example, copy data underlying the same position as the copy scribbles in the original image. For recolorizing applications, preprocessing converts each pixel of copy scribbles into separate color scribbles having the same chrominance as that of the image pixel at that position. These color scribbles\u2014which are actually a kind of result-data scribble\u2014propagate over the image in the normal fashion, but at a later stage of the algorithm. Black scribbles, described below, may operate as masks. Another example of a scribble kind of this class may generate palette scribbles according to underlying color statistics.","Scribble kinds that belong to a measurement class are effectuated only in the measurement stage of the algorithm. Unlike those of the other classes, measurement scribbles produce no data that propagates or blends. Rather, they operate upon or modify intrinsic distances, to affect how data from other scribbles propagate across the input image. For example, directional scribbles may penalize or enhance propagation only in a specified direction of the image. Such a directional penalty may be a hard constraint specified by the user, or it may be a soft constraint that varies with the underlying measurement data. (In this type of scribble, the \u201clending channel\u201d may be considered the same as the measurement channel.) Boundary scribbles decrease the propagation of other scribbles through their boundaries, either when entering or when exiting scribbles through them. Hard boundaries stop all propagation; that is, they effectively increase the intrinsic distance from other scribbles to an infinite value. Soft boundaries extract a propagation penalty by increasing intrinsic distance values. The penalty may be an interpolation of the measurement medium. For example, a boundary scribble that detects an edge in the image may penalize only that edge, rather than the entire scribble area. Boundary scribbles may be placed to prevent color from bleeding into an image area that has no edge or luminosity gradient. Easer or enhancement scribbles are essentially negative boundary scribbles. They enhance data propagation through them, by decreasing effective intrinsic distances.","Result data is the data type that results from the application of a blending algorithm to image data for an attribute, characteristic, property, or data channel that is to be modified in the image. This image data may be a further channel added to the original input image, or it may already exist in the input image. For example, colorizing employs chrominance data or channels as the result data type. Other examples include luminance or intensity, depth maps, angle data, transparency data, or reflection data. Result data are calculated in accordance with intrinsic distances from the measurement medium.","Blend weight is calculated from intrinsic distances between a scribble pixel and another arbitrary pixel in the image. Although the effects of different scribbles upon a given image pixel could vary in direct proportion to their intrinsic distances, the distances may be weighted according to a desired weighting function. As described below, a weighting function may comprise W=r, where r is the intrinsic distance and b is a parameter; in one example, b=4. Another possible distance weighting function is W=e. It is also possible to use multiple different distance weighting functions concurrently for different purposes, such as for different kinds of scribbles.","The combination of the different types of scribbles and different types of measurements and blends provide a rich framework for a large number of image-modification tasks, beyond mere colorization and recolorization of still or video images.",{"@attributes":{"id":"p-0065","num":"0073"},"figref":"FIG. 1","b":"100"},"Block  receives an input digital image, usually in the form of one or more arrays of pixels having certain channels of data for each pixel. As noted earlier, the image may include only one channel, such as luminance data, or it may include multiple channels, such as luminance, chrominance, depth, transparency, and so forth. Video images may include channels such as optical flow. Block  may also display the input image to a user.","Block  receives scribbles from the user. The user may draw scribbles with an input device, such as a mouse, graphics tablet, or touch screen, directly on a display of the input image if desired, specifying different types of scribbles by keyboard selection or other means. Block  may display the scribbles directly on the input image. Different kinds of scribbles may be displayed differently for tracking by the user. Different media (e.g., brush width or scribble shapes) may be simultaneously used to input the scribbles. Block  may also store the image locations and types of the scribbles in one or more appropriate data structures. Scribbles may additionally be input from other images. For example, a set of prespecified scribbles may be used for multiple images, or user-defined scribbles from one frame of a video may serve to colorize a different frame. Input data for scribbles may originate from sources other than images.","In another application, the invention may be used to implement a form of lossy image compression. Instead of storing a full color image, a gray-scale image version may be stored with an automatically generated list of single-pixel scribbles for subsequently recoloring the image.","Block  represents an optional preprocessing stage of method . Stage  converts scribble kinds of the preprocessing class into scribble kinds of other classes, which will be acted upon in subsequent stages.","Stage  may also perform general image-processing functions, automatically or as specified by a user, to produce a modified image from the original image. For example, a median filter may perform a denoising operation upon the input image, or edge enhancement. In this implementation, the modified image is used only for measurement purposes in block ; block  always employs the original image. The functionality of block  is required only if preprocessing scribbles are input from block , or if a general image-processing function is selected. If the original image is needed as part of the result (such as for colorizing the luminance channel), block  may store an unprocessed copy of the input image.","Block  represents the measurement stage of the algorithm, which calculates intrinsic distances from each scribble to pixels in the input image, including any alterations due to scribbles of the measurement class.","Block  applies blending effects and blends the appropriate result-data type from each scribble of the effect class to determine values of each pixel in the final image in each relevant channel\u2014luminosity, chrominance, transparency, etc. One or more channels, such as luminosity, may remain the same in the final image as they were in the original input image.","Block  outputs the final image. This final image may be stored, displayed, printed, transmitted, or further manipulated as desired. For example, the final image may go through a post-processing operation such as adding granularity noise.",{"@attributes":{"id":"p-0074","num":"0082"},"figref":"FIG. 2","b":["130","130","210"]},"Loop header  processes each pixel in the current preprocessing scribble. Code in block  generates a new scribble of another class for the pixel location according to a function defined for that scribble kind.","Block  performs general processing effects on the input image, such as denoising. This is important for example for processing noisy images such as old pictures or films. Processing effects may be executed before blocks -, as well as afterward. Because block  may produce a modified image, block  saves a copy of the original input image for use by other stages, such as  or .",{"@attributes":{"id":"p-0077","num":"0085"},"figref":"FIG. 3","b":["140","150"]},"In initialization blocks , block  initializes the blend structures (BSs) of all pixels to be empty. In a 2D input image, the location Lof each pixel may be specified by its {x,y} coordinates in an array. The blend structure BS for each pixel has a variable number of elements, initially none. Each element has two entries. The first entry designates one of the kinds of scribbles present in the image. In this embodiment, a single kind is eligible for inclusion only once in a single blending structure; the algorithm guarantees that the scribble that is included is the closest one of its kind to the current image pixel. The second entry contains the intrinsic distance Lof that pixel a scribble of that kind. The intrinsic distance to a multi-pixel scribble of that kind may be taken as the intrinsic distance to the closest pixel of the scribble to L.","Initialization block  creates a priority queue Q initially having a link for every image pixel that is part of each scribble of the effect class. Because a single image pixel may be included in more than one effect scribble, a single image pixel may have multiple links. One entry of each link is initialized to point to the image pixel location L. Another entry contains a code designating the kind Lof the scribble. The third entry contains the intrinsic distance of the pixel Lfrom the scribble; this value is initialized to zero. (The distance of another pixel within the same scribble will remain zero.) The links are arranged in priority order according to their distance entries L; larger distances have lower priorities. The queue may assume a number of different forms, including a binary or k-ary heap, a binomial, Fibonacci, or other heap, a bucket sort, or a calendar queue. Details of one specific implementation will be described in connection with , where the queue Q may have a number of buckets, and may be cyclic.","Output blocks  terminate measurement stage . When block  finds that queue Q is empty, all links have been processed. Block  then outputs the completed blend structures for all scribble pixels to the next stage.","Blocks  process a link in the queue. As long as the queue is not empty, block  fetches the next link, removing it from the queue. Because Q is a priority queue, the links are fetched in order of increasing distance L. If a scribble of the same kind Lalready resides in the blend structure for that particular image pixel, block  returns control to loop head  without further processing. Preventing multiple scribbles of the same kind avoids loops in the algorithm.","Several tests optionally speed up computation at the expense of small, usually acceptable, and often not noticeable, accuracy penalties. Stage  may include an arbitrary maximum size limit for the number of kinds that can participate in a blend. Block  detects whether this limit has been reached, and return control to loop head  if the blend is already full. Block  tests the pixel against an optional significance function, described earlier. This function returns a FALSE value if the pixel distance exceeds an arbitrary threshold. In that case, the effect of a blend would be imperceptible, and control returns to block .","If tests - are successful, block  adds the values of Land Lfrom the current link as a new element in the blend structure of the current pixel L.","Blocks  create links that attempt to propagate the same scribble kind Lto neighbors of the current image pixel. Block  selects each neighbor in turn of an image pixel. Block  calculates the local distance of that neighbor according to the measurement medium, according to a local distance function as described above. Block  adds the local distance between the neighbor and the current pixel to the Lvalue of the current pixel, taken from its link . Block  then creates a new link containing the Lof the neighbor pixel, the Ldesignation of the scribble from the link fetched by block , and an Lvalue representing the summed distances from block . Block  inserts the link into the queue at a priority determined by the Lvalue of the new link.","Distance addition and the priority queue cause stage  to calculate intrinsic distances outwardly from the scribble areas in an efficient manner, starting with image pixels that are most affected by the scribble, and terminating the propagation as soon as one of the tests in blocks - finds that the scribble would no longer contribute any significant amount to the blend for a given image pixel.","Blocks  calculate distance if the neighbor pixel lies within a scribble of the measurement class. Block  determines whether the image pixel location lies within a measurement scribble. If so block  calculates an altered local distance according to the kind of the measurement scribble by calling the kind's predefined measurement function to generate the altered local distance. As discussed previously, measurement scribbles may be of several different kinds.",{"@attributes":{"id":"p-0087","num":"0095"},"figref":["FIG. 4","FIG. 1"],"b":["150","150","150","140"]},"Block  traverses each image pixel in the input image as a subject pixel. Blocks  process individual scribble kinds in the pixel's blend. By the beginning of stage , all scribbles are of the effect class, because stage  has converted preprocessing scribbles into effect scribbles, and measurement scribbles are never added to the blend. As noted above, result data scribbles are actually a sub-class of the effect-scribble class, and are treated the same in stage .","Blocks  process the scribbles that are contained in the blend structure for the current pixel selected at block . Block  selects in turn each scribble kind that is present in the blend structure of the current pixel. Block  then executes the predefined function that generates the effect of that kind of scribble. For example a simple color scribble produces a chrominance value matching that of the color scribble itself. A style scribble function may insert a color, intensity, or other attribute taken from a stored pattern for that style. A palette scribble function selects a color out of a palette according to the intensity of the original image or according to the type of region being processed, such as a library of colors for a tree or for the sky. The palette can be fixed or variable (dynamic), for example for movie colorization. A blur scribble function may mix original colors from nearby image-pixel locations.","Block  converts the intrinsic distance of the current scribble kind to a blend weight using a predefined weighting function, such as described above under the definition of \u201cblend weight.\u201d","When all scribbles have been processed in blocks , block  transfers control to block . This block normalizes the blend weights of the current pixel. Dividing each one by the sum of all of them is a convenient way to normalize the weights. For example, if a certain image pixel is affected by a green, a brown, and a mauve scribble with respective weights 5, 15, and 30, then the mix of colors for that pixel would be 10% green, 30% brown, and 60% mauve. Block  then applies the blend to the current pixel, and  selects another current pixel until all pixels in the input image have been blended.",{"@attributes":{"id":"p-0092","num":"0100"},"figref":"FIG. 5"},{"@attributes":{"id":"p-0093","num":"0101"},"figref":"FIG. 6","b":["600","610","620","630","640","650","640","641","642","643","640"]},"Media  may hold or transfer code and data for implementing algorithm or method . Algorithm  utilizes data structures , such as the blend structure and priority queue described above.",{"@attributes":{"id":"p-0095","num":"0103"},"figref":"FIGS. 7-11"},{"@attributes":{"id":"p-0096","num":"0104"},"figref":["FIG. 7A","FIG. 7B","FIG. 7A","FIG. 7C","FIG. 7A","FIG. 7D"]},{"@attributes":{"id":"p-0097","num":"0105"},"figref":["FIG. 8A","FIG. 8B"]},{"@attributes":{"id":"p-0098","num":"0106"},"figref":["FIG. 9A","FIG. 9B"]},{"@attributes":{"id":"p-0099","num":"0107"},"figref":["FIG. 10A","FIG. 10B","FIG. 10A"]},{"@attributes":{"id":"p-0100","num":"0108"},"figref":["FIG. 11A","FIG. 11B"]},"The foregoing description and drawing illustrate certain aspects and embodiments sufficiently to enable those skilled in the art to practice the invention. Other embodiments may incorporate structural, process, and other changes. Examples merely typify possible variations, and are not limiting. Portions and features of some embodiments may be included in, substituted for, or added to those of others. Individual components, structures, and functions are optional unless explicitly required, and operation sequences may vary. The word \u201cor\u201d herein implies one or more of the listed items, in any combination, wherever possible. The required Abstract is provided only as a search tool, and is not to be used to interpret the claims. The scope of the invention encompasses the full ambit of the following claims and all available equivalents."],"GOVINT":[{},{}],"BRFSUM":[{},{}],"brief-description-of-drawings":[{},{}],"description-of-drawings":{"heading":"DRAWING","p":[{"@attributes":{"id":"p-0015","num":"0014"},"figref":"FIG. 1"},{"@attributes":{"id":"p-0016","num":"0015"},"figref":["FIG. 2","FIG. 1"]},{"@attributes":{"id":"p-0017","num":"0016"},"figref":["FIG. 3","FIG. 1"]},{"@attributes":{"id":"p-0018","num":"0017"},"figref":["FIG. 4","FIG. 1"]},{"@attributes":{"id":"p-0019","num":"0018"},"figref":["FIG. 5","FIG. 4"]},{"@attributes":{"id":"p-0020","num":"0019"},"figref":"FIG. 6"},{"@attributes":{"id":"p-0021","num":"0020"},"figref":"FIGS. 7A-D"},{"@attributes":{"id":"p-0022","num":"0021"},"figref":"FIGS. 8A-B"},{"@attributes":{"id":"p-0023","num":"0022"},"figref":"FIGS. 9A-B"},{"@attributes":{"id":"p-0024","num":"0023"},"figref":"FIGS. 10A-B"},{"@attributes":{"id":"p-0025","num":"0024"},"figref":"FIGS. 11A-B"}]},"DETDESC":[{},{}]}
